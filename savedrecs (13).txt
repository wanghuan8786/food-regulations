FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Sherman, ZM
   Howard, MP
   Lindquist, BA
   Jadrich, RB
   Truskett, TM
AF Sherman, Zachary M.
   Howard, Michael P.
   Lindquist, Beth A.
   Jadrich, Ryan B.
   Truskett, Thomas M.
TI Inverse methods for design of soft materials
SO JOURNAL OF CHEMICAL PHYSICS
AB Functional soft materials, comprising colloidal and molecular building blocks that self-organize into complex structures as a result of their tunable interactions, enable a wide array of technological applications. Inverse methods provide a systematic means for navigating their inherently high-dimensional design spaces to create materials with targeted properties. While multiple physically motivated inverse strategies have been successfully implemented in silico, their translation to guiding experimental materials discovery has thus far been limited to a handful of proof-of-concept studies. In this perspective, we discuss recent advances in inverse methods for design of soft materials that address two challenges: (1) methodological limitations that prevent such approaches from satisfying design constraints and (2) computational challenges that limit the size and complexity of systems that can be addressed. Strategies that leverage machine learning have proven particularly effective, including methods to discover order parameters that characterize complex structural motifs and schemes to efficiently compute macroscopic properties from the underlying structure. We also highlight promising opportunities to improve the experimental realizability of materials designed computationally, including discovery of materials with functionality at multiple thermodynamic states, design of externally directed assembly protocols that are simple to implement in experiments, and strategies to improve the accuracy and computational efficiency of experimentally relevant models.
RI Park, Michael/HNJ-2201-2023; Truskett, Thomas M/D-4624-2009; Truskett,
   Thomas/N-1098-2019; Howard, Michael/F-1587-2019
OI Truskett, Thomas M/0000-0002-6607-6468; Sherman,
   Zachary/0000-0001-9798-287X; Jadrich, Ryan/0000-0002-0175-1709; Howard,
   Michael/0000-0002-9561-4165
SN 0021-9606
EI 1089-7690
PD APR 14
PY 2020
VL 152
IS 14
AR 140902
DI 10.1063/1.5145177
UT WOS:000526709300002
PM 32295358
ER

PT J
AU Al-Jodah, A
   Shirinzadeh, B
   Ghafarian, M
   Das, TK
   Tian, YL
   Zhang, DW
   Wang, FJ
AF Al-Jodah, Ammar
   Shirinzadeh, Bijan
   Ghafarian, Mohammadali
   Das, Tilok Kumar
   Tian, Yanking
   Zhang, Dawei
   Wang, Fujun
TI Development and control of a large range XY circle minus
   micropositioning stage
SO MECHATRONICS
AB The recent developments in micro/nano-positioning technologies have highlighted the demand for compact large range three-degrees-of-freedom (3-DOF) XY circle minus mechanisms for applications such as sample positioning in nanoimprint lithography, scanning probe microscopy, precision machining, and many more. However, this type of mechanisms suffers from a large footprint, sensing difficulties, and low motion accuracy due to the cross-coupling errors. In this paper, a compact design is proposed to achieve large workspace and high motion accuracy. Prismatic-Prismatic-Revolute (PPR) joints were used to construct this mechanism to yield deterministic large range motions. Laser-based measurement technique based on retroreflectors is proposed to sense large translations and rotation simultaneously with nanometer resolution. A prototype of the proposed mechanism was fabricated to investigate the static and dynamic properties of its structure, and compare these with the computational results. The motion accuracy of the mechanism was improved by using a sliding mode controller based on a nonlinear disturbance observer. The cross-coupling effects and modelling uncertainties were estimated and compensated in this control scheme, which consequently improved the tracking performance. The experimental results showed that the proposed design achieved large workspace, high resolution, improved tracking performance, and required level of compactness as compared with other designs reported in the literature.
RI Al-Jodah, Ammar/U-6920-2019; Ghafarian, Mohammadali/AAB-2372-2020
OI Al-Jodah, Ammar/0000-0003-4536-1240; Ghafarian,
   Mohammadali/0000-0003-4649-650X; Das, Tilok Kumar/0000-0001-8460-6533
SN 0957-4158
PD APR
PY 2020
VL 66
AR 102343
DI 10.1016/j.mechatronics.2020.102343
UT WOS:000528260300007
ER

PT J
AU Kavitha, PM
   Anitha, M
   Pushpalatha, K
AF Kavitha, P. M.
   Anitha, M.
   Pushpalatha, K.
TI Art of Image Augmentation with Cartoon Models
SO BIOSCIENCE BIOTECHNOLOGY RESEARCH COMMUNICATIONS
AB A CNN is used to classify the data when it's placed in different orientations. The CNN is invariant to translation, viewpoint, illumination or size. It can even be a combination of these. Thus by using data augmentation, information can be added to the base data and enhancing the quality of the same. A machine learning network usually needs tremendous amount of data to work with. Practically collecting such huge data may often be costly. To reduce it, the data is augmented before its fed into the network. Augmentation reduces the manual intervention and develops the data. Augmentation can be applied to the data irrespective of the form. Image augmentation is s methodology where the image is manipulated by various augmentation techniques, thereby creating numerous different samples for a single image. In simple words, it creates a diverse set of images from a small set of input image. Among the various techniques available, the most common techniques included here are cropping, flipping, rotation, zoom-out. Once these techniques are applied on the image the respective images are obtained via augmentation methodology. After the augmented images are in hand, one can apply to any network any get the accurate output. Without augmentation, there may be a chance of irrelevant of erroneous output, since only a few data may be fed into the network.
RI Krishnan, Pushpalatha/AAY-7568-2021; Kavitha, PM/ABE-3866-2021
OI Krishnan, Pushpalatha/0000-0002-9301-9274; Kavitha,
   PM/0000-0003-2709-2032
SN 0974-6455
PY 2020
VL 13
IS 6
SI SI
BP 45
EP 49
UT WOS:000640077500010
ER

PT C
AU Watson, C
   Tufano, M
   Moran, K
   Bavota, G
   Poshyvanyk, D
AF Watson, Cody
   Tufano, Michele
   Moran, Kevin
   Bavota, Gabriele
   Poshyvanyk, Denys
GP IEEE Comp Soc
TI On Learning Meaningful Assert Statements for Unit Test Cases
SO 2020 ACM/IEEE 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING
   (ICSE 2020)
SE International Conference on Software Engineering
CT 42nd ACM/IEEE International Conference on Software Engineering -
   Companion Proceedings (ICSE-Companion) / 42nd ACM/IEEE International
   Conference on Software Engineering - Software Engineering in Practice
   (ICSE-SEIP)
CY JUN 27-JUL 19, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, IEEE, IEEE Comp Soc, IEEE Comp Soc Tech Comm Software Engn, ACM Special Interest Grp Software Engn, Korean Inst Informat Scientists & Engineers, Natl Sci Fdn, Facebook, N Carolina State Univ, Microsoft, Samsung, LG Elect, KAIST, SK Hynix, NAVER, Suresoft, HITACHI, Google
AB Software testing is an essential part of the software lifecycle and requires a substantial amount of time and effort. It has been estimated that software developers spend close to 50% of their time on testing the code they write. For these reasons, a long standing goal within the research community is to (partially) automate software testing. While several techniques and tools have been proposed to automatically generate test methods, recent work has criticized the quality and usefulness of the assert statements they generate. Therefore, we employ a Neural Machine Translation (NMT) based approach called Atlas (AuTomatic Learning of Assert Statements) to automatically generate meaningful assert statements for test methods. Given a test method and a focal method (i.e., the main method under test), Atlas can predict a meaningful assert statement to assess the correctness of the focal method. We applied Atlas to thousands of test methods from GitHub projects and it was able to predict the exact assert statement manually written by developers in 31% of the cases when only considering the top-1 predicted assert. When considering the top-5 predicted assert statements, Atlas is able to predict exact matches in 50% of the cases. These promising results hint to the potential usefulness of our approach as (i) a complement to automatic test case generation techniques, and (ii) a code completion support for developers, who can benefit from the recommended assert statements while writing test code.
OI Poshyvanyk, Denys/0000-0002-5626-7586; BAVOTA,
   Gabriele/0000-0002-2216-3148
SN 0270-5257
BN 978-1-4503-7121-6
PY 2020
BP 1398
EP 1409
DI 10.1145/3377811.3380429
UT WOS:000652529800114
ER

PT J
AU Ghica, DR
   Alyahya, K
AF Ghica, Dan R.
   Alyahya, Khulood
TI Latent semantic analysis of game models using LSTM
SO JOURNAL OF LOGICAL AND ALGEBRAIC METHODS IN PROGRAMMING
AB We are proposing a method for identifying whether the observed behaviour of a function at an interface is consistent with the typical behaviour of a particular programming language. This is a challenging problem with significant potential applications such as in security (intrusion detection) or compiler optimisation (profiling). To represent behaviour we use game semantics, a powerful method of semantic analysis for programming languages. It gives mathematically accurate models ('fully abstract') for a wide variety of programming languages. Game-semantic models are combinatorial characterisations of all possible interactions between a term and its syntactic context. Because such interactions can be concretely represented as sets of sequences, it is possible to ask whether they can be learned from examples. Concretely, we are using LSTM, a technique which proved effective in learning natural languages for automatic translation and text synthesis, to learn game-semantic models of sequential and concurrent versions of Idealised Algol (IA), which are algorithmically complex yet can be concisely described. We will measure how accurate the learned models are as a function of the degree of the term and the number of free variables involved. Finally, we will show how to use the learned model to perform latent semantic analysis between concurrent and sequential Idealised Algol. (C) 2019 Elsevier Inc. All rights reserved.
OI Ghica, Dan/0000-0002-4003-8893
SN 2352-2208
EI 2352-2216
PD AUG
PY 2019
VL 106
BP 39
EP 54
DI 10.1016/j.jlamp.2019.04.003
UT WOS:000474505200003
ER

PT J
AU Islam, MM
   Hu, GQ
   Liu, QB
AF Islam, Md Mojahidul
   Hu, Guoqing
   Liu, Qianbo
TI Online Model Updating and Dynamic Learning Rate-Based Robust Object
   Tracking
SO SENSORS
AB Robust visual tracking is a significant and challenging issue in computer vision-related research fields and has attracted an immense amount of attention from researchers. Due to various practical applications, many studies have been done that have introduced numerous algorithms. It is considered to be a challenging problem due to the unpredictability of various real-time situations, such as illumination variations, occlusion, fast motion, deformation, and scale variation, even though we only know the initial target position. To address these matters, we used a kernelized-correlation-filter-based translation filter with the integration of multiple features such as histogram of oriented gradients (HOG) and color attributes. These powerful features are useful to differentiate the target from the surrounding background and are effective for motion blur and illumination variations. To minimize the scale variation problem, we designed a correlation-filter-based scale filter. The proposed adaptive model's updating and dynamic learning rate strategies based on a peak-to-sidelobe ratio effectively reduce model-drifting problems by avoiding noisy appearance changes. The experiment results show that our method provides the best performance compared to other methods, with a distance precision score of 79.9%, overlap success score of 59.0%, and an average running speed of 74 frames per second on the object tracking benchmark (OTB-2015).
RI ISLAM, MOJAHIDUL/AAG-1562-2019
OI Islam, Md Mojahidul/0000-0002-8408-4939
EI 1424-8220
PD JUL
PY 2018
VL 18
IS 7
AR 2046
DI 10.3390/s18072046
UT WOS:000441334300068
PM 29949950
ER

PT J
AU Farooqi, AA
   Mansoor, Q
   Alaaeddine, N
   Xu, BJ
AF Farooqi, Ammad Ahmad
   Mansoor, Qaisar
   Alaaeddine, Nada
   Xu, Baojun
TI MicroRNA Regulation of Telomerase Reverse Transcriptase (TERT): Micro
   Machines Pull Strings of Papier-Mache Puppets
SO INTERNATIONAL JOURNAL OF MOLECULAR SCIENCES
AB Substantial fraction of high-quality information is continuously being added into the existing pool of knowledge related to the biology of telomeres. Based on the insights gleaned from decades of research, it is clear that chromosomal stability needs a highly controlled and dynamic balance of DNA gain and loss in each terminal tract of telomeric repeats. Telomeres are formed by tandem repeats of TTAGGG sequences, which are gradually lost with each round of division of the cells. Targeted inhibition of telomerase to effectively induce apoptosis in cancer cells has attracted tremendous attention and overwhelmingly increasingly list of telomerase inhibitors truthfully advocates pharmacological significance of telomerase. Telomerase reverse transcriptase (TERT) is a multi-talented and catalytically active component of the telomerase-associated protein machinery. Different proteins of telomerase-associated machinery work in a synchronized and orchestrated manner to ensure proper maintenance of telomeric length of chromosomes. Rapidly emerging scientific findings about regulation of TERT by microRNAs has revolutionized our understanding related to the biology of telomeres and telomerase. In this review, we have comprehensively discussed how different miRNAs regulate TERT in different cancers. Use of miRNA-based therapeutics against TERT in different cancers needs detailed research in preclinical models for effective translation of laboratory findings to clinically effective therapeutics.
RI Farooqi, Ammad A/H-1610-2016; Farooqi, Ammad/O-9760-2018; Xu,
   Baojun/B-7971-2017; Farooqi, Ammad Ahmad/AAF-5325-2021
OI Xu, Baojun/0000-0003-0739-3735; Mansoor, Qaisar/0000-0003-1341-7174;
   Farooqi, Ammad/0000-0003-2899-5014
EI 1422-0067
PD APR
PY 2018
VL 19
IS 4
AR 1051
DI 10.3390/ijms19041051
UT WOS:000434978700130
PM 29614790
ER

PT J
AU Chang, TH
   Tung, L
   Yeh, FL
   Chen, JH
   Chang, SL
AF Chang, Tien-Hsien
   Tung, Luh
   Yeh, Fu-Lung
   Chen, Jui-Hui
   Chang, Shang-Lin
TI Functions of the DExD/H-box proteins in nuclear pre-mRNA splicing
SO BIOCHIMICA ET BIOPHYSICA ACTA-GENE REGULATORY MECHANISMS
AB In eukaryotes, many genes are transcribed as precursor messenger RNAs (pre-mRNAs) that contain exons and introns, the latter of which must be removed and exons ligated to form the mature mRNAs. This process is called pre-mRNA splicing, which occurs in the nucleus. Although the chemistry of pre-mRNA splicing is identical to that of the self-splicing Group II introns, hundreds of proteins and five small nuclear RNAs (snRNAs), U1, U2, U4, U5, and U6, are essential for executing pre-mRNA splicing. Spliceosome, arguably the most complex cellular machine made up of all those proteins and snRNAs, is responsible for carrying out pre-mRNA splicing. In contrast to the transcription and the translation machineries, spliceosome is formed anew onto each pre-mRNA and undergoes a series of highly coordinated reconfigurations to form the catalytic center. This amazing process is orchestrated by a number of DExD/H-proteins that are the focus of this article, which aims to review the field in general and to project the exciting challenges and opportunities ahead. This article is part of a Special Issue entitled: The Biology of RNA helicases - Modulation for life. (C) 2013 Elsevier B.V. All rights reserved.
SN 1874-9399
PD AUG
PY 2013
VL 1829
IS 8
SI SI
BP 764
EP 774
DI 10.1016/j.bbagrm.2013.02.006
UT WOS:000320212300004
PM 23454554
ER

PT J
AU Mamitsuka, H
AF Mamitsuka, H
TI Essential latent knowledge for protein-protein interactions: Analysis by
   an unsupervised learning approach
SO IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS
AB Protein-protein interactions play a number of central roles in many cellular functions, including DNA replication, transcription and translation, signal transduction, and metabolic pathways. A recent increase in the number of protein-protein interactions has made predicting unknown protein-protein interactions important for the understanding of living cells. However, the protein-protein interactions experimentally obtained so far are often incomplete and contradictory and, consequently, existing computational prediction methods have integrated evidence (latent knowledge of proteins) from different and more reliable sources. Analyzing the relationships between proteins and the latent knowledge is important to understanding the cellular processes. For this analysis, we propose a new probabilistic model for protein-protein interactions by considering the latent knowledge of proteins. We further present an efficient learning algorithm for this model, based on an EM algorithm. Experimental results have shown that in a supervised test setting, the proposed method outperformed five other competing methods by a statistically significant factor in all cases. Using the probability parameters of a trained model, we have further shown the latent knowledge that is essential to predicting protein-protein interactions. Overall, our experimental results confirm that our proposed model is especially effective for analyzing protein-protein interactions from a viewpoint of the latent knowledge of proteins.
RI Mamitsuka, Hiroshi/R-1110-2016
OI Mamitsuka, Hiroshi/0000-0002-6607-5617
SN 1545-5963
EI 1557-9964
PD APR-JUN
PY 2005
VL 2
IS 2
BP 119
EP 130
DI 10.1109/TCBB.2005.23
UT WOS:000235704100005
PM 17044177
ER

PT J
AU Porto-Alvarez, J
   Barnes, GT
   Villanueva, A
   Garcia-Figueiras, R
   Baleato-Gonzalez, S
   Zapico, EH
   Souto-Bayarri, M
AF Porto-Alvarez, Jacobo
   Barnes, Gary T.
   Villanueva, Alex
   Garcia-Figueiras, Roberto
   Baleato-Gonzalez, Sandra
   Huelga Zapico, Emilio
   Souto-Bayarri, Miguel
TI Digital Medical X-ray Imaging, CAD in Lung Cancer and Radiomics in
   Colorectal Cancer: Past, Present and Future
SO APPLIED SCIENCES-BASEL
AB Computed tomography (CT) introduced medicine to digital imaging. This occurred in the early 1970s and it was the start of the digital medical imaging revolution. The resulting changes and improvements in health care associated with digital imaging have been marked, are occurring now, and are likely to continue into the future. Before CT, medical images were acquired, stored, and displayed in analog form (i.e., on film). Now essentially all medical images are acquired and stored digitally. When they are not viewed by computer, they are converted to an analog image to be seen. The application of computer algorithms and the processing of digital medical images improves the visualization of diagnostically important details and aids diagnosis by extracting significant quantitative information. Examples of this can be seen with CAD and radiomics applications in the diagnosis of lung and colorectal cancer, respectively. The objectives of this article are to point out the key aspects of the digital medical imaging revolution, to review its current status, to discuss its clinical translation in two major areas: lung and colorectal cancer, and to provide future directions and challenges of these techniques.
EI 2076-3417
PD FEB
PY 2023
VL 13
IS 4
AR 2218
DI 10.3390/app13042218
UT WOS:000938236000001
ER

PT J
AU Wong, DYL
   Lam, MC
   Ran, A
   Cheung, CY
AF Wong, Dragon Y. L.
   Lam, Mary C.
   Ran, Anran
   Cheung, Carol Y.
TI Artificial intelligence in retinal imaging for cardiovascular disease
   prediction: current trends and future directions
SO CURRENT OPINION IN OPHTHALMOLOGY
AB Purpose of review
   Retinal microvasculature assessment has shown promise to enhance cardiovascular disease (CVD) risk stratification. Integrating artificial intelligence into retinal microvasculature analysis may increase the screening capacity of CVD risks compared with risk score calculation through blood-taking. This review summarizes recent advancements in artificial intelligence based retinal photograph analysis for CVD prediction, and suggests challenges and future prospects for translation into a clinical setting.
   Recent findings
   Artificial intelligence based retinal microvasculature analyses potentially predict CVD risk factors (e.g. blood pressure, diabetes), direct CVD events (e.g. CVD mortality), retinal features (e.g. retinal vessel calibre) and CVD biomarkers (e.g. coronary artery calcium score). However, challenges such as handling photographs with concurrent retinal diseases, limited diverse data from other populations or clinical settings, insufficient interpretability and generalizability, concerns on cost-effectiveness and social acceptance may impede the dissemination of these artificial intelligence algorithms into clinical practice.
   Summary
   Artificial intelligence based retinal microvasculature analysis may supplement existing CVD risk stratification approach. Although technical and socioeconomic challenges remain, we envision artificial intelligence based microvasculature analysis to have major clinical and research impacts in the future, through screening for high-risk individuals especially in less-developed areas and identifying new retinal biomarkers for CVD research.
SN 1040-8738
EI 1531-7021
PD SEP
PY 2022
VL 33
IS 5
BP 440
EP 446
DI 10.1097/ICU.0000000000000886
UT WOS:000834989600019
PM 35916571
ER

PT J
AU Plucker, JA
AF Plucker, Jonathan A.
TI The Patient is Thriving! Current Issues, Recent Advances, and Future
   Directions in Creativity Assessment
SO CREATIVITY RESEARCH JOURNAL
AB In 1998, Plucker and Runco provided an overview of creativity assessment, noting current issues (fluency confounds, generality vs. specificity), recent advances (predictive validity, implicit theories), and promising future directions (moving beyond divergent thinking measures, reliance on batteries of assessments, translation into practice). In the ensuing quarter century, the field experienced large growth in the quantity, breadth, and depth of assessment work, suggesting another analysis is timely. The purpose of this paper is to review the 1998 analysis and identify current issues, advances, and future directions for creativity measurement. Recent advances include growth in assessment quantity and quality and use of semantic distance as a scoring technique. Current issues include mismatches between current conceptions of creativity and those on which many measures are based, the need for psychometric quality standards, and a paucity of predictive validity evidence. The paper concludes with analysis of likely future directions, including use of machine learning to administer and score assessments and refinement of our conceptual frameworks for creativity assessment. Although the 1998 paper was written within an academic climate of harsh criticism of creativity measurement, the current climate is more positive, with reason for optimism about the continued growth of this important aspect of the field.
OI Plucker, Jonathan/0000-0002-5327-0851
SN 1040-0419
EI 1532-6934
DI 10.1080/10400419.2022.2110415
EA AUG 2022
UT WOS:000841842000001
ER

PT J
AU Cui, Y
   Wang, F
AF Cui, Yun
   Wang, Fu
TI Research on Audio Recognition Based on the Deep Neural Network in Music
   Teaching
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
AB Solfeggio is an important basic course for music majors, and audio recognition training is one of the important links. With the improvement of computer performance, audio recognition has been widely used in smart wearable devices. In recent years, the development of deep learning has accelerated the research process of audio recognition. However, there is a lot of sound interference in music teaching environment, which leads to the performance of the audio classifier that cannot meet the actual demand. In order to solve this problem, an improved audio recognition system based on YOLO-v4 is proposed, which mainly improves the network structure. First, Mel frequency cepstrum number is used to process the original audio and extract the corresponding features. Then, try to apply the YOLO-v4 model in the field of deep learning to the field of audio recognition and improve it by combining with the spatial pyramid pool module to strengthen the generalization ability of data in different audio formats. Second, the stacking method in ensemble learning is used to fuse the independent submodels of two different channels. Experimental results show that compared with other deep learning technologies, the improved YOLO-v4 model can improve the performance of audio recognition, and it has better performance in processing data of different audio formats, which shows better generalization ability.
SN 1687-5265
EI 1687-5273
PD MAY 27
PY 2022
VL 2022
AR 7055624
DI 10.1155/2022/7055624
UT WOS:000807810000028
PM 35669668
ER

PT C
AU De Lima, TB
   Miranda, P
   Mello, RF
   Wenceslau, M
   Bittencourt, II
   Cordeiro, TD
   Jose, J
AF De Lima, Tiago B.
   Miranda, Pericles
   Mello, Rafael Ferreira
   Wenceslau, Moesio
   Bittencourt, Ig Ibert
   Cordeiro, Thiago Damasceno
   Jose, Jario
BE Xavier-Junior, JC
   Rios, RA
TI Sequence Labeling Algorithms for Punctuation Restoration in Brazilian
   Portuguese Texts
SO INTELLIGENT SYSTEMS, PT II
SE Lecture Notes in Computer Science
CT 11th Brazilian Conference on Intelligent Systems (BRACIS)
CY NOV 28-DEC 01, 2022
CL Univ Campinas, Campinas, BRAZIL
SP Brazilian Inst Data Sci
HO Univ Campinas
AB Punctuation Restoration is an essential post-processing task of text generation methods, such as Speech-to-Text (STT) and Machine Translation (MT). Usually, the generation models employed in those tasks produce unpunctuated text, which is difficult for human readers and might degrade the performance of many downstream text processing tasks. Thus, many techniques exist to restore the text's punctuation. For instance, approaches based on Conditional Random Fields (CRF) and pre-trained models, such as the Bidirectional Encoder Representations from Transformers (BERT), have been widely applied. In the last few years, however, one approach has gained significant attention: casting the Punctuation Restoration problem into a sequence labeling task. In Sequence Labeling, each punctuation symbol becomes a label (e.g., COMMA, QUESTION, and PERIOD) that sequence tagging models can predict. This approach has achieved competitive results against stateof-the-art punctuation restoration algorithms. However, most research focuses on English, lacking discussion in other languages, such as Brazilian Portuguese. Therefore, this paper conducts an experimental analysis comparing the Bi-Long Short-Term Memory (BI-LSTM) + CRF model and BERT to predict punctuation in Brazilian Portuguese. We evaluate those approaches in the IWSLT2 2012-03 and OBRAS dataset in terms of precision, recall, and F1-score. The results showed that BERT achieved competitive results in terms of punctuation prediction, but it requires much more GPU resources for training than the BI-LSTM + CRF algorithm.
SN 0302-9743
EI 1611-3349
BN 978-3-031-21688-6; 978-3-031-21689-3
PY 2022
VL 13654
BP 616
EP 630
DI 10.1007/978-3-031-21689-3_43
UT WOS:000907772100043
ER

PT J
AU Cho, D
   Lee, H
   Kang, S
AF Cho, Danbi
   Lee, Hyunyoung
   Kang, Seungshik
TI An Empirical Study of Korean Sentence Representation with Various
   Tokenizations
SO ELECTRONICS
AB It is important how the token unit is defined in a sentence in natural language process tasks, such as text classification, machine translation, and generation. Many studies recently utilized the subword tokenization in language models such as BERT, KoBERT, and ALBERT. Although these language models achieved state-of-the-art results in various NLP tasks, it is not clear whether the subword tokenization is the best token unit for Korean sentence embedding. Thus, we carried out sentence embedding based on word, morpheme, subword, and submorpheme, respectively, on Korean sentiment analysis. We explored the two-sentence representation methods for sentence embedding: considering the order of tokens in a sentence and not considering the order. While inputting a sentence, which is decomposed by token unit, to the two-sentence representation methods, we construct the sentence embedding with various tokenizations to find the most effective token unit for Korean sentence embedding. In our work, we confirmed: the robustness of the subword unit for out-of-vocabulary (OOV) problems compared to other token units, the disadvantage of replacing whitespace with a particular symbol in the sentiment analysis task, and that the optimal vocabulary size is 16K in subword and submorpheme tokenization. We empirically noticed that the subword, which was tokenized by a vocabulary size of 16K without replacement of whitespace, was the most effective for sentence embedding on the Korean sentiment analysis task.
OI Kang, Seungshik/0000-0003-3318-6326; Cho, Danbi/0000-0003-1611-3192
EI 2079-9292
PD APR
PY 2021
VL 10
IS 7
AR 845
DI 10.3390/electronics10070845
UT WOS:000638342200001
ER

PT J
AU Zhang, PY
   Huang, XZ
   Li, MZ
   Xue, Y
AF Zhang, Peiying
   Huang, Xingzhe
   Li, Maozhen
   Xue, Yu
TI Hybridization between Neural Computing and Nature-Inspired Algorithms
   for a Sentence Similarity Model Based on the Attention Mechanism
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB Sentence similarity analysis has been applied in many fields, such as machine translation, the question answering system, and voice customer service. As a basic task of natural language processing, sentence similarity analysis plays an important role in many fields. The task of sentence similarity analysis is to establish a sentence similarity scoring model through multi-features. In previous work, researchers proposed a variety of models to deal with the calculation of sentence similarity. But these models do not consider the association information of sentence pairs, but only input sentence pairs into the model. In this article, we propose a sentence feature extraction model based on multi-feature attention. In addition, with the development of deep learning and the application of nature-inspired algorithms, researchers have proposed various hybrid algorithms that combine nature-inspired algorithms with neural networks. The hybrid algorithms not only solve the problem of decision-making based on multiple features but also improve the performance of the model. In the model, we use the attention mechanism to extract sentence features and assign weight. Then, the convolutional neural network is used to reduce the dimension of the matrix. In the training process, we integrate the firefly algorithm in the neural networks. The experimental results show that the accuracy of our model is 74.21%.
SN 2375-4699
EI 2375-4702
PD APR
PY 2021
VL 20
IS 1
AR 11
DI 10.1145/3447756
UT WOS:000640893600011
ER

PT C
AU Belay, BH
   Habtegebrial, T
   Liwicki, M
   Belay, G
   Stricker, D
AF Belay, Birhanu Hailu
   Habtegebrial, Tewodros
   Liwicki, Marcus
   Belay, Gebeyehu
   Stricker, Didier
BE DeMarsico, M
   DiBaja, GS
   Fred, A
TI A Blended Attention-CTC Network Architecture for Amharic Text-image
   Recognition
SO PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION
   APPLICATIONS AND METHODS (ICPRAM)
CT 10th International Conference on Pattern Recognition Applications and
   Methods (ICPRAM)
CY FEB 04-06, 2021
CL ELECTR NETWORK
AB In this paper, we propose a blended Attention-Connectionist Temporal Classification (CTC) network architecture for a unique script, Amharic, text-image recognition. Amharic is an indigenous Ethiopic script that uses 34 consonant characters with their 7 vowel variants of each and 50 labialized characters which are derived, with a small change, from the 34 consonant characters. The change involves modifying the structure of these characters by adding a straight line, or shortening and/or elongating one of its main legs including the addition of small diacritics to the right, left, top or bottom of the character. Such a small change affects orthographic identities of character and results in shape similarly among characters which are interesting, but challenging task, for OCR research. Motivated with the recent success of attention mechanism on neural machine translation tasks, we propose an attention-based CTC approach which is designed by blending attention mechanism directly within the CTC network. The proposed model consists of an encoder module, attention module and transcription module in a unified framework. The efficacy of the proposed model on the Amharic language shows that attention mechanism allows learning powerful representations by integrating information from different time steps. Our method outperforms state-of-the-art methods and achieves 1.04% and 0.93% of the character error rate on ADOCR test datasets.
BN 978-989-758-486-2
PY 2021
BP 435
EP 441
DI 10.5220/0010284204350441
UT WOS:000662835900050
ER

PT C
AU Banik, N
   Rahman, MHH
AF Banik, Nayan
   Rahman, Md. Hasan Hafizur
GP IEEE
TI GRU based Named Entity Recognition System for Bangla Online Newspapers
SO 2018 INTERNATIONAL CONFERENCE ON INNOVATION IN ENGINEERING AND
   TECHNOLOGY (ICIET)
CT International Conference on Innovation in Engineering and Technology
   (ICIET)
CY DEC 27-28, 2018
CL Dhaka, BANGLADESH
AB Information Extraction (IE) from textual documents locates important entities and their underlying connections using automated systems which are crucial to different applications including Data Mining (DM), Question Answering (QA), Machine Translation (MT) and so on. Named Entity Recognition (NER) being a sub-component of Natural Language Processing (NLP) is an IE task which aims at locating the textual presence of entities belonging to a prescribed set of classes. Due to its political and geographical influence, Bangla language is widely spoken around the globe and it is important to enrich its linguistic knowledge through NLP tools where NER is a common preprocessing step. The expeditiously growing World Wide Web (WWW) containing Bangla textual documents is in a formative stage with the proliferation of Bangla online newspapers and researchers have applied traditional classic learning algorithms for Bangla NER task while few researchers have used hand-crafted rules. Technological improvements show that with the capability of Deep Learning technique, NER performance can be boosted and hence this work is an effort to apply a variation of Recurrent Neural Network (RNN); especially a Gated Recurrent Unit (GRU) model for developing a Bangla NER task with a manually annotated dataset. The evaluation of our experimental results discovers how our approach can perform better when applied on a large scale dataset.
BN 978-1-5386-5229-9
PY 2018
UT WOS:000462911200016
ER

PT J
AU Dehkhoda, S
   Detournay, E
AF Dehkhoda, Sevda
   Detournay, Emmanuel
TI Mechanics of Actuated Disc Cutting
SO ROCK MECHANICS AND ROCK ENGINEERING
AB This paper investigates the mechanics of an actuated disc cutter with the objective of determining the average forces acting on the disc as a function of the parameters characterizing its motion. The specific problem considered is that of a disc cutter revolving off-centrically at constant angular velocity around a secondary axis rigidly attached to a cartridge, which is moving at constant velocity and undercutting rock at a constant depth. This model represents an idealization of a technology that has been implemented in a number of hard rock mechanical excavators with the goal of reducing the average thrust force to be provided by the excavation equipment. By assuming perfect conformance of the rock with the actuated disc as well as a prescribed motion of the disc (perfectly rigid machine), the evolution of the contact surface between the disc and the rock during one actuation of the disc can be computed. Coupled with simple cutter/rock interaction models that embody either a ductile or a brittle mode of fragmentation, these kinematical considerations lead to an estimate of the average force on the cartridge and of the partitioning of the energy imparted by the disc to the rock between the actuation mechanism of the disc and the translation of the cartridge on which the actuated disc is attached.
RI Detournay, Emmanuel/K-3793-2019; Dehkhoda, Sevda/A-1248-2018
OI Detournay, Emmanuel/0000-0003-3698-7575; Dehkhoda,
   Sevda/0000-0002-8540-0147
SN 0723-2632
EI 1434-453X
PD FEB
PY 2017
VL 50
IS 2
BP 465
EP 483
DI 10.1007/s00603-016-1121-y
UT WOS:000394172600014
ER

PT J
AU Migeon, C
   Texier, A
   Pineau, G
AF Migeon, C
   Texier, A
   Pineau, G
TI Effects of lid-driven cavity shape on the flow establishment phase
SO JOURNAL OF FLUIDS AND STRUCTURES
AB Experiments are carried out to study the flow establishment phase inside closed cavities submitted to the impulsive translation, from rest, of one of their walls at a Reynolds number of 1000. Three standard industrially machined or molded cylindrical cavity shapes are studied and are compared with respect to the efficiency of mixing process: square, rectangular and semicircular of length-to-width ratio of 2:1. The flow structures in the mid-cross-section are analysed by means of fine topological and kinematic visualization series using two complementary techniques: continuous dye filament and discrete solid tracers both coupled with a laser sheet illumination. Particular attention is given to vorticity propagation and primary/secondary eddy formations. Although a roughly similar vortex generation is observed in all examined cavities, important differences appear with time. The semi-circular cavity flow results in a much more homogeneous and uniform recirculation with no secondary flow recirculation zone. On the contrary, the square and rectangular cavity flows develop a better flow mass dispersion and, respectively, one and two secondary eddies. At the final time of observation (t* = 12), both semi-circular and rectangular cavity flows seem to reach their steady state whereas the square one continues to evolve. Comparisons with 2-D computational results of other authors illustrate the three-dimensional flow aspect present in experiments. (C) 2000 Academic Press.
SN 0889-9746
PD MAY
PY 2000
VL 14
IS 4
BP 469
EP 488
DI 10.1006/jfls.1999.0282
UT WOS:000087240300002
ER

PT J
AU Daniels, K
   Milenkovic, VJ
AF Daniels, K
   Milenkovic, VJ
TI Multiple translational containment .1. An approximate algorithm
SO ALGORITHMICA
AB We present an algorithm for finding a solution to the two-dimensional translational approximate multiple containment problem: find translations for k polygons which place them Inside a polygonal container so that no point of any polygon is more than 2 epsilon inside of the boundary of any other polygon. The polygons and container may be nonconvex. The value of epsilon is an input to the algorithm. In industrial applications the containment solution acts as a guide to a machine cutting out polygonal shapes from a sheet of material. If epsilon is chosen to be a fraction of the cutter's accuracy, then the solution to the approximate containment problem is sufficient for industrial purposes.
   Given a containment problem, we characterize its solution and create a collection of containment sub-problems from this characterization. We solve each subproblem by first restricting certain two-dimensional configuration spaces until a steady state is reached, and then testing for a solution inside the configuration spaces. If necessary, ive subdivide the configuration spaces to generate new subproblems. The running time of our algorithm is O((1/epsilon)(k) log(1/epsilon)k(6)s log s), where s is the largest number of vertices of any polygon generated by a restriction operation, In the worst case s can be exponential in the size of the input, but, in practice, it is usually not more than quadratic.
SN 0178-4617
PD SEP-OCT
PY 1997
VL 19
IS 1-2
BP 148
EP 182
DI 10.1007/PL00014415
UT WOS:A1997XF99800008
ER

PT J
AU Agresti, G
   Schafer, H
   Sartor, P
   Incesu, Y
   Zanuttigh, P
AF Agresti, Gianluca
   Schaefer, Henrik
   Sartor, Piergiorgio
   Incesu, Yalcin
   Zanuttigh, Pietro
TI Unsupervised Domain Adaptation of Deep Networks for ToF Depth Refinement
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB Depth maps acquired with ToF cameras have a limited accuracy due to the high noise level and to the multi-path interference. Deep networks can be used for refining ToF depth, but their training requires real world acquisitions with ground truth, which is complex and expensive to collect. A possible workaround is to train networks on synthetic data, but the domain shift between the real and synthetic data reduces the performances. In this paper, we propose three approaches to perform unsupervised domain adaptation of a depth denoising network from synthetic to real data. These approaches are respectively acting at the input, at the feature and at the output level of the network. The first approach uses domain translation networks to transform labeled synthetic ToF data into a representation closer to real data, that is then used to train the denoiser. The second approach tries to align the network internal features related to synthetic and real data. The third approach uses an adversarial loss, implemented with a discriminator trained to recognize the ground truth statistic, to train the denoiser on unlabeled real data. Experimental results show that the considered approaches are able to outperform other state-of-the-art techniques and achieve superior denoising performances.
RI Zanuttigh, Pietro/AAB-9555-2019
OI Zanuttigh, Pietro/0000-0002-9502-2389
SN 0162-8828
EI 1939-3539
PD DEC 1
PY 2022
VL 44
IS 12
BP 9195
EP 9208
DI 10.1109/TPAMI.2021.3123843
UT WOS:000880661400046
PM 34714740
ER

PT J
AU Bae, J
   Cheon, BD
   Kim, HY
AF Bae, Jongseong
   Cheon, Byung Do
   Kim, Ha Young
TI Pro-Attention: Efficient Probability Distribution Matching-Based
   Attention Through Feature Space Conversion
SO IEEE ACCESS
AB The self-attention mechanism requires a huge amount of computational cost despite its successful use in the transformer. The computational cost linearly increases in proportion to the embedding dimension size, owing to the dot product operation that calculates token similarities in vector spaces. To tackle this problem, we propose a novel efficient self-attention mechanism (Pro-attention) that computes the attention scores through distribution matching in probability space. To this end, we assume that each token has its unique probability distribution and regard each component of a token vector as a sample from the probability distribution. Then, we estimate the statistics of each token-specific probability distribution from the samples, and the token similarities are obtained by using the Kullback-Leibler Divergence. According to the time complexity analysis, the computational cost is markedly saved because the time complexity is independent of the feature dimension size. Our method produces competitive performances in machine translation and language modeling benchmarks such as IWSLT'14 De-En, WMT'14 En-De, WMT'14 En-Fr, and WikiText-103 datasets. Moreover, our model maintains the performances with considerably reduced FLOPs of the self-attention mechanism, which is up to 87% less compared to the baseline transformer. Especially, our model improves the efficiency in a large volume of the training dataset.
OI Kim, Ha Young/0000-0001-5115-9984; Bae, Jongseong/0000-0002-7322-9573
SN 2169-3536
PY 2022
VL 10
BP 131192
EP 131201
DI 10.1109/ACCESS.2022.3229055
UT WOS:000902064400001
ER

PT J
AU Mitchell, SM
   Cero, I
   Littlefield, AK
   Brown, SL
AF Mitchell, Sean M.
   Cero, Ian
   Littlefield, Andrew K.
   Brown, Sarah L.
TI Using categorical data analyses in suicide research: Considering
   clinical utility and practicality
SO SUICIDE AND LIFE-THREATENING BEHAVIOR
AB Objective Categorical data analysis is relevant to suicide risk and prevention research that focuses on discrete outcomes (e.g., suicide attempt status). Unfortunately, results from these analyses are often misinterpreted and not presented in a clinically tangible manner. We aimed to address these issues and highlight the relevance and utility of categorical methods in suicide research and clinical assessment. Additionally, we introduce relevant basic machine learning methods concepts and address the distinct utility of the current methods.
   Method We review relevant background concepts and pertinent issues with references to helpful resources. We also provide non-technical descriptions and tutorials of how to convey categorical statistical results (logistic regression, receiver operating characteristic [ROC] curves, area under the curve [AUC] statistics, clinical cutoff scores) for clinical context and more intuitive use.
   Results We provide comprehensive examples, using simulated data, and interpret results. We also note important considerations for conducting and interpreting these analyses. We provide a walk-through demonstrating how to convert logistic regression estimates into predicted probability values, which is accompanied by Appendices demonstrating how to produce publication-ready figures in R and Microsoft Excel.
   Conclusion Improving the translation of statistical estimates to practical, clinically tangible information may narrow the divide between research and clinical practice.
RI Mitchell, Sean/C-7033-2019
OI Mitchell, Sean/0000-0002-3729-7368; Cero, Ian/0000-0002-2862-0450
SN 0363-0234
EI 1943-278X
PD FEB
PY 2021
VL 51
IS 1
BP 76
EP 87
DI 10.1111/sltb.12670
UT WOS:000621079800009
PM 33624878
ER

PT J
AU Witzany, G
AF Witzany, Guenther
TI PRELIMINARY REMARKS TO AN INTEGRATIVE THEORY OF EVOLUTION
SO THEORETICAL BIOLOGY FORUM
AB For nearly a century the main focus in biological disciplines such as molecular biology, biochemistry, genetics and evolutionary theory was cellular life as a machine like process in which mechanistic pathways regulate metabolism, genetic reading and translation into proteins and evolution by variations (random error replications) and selection. Modern biochemistry started with the cellular theory of life. Also the modern synthesis focused on cells at the starting event of life. The dominance of this paradigm lasted until ten years ago. Then the comeback of virology offered new empirical data and explanatory models of how viruses determine cellular life through an abundance of parasite host interactions that overrule cellular processes. The RNA world hypothesis demonstrated that prior to cellular life RNA group interactions were at the beginning of biological selection before cellular life emerged. Last but not least the central dogma of molecular biology collapsed when epigenetics demonstrated that history and developmental experiences of the past can be epigenetically imprinted and serve as identity markings that in every replication process of any cell in any organism on this planet the timely and locally coordinated replication is regulated and orchestrated by these programmings. In the light of this knowledge a better explanatory model than an extension of the modern synthesis will be more successful in the 21st century.
SN 2282-2593
EI 2283-7175
PY 2021
VL 114
IS 2
BP 41
EP 59
DI 10.19272/202111402004
UT WOS:000830158100004
PM 36382548
ER

PT C
AU Thuy, NTT
   Bach, NX
   Phuong, TM
AF Nguyen Thi Thanh Thuy
   Ngo Xuan Bach
   Tu Minh Phuong
GP IEEE
TI Leveraging Foreign Language Labeled Data for Aspect-Based Opinion Mining
SO 2020 RIVF INTERNATIONAL CONFERENCE ON COMPUTING & COMMUNICATION
   TECHNOLOGIES (RIVF 2020)
SE IEEE RIVF International Conference on Computing and Communication
   Technologies Research Innovation and Vision for the Future
CT RIVF International Conference on Computing and Communication
   Technologies (RIVF)
CY OCT 14-15, 2020
CL RMIT University, Ho Chi Minh City, VIETNAM
SP IEEE Vietnam Sect
HO RMIT University
AB Aspect-based opinion mining is the task of identifying sentiment at the aspect level in opinionated text, which consists of two subtasks: aspect category extraction and sentiment polarity classification. While aspect category extraction aims to detect and categorize opinion targets such as product features, sentiment polarity classification assigns a sentiment label, i.e. positive, negative, or neutral, to each identified aspect. Supervised learning methods have been shown to deliver better accuracy for this task but they require labeled data, which is costly to obtain, especially for resource-poor languages like Vietnamese. To address this problem, we present a supervised aspect-based opinion mining method that utilizes labeled data from a foreign language (English in this case), which is translated to Vietnamese by an automated translation tool (Google Translate). Because aspects and opinions in different languages may be expressed by different words, we propose using word embeddings, in addition to other features, to reduce the vocabulary difference between the original and translated texts, thus improving the effectiveness of aspect category extraction and sentiment polarity classification processes. We also introduce an annotated corpus of aspect categories and sentiment polarities extracted from restaurant reviews in Vietnamese, and conduct a series of experiments on the corpus. Experimental results demonstrate the effectiveness of the proposed approach.
SN 2162-786X
BN 978-1-7281-5377-3
PY 2020
BP 35
EP 40
UT WOS:000648838400007
ER

PT C
AU Ma, CF
   Sha, Y
   Tan, JL
   Guo, L
   Peng, HL
AF Ma, Chengfang
   Sha, Ying
   Tan, Jianlong
   Guo, Li
   Peng, Huailiang
BE Getov, V
   Gaudiot, JL
   Yamai, N
   Cimato, S
   Chang, M
   Teranishi, Y
   Yang, JJ
   Leong, HV
   Shahriar, H
   Takemoto, M
   Towey, D
   Takakura, H
   Elci, A
   Susumu
   Puri, S
TI Chinese Social Media Entity Linking Based on Effective Context with
   Topic Semantics
SO 2019 IEEE 43RD ANNUAL COMPUTER SOFTWARE AND APPLICATIONS CONFERENCE
   (COMPSAC), VOL 1
SE Proceedings International Computer Software and Applications Conference
CT 43rd IEEE-Computer-Society Annual International Computers, Software and
   Applications Conference (COMPSAC)
CY JUL 15-19, 2019
CL Marquette Univ, Milwaukee, WI
SP IEEE, IEEE Comp Soc, IEEE Future Direct
HO Marquette Univ
AB On social media, entity linking is very important for natural language processing tasks, such as Sentiment Analysis, Question Answering (QA) and Machine Translation. Compared to English-oriented entity linking, Chinese entity linking has its special difficulties. Just like the entity linking for short text, Chinese microblogs have lots of noise and the mention lacks effective context information. In order to solve these problems, we present a new model for Chinese microblogs entity linking. Entity linking usually includes two steps: candidate entities generation and candidate entities ranking. First, based on the characteristics of Chinese, we put forward multi-method fusion strategies for candidate generation to improve the recall rate of candidate entities. Second, we propose a new neural network model called TAS (Topic attention Siamese) for candidate entities ranking. In TAS model, we add effective topic semantics on Siamese network to learn representations of context, mention and entity, and rank the mention-entity similarity. The representation of mention incorporates information from multiple sentences on the same topic, which can effectively solve the problem of the lack of contextual information. We also use Character-enhanced Word Embedding model (CWE) to pre-train both word embedding and characters embedding to work out noise and word segmentation impact. Experimental results demonstrate that our method significantly outperforms the state-of-the-art results for entity linking on Chinese social media.
SN 0730-3157
BN 978-1-7281-2607-4
PY 2019
BP 386
EP 395
DI 10.1109/COMPSAC.2019.00063
UT WOS:000538791700052
ER

PT C
AU Alharbi, R
   Vafaie, N
   Liu, K
   Moran, K
   Ledford, G
   Pfammatter, A
   Spring, B
   Alshurafa, N
AF Alharbi, Rawan
   Vafaie, Nilofar
   Liu, Kitty
   Moran, Kevin
   Ledford, Gwendolyn
   Pfammatter, Angela
   Spring, Bonnie
   Alshurafa, Nabil
GP IEEE
TI Investigating Barriers and Facilitators to Wearable Adherence in
   Fine-Grained Eating Detection
SO 2017 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND
   COMMUNICATIONS WORKSHOPS (PERCOM WORKSHOPS)
SE International Conference on Pervasive Computing and Communications
CT IEEE International Conference on Pervasive Computing and Communications
   (PerCom)
CY MAR 13-17, 2017
CL HI
SP IEEE
AB Energy balance is one component of weight management, but passive objective measures of caloric intake are non-existent. Given the recent success of actigraphy as a passive objective measure of the physical activity construct that relieves participants of the burden of biased self-report, computer scientists and engineers are aiming to find a passive objective measure of caloric intake. Passive sensing food intake systems have failed to go beyond the lab and into behavioral research in part due to low adherence to wearing passive monitoring systems. While system accuracy and battery lifetime are sine qua non to a successfully deployed technology, they come second to adherence, since a system does nothing if it remains unused. This paper focuses on adherence as affected by: 1) perceived data privacy; 2) stigma of wearing devices; 3) comfort. These factors highlight new challenges surrounding participant informed consent and Institutional Review Board (IRB) risk assessment. The wearables examined include neck-and wrist-worn sensors, and video camera-based systems. Findings support the potential for adherence using wrist-and shoulder-based video cameras, and personalized style-conscious neck-worn sensors. The feasibility of detecting fine-grained eating gestures to validate the machine learning models is shown, improving the potential of translation of this technology.
RI Pfammatter, Angela/AAZ-6036-2021; Alharbi, Rawan/AAH-3393-2019; AlHarbi,
   Rawan/ABE-4530-2020
OI Pfammatter, Angela/0000-0003-0081-4090; 
SN 2474-2503
BN 978-1-5090-4338-5
PY 2017
UT WOS:000411208400086
ER

PT C
AU Kumkar, M
   Kaiser, M
   Kleiner, J
   Grossmann, D
   Flamm, D
   Bergner, K
   Nolte, S
AF Kumkar, M.
   Kaiser, M.
   Kleiner, J.
   Grossmann, D.
   Flamm, D.
   Bergner, K.
   Nolte, S.
BE Neuenschwander, B
   Roth, S
   Grigoropoulos, CP
   Makimura, T
TI Ultrafast laser processing of transparent materials supported by in-situ
   diagnostics
SO LASER APPLICATIONS IN MICROELECTRONIC AND OPTOELECTRONIC MANUFACTURING
   (LAMOM) XXI
SE Proceedings of SPIE
CT 8th International Conference on Modern Research in Psychology
CY JUN, 2015
CL Sibiu, ROMANIA
AB For the development of industrial NIR ultrafast laser processing of transparent materials, the absorption inside the bulk material has to be controlled. Applications we aim for are front and rear side ablation, drilling and inscription of modifications for cleaving and selective laser etching of glass and sapphire in sheet geometry.
   We applied pump probe technology and in situ stress birefringence microscopy for fundamental studies on the influence of energy and duration (100 fs - 20 ps), temporal and spatial spacing, focusing and beam shaping of the laser pulses. Applying pump probe technique we are able to visualize differences of spatio-temporal build up of absorption, self focusing, shock wave generation for standard, multispot and beam shaped focusing. Incubation effects and disturbance of beam propagation due to modifications or ablation can be observed.
   In-situ imaging of stress birefringence gained insight in transient build up of stress with and without translation. The results achieved so far, demonstrate that transient stress has to be taken into account in scaling the laser machining throughput of brittle materials. Furthermore it points out that transient stress birefringence is a good indicator for accumulation effects, supporting tailored processing strategies.
   Cutting results achieved for selective laser etching by single pass laser modification exemplifies the benefits of process development supported by in situ diagnostics.
SN 0277-786X
EI 1996-756X
BN 978-1-62841-970-2
PY 2016
VL 9735
AR 97350P
DI 10.1117/12.2209507
UT WOS:000379995000016
ER

PT J
AU Bemporad, A
   Giorgetti, N
AF Bemporad, Alberto
   Giorgetti, Nicolo
TI Logic-based solution methods for optimal control of hybrid systems
SO IEEE TRANSACTIONS ON AUTOMATIC CONTROL
AB Combinatorial optimization over continuous and integer variables is a useful tool for solving complex optimal control problems of hybrid dynamical systems formulated in discrete-time. Current approaches are based on mixed-integer linear (or quadratic) programming (MIP), which provides the solution after solving a sequence of relaxed linear (or quadratic) programs. KIP formulations require the translation of the discrete/logic part of the hybrid problem into mixed-integer inequalities. Although this operation can be done automatically, most of the original symbolic structure of the problem (e.g., transition functions of finite state machines, logic constraints, symbolic variables, etc.) is lost during the conversion, with a consequent loss of computational performance. In this paper, we attempt to overcome such a difficulty by combining numerical techniques for solving convex programming problems with symbolic techniques for solving constraint satisfaction problems (CSP). The resulting "hybrid" solver proposed here takes advantage of CSP solvers for dealing with satisfiability of logic constraints very efficiently. We propose a suitable model of the hybrid dynamics and a class of optimal control problems that embrace both symbolic and continuous variables/functions, and that are tailored to the use of the new hybrid solver. The superiority in terms of computational performance with respect to commercial MIP solvers is shown on a centralized supply chain management problem with uncertain forecast demand.
SN 0018-9286
EI 1558-2523
PD JUN
PY 2006
VL 51
IS 6
BP 963
EP 976
DI 10.1109/TAC.2006.876949
UT WOS:000238660600005
ER

PT J
AU Yeasin, M
AF Yeasin, M
TI Optical flow in log-mapped image plane - A new approach
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB Foveating vision sensors are important in both machine and biological vision. The term space-variant or foveating vision refers to sensor architectures based on smooth variation of resolution across the visual field, like that of the human visual system. Traditional image processing techniques do not hold when applied directly to such a image representation since the translation symmetry and the neighborhood structure in the spatial domain is broken by the space-variant properties of the sensor. Unfortunately, there has been little systematic development of image processing tools that are explicitly designed for foveated vision. In this article, we propose a novel approach to compute the optical flow directly on log-mapped images. We propose the use of a generalized dynamic image model (GDIM) based method for computing the optical flow as opposed to the brightness constancy model (BCM) based method. We introduce a new notion of "variable window" and use the space-variant form of gradient operator while computing the spatio-temporal gradient in log-mapped images for a better accuracy and to ensure that the local neighborhood is preserved. We emphasize that the proposed method must be numerically accurate, provide a consistent interpretation, and be capable of computing the peripheral motion. Experimental results on both the synthetic and real images have been presented to show the efficacy of the proposed method.
SN 0162-8828
PD JAN
PY 2002
VL 24
IS 1
BP 125
EP 131
DI 10.1109/34.982889
UT WOS:000172960300009
ER

PT J
AU Yamada, R
   Okada, D
   Wang, J
   Basak, T
   Koyama, S
AF Yamada, Ryo
   Okada, Daigo
   Wang, Juan
   Basak, Tapati
   Koyama, Satoshi
TI Interpretation of omics data analyses
SO JOURNAL OF HUMAN GENETICS
AB Omics studies attempt to extract meaningful messages from large-scale and high-dimensional data sets by treating the data sets as a whole. The concept of treating data sets as a whole is important in every step of the data-handling procedures: the pre-processing step of data records, the step of statistical analyses and machine learning, translation of the outputs into human natural perceptions, and acceptance of the messages with uncertainty. In the pre-processing, the method by which to control the data quality and batch effects are discussed. For the main analyses, the approaches are divided into two types and their basic concepts are discussed. The first type is the evaluation of many items individually, followed by interpretation of individual items in the context of multiple testing and combination. The second type is the extraction of fewer important aspects from the whole data records. The outputs of the main analyses are translated into natural languages with techniques, such as annotation and ontology. The other technique for making the outputs perceptible is visualization. At the end of this review, one of the most important issues in the interpretation of omics data analyses is discussed. Omics studies have a large amount of information in their data sets, and every approach reveals only a very restricted aspect of the whole data sets. The understandable messages from these studies have unavoidable uncertainty.
OI Koyama, Satoshi/0000-0002-9286-0360; Yamada, Ryo/0000-0002-1587-630X
SN 1434-5161
EI 1435-232X
PD JAN
PY 2021
VL 66
IS 1
BP 93
EP 102
DI 10.1038/s10038-020-0763-5
EA MAY 2020
UT WOS:000531146400002
PM 32385339
ER

PT J
AU Syn, T
   Ramaprasad, A
AF Syn, Thant
   Ramaprasad, Arkalgud
TI Megaprojects - symbolic and sublime: an ontological review
SO INTERNATIONAL JOURNAL OF MANAGING PROJECTS IN BUSINESS
AB Purpose Megaprojects are symbolic milestones of human history. Most megaprojects are one-of-a-kind endeavors to which traditional project management principles are neither applicable nor suitable, rendering the holistic study of megaprojects especially difficult. There is no systemic framework that can help systematically assess and guide megaprojects and megaproject research. In the absence of such a framework there is a significant risk of bias in planning the projects and the topics researched. The purpose of this paper is to present an ontological framework of megaprojects and discuss how it can help analyze individual megaprojects and synthesize the corpus of megaproject research. Design/methodology/approach An ontology framework of megaproject is developed by deconstructing the symbolism and purpose of megaprojects into respective dimensions and their categories. The ontological framework is then used to map the extent literature on megaproject to identify the dominant themes and gaps in the state-of-the-research. Findings The megaproject research has predominantly focused on select stakeholders (builders, governments, and communities), translation stages (implementation and conceptualization), and sublime (mostly economic). Other aspects of megaprojects have received little or no attention. Originality/value The paper presents an ontological framework to holistically capture the symbolism and sublime of megaprojects. The framework is complete, expansive, and grounded, yet simple, parsimonious, and innovative. It is a tool for decision makers more than a formal ontology readable by machines.
RI Syn, Thant/D-3302-2015
OI Syn, Thant/0000-0001-5727-5927; Ramaprasad, Arkalgud/0000-0003-1551-6854
SN 1753-8378
EI 1753-8386
PD JUN 3
PY 2019
VL 12
IS 2
BP 377
EP 399
DI 10.1108/IJMPB-03-2018-0054
UT WOS:000479290200008
ER

PT J
AU Alarie, B
   Niblett, A
   Yoon, AH
AF Alarie, Benjamin
   Niblett, Anthony
   Yoon, Albert H.
TI HOW ARTIFICIAL INTELLIGENCE WILL AFFECT THE PRACTICE OF LAW
SO UNIVERSITY OF TORONTO LAW JOURNAL
AB Artificial intelligence is exerting an influence on all professions and industries. We have autonomous vehicles, instantaneous translation among the world's leading languages, and search engines that rapidly locate information anywhere on the web in a way that is tailored to a user's interests and past search history. Law is not immune from disruption by new technology. Software tools are beginning to affect various aspects of lawyers' work, including those tasks that historically relied upon expert human judgment, such as predicting court outcomes. These new software tools present new challenges and new opportunities. In the short run, we can expect greater legal transparency, more efficient dispute resolution, improved access to justice, and new challenges to the traditional organization of private law firms delivering legal services on a billable hour basis through a leveraged partner-associate model. With new technology, lawyers will be empowered to work more efficiently, deepen and broaden their areas of expertise, and provide more value to clients. These developments will predictably transform both how lawyers do legal work and resolve disputes on behalf of their clients. In the longer term, it is difficult to predict what the impact of artificially intelligent tools will be, as lawyers incorporate them into their practice and expand their range of services on behalf of clients.
OI Alarie, Benjamin/0000-0002-2705-0417
SN 0042-0220
EI 1710-1174
PY 2018
VL 68
SU 1
BP 106
EP 124
DI 10.3138/utlj.2017-0052
UT WOS:000427068000006
ER

PT C
AU Peng, YH
   Bao, YX
   Chen, YR
   Wu, C
   Guo, CX
AF Peng, Yanghua
   Bao, Yixin
   Chen, Yangrui
   Wu, Chuan
   Guo, Chuanxiong
GP Assoc Comp Machinery
TI Optimus: An Efficient Dynamic Resource Scheduler for Deep Learning
   Clusters
SO EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE
CT 13th EuroSys Conference (EuroSys)
CY APR 23-26, 2018
CL Porto, PORTUGAL
AB Deep learning workloads are common in today's production clusters due to the proliferation of deep learning driven AI services (e.g., speech recognition, machine translation). A deep learning training job is resource-intensive and time-consuming. Efficient resource scheduling is the key to the maximal performance of a deep learning cluster. Existing cluster schedulers are largely not tailored to deep learning jobs, and typically specifying a fixed amount of resources for each job, prohibiting high resource efficiency and job performance. This paper proposes Optimus, a customized job scheduler for deep learning clusters, which minimizes job training time based on online resource-performance models. Optimus uses online fitting to predict model convergence during training, and sets up performance models to accurately estimate training speed as a function of allocated resources in each job. Based on the models, a simple yet effective method is designed and used for dynamically allocating resources and placing deep learning tasks to minimize job completion time. We implement Optimus on top of Kubernetes, a cluster manager for container orchestration, and experiment on a deep learning cluster with 7 CPU servers and 6 GPU servers, running 9 training jobs using the MXNet framework. Results show that Optimus outperforms representative cluster schedulers by about 139% and 63% in terms of job completion time and makespan, respectively.
RI Peng, Yanghua/AAF-7611-2020; Bao, Yixin/AAF-2767-2020
OI Peng, Yanghua/0000-0003-3989-4358; Bao, Yixin/0000-0002-6921-2154; Guo,
   Chuanxiong/0000-0002-0730-8468
BN 978-1-4503-5584-1
PY 2018
DI 10.1145/3190508.3190517
UT WOS:000460467600003
ER

PT J
AU Combefis, S
   Giannakopoulou, D
   Pecheur, C
AF Combefis, Sebastien
   Giannakopoulou, Dimitra
   Pecheur, Charles
TI Automatic Detection of Potential Automation Surprises for ADEPT Models
SO IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS
AB This paper describes how to automatically detect potential automation surprises in interactive systems, within a rapid automation interface design tool named ADEPT. The proposed analysis method in this paper is based on a conformance relation, called full-control, between the model of the actual system and a mental model of it, that is, its behavior as perceived by the operator. The method can, among other things, automatically generate a so-called minimal full-control mental model for a given system. Systems are well designed if they can be described by relatively simple mental models for their operators, which can be assessed with the minimal full-control mental model generation algorithms. During the generation, potential automation surprises are detected and highlighted with execution examples that may lead to confusion. The analysis methods are based on an enriched version of labeled transition systems to describe the system and mental models. In order to be able to integrate the analysis method within ADEPT, a semantics for ADEPT models makes it possible to translate them into enriched LTSs. The proposed translation is automated for a specified class of ADEPT models that are characterized and defined in this paper. A case study demonstrates the proposed analysis framework and informs how the integration with ADEPT can be improved.
OI Combefis, Sebastien/0000-0002-8987-9589
SN 2168-2291
EI 2168-2305
PD APR
PY 2016
VL 46
IS 2
BP 267
EP 278
DI 10.1109/THMS.2015.2424851
UT WOS:000372841200010
ER

PT C
AU Ladeji-Osias, J
   Theobalds, A
   Nare, O
   Wandji, T
   Scott, C
   Nyarko, K
AF Ladeji-Osias, Jumoke
   Theobalds, Andre
   Nare, Otsebele
   Wandji, Thierry
   Scott, Craig
   Nyarko, Kofi
BE Verly, JG
   Guell, JJ
TI Implementing a shadow detection algorithm for synthetic vision systems
   in reconfigurable hardware
SO ENHANCED AND SYNTHETIC VISION 2006
SE Proceedings of SPIE
CT Conference on Enhanced and Synthetic Vision 2006
CY APR 17-18, 2006
CL Kissimmee, FL
SP SPIE
AB The integrity monitor for synthetic vision systems provides pilots with a consistency check between stored Digital Elevation Models (DEM) and real-time sensor data. This paper discusses the implementation of the Shadow Detection and Extraction (SHADE) algorithm in reconfigurable hardware to increase the efficiency of the design. The SHADE algorithm correlates data from a weather radar and DEM to determine occluded regions of the flight path terrain. This process of correlating the weather radar and DEM data occurs in two parallel threads which are then fed into a disparity checker. The DEM thread is broken up into four main sub-functions: 1) synchronization and translation of GPS coordinates of aircraft to the weather radar, 2) mapping range bins to coordinates and computing depression angles, 3) mapping state assignments to range bins, and 4) shadow region edge detection. This correlation must be done in real-time; therefore, a hardware implementation is ideal due to the amount of data that is to be processed. The hardware of choice is the field programmable gate array because of programmability, reusability, and computational ability. Assigning states to each range bin is the most computationally intensive process and it is implemented as a finite state machine (FSM). Results of this work are focused on the implementation of the FSM.
OI Ladeji-Osias, Jumoke/0000-0002-8645-696X; Nare,
   Otsebele/0000-0002-3741-9230
SN 0277-786X
EI 1996-756X
BN 0-8194-6282-9
PY 2006
VL 6226
AR 622603
DI 10.1117/12.665895
UT WOS:000239569900003
ER

PT C
AU Wang, C
   Chen, YH
   Liu, YY
   Tian, Y
   Liu, FB
   McCarthy, DJ
   Elliott, M
   Frazer, H
   Carneiro, G
AF Wang, Chong
   Chen, Yuanhong
   Liu, Yuyuan
   Tian, Yu
   Liu, Fengbei
   McCarthy, Davis J.
   Elliott, Michael
   Frazer, Helen
   Carneiro, Gustavo
BE Wang, L
   Dou, Q
   Fletcher, PT
   Speidel, S
   Li, S
TI Knowledge Distillation to Ensemble Global and Interpretable
   Prototype-Based Mammogram Classification Models
SO MEDICAL IMAGE COMPUTING AND COMPUTER ASSISTED INTERVENTION, MICCAI 2022,
   PT III
SE Lecture Notes in Computer Science
CT 25th International Conference on Medical Image Computing and Computer
   Assisted Intervention (MICCAI)
CY SEP 18-22, 2022
CL Singapore, SINGAPORE
SP MICCAI Soc
AB State-of-the-art (SOTA) deep learning mammogram classifiers, trained with weakly-labelled images, often rely on global models that produce predictions with limited interpretability, which is a key barrier to their successful translation into clinical practice. On the other hand, prototype-based models improve interpretability by associating predictions with training image prototypes, but they are less accurate than global models and their prototypes tend to have poor diversity. We address these two issues with the proposal of BRAIxPro-toPNet++, which adds interpretability to a global model by ensembling it with a prototype-based model. BRAIxProtoPNet++ distills the knowledge of the global model when training the prototype-based model with the goal of increasing the classification accuracy of the ensemble. Moreover, we propose an approach to increase prototype diversity by guaranteeing that all prototypes are associated with different training images. Experiments on weakly-labelled private and public datasets show that BRAIxProtoPNet++ has higher classification accuracy than SOTA global and prototype-based models. Using lesion localisation to assess model interpretability, we show BRAIxProtoPNet++ is more effective than other prototype-based models and post-hoc explanation of global models. Finally, we show that the diversity of the prototypes learned by BRAIxProtoPNet++ is superior to SOTA prototype-based approaches.
RI Wang, Chong/AHE-1967-2022
OI Wang, Chong/0000-0003-0022-0217; Carneiro, Gustavo/0000-0002-5571-6220
SN 0302-9743
EI 1611-3349
BN 978-3-031-16437-8; 978-3-031-16436-1
PY 2022
VL 13433
BP 14
EP 24
DI 10.1007/978-3-031-16437-8_2
UT WOS:000867397400002
ER

PT J
AU Cruz, BGS
   Bossa, MN
   Solter, J
   Husch, AD
AF Cruz, Beatriz Garcia Santa
   Bossa, Matias Nicolas
   Solter, Jan
   Husch, Andreas Dominik
TI Public Covid-19 X-ray datasets and their impact on model bias-A
   systematic review of a significant problem
SO MEDICAL IMAGE ANALYSIS
AB Computer-aided-diagnosis and stratification of COVID-19 based on chest X-ray suffers from weak bias assessment and limited quality-control. Undetected bias induced by inappropriate use of datasets, and improper consideration of confounders prevents the translation of prediction models into clinical practice. By adopting established tools for model evaluation to the task of evaluating datasets, this study provides a systematic appraisal of publicly available COVID-19 chest X-ray datasets, determining their potential use and evaluating potential sources of bias. Only 9 out of more than a hundred identified datasets met at least the criteria for proper assessment of risk of bias and could be analysed in detail. Remarkably most of the datasets utilised in 201 papers published in peer-reviewed journals, are not among these 9 datasets, thus leading to models with high risk of bias. This raises concerns about the suitability of such models for clinical use. This systematic review highlights the limited description of datasets employed for modelling and aids researchers to select the most suitable datasets for their task. (c) 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ )
RI Husch, Andreas Dominik/ABA-3174-2020; Bossa Bossa, Matias
   Nicolas/B-6865-2012
OI Husch, Andreas Dominik/0000-0001-9404-5127; Bossa Bossa, Matias
   Nicolas/0000-0001-5127-2573
SN 1361-8415
EI 1361-8423
PD DEC
PY 2021
VL 74
AR 102225
DI 10.1016/j.media.2021.102225
EA SEP 2021
UT WOS:000704125900004
PM 34597937
ER

PT J
AU Xu, B
   Wu, Q
   Xi, C
   He, R
AF Xu, Bin
   Wu, Qi
   Xi, Chen
   He, Ren
TI Recognition of the fatigue status of pilots using BF-PSO optimized
   multi-class GP classification with sEMG signals
SO RELIABILITY ENGINEERING & SYSTEM SAFETY
AB Air crashes caused by human factors pose a problem. Many researchers have focused on aviation human factors and found that pilots' fatigue status is the key factor. In this study, a hybrid multi-class Gaussian process model is proposed to identify the fatigue status of pilots by analyzing the surface electromyogram signals on the back of their neck and upper arm muscles. Instead of using the traditional conjugate gradient technique to determine the optimal parameters, a hybrid bacterial foraging and particle swarm method is proposed to optimize the unknown parameters to improve the classification accuracy of the multi-class Gaussian process. In the proposed method, the entropy-based features are extracted by wavelet translation from the collected signals to estimate the fatigue status of pilots. Experiments are performed through flight simulation in a full-flight simulator to provide three situations for the fatigue level of the subjects. Comparison of experimental results validates the feasibility of the proposed method to identify the fatigue status of pilots and the further enhancements by the proposed classification system in terms of classification accuracy. Results also show that the developed method helps prevent air crashes caused by pilots' fatigue.
SN 0951-8320
EI 1879-0836
PD JUL
PY 2020
VL 199
AR 106930
DI 10.1016/j.ress.2020.106930
UT WOS:000534159800028
ER

PT J
AU Philip, RC
   Rodriguez, JJ
   Niihori, M
   Francis, RH
   Mudery, JA
   Caskey, JS
   Krupinski, E
   Jacob, A
AF Philip, Rohit C.
   Rodriguez, Jeffrey J.
   Niihori, Maki
   Francis, Ross H.
   Mudery, Jordan A.
   Caskey, Justin S.
   Krupinski, Elizabeth
   Jacob, Abraham
TI Automated High-Throughput Damage Scoring of Zebrafish Lateral Line Hair
   Cells After Ototoxin Exposure
SO ZEBRAFISH
AB Zebrafish have emerged as a powerful biological system for drug development against hearing loss. Zebrafish hair cells, contained within neuromasts along the lateral line, can be damaged with exposure to ototoxins, and therefore, pre-exposure to potentially otoprotective compounds can be a means of identifying promising new drug candidates. Unfortunately, anatomical assays of hair cell damage are typically low-throughput and labor intensive, requiring trained experts to manually score hair cell damage in fluorescence or confocal images. To enhance throughput and consistency, our group has developed an automated damage-scoring algorithm based on machine-learning techniques that produce accurate damage scores, eliminate potential operator bias, provide more fidelity in determining damage scores that are between two levels, and deliver consistent results in a fraction of the time required for manual analysis. The system has been validated against trained experts using linear regression, hypothesis testing, and the Pearson's correlation coefficient. Furthermore, performance has been quantified by measuring mean absolute error for each image and the time taken to automatically compute damage scores. Coupling automated analysis of zebrafish hair cell damage to behavioral assays for ototoxicity produces a novel drug discovery platform for rapid translation of candidate drugs into preclinical mammalian models of hearing loss.
SN 1545-8547
EI 1557-8542
PD APR
PY 2018
VL 15
IS 2
BP 145
EP 155
DI 10.1089/zeb.2017.1451
EA JAN 2018
UT WOS:000423747700001
PM 29381431
ER

PT J
AU Wang, X
AF Wang, Xia
TI Semantic Role Labeling in Chinese using HowNet
SO LANGUAGE AND LINGUISTICS
AB Semantic Role Labeling (SRL) has significant impact on many application systems, such as Machine Translation, Information Extraction, Question-Answering, Text Summarization and Text Data Mining. Therefore research on SRL is important for natural language understanding, and so far a number of algorithms, mostly statistically oriented, have been proposed in this field.
   Statistical algorithms must deal with the problem of data sparseness. In our initial study, we found that most words appear only a small number of times, and other words are absent completely in the training set. Only a small number of frequent words supply sufficient data for training. To solve this problem, we developed a backoff model based on HowNet.
   In this study, we demonstrate the benefit of applying the knowledge from HowNet to Semantic Role Labeling by experimenting with four selected Chinese words. Our system employs a statistical approach, which was trained on 208 sentences and tested on 89 sentences. We extracted various lexical and syntactic features, including the phrase type of each constituent, the headword, and the position and distance from the predicate to the constituent in question and voice.
   Comparing the result with knowledge support of HowNet to the result without it, we found distinct improvement when using HowNet.
   The study also reveals that the system can be improved by applying more information from HowNet, introducing full parsing information, enriching the feature set, and using more appropriate probability estimation model.
SN 1606-822X
PD APR
PY 2008
VL 9
IS 2
BP 449
EP 461
UT WOS:000255977400013
ER

PT J
AU Sarantoglou, G
   Bogris, A
   Mesaritakis, C
   Theodoridis, S
AF Sarantoglou, George
   Bogris, Adonis
   Mesaritakis, Charis
   Theodoridis, Sergios
TI Bayesian Photonic Accelerators for Energy Efficient and Noise Robust
   Neural Processing
SO IEEE JOURNAL OF SELECTED TOPICS IN QUANTUM ELECTRONICS
AB Artificial neural networks are efficient computing platforms inspired by the brain. Such platforms can tackle a vast area of real-life tasks ranging from image processing to language translation. Silicon photonic integrated chips (PICs), by employing coherent interactions in Mach-Zehnder interferometers, are promising accelerators offering record low power consumption and ultra-fast matrix multiplication. Such photonic accelerators, however, suffer from phase uncertainty due to fabrication errors and crosstalk effects that inhibit the development of high-density implementations. In this work, we present a Bayesian learning framework for such photonic accelerators. In addition to the conventional log-likelihood optimization path, two novel training schemes are derived, namely a regularized version and a fully Bayesian learning scheme. They are applied on a photonic neural network with 512 phase shifters targeting the MNIST dataset. The new schemes, when combined with a pre-characterization stage that provides the passive offsets, are able to dramatically decrease the operational power of the PIC beyond 70%, with just a slight loss in classification accuracy. The full Bayesian scheme, apart from this energy reduction, returns information with respect to the sensitivity of the phase shifters. This information is used to de-activate 31% of the phase actuators and, thus, significantly simplify the driving system.
RI Bogris, Adonis/O-4808-2018
OI Bogris, Adonis/0000-0002-5740-6285; Theodoridis,
   Sergios/0000-0001-5040-161X; Mesaritakis, Charis/0000-0002-0072-3116
SN 1077-260X
EI 1558-4542
PD NOV
PY 2022
VL 28
IS 6
AR 6100710
DI 10.1109/JSTQE.2022.3183444
UT WOS:000819825000002
ER

PT J
AU Hamad, AH
   Mahmood, AA
   Abed, SA
   Ying, X
AF Hamad, Aws Hamed
   Mahmood, Ali Abdulkareem
   Abed, Saad Adnan
   Ying, Xu
TI Semantic relatedness maximisation for word sense disambiguation using a
   hybrid firefly algorithm
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
AB Word sense disambiguation (WSD) refers to determining the right meaning of a vague word using its context. The WSD intermediately consolidates the performance of final tasks to achieve high accuracy. Mainly, a WSD solution improves the accuracy of text summarisation, information retrieval, and machine translation. This study addresses the WSD by assigning a set of senses to a given text, where the maximum semantic relatedness is obtained. This is achieved by proposing a swarm intelligence method, called firefly algorithm (FA) to find the best possible set of senses. Because of the FA is based on a population of solutions, it explores the problem space more than exploiting it. Hence, we hybridise the FA with a one-point search algorithm to improve its exploitation capacity. Practically, this hybridisation aims to maximise the semantic relatedness of an eligible set of senses. In this study, the semantic relatedness is measured by proposing a glosses-overlapping method enriched by the notion of information content. To evaluate the proposed method, we have conducted intensive experiments with comparisons to the related works based on benchmark datasets. The obtained results showed that our method is comparable if not superior to the related works. Thus, the proposed method can be considered as an efficient solver for the WSD task.
RI HAMAD, AWS HAMED/GLV-5934-2022
SN 1064-1246
EI 1875-8967
PY 2021
VL 41
IS 6
BP 7047
EP 7061
DI 10.3233/JIFS-210934
UT WOS:000731754900086
ER

PT J
AU Khan, MF
   Patra, S
AF Khan, Mohd Faheem
   Patra, Sanjukta
TI Deciphering the rationale behind specific codon usage pattern in
   extremophiles
SO SCIENTIFIC REPORTS
AB Protein stability is affected at different hierarchies - gene, RNA, amino acid sequence and structure. Gene is the first level which contributes via varying codon compositions. Codon selectivity of an organism differs with normal and extremophilic milieu. The present work attempts at detailing the codon usage pattern of six extremophilic classes and their harmony. Homologous gene datasets of thermophile- mesophile, psychrophile-mesophile, thermophile- psychrophile, acidophile-alkaliphile, halophile-nonhalophile and barophile-nonbarophile were analysed for filtering statistically significant attributes. Relative abundance analysis, 1-9 scale ranking, nucleotide compositions, attribute weighting and machine learning algorithms were employed to arrive at findings. AGG in thermophiles and barophiles, CAA in mesophiles and psychrophiles, TGG in acidophiles, GAG in alkaliphiles and GAC in halophiles had highest preference. Preference of GC-rich and G/C-ending codons were observed in halophiles and barophiles whereas, a decreasing trend was reflected in psychrophiles and alkaliphiles. GC-rich codons were found to decrease and G/C-ending codons increased in thermophiles whereas, acidophiles showed equal contents of GC-rich and G/C-ending codons. Codon usage patterns exhibited harmony among different extremophiles and has been detailed. However, the codon attribute preferences and their selectivity of extremophiles varied in comparison to non-extremophiles. The finding can be instrumental in codon optimization application for heterologous expression of extremophilic proteins.
OI Khan, Mohd Faheem/0000-0002-0589-3368
SN 2045-2322
PD OCT 19
PY 2018
VL 8
AR 15548
DI 10.1038/s41598-018-33476-x
UT WOS:000447707900063
PM 30341344
ER

PT C
AU Chen, W
   Ananthakrishnan, S
   Prasad, R
   Natarajan, P
AF Chen, Wei
   Ananthakrishnan, Sankaranarayanan
   Prasad, Rohit
   Natarajan, Prem
BE Bimbot, F
   Cerisara, C
   Fougeron, C
   Gravier, G
   Lamel, L
   Pellegrino, F
   Perrier, P
TI Variable-Span Out-of-Vocabulary Named Entity Detection
SO 14TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2013), VOLS 1-5
SE Interspeech
CT 14th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2013)
CY AUG 25-29, 2013
CL Lyon, FRANCE
SP Int Speech Commun Assoc, europa org, amazon, Microsoft, Google, TcL SYTRAL, European Language Resources Assoc, ouaero, imaginove, VOCAPIA res, acapela, speech ocean, ALDEBARAN, orange, vecsys, IBM Res, Raytheon BBN Technol, voxygen
AB Out-of-vocabulary named entities (OOV NEs) are always misrecognized by fixed-vocabulary automatic speech recognition (ASR) systems. This has a negative impact on downstream applications such as language understanding and machine translation (MT). Automatic detection of OOV NEs in ASR hypotheses can help mitigate this problem by triggering the use of alternative approaches to acquire and process these NEs. State-of-the-art OOV NE detection typically involves tagging ASR-hypothesized words using a sequence model, such as conditional random fields (CRF), in conjunction with a variety of contextual and ASR-derived features. In this paper, we propose a novel variable-span tagging approach for detecting OOV NEs. Instead of tagging individual words in ASR hypotheses, we directly tag longer spans of consecutive words. The proposed approach outperforms a state-of-the-art CRF tagger on two distinct held out test sets with different OOV NE distributions. On a 5.1K word test set rich in OOV NEs, our method achieves 56.1% detection rate at 10% false alarm rate (vs. 52.1% for the CRF detector). On a 39.4K-word test set with a natural distribution of OOV NEs, we obtain 73.0% detection rate at 10% false alarm rate (vs. 69.5% for the CRF detector). In all cases, OOV NEs are completely unobserved in our training data.
SN 2308-457X
BN 978-1-62993-443-3
PY 2013
BP 3728
EP 3732
UT WOS:000395050001294
ER

PT C
AU Ekinci, M
   Aykut, M
   Gedikli, E
AF Ekinci, Murat
   Aykut, Murat
   Gedikli, Eyup
BE Perner, P
TI Gait Recognition by Applying Multiple Projections and Kernel PCA
SO MACHINE LEARNING AND DATA MINING IN PATTERN RECOGNITION, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
CT 5th International Conference on Machine Learning and Data Mining in
   Pattern Recognition
CY JUL 18-20, 2007
CL Leipzig, GERMANY
AB Recognizing people by gait has a unique advantage over other biometrics: it has potential for use at a distance when other biometrics might be at too low a resolution, or might be obscured. In this paper, an improved method for gait recognition is proposed. The proposed work introduces a nonlinear machine learning method, kernel Principal Component Analysis (KPCA), to extract gait features from silhouettes for individual recognition. Binarized silhouette of a motion object is first represented by four 1-D signals which are the basic image features called the distance vectors. The distance vectors are differences between the bounding box and silhouette, and extracted using four projections to silhouette. Classic linear feature extraction approaches, such as PCA, LDA, and FLDA, only take the 2-order statistics among gait patterns into account, and are not sensitive to higher order statistics of data. Therefore, KPCA is used to extract higher order relations among gait patterns for future recognition. Fast Fourier Transform (FFT) is employed as a preprocessing step to achieve translation invariant on the gait patterns accumulated from silhouette sequences which are extracted from the subjects walk in different speed and/or different time. The experiments are carried out on the CMU and the USF gait databases and presented based on the different training gait cycles. Finally, the performance of the proposed algorithm is comparatively illustrated to take into consideration the published gait recognition approaches.
RI Gedikli, Eyup/U-5309-2017; AYKUT, Murat/AAV-9658-2020; Ekinci,
   Murat/A-9653-2012
OI Gedikli, Eyup/0000-0002-7212-5457; Aykut, Murat/0000-0003-0100-6343
SN 0302-9743
EI 1611-3349
BN 978-3-540-73498-7
PY 2007
VL 4571
BP 727
EP +
UT WOS:000248523200054
ER

PT J
AU Lee, KW
   Chin, RKY
AF Lee, Kin Wai
   Chin, Renee Ka Yin
TI Diverse COVID-19 CT Image-to-Image Translation with Stacked Residual
   Dropout
SO BIOENGINEERING-BASEL
AB Machine learning models are renowned for their high dependency on a large corpus of data in solving real-world problems, including the recent COVID-19 pandemic. In practice, data acquisition is an onerous process, especially in medical applications, due to lack of data availability for newly emerged diseases and privacy concerns. This study introduces a data synthesization framework (sRD-GAN) that generates synthetic COVID-19 CT images using a novel stacked-residual dropout mechanism (sRD). sRD-GAN aims to alleviate the problem of data paucity by generating synthetic lung medical images that contain precise radiographic annotations. The sRD mechanism is designed using a regularization-based strategy to facilitate perceptually significant instance-level diversity without content-style attribute disentanglement. Extensive experiments show that sRD-GAN can generate exceptional perceptual realism on COVID-19 CT images examined by an experiment radiologist, with an outstanding Frechet Inception Distance (FID) of 58.68 and Learned Perceptual Image Patch Similarity (LPIPS) of 0.1370 on the test set. In a benchmarking experiment, sRD-GAN shows superior performance compared to GAN, CycleGAN, and one-to-one CycleGAN. The encouraging results achieved by sRD-GAN in different clinical cases, such as community-acquired pneumonia CT images and COVID-19 in X-ray images, suggest that the proposed method can be easily extended to other similar image synthetization problems.
EI 2306-5354
PD NOV
PY 2022
VL 9
IS 11
AR 698
DI 10.3390/bioengineering9110698
UT WOS:000894671600001
PM 36421099
ER

PT C
AU Xu, DQ
   Li, JH
   Zhu, MH
   Zhang, M
   Zhou, GD
AF Xu, Dongqin
   Li, Junhui
   Zhu, Muhua
   Zhang, Min
   Zhou, Guodong
GP Assoc Computat Linguist
TI XLPT-AMR: Cross-Lingual Pre-Training via Multi-Task Learning for
   Zero-Shot AMR Parsing and Text Generation
SO 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND
   THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING,
   VOL 1 (ACL-IJCNLP 2021)
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB Due to the scarcity of annotated data, Abstract Meaning Representation (AMR) research is relatively limited and challenging for languages other than English. Upon the availability of English AMR dataset and English-to-X parallel datasets, in this paper we propose a novel cross-lingual pre-training approach via multi-task learning (MTL) for both zero-shot AMR parsing and AMR-to-text generation. Specifically, we consider three types of relevant tasks, including AMR parsing, AMR-to-text generation, and machine translation. We hope that knowledge gained while learning for English AMR parsing and text generation can be transferred to the counterparts of other languages. With properly pretrained models, we explore four different fine-tuning methods, i.e., vanilla fine-tuning with a single task, one-for-all MTL fine-tuning, targeted MTL fine-tuning, and teacher-student-based MTL fine-tuning. Experimental results on AMR parsing and text generation of multiple non-English languages demonstrate that our approach significantly outperforms a strong baseline of pre-training approach, and greatly advances the state of the art. In detail, on LDC2020T07 we have achieved 70.45%, 71.76%, and 70.80% in Smatch F1 for AMR parsing of German, Spanish, and Italian, respectively, while for AMR-to-text generation of the languages, we have obtained 25.69, 31.36, and 28.42 in BLEU respectively.
BN 978-1-954085-52-7
PY 2021
BP 896
EP 907
UT WOS:000698663100073
ER

PT C
AU Xiong, K
   Yuan, R
   He, WX
   Jing, YM
   Wang, YS
   He, QQ
   Li, HF
AF Xiong, Kai
   Yuan, Rui
   He, Wenxue
   Jing, Yanmei
   Wang, Yansheng
   He, Qiqi
   Li, Huafu
GP IOP
TI Crawling Chinese-Myanmar Parallel Corpus: Automatic Collection,
   Screening and Cleaning Corpus
SO 2019 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE
   APPLICATIONS AND TECHNOLOGIES (AIAAT 2019)
SE IOP Conference Series-Materials Science and Engineering
CT 3rd International Conference on Artificial Intelligence Applications and
   Technologies (AIAAT)
CY AUG 01-03, 2019
CL Beijing, PEOPLES R CHINA
SP Hong Kong Soc Mech Engineers, Xidian Univ, York Univ, Donghua Univ, Fudan Univ
AB The collection of Chinese-Myanmar Parallel Corpus (CMPC) is the key step in the natural language processing (NLP) and training Machine Translation Engine (MTE) of Southeast Asia minority languages. As the scarcity of CMPC resources that efficient corpus collection methods are worth studying extremely. Traditional corpus collection methods include manual collection, text recognition of books and Internet crawlers, etc. Among them, the most efficient method to collect corpus is internet crawler preached by many. Traditional Internet crawler algorithm is interfere easily by a lot of spamming and advertising that lead to the time-consuming and low-precision. We propose a web crawler mechanism combines acquisition automatically technology bilingual website list, crawling corpus and cleaning corpus to obtain high quality parallel corpus. Firstly, using the hyperlinks to recursively access related corpus websites through building the website graph. Furthermore, the breadth-first, Backline and PageRank crawler framework used to build a corpus selection model based on crawling with threshold, matching link, ranking the heat of page, through this, the CMPC can be found accurately. Finally, the corpus cleaning model based on the HTML parsing to determine a set of standardized token sequences. By testing the Chinese-Myanmar reptile algorithm established in this paper, the experimental results show that our benchmarks this model exceeds previous published benchmarks. Up to now, we have obtained 1.1 million parallel corpus pairs of Chinese-Myanmar.
SN 1757-8981
PY 2019
VL 646
AR 012046
DI 10.1088/1757-899X/646/1/012046
UT WOS:000562602300045
ER

PT J
AU Schwemmer, MA
   Skomrock, ND
   Sederberg, PB
   Ting, JE
   Sharma, G
   Bockbrader, MA
   Friedenberg, DA
AF Schwemmer, Michael A.
   Skomrock, Nicholas D.
   Sederberg, Per B.
   Ting, Jordyn E.
   Sharma, Gaurav
   Bockbrader, Marcia A.
   Friedenberg, David A.
TI Meeting brain-computer interface user performance expectations using a
   deep neural network decoding framework
SO NATURE MEDICINE
AB Brain-computer interface (BCI) neurotechnology has the potential to reduce disability associated with paralysis by translating neural activity into control of assistive devices(1-9). Surveys of potential end-users have identified key BCI system features(10-14), including high accuracy, minimal daily setup, rapid response times, and multifunctionality. These performance characteristics are primarily influenced by the BCI's neural decoding algorithm(1,15), which is trained to associate neural activation patterns with intended user actions. Here, we introduce a new deep neural network(16) decoding framework for BCI systems enabling discrete movements that addresses these four key performance characteristics. Using intracortical data from a participant with tetraplegia, we provide offline results demonstrating that our decoder is highly accurate, sustains this performance beyond a year without explicit daily retraining by combining it with an unsupervised updating procedure(3,17- 20), responds faster than competing methods(8), and can increase functionality with minimal retraining by using a technique known as transfer learning(21). We then show that our participant can use the decoder in real-time to reanimate his paralyzed forearm with functional electrical stimulation (FES), enabling accurate manipulation of three objects from the grasp and release test (GRT)(22). These results demonstrate that deep neural network decoders can advance the clinical translation of BCI technology.
RI Bockbrader, Marcia/U-7844-2019; Sharma, Gaurav/HTO-3197-2023;
   Bockbrader, Marcia/J-6203-2013
OI Bockbrader, Marcia/0000-0001-6419-0630; Bockbrader,
   Marcia/0000-0001-6419-0630; Friedenberg, David/0000-0002-4404-8941
SN 1078-8956
EI 1546-170X
PD NOV
PY 2018
VL 24
IS 11
BP 1669
EP +
DI 10.1038/s41591-018-0171-y
UT WOS:000449404200017
PM 30250141
ER

PT J
AU Nan, XG
   Bao, LL
   Zhao, XS
   Zhao, XW
   Sangaiah, AK
   Wang, GG
   Ma, ZQ
AF Nan, Xuanguo
   Bao, Lingling
   Zhao, Xiaosa
   Zhao, Xiaowei
   Sangaiah, Arun Kumar
   Wang, Gai-Ge
   Ma, Zhiqiang
TI EPuL: An Enhanced Positive-Unlabeled Learning Algorithm for the
   Prediction of Pupylation Sites
SO MOLECULES
AB Protein pupylation is a type of post-translation modification, which plays a crucial role in cellular function of bacterial organisms in prokaryotes. To have a better insight of the mechanisms underlying pupylation an initial, but important, step is to identify pupylation sites. To date, several computational methods have been established for the prediction of pupylation sites which usually artificially design the negative samples using the verified pupylation proteins to train the classifiers. However, if this process is not properly done it can affect the performance of the final predictor dramatically. In this work, different from previous computational methods, we proposed an enhanced positive-unlabeled learning algorithm (EPuL) to the pupylation site prediction problem, which uses only positive and unlabeled samples. Firstly, we separate the training dataset into the positive dataset and the unlabeled dataset which contains the remaining non-annotated lysine residues. Then, the EPuL algorithm is utilized to select the reliably negative initial dataset and then iteratively pick out the non-pupylation sites. The performance of the proposed method was measured with an accuracy of 90.24%, an Area Under Curve (AUC) of 0.93 and an MCC of 0.81 by 10-fold cross-validation. A user-friendly web server for predicting pupylation sites was developed and was freely available at http://59.73.198.144:8080/EPuL.
RI Wang, Gai-Ge/B-6060-2019; Sangaiah, Arun Kumar/U-6785-2019
OI Wang, Gai-Ge/0000-0002-3295-8972; Sangaiah, Arun
   Kumar/0000-0002-0229-2460; zhao, xiaosa/0000-0003-3510-6473
EI 1420-3049
PD SEP
PY 2017
VL 22
IS 9
AR 1463
DI 10.3390/molecules22091463
UT WOS:000411499400065
PM 28872627
ER

PT J
AU Ruf, CA
   De Massari, D
   Furdea, A
   Matuz, T
   Fioravanti, C
   van der Heiden, L
   Halder, S
   Birbaumer, N
AF Ruf, Carolin A.
   De Massari, Daniele
   Furdea, Adrian
   Matuz, Tamara
   Fioravanti, Chiara
   van der Heiden, Linda
   Halder, Sebastian
   Birbaumer, Niels
TI Semantic classical conditioning and brain-computer interface control:
   encoding of affirmative and negative thinking
SO FRONTIERS IN NEUROSCIENCE
AB The aim of the study was to investigate conditioned electroencephalography (EEG) responses to factually correct and incorrect statements in order to enable binary communication by means of a brain-computer interface (BCI). In two experiments with healthy participants true and false statements (serving as conditioned stimuli, CSs) were paired with two different tones which served as unconditioned stimuli (USs). The features of the USs were varied and tested for their effectiveness to elicit differentiable conditioned reactions (CRs). After acquisition of the CRs, these CRs to true and false statements were classified offline using a radial basis function kernel support vector machine. A mean single-trial classification accuracy of 50.5% was achieved for differentiating conditioned "yes" versus "no" thinking and mean accuracies of 65.4% for classification of "yes" and 68.8% for "no" thinking (both relative to baseline) were found using the best US. Analysis of the area under the curve of the conditioned EEG responses revealed significant differences between conditioned "yes" and "no" answers. Even though improvements are necessary, these first results indicate that the semantic conditioning paradigm could be a useful basis for further research regarding BCI communication in patients in the complete locked-in state.
RI Halder, Sebastian/G-3745-2012; Halder, Sebastian/J-6144-2019
OI Halder, Sebastian/0000-0003-1017-3696; Birbaumer,
   Niels/0000-0002-6786-5127
SN 1662-453X
PY 2013
VL 7
AR 23
DI 10.3389/fnins.2013.00023
UT WOS:000346567300023
PM 23471568
ER

PT J
AU Abbas, M
   Smaili, K
   Berkani, D
AF Abbas, M.
   Smaili, K.
   Berkani, D.
TI Evaluation of Topic Identification Methods for Arabic Texts and their
   Combination by using a Corpus Extracted from the Omani Newspaper Alwatan
SO ARAB GULF JOURNAL OF SCIENTIFIC RESEARCH
AB Topic identification is used in several applications, as adapting language models for speech recognition and machine translation, focusing on a specific use for search engines, etc. Topic identification consists to assign one or several topic labels to a flow of textual data. Labels are chosen from a set of topics fixed a priori. In this paper, we present a study about identifying topics of Arabic texts. For this, a considerable amount of data is needed. Thus, we started by collecting texts from the website of the Omani newspaper "Alwatan". The result is an Arabic corpus composed of more than 9000 articles corresponding to nearly 10 millions words. The considered topics in our experiments are: Culture, Religion, Economy, Local news, International news and sports. Some of the methods presented in this study, are well known in the text categorization community, as TFIDF classifier and kNN "k Nearest Neighbors". The objective to use these methods is to compare them to TR-classifier "TRiggers-based classifier", a new method that we have proposed, which is based on computing triggers or the Average Mutual Information of each couple of words. In order to enhance performances, we have combined results of the three methods by using three approaches: Majority Vote, Enhanced Majority Vote and Linear Combination.
RI Abbas, Mourad/AAI-5127-2020
OI Abbas, Mourad/0000-0002-8291-0862
SN 1015-4442
PD SEP-DEC
PY 2011
VL 29
IS 3-4
BP 183
EP 191
UT WOS:000303538600007
ER

PT J
AU Ponsen, M
   Spronck, P
   Munoz-Avila, H
   Aha, DW
AF Ponsen, Marc
   Spronck, Pieter
   Munoz-Avila, Hector
   Aha, David W.
TI Knowledge acquisition for adaptive game AI
SO SCIENCE OF COMPUTER PROGRAMMING
AB Game artificial intelligence (AI) controls the decision-making process of computer-controlled opponents in computer games. Adaptive game AI (i.e., game At that can automatically adapt the behaviour of the computer players to changes in the environment) can increase the entertainment value of computer games. Successful adaptive game AI is invariably based on the game's domain knowledge. We show that an offline evolutionary algorithm can learn important domain knowledge in the form of game tactics (i.e., a sequence of game actions) for dynamic scripting, an offline algorithm inspired by reinforcement learning approaches that we use to create adaptive game AI. We compare the performance of dynamic scripting under three conditions for defeating non-adaptive opponents in a real-time strategy game. In the first condition, we manually encode its tactics. In the second condition, we manually translate the tactics learned by the evolutionary algorithm, and use them for dynamic scripting. In the third condition, this translation is automated. We found that dynamic scripting performs best under the third condition, and both of the latter conditions outperform manual tactic encoding. We discuss the implications of these results, and the performance of dynamic scripting for adaptive game At from the perspective of machine learning research and commercial game development. (c) 2007 Published by Elsevier B.V.
SN 0167-6423
EI 1872-7964
PD JUN 1
PY 2007
VL 67
IS 1
BP 59
EP 75
DI 10.1016/j.scico.2007.01.006
UT WOS:000247838100004
ER

PT J
AU Blankertz, B
   Muller, KR
   Krusienski, DJ
   Schalk, G
   Wolpaw, JR
   Schlogl, A
   Pfurtscheller, G
   Millan, JDR
   Schroder, M
   Birbaumer, N
AF Blankertz, Benjamin
   Mueller, Klaus-Robert
   Krusienski, Dean J.
   Schalk, Gerwin
   Wolpaw, Jonathan R.
   Schloegl, Alois
   Pfurtscheller, Gert
   Millan, Jose D. R.
   Schroeder, Michael
   Birbaumer, Niels
TI The BCI competition III: Validating alternative approaches to actual BCI
   problems
SO IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING
CT 3rd International Meeting on Brain-Computer Interface Technology
CY JUN, 2005
CL Rensselaerville Inst, Rensselaerville, NY
HO Rensselaerville Inst
AB A brain-computer interface (BCI) is a system that allows its users to control external devices with brain activity. Although the proof-of-concept was given decades ago, the reliable translation of user intent into device control commands is still a major challenge. Success requires the effective interaction of two adaptive controllers: the user's brain, which produces brain activity that encodes intent, and the BCI system, which translates that activity into device control commands. In order to facilitate this interaction, many laboratories are exploring a variety of signal analysis techniques to improve the adaptation of the BCI system to the user. In the literature, many machine learning and pattern classification algorithms have been reported to give impressive results when applied to BCI data in offline analyses. However, it is more difficult to evaluate their relative value for actual online use. BCI data competitions have been organized to provide objective formal evaluations of alternative methods. Prompted by the great interest in the first two BCI Competitions, we organized the third BCI Competition to address several of the most difficult and important analysis problems in BCI research. The paper describes the data sets that were provided to the competitors and gives an overview of the results.
RI del R. Millan, Jose/F-1696-2011; Tangermann, Michael/HPF-1421-2023;
   Mueller, Klaus-Robert/Y-3547-2019; Krusienski, Dean J/AAI-3782-2020;
   Mueller, Klaus-Robert/C-3196-2013
OI del R. Millan, Jose/0000-0001-5819-1522; Tangermann,
   Michael/0000-0001-6729-0290; Mueller, Klaus-Robert/0000-0002-3861-7685;
   Krusienski, Dean J/0000-0002-4668-5784; Mueller,
   Klaus-Robert/0000-0002-3861-7685; Wolpaw, Jonathan/0000-0003-0805-1315;
   Blankertz, Benjamin/0000-0002-2437-4846; Schalk,
   Gerwin/0000-0003-3443-9487; Schlogl, Alois/0000-0002-5621-8100;
   Birbaumer, Niels/0000-0002-6786-5127
SN 1534-4320
EI 1558-0210
PD JUN
PY 2006
VL 14
IS 2
BP 153
EP 159
DI 10.1109/TNSRE.2006.875642
UT WOS:000238394700008
PM 16792282
ER

PT J
AU Basili, R
   DellaRocca, M
   Pazienza, MT
AF Basili, R
   DellaRocca, M
   Pazienza, MT
TI Contextual word sense tuning and disambiguation
SO APPLIED ARTIFICIAL INTELLIGENCE
AB The discrimination of word senses, word sense disambiguation (WSD), is a major problem in natural language processing (NLP) applications, e.g., text classification and understanding. The problem of determining the correct sense of lexical items in raw texts is relevant to the activities of categorization, machine translation, information retrieval, and any language engineering task Problems are related to the pervasive ambiguity of words and their use in texts. Moreover the specificity of senses in the knowledge domains, where words are used, tends to augment the complexity of the disambiguation task affecting the completeness of most on-line sources, like dictionaries and general purpose lexical resources. In this article an integrated method based on a well-known lexical knowledge base (i.e., WordNet) and on corpus statistics is used to tune the sense classification to a specific sublanguage and to drive contextual dis-ambiguation of word senses. The method results in a system (General Purpose Ontology Disambiguation and Tuning, GODoT) aiming to support a semantic boot-strapping process within specific application domains. The approach has been extensively tested on verb classification in two different corpora, although it can be applied to other syntactic categories as well. The resulting disambiguation framework is intended to serve several NLP tasks like lexical acquisition (in the definition of class-based language models) or information retrieval (in the characterization of indexes by means of their senses in contexts).
OI BASILI, ROBERTO/0000-0001-5140-0694
SN 0883-9514
PD APR-MAY
PY 1997
VL 11
IS 3
BP 235
EP 262
DI 10.1080/088395197118244
UT WOS:A1997WX21900004
ER

PT J
AU Li, S
   Hendrich, N
   Liang, HZ
   Ruppel, P
   Zhang, CS
   Zhang, JW
AF Li, Shuang
   Hendrich, Norman
   Liang, Hongzhuo
   Ruppel, Philipp
   Zhang, Changshui
   Zhang, Jianwei
TI A Dexterous Hand-Arm Teleoperation System Based on Hand Pose Estimation
   and Active Vision
SO IEEE TRANSACTIONS ON CYBERNETICS
AB Markerless vision-based teleoperation that leverages innovations in computer vision offers the advantages of allowing natural and noninvasive finger motions for multifingered robot hands. However, current pose estimation methods still face inaccuracy issues due to the self-occlusion of the fingers. Herein, we develop a novel vision-based hand-arm teleoperation system that captures the human hands from the best viewpoint and at a suitable distance. This teleoperation system consists of an end-to-end hand pose regression network and a controlled active vision system. The end-to-end pose regression network (Transteleop), combined with an auxiliary reconstruction loss function, captures the human hand through a low-cost depth camera and predicts joint commands of the robot based on the image-to-image translation method. To obtain the optimal observation of the human hand, an active vision system is implemented by a robot arm at the local site that ensures the high accuracy of the proposed neural network. Human arm motions are simultaneously mapped to the slave robot arm under relative control. Quantitative network evaluation and a variety of complex manipulation tasks, for example, tower building, pouring, and multitable cup stacking, demonstrate the practicality and stability of the proposed teleoperation system.
OI Ruppel, Philipp/0000-0002-1336-8483; Liang,
   Hongzhuo/0000-0002-6870-9898; Hendrich, Norman/0000-0003-0499-886X
SN 2168-2267
EI 2168-2275
DI 10.1109/TCYB.2022.3207290
EA SEP 2022
UT WOS:000865066000001
PM 36179009
ER

PT J
AU Chen, QL
AF Chen, Qinglai
TI Application of Virtual Reality Technology in Teaching and Training
   System of Processing Industrial Robot
SO WIRELESS COMMUNICATIONS & MOBILE COMPUTING
AB In order to solve the problem of difficult teaching and slow teaching in the traditional teaching method of industrial robots, a virtual reality technology is proposed in the teaching and training system of industrial robots. The binocular vision module is fixedly connected to the end tool of the robot to reduce the limitation of teaching range. A hand-held teaching device with a feature plate and a position and pose measuring rod is designed to teach the position and pose of set points quickly. The least square method is used to calibrate the translation parameters of the end of the feature plate. The system collects the image of the feature plate of the hand-held teaching device through binocular vision module and processes the image to obtain the position and pose information of the end points; the pose information is converted to the robot base coordinate system to realize the robot teaching reproduction, and then the teaching reproduction test of 25 points in space is carried out. The experimental results show that the average error of the robot teaching position is 2.427 mm; after using mobile demonstration, the mean position error decreases by 25.3%. Conclusion. The application of virtual reality technology in the teaching and training system of machining industrial robot can improve the accuracy of teaching repetition.
SN 1530-8669
EI 1530-8677
PD SEP 20
PY 2022
VL 2022
AR 3415660
DI 10.1155/2022/3415660
UT WOS:000881578900003
ER

PT C
AU Wijenayake, WWGPA
   Gunathilake, MDSS
   Gurusinghe, PM
   Samararathne, WAHK
   Sriyaratna, D
AF Wijenayake, W. W. G. P. A.
   Gunathilake, M. D. S. S.
   Gurusinghe, P. M.
   Samararathne, W. A. H. K.
   Sriyaratna, Disni
BE Arai, K
TI EasyChat: A Chat Application for Deaf/Dumb People to Communicate with
   the General Community
SO INTELLIGENT COMPUTING, VOL 1
SE Lecture Notes in Networks and Systems
CT Computing Conference on Intelligent Computing
CY JUL 14-15, 2022
CL ELECTR NETWORK
AB Sign Language is closely associated with the deaf and dumb community to communicate with each other. However, not everyone understands sign language or verbal languages, so these communities need proper ways to communicate online. Therefore, this paper presents EasyChat, a sign language chat application that can translate three main sign languages into Simple English text as well as Simple English text into sign language, which would benefit for deaf/dumb community to express their ideas with the general community by simply capturing their British Sign Language (BSL) or Makaton gestures/symbols or lip movements. These steps are handled by four components. The first component, Convert BSL into Simple English, and the second component, handles Lip Reading conversion. The Makaton gesture and symbol conversion component produces a simple English text-formatted output for identified Makaton hand signs. Finally, the Text/voice to Sign Converter works on converting entered English text back into the sign language-based images. By using these components, EasyChat can detect relevant gestures and lip movement inputs with superior accuracy and translate. This can lead to more effective and efficient online communication between the community of deaf/dumb individuals and the general public.
SN 2367-3370
EI 2367-3389
BN 978-3-031-10461-9; 978-3-031-10460-2
PY 2022
VL 506
BP 332
EP 344
DI 10.1007/978-3-031-10461-9_23
UT WOS:000889415900023
ER

PT J
AU Kalafat, MA
   Sevinc, H
   Samankan, S
   Altinkaynak, A
   Temel, Z
AF Kalafat, Merve Acer
   Sevinc, Hasan
   Samankan, Shahrad
   Altinkaynak, Atakan
   Temel, Zeynep
TI A Novel Origami-Inspired Delta Mechanism With Flat Parallelogram Joints
SO JOURNAL OF MECHANISMS AND ROBOTICS-TRANSACTIONS OF THE ASME
AB In robotics, the origami-based design methodology uses straightforward fabrication and assembly processes to create small-scale parallel mechanisms. Delta mechanisms are among the well-known parallel mechanisms used mostly in pick-and-place operations due to their capability to reach high speeds and accelerations. In this work, we present a novel Delta mechanism based on origami-inspired designs and two-dimensional layer-by-layer fabrication methods, reducing the time and errors in manufacturing. We developed a new flat parallelogram providing translations in X-Y-Z directions, respecting the Delta mechanism's conventional kinematic models. The fabrication and assembly processes include laser machining and lamination, eliminating manual folding and bonding steps. The mechanism operates in a 20 x 20 x 20 mm(3) workspace and a 17.5 cm diameter circular footprint when it is entirely flat. The kinematic performance of the mechanism is analyzed using a six degrees-of-freedom position sensor on the end effector. The experiments are conducted to follow circular trajectories with varying radii at different heights. Despite having no feedback control from the end effector, the mechanism follows the given trajectories with 1.5 mm root-mean-square (RMS) precision. We also present the effects of the elasticity of flexible materials at different regions of the mechanism on the performance of the Delta robot.
RI Samankan, shahrad/ABC-3967-2021; Altınkaynak, Atakan/AAD-9740-2020;
   Kalafat, Merve Acer/ABA-7600-2020
OI Samankan, shahrad/0000-0002-4680-021X; Altınkaynak,
   Atakan/0000-0003-3971-3641; Kalafat, Merve Acer/0000-0002-5203-7775
SN 1942-4302
EI 1942-4310
PD APR 1
PY 2021
VL 13
IS 2
AR 021005
DI 10.1115/1.4048917
UT WOS:000629534500006
ER

PT C
AU Xu, DQ
   Li, JH
   Zhu, MH
   Zhang, M
   Zhou, GD
AF Xu, Dongqin
   Li, Junhui
   Zhu, Muhua
   Min Zhang
   Zhou, Guodong
GP Assoc Computat Linguist
TI Improving AMR Parsing with Sequence-to-Sequence Pre-training
SO PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL
   LANGUAGE PROCESSING (EMNLP)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 16-20, 2020
CL ELECTR NETWORK
SP Bloomberg Engn, Google Res, Apple, Amazon Sci, Baidu, Megagon Labs, Facebook, DeepMind, Grammarly, ByteDance, Zeta Alpha, Babelscape, Naver, Adobe, Hitachi, Salesforce, Univ So Calif, Viterbi Sch Engn, Informat Sci Inst
AB In the literature, the research on abstract meaning representation (AMR) parsing is much restricted by the size of human-curated dataset which is critical to build an AMR parser with good performance. To alleviate such data size restriction, pre-trained models have been drawing more and more attention in AMR parsing. However, previous pre-trained models, like BERT, are implemented for general purpose which may not work as expected for the specific task of AMR parsing. In this paper, we focus on sequence-to-sequence (seq2seq) AMR parsing and propose a seq2seq pre-training approach to build pre-trained models in both single and joint way on three relevant tasks, i.e., machine translation, syntactic parsing, and AMR parsing itself. Moreover, we extend the vanilla fine-tuning method to a multi-task learning fine-tuning method that optimizes for the performance of AMR parsing while endeavors to preserve the response of pre-trained models. Extensive experimental results on two English benchmark datasets show that both the single and joint pre-trained models significantly improve the performance (e.g., from 71.5 to 80.2 on AMR 2.0), which reaches the state of the art. The result is very encouraging since we achieve this with seq2seq models rather than complex models. We make our code and model available at https:// github.com/xdqkid/S2S- AMR- Parser.
BN 978-1-952148-60-6
PY 2020
BP 2501
EP 2511
UT WOS:000855160702053
ER

PT J
AU Wu, LJ
   Tan, X
   Qin, T
   Lai, JH
   Liu, TY
AF Wu, Lijun
   Tan, Xu
   Qin, Tao
   Lai, Jianhuang
   Liu, Tie-Yan
TI Beyond Error Propagation: Language Branching Also Affects the Accuracy
   of Sequence Generation
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB Sequence generation tasks, such as neural machine translation (NMT) and abstractive summarization, usually suffer from exposure bias as well as the error propagation problem due to the autoregressive training and generation. Many previous works have discussed the relationship between error propagation and the accuracy drop problem (i.e., the right part of the generated sentence is often worse than its left part in left-to-right decoding models). In this paper, taking NMT as a typical sequence generation task, we measure the accuracy of the generated sentence with various metrics and conduct a series of analyses to deeply understand the accuracy drop problem. We obtain several interesting findings. First, The role of error propagation on accuracy drop is overstated in the literature, although it is indeed a cause to the accuracy drop problem. Second, Characteristics of a language play a more important role in causing the accuracy drop problem: the left part of the generated sentence in a right-branching language (e.g., English) is more likely to bemore accurate than its right part, while the right part is more accurate for a left-branching language (e.g., Japanese). Our discoveries are also confirmed on other generation tasks (e.g., image captioning, abstractive summarization and language modeling) with multiple left/right-branching languages, as well as in various model structures.
OI Wu, Lijun/0000-0002-3530-590X; Qin, Tao/0000-0002-9095-0776
SN 2329-9290
EI 2329-9304
PD DEC
PY 2019
VL 27
IS 12
BP 1868
EP 1879
DI 10.1109/TASLP.2019.2933727
UT WOS:000484295700001
ER

PT J
AU Yang, LB
   Zhang, ZQ
   Cai, XY
   Dai, T
AF Yang, Libin
   Zhang, Zeqing
   Cai, Xiaoyan
   Dai, Tao
TI Attention-Based Personalized Encoder-Decoder Model for Local Citation
   Recommendation
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
AB With a tremendous growth in the number of scientific papers, researchers have to spend too much time and struggle to find the appropriate papers they are looking for. Local citation recommendation that provides a list of references based on a text segment could alleviate the problem. Most existing local citation recommendation approaches concentrate on how to narrow the semantic difference between the scientific papers' and citation context's text content, completely neglecting other information. Inspired by the successful use of the encoder-decoder framework in machine translation, we develop an attention-based encoder-decoder (AED) model for local citation recommendation. The proposed AED model integrates venue information and author information in attention mechanism and learns relations between variable-length texts of the two text objects, i.e., citation contexts and scientific papers. Specifically, we first construct an encoder to represent a citation context as a vector in a low-dimensional space; after that, we construct an attention mechanism integrating venue information and author information and use RNN to construct a decoder, then we map the decoder's output into a softmax layer, and score the scientific papers. Finally, we select papers which have high scores and generate a recommended reference paper list. We conduct experiments on the DBLP and ACL Anthology Network (AAN) datasets, and the results illustrate that the performance of the proposed approach is better than the other three state-of-the-art approaches.
SN 1687-5265
EI 1687-5273
PY 2019
VL 2019
AR 1232581
DI 10.1155/2019/1232581
UT WOS:000471904200001
PM 31281332
ER

PT J
AU Russwurm, M
   Korner, M
AF Russwurm, Marc
   Koerner, Marco
TI Multi-Temporal Land Cover Classification with Sequential Recurrent
   Encoders
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
AB Earth observation (EO) sensors deliver data at daily or weekly intervals. Most land use and land cover classification (LULC) approaches, however, are designed for cloud-free and mono-temporal observations. The increasing temporal capabilities of today's sensors enable the use of temporal, along with spectral and spatial features. Domains such as speech recognition or neural machine translation, work with inherently temporal data and, today, achieve impressive results by using sequential encoder-decoder structures. Inspired by these sequence-to-sequence models, we adapt an encoder structure with convolutional recurrent layers in order to approximate a phenological model for vegetation classes based on a temporal sequence of Sentinel 2 (S2) images. In our experiments, we visualize internal activations over a sequence of cloudy and non-cloudy images and find several recurrent cells that reduce the input activity for cloudy observations. Hence, we assume that our network has learned cloud-filtering schemes solely from input data, which could alleviate the need for tedious cloud-filtering as a preprocessing step for many EO approaches. Moreover, using unfiltered temporal series of top-of-atmosphere (TOA) reflectance data, our experiments achieved state-of-the-art classification accuracies on a large number of crop classes with minimal preprocessing, compared to other classification approaches.
OI Korner, Marco/0000-0002-9186-4175; Russwurm, Marc/0000-0001-6612-5744
SN 2220-9964
PD APR
PY 2018
VL 7
IS 4
AR 129
DI 10.3390/ijgi7040129
UT WOS:000435186000002
ER

PT C
AU Botalb, A
   Moinuddin, M
   Al-Saggaf, UM
   Ali, SSA
AF Botalb, Abdelaziz
   Moinuddin, M.
   Al-Saggaf, U. M.
   Ali, Syed S. A.
GP IEEE
TI Contrasting Convolutional Neural Network (CNN) with Multi-Layer
   Perceptron (MLP) for Big Data Analysis
SO 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT AND ADVANCED SYSTEM (ICIAS
   2018) / WORLD ENGINEERING, SCIENCE & TECHNOLOGY CONGRESS (ESTCON)
CT World Engineering, Science and Technology Congress (ESTCON) / 7th
   International Conference on Intelligent and Advanced System (ICIAS)
CY AUG 13-14, 2018
CL Kuala Lumpur, MALAYSIA
SP Univ Teknologi Petronas, Elect & Elect Engn Dept
AB Recently, CNNs have become very popular in the machine learning field, due to their high predictive power in classification problems that involve very high dimensional data with tens of hundreds of different classes. CNN is a natural extension to MLP with few modifications which resulted in a breakthrough. Mainly, the MLP algebraic dot product as a similarity function was replaced with 2-d convolution; in addition to a pooling layer which reduces parameter dimensions making the model equi-variant to translations, distortions, and transformations. The sparse connectivity nature of CNN is also a variation to the MLP. The two models were implemented on the EMNIST dataset which was used as 50% and 100% of its capacity. The models were trained with fixed and flexible number of epochs in two runs. Using 100% of EMNIST; for the fixed run CNN achieved test accuracy of 92% and MLP 31.43%, where in the flexible run the CNN achieved 92% and MLP 89.47%. Using 50% of EMNIST; for the fixed run CNN achieved test accuracy of 92.9% and MLP 33.75%, where in the flexible run of 92.9% and MLP 88.20%. The CNN demonstrated a good maintenance of high accuracy for image like inputs and also proved to be a better candidate for big data applications.
RI Al-Saggaf, Ubaid M./I-2704-2012; Ali, Syed Saad Azhar/HJP-9650-2023;
   Al-Saggaf, Ubaid M./AAF-1743-2021
OI Al-Saggaf, Ubaid M./0000-0002-2925-5184; Ali, Syed Saad
   Azhar/0000-0002-5615-4629; Al-Saggaf, Ubaid M./0000-0002-2925-5184;
   Moinuddin, Muhammad/0000-0003-4735-0692
BN 978-1-5386-7269-3
PY 2018
UT WOS:000465101000058
ER

PT C
AU Showkatramani, GJ
   Khatri, N
   Landicho, A
   Layog, D
AF Showkatramani, Girish J.
   Khatri, Nidhi
   Landicho, Arlene
   Layog, Darwin
BE Wani, MA
   Kantardzic, M
   Sayedmouchaweh, M
   Gama, J
   Lughofer, E
TI Trademark Design Code Identification Using Deep Neural Networks
SO 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   APPLICATIONS (ICMLA)
CT 17th IEEE International Conference on Machine Learning and Applications
   (IEEE ICMLA)
CY DEC 17-20, 2018
CL Orlando, FL
SP IEEE, Assoc Machine Learning & Applicat
AB Trademark review and approval is a complex process that involves thorough analysis and review of the design components of the marks including the visual characteristics as well as the textual mark description data specifying the significant aspects of the mark. One of the crucial aspect in review of the trademark application is determining the design codes of the trademarks based on their mark description. Currently, the process of identifying the design codes for a trademark is performed manually in the United States Patent and Trademark Office (USPTO) and takes substantial amount of time.
   Recently, word embeddings and deep neural networks (DNNs) have demonstrated excellent performance in computer vision and various natural language processing (NLP) tasks such as machine translation, speech recognition, sentence and document classification etc. to name a few. In this study, we explored fastText and different neural networks such as Convolution Neural Networks (CNN), Long Short Term Memory (LSTM), bidirectional versions of both LSTM and Gated Recurrent Unit (GRU) and Recurrent Convolutional Neural Network (RCNN) to automate trademark design code classification based on their mark description. Overall, it was found that the trademark word embeddings with RCNN model outperformed other models. Our study thereby seeks to provide a solution towards the time intensive and laborious process of identifying design codes of the trademarks.
BN 978-1-5386-6805-4
PY 2018
BP 61
EP 65
DI 10.1109/ICMLA.2018.00017
UT WOS:000463034400009
ER

PT J
AU Shi, ZL
   Ye, YD
   Wu, YP
AF Shi, Zenglin
   Ye, Yangdong
   Wu, Yunpeng
TI Rank-based pooling for deep convolutional neural networks
SO NEURAL NETWORKS
AB Pooling is a key mechanism in deep convolutional neural networks (CNNs) which helps to achieve translation invariance. Numerous studies, both empirically and theoretically, show that pooling consistently boosts the performance of the CNNs. The conventional pooling methods are operated on activation values. In this work, we alternatively propose rank-based pooling. It is derived from the observations that ranking list is invariant under changes of activation values in a pooling region, and thus rank-based pooling operation may achieve more robust performance. In addition, the reasonable usage of rank can avoid the scale problems encountered by value-based methods. The novel pooling mechanism can be regarded as an instance of weighted pooling where a weighted sum of activations is used to generate the pooling output. This pooling mechanism can also be realized as rank-based average pooling (RAP), rank-based weighted pooling (RWP) and rank-based stochastic pooling (RSP) according to different weighting strategies. As another major contribution, we present a novel criterion to analyze the discriminant ability of various pooling methods, which is heavily under-researched in machine learning and computer vision community. Experimental results on several image benchmarks show that rank-based pooling outperforms the existing pooling methods in classification performance. We further demonstrate better performance on CIFAR datasets by integrating RSP into Network-in-Network. (C) 2016 Elsevier Ltd. All rights reserved.
OI Wu, Yunpeng/0000-0002-0648-868X
SN 0893-6080
EI 1879-2782
PD NOV
PY 2016
VL 83
BP 21
EP 31
DI 10.1016/j.neunet.2016.07.003
UT WOS:000386320300003
PM 27543927
ER

PT C
AU Ray, A
   Shah, A
   Chaudhury, S
AF Ray, Anupama
   Shah, Archit
   Chaudhury, Santanu
GP IEEE
TI Recognition based Text Localization from Natural Scene Images
SO 2016 23RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
CT 23rd International Conference on Pattern Recognition (ICPR)
CY DEC 04-08, 2016
CL Mexican Assoc Comp Vis Robot & Neural Comp, Cancun, MEXICO
SP Int Assoc Pattern Recognit, Int Conf Pattern Recognit, Org Comm, Elsevier, IBM Res, INTEL, CONACYT
HO Mexican Assoc Comp Vis Robot & Neural Comp
AB With the rapid increase of multimedia data, textual content in an image has become a very important source of information for several applications like navigation, image search and retrieval, image understanding, captioning, machine translation and several others. Scene text localization is the first step towards such applications and most current methods focus on generating a small set of high precision detectors rather than obtaining large set of detections covering all text patches. In this work we propose a novel hybrid framework for text localization which uses character level recognition recursively in a feedback mechanism to refine text patches and reduce false positives. We use popular MSER algorithm at multiple scales as an initial region proposal algorithm and several filtering stages recursively to improve precision as well as maximize recall. We aim at achieving high recall rather than achieving higher precision since several robust word recognition systems are already available. The word recognition systems are mature enough to produce highly accurate results if provided with maximum amount of regions rather than providing small set of highly precise text patches and losing several other text regions. The main contribution of this paper is the use of character recognizer within a novel feedback mechanism to recursively search for text regions in the neighborhood of previously detected text patches. Using 3 publicly available benchmark datasets (ICDAR2011, MSRA TD-500 and OSTD), we demonstrate the efficacy of the proposed framework for text localization.
OI Ray, Anupama/0000-0002-9193-5017
SN 1051-4651
BN 978-1-5090-4847-2
PY 2016
BP 1177
EP 1182
UT WOS:000406771301031
ER

PT J
AU Casal, N
   Bates, P
   Bede, O
   Damiani, C
   Dubus, G
   Omran, H
   Palmer, J
   Puiu, A
   Reichle, R
   Suarez, A
   Walker, C
   Walsh, M
AF Casal, Natalia
   Bates, Philip
   Bede, Otto
   Damiani, Carlo
   Dubus, Gregory
   Omran, Hassan
   Palmer, Jim
   Puiu, Adrian
   Reichle, Roger
   Suarez, Alejandro
   Walker, Christopher
   Walsh, Michael
TI Engineering analysis of ITER In-Vessel Viewing System guide tube
SO FUSION ENGINEERING AND DESIGN
CT 28th Symposium on Fusion Technology (SOFT)
CY SEP 29-OCT 03, 2014
CL San Sebastian, SPAIN
SP Spanish Res Ctr Energy Environm & Technol, CIEMAT
AB The In Vessel Viewing System (IVVS) will be one of the essential machine diagnostic systems at ITER to provide information about the status of in-vessel and plasma facing components and to evaluate the dust inside the Vacuum Vessel. The current design consists of six scanning probes and their deployment systems, which are placed in dedicated ports at the divertor level. These units are located in resident guiding tubes 10 m long, which allow the IVVS probes to go from their storage location to the scanning position by means of a simple straight translation. Moreover, each resident tube is supported inside the corresponding Vacuum Vessel and Cryostat port extensions, which are part of the primary confinement barrier. As the Vacuum Vessel and the Cryostat will move with respect to each other during operation (especially during baking) and during incidents and accidents (disruptions, vertical displacement events, seismic events), the structural integrity of the resident tube and the surrounding vacuum boundaries would be compromised if the required flexibility and supports are not appropriately assured. This paper focuses on the integration of the present design of the IVVS into the Vacuum Vessel and Cryostat environment. It presents the adopted strategy to withstand all the main interfacing loads without damaging the confinement barriers and the corresponding analysis supporting it. (C) 2015 Elsevier B.V. All rights reserved.
SN 0920-3796
EI 1873-7196
PD OCT
PY 2015
VL 96-97
BP 742
EP 745
DI 10.1016/j.fusengdes.2015.06.070
PN A
UT WOS:000364255900150
ER

PT J
AU Li, JL
   Zhang, DW
AF Li, JunLan
   Zhang, DaWei
TI Camera calibration with a near-parallel imaging system based on
   geometric moments
SO OPTICAL ENGINEERING
AB This paper presents a novel approach of camera calibration under the near-parallel condition based on geometric moments. The near-parallel condition means that the calibration board is near parallel (or parallel) to the imaging plane. A camera calibration model for the near-parallel condition and a calibration board with arranged rectangular features are suggested. Before calibration, feature regions on the image of calibration board are extracted, and centroid and rotation of each feature are detected using geometric moments. These centroids are used for feature points, and meanwhile mean value of rotations is used for the rotation around axis Z. Then, the closed-form solutions to the translations, other two angles and effective focal length are provided by combining Gauss lens model with camera model. Subsequently, principal point is received by radial alignment constraint (RAC), and distortion coefficients are calculated. Finally, all camera parameters are refined by a nonlinear minimization procedure according to the distortion coefficients. Simulations and experiments are performed to verify the proposed camera calibration algorithm. The precision of detecting feature points and calibrating camera parameters are analyzed. The precision of camera calibration results is also evaluated. (c) 2011 Society of Photo-Optical Instrumentation Engineers (SPIE). [DOI: 10.1117/1.3533032]
RI Li, Junlan/M-5859-2015
OI Li, Junlan/0000-0001-9025-7616
SN 0091-3286
PD FEB
PY 2011
VL 50
IS 2
AR 023601
DI 10.1117/1.3533032
UT WOS:000287864600009
ER

PT C
AU Andres, J
   Gracia, L
   Marti, H
   Tornero, J
AF Andres, Javier
   Gracia, Luis
   Marti, Hector
   Tornero, Josep
GP IEEE
TI TOOLPATH POSTPROCESSING FOR THREE AXES MILLING IN REDUNDANT ROBOTIC
   WORKCELLS BY MEANS OF FUZZY INTEGRATION IN A CAM PLATFORM
SO 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS, VOLS 1 AND 2
CT IEEE International Conference on Mechatronics (ICM 2009)
CY APR 14-17, 2009
CL Malaga, SPAIN
SP IEEE
AB Nowadays, the use of kinematically redundant robotic workcells for machining tasks is increasing. It is due to their capacity to avoid singular configurations, although a choice among a set of possible configurations is required. Experience and knowledge of the workman in charge of the manufacturing process allow carrying out an efficient control of the movement in these cases. However, it is a tedious job.
   This article presents an effective implementation of a CAM-Robotics integrated fuzzy postprocessor based on the position analysis. It is focused on a workcell consisting of one robotic manipulator (KUKA KR15/2 with 6 rotary joints) mounted on a linear axis and synchronized with a rotary table. After the implementation of the inverse kinematics position analysis, a stand-alone fuzzy controller has been programmed with Matlab's Fuzzy Logic Toolbox (The MathWorks, Inc.). Two C++ programs complement the translation of toolpath position information from the NX-CAM platform (NX (TM)-Siemens Corp.) into KRL (KUKA Robot Language), in order to adequate the location of the robot and the workpiece in the execution of the task and avoiding singularities or joint limits. This article solves the problem for a constant tool orientation milling process and sets the technological basis for future research at five axis milling operations.
RI Andres-Esperanza, Javier/AAB-6657-2020
OI Andres-Esperanza, Javier/0000-0001-9298-5393
BN 978-1-4244-4194-5
PY 2009
BP 462
EP +
UT WOS:000273269400079
ER

PT J
AU Morita, T
   Maki, K
   Aiba, H
AF Morita, T
   Maki, K
   Aiba, H
TI RNase E-based ribonucleoprotein complexes: mechanical basis of mRNA
   destabilization mediated by bacterial noncoding RNAs
SO GENES & DEVELOPMENT
AB Hfq-binding antisense small RNAs of Escherichia coli, SgrS and RyhB, mediate the destabilization of target mRNAs in an RNase E-dependent manner. SgrS, whose expression is induced in response to phosphosugar stress, act on the ptsG mRNA encoding a major glucose transporter, while RyhB, whose expression is induced in response to Fe depletion, acts on several mRNAs encoding Fe-binding proteins. In this report, we addressed the question of how SgrS and RyhB RNAs cooperate with RNase E to destabilize the target mRNAs. We demonstrate that Hfq along with SgrS and RyhB copurified with RNase E but not with truncated RNase E. In addition, we show that RNase E but not other degradosome components copurified with Hfq. Taken together, we conclude that RNase E forms variable ribonucleoprotein complexes with Hfq/small RNAs through its C-terminal scaffold region. These complexes, distinct from the RNA degradosome, may act as specialized RNA decay machines that initiate the degradation of mRNAs targeted by each small RNA. The present finding has uncovered the mechanical basis of mRNA destabilization mediated by bacterial small RNAs. The formation of ribonucleoprotein complexes containing RNases could be a general way by which small RNAs destabilize target mRNAs in both prokaryotes and eukaryotes.
RI Morita, Teppei/HRC-8822-2023
SN 0890-9369
EI 1549-5477
PD SEP 15
PY 2005
VL 19
IS 18
BP 2176
EP 2186
DI 10.1101/gad.1330405
UT WOS:000231929100009
PM 16166379
ER

PT C
AU Alemu, A
   Asker, L
AF Alemu, A
   Asker, L
BE Callaos, N
   Margenstern, M
   Zhang, J
   Castillo, O
   Doberkat, EE
TI Natural language processing with few computational linguistic resources:
   An experiment with automatic sentence parsing for amharic texts
SO 7TH WORLD MULTICONFERENCE ON SYSTEMICS, CYBERNETICS AND INFORMATICS, VOL
   V, PROCEEDINGS: COMPUTER SCIENCE AND ENGINEERING: I
CT 7th World Multiconference on Systemics, Cybernetics and Informatics
CY JUL 27-30, 2003
CL ORLANDO, FL
SP Int Inst Informat & System
AB The amount of work required to start from scratch in developing all aspects of natural language processing for a new language is huge. At the same time there is an urgent need for a variety of applications including local language spell-checkers, word processors, machine translation systems, search engines, etc. For these applications to be developed, the existence of computerized language resources and a well developed framework for research in this area is essential. Tree-banks, Part-of-speech taggers, computerized grammars, lexica, and parsers are all necessary parts of this framework. The study reported in this article describes an attempt to design and implement a prototype of an automatic sentence parser for Amharic text. Amharic is the official government language of Ethiopia and a language for which very few computational linguistic resources exist. To automatically parse sentences, the study used the Inside Outside algorithm with a bottom up chart parsing strategy. The probabilistic context free grammar was used as a grammatical formalism to represent the phrase structure rules of the language. A small sample corpus of 100 four-word sentences was selected from sentences in the language, and has been used to serve as a training and test set. In spite of the limited amount of data and other resources available, the experiments show some promising results.
BN 980-6560-01-9
PY 2003
BP 51
EP 56
UT WOS:000189330600010
ER

PT J
AU Xiang, L
   Zhu, JN
   Zhao, Y
   Zhou, Y
   Zong, CQ
AF Xiang, Lu
   Zhu, Junnan
   Zhao, Yang
   Zhou, Yu
   Zong, Chengqing
TI Robust Cross-lingual Task-oriented Dialogue
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB Cross-lingual dialogue systems are increasingly important in e-commerce and customer service due to the rapid progress of globalization. In real-world system deployment, machine translation (MT) services are often used before and after the dialogue system to bridge different languages. However, noises and errors introduced in the MT process will result in the dialogue system's low robustness, making the system's performance far from satisfactory. In this article, we propose a novel MT-oriented noise enhanced framework that exploits multi-granularityMTnoises and injects such noises into the dialogue system to improve the dialogue system's robustness. Specifically, we first design a method to automatically construct multi-granularity MT-oriented noises and multi-granularity adversarial examples, which contain abundant noise knowledge oriented to MT. Then, we propose two strategies to incorporate the noise knowledge: (i) Utterance-level adversarial learning and (ii) Knowledge-level guided method. The former adopts adversarial learning to learn a perturbation-invariant encoder, guiding the dialogue system to learn noise-independent hidden representations. The latter explicitly incorporates the multi-granularity noises, which contain the noise tokens and their possible correct forms, into the training and inference process, thus improving the dialogue system's robustness. Experimental results on three dialoguemodels, two dialogue datasets, and two language pairs have shown that the proposed framework significantly improves the performance of the cross-lingual dialogue system.
OI Zong, Chengqing/0000-0002-9864-3818
SN 2375-4699
EI 2375-4702
PD NOV
PY 2021
VL 20
IS 6
AR 93
DI 10.1145/3457571
UT WOS:000721586800002
ER

PT J
AU Yamamoto, S
   Suzuki, R
   Fukusato, T
   Kataoka, H
   Morishima, S
AF Yamamoto, Shintaro
   Suzuki, Ryota
   Fukusato, Tsukasa
   Kataoka, Hirokatsu
   Morishima, Shigeo
TI A Case Study on User Evaluation of Scientific Publication Summarization
   by Japanese Students
SO APPLIED SCIENCES-BASEL
AB Summaries of scientific publications enable readers to gain an overview of a large number of studies, but users' preferences have not yet been explored. In this paper, we conduct two user studies (i.e., short- and long-term studies) where Japanese university students read summaries of English research articles that were either manually written or automatically generated using text summarization and/or machine translation. In the short-term experiment, subjects compared and evaluated the two types of summaries of the same article. We analyze the characteristics in the generated summaries that readers regard as important, such as content richness and simplicity. The experimental results show that subjects are mainly judged based on four criteria, including content richness, simplicity, fluency, and format. In the long-term experiment, subjects read 50 summaries and answered whether they would like to read the original papers after reading the summaries. We discuss the characteristics in the summaries that readers tend to use to determine whether to read the papers, such as topic, methods, and results. The comments from subjects indicate that specific components of scientific publications, including research topics and methods, are important to judge whether to read or not. Our study provides insights to enhance the effectiveness of automatic summarization of scientific publications.
RI Yamamoto, Shintaro/AAS-1350-2020; Kataoka, Hirokatsu/M-4282-2016
OI Kataoka, Hirokatsu/0000-0001-8844-165X
EI 2076-3417
PD JUL
PY 2021
VL 11
IS 14
AR 6287
DI 10.3390/app11146287
UT WOS:000678174300001
ER

PT J
AU Du, ZH
   Xiao, XD
   Uversky, VN
AF Du, Zhihua
   Xiao, Xiangdong
   Uversky, Vladimir N.
TI DeepA-RBPBS: A hybrid convolution and recurrent neural network combined
   with attention mechanism for predicting RBP binding site
SO JOURNAL OF BIOMOLECULAR STRUCTURE & DYNAMICS
AB It's important to infer the binding site of RNA-binding proteins (RBP) for understanding the interaction between RBP and its RNA targets and decipher the mechanisms of transcriptional regulation. However, experimental detection of RBP binding sites is still time-intensive and expensive. Algorithms based on machine learning can speed up detection of RBP binding sites. In this article, we propose a new deep learning method, DeepA-RBPBS, which can use RNA sequences and structural features to predict RBP binding site. DeepA-RBPBS uses CNN and BiGRU to extract sequences and structural features without long-term dependence issues. It also utilizes an attention mechanism to enhance the contribution of key features. The comparison shows that the performance of DeepA-RBPBS is better than that of the state-of-the-art predictors. In the testing on 31 datasets of CLIP-seq experiments over 19 proteins, MCC (AUC) is 8% (5%) higher than those of the latest method based on deep learning, iDeepS. We also apply DeepA-RBPBS to the target RNA data of RBPs related to diabetes (LIN28, RBFOX2, FTO, IGF2BP2, CELF1 and HuR). The results show that DeepA-RBPBS correctly predicted 41,693 samples, where iDeepS predicted 31,381 samples.
   Communicated by Ramaswamy H. Sarma
RI Uversky, Vladimir N./F-4515-2011
OI Uversky, Vladimir N./0000-0002-4037-5857
SN 0739-1102
EI 1538-0254
PD MAY 23
PY 2022
VL 40
IS 9
BP 4250
EP 4258
DI 10.1080/07391102.2020.1854861
EA NOV 2020
UT WOS:000596190000001
PM 33272122
ER

PT C
AU Rippel, O
   Nair, S
   Lew, C
   Branson, S
   Anderson, AG
   Bourdev, L
AF Rippel, Oren
   Nair, Sanjay
   Lew, Carissa
   Branson, Steve
   Anderson, Alexander G.
   Bourdev, Lubomir
GP IEEE
TI Learned Video Compression
SO 2019 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2019)
SE IEEE International Conference on Computer Vision
CT IEEE/CVF International Conference on Computer Vision (ICCV)
CY OCT 27-NOV 02, 2019
CL Seoul, SOUTH KOREA
SP IEEE, IEEE Comp Soc, CVF
AB We present a new algorithm for video coding, learned end-to-end for the low-latency mode. In this setting, our approach outperforms all existing video codecs across nearly the entire bitrate range. To our knowledge, this is the first ML-based method to do so.
   We evaluate our approach on standard video compression test sets of varying resolutions, and benchmark against all mainstream commercial codecs in the low-latency mode. On standard-definition videos, HEVC/H.265, AVC/H.264 and VP9 typically produce codes up to 60% larger than our algorithm. On high-definition 1080p videos, H.265 and VP9 typically produce codes up to 20% larger, and H.264 up to 35% larger. Furthermore, our approach does not suffer from blocking artifacts and pixelation, and thus produces videos that are more visually pleasing.
   We propose two main contributions. The first is a novel architecture for video compression, which (1) generalizes motion estimation to perform any learned compensation beyond simple translations, (2) rather than strictly relying on previously transmitted reference frames, maintains a state of arbitrary information learned by the model, and (3) enables jointly compressing all transmitted signals (such as optical flow and residual).
   Secondly, we present a framework for ML-based spatial rate control-a mechanism for assigning variable bitrates across space for each frame. This is a critical component for video coding, which to our knowledge had not been developed within a machine learning setting.
SN 1550-5499
BN 978-1-7281-4803-8
PY 2019
BP 3453
EP 3462
DI 10.1109/ICCV.2019.00355
UT WOS:000531438103061
ER

PT C
AU Alasfour, AAA
   Trausan-Matu, S
AF Alasfour, Abdel Alnasser A.
   Trausan-Matu, Stefan
BE Petre, E
   Brezovan, M
TI Developing an Arabic Corpus for Event Mining
SO 2013 17TH INTERNATIONAL CONFERENCE ON SYSTEM THEORY, CONTROL AND
   COMPUTING (ICSTCC)
CT 17th International Conference System Theory, Control and Computing
   (ICSTCC)
CY OCT 11-13, 2013
CL Sinaia, ROMANIA
SP IEEE, IEEE Control Syst Soc, Fac Automatica, Calculatoare Electronica, Fac Automatica Calculatoare, Fac ACIEE Galati, NETROM Romania, SINTEC MEDIA Romania, Ubisoft Romania, DOLSAT Consult, Polisea Romania, Top Edge Engn Romania, SMC Romania, Univ Craiova, Fac Automat, Comp & Elect, Automat Control Res Ctr
AB Recently, Arabic Natural Language Processing (A-NLP) is beginning to gain more interest. Corpora in general, have become a dependable resource for Language Engineering including Information Retrieval, Machine Translation and other Natural Language-related disciplines. As a result, many Arabic corpora have been developed and most of them are available online for linguistics' researchers. For example, the Agence France-Press (AFP) corpus is an Arabic newswire developed by the Linguistic Data Consortium (LDC) [1,8] and the Quranic Arabic corpus organized by the University of Leeds [5]. For any objective research in NLP, there must be a corpus covering most of the language patterns in variant domains [21]. But, over the years, different new jargons have appeared within the Arabic speaking states. In this paper, a modern standard Arabic is used to avoid any region specific Arabic language patterns [1]. The Organization of Islamic Cooperation (OIC) is selected as a main data source. OIC is the second largest inter-governmental organization after the United Nations, comprising of 57 member states in four continents. Some data is also taken from International Islamic News Agency (IINA). IINA is the informational side of the OIC, working as an electronic newspaper, having electronic categorization of news documents. In future, this corpus will be a part of parallel corpus (Arabic - English). For that reason, we have selected sites with the ability of parallel multilingual document Arabic and English.
RI Trausan-Matu, Stefan/E-6411-2011
OI Trausan-Matu, Stefan/0000-0001-8082-8497
BN 978-1-4799-2228-4; 978-1-4799-2227-7
PY 2013
BP 21
EP 28
UT WOS:000330660500003
ER

PT J
AU Chakraborty, B
   Sha, RJ
   Seeman, NC
AF Chakraborty, Banani
   Sha, Ruojie
   Seeman, Nadrian C.
TI A DNA-based nanomechanical device with three robust states
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
AB DNA has been used to build a variety of devices, ranging from those that are controlled by DNA structural transitions to those that are controlled by the addition of specific DNA strands. These sequence-dependent devices fulfill the promise of DNA in nanotechnology because a variety of devices in the same physical environment can be controlled individually. Many such devices have been reported, but most of them contain one or two structurally robust end states, in addition to a floppy intermediate or even a floppy end state. We describe a system in which three different structurally robust end states can be obtained, all resulting from the addition of different set strands to a single floppy intermediate. This system is an extension of the PX-JX(2). DNA device. The three states are related to each other by three different motions, a twofold rotation, a translation of approximate to 2.1-2.5 nm, and a twofold screw rotation, which combines these two motions. We demonstrate the transitions by gel electrophoresis, by fluorescence resonance energy transfer, and by atomic force microscopy. The control of this system by DNA strands opens the door to trinary logic and to systems containing N devices that are able to attain 3(N) structural states.
SN 0027-8424
PD NOV 11
PY 2008
VL 105
IS 45
BP 17245
EP 17249
DI 10.1073/pnas.0707681105
UT WOS:000260981800016
PM 18474862
ER

PT J
AU Tu, JL
   Tao, H
   Huang, T
AF Tu, Jilin
   Tao, Hai
   Huang, Thomas
TI Face as mouse through visual face tracking
SO COMPUTER VISION AND IMAGE UNDERSTANDING
AB This paper introduces a novel camera mouse driven by visual face tracking based on a 3D model. As the camera becomes standard configuration for personal computers (PCs) and computation speed increases, achieving human-machine interaction through visual face tracking becomes a feasible solution to hands-free control. Human facial movements can be broken down into rigid motions, such as rotation and translation, and non-rigid motions such as opening, closing, and stretching of the mouth. First, we describe our face tracking system which can robustly and accurately retrieve these motion parameters from videos in real time [H. Tao, T. Huang, Explanation-based facial motion tracking using a piecewise Bezier volume deformation model, in: Proceedings of IEEE Computer Vision and Pattern Recogintion, vol. 1, 1999, pp. 611-617]. The retrieved (rigid) motion parameters can be employed to navigate the mouse cursor; the detection of mouth (non-rigid) motions triggers mouse events in the operating system. Three mouse control modes are investigated and their usability is compared. Experiments in the Windows XP environment verify the convenience of our camera mouse in hands-free control. This technology can be an alternative input option for people with hand and speech disability, as well as for futuristic vision-based games and interfaces. (C) 2007 Elsevier Inc. All rights reserved.
RI yan, shuicheng/A-8531-2014
OI yan, shuicheng/0000-0001-8906-3777
SN 1077-3142
EI 1090-235X
PD OCT-NOV
PY 2007
VL 108
IS 1-2
BP 35
EP 40
DI 10.1016/j.cviu.2006.11.007
UT WOS:000250033600004
ER

PT J
AU Klopries, H
   Schwung, A
AF Klopries, Hendrik
   Schwung, Andreas
TI Extracting interpretable features for time series analysis: A
   Bag-of-Functions approach
SO EXPERT SYSTEMS WITH APPLICATIONS
AB In this work we consider the problem of analyzing and predicting time series data using a Bag-of-Functions approach by a self supervised autoencoder. Particularly, by means of deep neural networks, we define a latent space of multivariate time series data as the parameterization for a bag of multivariate functions. Specifically, the latent space encoding represents a set of parameters for the bag of functions as well as a top-k distribution that selects the functions most likely to represent the data sequence. The approach bears some intended similarities to well known approaches from natural language processing and machine translation where first a sparse representation of words is learned and second these sparse representations are stored in a bag-of-words or embeddings. To underline the performance and its fast capability of adaption, we first perform a pretraining task on synthetic data. Afterwards we use transfer learning to apply the network on the M4 benchmark dataset and gain suitable reconstructions on certain forecasters over multiple horizons without any significant loss of performance. Tests on a new energy supply dataset show interesting results in terms of unsupervised time series analysis and decomposition, while the trajectories always remain fully interpretable. In all cases the approach learns its own way of decomposing and describing time series and easily adapts to very different courses.
SN 0957-4174
EI 1873-6793
PD JUL 1
PY 2023
VL 221
AR 119787
DI 10.1016/j.eswa.2023.119787
EA MAR 2023
UT WOS:000954929200001
ER

PT J
AU Dimou, AL
   Papavassiliou, V
   Goulas, T
   Vasilaki, K
   Vacalopoulou, A
   Fotinea, SE
   Efthimiou, E
AF Dimou, Athanasia-Lida
   Papavassiliou, Vassilis
   Goulas, Theodoros
   Vasilaki, Kyriaki
   Vacalopoulou, Anna
   Fotinea, Stavroula-Evita
   Efthimiou, Eleni
TI What about synthetic signing? A methodology for signer involvement in
   the development of avatar technology with generative capacity
SO FRONTIERS IN COMMUNICATION
AB Although signing avatar technology seems to be the only option currently available to serve sign language (SL) display in the context of applications which demand generative capacity from the part of the technology like in machine translation to SL, signing avatars have not yet been accepted by signers' communities. One major factor for this rejection is the feeling that technology is developed without the involvement of its actual users. Aiming to invite the signers' community into the process of signing avatar development, we have designed the shell methodological framework for signer-informed technology which is implemented as on-line surveys addressed to signer communities of different SLs. The surveys are communicated via focused on-line questionnaires with content of signing avatar performance that allows rating of various aspects of the produced SL synthetic signing by human signers. Here we report on the first survey application with content from the Greek Sign Language (GSL). The analysis of the obtained results is 2-fold: it highlights the significance of signer involvement and the provided feedback in the technological development of synthetic signing; in parallel it reveals those aspects of the survey setup that need fine-tuning before its next distribution cycles. The implementation of the first on-line survey can be found in: .
OI Efthimiou, Eleni/0000-0003-4253-5612; /0000-0002-3045-7461;
   Vacalopoulou, Anna/0000-0002-1509-2951
EI 2297-900X
PD AUG 1
PY 2022
VL 7
AR 798644
DI 10.3389/fcomm.2022.798644
UT WOS:000840948800001
ER

PT J
AU Meng, FQ
   Zheng, YJ
   Bao, SB
   Wang, JD
   Yang, SS
AF Meng, Fanqi
   Zheng, Yujie
   Bao, Songbin
   Wang, Jingdong
   Yang, Shuaisong
TI Formulaic language identification model based on GCN fusing associated
   information
SO PEERJ COMPUTER SCIENCE
AB Formulaic language is a general term for ready-made structures in a language. It usually has fixed grammatical structure, stable language expression meaning and specific use context. The use of formulaic language can coordinate sentence generation in the process of writing and communication, and can significantly improve the idiomaticity and logic of machine translation, intelligent question answering and so on. New formulaic language is generated almost every day, and how to accurately identify them is a topic worthy of research. To this end, this article proposes a formulaic language identification model based on GCN fusing associated information. The innovation is that each sentence is constructed into a graph in which the nodes are part-of-speech features and semantic features of the words in the sentence and the edges between nodes are constructed according to mutual information and dependency syntactic relation. On this basis, the graph convolutional neural network is adopted to extract the associated information between words to mine deeper grammatical features. Therefore, it can improve the accuracy of formulaic language identification. The experimental results show that the model in this article is superior to the classical formulaic language identification model in terms of accuracy, recall and F1-score. It lays a foundation for the follow-up research of formulaic language identification tasks.
RI Meng, Fanqi/GLU-4878-2022
OI Meng, Fanqi/0000-0002-5699-592X
EI 2376-5992
PD JUN 3
PY 2022
VL 8
AR e984
DI 10.7717/peerj-cs.984
UT WOS:000812999600001
PM 35721417
ER

PT J
AU Shifat-E-Rabbi, M
   Yin, XW
   Rubaiyat, AM
   Li, SY
   Kolouri, S
   Aldroubi, A
   Nichols, JM
   Rohde, GK
AF Shifat-E-Rabbi, Mohammad
   Yin, Xuwang
   Rubaiyat, Abu Hasnat Mohammad
   Li, Shiying
   Kolouri, Soheil
   Aldroubi, Akram
   Nichols, Jonathan M.
   Rohde, Gustavo K.
TI Radon Cumulative Distribution Transform Subspace Modeling for Image
   Classification
SO JOURNAL OF MATHEMATICAL IMAGING AND VISION
AB We present a new supervised image classification method applicable to a broad class of image deformation models. The method makes use of the previously described Radon Cumulative Distribution Transform (R-CDT) for image data, whose mathematical properties are exploited to express the image data in a form that is more suitable for machine learning. While certain operations such as translation, scaling, and higher-order transformations are challenging to model in native image space, we show the R-CDT can capture some of these variations and thus render the associated image classification problems easier to solve. The method-utilizing a nearest-subspace algorithm in the R-CDT space-is simple to implement, non-iterative, has no hyper-parameters to tune, is computationally efficient, label efficient, and provides competitive accuracies to state-of-the-art neural networks for many types of classification problems. In addition to the test accuracy performances, we show improvements (with respect to neural network-based methods) in terms of computational efficiency (it can be implemented without the use of GPUs), number of training samples needed for training, as well as out-of-distribution generalization. The Python code for reproducing our results is available at Shifat-E-Rabbi et al. (Python code implementing the Radon cumulative distribution transform subspace model for image classification. https://github.com/rohdelab/rcdt_ns_classifier).
OI Li, Shiying/0000-0001-6988-8229; Rabbi, Mohammad Shifat
   E/0000-0002-0972-5353
SN 0924-9907
EI 1573-7683
PD NOV
PY 2021
VL 63
IS 9
BP 1185
EP 1203
DI 10.1007/s10851-021-01052-0
EA AUG 2021
UT WOS:000681569600001
PM 35464640
ER

PT J
AU Sheikh, UA
   Carreiras, M
   Soto, D
AF Sheikh, Usman Ayub
   Carreiras, Manuel
   Soto, David
TI Neurocognitive mechanisms supporting the generalization of concepts
   across languages
SO NEUROPSYCHOLOGIA
AB The neurocognitive mechanisms that support the generalization of semantic representations across different languages remain to be determined. Current psycholinguistic models propose that semantic representations are likely to overlap across languages, although there is evidence also to the contrary. Neuroimaging studies observed that brain activity patterns associated with the meaning of words may be similar across languages. However, the factors that mediate cross-language generalization of semantic representations are not known. We here identify a key factor: the depth of processing. Human participants were asked to process visual words as they underwent functional MRI. We found that, during shallow processing, multivariate pattern classifiers could decode the word semantic category within each language in putative substrates of the semantic network, but there was no evidence of cross-language generalization in the shallow processing context. By contrast, when the depth of processing was higher, significant cross-language generalization was observed in several regions, including inferior parietal, ventromedial, lateral temporal, and inferior frontal cortex. These results are in keeping with distributed-only views of semantic processing and favour models based on multiple semantic hubs. The results also have ramifications for existing psycholinguistic models of word processing such as the BIA+, which by default assumes non-selective access to both native and second languages.
RI Carreiras, Manuel/D-5267-2009
OI Carreiras, Manuel/0000-0001-6726-7613; Sheikh, Usman
   Ayub/0000-0002-0259-4725
SN 0028-3932
EI 1873-3514
PD MAR 12
PY 2021
VL 153
AR 107740
DI 10.1016/j.neuropsychologia.2020.107740
EA FEB 2021
UT WOS:000621714000005
PM 33388337
ER

PT J
AU Bilalovic, O
   Avdagic, Z
   Omanovic, S
   Besic, I
   Letic, V
   Tatout, C
AF Bilalovic, Omar
   Avdagic, Zikrija
   Omanovic, Samir
   Besic, Ingmar
   Letic, Vedad
   Tatout, Christophe
TI Mathematical Modelling of Ground Truth Image for 3D Microscopic Objects
   Using Cascade of Convolutional Neural Networks Optimized with
   Parameters' Combinations Generators
SO SYMMETRY-BASEL
AB Mathematical modelling to compute ground truth from 3D images is an area of research that can strongly benefit from machine learning methods. Deep neural networks (DNNs) are state-of-the-art methods design for solving these kinds of difficulties. Convolutional neural networks (CNNs), as one class of DNNs, can overcome special requirements of quantitative analysis especially when image segmentation is needed. This article presents a system that uses a cascade of CNNs with symmetric blocks of layers in chain, dedicated to 3D image segmentation from microscopic images of 3D nuclei. The system is designed through eight experiments that differ in following aspects: number of training slices and 3D samples for training, usage of pre-trained CNNs and number of slices and 3D samples for validation. CNNs parameters are optimized using linear, brute force, and random combinatorics, followed by voter and median operations. Data augmentation techniques such as reflection, translation and rotation are used in order to produce sufficient training set for CNNs. Optimal CNN parameters are reached by defining 11 standard and two proposed metrics. Finally, benchmarking demonstrates that CNNs improve segmentation accuracy, reliability and increased annotation accuracy, confirming the relevance of CNNs to generate high-throughput mathematical ground truth 3D images.
RI AVDAGIC, ZIKRIJA/AAE-6180-2020; Omanovic, Samir/F-9084-2012; Letic,
   Vedad/HMP-2259-2023; Besic, Ingmar/V-2306-2019
OI AVDAGIC, ZIKRIJA/0000-0002-0933-2699; Omanovic,
   Samir/0000-0003-1161-7180; Besic, Ingmar/0000-0003-1632-570X
EI 2073-8994
PD MAR
PY 2020
VL 12
IS 3
AR 416
DI 10.3390/sym12030416
UT WOS:000525824300091
ER

PT J
AU Yuan, SQ
   Zhong, L
   Li, L
AF Yuan, Shengqiong
   Zhong, Luo
   Li, Lin
TI Image inspired Chinese couplet generation
SO WEB INTELLIGENCE
AB Chinese couplets, as one of the traditional Chinese culture, is the treasure of Chinese civilization and the inheritance of Chinese history. Given a sentence (namely an antecedent clause), people reply with another sentence (namely a subsequent clause) equal in length. Because of the complexity of the semantic and grammatical rules of couplet, it is not easy to create a suitable couplet that meets the requirements of sentence pattern, context, and flatness. With the development of neural models and natural language processing, automatic generation of Chinese couplets has drawn significant attention due to its artistic and cultural value, most of these works mainly focus on generating couplet by given text information, while visual inspirations for couplet generation have been rarely explored. In this paper, we design a Chinese couplet generation model based on NIC (Neural Image Caption), which can compose a piece of couplet suitable to the artistic conception in an image. At first, we use the improved VGG16 model to predict the input image. The content of the image can be automatically recognized and the corresponding description are generated and translated into Chinese keywords. Then, the encoder-decoder framework is used repeatedly to process these keywords, and finally the couplet can be generated. Moreover, to satisfy special characteristics of couplets, we incorporate the attention mechanism into the encoding-decoding process, which greatly improves the accuracy of couplets generated automatically.
RI li, li/HII-4157-2022; Li, Li/AEM-3636-2022
SN 2405-6456
EI 2405-6464
PY 2020
VL 18
IS 3
BP 217
EP 227
DI 10.3233/WEB-200443
UT WOS:000579090600005
ER

PT J
AU Rastegar-Mojarad, M
   Elayavilli, RK
   Liu, HF
AF Rastegar-Mojarad, Majid
   Elayavilli, Ravikumar Komandur
   Liu, Hongfang
TI BELTracker: evidence sentence retrieval for BEL statements
SO DATABASE-THE JOURNAL OF BIOLOGICAL DATABASES AND CURATION
AB Biological expression language (BEL) is one of the main formal representation models of biological networks. The primary source of information for curating biological networks in BEL representation has been literature. It remains a challenge to identify relevant articles and the corresponding evidence statements for curating and validating BEL statements. In this paper, we describe BELTracker, a tool used to retrieve and rank evidence sentences from PubMed abstracts and full-text articles for a given BEL statement (per the 2015 task requirements of BioCreative V BEL Task). The system is comprised of three main components, (i) translation of a given BEL statement to an information retrieval (IR) query, (ii) retrieval of relevant PubMed citations and (iii) finding and ranking the evidence sentences in those citations. BELTracker uses a combination of multiple approaches based on traditional IR, machine learning, and heuristics to accomplish the task. The system identified and ranked at least one fully relevant evidence sentence in the top 10 retrieved sentences for 72 out of 97 BEL statements in the test set. BELTracker achieved a precision of 0.392, 0.532 and 0.615 when evaluated with three criteria, namely full, relaxed and context criteria, respectively, by the task organizers. Our team at Mayo Clinic was the only participant in this task. BELTracker is available as a RESTful API and is available for public use.
SN 1758-0463
PD MAY 12
PY 2016
AR baw079
DI 10.1093/database/baw079
UT WOS:000375777600002
PM 27173525
ER

PT C
AU De Baere, I
   Van Paepegem, W
   Lammens, N
   Lava, P
   Debruyne, D
   Cofaru, C
   Philips, W
   Degrieck, J
AF De Baere, I.
   Van Paepegem, W.
   Lammens, N.
   Lava, P.
   Debruyne, D.
   Cofaru, C.
   Philips, W.
   Degrieck, J.
BE Paipetis, AS
   Matikas, TE
   Aggelis, DG
   VanHemelrijck, D
TI Experimentally induced errors in Digital Image Correlation measurement
   of small strains with large gradients
SO EMERGING TECHNOLOGIES IN NON-DESTRUCTIVE TESTING V
CT 5th International Conference on Emerging Technologies in Non-Destructive
   Testing (NDT)
CY SEP 19-21, 2011
CL Ioannina, GREECE
SP Univ Ioannina, Dept Mat Sci & Engn
AB Digital Image Correlation or DIC is an already widespread and commonly used technique to perform full field strain measurements. Usually, a so called 'speckle pattern' is put on the specimen and then, pictures are taken first in the undeformed stage, which is the reference and then in various deformed states. The technique itself consists of comparing the image of a deformed pattern with a reference image and determining the displacements of the so called 'subsets'. The mathematical algorithm eliminates rigid rotations of the subset and is able to determine the strain field. This technique was originally designed for large-strain measurements and as such, it works very well when large strains are present, but when determining (very) small strain fields, especially in combination with large (rigid body) deformations or large strain gradients, this technique becomes a lot more sensitive to the boundary conditions of the experimental setup.
   This manuscript will illustrate the errors induced by experimental factors such as in-plane rotation, in-plane rigid body translation, out-of-plane rigid body rotation, which are in fact all related to how the specimen is gripped in the tensile machine, on the eventual derived strain field. Furthermore, processing parameters such as subset and step size and the used strain window on numerically and experimentally induced transformations will be assessed.
RI VAN PAEPEGEM, Wim/A-1822-2008
OI VAN PAEPEGEM, Wim/0000-0003-0672-3675; Lammens,
   Nicolas/0000-0002-7866-6158
BN 978-0-415-62131-1
PY 2012
BP 441
EP 446
UT WOS:000327989800070
ER

PT S
AU Janga, SC
   Vallabhaneni, S
AF Janga, Sarath Chandra
   Vallabhaneni, Swathi
BE Collins, LJ
TI MicroRNAs AS POST-TRANSCRIPTIONAL MACHINES AND THEIR INTERPLAY WITH
   CELLULAR NETWORKS
SO RNA INFRASTRUCTURE AND NETWORKS
SE Advances in Experimental Medicine and Biology
AB Gene expression is a highly controlled process which is known to occur at several levels in eukaryotic organisms. Although RNAs have been traditionally viewed as passive molecules in the pathway from transcription to translation, there is increasing evidence that their metabolism is controlled by a class of small noncoding RNAs called MicroRNAs (miRNAs). MicroRNAs (miRNAs) control essential gene regulatory pathways in both plants and animals however our understanding about their function, evolution and interplay with other cellular components is only beginning to be elucidated. In this chapter, we provide an overview of the recent developments in our understanding of this class of RNAs from diverse perspectives including biogenesis, mechanism of their function, evolution of their clusters, and discuss the approaches currently available for the construction of post-transcriptional networks governed by them. We also present our current understanding on these post-transcriptional networks in the context other cellular networks. We finally argue that such developments would not only allow us to gain a deeper understanding of regulation at a level that has been under-appreciated over the past decades, but would also allow us to use the newly developed high-throughput approaches to interrogate the prevalence of these phenomena in different states, and thereby exploit the functions of these RNA molecules for therapeutic advantage in higher eukaryotes.
OI Janga, Sarath Chandra/0000-0001-7351-6268
SN 0065-2598
EI 2214-8019
BN 978-1-4614-0331-9
PY 2011
VL 722
BP 59
EP 74
D2 10.1007/978-1-4614-0332-6
UT WOS:000293762900004
PM 21915782
ER

PT C
AU Gorman, M
   Healy, P
AF Gorman, Mel
   Healy, Patrick
GP ACM
TI Supporting Superpage Allocation Without Additional Hardware Support
SO ISMM'08: PROCEEDINGS OF THE 2008 INTERNATIONAL SYMPOSIUM ON MEMORY
   MANAGEMENT
CT International Symposium on Memory Management
CY JUN 07-08, 2008
CL Tucson, AZ
SP ACM SIGPLAN
AB Today, many modern processors support more than one page size. The larger pages, called superpages, have been identified as one means of reducing the time spent servicing translation lookaside buffer (TLB) misses in the early 1990s by increasing TLB reach. Widespread usage of superpages has been limited by the requirement that superpages consist of physically contiguous and naturally-aligned small pages. This makes external fragmentation it serious problem for an operating system, one that is almost nonexistent when processes use only one page size. Hardware solutions to mitigate this limitation such as sub-blocking, shadow page-tables and a variety of hybrid solutions have not seen wide-spread adoption. This has curtailed automatic superpage support as it is known that superpage availability will decrease during the system's lifetime as external fragmentation grows.
   This paper presents a placement policy for tin operating system's physical page allocator to mitigate external fragmentation problems by grouping pages based oil the system's ability to relocate the data. Secondly, the necessary changes to the page reclamation algorithm for it to be contiguity-aware are described while minimising impact to the reclamation algorithms' normal decisions. The performance impact on different machine types is illustrated and it is shown that the superpage allocation success rate is improved. These mechanisms are complementary to any of the hardware Solutions proposed in the past.
BN 978-1-60558-134-7
PY 2008
BP 41
EP 50
UT WOS:000266033900005
ER

PT J
AU Wiseman, H
AF Wiseman, Harris
TI THEORIA TO THEORY (AND BACK AGAIN): INTEGRATING MASTERMAN'S WRITINGS ON
   LANGUAGE AND RELIGION with Harris Wiseman and Fraser Watts, "Spiritual
   Intelligence: Participating with Heart, Mind and Body"; Harris Wiseman,
   "Knowing Slowly: Unfolding the Depths of Meaning"; Harris Wiseman, "The
   Japanese Arts and Meditation-in-Action"; Harris Wiseman, "Meaning and
   Embodiment in Ritual Practice"; and Harris Wiseman, "Theoria to Theory
   (and Back Again): Integrating Masterman's Writings on Language and
   Religion."
SO ZYGON
AB This article explores three aspects of Masterman's language work and applies them to questions of spiritual intelligence: metaphor, coherence, and ambiguity. First, metaphor, which is ubiquitous in ordinary language, both leads and misleads in religious and scientific understanding. Masterman's case for a "dual-approach" to thinking, both speculative and critical, is explored and tied to concepts of moral-spiritual development per Pierre Hadot and Hannah Arendt. Second, Masterman's work on machine translation presents semantic disambiguation as an emerging coherence wherein one gradually hones in on meaning through features of ordinary language (like redundancy and repetition). This is applied to the problem of comprehending difficult spiritual language, and tied to spiritual stretching and spiritual cartography. Third, Masterman's work with thesauri, rather than relying on words as having fixed meanings, appeals to a concept of semantic spaces, nebulae of variously interconnected meanings. This is constructed into an exhortation to reambiguate overfamiliar religious language, to reinvest one's quotidian surroundings with spiritual meaning through defamilarization.
SN 0591-2385
EI 1467-9744
PD SEP
PY 2022
VL 57
IS 3
BP 797
EP 825
DI 10.1111/zygo.12807
EA JUL 2022
UT WOS:000819556200001
ER

PT J
AU Zhang, HB
   Zhu, JH
AF Zhang, Huaibo
   Zhu, Jianghua
TI Practicability of Sports Goods in the Sports Field Based on Artificial
   Intelligence Technology
SO MOBILE INFORMATION SYSTEMS
AB People are in the intellectual age. The use of technologies such as smart search engines, machine translation, fingerprint analysis, facial scanning, and self-driving makes people's social and work lives happier. The intersection of artificial intelligence and other projects has also become the focus of research in the new era. This article uses comparative experimental methods and sampling methods, puts forward the evaluation method of association rules in the recommendation of sports goods, and compares the selection of sensors used by the five types of sports companies in the sports experiments. In the experiment part, according to the minimum confidence level, the two rules are met. Minimum confidence is a threshold defined by users or experts to measure confidence, which represents the lowest reliability of association rules. The conclusion is that 30% of users have bought running shoes and hiking shoes at the same time and 66.6% of users have also purchased sports suits; there are also sports suits purchased at the same time. All mountain bike users have bought sports gloves. The weight of Freescale is 0.2530, the weight of Bosch is 0.4457, the weight of ST is 0.0946, the weight of VTI is 0.0953, and the weight of Konix is 0.1114. The experimental results show that the selection result of the three-axis acceleration sensor is the SMB380 model of Bosch.
SN 1574-017X
EI 1875-905X
PD JUN 21
PY 2022
VL 2022
AR 4964894
DI 10.1155/2022/4964894
UT WOS:000821848600003
ER

PT C
AU Purkayastha, S
   Dana, S
   Garg, D
   Khandelwal, D
   Bhargav, GPS
AF Purkayastha, Sukannya
   Dana, Saswati
   Garg, Dinesh
   Khandelwal, Dinesh
   Bhargav, G. P. Shrivatsa
GP IEEE
TI A Deep Neural Approach to KGQA via SPARQL Silhouette Generation
SO 2022 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / IEEE World
   Congress on Computational Intelligence (IEEE WCCI) / International Joint
   Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary
   Computation (IEEE CEC)
CY JUL 18-23, 2022
CL Padua, ITALY
SP IEEE, Int Neural Network Soc, IEEE Computat Intelligence Soc, Evolutionary Programming Soc, IET, Univ Padova, Dept Math Tullio Levi Civita, European Space Agcy, expert.ai, Elsevier, Springer Nature, Google, Baker & Hughes, NVIDIA
AB Knowledge Graph Question Answering (KGQA) has become a prominent area in natural language processing due to the emergence of large scale Knowledge Graphs (KGs). Semantic parsing based approach is the predominant direction to solve the KGQA task where natural language question is translated into a logic form such as SPARQL query. Recently Neural Machine Translation (NMT) based approaches are gaining momentum in order to translate natural language query to structured query languages thereby solving the KGQA task. However, most of these methods struggle with out-of-vocabulary words where test entities and relations are not seen during training time. In this work, we propose a modular two stage neural architecture to solve the KGQA task. Stage-I of our approach comprises a NMT-based seq2seq module that translates a question into a sketch of the desired SPARQL query called a SPARQL silhouette. Stage-II of our approach comprises a Neural Graph Search (NGS) module which aims to improve the quality of the SPARQL silhouette by detecting the right relations in the underlying knowledge graph. Experimental results show that we achieve substantial improvements and obtain state-of-the-art performance or comparable results to the best performing systems on two benchmark datasets. We believe, our proposed approach is novel and will lead to dynamic KGQA solutions that are well-suited for practical applications.
SN 2161-4393
BN 978-1-7281-8671-9
PY 2022
DI 10.1109/IJCNN55064.2022.9892263
UT WOS:000867070903023
ER

PT J
AU Cancino, M
   Panes, J
AF Cancino, Marco
   Panes, Jaime
TI The impact of Google Translate on L2 writing quality measures: Evidence
   from Chilean EFL high school learners
SO SYSTEM
AB Over the last 30 years, English as a Foreign Language (EFL) classrooms have been consistently nurtured by technology. An important breakthrough in this respect has been Google Translate (GT), one of the most widely used online translators (OTs). Research suggests that when teachers are aware of the limitations of OTs and provide adequate guidance to use them, they can become effective pedagogical devices. However, most of the studies conducted in EFL settings focus on adult learners' perceptions toward OTs or rely on holistic rubrics to assess writing quality. Thus, the present study sought to apply a linguistic approach to the analysis of writing output produced by high school learners using GT. Sixty-one high-school EFL learners were randomly assigned to one of three groups: (GT without instruction, GT with instruction, and a group with no access to GT). Writing quality was assessed in terms of T-unit length, syntactic complexity, and accuracy in a narrative task. Results suggest that syntactic complexity and accuracy scores were higher in the groups that had access to GT. The possibilities for GT as an effective learning tool are discussed, while emphasizing the need for learners to receive adequate instruction on how to utilize it.
   (c) 2021 Elsevier Ltd. All rights reserved.
SN 0346-251X
EI 1879-3282
PD JUN
PY 2021
VL 98
AR 102464
DI 10.1016/j.system.2021.102464
EA JAN 2021
UT WOS:000643325600008
ER

PT J
AU Bolourchi, P
   Moradi, M
   Demirel, H
   Uysal, S
AF Bolourchi, Pouya
   Moradi, Masoud
   Demirel, Hasan
   Uysal, Sener
TI Ensembles of classifiers for improved SAR image recognition using pseudo
   Zernike moments
SO JOURNAL OF DEFENSE MODELING AND SIMULATION-APPLICATIONS METHODOLOGY
   TECHNOLOGY-JDMS
AB In this paper, a new approach for improving the classification of different kinds of ground vehicles from moving stationary target acquisition and recognition images is proposed. Pseudo Zernike moments are used for feature extraction due to its capability of being scale, rotation, and translation invariant. To benefit from the diversities of regions we utilize both target and shadow regions as separate regions of interest for vehicle representation. Region of interests in the form of "area,""boundary," and "texture" are used for extraction. Extracted features from target and shadow regions of area, boundary, and texture are fused and fed to different classifiers. Five classifiers with different properties are adopted, including support vector machine, which is a parametric classifier that can control overfitting, in contrast to the decision tree, which is a nonparametric classifier, linear discriminant analysis, and k-nearest neighbor, which have cheaper computational cost, and random forest, which is an appropriate classifier for estimating outlier and missing data. In order to improve the overall performance of target recognition, we proposed a novel approach in which first we define six regions and fuse them to a single vector. Then fused feature vectors are fed to classifiers and the final decision is generated using majority voting. Experimental results justify that by combining decision with majority voting the performance is improved.
RI Bolourchi, Pouya/M-3311-2019
OI Bolourchi, Pouya/0000-0003-3492-0617
SN 1548-5129
EI 1557-380X
PD APR
PY 2020
VL 17
IS 2
BP 205
EP 211
DI 10.1177/1548512919844610
UT WOS:000527298900007
ER

PT C
AU Fujita, Y
   Watanabe, S
   Omachi, M
   Chang, XK
AF Fujita, Yuya
   Watanabe, Shinji
   Omachi, Motoi
   Chang, Xuankai
GP Int Speech Commun Assoc
TI Insertion-Based Modeling for End-to-End Automatic Speech Recognition
SO INTERSPEECH 2020
SE Interspeech
CT Interspeech Conference
CY OCT 25-29, 2020
CL Shanghai, PEOPLES R CHINA
AB End-to-end (E2E) models have gained attention in the research field of automatic speech recognition (ASR). Many E2E models proposed so far assume left-to-right autoregressive generation of an output token sequence except for connectionist temporal classification (CTC) and its variants. However, left-to-right decoding cannot consider the future output context, and it is not always optimal for ASR. One of the non-left-to-right models is known as non-autoregressive Transformer (NAT) and has been intensively investigated in the area of neural machine translation (NMT) research. One NAT model, mask-predict, has been applied to ASR but the model needs some heuristics or additional component to estimate the length of the output token sequence. This paper proposes to apply another type of NAT called insertion-based models, that were originally proposed for NMT, to ASR tasks. Insertion-based models solve the above mask-predict issues and can generate an arbitrary generation order of an output sequence. In addition, we introduce a new formulation of joint training of the insertion-based models and CTC. This formulation reinforces CTC by making it dependent on insertion-based token generation in a non-autoregressive manner. We conducted experiments on three public benchmarks and achieved competitive performance to strong autoregressive Transformer with a similar decoding condition.
OI Watanabe, Shinji/0000-0002-5970-8631
SN 2308-457X
PY 2020
BP 3660
EP 3664
DI 10.21437/Interspeech.2020-1619
UT WOS:000833594103160
ER

PT J
AU Hammon, PS
   de Sa, VR
AF Hammon, Paul S.
   de Sa, Virginia R.
TI Preprocessing and meta-classification for brain-computer interfaces
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
AB A brain-computer interface (BCI) is a system which allows direct translation of brain states into actions, bypassing the usual muscular pathways. A BCI system works by extracting user brain signals, applying machine learning algorithms to classify the user's brain state, and performing a computer-controlled action. Our goal is to improve brain state classification. Perhaps the most obvious way to improve classification performance is the selection of an advanced learning algorithm. However, it is now well known in the BCI community that careful selection of Preprocessing steps is crucial to the success of any classification scheme. Furthermore, recent work indicates that combining the output of multiple classifiers (meta-classification) leads to improved classification rates relative to single classifiers (Dornbege et al., 2004). In this paper, we develop an automated approach which systematically analyzes the relative contributions of different preprocessing and meta-classification approaches. We apply this procedure to three data sets drawn from BCI Competition 2003 (Blankertz et al, 2004) and BCI Competition III (Blankertz et al., 2006), each of which exhibit very different characteristics. Our final classification results compare favorably with those from past BCI competitions. Additionally, we analyze the relative contributions of individual preprocessing and meta-classification choices and discuss which types of BCI data benefit most from specific algorithms.
SN 0018-9294
EI 1558-2531
PD MAR
PY 2007
VL 54
IS 3
BP 518
EP 525
DI 10.1109/TBME.2006.888833
UT WOS:000244498800020
PM 17355065
ER

PT J
AU Heo, TS
   Kim, JD
   Park, CY
   Kim, YS
AF Heo, Tak-Sung
   Kim, Jong-Dae
   Park, Chan-Young
   Kim, Yu-Seop
TI Sentence similarity evaluation using Sent2Vec and siamese neural network
   with parallel structure
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
CT 8th International Multi-Conference on Engineering and Technology
   Innovation (IMETI)
CY NOV 15-19, 2019
CL Kaohsiung, TAIWAN
AB Sentence similarity evaluation is a significant task used in machine translation, classification, and information extraction in the field of natural language processing. When two sentences are given, an accurate judgment should be made whether the meaning of the sentences is equivalent even if the words and contexts of the sentences are different. To this end, existing studies have measured the similarity of sentences by focusing on the analysis of words, morphemes, and letters. To measure sentence similarity, this study uses Sent2Vec, a sentence embedding, as well as morpheme word embedding. Vectors representing words are input to the 1-dimension convolutional neural network (1D-CNN) with various sizes of kernels and bidirectional long short-term memory (Bi-LSTM). Self-attention is applied to the features transformed through Bi-LSTM. Subsequently, vectors undergoing 1D-CNN and self-attention are converted through global max pooling and global average pooling to extract specific values, respectively. The vectors generated through the above process are concatenated to the vector generated through Sent2Vec and are represented as a single vector. The vector is input to softmax layer, and finally, the similarity between the two sentences is determined. The proposed model can improve the accuracy by up to 5.42% point compared with the conventional sentence similarity estimation models.
OI Heo, Tak-Sung/0000-0002-7022-4443
SN 1064-1246
EI 1875-8967
PY 2021
VL 40
IS 4
BP 7735
EP 7744
DI 10.3233/JIFS-189593
UT WOS:000640518000173
ER

PT C
AU Soo, VW
   Huang, CF
   Su, YH
   Su, MJ
AF Soo, Von-Wun
   Huang, Chih-Fang
   Su, Yu-Huei
   Su, Mei-Ju
BE Wu, TT
   Huang, YM
   Shadiev, R
   Lin, L
   Starcic, AI
TI AI Applications on Music Technology for Edutainment
SO INNOVATIVE TECHNOLOGIES AND LEARNING, ICITL 2018
SE Lecture Notes in Computer Science
CT 1st International Conference of Innovative Technologies and Learning
   (ICITL)
CY AUG 27-30, 2018
CL Portoroz, SLOVENIA
SP Natl Cheng Kung Univ, Kun Shan Univ, Natl Yunlin Univ Sci & Technol, Assoc Taiwan Engn Educ & Management, Univ Ljubljana
AB Music composition for songs is difficult for people, due to the necessity of the complicated music composition theory and the combined artistic conception and emotion-based ideas. The emotional representation can define the valence and arousal coordinate, and it is possible to perform the mapping technique between music and emotion, according to lyrics emotion. The proposed emotion-based algorithmic music composition uses song lyrics emotion to classify music segments, and use the mapping between music and emotion. It can make people who even don't know music theory easily compose a song. Some demos finally show the result of the research. Therefore the proposed method can be applied to such fields as the popular songs composition, background music, musical edutainment, education musicale, etc. Some traditional sources of entertainment have embraced AI to compose music and create stage performances. AI will increasingly enable entertainment that is more interactive, personalized, and engaging. In the future, more sophisticated tools and apps will become available to make it even easier to compose music. The creation and dissemination of entertainment will benefit from the progress of technologies such as ASR, dubbing, and Machine Translation, which will enable content to be customized to different audiences inexpensively. This democratization and proliferation of AI-created media makes it difficult to predict how humans' taste for entertainment, which are already fluid, will evolve.
SN 0302-9743
EI 1611-3349
BN 978-3-319-99737-7; 978-3-319-99736-0
PY 2018
VL 11003
BP 594
EP 599
DI 10.1007/978-3-319-99737-7_63
UT WOS:000548899200063
ER

PT C
AU Ahmed, K
   Lee, S
AF Ahmed, Kabir
   Lee, Soobum
BE Griffin, SF
TI Mechanical Motion Conversion from Reciprocating Translation to
   One-Directional Rotation for Effective Energy Harvesting
SO INDUSTRIAL AND COMMERCIAL APPLICATIONS OF SMART STRUCTURES TECHNOLOGIES
   2016
SE Proceedings of SPIE
CT Conference on Industrial and Commercial Applications of Smart Structures
   Technologies
CY MAR 21-22, 2016
CL Las Vegas, NV
SP SPIE, Polytec Inc, OZ Opt Ltd, APS Dynam Inc, TA Electroforce Corp, ElectroForce Syst Grp, Inst Phys, Amer Elements
AB This paper proposes a new efficient motion conversion system which can be used in an energy harvesting system that converts wasted kinematic energy into electrical energy. In the proposed system, a reciprocating translational motion will be converted into one-directional rotational motion that spins a generator. The system will be devised with a two overlapping chambers (chamber 1 and 2) which move relatively through the sliding joint, and a pair of flexible strings (belt, steel wire, or chain) run around the rotor of the generator. Each end of the string fixed to chamber 1 is designed not to interfere with chamber 2 where the generator is mounted. When the two chambers move relatively, either top or bottom string is tensioned to spin the rotor while the other string is being rewound. One-directional clutch with a coil spring is engaged in a rewinding system - as found in a rowing machine, for example - so each string actuates the rotor only when it is in tension. This device can be applied to any mechanism where reciprocating translational motion exists, such as linear suspension system in a vehicle, a bicycle, and an energy generating marine buoy. The experimental study result will be reported as well as its battery-charging capacity will be demonstrated.
SN 0277-786X
EI 1996-756X
BN 978-1-5106-0042-3
PY 2016
VL 9801
AR 98010N
DI 10.1117/12.2219457
UT WOS:000389022200015
ER

PT J
AU Fatimah, YA
   Raven, RPJM
   Arora, S
AF Fatimah, Yuti Ariani
   Raven, Rob P. J. M.
   Arora, Saurabh
TI Scripts in transition: Protective spaces of Indonesian biofuel villages
SO TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
AB This paper studies the development of biofuel village pilot projects in Indonesia. Despite the central government's political and financial commitment to the projects, the projects failed to survive and produce sustainable effects. In order to understand why the projects were stalled, this paper traces how the design of Indonesia's biofuel policies shaped the actual socio-technical configurations of the projects. To trace this relationship between the policies and the actual project configurations, we develop a framework that combines the concept of protective space from transition studies and the concept of script from actor-network theory. The concept of script allows us to investigate how the designs of protective spaces and of the experimental projects are enacted through non-coherent processes involving misunderstandings and shifts in meanings between narratives and things (e.g. between policies implemented and the machines put in place). Our analysis makes manifest the non-linearity of the relation between the design of a protective space and the actual practices engendered. This non-linearity emerged through changes in direction brought about by the central government's inability to stretch and transform the local environment in accordance with the policy design and through changes in individual actors' interests in the projects. (C) 2015 Elsevier Inc. All rights reserved.
RI Raven, Rob/V-5710-2019; Raven, Rob/GXG-2362-2022; Raven, Rob/C-3048-2017
OI Raven, Rob/0000-0002-6330-0831; Raven, Rob/0000-0002-6330-0831; Raven,
   Rob/0000-0002-6330-0831; Fatimah, Yuti Ariani/0000-0002-6807-8184
SN 0040-1625
EI 1873-5509
PD OCT
PY 2015
VL 99
BP 1
EP 13
DI 10.1016/j.techfore.2015.06.021
UT WOS:000365062700001
ER

PT J
AU Soltau, H
   Saon, G
   Kingsbury, B
   Kuo, HKJ
   Mangu, L
   Povey, D
   Emami, A
AF Soltau, Hagen
   Saon, George
   Kingsbury, Brian
   Kuo, Hong-Kwang Jeff
   Mangu, Lidia
   Povey, Daniel
   Emami, Ahmad
TI Advances in Arabic Speech Transcription at IBM Under the DARPA GALE
   Program
SO IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB This paper describes the Arabic broadcast transcription system fielded by IBM in the GALE Phase 2.5 machine translation evaluation. Key advances include the use of additional training data from the Linguistic Data Consortium (LDC), use of a very large vocabulary comprising 737 K words and 2.5 M pronunciation variants, automatic vowelization using flat-start training, cross-adaptation between unvowelized and vowelized acoustic models, and rescoring with a neural-network language model. The resulting system achieves word error rates below 10% on Arabic broadcasts. Very large scale experiments with unsupervised training demonstrate that the utility of unsupervised data depends on the amount of supervised data available. While unsupervised training improves system performance when a limited amount (135 h) of supervised data is available, these gains disappear when a greater amount (848 h) of supervised data is used, even with a very large (7069 h) corpus of unsupervised data. We also describe a method for modeling Arabic dialects that avoids the problem of data sparseness entailed by dialect-specific acoustic models via the use of non-phonetic, dialect questions in the decision trees. We show how this method can be used with a statically compiled decoding graph by partitioning the decision trees into a static component and a dynamic component, with the dynamic component being replaced by a mapping that is evaluated at run-time.
SN 1558-7916
EI 1558-7924
PD JUL
PY 2009
VL 17
IS 5
BP 884
EP 894
DI 10.1109/TASL.2009.2022966
UT WOS:000267434300004
ER

PT C
AU Hartrumpf, S
   Glockner, I
   Leveling, J
AF Hartrumpf, Sven
   Gloeckner, Ingo
   Leveling, Johannes
BE Peters, C
TI Efficient Question Answering with Question Decomposition and Multiple
   Answer Streams
SO EVALUATING SYSTEMS FOR MULTILINGUAL AND MULTIMODAL INFORMATION ACCESS
SE Lecture Notes in Computer Science
CT 9th Workshop of the Cross-Language Evaluation Forum (CLEF 2008)
CY SEP 17-19, 2008
CL Aarhus, DENMARK
AB The German question answering (QA) system IRSAW (Formerly: hiSicht) participated in QA@CLEF for the fifth time. IRSAW was introduced in 2007 by integrating the deep answer producer InSicht, several shallow answer producers, and a logical validator. InSicht builds on a deep QA approach: it transforms documents to semantic representations using a parser, draws inferences on semantic representations with rules, and matches semantic representations derived from questions and documents. hiSicht was improved for QA@CLEF 2008 mainly ill the following two areas. The coreference resolver was trained oil question series instead of newspaper texts in order to be better applicable for follow-lip questions. Questions are decomposed by several methods on the level of semantic representations. Oil the shallow processing side, the number of answer producers was increased from two to four by adding FACT; a fact index, and SHASE, a shallow semantic network matcher. The answer validator introduced in 2007 was replaced by the faster RAVE validator designed for logic-based answer validation under time constraints. Using RAVE for merging the results of the answer producers, monolingual German man runs bilingual runs with source language English and Spanish were produced by applying the machine translation web service Promt. An error analysis shows the main problems for the precision-oriented deep answer producer InSicht and the potential offered by the recall-oriented shallow answer producers.
OI Leveling, Johannes/0000-0003-0603-4191
SN 0302-9743
EI 1611-3349
BN 978-3-642-04446-5
PY 2009
VL 5706
BP 421
EP +
UT WOS:000273344500049
ER

PT J
AU Burkett, P
   Foster, JB
AF Burkett, Paul
   Foster, John Bellamy
TI The Podolinsky myth: An obituary introduction to 'Human labour and unity
   of force', by Sergei Podolinsky
SO HISTORICAL MATERIALISM-RESEARCH IN CRITICAL MARXIST THEORY
AB The relationship between Marxism and ecology has been sullied by Martinez-Alier's influential interpretation of Engels's reaction to the agricultural energetics of Sergei Podolinsky. This introduction to the first English translation of Podolinsky's 1883 Die Neue Zeit piece evaluates Martinez-Alier's interpretation in light of the four distinct but closely related articles Podolinsky published over the years 1880-3. This evaluation also emphasises the important but previously underrated role of energy analysis in Marx's Capital. Engels's criticisms of Podolinsky are found to be quite justified from both political-economy and ecological perspectives. From the standpoint of Marx and Engels's metabolic and class-relational approach to production, Podolinsky's attempt to reduce use-value to energy is fraught with problems. Podolinsky's energy reductionism does not even come close to representing an alternative value analysis - let alone a groundbreaking perspective on ecological history - as was suggested by Martinez-Alier. Far from Marx and Engels's vision of communism as an ecologically sustainable and coevolutionary human development, Podolinskys conception of human labor as an energy accumulation machine seems to uncritically mimic the standpoint of the capitalist interested in using nature only to extract as much energy throughput (work) as possible from the labour-power (potential work) of the worker.
SN 1465-4466
PY 2008
VL 16
IS 1
BP 115
EP 161
DI 10.1163/156920608X276323
UT WOS:000256144700006
ER

PT C
AU Tang, MZ
   Zhang, HT
   Mccoy, J
   Her, TH
AF Tang, Mingzhen
   Zhang, Haitao
   McCoy, Jerry
   Her, Tsing-Hua
BE Maher, MA
   Stewart, HD
   Chiao, JC
   Suleski, TJ
   Jonhson, EG
   Nordin, GP
TI Periodic nanoripple generated by femtosecond laser beam in LCVD system
SO MICROMACHINING TECHNOLOGY FOR MICRO-OPTICS AND NANO-OPTICS V AND
   MICROFABRICATION PROCESS TECHNOLOGY XII
SE Proceedings of SPIE
CT Conference on Micromachining Technology For Micro-Optics and Nano-Optics
   V and Microfabrication Process Technology XII
CY JAN 22-24, 2007
CL San Jose, CA
SP SPIE
AB We demonstrate deposition of periodic tungsten nanoripple on different substrate using a single 400nm femtosecond laser beam at room temperature. The laser beam generated by frequency doubling the output from mode-locked 80MHz Ti: sapphire oscillator was applied in a laser-induced chemical vapor deposition configuration, in which tungsten hexacarbonyl was used as precursor. The deposition strongly depended on laser polarization. With linearly polarized light, periodic ripple structure with willow-leaf shape was formed inside the exposure area. The ripple orientation was found parallel to the laser polarization direction. Affects of laser power and exposure time on ripple formation were investigated. By translating the substrate with respective to the laser beam, longitudinal or transverse grating structure was observed. The period of this grating structure is about 150nm on sapphire, and the orientation is parallel to laser polarization. Simply by programming the translation of the substrate, large area patterns and other patterns such as circle and characters were formed. Similar ripple and grating structures observed on all the substrates we investigated, including insulators, semiconductors and metals, implies that ripple formation might be a universal phenomenon. Considering the simplicity of this process and material flexibility of laser CVD, this technique may provide a novel cost-effective patterning method to produce periodic subwavelength nanostructures of a wide range of materials on many substrates.
SN 0277-786X
EI 1996-756X
BN 978-0-8194-6575-7
PY 2007
VL 6462
AR 64620T
DI 10.1117/12.700745
UT WOS:000246049500023
ER

PT C
AU Daicos, C
   Knight, GS
AF Daicos, C
   Knight, GS
BE Gritzalis, D
   DiVimercati, SD
   Samarati, P
   Katsikas, S
TI Concerning enterprise network vulnerability to HTTP tunnelling
SO SECURITY AND PRIVACY IN THE AGE OF UNCERTAINTY
SE INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING
CT 18th International Conference on Information Security
CY MAY 26-28, 2003
CL ATHENS, GREECE
SP Int Federat Informat Proc, TC 11
AB It has been understood for some time that arbitrary data, including the communications associated with malicious backdoors and Trojan horses, call be tunnelled by Subverting the HTTP protocol. Although there are a number demonstration programs openly available, the risks associated with this vulnerability have not been characterised ill the literature. This research investigates the nature of the Vulnerability and the efficacy of contemporary network defence strategies Such as firewall technology, intrusion detection systems, HTTP caching and proxying, and network address translation. All of these techniques are quite easily circumvented by HTTP tunnelling strategies. This Vulnerability is serious for most enterprise environments today. The use of some Internet services is considered to be a requirement for business operations in many organisations. Even with very strict firewall rule sets and layered defence architectures, legitimate web traffic originating from within the protected network is often allowed. Web traffic also forms a large portion of the traffic crossing network boundaries, which makes the HTTP protocol all attractive target for subversion. This research explores techniques that may he used to hide malicious traffic in what seems to be legitimate HTTP traffic originating from within the protected network. The covert channel provides external control of a computer Oil the protected network from a machine anywhere on the Internet. The techniques explored by this project are used ill parallel research projects to detect such malicious tunnel traffic and validate new intrusion detection technology.
SN 1571-5736
BN 1-4020-7449-2
PY 2003
VL 122
BP 13
EP 24
UT WOS:000184323200002
ER

PT C
AU Albertsson, L
AF Albertsson, L
BE Kienzle, MG
   Shenoy, PJ
TI Temporal debugging and profiling of multimedia applications
SO MULTIMEDIA COMPUTING AND NETWORKING 2002
SE Proceedings of SPIE
CT Conference on Multimedia Computing and Networking 2002
CY JAN 23-24, 2002
CL SanJose, CA
SP Soc Imaging Sci & Technol, SPIE, ACM SIG Multimedia
AB We present a temporal debugger, capable of examining time flow of applications in general-purpose computer systems. The debugger is attached to a complete system simulator, which models an entire workstation in sufficient detail to run commodity operating systems and workloads. Unlike traditional debuggers, a debugger operating on a simulated system does not disturb the timing of the target program, allowing reproducible experiments and large amounts of instrumentation and monitoring without intrusion.
   We have implemented the temporal debugger by modifying the GNU debugger to operate on applications in a simulated Linux system. Debugger implementation is difficult because the debugger expects application-related data, whereas the simulator provides low-level data. We introduce a technique, virtual machine translation, for mapping simulator data to the debugger by parsing operating system data structures in the simulated system.
   The debugger environment allows collection of performance statistics from multiple abstraction levels: hardware, operating system, and application level. We show how this data can be used to profile quality of service performance of a video decoder. The debugger is used to detect display jitter, and by correlating runtime statistics to image rendering time, we expose deviations when the application is unable to render an image in time, thereby locating the cause of the display jitter.
SN 0277-786X
EI 1996-756X
BN 0-8194-4413-8
PY 2002
VL 4673
BP 196
EP 207
UT WOS:000176001000016
ER

PT J
AU Rost, N
   Bruckl, TM
   Koutsouleris, N
   Binder, EB
   Muller-Myhsok, B
AF Rost, Nicolas
   Bruckl, Tanja M.
   Koutsouleris, Nikolaos
   Binder, Elisabeth B.
   Mueller-Myhsok, Bertram
TI Creating sparser prediction models of treatment outcome in depression: a
   proof-of-concept study using simultaneous feature selection and
   hyperparameter tuning
SO BMC MEDICAL INFORMATICS AND DECISION MAKING
AB Background Predicting treatment outcome in major depressive disorder (MDD) remains an essential challenge for precision psychiatry. Clinical prediction models (CPMs) based on supervised machine learning have been a promising approach for this endeavor. However, only few CPMs have focused on model sparsity even though sparser models might facilitate the translation into clinical practice and lower the expenses of their application. Methods In this study, we developed a predictive modeling pipeline that combines hyperparameter tuning and recursive feature elimination in a nested cross-validation framework. We applied this pipeline to a real-world clinical data set on MDD treatment response and to a second simulated data set using three different classification algorithms. Performance was evaluated by permutation testing and comparison to a reference pipeline without nested feature selection. Results Across all models, the proposed pipeline led to sparser CPMs compared to the reference pipeline. Except for one comparison, the proposed pipeline resulted in equally or more accurate predictions. For MDD treatment response, balanced accuracy scores ranged between 61 and 71% when models were applied to hold-out validation data. Conclusions The resulting models might be particularly interesting for clinical applications as they could reduce expenses for clinical institutions and stress for patients.
OI Rost, Nicolas/0000-0002-2079-5555
EI 1472-6947
PD JUL 14
PY 2022
VL 22
IS 1
AR 181
DI 10.1186/s12911-022-01926-2
UT WOS:000825419000001
PM 35836174
ER

PT J
AU Kadumudi, FB
   Hasany, M
   Pierchala, MK
   Jahanshahi, M
   Taebnia, N
   Mehrali, M
   Mitu, CF
   Shahbazi, MA
   Zsurzsan, TG
   Knott, A
   Andresen, TL
   Dolatshahi-Pirouz, A
AF Kadumudi, Firoz Babu
   Hasany, Masoud
   Pierchala, Malgorzata Karolina
   Jahanshahi, Mohammadjavad
   Taebnia, Nayere
   Mehrali, Mehdi
   Mitu, Cristian Florian
   Shahbazi, Mohammad-Ali
   Zsurzsan, Tiberiu-Gabriel
   Knott, Arnold
   Andresen, Thomas L.
   Dolatshahi-Pirouz, Alireza
TI The Manufacture of Unbreakable Bionics via Multifunctional and
   Self-Healing Silk-Graphene Hydrogels
SO ADVANCED MATERIALS
AB Biomaterials capable of transmitting signals over longer distances than those in rigid electronics can open new opportunities for humanity by mimicking the way tissues propagate information. For seamless mirroring of the human body, they also have to display conformability to its curvilinear architecture, as well as, reproducing native-like mechanical and electrical properties combined with the ability to self-heal on demand like native organs and tissues. Along these lines, a multifunctional composite is developed by mixing silk fibroin and reduced graphene oxide. The material is coined "CareGum" and capitalizes on a phenolic glue to facilitate sacrificial and hierarchical hydrogen bonds. The hierarchal bonding scheme gives rise to high mechanical toughness, record-breaking elongation capacity of approximate to 25 000%, excellent conformability to arbitrary and complex surfaces, 3D printability, a tenfold increase in electrical conductivity, and a fourfold increase in Young's modulus compared to its pristine counterpart. By taking advantage of these unique properties, a durable and self-healing bionic glove is developed for hand gesture sensing and sign translation. Indeed, CareGum is a new advanced material with promising applications in fields like cyborganics, bionics, soft robotics, human-machine interfaces, 3D-printed electronics, and flexible bioelectronics.
RI Dolatshahi-Pirouz, Alireza/P-8179-2014; Hasany, Masoud/P-5522-2016;
   shahbazi, Mohammad-Ali/M-5838-2013; Mehrali, Mehdi/G-6395-2011; Knott,
   Arnold/D-4286-2014; Kadumudi, Firoz Babu/M-8495-2015; Zsurzsan,
   Tiberiu-Gabriel/H-5809-2017
OI Dolatshahi-Pirouz, Alireza/0000-0001-6326-0836; Hasany,
   Masoud/0000-0002-1407-257X; shahbazi, Mohammad-Ali/0000-0002-4860-3017;
   Mehrali, Mehdi/0000-0002-5084-1823; Jahanshahi,
   Mohammadjavad/0000-0002-6672-9801; Andresen, Thomas
   Lars/0000-0002-1048-127X; Pierchala, Malgorzata
   Karolina/0000-0002-3421-7991; Taebnia, Nayere/0000-0003-0707-278X;
   Knott, Arnold/0000-0003-4384-0432; Kadumudi, Firoz
   Babu/0000-0002-1329-4015; Zsurzsan, Tiberiu-Gabriel/0000-0003-4271-870X
SN 0935-9648
EI 1521-4095
PD SEP
PY 2021
VL 33
IS 35
AR 2100047
DI 10.1002/adma.202100047
EA JUL 2021
UT WOS:000671662100001
PM 34247417
ER

PT J
AU Tomaszewski, MR
   Gillies, RJ
AF Tomaszewski, Michal R.
   Gillies, Robert J.
TI The Biological Meaning of Radiomic Features
SO RADIOLOGY
AB Radiomic analysis offers a powerful tool for the extraction of clinically relevant information from radiologic imaging. Radiomics can be used to predict patient outcome through automated high-throughput feature extraction, using large training cohorts to elucidate subtle relationships between image characteristics and disease status. However powerful, the data-driven nature of radiomics inherently offers no insight into the biological underpinnings of the observed relationships. Early radiomics work was dominated by analysis of semantic, radiologist-defined features and carried qualitative real-world meaning. Following the rapid developments and popularity of machine learning approaches, the field moved quickly toward high-throughput agnostic analyses, resulting in increasingly large feature sets. This trend took the focus toward an increase in predictive power and further away from a biological understanding of the findings. Such a disconnect between predictor model and biological meaning will inherently limit broad clinical translation. Efforts to reintroduce biological meaning into radiomics are gaining traction in the field with distinct emerging approaches available, including genomic correlates, local microscopic pathologic image textures, and macroscopic histopathologic marker expression. These methods are presented in this review, and their significance is discussed. The authors predict that following the increasing pressure for robust radiomics, biological validation will become a standard practice in the field, thus further cementing the role of the method in clinical decision making. (C) RSNA, 2021
OI Tomaszewski, Michal/0000-0002-3194-9492; Gillies,
   Robert/0000-0002-8888-7747
SN 0033-8419
PD MAR
PY 2021
VL 298
IS 3
BP 505
EP 516
DI 10.1148/radiol.2021202553
UT WOS:000621371200014
PM 33900879
ER

PT C
AU Failla, L
   Rossoni, M
   Vallesi, M
   Colombo, G
AF Failla, Lorenzo
   Rossoni, Marco
   Vallesi, Michele
   Colombo, Giorgio
GP Amer Soc Mech Engineers
TI ONTOLOGY FOR PRODUCT LIFECYCLE MANAGEMENT IN THE OIL&GAS TURBOMACHINERY
   INDUSTRY
SO PROCEEDINGS OF ASME 2021 INTERNATIONAL MECHANICAL ENGINEERING CONGRESS
   AND EXPOSITION (IMECE2021), VOL 6
CT ASME International Mechanical Engineering Congress and Exposition
   (IMECE)
CY NOV 01-05, 2021
CL ELECTR NETWORK
SP Amer Soc Mech Engineers
AB In the industrial contexts of the digital era, data, information and knowledge should seamlessly flow throughout the product lifecycle, and be available at any time and to any agent acting in the value creation stream. PLM is one of the enabler of this scenario, striving to scale the "cobbler" model - where people, information, resources and processes are perfectly integrated to modern industrial realities operating with multi-disciplinary teams and world-wide dispersed internal and external resources. Yet, despite many industrial realities has invested in the institutionalization of a PLM system, still approx. 60% of time in the value creation process is wasted in searching and waiting for data, data translation, working with wrong data or reinvention of the existing knowledge. After having analyzed the above scenario in the context of a real big industrial reality operating in the turbo-machinery production for Oil & Gas and Engery markets, the present paper aims to propose a solution introducing a working approach based on the modeling of the knowledge domain relevant to a product and its data model by an OWL-DL ontology, and to present the relevant preliminary results. The final target will be the establishment of an ontology-based domain model as the foundation for a digital, human-machine interoperable, product knowledge and data lifecycle management system to bridge the diverse agents operating in the Product Lifecycle Management.
BN 978-0-7918-8560-4
PY 2021
AR V006T06A034
UT WOS:000883011100034
ER

PT C
AU Chen, JJ
   Ngo, CW
   Feng, FL
   Chua, TS
AF Chen, Jing-Jing
   Ngo, Chong-Wah
   Feng, Fu-Li
   Chua, Tat-Seng
GP ACM
TI Deep Understanding of Cooking Procedure for Cross-modal Recipe Retrieval
SO PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18)
CT 26th ACM Multimedia Conference (MM)
CY OCT 22-26, 2018
CL Seoul, SOUTH KOREA
SP Assoc Comp Machinery, ACM SIGMM
AB Finding a right recipe that describes the cooking procedure for a dish from just one picture is inherently a difficult problem. Food preparation undergoes a complex process involving raw ingredients, utensils, cutting and cooking operations. This process gives clues to the multimedia presentation of a dish (e.g., taste, colour, shape). However, the description of the process is implicit, implying only the cause of dish presentation rather than the visual effect that can be vividly observed on a picture. Therefore, different from other cross-modal retrieval problems in the literature, recipe search requires the understanding of textually described procedure to predict its possible consequence on visual appearance. In this paper, we approach this problem from the perspective of attention modeling. Specifically, we model the attention of words and sentences in a recipe and align them with its image feature such that both text and visual features share high similarity in multi-dimensional space. Through a large food dataset, Recipe1M, we empirically demonstrate that understanding the cooking procedure can lead to improvement in a large margin compared to the existing methods which mostly consider only ingredient information. Furthermore, with attention modeling, we show that language-specific named-entity extraction becomes optional. The result gives light to the feasibility of performing cross-lingual cross-modal recipe retrieval with off-the-shelf machine translation engines.
RI chen, JJ/HGB-6029-2022
BN 978-1-4503-5665-7
PY 2018
BP 1020
EP 1028
DI 10.1145/3240508.3240627
UT WOS:000509665700117
ER

PT C
AU Silfa, F
   Dot, G
   Arnau, JM
   Gonzalez, A
AF Silfa, Franyell
   Dot, Gem
   Arnau, Jose-Maria
   Gonzalez, Antonio
GP Assoc Comp Machinery
TI E-PUR: An Energy-Efficient Processing Unit for Recurrent Neural Networks
SO 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION
   TECHNIQUES (PACT 2018)
CT 27th IEEE/ACM/IFIP International Conference on Parallel Architectures
   and Compilation Techniques (PACT)
CY NOV 01-04, 2018
CL Limassol, CYPRUS
SP IEEE Comp Soc, ACM SIGARCH, IFIP, Assoc Comp Machinery, IEEE, IBM, nVIDIA, NSF, Huawei, Microsoft
AB Recurrent Neural Networks (RNNs) are a key technology for emerging applications such as automatic speech recognition, machine translation or image description. Long Short Term Memory (LSTM) networks are the most successful RNN implementation, as they can learn long term dependencies to achieve high accuracy. Unfortunately, the recurrent nature of LSTM networks significantly constrains the amount of parallelism and, hence, multicore CPUs and many-core GPUs exhibit poor efficiency for RNN inference.
   In this paper, we present E-PUR, an energy-efficient processing unit tailored to the requirements of LSTM computation. The main goal of E-PUR is to support large recurrent neural networks for low-power mobile devices. E-PUR provides an efficient hardware implementation of LSTM networks that is flexible to support diverse applications. One of its main novelties is a technique that we call Maximizing Weight Locality (MWL), which improves the temporal locality of the memory accesses for fetching the synaptic weights, reducing the memory requirements by a large extent.
   Our experimental results show that E-PUR achieves real-time performance for different LSTM networks, while reducing energy consumption by orders of magnitude with respect to general-purpose processors and GPUs, and it requires a very small chip area. Compared to a modern mobile SoC, an NVIDIA Tegra X1, E-PUR provides an average energy reduction of 88x.
BN 978-1-4503-5986-3
PY 2018
DI 10.1145/3243176.3243184
UT WOS:000475553400018
ER

PT J
AU Liu, JCH
AF Liu, Joyce C. H.
TI Against Agamben: Sovereignty and the Void in the Discourse of the Nation
   in Early Modern China
SO THEORY CULTURE & SOCIETY
AB In Kingdom and Glory, Agamben analyzed the dual perspective of the void, through the metaphor of the empty throne, in the governmental machine in the West. I engage with the ambiguous question of the void with regard to the concept of sovereignty through my reading of two Chinese intellectuals in the late Qing period, Liang Qichao (1872-1929) and Zhang Taiyan (1869-1936). This paper therefore addresses the question of sovereignty and the void in the discourse of nation in early modern China, an issue that is related to the problem of the political economy or the politics of life. I argue that the rhetorical move in Liang Qichao's argument for the birth of a new nation and new people was to move from the not-having (?) to the there is (?) in support of the formation of a new nation-state and a restricted logic of sovereignty, while Zhan Taiyan's position was to affirm the dynamitic re-composition of the void by constantly negating the given fixated state, and thus proposing a different and radical vision of nation and full sovereignty of the lives of each and every one of the people who are co-inhabiting in the polis.
OI Liu, Joyce C.H./0000-0002-0235-2195
SN 0263-2764
EI 1460-3616
PD JUL
PY 2015
VL 32
IS 4
BP 81
EP 104
DI 10.1177/0263276415580855
UT WOS:000355754900005
ER

PT J
AU Narayan, L
AF Narayan, Lalit
TI Addressing language barriers to healthcare in India
SO NATIONAL MEDICAL JOURNAL OF INDIA
AB In spite of a growing recognition of the importance of doctor-patient communication, the issue of language barriers to healthcare has received very little attention in India. The Indian population speaks over 22 major languages with English used as the lingua franca for biomedicine. Large-scale internal migration has meant that health workers are encountering increasing instances of language discordance within clinical settings. Research done predominantly in the West has shown language discordance to significantly affect access to care, cause problems of comprehension and adherence, and decrease the satisfaction and quality of care. Addressing language barriers to healthcare in India requires a stronger political commitment to providing non-discriminatory health services, especially to vulnerable groups such as illiterate migrant workers. Research will have to address three broad areas: the ways in which language barriers affect health and healthcare, the efficacy of interventions to overcome language barriers, and the costs of language barriers and efforts to overcome them. There is a need to address such barriers in health worker education and clinical practice. Proven strategies such as hiring multilingual healthcare workers, providing language training to health providers, employing in situ translators or using telephone interpretation services will have to be evaluated for their appropriateness to the Indian context. Internet-based initiatives, the proliferation of mobile phones and recent advances in machine translation promise to contribute to the solution.
SN 0970-258X
PD JUL-AUG
PY 2013
VL 26
IS 4
BP 236
EP 238
UT WOS:000340322200014
PM 24758452
ER

PT C
AU Ali, MNY
   Das, JK
   Al-Mamun, SMA
   Choudhury, MEH
AF Ali, Md. Nawab Yousuf
   Das, Jugal Krishna
   Al-Mamun, S. M. Abdullah
   Choudhury, Md Ershadul H.
GP IEEE
TI Specific features of a converter of web documents from Bengali to
   Universal Networking Language
SO 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING,
   VOLS 1-3
CT International Conference on Computer and Communication Engineering
CY MAY 13-15, 2008
CL Kuala Lumpur, MALAYSIA
SP Int Islam Univ Malaysia, Fac Engn
AB In this paper, we present a workable structure along with characteristic features of a subsystem that may become an integral part of a Language Server bridging Bengali and the Universal Networking Language (M). We try to assimilate the results of the research efforts of the UNL community and also of various machine translation projects. Vast information resources in different languages are available in the Internet, but the can not be shared (because of vastly due to the language barrier). And the UNL community is set to devise an effective and efficient system to diminish that barrier with an ultimate aim to allow automatic conversion of web based resources in one member language to that in another member language. A good number of researchers in computational linguistics all over the world have already joined hands with the UNL initiators, and research groups representing most widely used natural languages are working intensively for the purpose. This paper is to demonstrate our pioneering efforts in the field of Bengali (Bangla). Here we here outline a possible Bangla-UNL dictionary, feature an annotation editor for Bangla texts, infer significant morphological, syntactic and semantic rules for parsing Bangla web documents in connection with conversion to the UNL, and show possible ways of future contribution towards the goal.
BN 978-1-4244-2357-6
PY 2008
BP 726
EP +
DI 10.1109/ICCCE.2008.4580700
UT WOS:000259601400145
ER

PT J
AU Dilawari, A
   Khan, MUG
   Saleem, S
   Zahoor-Ur-Rehman
   Shaikh, FS
AF Dilawari, Aniqa
   Khan, Muhammad Usman Ghani
   Saleem, Summra
   Zahoor-Ur-Rehman
   Shaikh, Fatema Sabeen
TI Neural Attention Model for Abstractive Text Summarization Using
   Linguistic Feature Space
SO IEEE ACCESS
AB Summarization generates a brief and concise summary which portrays the main idea of the source text. There are two forms of summarization: abstractive and extractive. Extractive summarization chooses important sentences from the text to form a summary whereas abstractive summarization paraphrase using advanced and nearer-to human explanation by adding novel words or phrases. For a human annotator, producing summary of a document is time consuming and expensive because it requires going through the long document and composing a short summary. An automatic feature-rich model for text summarization is proposed that can reduce the amount of labor and produce a quick summary by using both extractive and abstractive approach. A feature-rich extractor highlights the important sentences in the text and linguistic characteristics are used to enhance results. The extracted summary is then fed to an abstracter to further provide information using features such as named entity tags, part of speech tags and term weights. Furthermore, a loss function is introduced to normalize the inconsistency between word-level and sentence-level attentions. The proposed two-staged network achieved a ROUGE score of 37.76% on the benchmark CNN/DailyMail dataset, outperforming the earlier work. Human evaluation is also conducted to measure the comprehensiveness, conciseness and informativeness of the generated summary.
SN 2169-3536
PY 2023
VL 11
BP 23557
EP 23564
DI 10.1109/ACCESS.2023.3249783
UT WOS:000952558300001
ER

PT C
AU Blasch, E
   Liu, Z
   Zheng, YF
AF Blasch, Erik
   Liu, Zheng
   Zheng, Yufeng
BE Andresen, BF
   Fulop, GF
   Zheng, L
TI Advances in Infrared Image Processing and Exploitation using Deep
   Learning
SO INFRARED TECHNOLOGY AND APPLICATIONS XLVIII
SE Proceedings of SPIE
CT Conference on Infrared Technology and Applications XLVIII Part of SPIE
   Defense and Commercial Sensing Conference
CY APR 03-JUN 12, 2022
CL ELECTR NETWORK
SP SPIE
AB Since the rise of deep learning (DL), methods are being proposed daily for all kinds of applications such as systems that include radar, infrared (IR), and electro-optical (EO) imagery. The most common DL application uses the convolutional neural network (CNN) for visual (VIS) imagery as data sets are available for training. This paper highlights recent advances of DL for Infrared (IR) applications by conducting a literature review for IR only and IR plus another modality (e.g., Visual+IR). For IR DL developments, the paper examines that of (1) applications (medical, non-destructive evaluation, target recognition), (2) sensing (space, air, ground), and (3) multi-modal (transfer learning, image enhancement, band selection); while determining aspects for improving the IR sensor design. For IR applications with existing IR data, researchers quickly replaced machine learning with DL. For sensing, the assessment demonstrates different domains in which IR is used. For multi-modal IR analysis, the DL methods are developed towards improving perception for users. After an extensive literature review, there are emerging trends easily discernable on IR sensor analytics. Future directions for IR DL require labeled data collections, user-described mission needs, and alignment with applications such autonomous cars for enhanced day-night performance.
RI Liu, Zheng/D-8678-2016
OI Liu, Zheng/0000-0002-7241-3483
SN 0277-786X
EI 1996-756X
BN 978-1-5106-5091-6; 978-1-5106-5090-9
PY 2022
VL 12107
AR 121071M
DI 10.1117/12.2619140
UT WOS:000850470600044
ER

PT C
AU Pranathi, P
   Lakshmi, C
   Suneetha, M
AF Pranathi, P.
   Lakshmi, C.
   Suneetha, M.
GP IEEE
TI A Review on Various Facial Expression Recognition Techniques
SO PROCEEDINGS OF THE 2021 FIFTH INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN
   SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC 2021)
CT 5th International Conference on IoT in Social, Mobile, Analytics and
   Cloud (I-SMAC)
CY NOV 11-13, 2021
CL ELECTR NETWORK
SP IEEE, SCAD Inst Technol
AB In present days, Facial Expression Acknowledgment (FER) has now become an unbelievable issue in contemporary science study. Facial expression, a vital mode of communication of human emotions, has been studied throughout the world in the fields of Driver Protection, human computer interaction (HCI), deception detection, health care, monitoring etc. Generative Adverse Networks (GANs), with various gestures, can create more one-to-one faces that can be used to improve data base. Facial expression recognition is one of the most effective naturalizing and instant means for people to convey their feelings and intentions. FER is a common research subject which has brought a range of computational vision tasks, such as image generation, video generation, super resolution reconstruction and image translation. Happiness, sorrow, surprise, disgust, fear and rage all constitute six universal facial expressions. Other things such as eye change, breathing and combing the variance in expression will underline all the emotion above. A face recognition device is a behavior request for the identification or authentication of an individual automatically from a digital picture or from a video source. This analysis paper helps to explain methods, strategies and challenges in the real time FER climate, which discuss and examine problems and challenges. This paper finally concludes the latest developments and addresses the problems facing the FER process and the potential of future growth.
RI Manne, Suneetha/AAQ-2991-2020
OI Manne, Suneetha/0000-0002-8917-276X
BN 978-1-6654-2642-8
PY 2021
BP 1246
EP 1254
DI 10.1109/I-SMAC52330.2021.9640733
UT WOS:000760875500218
ER

PT C
AU Dong, GL
   Wang, JY
   Sun, J
   Zhang, Y
   Wang, XY
   Dai, T
   Dong, JS
   Wang, XG
AF Dong, Guoliang
   Wang, Jingyi
   Sun, Jun
   Zhang, Yang
   Wang, Xinyu
   Dai, Ting
   Dong, Jin Song
   Wang, Xingen
GP IEEE Comp Soc
TI Towards Interpreting Recurrent Neural Networks through Probabilistic
   Abstraction
SO 2020 35TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE
   ENGINEERING (ASE 2020)
SE IEEE ACM International Conference on Automated Software Engineering
CT 35th IEEE/ACM International Conference on Automated Software Engineering
   (ASE)
CY SEP 21-25, 2020
CL ELECTR NETWORK
SP IEEE, Assoc Comp Machinery, IEEE Comp Soc, Monash Univ, NASA Ames Rese Ctr, IEEE Tech Council Software Engn, ACM SIGAI, ACM Special Interest Grp Software Engn, Deakin Univ
AB Neural networks are becoming a popular tool for solving many real-world problems such as object recognition and machine translation, thanks to its exceptional performance as an end-to-end solution. However, neural networks are complex black-box models, which hinders humans from interpreting and consequently trusting them in making critical decisions. Towards interpreting neural networks, several approaches have been proposed to extract simple deterministic models from neural networks. The results are not encouraging (e.g., low accuracy and limited scalability), fundamentally due to the limited expressiveness of such simple models.
   In this work, we propose an approach to extract probabilistic automata for interpreting an important class of neural networks, i.e., recurrent neural networks. Our work distinguishes itself from existing approaches in two important ways. One is that probability is used to compensate for the loss of expressiveness. This is inspired by the observation that human reasoning is often 'probabilistic'. The other is that we adaptively identify the right level of abstraction so that a simple model is extracted in a request-specific way. We conduct experiments on several real-world datasets using state-of-the-art architectures including GRU and LSTM. The result shows that our approach significantly improves existing approaches in terms of accuracy or scalability. Lastly, we demonstrate the usefulness of the extracted models through detecting adversarial texts.
RI Wang, Jingyi/AHE-1352-2022
OI Wang, Jingyi/0000-0001-7113-7635
SN 1527-1366
BN 978-1-4503-6768-4
PY 2020
BP 499
EP 510
DI 10.1145/3324884.3416592
UT WOS:000651313500043
ER

PT C
AU Hlubik, P
   Spanel, M
   Bohac, M
   Weingartova, L
AF Hlubik, Pavel
   Spanel, Martin
   Bohac, Marek
   Weingartova, Lenka
BE Sojka, P
   Kopecek, I
   Pala, K
   Horak, A
TI Inserting Punctuation to ASR Output in a Real-Time Production
   Environment
SO TEXT, SPEECH, AND DIALOGUE (TSD 2020)
SE Lecture Notes in Artificial Intelligence
CT 23rd Annual International Conference on Text, Speech, and Dialogue (TSD)
CY SEP 08-11, 2020
CL ELECTR NETWORK
SP Masaryk Univ, Fac Informat, Univ W Bohemia Plzen, Fac Appl Sci, Lexical Comp Ltd, IBM Ceska Republika spol s r o, Amazon Alexa
AB The output of a speech recognition system is a continuous stream of words that has to be post-processed in various ways, out of which punctuation insertion is an essential step. Punctuated text is far more comprehensible to the reader, can be used for subtitling, and is necessary for further NLP processing, such as machine translation. In this article, we describe how state-of-the-art results in the field of punctuation restoration can be utilized in a production-ready business environment in the Czech language. A recurrent neural network based on long short-term memory is employed, making use of various features: textual based on pre-trained word embeddings, prosodic (mainly temporal), morphological, noise information, and speaker diarization. All the features except morphological tags were found to improve our baseline system. As we work in a real-time setup, it is not possible to employ information from the future of the word stream, yet we achieve significant improvements using LSTM. The usage of RNN also allows the model to learn longer dependencies than any n-gram-based language model can, which we find essential for the insertion of question marks. The deployment of an RNN-based model thus leads to a relative 22.6% decrease in punctuation errors and improvement in all metrics but one.
OI Weingartova, Lenka/0000-0002-2722-6697
SN 0302-9743
EI 1611-3349
BN 978-3-030-58323-1; 978-3-030-58322-4
PY 2020
VL 12284
BP 418
EP 425
DI 10.1007/978-3-030-58323-1_45
UT WOS:000611543200045
ER

PT J
AU Junaid, S
   Kumar, SC
   Mathez, M
   Hermes, M
   Stone, N
   Shephero, N
   Ebrahim-Zadeh, M
   Tidemand-Lichtenberg, P
   Pedersen, C
AF Junaid, S.
   Kumar, S. Chaitanya
   Mathez, M.
   Hermes, M.
   Stone, N.
   Shephero, N.
   Ebrahim-Zadeh, M.
   Tidemand-Lichtenberg, P.
   Pedersen, C.
TI Video-rate, mid-infrared hyperspectral upconversion imaging
SO OPTICA
AB In this work we demonstrate, to the best of our knowledge, a novel wide field-of-view upconversion system, supporting upconversion of monochromatic mid-infrared (mid-IR) images, e.g., for hyperspectral imaging (HSI). An optical parametric oscillator delivering 20 ps pulses tunable in the 2.3-4 mu m range acts as a monochromatic mid-IR illumination source. A standard CCD camera, in synchronism with the crystal rotation of the upconversion system, acquires in only 2.5 ms the upconverted mid-IR images containing 64 kpixels, thereby eliminating the need for postprocessing. This approach is generic in nature and constitutes a major simplification in realizing video-frame-rate mid-IR monochromatic imaging. A second part of this paper includes a proof-of-principle study on esophageal tissues samples, from a tissue microarray, in the 3-4 mu m wavelength range. The use of mid-IR HSI for investigation of esophageal cancers is particularly promising as it allows for a much faster and possibly more observer-independent workflow than state-ofthe-art histology. Comparing histologically stained sections evaluated by a pathologist to images obtained by either Fourier transform IR or upconversion HSI based on machine learning shows great promise for further work pointing towards clinical translation using the presented mid-IR HSI upconversion system. (C) 2019 Optical Society of America under the terms of the OSA Open Access Publishing Agreement
RI Tidemand-Lichtenberg, Peter/E-6312-2010; Suddapalli, Chaitanya
   Kumar/C-6969-2011
OI Tidemand-Lichtenberg, Peter/0000-0002-4988-0526; Suddapalli, Chaitanya
   Kumar/0000-0002-5164-6130; Pedersen, Christian/0000-0001-7238-489X;
   Ebrahim-Zadeh, Majid/0000-0003-2849-0390; Junaid,
   Saher/0000-0001-9644-0673; Stone, Nick/0000-0001-5603-3731
SN 2334-2536
PD JUN 20
PY 2019
VL 6
IS 6
BP 702
EP 708
DI 10.1364/OPTICA.6.000702
UT WOS:000472154900001
ER

PT J
AU Choi, H
AF Choi, Heeyoul
TI Persistent hidden states and nonlinear transformation for long
   short-term memory
SO NEUROCOMPUTING
AB Recurrent neural networks (RNNs) have been drawing much attention with great success in many applications like speech recognition and neural machine translation. Long short-term memory (LSTM) is one of the most popular RNN units in deep learning applications. LSTM transforms the input and the previous hidden states to the next states with the affine transformation, multiplication operations and a nonlinear activation function, which makes a good data representation for a given task. The affine transformation includes rotation and reflection, which change the semantic or syntactic information of dimensions in the hidden states. However, considering that a model interprets the output sequence of LSTM over the whole input sequence, the dimensions of the states need to keep the same type of semantic or syntactic information regardless of the location in the sequence. In this paper, we propose a simple variant of the LSTM unit, persistent recurrent unit (PRU), where each dimension of hidden states keeps persistent information across time, so that the space keeps the same meaning over the whole sequence. In addition, to improve the nonlinear transformation power, we add a feedforward layer in the PRU structure. In the experiment, we evaluate our proposed methods with three different tasks, and the results confirm that our methods have better performance than the conventional LSTM. (C) 2018 Elsevier B.V. All rights reserved.
OI choi, heeyoul/0000-0002-0855-8725
SN 0925-2312
EI 1872-8286
PD FEB 28
PY 2019
VL 331
BP 458
EP 464
DI 10.1016/j.neucom.2018.11.069
UT WOS:000455210900040
ER

PT J
AU Wu, MY
   Guo, JJ
   Jiang, M
AF Wu Minyang
   Guo Jianjun
   Jiang Ming
TI Calibration Method of Microscopic Three-Dimensional Digital Image
   Correlation System Based on Fixed-Point Rotation
SO ACTA OPTICA SINICA
AB The macroscopic calibration method cannot be applied in the microscopic three-dimensional digital image correlation system due to the small depth of field and the complex optical paths of a stereo microscope. As for this problem, a fixed-point rotation calibration method is proposed, which is suitable for microscopic stereo vision. The mathematical model is established based on the relationship between magnification and depth of field, and thus the maximum angle between calibration plate and XY plane is obtained. In addition, the fixed-point rotation platform is designed to calibrate the calibration plate. The calibration parameters arc optimized by a series of experiments and the inclination angle used for minimizing the overall error of the calibration parameters is obtained. The calibration results show that the main point coordinate error is not larger than 1.8 pixel, the maximum deviation of the relative translation vector of Z component is less than 0.15 mm, and the calibration result tends to be stable when the attitude number is 10 or above. The accuracy of the calibration results is tested by use of a precision displacement platform and the results show that the average relative error of displacement measurement by the proposed method is 2.2% and the mean square error is 0.36 mu m.
SN 0253-2239
PD DEC 10
PY 2018
VL 38
IS 12
AR 1215010
DI 10.3788/AOS201838.1215010
UT WOS:000619509300013
ER

PT J
AU Boloz, L
AF Boloz, Lukasz
TI MODEL TESTS OF LONGWALL SHEARER WITH STRING FEED SYSTEM
SO ARCHIVES OF MINING SCIENCES
AB This article concerns model tests of longwall shearer with string feed system. The introduction outlined the problem of exploitation of thin seams, in particular hard coal seams, and briefly described the construction and operation technology of a single-unit shearer with a string feed system for their exploitation. The problem of modeling of longwall machines with such a feed system was presented, as well as the author's physical and mathematical model of a longwall unitary shearer. Then, for the assumed parameters, model tests were carried out on the dynamics of the longwall shearer together with the string feed system. Comprehensive dynamic tests were carried out for the wall height range from 1.0 m to 1.6 m, length from 180 m to 300 m and taking into account four dimensions of the applied chain. As a result, a number of information was obtained concerning the kinematics of the longwall shearer, its feed along the wall, as well as translations and rotation in relation to particular axes and loadings of particular construction nodes. The most important part are the results of model tests, which together with their interpretation enable verification and optimization of the construction as well as the selection of power of feeder drives and shearer body.
RI Bołoz, Łukasz/AAV-7261-2021; Bołoz, Łukasz/Q-7946-2016
OI Bołoz, Łukasz/0000-0002-7139-0558
SN 0860-7001
EI 1689-0469
PY 2018
VL 63
IS 1
BP 61
EP 74
DI 10.24425/118885
UT WOS:000433094300004
ER

PT C
AU Medrouk, L
   Pappa, A
AF Medrouk, Lisa
   Pappa, Anna
GP IEEE
TI Do Deep Networks Really Need Complex Modules for Multilingual Sentiment
   Polarity Detection and Domain Classification?
SO 2018 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY JUL 08-13, 2018
CL Rio de Janeiro, BRAZIL
AB In this article we introduce an empirical study of multilingual and multi-topic opinion classification. The particularity relies on the reviews that are written in different languages and refer to different but semantically close topics: Restaurants and Hotels. Our key objective is to emphasize the ability of a deep learning model to establish the sentiment polarity of reviews and topics Classification in a multilingual environment without any prior knowledge. For this work, we use unstructured text data, collected from the web, written in French, English and Greek (a less opinion-present language). The incorporate corpus- based input is raw, used without any pre-processing, translation, annotation nor additional knowledge features. For the machine learning approach, we use two different deep neural networks, Convolutional Neural Networks (CONVNETS) and Recurrent Neural Networks (RNNS). The learning model exploits n-gram level information, and achieves high accuracy for sentiment polarity and topics classification according to the experimental tests and results. From our hypothesis, we argue that the multilingual environment composed of reviews in semantically close domains, does not impact the network performance, and lead us to deduce that semantic features extraction with ConvNets and RNNs are language and context independent. Following these results, we tend to promote the inception of simple yet powerful approach for feeding deep networks in multilingual context.
OI Pappa, Anna/0000-0003-2447-4078
SN 2161-4393
BN 978-1-5090-6014-6
PY 2018
BP 331
EP 336
UT WOS:000585967400045
ER

PT J
AU Sulubacak, U
   Eryigit, G
AF Sulubacak, Umut
   Eryigit, Gulsen
TI Implementing universal dependency, morphology, and multiword expression
   annotation standards for Turkish language processing
SO TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES
AB Released only a year ago as the outputs of a research project ("Parsing Web 2.0 Sentences", supported in part by a TUBITAK 1001 grant (No. 112E276) and a part of the ICT COST Action PARSEME (IC1207)), IMST and IWT are currently the most comprehensive Turkish dependency treebanks in the literature. This article introduces the final states of our treebanks, as well as a newly integrated hierarchical categorization of the multiheaded dependencies and their organization in an exclusive deep dependency layer in the treebanks. It also presents the adaptation of recent studies on standardizing multiword expression and named entity annotation schemes for the Turkish language and integration of benchmark annotations into the dependency layers of our treebanks and the mapping of the treebanks to the latest Universal Dependencies (v2.0) standard, ensuring further compliance with rising universal annotation trends. In addition to significantly boosting the universal recognition of Turkish treebanks, our recent efforts have shown an improvement in their syntactic parsing performance (up to 77.8%/82.8% LAS and 84.0%/87.9% UAS for IMST/IWT, respectively). The final states of the treebanks are expected to be more suited to different natural language processing tasks, such as named entity recognition, multiword expression detection, transfer-based machine translation, semantic parsing, and semantic role labeling.
RI Eryiğit, Gülşen/O-4106-2016
OI Eryiğit, Gülşen/0000-0003-4607-7305
SN 1300-0632
EI 1303-6203
PY 2018
VL 26
IS 3
BP 1662
EP 1672
DI 10.3906/elk-1706-81
UT WOS:000434009500043
ER

PT J
AU Sung, YT
   Lin, WC
   Dyson, SB
   Chang, KE
   Chen, YC
AF Sung, Yao-Ting
   Lin, Wei-Chun
   Dyson, Scott Benjamin
   Chang, Kuo-En
   Chen, Yu-Chia
TI Leveling L2 Texts Through Readability: Combining Multilevel Linguistic
   Features with the CEFR
SO MODERN LANGUAGE JOURNAL
AB Selecting appropriate texts for L2 (second/foreign language) learners is an important approach to enhancing motivation and, by extension, learning. There is currently no tool for classifying foreign language texts according to a language proficiency framework, which makes it difficult for students and educators to determine the precise difficulty/complexity levels of an unclassified text. Taking the Chinese language as an example, this study aimed to create a readability assessment system, called the Chinese Readability Index Explorer for Chinese as a Foreign Language (CRIE-CFL), in order to levelthat is, to sort by proficiency leveltexts that will be used for instructional purposes. The framework of choice in this project is the Common European Framework of Reference (CEFR). A team of expert CFL teachers first classified 1,578 CFL texts into their appropriate CEFR levels. A set of 30 CFL readability features was then developed or drawn from previous research, and sorted according to importance using F-scores. In addition, a support vector machine model was trained by sequentially integrating the features into the model to optimize accuracy. The empirical evaluation of CRIE-CFL revealed average exact- and adjacent-level accuracies of 74.97% and 99.62%, respectively, for predicting the expert classification of a text. The functionalities of CRIE-CFL are introduced and discussed.
SN 0026-7902
EI 1540-4781
PD SUM
PY 2015
VL 99
IS 2
BP 371
EP 391
DI 10.1111/modl.12213
UT WOS:000358691800009
ER

PT J
AU HELMAN, D
   JAJA, J
AF HELMAN, D
   JAJA, J
TI EFFICIENT IMAGE-PROCESSING ALGORITHMS ON THE SCAN LINE ARRAY PROCESSOR
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB We develop efficient algorithms for low and intermediate level images processing on the scan line array processor, a SIMD machine consisting of a linear array of cells that processes images in a scan line fashion. For low level processing, we present algorithms for block DFT, block DCT, convolution, template matching, shrinking, and expanding which run in real-time. By real-time, we mean that, if the required processing is based on neighborhoods of size m x m, then the output lines are generated at a rate of O(m) operations per line and a latency of O(m) scan lines, which is the best that can be achieved on this model. We also develop an algorithm for median filtering which runs in almost real-time at a cost of O(m log m) time per scan line and a latency of [m/2] scan lines. For intermediate level processing, we present optimal algorithms for translation, histogram computation, scaling, and rotation. We also develop efficient algorithms for labelling the connected components and determining the convex hulls of multiple figures which run in O(nlog n) and O(n log(2)n) time, respectively. The latter algorithms are significantly simpler and easier to implement than those already reported in the literature for linear arrays.
SN 0162-8828
PD JAN
PY 1995
VL 17
IS 1
BP 47
EP 56
DI 10.1109/34.368153
UT WOS:A1995QB39400005
ER

PT J
AU White, NM
AF White, Nathan M.
TI The Hmong Medical Corpus: a biomedical corpus for a minority language
SO LANGUAGE RESOURCES AND EVALUATION
AB Biomedical communication is an area that increasingly benefits from natural language processing (NLP) work. Biomedical named entity recognition (NER) in particular provides a foundation for advanced NLP applications, such as automated medical question-answering and translation services. However, while a large body of biomedical documents are available in an array of languages, most work in biomedical NER remains in English, with the remainder in official national or regional languages. Minority languages so far remain an underexplored area. The Hmong language, a minority language with sizable populations in several countries and without official status anywhere, represents an exceptional challenge for effective communication in medical contexts. Taking advantage of the large number of government-produced medical information documents in Hmong, we have developed the first named entity-annotated biomedical corpus for a resource-poor minority language. The Hmong Medical Corpus contains 100,535 tokens with 4554 named entities (NEs) of three UMLS semantic types: diseases/syndromes, signs/symptoms, and body parts/organs/organ components. Furthermore, a subset of the corpus is annotated for word position and parts of speech, representing the first such gold-standard dataset publicly available for Hmong. The methodology presented provides a readily reproducible approach for the creation of biomedical NE-annotated corpora for other resource-poor languages.
RI White, Nathan M./AAZ-1385-2021
OI White, Nathan M./0000-0003-4648-8040
SN 1574-020X
EI 1574-0218
PD DEC
PY 2022
VL 56
IS 4
BP 1315
EP 1332
DI 10.1007/s10579-022-09596-2
EA JUL 2022
UT WOS:000825892300001
ER

PT C
AU Adewumi, T
   Vadoodi, R
   Tripathy, A
   Nikolaidou, K
   Liwicki, F
   Liwicki, M
AF Adewumi, Tosin
   Vadoodi, Roshanak
   Tripathy, Aparajita
   Nikolaidou, Konstantina
   Liwicki, Foteini
   Liwicki, Marcus
BA Mariani, J
BF Mariani, J
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mazo, H
   Odijk, H
   Piperidis, S
TI Potential Idiomatic Expression (PIE)-English: Corpus for Classes of
   Idioms
SO LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION
CT 13th International Conference on Language Resources and Evaluation
   (LREC)
CY JUN 20-25, 2022
CL Marseille, FRANCE
SP Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur
AB We present a fairly large, Potential Idiomatic Expression (PIE) dataset for Natural Language Processing (NLP) in English. The challenges with NLP systems with regards to tasks such as Machine Translation (MT), word sense disambiguation (WSD) and information retrieval make it imperative to have a labelled idioms dataset with classes such as it is in this work. To the best of the authors' knowledge, this is the first idioms corpus with classes of idioms beyond the literal and the general idioms classification. In particular, the following classes are labelled in the dataset: metaphor, simile, euphemism, parallelism, personification, oxymoron, paradox, hyperbole, irony and literal. We obtain an overall inter-annotator agreement (IAA) score, between two independent annotators, of 88.89%. Many past efforts have been limited in the corpus size and classes of samples but this dataset contains over 20,100 samples with almost 1,200 cases of idioms (with their meanings) from 10 classes (or senses). The corpus may also be extended by researchers to meet specific needs. The corpus has part of speech (PoS) tagging from the NLTK library. Classification experiments performed on the corpus to obtain a baseline and comparison among three common models, including the state-of-the-art (SoTA) BERT model, give good results. We also make publicly available the corpus and the relevant codes for working with it for NLP tasks.
BN 979-10-95546-72-6
PY 2022
BP 689
EP 696
UT WOS:000889371700072
ER

PT C
AU Lennon, M
   Drenkow, N
   Burlina, P
AF Lennon, Max
   Drenkow, Nathan
   Burlina, Phil
GP IEEE Comp Soc
TI Patch Attack Invariance: How Sensitive are Patch Attacks to 3D Pose?
SO 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS
   (ICCVW 2021)
SE IEEE International Conference on Computer Vision Workshops
CT 18th IEEE/CVF International Conference on Computer Vision (ICCV)
CY OCT 11-17, 2021
CL ELECTR NETWORK
SP IEEE, CVF, IEEE Comp Soc
AB Perturbation-based attacks, while not physically realizable, have been the main emphasis of adversarial machine learning (ML) research. Patch-based attacks by contrast are physically realizable, yet most work has focused on 2D domain with recent forays into 3D. Characterizing the robustness properties of patch attacks and their invariance to 3D pose is important, yet not fully elucidated, and is the focus of this paper. To this end, several contributions are made here: A) we develop a new metric called mean Attack Success over Transformations (mAST) to evaluate patch attack robustness and invariance; and B), we systematically assess robustness of patch attacks to 3D position and orientation for various conditions; in particular, we conduct a sensitivity analysis which provides important qualitative insights into attack effectiveness as a function of the 3D pose of a patch relative to the camera (rotation, translation) and sets forth some properties for patch attack 3D invariance; and C), we draw novel qualitative conclusions including: 1) we demonstrate that for some 3D transformations, namely rotation and loom, increasing the training distribution support yields an increase in patch success over the full range at test time. 2) We provide new insights into the existence of a fundamental cutoff limit in patch attack effectiveness that depends on the extent of out-of-plane rotation angles. These findings should collectively guide future design of 3D patch attacks and defenses.
SN 2473-9936
BN 978-1-6654-0191-3
PY 2021
BP 112
EP 121
DI 10.1109/ICCVW54120.2021.00018
UT WOS:000739651100012
ER

PT J
AU Imam, AT
   Alnsour, AJ
AF Imam, Ayad Tareq
   Alnsour, Ayman Jameel
TI The Use of Natural Language Processing Approach for Converting Pseudo
   Code to C# Code
SO JOURNAL OF INTELLIGENT SYSTEMS
AB Although current computer-aided software engineering tools support developers in composing a program, there is no doubt that more flexible supportive tools are needed to address the increases in the complexity of programs. This need can be met by automating the intellectual activities that are carried out by humans when composing a program. This paper aims to automate the composition of a programming language code from pseudocode, which is viewed here as a translation process for a natural language text, as pseudocode is a formatted text in natural English language. Based on this view, a new automatic code generator is developed that can convert pseudocode to C# programming language code. This new automatic code generator (ACG), which is called CodeComposer, uses natural language processing (NLP) techniques such as verb classification, thematic roles, and semantic role labeling (SRL) to analyze the pseudocode. The resulting analysis of linguistic information from these techniques is used by a semantic rule-based mapping machine to perform the composition process. CodeComposer can be viewed as an intelligent computer-aided software engineering (I_CASE) tool. An evaluation of the accuracy of CodeComposer using a binomial technique shows that it has a precision of 88%, a recall of 91%, and an F-measure of 89%.
RI Imam, Ayad Tareq/AAB-3970-2019
OI Imam, Ayad Tareq/0000-0002-9942-4772
SN 0334-1860
EI 2191-026X
PD JAN
PY 2020
VL 29
IS 1
BP 1388
EP 1407
DI 10.1515/jisys-2018-0291
UT WOS:000504634100093
ER

PT C
AU Dalvi, F
   Durrani, N
   Sajjad, H
   Belinkov, Y
   Bau, A
   Glass, J
AF Dalvi, Fahim
   Durrani, Nadir
   Sajjad, Hassan
   Belinkov, Yonatan
   Bau, Anthony
   Glass, James
GP AAAI
TI What Is One Grain of Sand in the Desert? Analyzing Individual Neurons in
   Deep NLP Models
SO THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 33rd AAAI Conference on Artificial Intelligence / 31st Innovative
   Applications of Artificial Intelligence Conference / 9th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY JAN 27-FEB 01, 2019
CL Honolulu, HI
SP Assoc Advancement Artificial Intelligence
AB Despite the remarkable evolution of deep neural networks in natural language processing (NLP), their interpretability remains a challenge. Previous work largely focused on what these models learn at the representation level. We break this analysis down further and study individual dimensions (neurons) in the vector representation learned by end-to-end neural models in NLP tasks. We propose two methods: Linguistic Correlation Analysis, based on a supervised method to extract the most relevant neurons with respect to an extrinsic task, and Cross-model Correlation Analysis, an unsupervised method to extract salient neurons w.r.t. the model itself. We evaluate the effectiveness of our techniques by ablating the identified neurons and reevaluating the network's performance for two tasks: neural machine translation (NMT) and neural language modeling (NLM). We further present a comprehensive analysis of neurons with the aim to address the following questions: i) how localized or distributed are different linguistic properties in the models? ii) are certain neurons exclusive to some properties and not others? iii) is the information more or less distributed in NMT vs. NLM? and iv) how important are the neurons identified through the linguistic correlation method to the overall task? Our code is publicly available as part of the NeuroX toolkit (Dalvi et al. 2019a). This paper is a non-archived version of the paper published at AAAI (Dalvi et al. 2019b).
OI Dalvi, Fahim/0000-0003-1183-7837
SN 2159-5399
EI 2374-3468
BN 978-1-57735-809-1
PY 2019
BP 6309
EP 6317
UT WOS:000486572500103
ER

PT C
AU Tumino, D
   Adamo, G
   Alaimo, A
AF Tumino, Davide
   Adamo, Gabriele
   Alaimo, Andrea
BE Kurniawan, D
   Nor, FM
TI An applicative method to evaluate the geometric correspondence of a
   manufactured sweep object to its CAD model by means of point cloud
   manipulation
SO 2ND INTERNATIONAL MATERIALS, INDUSTRIAL, AND MANUFACTURING ENGINEERING
   CONFERENCE, MIMEC2015
SE Procedia Manufacturing
CT 2nd International Materials, Industrial, and Manufacturing Engineering
   Conference, MIMEC2015
CY FEB 04-06, 2015
CL Bali, INDONESIA
AB This paper presents an applicative method for evaluating the global axis deformation of a sweep object caused by the manufacturing process with respect to its ideal CAD model. Object and CAD shapes are given in form of point clouds, the former derived from a laser-scanning measurement, the latter from sampling the original surface by a dense and uniform point grid. After an initial rigid registration, approximated centroidal axes of both shapes are extracted, compared and processed in order to evaluate macroscopical translation errors occurring in any scanned object's section.
   This method has been applied and tested to the analysis of a helical Darrieus blade prototype, parametrically designed and modelled with McNeel Rhinoceros and Grasshopper software, manufactured with a three-axes CNC machine and reinforced by a carbon fibre composite laminate. The point cloud obtained from the subsequent laser scanning has been processed and compared to the original NURBS model in order to build the global contour map of the mutual difference. The application of this procedure is able to check the conformity of the manufactured airfoil to the theoretical one and, therefore, to establish the efficiency of the final prototype of the blade turbine. (C) 2015 The Authors. Published by Elsevier B.V.
RI Tumino, Davide/AAB-9066-2020
OI alaimo, andrea/0000-0002-6691-6965
SN 2351-9789
PY 2015
VL 2
BP 258
EP 262
DI 10.1016/j.promfg.2015.07.045
UT WOS:000380490700045
ER

PT J
AU Hwang, YS
   Lin, TY
   Chang, RG
AF Hwang, Yuan-Shin
   Lin, Tzong-Yen
   Chang, Rong-Guey
TI DisIRer: Converting a Retargetable Compiler into a Multiplatform Binary
   Translator
SO ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION
AB This article proposes an alternative yet effective way of constructing a multiplatform binary translator, by converting a retargetable compiler into a binary translator. The rationale is that a retargetable compiler usually parses source programs into an Intermediate Representation (IR), and then translates IR into object code of different targets after performing analysis and optimizations. Specifically, the mechanism of code generation for multiple platforms from IR is already in place, and the missing link of building a multiplatform binary translator is a tool to transform binary programs back into IR. In order to fill in this missing link, this article presents a tool, called the disIRer. Just as a translator from machine language to assembly language is called a disassembler, a tool that translates executable binary programs to IR is called here a disIRer. The unique feature of this approach is that the retargetability of the binary translator is inherited directly from the retargetable compiler. A prototype multiplatform binary translator has been implemented upon GCC (the GNU Compiler Collection). DisIRer first converts binary programs back into GCC IR (Intermediate Representation), and afterward the GCC backend translates the IR to target binary programs of specified platforms. Experimental results show that x86 binary programs can be translated by this technique into ARM and Alpha binaries with reasonable code density and quality.
SN 1544-3566
EI 1544-3973
PD DEC
PY 2010
VL 7
IS 4
AR 18
DI 10.1145/1880043.1880045
UT WOS:000286637600002
ER

PT J
AU Zhou, ML
   Cai, M
   Li, G
   Li, M
AF Zhou, Mingle
   Cai, Ming
   Li, Gang
   Li, Min
TI An End-to-End Formula Recognition Method Integrated Attention Mechanism
SO MATHEMATICS
AB Formula recognition is widely used in document intelligent processing, which can significantly shorten the time for mathematical formula input, but the accuracy of traditional methods could be higher. In order to solve the complexity of formula input, an end-to-end encoder-decoder framework with an attention mechanism is proposed that converts formulas in pictures into LaTeX sequences. The Vision Transformer (VIT) is employed as the encoder to convert the original input picture into a set of semantic vectors. Due to the two-dimensional nature of mathematical formula, in order to accurately capture the formula characters' relative position and spatial characteristics, positional embedding is introduced to ensure the uniqueness of the character position. The decoder adopts the attention-based Transformer, in which the input vector is translated into the target LaTeX character. The model adopts joint codec training and Cross-Entropy as a loss function, which is evaluated on the im2latex-100k dataset and CROHME 2014. The experiment shows that BLEU reaches 92.11, MED is 0.90, and Exact Match(EM) is 0.62 on the im2latex-100k dataset. This paper's contribution is to introduce machine translation to formula recognition and realize the end-to-end transformation from the trajectory point sequence of formula to latex sequence, providing a new idea of formula recognition based on deep learning.
OI Li, Gang/0000-0002-7896-4833
EI 2227-7390
PD JAN
PY 2023
VL 11
IS 1
AR 177
DI 10.3390/math11010177
UT WOS:000908635800001
ER

PT J
AU Kim, T
   Kim, S
   Ryu, D
   Cho, JHY
AF Kim, Taeyoung
   Kim, Suntae
   Ryu, Duksan
   Cho, Jaehyuk
TI Deep Tasks Summarization for Comprehending Mixed Tasks in a Commit
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
AB In Version Control System (VCS), a developer frequently uploads multiple tasks such as adding features, code refactoring, and fixing bugs, into a single commit and crumbles each task's summary when writing a commit message. It causes code readers to feel challenged in understanding the developer's past tasks within the commit history. To resolve this issue, we propose an automatic approach to generating a task summary to help comprehend multiple mixed tasks in a commit and developed tool support named Task summary Generator (TsGen). In our approach, we use the commit with a single task as input and identify the task to sort its elements sequentially. Then we generate feature vectors from each sorted element to train the Neural Machine Translation (NMT) model. Based on the trained NMT model, we generate the feature vector from each task of a commit with multiple tasks and put each of them into the model to provide the task summary. In evaluation, we compared the performance of TsGen with two existing methods for nine open-source projects. As a result, TsGen outperformed CoDiSum and Jiang's NMT by 52.08% and 28.07% in BiLingual Evaluation Understudy (BLEU) scores. In addition, the human evaluation was carried out to demonstrate that TsGen helps understand mixed tasks in a commit and gained a 0.27 higher preference than the actual commit message.
SN 0218-1940
EI 1793-6403
PD FEB
PY 2023
VL 33
IS 02
BP 207
EP 229
DI 10.1142/S0218194022500711
EA DEC 2022
UT WOS:000896543700001
ER

PT J
AU Wei, SE
AF Emmy Wei, S.
TI Aliasing-Free Nonlinear Signal Processing Using Implicitly Defined
   Functions
SO IEEE ACCESS
AB Digital signal processing relies on the Nyquist-Shannon sampling theorem that applies to and requires a continuous signal with limited bandwidth. However, many systems or networks of signal processing involve nonlinear functions, which could generate new frequency components beyond the original bandwidth and lead to aliasing. Indeed, aliasing-induced shift variance has long been a nuisance and unsolved problem in convolutional neural networks and has recently been found to severely impair the performance of machine learning applications. The same problem exists in other fields such as computational lithography. In this paper, a new method and algorithms are introduced to solve the problem of aliasing induced by nonlinear functions involving operations other than linear convolutions and pointwise multiplications. Said new method and algorithms employ implicitly defined functions that are implemented via iterations of polynomial operations so that aliasing is completely avoided by upsampling signals before polynomial operations and limiting signal spectra before downsampling. Theoretical analyses and exemplary algorithms are presented to implement nonlinear functions commonly used in signal processing networks. In particular, exemplary embodiments and numerical experiments are reported to illustrate and verify aliasing-free operations of Wiener-Pade approximants, which are already universal in their ability to approximate any continuous activation functions to the desired accuracy.
OI Wei, Emmy/0000-0003-1314-5658
SN 2169-3536
PY 2022
VL 10
BP 76281
EP 76295
DI 10.1109/ACCESS.2022.3192387
UT WOS:000831084700001
ER

PT J
AU Thorne, J
   Yazdani, M
   Saeidi, M
   Silvestri, F
   Riedel, S
   Halevy, A
AF Thorne, James
   Yazdani, Majid
   Saeidi, Marzieh
   Silvestri, Fabrizio
   Riedel, Sebastian
   Halevy, Alon
TI From Natural Language Processing to Neural Databases
SO PROCEEDINGS OF THE VLDB ENDOWMENT
AB In recent years, neural networks have shown impressive performance gains on long-standing AI problems, such as answering queries from text and machine translation. These advances raise the question of whether neural nets can be used at the core of query processing to derive answers from facts, even when the facts are expressed in natural language. If so, it is conceivable that we could relax the fundamental assumption of database management, namely, that our data is represented as fields of a pre-defined schema. Furthermore, such technology would enable combining information from text, images, and structured data seamlessly.
   This paper introduces neural databases, a class of systems that use NLP transformers as localized answer derivation engines. We ground the vision in NEURALDB, a system for querying facts represented as short natural language sentences. We demonstrate that recent natural language processing models, specifically transformers, can answer select-project-join queries if they are given a set of relevant facts. However, they cannot scale to non-trivial databases nor answer set-based and aggregation queries. Based on these insights, we identify specific research challenges that are needed to build neural databases. Some of the challenges require drawing upon the rich literature in data management, and others pose new research opportunities to the NLP community. Finally, we show that with preliminary solutions, NEURALDB can already answer queries over thousands of sentences with very high accuracy.
RI Thorne, James/AFO-1421-2022
OI Thorne, James/0000-0001-9190-1418
SN 2150-8097
PD FEB
PY 2021
VL 14
IS 6
BP 1033
EP 1039
DI 10.14778/3447689.3447706
UT WOS:000658496900016
ER

PT J
AU Xu, CL
   Wang, H
   Wu, SL
   Lin, ZW
AF Xu, Chunlin
   Wang, Hui
   Wu, Shengli
   Lin, Zhiwei
TI TreeLSTM with tag-aware hypernetwork for sentence representation
SO NEUROCOMPUTING
AB Tree-structured neural networks, such as TreeLSTM and its variants, have proven effective for learning semantic representations of sentences, which are useful for a variety of tasks in natural language processing such as text categorisation, text semantic matching and machine translation. These neural network models take as inputs parse trees of sentences, which are generated by a language parser. However, most existing tree-structured neural network models lack the ability of distinguishing different syntactic compositions, thus the expressive power of these models is limited. Moreover, the syntactic knowledge provided by Part-of-Speech tags in a parse tree has not been fully utilised in existing tree-structured neural network models. It is expected that such syntactic knowledge should help distinguish syntactic compositions, so should result in better semantic representation. This paper proposes a novel neural network model, TagHyperTreeLSTM, which contains two components, a tag-aware hypernetwork and a sentence encoder. The tag-aware hypernetwork, which accepts tags as inputs, generates the parameters of the sentence encoder dynamically in order to distinguish different syntactic compositions. The sentence encoder, which accepts words as inputs, generates the final sentence representation. Experimental results show that the proposed model achieves superior or competitive performance in text classification and text semantic matching based on six benchmark datasets when compared against previous tree-structured models.
   CO 2020 Elsevier B.V. All rights reserved.
RI wang, hui/HSG-6135-2023; Wang, Hui/HMU-9512-2023
OI Wang, Hui/0000-0003-2633-6015
SN 0925-2312
EI 1872-8286
PD APR 28
PY 2021
VL 434
BP 11
EP 20
DI 10.1016/j.neucom.2020.12.074
EA JAN 2021
UT WOS:000631524900001
ER

PT J
AU Cheng, YJ
   Zhou, B
   Lu, C
   Yang, C
AF Cheng, Yujie
   Zhou, Bo
   Lu, Chen
   Yang, Chao
TI Fault Diagnosis for Rolling Bearings under Variable Conditions Based on
   Visual Cognition
SO MATERIALS
AB Fault diagnosis for rolling bearings has attracted increasing attention in recent years. However, few studies have focused on fault diagnosis for rolling bearings under variable conditions. This paper introduces a fault diagnosis method for rolling bearings under variable conditions based on visual cognition. The proposed method includes the following steps. First, the vibration signal data are transformed into a recurrence plot (RP), which is a two-dimensional image. Then, inspired by the visual invariance characteristic of the human visual system (HVS), we utilize speed up robust feature to extract fault features from the two-dimensional RP and generate a 64-dimensional feature vector, which is invariant to image translation, rotation, scaling variation, etc. Third, based on the manifold perception characteristic of HVS, isometric mapping, a manifold learning method that can reflect the intrinsic manifold embedded in the high-dimensional space, is employed to obtain a low-dimensional feature vector. Finally, a classical classification method, support vector machine, is utilized to realize fault diagnosis. Verification data were collected from Case Western Reserve University Bearing Data Center, and the experimental result indicates that the proposed fault diagnosis method based on visual cognition is highly effective for rolling bearings under variable conditions, thus providing a promising approach from the cognitive computing field.
RI Lu, Chen/B-6310-2016
EI 1996-1944
PD JUN
PY 2017
VL 10
IS 6
AR 582
DI 10.3390/ma10060582
UT WOS:000404415000016
PM 28772943
ER

PT J
AU Wang, XJ
   Zhang, L
   Ma, WY
AF Wang, Xin-Jing
   Zhang, Lei
   Ma, Wei-Ying
TI Duplicate-Search-Based Image Annotation Using Web-Scale Data
SO PROCEEDINGS OF THE IEEE
AB Easy photo-taking and photo-sharing today make image an increasingly important type of media in people's everyday life, which arouses a growing demand for a practical image understanding technique. Traditional computer vision or machine learning methods which learn models based on a set of training data are still in the stage of tackling hundreds of object categories. Such a scale is far from practical usage. In recent years, the technique of search-based image annotation on a large-scale data set has demonstrated great success. Rather than directly mapping visual features to texts which is inevitably hindered by the semantic gap, it understands the content of an image by propagating labels of its similar images in a large-scale data set. Since similarity search is performed among homogenous data, the difficulty is greatly reduced. This paper summarizes the extensive work on web image annotation using the large-scale metadata and social information available on the Web, and introduces the Arista system, which is a nonparametric image annotation platform built upon two billion web images. We propose a highly efficient and scalable duplicate-search technique so that the Arista system can be deployed on a few servers. A few interesting applications such as building large-scale celebrity face database and text-to-image translation are also presented in this paper.
RI Wang, Xin-Jing/C-4505-2014
SN 0018-9219
EI 1558-2256
PD SEP
PY 2012
VL 100
IS 9
SI SI
BP 2705
EP 2721
DI 10.1109/JPROC.2012.2193109
UT WOS:000307892900010
ER

PT J
AU Rakhra, M
   Bhargava, A
   Bhargava, D
   Singh, R
   Bhanot, A
   Rahmani, AW
AF Rakhra, Manik
   Bhargava, Amitabh
   Bhargava, Deepshikha
   Singh, Ramandeep
   Bhanot, Astha
   Rahmani, Abdul Wahab
TI Implementing Machine Learning for Supply-Demand Shifts and Price Impacts
   in Farmer Market for Tool and Equipment Sharing
SO JOURNAL OF FOOD QUALITY
AB Several industries have recently seen the replacement of human labor by automated machinery and equipment. Across the globe, farmers' attitudes on the use of technology in agriculture are divergent. However, although some people are excited and ready to embrace technology, others are cautious and wary of trying new technologies for the first time. The third category is particularly prevalent in underdeveloped nations such as India, owing to a lack of competence, a lack of effective translation, and most crucially, a lack of financial resources. It is fruitless for the government to attempt to resolve these difficulties due to the fact that they do not take into consideration the changing circumstances and input needs of each agricultural group. Smart Tillage is a cutting-edge framework that was developed to solve the challenges listed above. In India, a decision-based smart engine for the rental and sharing of tools and equipment has been developed, which leverages machine learning methods to proceed towards a selection of tools and equipment. The option is entirely reliant on a variety of input variables, including crop kind, harvest time/month, crop equipment needed, harvest type, and the amount of money available for rental. Additionally, an ideal recommendation engine driven by content and collaborative-based filtering will provide the farmer's requirements depending on their requirements. In terms of escalation, the proposals would be cost-effective and excellent since they would need little changes in training, technique improvements, and resource management via a new rent-share model similar to that used by Uber. In this work, demand and supply algorithms are used to define market equilibrium, and the results are shown in graphs. This includes discussion of a variety of demand and supply parameters, their impact on market equilibrium prices and quantities, and their effect on shifting demand and supply curves. The many sorts of elasticities (demand, cross-price, supply, income, and so on) are examined, as well as the ramifications for pricing systems that may result from these elasticities.
RI Bhargava, Deepshikha/O-6307-2014
OI Bhargava, Deepshikha/0000-0001-7017-1372; rakhra,
   manik/0000-0003-1680-6992; Singh, Ramandeep/0000-0001-5775-7993;
   Bhargava, Amitabh/0000-0002-0468-8549
SN 0146-9428
EI 1745-4557
PD MAR 15
PY 2022
VL 2022
AR 4496449
DI 10.1155/2022/4496449
UT WOS:000787244900001
ER

PT J
AU Orloci, L
AF Orloci, L.
TI Vegetation displacement issues and transition statistics in climate
   warming cycle
SO COMMUNITY ECOLOGY
AB Scepticism largely deflated, and the denial machine's intent to mislead unmasked, climate warming owing to anthropic carbon emission is now seen by most as an ongoing process. When compared to the historic rates, the predicted warming rate and concomitant rates of biotic response should be considered simply colossal. This is the point about which the present paper gives insight based on numerical analyses. The Vostok temperature series, its different transforms, and palynological spectra from global sites are the basic data. These are marshalled in support of the paper's main proposition that the thermal effect on the vegetation depends not only on the rate of troposphere warming or cooling, but very much on the velocity of onset and length of duration. The main text begins with a definition of terms, followed by a short essay tracing how the conceptualisation of the climate warming paradigm evolved from initial scepticism to acceptance as a reality. The technical sections treat the conversion problem from Vostok inversion-layer temperature differences to global mean rates. It offers frequency distributions for historic warming/cooling rates, and explains the latitude dependence of the translation of the rates into local thermal flux. Presentation of examples of historic thermal events and the effect on the global vegetation close the main text. Statistical analyses are involved based on a novel methodology. The methods are concerned with formation migration rates, metrics of compositional transition velocity and acceleration, long-term variation in the representation of specific taxa in palynological spectra, taxon traits and taxon plasticity, and hotspots detection in compositional transitions. The palynological data are examined in synchrony with historic trends in the troposphere's Late Quaternary temperature history. Owing to the broad topical contents, the paper adapts a modular structure of presentation which requires the evaluation and interpretation of the results where they are presented. An overview is given at the end with emphasis on the general trends.
SN 1585-8553
EI 1588-2756
PD JUN
PY 2008
VL 9
IS 1
BP 83
EP 98
DI 10.1556/ComEc.9.2008.1.10
UT WOS:000258174100010
ER

PT J
AU Mahany, A
   Khaled, H
   Elmitwally, NS
   Aljohani, N
   Ghoniemy, S
AF Mahany, Ahmed
   Khaled, Heba
   Elmitwally, Nouh Sabri
   Aljohani, Naif
   Ghoniemy, Said
TI Negation and Speculation in NLP: A Survey, Corpora, Methods, and
   Applications
SO APPLIED SCIENCES-BASEL
AB Negation and speculation are universal linguistic phenomena that affect the performance of Natural Language Processing (NLP) applications, such as those for opinion mining and information retrieval, especially in biomedical data. In this article, we review the corpora annotated with negation and speculation in various natural languages and domains. Furthermore, we discuss the ongoing research into recent rule-based, supervised, and transfer learning techniques for the detection of negating and speculative content. Many English corpora for various domains are now annotated with negation and speculation; moreover, the availability of annotated corpora in other languages has started to increase. However, this growth is insufficient to address these important phenomena in languages with limited resources. The use of cross-lingual models and translation of the well-known languages are acceptable alternatives. We also highlight the lack of consistent annotation guidelines and the shortcomings of the existing techniques, and suggest alternatives that may speed up progress in this research direction. Adding more syntactic features may alleviate the limitations of the existing techniques, such as cue ambiguity and detecting the discontinuous scopes. In some NLP applications, inclusion of a system that is negation- and speculation-aware improves performance, yet this aspect is still not addressed or considered an essential step.
RI Ghoniemy, Said/O-5262-2014
OI Ghoniemy, Said/0000-0002-7436-956X; Mahany, Ahmed/0000-0001-5133-6995;
   Elmitwally, Nouh/0000-0002-3030-9696
EI 2076-3417
PD MAY
PY 2022
VL 12
IS 10
AR 5209
DI 10.3390/app12105209
UT WOS:000802440700001
ER

PT J
AU Shi, XJ
   Liu, T
   Han, X
AF Shi, Xiaojing
   Liu, Tao
   Han, Xie
TI Improved Iterative Closest Point(ICP) 3D point cloud registration
   algorithm based on point cloud filtering and adaptive fireworks for
   coarse registration
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
AB Aiming at the problem of long computation time and poor registration accuracy in the current three-dimensional point cloud registration problem, this paper presents a k-dimensional Tree(KD-tree) improved ICP algorithm(KD-tree_ICP) that combines point cloud filtering and adaptive fireworks algorithms for coarse registration. On the basis of the typical KD-tree improved ICP algorithm, the point cloud filtering process and adaptive firework coarse registration process are added. Firstly, the point cloud data acquired by the 3D laser scanner is filtered. And then the adaptive fireworks algorithm is used to perform coarse registration on the filtered point cloud data. Next, the KD-tree_ICP algorithm is used to perform accurate registration on the basis of coarse registration, and the obtained translation and rotation relations are applied to the original point cloud data to obtain the result after registration. Finally, 3D point clouds of physical models of five statues are used for experimental verification, including error analysis, stability analysis and comparison with other algorithms. The experimental results show that the method proposed in this paper has greatly improved the calculation speed and accuracy, and the algorithm is stable and reliable, which can also be applied to the reconstruction of 3D building models, restoration of cultural relics, precision machining and other fields.
SN 0143-1161
EI 1366-5901
PD APR 17
PY 2020
VL 41
IS 8
BP 3197
EP 3220
DI 10.1080/01431161.2019.1701211
UT WOS:000505127300001
ER

PT C
AU Yang, XX
   Yan, BN
   Li, H
   Chen, YR
AF Yang, Xiaoxuan
   Yan, Bonan
   Li, Hai
   Chen, Yiran
GP IEEE
TI RETRANSFORMER: ReRAM-based Processing-in-Memory Architecture for
   Transformer Acceleration
SO 2020 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED-DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
CT 39th IEEE/ACM International Conference On Computer Aided Design (ICCAD)
CY NOV 02-05, 2020
CL ELECTR NETWORK
SP IEEE, Assoc Comp Machinery, IEEE Circuits & Syst Soc, IEEE Council Elect Design Automat, ACM SIGDA, IEEE Electron Devices Soc
AB Transformer has emerged as a popular deep neural network (DNN) model for Neural Language Processing (NLP) applications and demonstrated excellent performance in neural machine translation, entity recognition, etc. However, its scaled dot-product attention mechanism in auto-regressive decoder brings a performance bottleneck during inference. Transformer is also computationally and memory intensive and demands for a hardware acceleration solution. Although researchers have successfully applied ReRAM-based Processing-in-Memory (PIM) to accelerate convolutional neural networks (CNNs) and recurrent neural networks (RNNs), the unique computation process of the scaled dot-product attention in Transformer makes it difficult to directly apply these designs. Besides, how to handle intermediate results in Matrix-matrix Multiplication (MatMul) and how to design a pipeline at a finer granularity of Transformer remain unsolved. In this work, we propose ReTransformer - a ReRAM-based PIM architecture for Transformer acceleration. ReTransformer can not only accelerate the scaled dot-product attention of Transformer using ReRAM-based PIM but also eliminate some data dependency by avoiding writing the intermediate results using the proposed matrix decomposition technique. Moreover, we propose a new sub-matrix pipeline design for multi-head self-attention. Experimental results show that compared to GPU and Pipelayer, ReTransformer improves computing efficiency by 23.21x and 3.25x, respectively. The corresponding overall power is reduced by 1086x and 2.82x, respectively.
RI Li, Hai/L-8558-2017; Chen, Yiran/L-4812-2017
OI Li, Hai/0000-0003-3228-6544; Yang, Xiaoxuan/0000-0002-2553-2631; Chen,
   Yiran/0000-0002-1486-8412
SN 1933-7760
BN 978-1-6654-2324-3
PY 2020
DI 10.1145/3400302.3415640
UT WOS:000671087100051
ER

PT J
AU Li, HY
   Siddiqui, O
   Zhang, HJ
   Guan, YF
AF Li, Hongyang
   Siddiqui, Omer
   Zhang, Hongjiu
   Guan, Yuanfang
TI Joint learning improves protein abundance prediction in cancers
SO BMC BIOLOGY
AB Background The classic central dogma in biology is the information flow from DNA to mRNA to protein, yet complicated regulatory mechanisms underlying protein translation often lead to weak correlations between mRNA and protein abundances. This is particularly the case in cancer samples and when evaluating the same gene across multiple samples. Results Here, we report a method for predicting proteome from transcriptome, using a training dataset provided by NCI-CPTAC and TCGA, consisting of transcriptome and proteome data from 77 breast and 105 ovarian cancer samples. First, we establish a generic model capturing the correlation between mRNA and protein abundance of a single gene. Second, we build a gene-specific model capturing the interdependencies among multiple genes in a regulatory network. Third, we create a cross-tissue model by joint learning the information of shared regulatory networks and pathways across cancer tissues. Our method ranked first in the NCI-CPTAC DREAM Proteogenomics Challenge, and the predictive performance is close to the accuracy of experimental replicates. Key functional pathways and network modules controlling the proteomic abundance in cancers were revealed, in particular metabolism-related genes. Conclusions We present a method to predict proteome from transcriptome, leveraging data from different cancer tissues to build a trans-tissue model, and suggest how to integrate information from multiple cancers to provide a foundation for further research.
OI Guan, Yuanfang/0000-0001-8275-2852; Zhang, Hongjiu/0000-0003-0545-5613
EI 1741-7007
PD DEC 23
PY 2019
VL 17
IS 1
AR 107
DI 10.1186/s12915-019-0730-9
UT WOS:000512066000001
PM 31870366
ER

PT C
AU Li, NH
   Liu, SJ
   Liu, YQ
   Zhao, S
   Liu, M
AF Li, Naihan
   Liu, Shujie
   Liu, Yanqing
   Zhao, Sheng
   Liu, Ming
GP AAAI
TI Neural Speech Synthesis with Transformer Network
SO THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 33rd AAAI Conference on Artificial Intelligence / 31st Innovative
   Applications of Artificial Intelligence Conference / 9th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY JAN 27-FEB 01, 2019
CL Honolulu, HI
SP Assoc Advancement Artificial Intelligence
AB Although end-to-end neural text-to-speech (TTS) methods (such as Tacotron2) are proposed and achieve state-of-the-art performance, they still suffer from two problems: 1) low efficiency during training and inference; 2) hard to model long dependency using current recurrent neural networks (RNNs). Inspired by the success of Transformer network in neural machine translation (NMT), in this paper, we introduce and adapt the multi-head attention mechanism to replace the RNN structures and also the original attention mechanism in Tacotron2. With the help of multi-head self-attention, the hidden states in the encoder and decoder are constructed in parallel, which improves training efficiency. Meanwhile, any two inputs at different times are connected directly by a self-attention mechanism, which solves the long range dependency problem effectively. Using phoneme sequences as input, our Transformer TTS network generates mel spectrograms, followed by a WaveNet vocoder to output the final audio results. Experiments are conducted to test the efficiency and performance of our new network. For the efficiency, our Transformer TTS network can speed up the training about 4.25 times faster compared with Tacotron2. For the performance, rigorous human tests show that our proposed model achieves state-of-the-art performance (outperforms Tacotron2 with a gap of 0.048) and is very close to human quality (4.39 vs 4.44 in MOS).
SN 2159-5399
EI 2374-3468
BN 978-1-57735-809-1
PY 2019
BP 6706
EP 6713
UT WOS:000486572501030
ER

PT C
AU Song, JF
   Pang, KY
   Song, YZ
   Xiang, T
   Hospedales, TM
AF Song, Jifei
   Pang, Kaiyue
   Song, Yi-Zhe
   Xiang, Tao
   Hospedales, Timothy M.
GP IEEE
TI Learning to Sketch with Shortcut Cycle Consistency
SO 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR)
CY JUN 18-23, 2018
CL Salt Lake City, UT
SP IEEE, CVF, IEEE Comp Soc
AB To see is to sketch - free-hand sketching naturally builds ties between human and machine vision. In this paper; we present a novel approach for translating an object photo to a sketch, mimicking the human sketching process. This is an extremely challenging task because the photo and sketch domains differ significantly. Furthermore, human sketches exhibit various levels of sophistication and abstraction even when depicting the same object instance in a reference photo. This means that even if photo-sketch pairs are available, they only provide weak supervision signal to learn a translation model. Compared with existing supervised approaches that solve the problem of D(E(photo)) -> sketch), where E(.) and D(.) denote encoder and decoder respectively, we take advantage of the inverse problem (e.g., D(E(sketch) -> photo), and combine with the unsupervised learning tasks of within-domain reconstruction, all within a multi-task learning framework. Compared with existing unsupervised approaches based on cycle consistency (i.e., D(E(D(E(photo)))) -> photo), we introduce a shortcut consistency enforced at the encoder bottleneck (e.g., D(E(photo)) -> photo) to exploit the additional self-supervision. Both qualitative and quantitative results show that the proposed model is superior to a number of state-of-the-art alternatives. We also show that the synthetic sketches can be used to train a better fine-grained sketch-based image retrieval (FG-SBIR) model, effectively alleviating the problem of sketch data scarcity.
RI pang, kaiyue/HKM-8813-2023
OI pang, kaiyue/0000-0002-1324-4368
SN 1063-6919
BN 978-1-5386-6420-9
PY 2018
BP 801
EP 810
DI 10.1109/CVPR.2018.00090
UT WOS:000457843600083
ER

PT J
AU Bruno, L
   Poggialini, A
   Felice, G
AF Bruno, Luigi
   Poggialini, Andrea
   Felice, Giuseppina
TI Design and calibration of a piezoelectric actuator for interferometric
   applications
SO OPTICS AND LASERS IN ENGINEERING
AB The present work reports a Possible Solution for a low-cost piezoelectric actuator available for interferometric applications. In the paper the design, the assembly and the calibration of the actuator are described in detail.
   The solution adopted consists of a machined stainless steel case deformed by three low-voltage multilayer PlUmburn zirconate titanate (PZT) ceramic blocks. In the proposed arrangement a three degree of freedom device is obtained, by which a translation and two rotations can be performed.
   The PZTs are driven by a supply voltage provided by a 16 bit D/A converter directly connected to the parallel port of a personal computer which guarantees a very accurate output. This voltage is applied on each ceramic by means of a variable resistor, by which it is possible to adjust the maximum driving voltage for the single block. This electrical solution allows to match up the strokes of the ceramics in order to obtain a straight expansion of the whole actuator.
   After the mechanical and electrical set-LIP of the actuator, a static calibration was carried Out by inserting it along one arm of a Michelson speckle interferometer. The calibration procedure had emphasized the hysteresis loop and the non-linearity of the electromechanical behaviour or the actuator. (C) 2007 Elsevier Ltd. All rights reserved.
RI Bruno, Luigi/Q-7702-2016
OI Bruno, Luigi/0000-0002-6745-0466
SN 0143-8166
EI 1873-0302
PD DEC
PY 2007
VL 45
IS 12
BP 1148
EP 1156
DI 10.1016/j.optlaseng.2007.06.004
UT WOS:000250327200005
ER

PT J
AU Kim, KH
   Cho, MJ
   Kim, JS
   Kim, JS
   Song, CJ
   Song, SH
   Kim, SH
   Myers, L
   Kim, YE
AF Kim, KH
   Cho, MJ
   Kim, JS
   Kim, JS
   Song, CJ
   Song, SH
   Kim, SH
   Myers, L
   Kim, YE
TI Isocenter accuracy in frameless stereotactic radiotherapy using
   implanted fiducials
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
CT 3rd S Takahashi Memorial International Workshop on 3-dimensional
   Conformal Radiotherapy
CY DEC 08-10, 2001
CL NAGOYA, JAPAN
AB Purpose: The stereotactic radiotherapy (SRT) system verifies isocenter accuracy in patient space. In this study, we evaluate isocenter accuracy in frameless SRT using implanted cranial gold markers.
   Methods and Materials: We performed frameless SRT on 43 intracranial tumor patients between August 1997 and December 2000. The treatment technique was determined by the tumor shape and volume, and by the location of critical organs. The coordinates of anterior-posterior and lateral port film were inputted to ISOLOC software, which calculated (7) the couch moves translation distance required to bring the target point to the isocenter, and (2) the intermarker distance comparisons between the CT study and the treatment machine films. We evaluated the isocenter deviation based on the error between orthogonal film target coordinates and isocenter coordinates.
   Results: The mean treatment isocenter deviations (x, y, z) were -0.03, 0.14, and -0.04 mm, respectively. The systematic component isocenter standard deviations were 0.28, 0.31, and 0.35 mm (1 SD), respectively, and the random component isocenter standard deviations were 0.53, 0.52, and 0.50 mm (1 SD), respectively.
   Conclusion: The isocenter accuracy in the frameless SRT-implanted fiducial system is highly reliable and is comparable to that of other stereotactic radiosurgery systems. (C) 2003 Elsevier Inc.
RI Kim, Jae Sung/J-5429-2012
OI Kim, Seon-Hwan/0000-0002-5600-2801; Kim, Jae-Sung/0000-0001-5348-9178;
   KIM, JUN-SANG/0000-0002-5329-6605
SN 0360-3016
EI 1879-355X
PD MAY 1
PY 2003
VL 56
IS 1
BP 266
EP 273
DI 10.1016/S0360-3016(03)00088-9
UT WOS:000182309800033
PM 12694848
ER

PT J
AU Walia, RR
   Xue, LC
   Wilkins, K
   El-Manzalawy, Y
   Dobbs, D
   Honavar, V
AF Walia, Rasna R.
   Xue, Li C.
   Wilkins, Katherine
   El-Manzalawy, Yasser
   Dobbs, Drena
   Honavar, Vasant
TI RNABindRPlus: A Predictor that Combines Machine Learning and Sequence
   Homology-Based Methods to Improve the Reliability of Predicted
   RNA-Binding Residues in Proteins
SO PLOS ONE
AB Protein-RNA interactions are central to essential cellular processes such as protein synthesis and regulation of gene expression and play roles in human infectious and genetic diseases. Reliable identification of protein-RNA interfaces is critical for understanding the structural bases and functional implications of such interactions and for developing effective approaches to rational drug design. Sequence-based computational methods offer a viable, cost-effective way to identify putative RNA-binding residues in RNA-binding proteins. Here we report two novel approaches: (i) HomPRIP, a sequence homology-based method for predicting RNA-binding sites in proteins; (ii) RNABindRPlus, a new method that combines predictions from HomPRIP with those from an optimized Support Vector Machine (SVM) classifier trained on a benchmark dataset of 198 RNA-binding proteins. Although highly reliable, HomPRIP cannot make predictions for the unaligned parts of query proteins and its coverage is limited by the availability of close sequence homologs of the query protein with experimentally determined RNA-binding sites. RNABindRPlus overcomes these limitations. We compared the performance of HomPRIP and RNABindRPlus with that of several state-of-the-art predictors on two test sets, RB44 and RB111. On a subset of proteins for which homologs with experimentally determined interfaces could be reliably identified, HomPRIP outperformed all other methods achieving an MCC of 0.63 on RB44 and 0.83 on RB111. RNABindRPlus was able to predict RNA-binding residues of all proteins in both test sets, achieving an MCC of 0.55 and 0.37, respectively, and outperforming all other methods, including those that make use of structure-derived features of proteins. More importantly, RNABindRPlus outperforms all other methods for any choice of tradeoff between precision and recall. An important advantage of both HomPRIP and RNABindRPlus is that they rely on readily available sequence and sequence-derived features of RNA-binding proteins. A webserver implementation of both methods is freely available at http://einstein.cs.iastate.edu/RNABindRPlus/.
RI Honavar, Vasant G/K-9835-2015; El-Manzalawy, Yasser/ABE-3489-2020; Xue,
   LI C./ABG-4802-2021
OI Honavar, Vasant G/0000-0001-5399-3489; Xue, LI C./0000-0002-2613-538X;
   Dobbs, Drena/0000-0003-4404-9554; Walia, Rasna/0000-0001-7088-5535
SN 1932-6203
PD MAY 20
PY 2014
VL 9
IS 5
AR e97725
DI 10.1371/journal.pone.0097725
UT WOS:000339563400050
PM 24846307
ER

PT J
AU Yoo, S
   Sheng, Y
   Blitzblau, R
   McDuff, S
   Champ, C
   Morrison, J
   O'Neill, L
   Catalano, S
   Yin, FF
   Wu, JC
AF Yoo, Sua
   Sheng, Yang
   Blitzblau, Rachel
   McDuff, Susan
   Champ, Colin
   Morrison, Jay
   O'Neill, Leigh
   Catalano, Suzanne
   Yin, Fang-Fang
   Wu, Jackie
TI Clinical Experience With Machine Learning-Based Automated Treatment
   Planning for Whole Breast Radiation Therapy
SO ADVANCES IN RADIATION ONCOLOGY
AB Purpose: The machine learningebased automated treatment planning (MLAP) tool has been developed and evaluated for breast radiation therapy planning at our institution. We implemented MLAP for patient treatment and assessed our clinical experience for its performance.
   Methods and Materials: A total of 102 patients of breast or chest wall treatment plans were prospectively evaluated with institutional review board approval. A human planner executed MLAP to create an auto-plan via automation of fluence maps generation. If judged necessary, a planner further fine-tuned the fluence maps to reach a final plan. Planners recorded the time required for auto-planning and manual modification. Target (ie, breast or chest wall and nodes) coverage and dose homogeneity were compared between the auto-plan and final plan.
   Results: Cases without nodes (n = 71) showed negligible (<1%) differences for target coverage and dose homogeneity between the auto-plan and final plan. Cases with nodes (n = 31) also showed negligible difference for target coverage. However, mean +/- standard deviation of volume receiving 105% of the prescribed dose and maximum dose were reduced from 43.0% +/- 26.3% to 39.4% +/- 23.7% and 119.7% +/- 9.5% to 114.4% +/- 8.8% from auto-plan to final plan, respectively, all with P < .01 for cases with nodes (n = 31). Mean +/- standard deviation time spent for auto-plans and additional fluence modification for final plans were 12.1 +/- 9.3 and 13.1 +/- 12.9 minutes, respectively, for cases without nodes, and 16.4 +/- 9.7 and 26.4 +/- 16.4 minutes, respectively, for cases with nodes.
   Conclusions: The MLAP tool has been successfully implemented for routine clinical practice and has significantly improved planning efficiency. Clinical experience indicates that auto-plans are sufficient for target coverage, but improvement is warranted to reduce high dose volume for cases with nodal irradiation. This study demonstrates the clinical implementation of auto-planning for patient treatment and the significant importance of integrating human experience and feedback to improve MLAP for better clinical translation. (C) 2021 The Authors. Published by Elsevier Inc. on behalf of American Society for Radiation Oncology.
OI Yoo, Sua/0000-0002-1280-6859; Yin, Fang-Fang/0000-0002-2025-4740
EI 2452-1094
PD MAR-APR
PY 2021
VL 6
IS 2
AR 100656
DI 10.1016/j.adro.2021.100656
EA MAR 2021
UT WOS:000717463300003
PM 33748540
ER

PT J
AU Nag, A
   Haber, N
   Voss, C
   Tamura, S
   Daniels, J
   Ma, J
   Chiang, B
   Ramachandran, S
   Schwartz, J
   Winograd, T
   Feinstein, C
   Wall, DP
AF Nag, Anish
   Haber, Nick
   Voss, Catalin
   Tamura, Serena
   Daniels, Jena
   Ma, Jeffrey
   Chiang, Bryan
   Ramachandran, Shasta
   Schwartz, Jessey
   Winograd, Terry
   Feinstein, Carl
   Wall, Dennis P.
TI Toward Continuous Social Phenotyping: Analyzing Gaze Patterns in an
   Emotion Recognition Task for Children With Autism Through Wearable Smart
   Glasses
SO JOURNAL OF MEDICAL INTERNET RESEARCH
AB Background: Several studies have shown that facial attention differs in children with autism. Measuring eye gaze and emotion recognition in children with autism is challenging, as standard clinical assessments must be delivered in clinical settings by a trained clinician. Wearable technologies may be able to bring eye gaze and emotion recognition into natural social interactions and settings.
   Objective: This study aimed to test: (1) the feasibility of tracking gaze using wearable smart glasses during a facial expression recognition task and (2) the ability of these gaze-tracking data, together with facial expression recognition responses, to distinguish children with autism from neurotypical controls (NCs).
   Methods: We compared the eye gaze and emotion recognition patterns of 16 children with autism spectrum disorder (ASD) and 17 children without ASD via wearable smart glasses fitted with a custom eye tracker. Children identified static facial expressions of images presented on a computer screen along with nonsocial distractors while wearing Google Glass and the eye tracker. Faces were presented in three trials, during one of which children received feedback in the form of the correct classification. We employed hybrid human-labeling and computer vision-enabled methods for pupil tracking and world-gaze translation calibration. We analyzed the impact of gaze and emotion recognition features in a prediction task aiming to distinguish children with ASD from NC participants.
   Results: Gaze and emotion recognition patterns enabled the training of a classifier that distinguished ASD and NC groups. However, it was unable to significantly outperform other classifiers that used only age and gender features, suggesting that further work is necessary to disentangle these effects.
   Conclusions: Although wearable smart glasses show promise in identifying subtle differences in gaze tracking and emotion recognition patterns in children with and without ASD, the present form factor and data do not allow for these differences to be reliably exploited by machine learning systems. Resolving these challenges will be an important step toward continuous tracking of the ASD phenotype.
OI Schwartz, Jessey/0000-0003-4916-7891; Ramachandran,
   Shasta/0000-0002-6102-241X; Nag, Anish/0000-0002-0574-3722; tamura,
   serena/0000-0002-3090-2385; Ma, Jeffrey Jian/0000-0002-3646-3547; Haber,
   Nick/0000-0001-8804-7804
SN 1438-8871
PD APR 22
PY 2020
VL 22
IS 4
AR e13810
DI 10.2196/13810
UT WOS:000527464200001
PM 32319961
ER

PT J
AU Yang, H
   Li, XF
   Guo, YX
   Jia, LM
AF Yang, Han
   Li, Xiaofeng
   Guo, Yuxin
   Jia, Limin
TI RT-GAN: GAN Based Architecture for Precise Segmentation of Railway
   Tracks
SO APPLIED SCIENCES-BASEL
AB Identifying and locating track areas in images through machine vision technology is the primary task of autonomous UAV inspection. Aiming at the problems that railway track images are greatly affected by light and perspective, the background environment is complex and easy to misidentify, and existing methods are difficult to reason correctly about the obscured track area, this paper proposes a generative adversarial network (GAN)-based railway track precision segmentation framework, RT-GAN. RT-GAN consists of an encoder-decoder generator (named RT-seg) and a patch-based track discriminator. For the generator design, a linear span unit (LSU) and linear extension pyramid (LSP) are used to concatenate network features with different resolutions. In addition, a loss function containing gradient information is designed, and the gradient image of the segmentation result is added into the input of the track discriminator, aiming to guide the generator, RT-seg, to focus on the linear features of the railway tracks faster and more accurately. Experiments on the railway track dataset proposed in this paper show that with the improved loss function and adversarial training, RT-GAN provides a more accurate segmentation of rail tracks than the state-of-the-art techniques and has stronger occlusion inference capabilities, achieving 88.07% and 81.34% IoU in unaugmented and augmented datasets.
EI 2076-3417
PD DEC
PY 2022
VL 12
IS 23
AR 12044
DI 10.3390/app122312044
UT WOS:000895185000001
ER

PT J
AU Liu, C
   Zhang, XS
   Zhang, R
   Li, L
   Zhou, SY
   Huang, D
   Li, Z
   Du, ZD
   Liu, SL
   Chen, TS
AF Liu, Chang
   Zhang, Xishan
   Zhang, Rui
   Li, Ling
   Zhou, Shiyi
   Huang, Di
   Li, Zhen
   Du, Zidong
   Liu, Shaoli
   Chen, Tianshi
TI Rethinking the Importance of Quantization Bias, Toward Full Low-Bit
   Training
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
AB Quantization is a promising technique to reduce the computation and storage costs of DNNs. Low-bit ( $\leq8$ bits) precision training remains an open problem due to the difficulty of gradient quantization. In this paper, we find two long-standing misunderstandings of the bias of gradient quantization noise. First, the large bias of gradient quantization noise, instead of the variance, is the key factor of training accuracy loss. Second, the widely used stochastic rounding cannot solve the training crash problem caused by the gradient quantization bias in practice. Moreover, we find that the asymmetric distribution of gradients causes a large bias of gradient quantization noise. Based on our findings, we propose a novel adaptive piecewise quantization method to effectively limit the bias of gradient quantization noise. Accordingly, we propose a new data format, Piecewise Fixed Point (PWF), to present data after quantization. We apply our method to different applications including image classification, machine translation, optical character recognition, and text classification. We achieve approximately $1.9\sim 3.5\times $ speedup compared with full precision training with an accuracy loss of less than 0.5%. To the best of our knowledge, this is the first work to quantize gradients of all layers to 8 bits in both large-scale CNN and RNN training with negligible accuracy loss.
OI Li, Ling/0000-0001-8877-9052
SN 1057-7149
EI 1941-0042
PY 2022
VL 31
BP 7006
EP 7019
DI 10.1109/TIP.2022.3216776
UT WOS:000888975000003
PM 36322492
ER

PT J
AU Muller, D
   Ehlen, A
   Valeske, B
AF Mueller, David
   Ehlen, Andreas
   Valeske, Bernd
TI Convolutional Neural Networks for Semantic Segmentation as a Tool for
   Multiclass Face Analysis in Thermal Infrared
SO JOURNAL OF NONDESTRUCTIVE EVALUATION
AB Convolutional neural networks were used for multiclass segmentation in thermal infrared face analysis. The principle is based on existing image-to-image translation approaches, where each pixel in an image is assigned to a class label. We show that established networks architectures can be trained for the task of multiclass face analysis in thermal infrared. Created class annotations consisted of pixel-accurate locations of different face classes. Subsequently, the trained network can segment an acquired unknown infrared face image into the defined classes. Furthermore, face classification in live image acquisition is shown, in order to be able to display the relative temperature in real-time from the learned areas. This allows a pixel-accurate temperature face analysis e.g. for infection detection like Covid-19. At the same time our approach offers the advantage of concentrating on the relevant areas of the face. Areas of the face irrelevant for the relative temperature calculation or accessories such as glasses, masks and jewelry are not considered. A custom database was created to train the network. The results were quantitatively evaluated with the intersection over union (IoU) metric. The methodology shown can be transferred to similar problems for more quantitative thermography tasks like in materials characterization or quality control in production.
OI Valeske, Bernd/0000-0002-2758-9754; Muller, David/0000-0003-4995-0851
SN 0195-9298
EI 1573-4862
PD MAR
PY 2021
VL 40
IS 1
AR 9
DI 10.1007/s10921-020-00740-y
UT WOS:000606451300005
PM 33424071
ER

PT J
AU Jiang, YF
   Chen, H
   Loew, M
   Ko, H
AF Jiang, Yifan
   Chen, Han
   Loew, Murray
   Ko, Hanseok
TI COVID-19 CT Image Synthesis With a Conditional Generative Adversarial
   Network
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
AB Coronavirus disease 2019 (COVID-19) is an ongoing global pandemic that has spread rapidly since December 2019. Real-time reverse transcription polymerase chain reaction (rRT-PCR) and chest computed tomography (CT) imaging both play an important role in COVID-19 diagnosis. Chest CT imaging offers the benefits of quick reporting, a low cost, and high sensitivity for the detection of pulmonary infection. Recently, deep-learning-based computer vision methods have demonstrated great promise for use in medical imaging applications, including X-rays, magnetic resonance imaging, and CT imaging. However, training a deep-learning model requires large volumes of data, and medical staff faces a high risk when collecting COVID-19 CT data due to the high infectivity of the disease. Another issue is the lack of experts available for data labeling. In order to meet the data requirements for COVID-19 CT imaging, we propose a CT image synthesis approach based on a conditional generative adversarial network that can effectively generate high-quality and realistic COVID-19 CT images for use in deep-learning-based medical imaging tasks. Experimental results show that the proposed method outperforms other state-of-the-art image synthesis methods with the generated COVID-19 CT images and indicates promising for various machine learning applications including semantic segmentation and classification.
RI jiang, yifan/GQH-5044-2022
OI Ko, Hanseok/0000-0002-8744-4514; CHEN, HAN/0000-0002-6315-802X; JIANG,
   YIFAN/0000-0002-7369-7123
SN 2168-2194
EI 2168-2208
PD FEB
PY 2021
VL 25
IS 2
BP 441
EP 452
DI 10.1109/JBHI.2020.3042523
UT WOS:000616310200014
PM 33275588
ER

PT C
AU Oehri, E
   Guzman, E
AF Oehri, Emanuel
   Guzman, Emitza
BE Breaux, T
   Zisman, A
   Fricker, S
   Glinz, M
TI Same Same but Different: Finding Similar User Feedback Across Multiple
   Platforms and Languages
SO 2020 28TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE (RE'20)
SE International Requirements Engineering Conference
CT 28th IEEE International Requirements Engineering Conference (RE)
CY AUG 31-SEP 04, 2020
CL Zurich, SWITZERLAND
SP IEEE, IEEE Comp Soc, Univ Zurich, Tech Council Software Engn, Univ Appl Sci & Arts NW Switzerland, Inst Interact Technologies, ACM In Cooperat, Special Interest Grp Software Engn
AB Users submit feedback about the software they use through application distributions platforms, i.e., app stores, and social media. Previous research has found that this type of feedback contains valuable information for software evolution, such as bug reports, or feature requests. However, popular applications receive thousands of feedback entities per day, making their manual analysis unrealistic.
   In this work, we present an approach to automatically identify similar user feedback across different languages and platforms. At the core of the approach is a word aligner that aligns words based on their semantic similarity and the similarity of their local semantic contexts. Additionally, we make use of machine translation, sentiment analysis, and text classification, to extract the sentiment polarity and content nature of user feedback written in different languages. We use the results of these components to compute a similarity score between user feedback pairs. We evaluated our approach on user feedback entities written in four different languages, and retrieved from five different mobile applications obtained from four different app stores and social networking sites. The obtained results are encouraging. Compared to human assessment, the overall performance for monolingual user feedback pairs yielded a strong correlation of 0.79. For the crosslingual feedback pairs the correlation was also strong, with a value of 0.78.
SN 2332-6441
BN 978-1-7281-7438-9
PY 2020
BP 44
EP 54
DI 10.1109/RE48521.2020.00017
UT WOS:000628527900008
ER

PT C
AU Haryanto, A
   Budiwantoro, B
AF Haryanto, A.
   Budiwantoro, B.
GP IOP
TI Dynamic characteristics analysis of agitator design for soy sauce
   cooking process
SO 2ND INTERNATIONAL CONFERENCE ON NATURAL PRODUCTS AND BIORESOURCE
   SCIENCES - 2018
SE IOP Conference Series-Earth and Environmental Science
CT 2nd International Conference on Natural Products and Bioresource
   Sciences (ICONPROBIOS)
CY NOV 01-02, 2018
CL Tangerang, INDONESIA
SP Indonesian Inst Sci, Res Unit Nat Product Technol
AB Soy sauce is one type of dark brown condiment, distinctive smell, salty or sweet taste, lumpy, and contains protein produced from fermented. One of the machines that can be used for cooking soy sauce is a pressure vessel as cooking pan with an agitator. Agitation is a process of mixing and stirring and are carried out by heat transfer and mass inter-phases or with external surfaces (due to outside influences). The agitator is a system used for mixing and stirring accompanied by a phase change. In the design of rotating machinery, it is necessary to predict the dynamic characteristic in bending and in torsion to avoid failure. Dynamic characteristics analysis of agitator design for soy sauce cooking process consists of mechanical vibration analysis and mass unbalance response. The stiffness method for the agitator shaft by dividing the shaft element into two elements based on the bearing position. The bearing is assumed to be roller supports and only moves in the direction of translation and rotation. Based on the dynamic characteristics of rotordynamics prediction by using finite element method both theoretical and software, the agitator in operating conditions with the rotation speed of 5 RPM according to Campbell diagram will not fail. The highest amplitude of the mass unbalance response is less than 2.5x10' mm.
SN 1755-1307
PY 2019
VL 251
AR 012038
DI 10.1088/1755-1315/251/1/012038
UT WOS:000471239800038
ER

PT J
AU Zhang, YQ
   Hamada, M
AF Zhang, Yiqian
   Hamada, Michiaki
TI DeepM6ASeq: prediction and characterization of m6A-containing sequences
   using deep learning
SO BMC BIOINFORMATICS
CT 29th Internatioinal Conference on Genome Informatics (GIW) -
   Bioinformatics
CY DEC 03-05, 2018
CL Yunnan, PEOPLES R CHINA
AB BackgroundN6-methyladensine (m6A) is a common and abundant RNA methylation modification found in various species. As a type of post-transcriptional methylation, m6A plays an important role in diverse RNA activities such as alternative splicing, an interplay with microRNAs and translation efficiency. Although existing tools can predict m6A at single-base resolution, it is still challenging to extract the biological information surrounding m6A sites.ResultsWe implemented a deep learning framework, named DeepM6ASeq, to predict m6A-containing sequences and characterize surrounding biological features based on miCLIP-Seq data, which detects m6A sites at single-base resolution. DeepM6ASeq showed better performance as compared to other machine learning classifiers. Moreover, an independent test on m6A-Seq data, which identifies m6A-containing genomic regions, revealed that our model is competitive in predicting m6A-containing sequences. The learned motifs from DeepM6ASeq correspond to known m6A readers. Notably, DeepM6ASeq also identifies a newly recognized m6A reader: FMR1. Besides, we found that a saliency map in the deep learning model could be utilized to visualize locations of m6A sites.ConculsionWe developed a deep-learning-based framework to predict and characterize m6A-containing sequences and hope to help investigators to gain more insights for m6A research. The source code is available at https://github.com/rreybeyb/DeepM6ASeq.
SN 1471-2105
PD DEC 31
PY 2018
VL 19
SU 19
AR 524
DI 10.1186/s12859-018-2516-4
UT WOS:000454631500001
ER

PT J
AU Sarwar, R
   Li, Q
   Rakthanmanon, T
   Nutanong, S
AF Sarwar, Raheem
   Li, Qing
   Rakthanmanon, Thanawin
   Nutanong, Sarana
TI A scalable framework for cross-lingual authorship identification
SO INFORMATION SCIENCES
AB Cross-lingual authorship identification aims at finding the author of an anonymous document written in one language by using labeled documents written in other languages. The main challenge of cross-lingual authorship identification is that the stylistic markers (features) used in one language may not be applicable to other languages in the corpus. Existing methods overcome this challenge by using external resources such as machine translation and part-of-speech tagging. However, such solutions are not applicable to languages with poor external resources (known as low resource languages). They also fail to scale as the number of candidate authors and/or the number of languages in the corpus increases. In this investigation, we analyze different types of stylometric features and identify 10 high-performance language-independent features for cross-lingual stylometric analysis tasks. Based on these stylometric features, we propose a cross-lingual authorship identification solution that can accurately handle a large number of authors. Specifically, we partition the documents into fragments where each fragment is further decomposed into fixed size chunks. Using a multilingual corpus of 400 authors with 825 documents written in 6 different languages, we show that our method can achieve an accuracy level of 96.66%. Our solution also outperforms the best existing solution that does not rely on external resources. (C) 2018 Elsevier Inc. All rights reserved.
OI Jaroensuk, Supaluk/0000-0001-6936-9568; /0000-0002-0640-807X
SN 0020-0255
EI 1872-6291
PD OCT
PY 2018
VL 465
BP 323
EP 339
DI 10.1016/j.ins.2018.07.009
UT WOS:000445713900021
ER

PT C
AU Faes, M
   Gross, TR
AF Faes, Michael
   Gross, Thomas R.
BE Kell, S
   Marr, S
TI Efficient VM-Independent Runtime Checks for Parallel Programming
SO PROCEEDINGS OF THE 10TH ACM SIGPLAN INTERNATIONAL WORKSHOP ON VIRTUAL
   MACHINES AND INTERMEDIATE LANGUAGES (VMIL '18)
CT 10th ACM SIGPLAN International Workshop on Virtual Machines and Language
   Implementations (VMIL)
CY NOV 04, 2018
CL Boston, MA
SP Assoc Comp Machinery, ACM SIGPLAN
AB Many concurrent or parallel programming languages rely on runtime checking to ensure safety. To implement such a language on a virtual machine (VM), such runtime checks are often implemented in a VM-independent way, using source-to-source translation or bytecode instrumentation. This approach avoids modifying complex VM components like the just-in-time (JIT) compiler and offers great portability. However, obtaining good performance is challenging, as the approach cannot profit from custom JIT optimizations to eliminate redundant checks.
   In this paper, we present and evaluate two techniques to make the VM-independent approach efficient, using the example of a parallel programming language called Rolez. To guarantee that concurrent threads do not interfere, Rolez relies heavily on runtime checks: for every field access, the runtime system checks that the state of the target object currently permits this operation (unless the check is optimized away). The Rolez compiler we present here generates standard Java source code and the runtime system is implemented as a Java library. Nevertheless, many Rolez programs deliver performance roughly on par with manually synchronized Java implementations, which is achieved using these two techniques: 1) code-managed runtime data, which improves runtime check efficiency by passing performance-critical information from method to method, and 2) an interprocedural but modular concurrency analysis, which eliminates many runtime checks that are actually redundant.
BN 978-1-4503-6071-5
PY 2018
BP 5
EP 15
DI 10.1145/3281287.3281293
UT WOS:000458676700003
ER

PT J
AU Hang, HY
   Lin, ZC
   Liu, XY
   Wen, HW
AF Hang, Hanyuan
   Lin, Zhouchen
   Liu, Xiaoyu
   Wen, Hongwei
TI Histogram Transform Ensembles for Large-scale Regression
SO JOURNAL OF MACHINE LEARNING RESEARCH
AB In this paper, we propose a novel algorithm for large-scale regression problems named Histogram Transform Ensembles (HTE), composed of random rotations, stretchings, and translations. Our HTE method first implements a histogram transformed partition to the random affine mapped data, then adaptively leverages constant functions or SVMs to obtain the individual regression estimates, and eventually builds the ensemble predictor through an average strategy. First of all, in this paper, we investigate the theoretical properties of HTE when the regression function lies in the Holder space C-k,C-alpha, k is an element of N-0, alpha is an element of (0, 1]. In the case that k = 0, 1, we adopt the constant regressors and develop the naive his-togram transforms (NHT). Within the space C-0,C-alpha although almost optimal convergence rates can be derived for both single and ensemble NHT, we fail to show the benefits of ensembles over single estimators theoretically. In contrast, in the subspace C-1,C-alpha, we prove that if d >= 2(1 + alpha)/alpha, the lower bound of the convergence rates for single NHT turns out to be worse than the upper bound of the convergence rates for ensemble NHT. In the other case when k >= 2, the NHT may no longer be appropriate in predicting smoother regression functions. Instead, we circumvent this issue by applying kernel histogram transforms (KHT) equipped with smoother regressors, such as support vector machines (SVMs). Accordingly, it turns out that both single and ensemble KHT enjoy almost optimal convergence rates. Then, we validate the above theoretical results with extensive numerical experiments. On the one hand, simulations are conducted to elucidate that ensemble NHT outperforms single NHT. On the other hand, the effects of bin sizes on the accuracy of both NHT and KHT are also in accord with the theoretical analysis. Last but not least, in the real-data experiments, comparisons between the ensemble KHT, equipped with adaptive histogram transforms, and other state-of-the-art large-scale regression estimators verify the effectiveness and precision of the proposed algorithm.
SN 1532-4435
PY 2021
VL 22
AR 95
UT WOS:000663148600001
ER

PT J
AU Zhu, XL
   Liu, L
   He, JJ
   Fang, T
   Xiong, Y
   Mitchell, JC
AF Zhu, Xiaolei
   Liu, Ling
   He, Jingjing
   Fang, Ting
   Xiong, Yi
   Mitchell, Julie C.
TI iPNHOT: a knowledge-based approach for identifying protein-nucleic acid
   interaction hot spots
SO BMC BIOINFORMATICS
AB Background: The interaction between proteins and nucleic acids plays pivotal roles in various biological processes such as transcription, translation, and gene regulation. Hot spots are a small set of residues that contribute most to the binding affinity of a protein-nucleic acid interaction. Compared to the extensive studies of the hot spots on protein-protein interfaces, the hot spot residues within protein-nucleic acids interfaces remain less well-studied, in part because mutagenesis data for protein-nucleic acids interaction are not as abundant as that for protein-protein interactions.
   Results: In this study, we built a new computational model, iPNHOT, to effectively predict hot spot residues on protein-nucleic acids interfaces. One training data set and an independent test set were collected from dbAMEPNI and some recent literature, respectively. To build our model, we generated 97 different sequential and structural features and used a two-step strategy to select the relevant features. The final model was built based only on 7 features using a support vector machine (SVM). The features include two unique features such as increment SASsa(1/2)and esp3, which are newly proposed in this study. Based on the cross validation results, our model gave F1 score and AUROC as 0.725 and 0.807 on the subset collected from ProNIT, respectively, compared to 0.407 and 0.670 of mCSM-NA, a state-of-the art model to predict the thermodynamic effects of protein-nucleic acid interaction. The iPNHOT model was further tested on the independent test set, which showed that our model outperformed other methods.
   Conclusion: In this study, by collecting data from a recently published database dbAMEPNI, we proposed a new model, iPNHOT, to predict hotspots on both protein-DNA and protein-RNA interfaces. The results show that our model outperforms the existing state-of-art models. Our model is available for users through a webserver: http://zhulab.ahu.edu.cn/iPNHOT/.
RI Mitchell, Julie C/D-6436-2018; Xiong, Yi/F-7377-2012
OI Xiong, Yi/0000-0003-2910-6725
SN 1471-2105
PD JUL 6
PY 2020
VL 21
IS 1
AR 289
DI 10.1186/s12859-020-03636-w
UT WOS:000550092500001
PM 32631222
ER

PT J
AU Dickson, DW
   Baker, MC
   Jackson, JL
   DeJesus-Hernandez, M
   Finch, NA
   Tian, S
   Heckman, MG
   Pottier, C
   Gendron, TF
   Murray, ME
   Ren, YX
   Reddy, JS
   Graff-Radford, NR
   Boeve, BF
   Petersen, RC
   Knopman, DS
   Josephs, KA
   Petrucelli, L
   Oskarsson, B
   Sheppard, JW
   Asmann, YW
   Rademakers, R
   van Blitterswijk, M
AF Dickson, Dennis W.
   Baker, Matthew C.
   Jackson, Jazmyne L.
   DeJesus-Hernandez, Mariely
   Finch, NiCole A.
   Tian, Shulan
   Heckman, Michael G.
   Pottier, Cyril
   Gendron, Tania F.
   Murray, Melissa E.
   Ren, Yingxue
   Reddy, Joseph S.
   Graff-Radford, Neill R.
   Boeve, Bradley F.
   Petersen, Ronald C.
   Knopman, David S.
   Josephs, Keith A.
   Petrucelli, Leonard
   Oskarsson, Bjorn
   Sheppard, John W.
   Asmann, Yan W.
   Rademakers, Rosa
   van Blitterswijk, Marka
TI Extensive transcriptomic study emphasizes importance of vesicular
   transport in C9orf72 expansion carriers
SO ACTA NEUROPATHOLOGICA COMMUNICATIONS
AB The majority of the clinico-pathological variability observed in patients harboring a repeat expansion in the C9orf72-SMCR8 complex subunit (C9orf72) remains unexplained. This expansion, which represents the most common genetic cause of frontotemporal lobar degeneration (FTLD) and motor neuron disease (MND), results in a loss of C9orf72 expression and the generation of RNA foci and dipeptide repeat (DPR) proteins. The C9orf72 protein itself plays a role in vesicular transport, serving as a guanine nucleotide exchange factor that regulates GTPases. To further elucidate the mechanisms underlying C9orf72-related diseases and to identify potential disease modifiers, we performed an extensive RNA sequencing study. We included individuals for whom frontal cortex tissue was available: FTLD and FTLD/MND patients with (n = 34) or without (n = 44) an expanded C9orf72 repeat as well as control subjects (n = 24). In total, 6706 genes were differentially expressed between these groups (false discovery rate [FDR] < 0.05). The top gene was C9orf72 (FDR = 1.41E-14), which was roughly two-fold lower in C9orf72 expansion carriers than in (disease) controls. Co-expression analysis revealed groups of correlated genes (modules) that were enriched for processes such as protein folding, RNA splicing, synaptic signaling, metabolism, and Golgi vesicle transport. Within our cohort of C9orf72 expansion carriers, machine learning uncovered interesting candidates associated with clinico-pathological features, including age at onset (vascular endothelial growth factor A [VEGFA]), C9orf72 expansion size (cyclin dependent kinase like 1 [CDKL1]), DPR protein levels (eukaryotic elongation factor 2 kinase [EEF2K]), and survival after onset (small G protein signaling modulator 3 [SGSM3]). Given the fact that we detected a module involved in vesicular transport in addition to a GTPase activator (SGSM3) as a potential modifier, our findings seem to suggest that the presence of a C9orf72 repeat expansion might hamper vesicular transport and that genes affecting this process may modify the phenotype of C9orf72-linked diseases.
RI Murray, Melissa E/C-2763-2015; Reddy, Joseph S./AAF-7343-2020; van
   Blitterswijk, Marka/H-7274-2012; van Blitterswijk, Marka/AAL-4126-2021
OI Murray, Melissa E/0000-0001-7379-2545; Reddy, Joseph
   S./0000-0002-1783-4453; van Blitterswijk, Marka/0000-0002-3054-7053; van
   Blitterswijk, Marka/0000-0002-3054-7053; Pottier,
   Cyril/0000-0002-3049-9346; Sheppard, John/0000-0001-9487-5622
SN 2051-5960
PD OCT 8
PY 2019
VL 7
IS 1
AR 150
DI 10.1186/s40478-019-0797-0
UT WOS:000489231800001
PM 31594549
ER

PT J
AU Correa, EA
   Lopes, AA
   Amancio, DR
AF Correa, Edilson A., Jr.
   Lopes, Alneu A.
   Amancio, Diego R.
TI Word sense disambiguation: A complex network approach
SO INFORMATION SCIENCES
AB The word sense disambiguation (WSD) task aims at identifying the meaning of words in a given context for specific words conveying multiple meanings. This task plays a prominent role in a myriad of real world applications, such as machine translation, word processing and information retrieval. Recently, concepts and methods of complex networks have been employed to tackle this task by representing words as nodes, which are connected if they are semantically similar. Despite the increasingly number of studies carried out with such models, most of them use networks just to represent the data, while the pattern recognition performed on the attribute space is performed using traditional learning techniques. In other words, the structural relationships between words have not been explicitly used in the pattern recognition process. In addition, only a few investigations have probed the suitability of representations based on bipartite networks and graphs (bigraphs) for the problem, as many approaches consider all possible links between words. In this context, we assess the relevance of a bipartite network model representing both feature words (i.e. the words characterizing the context) and target (ambiguous) words to solve ambiguities in written texts. Here, we focus on semantical relationships between these two type of words, disregarding relationships between feature words. The adopted method not only serves to represent texts as graphs, but also constructs a structure on which the discrimination of senses is accomplished. Our results revealed that the adopted learning algorithm in such bipartite networks provides excellent results mostly when local features are employed to characterize the context. Surprisingly, our method even outperformed the support vector machine algorithm in particular cases, with the advantage of being robust even if a small training dataset is available. Taken together, the results obtained here show that the representation/classification used for the WSD problem might be useful to improve the semantical characterization of written texts without the use of deep linguistic information. (C) 2018 Elsevier Inc. All rights reserved.
RI Amancio, Diego Raphael/I-1071-2012
SN 0020-0255
EI 1872-6291
PD MAY
PY 2018
VL 442
BP 103
EP 113
DI 10.1016/j.ins.2018.02.047
UT WOS:000428827300006
ER

PT J
AU Rohmer, J
   Lincke, D
   Hinkel, J
   Le Cozannet, G
   Lambert, E
   Vafeidis, AT
AF Rohmer, Jeremy
   Lincke, Daniel
   Hinkel, Jochen
   Le Cozannet, Goneri
   Lambert, Erwin
   Vafeidis, Athanasios T.
TI Unravelling the Importance of Uncertainties in Global-Scale Coastal
   Flood Risk Assessments under Sea Level Rise
SO WATER
AB Global scale assessments of coastal flood damage and adaptation costs under 21st century sea-level rise are associated with a wide range of uncertainties, including those in future projections of socioeconomic development (shared socioeconomic pathways (SSP) scenarios), of greenhouse gas concentrations (RCP scenarios), and of sea-level rise at regional scale (RSLR), as well as structural uncertainties related to the modelling of extreme sea levels, data on exposed population and assets, and the costs of flood damages, etc. This raises the following questions: which sources of uncertainty need to be considered in such assessments and what is the relative importance of each source of uncertainty in the final results? Using the coastal flood module of the Dynamic Interactive Vulnerability Assessment modelling framework, we extensively explore the impact of scenario, data and model uncertainties in a global manner, i.e., by considering a large number (>2000) of simulation results. The influence of the uncertainties on the two risk metrics of expected annual damage (EAD), and adaptation costs (AC) related to coastal protection is assessed at global scale by combining variance-based sensitivity indices with a regression-based machine learning technique. On this basis, we show that the research priorities in terms of future data/knowledge acquisition to reduce uncertainty on EAD and AC differ depending on the considered time horizon. In the short term (before 2040), EAD uncertainty could be significantly decreased by 25 and 75% if the uncertainty of the translation of physical damage into costs and of the modelling of extreme sea levels could respectively be reduced. For AC, it is RSLR that primarily drives short-term uncertainty (with a contribution similar to 50%). In the longer term (>2050), uncertainty in EAD could be largely reduced by 75% if the SSP scenario could be unambiguously identified. For AC, it is the RCP selection that helps reducing uncertainty (up to 90% by the end of the century). Altogether, the uncertainty in future human activities (SSP and RCP) are the dominant source of the uncertainty in future coastal flood risk.
RI Lambert, Erwin/AAJ-6730-2020; Vafeidis, Athanasios Thomas/Z-6053-2019
OI Lambert, Erwin/0000-0001-7537-6385; Vafeidis, Athanasios
   Thomas/0000-0002-3906-5544; Rohmer, Jeremy/0000-0001-9083-5965; Le
   Cozannet, Goneri/0000-0003-2421-3003; Hinkel, Jochen/0000-0001-7590-992X
EI 2073-4441
PD MAR
PY 2021
VL 13
IS 6
AR 774
DI 10.3390/w13060774
UT WOS:000651946300001
ER

PT J
AU Jibb, LA
   Nanos, SM
   Alexander, S
   Malfitano, C
   Rydall, A
   Gupta, S
   Schimmer, AD
   Zimmermann, C
   Hales, S
   Nissim, R
   Marmar, C
   Schultebraucks, K
   Mah, K
   Rodin, G
AF Jibb, Lindsay A.
   Nanos, Stephanie M.
   Alexander, Sarah
   Malfitano, Carmine
   Rydall, Anne
   Gupta, Sumit
   Schimmer, Aaron D.
   Zimmermann, Camilla
   Hales, Sarah
   Nissim, Rinat
   Marmar, Charles
   Schultebraucks, Katharina
   Mah, Kenneth
   Rodin, Gary
TI Traumatic stress symptoms in family caregivers of patients with acute
   leukaemia: protocol for a multisite mixed methods, longitudinal,
   observational study
SO BMJ OPEN
AB IntroductionThe diagnosis, progression or recurrence of cancer is often highly traumatic for family caregivers (FCs), but systematic assessments of distress and approaches for its prevention and treatment are lacking. Acute leukaemia (AL) is a life-threatening cancer of the blood, which most often presents acutely, requires intensive treatment and is associated with severe physical symptoms. Consequently, traumatic stress may be common in the FCs of patients with AL. We aim to determine the prevalence, severity, longitudinal course and predictors of traumatic stress symptoms in FCs of patients with AL in the first year after diagnosis, and to understand their lived experience of traumatic stress and perceived support needs.
   Methods and analysisThis two-site longitudinal, observational, mixed methods study will recruit 223 adult FCs of paediatric or adult patients newly diagnosed with AL from two tertiary care centres. Quantitative data will be collected from self-report questionnaires at enrolment, and 1, 3, 6, 9 and 12months after admission to hospital for initial treatment. Quantitative data will be analysed using descriptive and machine learning approaches and a multilevel modelling (MLM) approach will be used to confirm machine learning findings. Semi-structured qualitative interviews will be conducted at 3, 6 and 12months and analysed using a grounded theory approach.
   Ethics and disseminationThis study is funded by the Canadian Institutes of Health Research (CIHR number PJT 173255) and has received ethical approval from the Ontario Cancer Research Ethics Board (CTO Project ID: 2104). The data generated have the potential to inform the development of targeted psychosocial interventions for traumatic stress, which is a public health priority for high-risk populations such as FCs of patients with haematological malignancies. An integrated and end-of-study knowledge translation strategy that involves FCs and other stakeholders will be used to interpret and disseminate study results.
RI ; Hales, Sarah/M-7432-2016
OI Schimmer, Aaron/0000-0003-4023-3899; Rydall, Anne/0000-0002-4692-9101;
   Jibb, Lindsay/0000-0001-6995-2825; Zimmermann,
   Camilla/0000-0003-4889-0244; Gupta, Sumit/0000-0003-1334-3670; Hales,
   Sarah/0000-0001-6404-8124
SN 2044-6055
PD NOV
PY 2022
VL 12
IS 11
AR e065422
DI 10.1136/bmjopen-2022-065422
UT WOS:000924534200026
PM 36332954
ER

PT J
AU Wang, M
   Qin, P
   Zan, T
   Gao, XS
   Han, BS
   Zhang, YL
AF Wang, Min
   Qin, Peng
   Zan, Tao
   Gao, Xiangsheng
   Han, Bisheng
   Zhang, Yanlin
TI Improving optimal chatter control of slender cutting tool through more
   accurate tuned mass damper modeling
SO JOURNAL OF SOUND AND VIBRATION
AB The slender cutting tools are employed in many conditions like boring and milling processes, but those machining processes often accompany with chatter phenomenon which will aggravate the machining efficiency and surface quality. The use of tuned mass damper (TMD) to damp slender tools is considered as a practical and effective way for chatter suppression. Generally, the TMD is embedded inside the hollow cutting tool with two spring-damping elements supporting the mass block at both ends. For the convenience of optimization calculation, the damped tool is generally modeled as an oscillation system with two equivalent lumped mass. With this simplified model, the difference of vibration displacements between two spring-damping elements is ignored. This makes it very difficult to tune the TMD to the best according to the optimization result in practical application especially when both cutting tool and TMD have a slender characteristic. This paper improves the optimal chatter control through a more accurate modeling method which considers the cutting tool as a cantilever Euler-Bernoulli beam and the TMD as a two degrees of freedom system including translation vibration and rotation vibration of the mass block. Based on the proposed model, the influences of the position and length of TMD on the optimal design parameters of two spring-damping elements are analyzed through a series of optimization. The results show that there are great differences in the chatter control mechanism of two springdamping elements and it is very important to choose respective appropriate stiffness and damping parameters for two spring-damping elements in the TMD damped slender cutting tools. Only in this way can the TMD be tuned in practice to the best performance for chatter control of slender cutting tools. Furthermore, based on the simulation results and comparisons with other conventional modeling methods, the difference and superiority of tuning optimization are discussed and the accuracy and practicability of the proposed modeling method are verified with a designed damped end mill cutter and some impact tests.
SN 0022-460X
EI 1095-8568
PD NOV 24
PY 2021
VL 513
AR 116393
DI 10.1016/j.jsv.2021.116393
EA AUG 2021
UT WOS:000724544900002
ER

PT J
AU Asgari, E
   McHardy, AC
   Mofrad, MRK
AF Asgari, Ehsaneddin
   McHardy, Alice C.
   Mofrad, Mohammad R. K.
TI Probabilistic variable-length segmentation of protein sequences for
   discriminative motif discovery (DiMotif) and sequence embedding
   (ProtVecX)
SO SCIENTIFIC REPORTS
AB In this paper, we present peptide-pair encoding (PPE), a general-purpose probabilistic segmentation of protein sequences into commonly occurring variable-length sub-sequences. The idea of PPE segmentation is inspired by the byte-pair encoding (BPE) text compression algorithm, which has recently gained popularity in subword neural machine translation. We modify this algorithm by adding a sampling framework allowing for multiple ways of segmenting a sequence. PPE segmentation steps can be learned over a large set of protein sequences (Swiss-Prot) or even a domain-specific dataset and then applied to a set of unseen sequences. This representation can be widely used as the input to any downstream machine learning tasks in protein bioinformatics. In particular, here, we introduce this representation through protein motif discovery and protein sequence embedding. (i) DiMotif: we present DiMotif as an alignment-free discriminative motif discovery method and evaluate the method for finding protein motifs in three different settings: (1) comparison of DiMotif with two existing approaches on 20 distinct motif discovery problems which are experimentally verified, (2) classification-based approach for the motifs extracted for integrins, integrin- binding proteins, and biofilm formation, and (3) in sequence pattern searching for nuclear localization signal. The DiMotif, in general, obtained high recall scores, while having a comparable F1 score with other methods in the discovery of experimentally verified motifs. Having high recall suggests that the DiMotif can be used for short-list creation for further experimental investigations on motifs. In the classification-based evaluation, the extracted motifs could reliably detect the integrins, integrin-binding, and biofilm formation-related proteins on a reserved set of sequences with high F1 scores. (ii) ProtVecX: we extend k-mer based protein vector (ProtVec) embedding to variablelength protein embedding using PPE sub-sequences. We show that the new method of embedding can marginally outperform ProtVec in enzyme prediction as well as toxin prediction tasks. In addition, we conclude that the embeddings are beneficial in protein classification tasks when they are combined with raw amino acids k-mer features.
RI /R-6010-2019; Asgari, Ehsaneddin/AAJ-3680-2021; McHardy,
   Alice/ABF-2322-2020
OI /0000-0001-7004-4859; McHardy, Alice/0000-0003-2370-3430
SN 2045-2322
PD MAR 5
PY 2019
VL 9
AR 3577
DI 10.1038/s41598-019-38746-w
UT WOS:000460381600150
PM 30837494
ER

PT J
AU Sitaram, R
   Zhang, HH
   Guan, CT
   Thulasidas, M
   Hoshi, Y
   Ishikawa, A
   Shimizu, K
   Birbaumer, N
AF Sitaram, Ranganatha
   Zhang, Haihong
   Guan, Cuntai
   Thulasidas, Manoj
   Hoshi, Yoko
   Ishikawa, Akihiro
   Shimizu, Koji
   Birbaumer, Niels
TI Temporal classification of multichannel near-infrared spectroscopy
   signals of motor imagery for developing a brain-computer interface
SO NEUROIMAGE
AB There has been an increase in research interest for brain-computer interface (BCI) technology as an alternate mode of communication and environmental control for the disabled, such as patients suffering from amyotrophic lateral sclerosis (ALS), brainstem stroke and spinal cord injury. Disabled patients with appropriate physical care and cognitive ability to communicate with their social environment continue to live with a reasonable quality of life over extended periods of time. Near-infrared spectroscopy is a non-invasive technique which utilizes light in the near-infrared range (700 to 1000 nm) to determine cerebral oxygenation, blood flow and metabolic status of localized regions of the brain. In this paper, we describe a study conducted to test the feasibility of using multichannel NIRS in the development of a BCI. We used a continuous wave 20-channel NIRS system over the motor cortex of 5 healthy volunteers to measure oxygenated and deoxygenated hemoglobin changes during left-hand and right-hand motor imagery. We present results of signal analysis indicating that there exist distinct patterns of hemodynamic responses which could be utilized in a pattern classifier towards developing a BCI. We applied two different pattern recognition algorithms separately, Support Vector Machines (SVM) and Hidden Markov Model (HMM), to classify the data offline. SVM classified left-hand imagery from right-hand imagery with an average accuracy of 73 % for all volunteers, while HMM performed better with an average accuracy of 89%. Our results indicate potential application of NIRS in the development of BCIs. We also discuss here future extension of our system to develop a word speller application based on a cursor control paradigm incorporating online pattern classification of single-trial NIRS data. (c) 2006 Elsevier Inc. All rights reserved.
RI Guan, Cuntai/G-7835-2016; THULASIDAS, Manoj/A-9920-2017
OI Guan, Cuntai/0000-0002-0872-3276; Sitaram,
   Ranganatha/0000-0002-8577-8035; Birbaumer, Niels/0000-0002-6786-5127
SN 1053-8119
EI 1095-9572
PD FEB 15
PY 2007
VL 34
IS 4
BP 1416
EP 1427
DI 10.1016/j.neuroimage.2006.11.005
UT WOS:000244349900009
PM 17196832
ER

PT J
AU Bohada, JA
   Riano, D
   Lopez-Vallverdu, JA
AF Bohada, John A.
   Riano, David
   Lopez-Vallverdu, Joan A.
TI Automatic generation of clinical algorithms within the
   state-decision-action model
SO EXPERT SYSTEMS WITH APPLICATIONS
AB Objective: To propose a methodology to automatically induce state-decision-action diagrams from health-care databases and electronic health records in order to show health-care professionals an explicit representation of the past health-care procedures carried out in a health-care organization and to use these representations to study the deviations with respect to official and predefined protocols and clinical algorithms.
   Materials and methods: The methodology is based on two data and knowledge structures: episode of care database and set of rules. These two structures contain, respectively, patient data from health-care centres and the translation rules which are used to adapt the data of the episode of care database to the terminology we want the resulting state-decision-action diagram to have. The data expressed in the new terminology is used to generate the final state-decision-action diagram by means of a machine learning method.
   Materials and methods: We have performed several tests on the treatment of hypertension with data from the SAGESSA Health-care Group in Spain. The state-decision-action diagrams obtained have been analyzed at the level of their ability to predict correct treatments and at the level of their adherence to the clinical algorithms published by four official health-care organizations.
   Results: The state-decision-action diagrams obtained represent an average 94.6% of the treatments in the database, only excluding some atypical cases. Moreover, these diagrams show a high level of adherence to the treatment proposed by the National Heart Foundation of Australia and the Spanish Society for Hypertension with about 90.4% of coincident treatment.
   Conclusions: A new methodology has been developed and validated which automatically induces state-decision-action diagrams which can be used as a graphical representation of the health-care procedures carried out in health-care organizations. The methodology is also a tool to study the adherence of these health-care procedures to the official standards. (C) 2012 Elsevier Ltd. All rights reserved.
RI Riaño, David/C-5664-2013; Bohada, John A./ABA-2734-2021; Bohada, John
   A./U-1492-2019
OI Riaño, David/0000-0002-1608-0215; Bohada, John A./0000-0002-3382-0190; 
SN 0957-4174
EI 1873-6793
PD SEP 15
PY 2012
VL 39
IS 12
BP 10709
EP 10721
DI 10.1016/j.eswa.2012.02.196
UT WOS:000305863300039
ER

PT C
AU Boroumand, A
   Ghose, S
   Akin, B
   Narayanaswami, R
   Oliveira, GF
   Ma, XY
   Shiu, E
   Mutlu, O
AF Boroumand, Amirali
   Ghose, Saugata
   Akin, Berkin
   Narayanaswami, Ravi
   Oliveira, Geraldo F.
   Ma, Xiaoyu
   Shiu, Eric
   Mutlu, Onur
BE Lee, J
   Cohen, A
TI Google Neural Network Models for Edge Devices: Analyzing and Mitigating
   Machine Learning Inference Bottlenecks
SO 30TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION
   TECHNIQUES (PACT 2021)
SE International Conference on Parallel Architectures and Compilation
   Techniques
CT 30th International Conference on Parallel Architectures and Compilation
   Techniques (PACT)
CY SEP 26-29, 2021
CL ELECTR NETWORK
SP IEEE Comp Soc, ACM SIGPLAN, Samsung, Reservoir Labs, Seoul Natl Univ
AB Emerging edge computing platforms often contain machine learning (ML) accelerators that can accelerate inference for a wide range of neural network (NN) models. These models are designed to fit within the limited area and energy constraints of the edge computing platforms, each targeting various applications (e.g., face detection, speech recognition, translation, image captioning, video analytics). To understand how edge ML accelerators perform, we characterize the performance of a commercial Google Edge TPU, using 24 Google edge NN models (which span a wide range of NN model types) and analyzing each NN layer within each model. We find that the Edge TPU suffers from three major shortcomings: (1) it operates significantly below peak computational throughput, (2) it operates significantly below its theoretical energy efficiency, and (3) its memory system is a large energy and performance bottleneck. Our characterization reveals that the one-size-fits-all, monolithic design of the Edge TPU ignores the high degree of heterogeneity both across different NN models and across different NN layers within the same NN model, leading to the shortcomings we observe.
   We propose a new acceleration framework called Mensa. Mensa incorporates multiple heterogeneous edge ML accelerators (including both on-chip and near-data accelerators), each of which caters to the characteristics of a particular subset of NN models and layers. During NN inference, for each NN layer, Mensa decides which accelerator to schedule the layer on, taking into account both the optimality of each accelerator for the layer and layer-to-layer communication costs. Our comprehensive analysis of the Google edge NN models shows that all of the layers naturally group into a small number of clusters, which allows us to design an efficient implementation of Mensa for these models with only three specialized accelerators. Averaged across all 24 Google edge NN models, Mensa improves energy efficiency and throughput by 3.0x and 3.1x over the Edge TPU, and by 2.4x and 4.3x over Eyeriss v2, a state-of-the-art accelerator.
RI Ghose, Saugata/GPK-2625-2022
SN 1089-795X
BN 978-1-6654-4278-7
PY 2021
BP 159
EP 172
DI 10.1109/PACT52795.2021.00019
UT WOS:000758464500012
ER

PT C
AU Sorkhabi, MM
   Benjaber, M
   Brown, P
   Denison, T
AF Sorkhabi, Majid Memarian
   Benjaber, Moaad
   Brown, Peter
   Denison, Timothy
GP IEEE
TI Physiological Artifacts and the Implications for Brain-Machine-Interface
   Design
SO 2020 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 11-14, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Syst Man & Cybernet Soc, IEEE Brain, Intheon, Guger Technologies
AB The accurate measurement of brain activity by Brain-Machine-Interfaces (BMI) and closed-loop Deep Brain Stimulators (DBS) is one of the most important steps in communicating between the brain and subsequent processing blocks. In conventional chest-mounted systems, frequently used in DBS, a significant amount of artifact can be induced in the sensing interface, often as a common-mode signal applied between the case and the sensing electrodes. Attenuating this common-mode signal can be a serious challenge in these systems due to finite common-mode-rejection-ratio (CMRR) capability in the interface. Emerging BMI and DBS devices are being developed which can mount on the skull. Mounting the system on the cranial region can potentially suppress these induced physiological signals by limiting the artifact amplitude. In this study, we model the effect of artifacts by focusing on cardiac activity, using a current- source dipole model in a torso-shaped volume conductor. Performing finite element simulation with the different DBS architectures, we estimate the ECG common mode artifacts for several device architectures. Using this model helps define the overall requirements for the total system CMRR to maintain resolution of brain activity. The results of the simulations estimate that the cardiac artifacts for skull-mounted systems will have a significantly lower effect than non-cranial systems that include the pectoral region. It is expected that with a pectoral mounted device, a minimum of 60-80 dB CMRR is required to suppress the ECG artifact, depending on device placement relative to the cardiac dipole, while in cranially mounted devices, a 0 dB CMRR is sufficient, in the worst-case scenario. In addition, the model suggests existing commercial devices could optimize performance with a right-hand side placement. The methods used for estimating cardiac artifacts can be extended to other sources such as motion/muscle sources. The susceptibility of the device to artifacts has significant implications for the practical translation of closed-loop DBS and BMI, including the choice of biomarkers, the system design requirements, and the surgical placement of the device relative to artifact sources.
OI Denison, Timothy/0000-0002-5404-4004
SN 1062-922X
BN 978-1-7281-8526-2
PY 2020
BP 1498
EP 1504
UT WOS:000687430601082
PM 33479560
ER

PT J
AU Lajis, MA
   Hosni, NAJ
AF Lajis, M. A.
   Hosni, N. A. J.
TI The influences of various mixed dielectric fluids on the performance
   electrical discharge machining of AISI D2 hardened steel
SO MATERIALWISSENSCHAFT UND WERKSTOFFTECHNIK
AB This research mainly explores the influence of various mixed dielectric fluids on the performance of electrical discharge machining of AISI D2 hardened steels. In this investigation, four types of dielectric fluids such as pure kerosene, kerosene and chromium powder mixed, kerosene and Span-20 surfactant and the combination of kerosene with chromium powder and Span-20 surfactant were studied. The obtained results illustrated that the addition of chromium powder and Span-20 surfactant in the dielectric fluid obtained high material removal rate, low electrode wear rate and good surface finish. The presence of chromium powder will stabilize the gap distance between electrodes which promotes the occurrence of multiple discharges in one input pulse and particle agglomeration is reduced after Span-20 surfactant molecules cover the surface of debris and carbon dregs in kerosene solution. Combination of kerosene with chromium and Span-20 surfactant were found significant to improve the effects of carbon accumulation and drag discharge, and reduce unstable concentrated discharge.
   Translation abstract Diese Forschung untersucht hauptsachlich den Einfluss verschiedener gemischter dielektrischer Flussigkeiten auf die Leistung der Funkenerosion von geharteten AISI D2-Stahlen. In dieser Untersuchung wurden vier Arten dielektrischer Flussigkeiten, wie reines Kerosin, Kerosin und Chrom-Pulver gemischt, Kerosin und Span-20-Tensid und die Kombination von Kerosin mit Chrom-Pulver und Span-20-Tensid untersucht. Die Ergebnisse zeigen, dass die Zugabe von Chrom-Pulver und Span-20-Tensid in die dielektrische Flussigkeit eine hohe Materialentfernungsrate, eine geringe Elektrodenverschlei ss rate und eine gute Oberflachengute ergibt. Das Vorhandensein von Chrom-Pulver stabilisiert den Spaltabstand zwischen den Elektroden, was das Auftreten von Mehrfachentladungen in einem Eingangsimpuls fordert und die Partikelagglomeration wird reduziert, nachdem Span-20-Tensidmolekule die Oberflache von Ablagerungen und Kohlenstoffabrieb in Kerosinlosung bedecken. Die Kombination von Kerosin mit Chrom-Pulver und Span-20-Tensid verbessert die Wirkungen der Kohlenstoffakkumulation und der Dreg-Entladung signifikant und reduziert die instabile konzentrierte Entladung.
RI Jamil Hosni, Nor Ain/ABA-1217-2021; Lajis, Mohd Amri/AAI-5119-2021
OI Lajis, Mohd Amri/0000-0002-8252-6510
SN 0933-5137
EI 1521-4052
PD APR
PY 2018
VL 49
IS 4
SI SI
BP 413
EP 419
DI 10.1002/mawe.201700253
UT WOS:000431007700001
ER

PT J
AU Liu, S
   Gurses, C
   Sha, ZY
   Quach, MM
   Sencer, A
   Bebek, N
   Curry, DJ
   Prabhu, S
   Tummala, S
   Henry, TR
   Ince, NF
AF Liu, Su
   Gurses, Candan
   Sha, Zhiyi
   Quach, Michael M.
   Sencer, Altay
   Bebek, Nerses
   Curry, Daniel J.
   Prabhu, Sujit
   Tummala, Sudhakar
   Henry, Thomas R.
   Ince, Nuri F.
TI Stereotyped high-frequency oscillations discriminate seizure onset zones
   and critical functional cortex in focal epilepsy
SO BRAIN
AB High-frequency oscillations are putative biomarkers of seizure onset zones, but can also be recorded from non-epileptic structures. Using machine-learning, Liu et al. show that HFOs generated by epileptic tissues produce stereotyped waveform patterns rarely observed in non-epileptogenic cortex, and discriminate between seizure onset zones, "eloquent" cortex and other cerebral regions.High-frequency oscillations in local field potentials recorded with intracranial EEG are putative biomarkers of seizure onset zones in epileptic brain. However, localized 80-500 Hz oscillations can also be recorded from normal and non-epileptic cerebral structures. When defined only by rate or frequency, physiological high-frequency oscillations are indistinguishable from pathological ones, which limit their application in epilepsy presurgical planning. We hypothesized that pathological high-frequency oscillations occur in a repetitive fashion with a similar waveform morphology that specifically indicates seizure onset zones. We investigated the waveform patterns of automatically detected high-frequency oscillations in 13 epilepsy patients and five control subjects, with an average of 73 subdural and intracerebral electrodes recorded per patient. The repetitive oscillatory waveforms were identified by using a pipeline of unsupervised machine learning techniques and were then correlated with independently clinician-defined seizure onset zones. Consistently in all patients, the stereotypical high-frequency oscillations with the highest degree of waveform similarity were localized within the seizure onset zones only, whereas the channels generating high-frequency oscillations embedded in random waveforms were found in the functional regions independent from the epileptogenic locations. The repetitive waveform pattern was more evident in fast ripples compared to ripples, suggesting a potential association between waveform repetition and the underlying pathological network. Our findings provided a new tool for the interpretation of pathological high-frequency oscillations that can be efficiently applied to distinguish seizure onset zones from functionally important sites, which is a critical step towards the translation of these signature events into valid clinical biomarkers.
RI Sencer, Altay/AAD-8002-2020; bebek, nerses/W-7266-2019; Henry,
   Thomas/X-1756-2019
OI Henry, Thomas/0000-0002-5708-903X
SN 0006-8950
EI 1460-2156
PD MAR
PY 2018
VL 141
BP 713
EP 730
DI 10.1093/brain/awx374
PN 3
UT WOS:000426813600018
PM 29394328
ER

PT C
AU Ikeda, Y
   Kobayashi, N
   Kuzmenko, PJ
   Little, SL
   Mirkarimi, PB
   Alameda, JB
   Kaji, S
   Sarugaku, Y
   Yasui, C
   Kondo, S
   Fukue, K
   Kawakita, H
AF Ikeda, Yuji
   Kobayashi, Naoto
   Kuzmenko, Paul J.
   Little, Steve L.
   Mirkarimi, Paul B.
   Alameda, Jennifer B.
   Kaji, Sayumi
   Sarugaku, Yuki
   Yasui, Chikako
   Kondo, Sohei
   Fukue, Kei
   Kawakita, Hideyo
BE Navarro, R
   Cunningham, CR
   Barto, AA
TI ZnSe immersion grating in the short NIR region
SO ADVANCES IN OPTICAL AND MECHANICAL TECHNOLOGIES FOR TELESCOPES AND
   INSTRUMENTATION
SE Proceedings of SPIE
CT Conference on Advances in Optical and Mechanical Technologies for
   Telescopes and Instrumentation
CY JUN 23-27, 2014
CL Montreal, CANADA
SP SPIE
AB ZnSe has a high refractive index (n similar to 2.45) and low optical loss (<0.1/cm) from 0.8 to 12 um. Therefore ZnSe immersion gratings can enable high-resolution spectroscopy over a wide wavelength range. We are developing ZnSe immersion gratings for a ground-based NIR high-resolution spectrograph WINERED. We previously produced a large prism-shaped ZnSe immersion grating with a grooved area 50 mm x 58 mm (Ikeda et al. 2010). However, we find two problems as NIR immersion grating: (i) serious chipping of the grooves, and (ii) inter-order ghosts in the diffraction pattern. We believed the chipping to be due to micro cracks just beneath surface present prior to diamond machining. Therefore we removed this damaged region, a few tens of microns thick, by etching the ZnSe grating blank with a mixture of HCl and HNO3. Ghosts appearing halfway between main diffraction orders originate from small differences in spacing between odd and even grooves. Apparently the blank shifts repeatably by about 120 nm in the direction orthogonal to the grooves depending on whether the translation stage holding the blank is moving right to left or left to right. Therefore we re-machined the grating only cutting grooves with the stage moving from right to left. After re-cutting, we also deposit the Cu coating with an enhanced interface layer of SiO2 on the groove, which is developed in our previous study. We evaluated the optical performances of this immersion grating. It shows light scattering of 3.8 % at 1 mu m, no prominent ghosts, and a spectral resolution of 91,200 at 1 mu m. However we measured an absolute diffraction efficiency of only 27.3% for TE and 25.9 % for TM waves at 1.55 mu m. A non-immersed measurement of the diffraction efficiency of the facet blazed near 20 degrees exceeded 60%, much closer to theoretical predictions. We plan to carry out more tests to resolve this discrepancy.
OI Mirkarimi, Paul/0000-0003-1796-0916; Yasui, Chikako/0000-0003-3579-7454
SN 0277-786X
EI 1996-756X
BN 978-0-8194-9619-5
PY 2014
VL 9151
AR 915144
DI 10.1117/12.2055378
UT WOS:000354525500125
ER

PT C
AU Tavakoli, HM
   Ru, BS
   Xie, TY
   Hadzikadic, M
   Wu, QJ
   Ge, YR
AF Tavakoli, Maryam H.
   Ru, Boshu
   Xie, Tianyi
   Hadzikadic, Mirsad
   Wu, Q. Jackie
   Ge, Yaorong
BE Yoo, IH
   Bi, JB
   Hu, X
TI Dose Prediction for Prostate Radiation Treatment: Feasibility of a
   Distance-Based Deep Learning Model
SO 2019 IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICINE
   (BIBM)
SE IEEE International Conference on Bioinformatics and Biomedicine-BIBM
CT IEEE International Conference on Bioinformatics and Biomedicine (BIBM)
CY NOV 18-21, 2019
CL San Diego, CA
SP IEEE, NSF
AB This study aims to demonstrate the feasibility of using a novel distance-based representation of 3D CT-scan images to train a deep learning model for dose predictions in radiation treatment planning. The distance representation is inspired by previous knowledge of the domain to increase the generalizability of the deep learning models for radiation treatment planning.
   Conventional knowledge-based planning methods extract engineered features from 3D CT-scan images, as well as other patients' features, to predict the best achievable dose in a cancerous area and other organs at risk. Recent studies have shown higher accuracy in voxel-level dose prediction using deep learning models compared to the conventional machine learning approaches. Since the data resources for training these models are limited, most of the studies use 2D contour information to represent the patient anatomy. This representation loses volumetric information, and it is sensitive to small changes in patient orientation and translation.
   The distance-based representation introduced in this paper is inspired by the domain knowledge and is able to maintain the volumetric distance information despite the 2D slicing of 3D CT-image. According to prior studies in the radiation treatment planning domain, there is a strong association between the organs-at-risk distance from the cancerous volume and the patient's vulnerability to receive excessive dose. Therefore, the contour value in prior representation was replaced by voxel distance from cancerous volume. This modification in representation makes it transition and orientation invariant and adds potential robustness to patient positioning differences during the imaging/planning process.
   We evaluated the distance-based deep learning models through experiments for prediction of prostate cancer patients' vulnerability and voxel-level dose distribution using convolutional neural network and U-net models, respectively. The results were compared with contour-based U-net model as well as conventional machine learning with engineered representations. We found that the performance was comparable or higher than the prior state-of-the-art results for prostate-cancer dose distribution prediction.
RI Tavakoli, Maryam/ABF-8439-2020
OI Tavakoli, Maryam/0000-0002-8380-5511
SN 2156-1125
EI 2156-1133
BN 978-1-7281-1867-3
PY 2019
BP 2379
EP 2386
UT WOS:000555804900413
ER

PT J
AU Arent, I
   Schmidt, FP
   Botsch, M
   Durr, V
AF Arent, Ilja
   Schmidt, Florian P.
   Botsch, Mario
   Duerr, Volker
TI Marker-Less Motion Capture of Insect Locomotion With Deep Neural
   Networks Pre-trained on Synthetic Videos
SO FRONTIERS IN BEHAVIORAL NEUROSCIENCE
AB Motion capture of unrestrained moving animals is a major analytic tool in neuroethology and behavioral physiology. At present, several motion capture methodologies have been developed, all of which have particular limitations regarding experimental application. Whereas marker-based motion capture systems are very robust and easily adjusted to suit different setups, tracked species, or body parts, they cannot be applied in experimental situations where markers obstruct the natural behavior (e.g., when tracking delicate, elastic, and/or sensitive body structures). On the other hand, marker-less motion capture systems typically require setup- and animal-specific adjustments, for example by means of tailored image processing, decision heuristics, and/or machine learning of specific sample data. Among the latter, deep-learning approaches have become very popular because of their applicability to virtually any sample of video data. Nevertheless, concise evaluation of their training requirements has rarely been done, particularly with regard to the transfer of trained networks from one application to another. To address this issue, the present study uses insect locomotion as a showcase example for systematic evaluation of variation and augmentation of the training data. For that, we use artificially generated video sequences with known combinations of observed, real animal postures and randomized body position, orientation, and size. Moreover, we evaluate the generalization ability of networks that have been pre-trained on synthetic videos to video recordings of real walking insects, and estimate the benefit in terms of reduced requirement for manual annotation. We show that tracking performance is affected only little by scaling factors ranging from 0.5 to 1.5. As expected from convolutional networks, the translation of the animal has no effect. On the other hand, we show that sufficient variation of rotation in the training data is essential for performance, and make concise suggestions about how much variation is required. Our results on transfer from synthetic to real videos show that pre-training reduces the amount of necessary manual annotation by about 50%.
RI Dürr, Volker/Y-5036-2019
OI Dürr, Volker/0000-0001-9239-4964; Schmidt, Florian/0000-0001-5126-723X
SN 1662-5153
PD APR 22
PY 2021
VL 15
AR 637806
DI 10.3389/fnbeh.2021.637806
UT WOS:000647442300001
PM 33967713
ER

PT J
AU Klimova, B
   Pikhart, M
   Polakova, P
   Cerna, M
   Yayilgan, SY
   Shaikh, S
AF Klimova, Blanka
   Pikhart, Marcel
   Polakova, Petra
   Cerna, Miloslava
   Yayilgan, Sule Yildirim
   Shaikh, Sarang
TI A Systematic Review on the Use of Emerging Technologies in Teaching
   English as an Applied Language at the University Level
SO SYSTEMS
AB At present, emerging technologies, such as machine learning, deep learning, or various forms of artificial intelligence are penetrating different fields of education, including foreign language education (FLE). Moreover, the current young generation was born into the technological environment, and they perceive technologies as being an indispensable part of their everyday life. However, they mainly use technologies in their informal learning, but there is not much research into emerging technologies in FLE, namely in teaching and learning English as an applied language. Therefore, the purpose of this systematic review is to identify, bring together, compare and analyze all of the technologies that are currently efficiently employed in foreign language teaching and learning, and based on the findings of the detected experimental studies, we provide specific pedagogical implications on how to use these technologies in the acquisition of English as an applied language at the university level. The methodology followed the PRISMA guidelines for systematic reviews and meta-analyses. The results of the detected experimental studies revealed that there was a serious lack of the latest technologies, such as chatbots or virtual reality (VR) devices, that are being empirically employed in a foreign language (FL) education. Moreover, mobile apps are merely focused on the development of FL vocabulary. The findings also indicate that although the FL teachers might theoretically know about these latest technological devices, such as neural machine translation, they do not know how to practically implement them in their teaching process. Therefore, this research suggests that teachers must be trained and pedagogically guided on how to purposefully implement them in their FL classes to support traditional instruction in order to identify what skills or language structures could be developed through their use. In addition, it is also claimed that more experimental studies are needed to clearly the evidence and its usefulness in teaching a foreign language as an applied language.
RI Klimova, Blanka/F-7016-2019; Pikhart, Marcel/D-8945-2012
OI Klimova, Blanka/0000-0001-8000-9766; Pikhart, Marcel/0000-0002-5633-9332
EI 2079-8954
PD JAN
PY 2023
VL 11
IS 1
AR 42
DI 10.3390/systems11010042
UT WOS:000927196700001
ER

PT C
AU Lin, WJ
   Chiu, MC
AF Lin, Wan-Jun
   Chiu, Ming-Chuan
BE Chen, CH
   Trappey, AC
   Peruzzini, M
   Stjepandic, J
   Wognum, N
TI Design a Personalized Brain-Computer Interface of LegoRobot Assisted by
   Data Analysis Method
SO TRANSDISCIPLINARY ENGINEERING: A PARADIGM SHIFT
SE Advances in Transdisciplinary Engineering
CT 24th ISPE Inc. International Conference on Transdisciplinary Engineering
CY JUL 10-14, 2017
CL Nanyang Technol Univ, Singapore, SINGAPORE
SP Int Soc Product Enhancement Inc, Fraunhofer, IOS Press, PROSTEP AG
HO Nanyang Technol Univ
AB In our daily life, the data is ubiquitous. With the advent of the data age, people's lives are closely related to it. Therefore, it is important to use these data for analysis to get effective conclusions. Through the data analysis method, we can analyze the results to do effective decisions-making and applications, more applicable to the interface design. Brain-computer interface (BCI) provides the communicated interface between brain and machines such as computers. It's a technique that the users allowed to interact directly with the machine by using brainwave. The technology includes brainwave (EEG) acquisition, feature extraction and translation algorithm. The researches of BCIs since the 1970s began, the most successful case was Jacques Vidal used brainwave signals to stimulate the visual response and controlled the cursor to take the maze of BCI. Nowadays, it has begun to use in medical aids, and improve the inconvenient situation in daily life. However, the applications in "personalized" BCIs are not popular in our life and less of a data validation to support the user-centric design process to provide. Therefore, this study firstly took the mobile application program of the Lego robot designed by the function as an example. Then used the data of the initial test which was assisted by the Data Analysis Method (DAM). The decision made by DAM was to redesign a data-oriented demonstration and user-centered design process (DAUCD). The Lego robot was integrated hardware and software to develop the learnable and personalized BCI. For usability test, we applied the Lego robots to demonstrate the redesign prototype to conduct the usability test. This study not only designed a personalized BCI but also developed a new data-oriented UCD design process. The brand-new method with DAUCD improved the original design and enhanced the usability test. We expect that this personalized BCI will be applied in medical treatments, businesses and livelihood, promoting the welfare of human being.
SN 2352-7528
BN 978-1-61499-779-5; 978-1-61499-778-8
PY 2017
VL 5
BP 311
EP 320
DI 10.3233/978-1-61499-779-5-311
UT WOS:000449466100036
ER

PT J
AU Vowels, LM
   Vowels, MJ
   Mark, KP
AF Vowels, Laura M.
   Vowels, Matthew J.
   Mark, Kristen P.
TI Uncovering the Most Important Factors for Predicting Sexual Desire Using
   Explainable Machine Learning
SO JOURNAL OF SEXUAL MEDICINE
AB Background: Low sexual desire is the most common sexual problem reported with 34% of women and 15% of men reporting lack of desire for at least 3 months in a 12-month period. Sexual desire has previously been associated with both relationship and individual well-being highlighting the importance of understanding factors that contribute to sexual desire as improving sexual desire difficulties can help improve an individual's overall quality of life.
   Aim: The purpose of the present study was to identify the most salient individual (eg, attachment style, attitudes toward sexuality, gender) and relational (eg, relationship satisfaction, sexual satisfaction, romantic love) predictors of dyadic and solitary sexual desire from a large number of predictor variables.
   Methods: Previous research has relied primarily on traditional statistical models which are limited in their ability to estimate a large number of predictors, non-linear associations, and complex interactions. We used a machine learning algorithm, random forest (a type of highly non-linear decision tree), to circumvent these issues to predict dyadic and solitary sexual desire from a large number of predictors across 2 online samples (N = 1,846; includes 754 individuals forming 377 couples). We also used a Shapley value technique to estimate the size and direction of the effect of each predictor variable on the model outcome.
   Outcomes: The outcomes included total, dyadic, and solitary sexual desire measured using the Sexual Desire Inventory.
   Results: The models predicted around 40% of variance in dyadic and solitary desire with women's desire being more predictable than men's overall. Several variables consistently predicted dyadic sexual desire such as sexual satisfaction and romantic love, and solitary desire such as masturbation and attitudes toward sexuality. These predictors were similar for both men and women and gender was not an important predictor of sexual desire.
   Clinical Translation: The results highlight the importance of addressing overall relationship satisfaction when sexual desire difficulties are presented in couples therapy. It is also important to understand clients' attitudes toward sexuality.
   Strengths & Limitations: The study improves on existing methodologies in the field and compares a large number of predictors of sexual desire. However, the data were cross-sectional and there may have been variables that are important for desire but were not present in the datasets.
   Conclusion: Higher sexual satisfaction and feelings of romantic love toward one's partner are important predictors of dyadic sexual desire whereas regular masturbation and more permissive attitudes toward sexuality predicted solitary sexual desire. Copyright (C) 2021, International Society of Sexual Medicine. Published by Elsevier Inc. All rights reserved.
RI Mark, Kristen/HNC-4886-2023
OI Vowels, Laura/0000-0001-5594-2095
SN 1743-6095
EI 1743-6109
PD JUL
PY 2021
VL 18
IS 7
BP 1198
EP 1216
DI 10.1016/j.jsxm.2021.04.010
EA JUL 2021
UT WOS:000675477900006
PM 34183292
ER

PT C
AU Nemeth, G
AF Nemeth, Geza
BE Ronzhin, A
   Potapova, R
   Delic, V
TI Gaps to Bridge in Speech Technology
SO SPEECH AND COMPUTER
SE Lecture Notes in Artificial Intelligence
CT 16th International Conference on Speech and Computer (SPECOM)
CY OCT 05-09, 2014
CL Novi Sad, SERBIA
SP Univ Novi Sad, Fac Tech Sci, Int Speech Commun Assoc, AlfaNum Speech Technologies Ltd, Speech Technol Ctr Ltd, Moscow State Linguist Univ, Russian Acad Sci, St. Petersburg Inst Informat & Automat
AB Although recently there has been significant progress in the general usage and acceptance of speech technology in several developed countries there are still major gaps that prevent the majority of possible users from daily use of speech technology-based solutions. In this paper some of them are listed and some directions for bridging these gaps are proposed. Perhaps the most important gap is the "Black box" thinking of software developers. They suppose that inputting text into a text-to-speech (TTS) system will result in voice output that is relevant to the given context of the application. In case of automatic speech recognition (ASR) they wait for accurate text transcription (even punctuation). It is ignored that even humans are strongly influenced by a priori knowledge of the context, the communication partners, etc. For example by serially combining ASR + machine translation + TTS in a speech-to-speech translation system a male speaker at a slow speaking rate might be represented by a fast female voice at the other end. The science of semantic modelling is still in its infancy. In order to produce successful applications researchers of speech technology should find ways to build-in the a priori knowledge into the application environment, adapt their technologies and interfaces to the given scenario. This leads us to the gap between generic and domain specific solutions. For example intelligibility and speaking rate variability are the most important TTS evaluation factors for visually impaired users while human-like announcements at a standard rate and speaking style are required for railway station information systems. An increasing gap is being built between "large" languages/markets and "small" ones. Another gap is the one between closed and open application environments. For example there is hardly any mobile operating system that allows TTS output re-direction into a live telephone conversation. That is a basic need for rehabilitation applications of speech impaired people. Creating an open platform where "smaller" and "bigger" players of the field could equally plug-in their engines/solutions at proper quality assurance and with a fair share of income could help the situation. In the paper some examples are given about how our teams at BME TMIT try to bridge the gaps listed.
RI Nemeth, Geza/N-1734-2013
OI Nemeth, Geza/0000-0002-2311-4858
SN 0302-9743
EI 1611-3349
BN 978-3-319-11581-8; 978-3-319-11580-1
PY 2014
VL 8773
BP 15
EP 23
UT WOS:000345576400002
ER

PT J
AU Shi, CY
   Tazi, A
   Fang, DX
   Iannuzzi, C
AF Shi, Chengyu
   Tazi, Adam
   Fang, Deborah Xiangdong
   Iannuzzi, Christopher
TI Study of ExacTrac X-ray 6D IGRT setup uncertainty for marker-based
   prostate IMRT treatment
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
AB Novalis Tx ExacTrac X-ray system has the 6D adjustment ability for patient setup. Limited studies exist about the setup uncertainty with ExacTrac X-ray system for IMRT prostate treatment with fiducial markers implanted. The purpose of this study is to investigate the marker-based prostate IMRT treatment setup uncertainty using ExacTrac 6D IGRT ability for patient setup. Forty-three patients with prostate cancers and markers implanted have been treated on the Novalis Tx machine. The ExacTrac X-ray system has been used for the patient pretreatment setup and intratreatment verification. In total, the shifts data for 1261 fractions and 3504 correction times (the numbers of X-ray images were taken from tube 1 and tube 2) have been analyzed. The setup uncertainty has been separated into uncertainties in 6D. Marker matching uncertainty was also analyzed. Correction frequency probability density function was plotted, and the radiation dose for imaging was calculated. The minimum, average, and maximum translation shifts were: -5.12 +/- 3.89 mm, 0.20 +/- 2.21 mm, and 6.07 +/- 4.44 mm, respectively, in the lateral direction; -6.80 +/- 3.21 mm, -1.09 +/- 2.21 mm, and 3.12 +/- 2.62 mm, respectively, in the longitudinal direction; and -7.33 +/- 3.46 mm, -0.93 +/- 2.70 mm, and 5.93 +/- 4.85 mm, respectively, in the vertical direction. The minimum, average, and maximum rotation shifts were: -1.23 degrees +/- 1.95 degrees, 0.25 degrees +/- 1.30 degrees, and 2.38 degrees +/- 2.91 degrees, respectively, along lateral direction; -0.67 degrees +/- 0.91 degrees, 0.10 degrees +/- 0.61 degrees, and 1.51 degrees +/- 2.04 degrees, respectively, along longitudinal direction; and -0.75 degrees +/- 1.01 degrees, 0.02 degrees +/- 0.50 degrees, and 0.82 degrees +/- 1.13 degrees, respectively, along vertical direction. On average, each patient had three correction times during one fraction treatment. The radiation dose is about 3 mSv per fraction. With the ExacTrac 6D X-ray system, the prostate IMRT treatment with marker implanted can achieve less than 2 mm setup uncertainty in translations, and less than 0.25 degrees in rotations as overall interfraction mean error. The imaging dose is less than kV (CBCT) for setup verification.
SN 1526-9914
PY 2012
VL 13
IS 3
BP 35
EP 42
DI 10.1120/jacmp.v13i3.3757
UT WOS:000304141400004
ER

PT J
AU Clanton, TO
   Williams, BT
   Backus, JD
   Dornan, GJ
   Liechti, DJ
   Whitlow, SR
   Saroki, AJ
   Turnbull, TL
   LaPrade, RF
AF Clanton, Thomas O.
   Williams, Brady T.
   Backus, Jonathon D.
   Dornan, Grant J.
   Liechti, Daniel J.
   Whitlow, Scott R.
   Saroki, Adriana J.
   Turnbull, Travis Lee
   LaPrade, Robert F.
TI Biomechanical Analysis of the Individual Ligament Contributions to
   Syndesmotic Stability
SO FOOT & ANKLE INTERNATIONAL
AB Background: Biomechanical data and contributions to ankle joint stability have been previously reported for the individual distal tibiofibular ligaments. These results have not yet been validated based on recent anatomic descriptions or using current biomechanical testing devices.
   Methods: Eight matched-pair, lower leg specimens were tested using a dynamic, biaxial testing machine. The proximal tibiofibular joint and the medial and lateral ankle ligaments were left intact. After fixation, specimens were preconditioned and then biomechanically tested following sequential cutting of the tibiofibular ligaments to assess the individual ligamentous contributions to syndesmotic stability. Matched paired specimens were randomly divided into 1 of 2 cutting sequences: (1) anterior-to-posterior: intact, anterior inferior tibiofibular ligament (AITFL), interosseous tibiofibular ligament (ITFL), deep posterior inferior tibiofibular ligament (PITFL), superficial PITFL, and complete interosseous membrane; (2) posterior-to-anterior: intact, superficial PITFL, deep PITFL, ITFL, AITFL, and complete interosseous membrane. While under a 750-N axial compressive load, the foot was rotated to 15 degrees of external rotation and 10 degrees of internal rotation for each sectioned state. Torque (Nm), rotational position (degrees), and 3-dimensional data were recorded continuously throughout testing.
   Results: Testing of the intact ankle syndesmosis under simulated physiologic conditions revealed 4.3 degrees of fibular rotation in the axial plane and 3.3 mm of fibular translation in the sagittal plane. Significant increases in fibular sagittal translation and axial rotation were observed after syndesmotic injury, particularly after sectioning of the AITFL and superficial PITFL. Sequential sectioning of the syndesmotic ligaments resulted in significant reductions in resistance to both internal and external rotation. Isolated injuries to the AITFL resulted in the most substantial reduction of resistance to external rotation (average of 24%). However, resistance to internal rotation was not significantly diminished until the majority of the syndesmotic structures had been sectioned.
   Conclusion: The ligaments of the syndesmosis provide significant contributions to rotary stability of the distal tibiofibular joint within the physiologic range of motion.
   Clinical Relevance: This study defined normal motion of the syndesmosis and the biomechanical consequences of injury. The degree of instability was increased with each additional injured structure; however, isolated injuries to the AITFL alone may lead to significant external rotary instability.
RI Clanton, Thomas O./I-7558-2019; Dornan, Grant/ABC-7409-2020; LaPrade,
   Robert F./AFA-8673-2022
OI Clanton, Thomas O./0000-0001-9831-7484; LaPrade, Robert
   F./0000-0002-9823-2306; Dornan, Grant/0000-0001-9039-9163
SN 1071-1007
EI 1944-7876
PD JAN
PY 2017
VL 38
IS 1
BP 66
EP 75
DI 10.1177/1071100716666277
UT WOS:000391808100010
PM 27681857
ER

PT J
AU Wang, Y
   Shan, GB
   Li, H
   Wang, L
AF Wang, Ye
   Shan, Gongbing
   Li, Hua
   Wang, Lin
TI A Wearable-Sensor System with AI Technology for Real-Time Biomechanical
   Feedback Training in Hammer Throw
SO SENSORS
AB Developing real-time biomechanical feedback systems for in-field applications will transfer human motor skills' learning/training from subjective (experience-based) to objective (science-based). The translation will greatly improve the efficiency of human motor skills' learning and training. Such a translation is especially indispensable for the hammer-throw training which still relies on coaches' experience/observation and has not seen a new world record since 1986. Therefore, we developed a wearable wireless sensor system combining with artificial intelligence for real-time biomechanical feedback training in hammer throw. A framework was devised for developing such practical wearable systems. A printed circuit board was designed to miniaturize the size of the wearable device, where an Arduino microcontroller, an XBee wireless communication module, an embedded load cell and two micro inertial measurement units (IMUs) could be inserted/connected onto the board. The load cell was for measuring the wire tension, while the two IMUs were for determining the vertical displacements of the wrists and the hip. After calibration, the device returned a mean relative error of 0.87% for the load cell and the accuracy of 6% for the IMUs. Further, two deep neural network models were built to estimate selected joint angles of upper and lower limbs related to limb coordination based on the IMUs' measurements. The estimation errors for both models were within an acceptable range, i.e., approximately +/- 12 degrees and +/- 4 degrees, respectively, demonstrating strong correlation existed between the limb coordination and the IMUs' measurements. The results of the current study suggest a remarkable novelty: the difficulty-to-measure human motor skills, especially in those sports involving high speed and complex motor skills, can be tracked by wearable sensors with neglect movement constraints to the athletes. Therefore, the application of artificial intelligence in a wearable system has shown great potential of establishing real-time biomechanical feedback training in various sports. To our best knowledge, this is the first practical research of combing wearables and machine learning to provide biomechanical feedback in hammer throw. Hopefully, more wearable biomechanical feedback systems integrating artificial intelligence would be developed in the future.
RI Wang, Lin/HNN-5231-2023
OI Wang, Lin/0000-0002-9111-2723; Shan, Gongbing/0000-0001-9864-715X
EI 1424-8220
PD JAN
PY 2023
VL 23
IS 1
AR 425
DI 10.3390/s23010425
UT WOS:000909593700001
PM 36617025
ER

PT J
AU Lopez, Y
   Patil, A
   Nakai, K
AF Lopez, Yosvany
   Patil, Ashwini
   Nakai, Kenta
TI Identification of novel motif patterns to decipher the promoter
   architecture of co-expressed genes in Arabidopsis thaliana
SO BMC SYSTEMS BIOLOGY
CT InCoB conference
CY SEP 20-22, 2013
CL Ctr Syst Biol Soochow Univ, Taicang, PEOPLES R CHINA
HO Ctr Syst Biol Soochow Univ
AB Background: The understanding of the mechanisms of transcriptional regulation remains a challenge for molecular biologists in the post-genome era. It is hypothesized that the regulatory regions of genes expressed in the same tissue or cell type share a similar structure. Though several studies have analyzed the promoters of genes expressed in specific metazoan tissues or cells, little research has been done in plants. Hence finding specific patterns of motifs to explain the promoter architecture of co-expressed genes in plants could shed light on their transcription mechanism.
   Results: We identified novel patterns of sets of motifs in promoters of genes co-expressed in four different plant structures (PSs) and in the entire plant in Arabidopsis thaliana. Sets of genes expressed in four PSs (flower, seed, root, shoot) and housekeeping genes expressed in the entire plant were taken from a database of co-expressed genes in A. thaliana. PS-specific motifs were predicted using three motif-discovery algorithms, 8 of which are novel, to the best of our knowledge. A support vector machine was trained using the average upstream distance of the identified motifs from the translation start site on both strands of binding sites. The correctly classified promoters per PS were used to construct specific patterns of sets of motifs to describe the promoter architecture of those co-expressed genes. The discovered PS-specific patterns were tested in the entire A. thaliana genome, correctly identifying 77.8%, 81.2%, 70.8% and 53.7% genes expressed in petal differentiation, synergid cells, root hair and trichome, as well as 88.4% housekeeping genes.
   Conclusions: We present five patterns of sets of motifs which describe the promoter architecture of co-expressed genes in five PSs with the ability to predict them from the entire A. thaliana genome. Based on these findings, we conclude that the positioning and orientation of transcription factor binding sites at specific distances from the translation start site is a reliable measure to differentiate promoters of genes expressed in different A. thaliana structures from background genomic promoters. Our method can be used to predict novel motifs and decipher a similar promoter architecture for genes co-expressed in A. thaliana under different conditions.
RI Nakai, Kenta/B-7293-2009
OI Nakai, Kenta/0000-0002-8721-8883; Patil, Ashwini/0000-0002-3353-1970;
   Lopez, Yosvany/0000-0002-9550-0053
EI 1752-0509
PD OCT 16
PY 2013
VL 7
SU 3
AR S10
DI 10.1186/1752-0509-7-S3-S10
UT WOS:000326808300010
PM 24555803
ER

PT J
AU Pasini, G
   Stefano, A
   Russo, G
   Comelli, A
   Marinozzi, F
   Bini, F
AF Pasini, Giovanni
   Stefano, Alessandro
   Russo, Giorgio
   Comelli, Albert
   Marinozzi, Franco
   Bini, Fabiano
TI Phenotyping the Histopathological Subtypes of Non-Small-Cell Lung
   Carcinoma: How Beneficial Is Radiomics?
SO DIAGNOSTICS
AB The aim of this study was to investigate the usefulness of radiomics in the absence of well-defined standard guidelines. Specifically, we extracted radiomics features from multicenter computed tomography (CT) images to differentiate between the four histopathological subtypes of non-small-cell lung carcinoma (NSCLC). In addition, the results that varied with the radiomics model were compared. We investigated the presence of the batch effects and the impact of feature harmonization on the models' performance. Moreover, the question on how the training dataset composition influenced the selected feature subsets and, consequently, the model's performance was also investigated. Therefore, through combining data from the two publicly available datasets, this study involves a total of 152 squamous cell carcinoma (SCC), 106 large cell carcinoma (LCC), 150 adenocarcinoma (ADC), and 58 no other specified (NOS). Through the matRadiomics tool, which is an example of Image Biomarker Standardization Initiative (IBSI) compliant software, 1781 radiomics features were extracted from each of the malignant lesions that were identified in CT images. After batch analysis and feature harmonization, which were based on the ComBat tool and were integrated in matRadiomics, the datasets (the harmonized and the non-harmonized) were given as an input to a machine learning modeling pipeline. The following steps were articulated: (i) training-set/test-set splitting (80/20); (ii) a Kruskal-Wallis analysis and LASSO linear regression for the feature selection; (iii) model training; (iv) a model validation and hyperparameter optimization; and (v) model testing. Model optimization consisted of a 5-fold cross-validated Bayesian optimization, repeated ten times (inner loop). The whole pipeline was repeated 10 times (outer loop) with six different machine learning classification algorithms. Moreover, the stability of the feature selection was evaluated. Results showed that the batch effects were present even if the voxels were resampled to an isotropic form and whether feature harmonization correctly removed them, even though the models' performances decreased. Moreover, the results showed that a low accuracy (61.41%) was reached when differentiating between the four subtypes, even though a high average area under curve (AUC) was reached (0.831). Further, a NOS subtype was classified as almost completely correct (true positive rate similar to 90%). The accuracy increased (77.25%) when only the SCC and ADC subtypes were considered, as well as when a high AUC (0.821) was obtained-although harmonization decreased the accuracy to 58%. Moreover, the features that contributed the most to models' performance were those extracted from wavelet decomposed and Laplacian of Gaussian (LoG) filtered images and they belonged to the texture feature class.. In conclusion, we showed that our multicenter data were affected by batch effects, that they could significantly alter the models' performance, and that feature harmonization correctly removed them. Although wavelet features seemed to be the most informative features, an absolute subset could not be identified since it changed depending on the training/testing splitting. Moreover, performance was influenced by the chosen dataset and by the machine learning methods, which could reach a high accuracy in binary classification tasks, but could underperform in multiclass problems.
   It is, therefore, essential that the scientific community propose a more systematic radiomics approach, focusing on multicenter studies, with clear and solid guidelines to facilitate the translation of radiomics to clinical practice.
EI 2075-4418
PD MAR
PY 2023
VL 13
IS 6
AR 1167
DI 10.3390/diagnostics13061167
UT WOS:000955493200001
PM 36980475
ER

PT J
AU Eken, E
AF Eken, Enes
TI Content loss and conditional space relationship in conditional
   generative adversarial networks
SO TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES
AB In the machine learning community, generative models, especially generative adversarial networks (GANs) continue to be an attractive yet challenging research topic. Right after the invention of GAN, many GAN models have been proposed by the researchers with the same goal: creating better images. The first and foremost feature that a GAN model should have is that creating realistic images that cannot be distinguished from genuine ones. A large portion of the GAN models proposed to this end have a common approach which can be defined as factoring the image generation process into multiple states for decomposing the difficult task into several more manageable sub tasks. This can be realized by using sequential conditional/unconditional generators. Although images generated by sequential generators experimentally prove the effectiveness of this approach, visually inspecting the generated images are far away of being objective and it is not yet quantitatively showed in an objective manner.
   In this paper, we quantitatively show the effectiveness of shrinking the conditional space by using the sequential generators instead of utilizing single but large generator. At the light of the content loss we demonstrate that in sequential designs, each generator helps to shrink the conditional space, and therefore reduces the loss and the uncertainties at the generated images. In order to quantitatively validate this approach, we tried different combinations of connecting generators sequentially and/or increasing the capacity of generators and using single or multiple discriminators under four different scenarios applied to image-to-image translation tasks. Scenario-1 uses the conventional pix2pix GAN model which serves as the based line model for the rest of the scenarios. In Scenario-2, we utilized two generators connected sequentially. Each generator is identical to the one used in Scenario-1. Another possibility is just doubling the size of a single generator which is evaluated in the Scenario-3. In the last scenario, we used two different discriminators in order to train two sequentially connected generators. Our quantitative results support that simply increasing the capacity of one generator, instead of using sequential generators, does not help a lot to reduce the content loss which is used in addition to adversarial loss and hence does not create better images.
OI Eken, Enes/0000-0002-7534-6247
SN 1300-0632
EI 1303-6203
PY 2022
VL 30
IS 5
BP 1741
EP 1757
DI 10.55730/1300-0632.3902
UT WOS:000904725600005
ER

PT J
AU Davoodi, E
   Montazerian, H
   Mirhakimi, AS
   Zhianmanesh, M
   Ibhadode, O
   Shahabad, SI
   Esmaeilizadeh, R
   Sarikhani, E
   Toorandaz, S
   Sarabi, SA
   Nasiri, R
   Zhu, YZ
   Kadkhodapour, J
   Li, BB
   Khademhosseini, A
   Toyserkani, E
AF Davoodi, Elham
   Montazerian, Hossein
   Mirhakimi, Anooshe Sadat
   Zhianmanesh, Masoud
   Ibhadode, Osezua
   Shahabad, Shahriar Imani
   Esmaeilizadeh, Reza
   Sarikhani, Einollah
   Toorandaz, Sahar
   Sarabi, Shima A.
   Nasiri, Rohollah
   Zhu, Yangzhi
   Kadkhodapour, Javad
   Li, Bingbing
   Khademhosseini, Ali
   Toyserkani, Ehsan
TI Additively manufactured metallic biomaterials
SO BIOACTIVE MATERIALS
AB Metal additive manufacturing (AM) has led to an evolution in the design and fabrication of hard tissue substitutes, enabling personalized implants to address each patient's specific needs. In addition, internal pore architectures integrated within additively manufactured scaffolds, have provided an opportunity to further develop and engineer functional implants for better tissue integration, and long-term durability. In this review, the latest advances in different aspects of the design and manufacturing of additively manufactured metallic biomaterials are highlighted. After introducing metal AM processes, biocompatible metals adapted for integration with AM machines are presented. Then, we elaborate on the tools and approaches undertaken for the design of porous scaffold with engineered internal architecture including, topology optimization techniques, as well as unit cell patterns based on lattice networks, and triply periodic minimal surface. Here, the new possibilities brought by the functionally gradient porous structures to meet the conflicting scaffold design requirements are thoroughly discussed. Subsequently, the design constraints and physical characteristics of the additively manufactured constructs are reviewed in terms of input parameters such as design features and AM processing parameters. We assess the proposed applications of additively manufactured implants for regeneration of different tissue types and the efforts made towards their clinical translation. Finally, we conclude the review with the emerging directions and perspectives for further development of AM in the medical industry.
RI Zhu, Yangzhi/S-3400-2019; Zhianmanesh, Masoud/GXG-4585-2022; Nasiri,
   Rohollah/AAB-4257-2022; Li, Bingbing/A-7042-2011
OI Zhu, Yangzhi/0000-0003-2920-3365; Zhianmanesh,
   Masoud/0000-0001-9645-1276; Nasiri, Rohollah/0000-0002-8245-692X; Imani
   Shahabad, Shahriar/0000-0002-5480-9345; Ibhadode,
   Osezua/0000-0001-6030-3490; Li, Bingbing/0000-0001-6140-4189; Davoodi,
   Elham/0000-0001-8578-9431; Sarikhani, Einollah/0000-0002-7841-5244
EI 2452-199X
PD SEP
PY 2022
VL 15
BP 214
EP 249
DI 10.1016/j.bioactmat.2021.12.027
EA MAR 2022
UT WOS:000789696200001
PM 35386359
ER

PT J
AU Devaprasad, A
   Pandit, A
AF Devaprasad, Abhinandan
   Pandit, Aridaman
TI Enrichment of SARS-CoV-2 Entry Factors and Interacting Intracellular
   Genes in Tissue and Circulating Immune Cells
SO VIRUSES-BASEL
AB SARS-CoV-2 uses ACE2 and TMPRSS2 to gain entry into the cell. However, recent studies have shown that SARS-CoV-2 may use additional host factors that are required for the viral lifecycle. Here we used publicly available datasets, CoV-associated genes, and machine learning algorithms to explore the SARS-CoV-2 interaction landscape in different tissues. We found that in general a small fraction of cells express ACE2 in the different tissues, including nasal, bronchi, and lungs. We show that a small fraction of immune cells (including T cells, macrophages, dendritic cells) found in tissues also express ACE2. We show that healthy circulating immune cells do not express ACE2 and TMPRSS2. However, a small fraction of circulating immune cells (including dendritic cells, monocytes, T cells) in the PBMC of COVID-19 patients express ACE2 and TMPRSS2. Additionally, we found that a large spectrum of cells (in tissues and circulation) in both healthy and COVID-19-positive patients were significantly enriched for SARS-CoV-2 factors, such as those associated with RHOA and RAB GTPases, mRNA translation proteins, COPI- and COPII-mediated transport, and integrins. Thus, we propose that further research is needed to explore if SARS-CoV-2 can directly infect tissue and circulating immune cells to better understand the virus' mechanism of action.
RI Pandit, Aridaman/ABH-1221-2021
OI Pandit, Aridaman/0000-0003-2057-9737
EI 1999-4915
PD SEP
PY 2021
VL 13
IS 9
AR 1757
DI 10.3390/v13091757
UT WOS:000702083800001
PM 34578338
ER

PT J
AU Banerjee, S
   Khapra, MM
AF Banerjee, Suman
   Khapra, Mitesh M.
TI Graph Convolutional Network with Sequential Attention for Goal-Oriented
   Dialogue Systems
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
AB Domain-specific goal-oriented dialogue systems typically require modeling three types of inputs, namely, (i) the knowledge-base associated with the domain, (ii) the history of the conversation, which is a sequence of utterances, and (iii) the current utterance for which the response needs to be generated. While modeling these inputs, current state-of-the-art models such as Mem2Seq typically ignore the rich structure inherent in the knowledge graph and the sentences in the conversation context. Inspired by the recent success of structure-aware Graph Convolutional Networks (GCNs) for various NLP tasks such as machine translation, semantic role labeling, and document dating, we propose a memory-augmented GCN for goal-oriented dialogues. Our model exploits (i) the entity relation graph in a knowledge-base and (ii) the dependency graph associated with an utterance to compute richer representations for words and entities. Further, we take cognizance of the fact that in certain situations, such as when the conversation is in a code-mixed language, dependency parsers may not be available. We show that in such situations we could use the global word co-occurrence graph to enrich the representations of utterances. We experiment with four datasets: (i) the modified DSTC2 dataset, (ii) recently released code-mixed versions of DSTC2 dataset in four languages, (iii) Wizard-of-Oz style CAM676 dataset, and (iv) Wizard-of-Oz style MultiWOZ dataset. On all four datasets our method outperforms existing methods, on a wide range of evaluation metrics.
EI 2307-387X
PY 2019
VL 7
BP 485
EP 500
DI 10.1162/tacl_a_00284
UT WOS:000736523200031
ER

PT C
AU Karaki, H
   Akkary, H
AF Karaki, Hussein
   Akkary, Haitham
GP IEEE
TI Multiple Instruction Sets Architecture (MISA)
SO 2011 INTERNATIONAL CONFERENCE ON ENERGY AWARE COMPUTING
SE International Conference on Energy Aware Computing
CT International Conference on Energy Aware Computing (ICEAC)
CY NOV 30-DEC 02, 2011
CL Istanbul, TURKEY
AB In the computer hardware industry, there are currently two highly successful instruction set architectures (ISAs): the CISC X86 ISA which is an established standard architecture in the personal computer and server markets, and the RISC ARM ISA which is currently used in many ultramobile computing devices, such as smart-phones and tablets. Platforms that run one standard ISA cannot run the other ISA application binaries without recompiling the source code.
   We are investigating the technical feasibility of designing an energy-efficient multiple instruction sets architecture (MISA) processor that can run both X86 and ARM binaries. We propose an approach in which special decoders interpret the binary instructions of the running ISA and translates them to a native target machine ISA that executes within the processor pipeline.
   We discuss the completed initial stage of our work involving the design of XAM, an X86 hardware binary interpreter for a MISA processor that runs native ARM instructions, and describe our design in detail. We present performance and energy simulation results of our MISA processor design for a set of synthetic benchmarks including Dhrystone2.1, measured using the ARM SimpleScalar microarchitecture and power simulator. We also discuss design issues of an ARM to X86 hardware interpreter we are currently developing. We expect the completed X86-to-ARM design and the current ARM-to-X86 work to lay a foundation for designing a well optimized processor having a new native ISA that can run efficiently both X86 and ARM binaries, using direct hardware interpretation.
SN 2163-5617
BN 978-1-4673-0465-8
PY 2011
UT WOS:000318034100021
ER

PT J
AU Likos, WJ
   Wayllace, A
   Godt, J
   Lu, N
AF Likos, William J.
   Wayllace, Alexandra
   Godt, Jonathan
   Lu, Ning
TI Modified Direct Shear Apparatus for Unsaturated Sands at Low Suction and
   Stress
SO GEOTECHNICAL TESTING JOURNAL
AB Modifications to a conventional laboratory testing system are described for direct shear testing of unsaturated soils at relatively low matric suction and net normal stress. Matric suction ranging from zero (saturated) to about 10 kPa is controlled using a hanging column assembly (ASTM D6836). Net normal stress ranging from about 0.3 to 10 kPa is controlled by directly applying dead loads to the specimen via a series of aluminum top caps machined to varying thicknesses. Precise control of suction and normal stress within these ranges makes the apparatus ideal for examining the shear strength behavior of unsaturated sands, which are characterized by relatively low air-entry pressures and for which the influences of matric suction on mechanical response can be subtle. Soil-water characteristic curves are concurrently obtained during the shear testing program by measuring transient and equilibrium pore water drainage under the imposed suction changes. Testing procedures and recommended protocols are described. Results from a series of tests using saturated and unsaturated specimens of poorly graded fine sand are presented to demonstrate application and performance of the system. Relationships between shear strength and matric suction are non-linear and exhibit peak shear strength at matric suction within the range of the air-entry suction. High friction angles measured for the portions of the failure envelope at low matric suction and normal stress may indicate the effects of dilation on the strength development.
SN 0149-6115
EI 1945-7545
PD JUL
PY 2010
VL 33
IS 4
BP 286
EP 298
UT WOS:000280305200002
ER

PT J
AU Mahmoud, AS
   Mohamed, SA
   El-Khoriby, RA
   AbdelSalam, HM
   El-Khodary, IA
AF Mahmoud, Amira S.
   Mohamed, Sayed A.
   El-Khoriby, Reda A.
   AbdelSalam, Hisham M.
   El-Khodary, Ihab A.
TI Oil Spill Identification based on Dual Attention UNet Model Using
   Synthetic Aperture Radar Images
SO JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING
AB Oil spills cause tremendous damage to marine, coastal environments, and ecosystems. Previous deep learning-based studies have addressed the task of detecting oil spills as a semantic segmentation problem. However, further improvement is still required to address the noisy nature of the Synthetic Aperture Radar (SAR) imagery problem, which limits segmentation performance. In this study, a new deep learning model based on the Dual Attention Model (DAM) is developed to automatically detect oil spills in a water body. We enhanced a conventional UNet segmentation network by integrating a dual attention model DAM to selectively highlight the relevant and discriminative global and local characteristics of oil spills in SAR imagery. DAM is composed of a Channel Attention Map and a Position Attention Map which are stacked in the decoder network of UNet. The proposed DAM-UNet is compared with four baselines, namely fully convolutional network, PSPNet, LinkNet, and traditional UNet. The proposed DAM-UNet outperforms the four baselines, as demonstrated empirically. Moreover, the EG-Oil Spill dataset includes a large set of SAR images with 3000 image pairs. The obtained overall accuracy of the proposed method increased by 3.2% and reaches 94.2% compared with that of the traditional UNet. The study opens new development ideas for integrating attention modules into other deep learning tasks, including machine translation, image-based analysis, action recognition, and speech recognition.
SN 0255-660X
EI 0974-3006
PD JAN
PY 2023
VL 51
IS 1
BP 121
EP 133
DI 10.1007/s12524-022-01624-6
EA NOV 2022
UT WOS:000885848800001
ER

PT J
AU Hazra, D
   Byun, YC
AF Hazra, Debapriya
   Byun, Yung-Cheol
TI OEBR-GAN: Object Extraction and Background Recovery Generative
   Adversarial Networks
SO IEEE ACCESS
AB Generative adversarial networks (GAN) have been widely used in the field of image-to-image translation. In this paper, we have proposed a novel object extraction and background recovery (OEBR-GAN) model, which can extract objects from an image and then complete the image by inpainting the background of the image. This model has been developed for a solar panel installation project, where the user would like to input an original colored image of the roof, and as output, the user requires an edge detected roof image. However, the condition in user requirement is that any object that is hiding the roof edges should be removed first and the background of that part of the roof image should be recovered so that the user can obtain a complete connected edge detected image of the roof. Therefore, the model also completes the image by connecting the hidden edges of the roof. We could achieve the user objective by building a GAN model with a dual generator and dual discriminator network. The generators have been built using an encoder-decoder network with and without skip connections and the discriminators have been built using deep convolutional neural networks and encoder architecture. Quantitative comparisons in the result section shows that OEBR-GAN performs much better than other adversarial models on our collected dataset.
OI Hazra, Debapriya/0000-0002-9660-4700
SN 2169-3536
PY 2020
VL 8
BP 135730
EP 135741
DI 10.1109/ACCESS.2020.3011187
UT WOS:000554898800001
ER

PT J
AU Lopez, JP
   Bosch-Baliarda, M
   Martin, CA
   Menendez, JM
   Orero, P
   Soler, O
   Alvarez, F
AF Pedro Lopez, Juan
   Bosch-Baliarda, Marta
   Alberto Martin, Carlos
   Manuel Menendez, Jose
   Orero, Pilar
   Soler, Olga
   Alvarez, Federico
TI Design and development of sign language questionnaires based on video
   and web interfaces
SO AI EDAM-ARTIFICIAL INTELLIGENCE FOR ENGINEERING DESIGN ANALYSIS AND
   MANUFACTURING
AB Conventional tests with written information used for the evaluation of sign language (SL) comprehension introduce distortions due to the translation process. This fact affects the results and conclusions drawn and, for that reason, it is necessary to design and implement the same language interpreter-independent evaluation tools. Novel web technologies facilitate the design of web interfaces that support online, multiple-choice questionnaires, while exploiting the storage of tracking data as a source of information about user interaction. This paper proposes an online, multiple-choice sign language questionnaire based on an intuitive methodology. It helps users to complete tests and automatically generates accurate, statistical results using the information and data obtained in the process. The proposed system presents SL videos and enables user interaction, fulfilling the requirements that SL interpretation is not able to cover. The questionnaire feeds a remote database with the user answers and powers the automatic creation of data for analytics. Several metrics, including time elapsed, are used to assess the usability of the SL questionnaire, defining the goals of the predictive models. These predictions are based on machine learning models, with the demographic data of the user as features for estimating the usability of the system. This questionnaire reduces costs and time in terms of interpreter dedication, as well as widening the amount of data collected while employing user native language. The validity of this tool was demonstrated in two different use cases.
RI Soler-Vilageliu, Olga/A-6391-2012; Menendez Garcia, Jose
   Manuel/L-1159-2014; Lopez Velasco, Juan Pedro/F-4731-2016
OI Soler-Vilageliu, Olga/0000-0001-9219-1913; Menendez Garcia, Jose
   Manuel/0000-0003-0584-2250; Lopez Velasco, Juan
   Pedro/0000-0001-5400-2747
SN 0890-0604
EI 1469-1760
PD NOV
PY 2019
VL 33
IS 4
SI SI
BP 429
EP 441
AR PII S0890060419000374
DI 10.1017/S0890060419000374
UT WOS:000509726900006
ER

PT C
AU Li, XP
   Song, JK
   Gao, LL
   Liu, XL
   Huang, WB
   He, XN
   Gan, C
AF Li, Xiangpeng
   Song, Jingkuan
   Gao, Lianli
   Liu, Xianglong
   Huang, Wenbing
   He, Xiangnan
   Gan, Chuang
GP AAAI
TI Beyond RNNs: Positional Self-Attention with Co-Attention for Video
   Question Answering
SO THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 33rd AAAI Conference on Artificial Intelligence / 31st Innovative
   Applications of Artificial Intelligence Conference / 9th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY JAN 27-FEB 01, 2019
CL Honolulu, HI
SP Assoc Advancement Artificial Intelligence
AB Most of the recent progresses on visual question answering are based on recurrent neural networks (RNNs) with attention. Despite the success, these models are often time-consuming and having difficulties in modeling long range dependencies due to the sequential nature of RNNs. We propose a new architecture, Positional Self-Attention with Coattention (PSAC), which does not require RNNs for video question answering. Specifically, inspired by the success of self-attention in machine translation task, we propose a Positional Self-Attention to calculate the response at each position by attending to all positions within the same sequence, and then add representations of absolute positions. Therefore, PSAC can exploit the global dependencies of question and temporal information in the video, and make the process of question and video encoding executed in parallel. Furthermore, in addition to attending to the video features relevant to the given questions (i.e., video attention), we utilize the co-attention mechanism by simultaneously modeling "what words to listen to" (question attention). To the best of our knowledge, this is the first work of replacing RNNs with self-attention for the task of visual question answering. Experimental results of four tasks on the benchmark dataset show that our model significantly outperforms the state-of-the-art on three tasks and attains comparable result on the Count task. Our model requires less computation time and achieves better performance compared with the RNNs-based methods. Additional ablation study demonstrates the effect of each component of our proposed model.
RI Huang, Wenbing/AHB-1846-2022; Huang, Wenbing/AAI-7943-2021
OI Huang, Wenbing/0000-0002-2566-4159; Huang, Wenbing/0000-0002-2566-4159
SN 2159-5399
EI 2374-3468
BN 978-1-57735-809-1
PY 2019
BP 8658
EP 8665
UT WOS:000486572503025
ER

PT J
AU Ciandrini, L
   Romano, MC
   Parmeggiani, A
AF Ciandrini, Luca
   Romano, M. Carmen
   Parmeggiani, Andrea
TI Stepping and Crowding of Molecular Motors: Statistical Kinetics from an
   Exclusion Process Perspective
SO BIOPHYSICAL JOURNAL
AB Motor enzymes are remarkable molecular machines that use the energy derived from the hydrolysis of a nucleoside triphosphate to generate mechanical movement, achieved through different steps that constitute their kinetic cycle. These macromolecules, nowadays investigated with advanced experimental techniques to unveil their molecular mechanisms and the properties of their kinetic cycles, are implicated in many biological processes, ranging from biopolymerization (e.g., RNA polymerases and ribosomes) to intracellular transport (motor proteins such as kinesins or dyneins). Although the kinetics of individual motors is well studied on both theoretical and experimental grounds, the repercussions of their stepping cycle on the collective dynamics still remains unclear. Advances in this direction will improve our comprehension of transport process in the natural intracellular medium, where processive motor enzymes might operate in crowded conditions. In this work, we therefore extend contemporary statistical kinetic analysis to study collective transport phenomena of motors in terms of lattice gas models belonging to the exclusion process class. Via numerical simulations, we show how to interpret and use the randomness calculated from single particle trajectories in crowded conditions. Importantly, we also show that time fluctuations and non-Poissonian behavior are intrinsically related to spatial correlations and the emergence of large, but finite, clusters of comoving motors. The properties unveiled by our analysis have important biological implications on the collective transport characteristics of processive motor enzymes in crowded conditions.
RI Ciandrini, Luca/I-5451-2019; Andrea, Parmeggiani/ABF-6554-2020
OI Ciandrini, Luca/0000-0001-5859-2764; Romano, M.
   Carmen/0000-0002-6261-2147; Parmeggiani, Andrea/0000-0003-3025-4266
SN 0006-3495
EI 1542-0086
PD SEP 2
PY 2014
VL 107
IS 5
BP 1176
EP 1184
DI 10.1016/j.bpj.2014.07.012
UT WOS:000341275100018
PM 25185553
ER

PT J
AU Nitschke, P
   Lodge, S
   Hall, D
   Schaefer, H
   Spraul, M
   Embade, N
   Millet, O
   Holmes, E
   Wist, J
   Nicholson, JK
AF Nitschke, Philipp
   Lodge, Samantha
   Hall, Drew
   Schaefer, Hartmut
   Spraul, Manfred
   Embade, Nieves
   Millet, Oscar
   Holmes, Elaine
   Wist, Julien
   Nicholson, Jeremy K.
TI Direct low field J-edited diffusional proton NMR spectroscopic
   measurement of COVID-19 inflammatory biomarkers in human serum
SO ANALYST
AB A JEDI NMR pulse experiment incorporating relaxational, diffusional and J-modulation peak editing has been implemented for a low field (80 MHz proton resonance frequency) spectrometer system to measure quantitatively two recently discovered plasma markers of SARS-CoV-2 infection and general inflammation. JEDI spectra capture a unique signature of two biomarker signals from acetylated glycoproteins (Glyc) and the supramolecular phospholipid composite (SPC) signals that are relatively enhanced by the combination of relaxation, diffusion and J-editing properties of the JEDI experiment that strongly attenuate contributions from the other molecular species in plasma. The SPC/Glyc ratio data were essentially identical in the 600 MHz and 80 MHz spectra obtained (R-2 = 0.97) and showed significantly different ratios for control (n = 28) versus SARS-CoV-2 positive patients (n = 29) (p = 5.2 x 10(-8) and 3.7 x 10(-8) respectively). Simplification of the sample preparation allows for data acquisition in a similar time frame to high field machines (similar to 4 min) and a high-throughput version with 1 min experiment time could be feasible. These data show that these newly discovered inflammatory biomarkers can be measured effectively on low field NMR instruments that do not not require housing in a complex laboratory environment, thus lowering the barrier to clinical translation of this diagnostic technology.
RI Millet, Oscar/F-9696-2011; Holmes, Elaine/A-2189-2015; Wist,
   Julien/J-4254-2018
OI Millet, Oscar/0000-0001-8748-4105; Lodge, Samantha/0000-0001-9193-0462;
   Wist, Julien/0000-0002-3416-2572
SN 0003-2654
EI 1364-5528
PD SEP 26
PY 2022
VL 147
IS 19
BP 4213
EP 4221
DI 10.1039/d2an01097f
EA AUG 2022
UT WOS:000842642700001
PM 35994017
ER

PT J
AU Kavitha, S
   Bhuvaneswari, NS
   Senthilkumar, R
   Shanker, NR
AF Kavitha, S.
   Bhuvaneswari, N. S.
   Senthilkumar, R.
   Shanker, N. R.
TI Magnetoresistance sensor-based rotor fault detection in induction motor
   using non-decimated wavelet and streaming data
SO AUTOMATIKA
AB In this paper, the giant magnetoresistance broken rotor (GBR) method is used to diagnose the induction motor (IM) rotor bar fault at an early stage from outward magnetic flux developed by IM.The outward magnetic field signal has anti-clockwise radiation due to broken rotor bar current.In this paper, the outward magnetic signal is acquired using a giant magnetoresistance (GMR) sensor. In the GBR method, IM rotor fault is analysed with a non-decimated wavelet transform (NDWT)-based outward magnetic signal. Experimental result shows the difference in statistical features and energy levels of sub-bands of NDWT for healthy and faulty IM. Least square-support vector machine(LS-SVM)-based classification results are verified by confusion matrix based on 150 outward magnetic signals from a healthy and damaged rotor (broken rotor). The proposed method identifies IM rotor faults with 95% sensitivity, 90% specificity and 92.5% classification accuracy. Furthermore, run-time IM condition monitoring is performed through the ThinkSpeak internet of things (IoT) platform for collecting outer magnetic signal data. ThinkSpeak streaming data of outward magnetic field help detect rotor fault at the initial stage and understand the growth of rotor fault in the motor. The proposed GBR method overcomes sensitivity, translation-invariance limitations of existing IM rotor fault diagnosis methods.
RI Rajendiran, Shanker/AAB-7228-2022
OI S, Kavitha/0000-0002-0043-9035
SN 0005-1144
EI 1848-3380
PD JUL 3
PY 2022
VL 63
IS 3
BP 525
EP 541
DI 10.1080/00051144.2022.2052533
UT WOS:000772747200001
ER

PT J
AU Liu, S
   Ren, Z
   Yuan, JS
AF Liu, Sheng
   Ren, Zhou
   Yuan, Junsong
TI SibNet: Sibling Convolutional Encoder for Video Captioning
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB Visual captioning, the task of describing an image or a video using one or few sentences, is a challenging task owing to the complexity of understanding the copious visual information and describing it using natural language. Motivated by the success of applying neural networks for machine translation, previous work applies sequence to sequence learning to translate videos into sentences. In this work, different from previous work that encodes visual information using a single flow, we introduce a novel Sibling Convolutional Encoder (SibNet) for visual captioning, which employs a dual-branch architecture to collaboratively encode videos. The first content branch encodes visual content information of the video with an autoencoder, capturing the visual appearance information of the video as other networks often do. While the second semantic branch encodes semantic information of the video via visual-semantic joint embedding, which brings complementary representation by considering the semantics when extracting features from videos. Then both branches are effectively combined with soft-attention mechanism and finally fed into a RNN decoder to generate captions. With our SibNet explicitly capturing both content and semantic information, the proposed model can better represent the rich information in videos. To validate the advantages of the proposed model, we conduct experiments on two benchmarks for video captioning, YouTube2Text and MSR-VTT. Our results demonstrate that the proposed SibNet consistently outperforms existing methods across different evaluation metrics.
SN 0162-8828
EI 1939-3539
PD SEPT 1
PY 2021
VL 43
IS 9
BP 3259
EP 3272
DI 10.1109/TPAMI.2019.2940007
UT WOS:000681124300030
PM 32149622
ER

PT J
AU Winster, SG
   Kumar, MN
AF Winster, S. Godfrey
   Kumar, M. Naveen
TI Automatic classification of emotions in news articles through ensemble
   decision tree classification techniques
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
AB Emotions form a major role in human life. As human interactions with online systems have increased drastically, emotion prediction from online text, which otherwise can be monotonous, would help to provide a better environment to the users. Identification of emotions from a normal text itself is very complicated while news text that does not explicitly convey emotions adds more intricacy to it. Data mining methods can be utilized in this context. In this work, the potential of decision tree classifiers in emotion classification is explored. The advocated methodology incorporates two segments towards emotion identification. The first segment deals with data preparation and involves dataset elicitation, translation, HTML tag removal, stop word elimination and stemming. The second segment that implements data mining takes the output of the first segment as its input and applies feature vector formulation, correlation based feature selection, building of bagged Grafted C4.5 learning model and performance evaluation. Based on the evolved classification rules, the emotions are categorized into joy, surprise, fear, sadness, disgust, neutral and mixed kind. Experiments have been conducted to analyse the effect of feature selection methods and ensemble methods in generating efficient rules. The accuracy is compared against eight other decision tree classifiers and also the support vector machine learning model. The proposed methodology achieves the maximum accuracy of 87.83% justifying its utilization in the real time applications.
SN 1868-5137
EI 1868-5145
PD MAY
PY 2021
VL 12
IS 5
BP 5709
EP 5720
DI 10.1007/s12652-020-02373-5
EA AUG 2020
UT WOS:000555364400006
ER

PT J
AU Ying, SS
   Aziz, AR
   Lee, MJC
AF Ying, Soh Sze
   Aziz, Abdul Rashid
   Lee, Marcus J. C.
TI AN ATTEMPT TO INDUCE POSTACTIVATION POTENTIATION TO IMPROVE KAYAK SPRINT
   PERFORMANCE USING AN ON-WATER KAYAK-SPECIFIC WARM UP
SO JOURNAL OF MECHANICS IN MEDICINE AND BIOLOGY
AB This study explores whether an on-water kayak-specific resistance exercise (KSRE) performed during the warm-up period can induce postactivation potentiation (PAP) to improve subsequent kayak-sprint performance. The KSRE involves stringing several tennis balls around the boat's hull to induce drag while paddling. In a laboratory setting, 10 well-trained male (N = 6) and female (N = 4) kayakers performed three repetitions of the single-arm seated-row (SASR) at 91% one-repetition maximum to induce PAP and were assessed for their peak power output while performing SASR on the Keiser machine at two-minute intervals up to 16 min. Each individual's latency period for the onset of PAP during this exercise was recorded. In separate sessions, athletes performed in random, a 30 m kayak-sprint in a swimming pool setting after either control (no pre-performance loading) or experimental (post-PAP induction via the KSRE taking into account the individual' onset of PAP latencies period obtained in the laboratory) conditions. Criterion measures of boat velocities of the third and fourth stroke from the start and 30 m sprint times, assessed using video, were not significantly different between control and experimental conditions. The translation of increased power output elicited via PAP using land-based resistance exercises into water-based resistance exercises to improve kayak-sprint performance remains a challenge.
RI Lee, Marcus/AAV-9476-2021
SN 0219-5194
EI 1793-6810
PD JUN
PY 2020
VL 20
IS 5
AR 2050026
DI 10.1142/S0219519420500268
UT WOS:000545745100004
ER

PT J
AU Wei, DX
   Wang, JZ
   Ni, KL
   Tang, GY
AF Wei, Danxiang
   Wang, Jianzhou
   Ni, Kailai
   Tang, Guangyu
TI Research and Application of a Novel Hybrid Model Based on a Deep Neural
   Network Combined with Fuzzy Time Series for Energy Forecasting
SO ENERGIES
AB In recent years, although deep learning algorithms have been widely applied to various fields, ranging from translation to time series forecasting, researchers paid limited attention to modelling parameter optimization and the combination of the fuzzy time series. In this paper, a novel hybrid forecasting system, named CFML (complementary ensemble empirical mode decomposition (CEEMD)-fuzzy time series (FTS)-multi-objective grey wolf optimizer (MOGWO)-long short-term memory (LSTM)), is proposed and tested. This model is based on the LSTM model with parameters optimized by MOGWO, before which a fuzzy time series method involving the LEM2 (learning from examples module version two) algorithm is adopted to generate the final input data of the optimized LSTM model. In addition, the CEEMD algorithm is also used to de-noise and decompose the raw data. The CFML model successfully overcomes the nonstationary and irregular features of wind speed data and electrical power load series. Several experimental results covering four wind speed datasets and two electrical power load datasets indicate that our hybrid forecasting system achieves average improvements of 49% and 70% in wind speed and electrical power load, respectively, under the metric MAPE (mean absolute percentage error).
RI Wang, Jianzhou/ABE-8452-2020; tang, guangyu/AAM-5360-2021
OI Wang, Jianzhou/0000-0001-9078-7617; tang, guangyu/0000-0001-9617-3632;
   Wei, Danxiang/0000-0002-8684-9317
EI 1996-1073
PD SEP
PY 2019
VL 12
IS 18
AR 3588
DI 10.3390/en12183588
UT WOS:000489101200184
ER

PT C
AU Sun, LL
   Mao, JJ
   Zhang, Y
   Sun, J
AF Sun, Lulu
   Mao, Jingjing
   Zhang, Yi
   Sun, Jin
BE Wang, Y
   Sun, Y
   Wu, X
TI Scheduling Workflow Tasks in Complex Networks on Mobile Clouds
SO PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON PROGRESS IN
   INFORMATICS AND COMPUTING (PIC)
SE Proceedings of the IEEE International Conference on Progress in
   Informatics and Computing
CT IEEE International Conference on Progress in Informatics and Computing
   (PIC)
CY DEC 14-16, 2018
CL Suzhou, PEOPLES R CHINA
SP IEEE, IEEE Beijing Sect, Shanghai Univ Finance & Econ, Tongji Univ, Soochow Univ
AB Mobile cloud computing technology enables users to cooperate with each other so that their mobile devices' resources can be integrated together to afford complicated application, such as machine auto-translation and image processing, which can always be represented as Directed Acyclic Graphs. On mobile clouds, due to the social relationships of mobile devices' owners, networks on mobile clouds are always complex and consist of multiple sub-networks intersecting at several joint devices. In these complex networks, joint devices can communicate with all devices of their related multiple sub-networks, whereas the other devices can only contact devices in the same sub-nebvork. In this paper, we study the workflow task scheduling problem in the aforementioned complex networks on mobile clouds, and formulate it as Integer Programming problem that is generally NP-Hard. Due to the constraint of each device's power capacity, the dependence among tasks in a workflow and the network complexity, it is too difficult to achieve feasible scheduling solutions for the considered problem. To solve this problem, we propose an Improved Round-Robin scheduling algorithm (IRR) and an Improved Greedy scheduling algorithm (IG) with the consideration of workflow tasks' features. Experimental results show that our proposed IRR and IG guarantee to achieve feasible solutions, whereas the General Round-Robin scheduling algorithm (GRR) does with the probability of 2.3%. Moreover, experimental results also indicate that IG outperforms ERR.
RI SUN, JIN/GPX-9641-2022
SN 2474-0209
BN 978-1-5386-7672-1
PY 2018
BP 311
EP 316
UT WOS:000469270700055
ER

PT J
AU Wong, CS
   Liao, HM
   Tsai, RTH
   Chang, MC
AF Wong, Cheng-Shih
   Liao, Hsiung-Ming
   Tsai, Richard Tzong-Han
   Chang, Ming-Ching
TI Semi-supervised learning for topographic map analysis over time: a study
   of bridge segmentation
SO SCIENTIFIC REPORTS
AB Geographical research using historical maps has progressed considerably as the digitalization of topological maps across years provides valuable data and the advancement of Al machine learning models provides powerful analytic tools. Nevertheless, analysis of historical maps based on supervised learning can be limited by the laborious manual map annotations. In this work, we propose a semisupervised learning method that can transfer the annotation of maps across years and allow map comparison and anthropogenic studies across time. Our novel two-stage framework first performs style transfer of topographic map across years and versions, and then supervised learning can be applied on the synthesized maps with annotations. We investigate the proposed semi-supervised training with the style-transferred maps and annotations on four widely-used deep neural networks (DNN), namely U-Net, fully-convolutional network (FCN), DeepLabV3, and MobileNetV3. The best performing network of U-Net achieves F1(inst:0.1) = 0.725 and F-1inst:0.01 = 0.743 trained on styletransfer synthesized maps, which indicates that the proposed framework is capable of detecting target features (bridges) on historical maps without annotations. In a comprehensive comparison, the F1(inst:0.1) of U-Net trained on Contrastive Unpaired Translation (CUT) generated dataset (0.662 +/- 0.008) achieves 57.3 %than the comparative score (0.089 +/- 0.065) of the least valid configuration (MobileNetV3 trained on CycIeGAN synthesized dataset). We also discuss the remaining challenges and future research directions.
SN 2045-2322
PD NOV 8
PY 2022
VL 12
IS 1
AR 18997
DI 10.1038/s41598-022-23364-w
UT WOS:000880437400006
PM 36348081
ER

PT C
AU Gao, CY
   Zeng, JC
   Xia, X
   Lo, D
   Lyu, MR
   King, I
AF Gao, Cuiyun
   Zeng, Jichuan
   Xia, Xin
   Lo, David
   Lyu, Michael R.
   King, Irwin
GP IEEE
TI Automating App Review Response Generation
SO 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING
   (ASE 2019)
CT 34th IEEE/ACM International Conference on Automated Software Engineering
   (ASE)
CY NOV 10-11, 2019
CL San Diego, CA
SP IEEE, Assoc Comp Machinery, IEEE Comp Soc, IEEE Comp Soc Tech Council Software Engn, ACM Special Interest Grp Artificial Intelligence, ACM Special Interest Grp Software Engn
AB Previous studies showed that replying to a user review usually has a positive effect on the rating that is given by the user to the app. For example, IIassan et al. found that responding to a review increases the chances of a user updating their given rating by up to six times compared to not responding. To alleviate the labor burden in replying to the bulk of user reviews, developers usually adopt a template-based strategy where the templates can express appreciation for using the app or mention the company email address for users to follow up. However, reading a large number of user reviews every day is not an easy task for developers. Thus, there is a need for more automation to help developers respond to user reviews.
   Addressing the aforementioned need, in this work we propose a novel approach RRGen that automatically generates review responses by learning knowledge relations between reviews and their responses. RRGen explicitly incorporates review attributes, such as user rating and review length, and learns the relations between reviews and corresponding responses in a supervised way from the available training data. Experiments on 58 apps and 309,246 review -response pairs highlight that RRGen out-performs the baselines by at least 67.4% in terms of BLEU-4 (an accuracy measure that is widely used to evaluate dialogue response generation systems). Qualitative analysis also confirms the effectiveness of RRGen in generating relevant and accurate responses.
RI King, Irwin/C-9681-2015; Xia, Xin/AAD-6217-2022
OI King, Irwin/0000-0001-8106-6447; 
BN 978-1-7281-2508-4
PY 2019
BP 163
EP 175
DI 10.1109/ASE.2019.00025
UT WOS:000533303400018
ER

PT J
AU Salehuddin, K
   Shahimin, MM
   Sulaiman, MZ
   Zolkapli, RBM
AF Salehuddin, Khazriyati
   Shahimin, Mizhanim Mohamad
   Sulaiman, Mohamed Zain
   Zolkapli, Rasyiqah Batrisya Md
TI HEAT MAPS AND SCAN PATHS: QUALITATIVE EYE-TRACKING EVIDENCE ON HOW THE
   QUR'AN IS MEMORIZED THROUGH READING
SO JOURNAL OF NUSANTARA STUDIES-JONUS
AB The process of memorizing the Qur'an typically takes place through reading its printed version (mus'haf). The Qur'an is read word by word so that the process of recalling the memorized verses or chapters is done accurately and fluently. Memorizing the Qur'an may be a great challenge to non-Arabic speakers because of their lack of knowledge in the Arabic vocabulary and grammar; yet more and more non-Arabic speakers continue to memorize the Qur'an for various reasons. In order to scientifically investigate how non-Arabic speakers memorize the Qur'an, a reading experiment was conducted to achieve this aim. Sixty-four (21 Male, 43 Female) native speakers of Malay who have memorized a portion of the Qur'an (10 juzu' and below) participated in this experiment. Using the Tobii TX300 eye-tracking machine, participants' eye movements, as they read to memorize four verses of the Qur'an (two with and two without Malay translations), were tracked, and their gaze plots were analysed qualitatively (via heat maps and scan paths). Results show evidence that Malay non-Arabic speakers' act of reading the Qur'an to memorize it went beyond what is usually known as "cramming"; instead, the process involved finding the meaning of unknown words, so that the process of recalling the memorized verses can be done accurately and fluently.
RI Md Zolkapli, Rasyiqah Batrisya/CAI-2241-2022; Sulaiman, Mohamed
   Zain/AAL-3470-2020; Shahimin, Mizhanim/GNM-5478-2022
OI Md Zolkapli, Rasyiqah Batrisya/0000-0002-4710-2149; 
SN 0127-9319
EI 0127-9386
PY 2019
VL 4
IS 2
BP 318
EP 334
DI 10.24200/jonus.vol4iss2pp318-334
UT WOS:000503372100015
ER

PT J
AU Neveol, A
   Dalianis, H
   Velupillai, S
   Savova, G
   Zweigenbaum, P
AF Neveol, Aurelie
   Dalianis, Hercules
   Velupillai, Sumithra
   Savova, Guergana
   Zweigenbaum, Pierre
TI Clinical Natural Language Processing in languages other than English:
   opportunities and challenges
SO JOURNAL OF BIOMEDICAL SEMANTICS
AB Background: Natural language processing applied to clinical text or aimed at a clinical outcome has been thriving in recent years. This paper offers the first broad overview of clinical Natural Language Processing (NLP) for languages other than English. Recent studies are summarized to offer insights and outline opportunities in this area.
   Main Body: We envision three groups of intended readers: (1) NLP researchers leveraging experience gained in other languages, (2) NLP researchers faced with establishing clinical text processing in a language other than English, and (3) clinical informatics researchers and practitioners looking for resources in their languages in order to apply NLP techniques and tools to clinical practice and/or investigation. We review work in clinical NLP in languages other than English. We classify these studies into three groups: (i) studies describing the development of new NLP systems or components de novo, (ii) studies describing the adaptation of NLP architectures developed for English to another language, and (iii) studies focusing on a particular clinical application.
   Conclusion: We show the advantages and drawbacks of each method, and highlight the appropriate application context. Finally, we identify major challenges and opportunities that will affect the impact of NLP on clinical practice and public health studies in a context that encompasses English as well as other languages.
OI Velupillai, Sumithra/0000-0002-4178-2980
SN 2041-1480
PD MAR 30
PY 2018
VL 9
AR 12
DI 10.1186/s13326-018-0179-8
UT WOS:000428928300001
PM 29602312
ER

PT C
AU Murthy, SR
   Akshatha, AN
   Upadhyaya, CG
   Kumar, PR
AF Murthy, Rajashekara S.
   Akshatha, A. N.
   Upadhyaya, Chandana G.
   Kumar, Ramakanth P.
GP IEEE
TI Kannada Spell Checker with Sandhi Splitter
SO 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS
   AND INFORMATICS (ICACCI)
CT International Conference on Advances in Computing, Communications and
   Informatics (ICACCI)
CY SEP 13-16, 2017
CL Manipal, INDIA
AB Spelling errors are introduced in text either during typing, or when the user does not know the correct phoneme or grapheme. If a language contains complex words like sandhi where two or more morphemes join based on some rules, spell checking becomes very tedious. In such situations, having a spell checker with sandhi splitter which alerts the user by flagging the errors and providing suggestions is very useful. A novel algorithm of sandhi splitting is proposed in this paper. The sandhi splitter can split about 7000 most common sandhi words in Kannada language used as test samples. The sandhi splitter was integrated with a Kannada spell checker and a mechanism for generating suggestions was added. A comprehensive, platform independent, standalone spell checker with sandhi splitter application software was thus developed and tested extensively for its efficiency and correctness. A comparative analysis of this spell checker with sandhi splitter was made and results concluded that the Kannada spell checker with sandhi splitter has an improved performance. It is twice as fast, 200 times more space efficient, and it is 90% accurate in case of complex nouns and 80% accurate for complex verbs. Such a spell checker with sandhi splitter will be of foremost significance in machine translation systems, voice processing, etc. This is the first sandhi splitter in Kannada and the advantage of the novel algorithm is that, it can be extended to all Indian languages.
RI Murthy, Rajashekara/AAB-4914-2021; S, Rajashekara Murthy/AAF-6167-2019
OI Murthy, Rajashekara/0000-0003-2633-8125; 
BN 978-1-5090-6367-3
PY 2017
BP 950
EP 956
UT WOS:000427645500158
ER

PT J
AU Huang, CH
   Lin, CH
AF Huang, Cong-Hui
   Lin, Chia-Hung
TI Multiple harmonic-source classification using a Self-Organization
   Feature Map network with voltage-current wavelet transformation patterns
SO APPLIED MATHEMATICAL MODELLING
CT International Applied Science and Precision Engineering Conference
   (ASPEC)
CY NOV 18-22, 2013
CL Nan Tou, TAIWAN
SP Taiwan Assoc of Engn & Technol Innovat, Chiuan Yan Technol Co Ltd, Natl Chung Hsing Univ, Natl Kaohsiung Univ of Appl Sci, Dept of Mech Engn
AB This paper proposes multiple harmonic-source classification using a Self-Organization Feature Map (SOFM) network with voltage (V)-current (I) wavelet transformation patterns. Using the V-I wavelet transformation (WT) patterns, a SOFM network is employed to separate non-harmonic loads from non-linear loads in a distribution system. Morlet wavelet functions are used as feature extractors to extract the features from voltage and current signals. These features are constructed from various V-I WT patterns, and can vary with different dilation and translation parameters. Therefore, the selectable features are relatively broad for real-time applications. Two-dimensional (2-D) patterns appear in different harmonic fluctuations with various harmonic orders, load levels, and power factors. A SOFM network is employed to classify the various V-I WT patterns, including non-linear electronic devices, AC/DC motors, and Electric Arc Furnaces (EAFs). By contrast with the traditional SOFM network and the support vector machine (SVM), the testing results show that the proposed method has a fast learning process, a high accuracy, and an adaptive capability with new add-in training patterns. It can be used as an added tool for power quality (PQ) engineers and can be integrated into monitor instruments. (C) 2015 Elsevier Inc. All rights reserved.
SN 0307-904X
EI 1872-8480
PD OCT 1
PY 2015
VL 39
IS 19
SI SI
BP 5849
EP 5861
DI 10.1016/j.apm.2015.03.045
UT WOS:000362609000012
ER

PT J
AU Chi, W
   He, BY
   Mao, J
   Li, QN
   Ma, JF
   Ji, DL
   Zou, MJ
   Zhang, LX
AF Chi, Wei
   He, Baoye
   Mao, Juan
   Li, Qiannan
   Ma, Jinfang
   Ji, Daili
   Zou, Meijuan
   Zhang, Lixin
TI The Function of RH22, a DEAD RNA Helicase, in the Biogenesis of the 50S
   Ribosomal Subunits of Arabidopsis Chloroplasts
SO PLANT PHYSIOLOGY
AB The chloroplast ribosome is a large and dynamic ribonucleoprotein machine that is composed of the 30S and 50S subunits. Although the components of the chloroplast ribosome have been identified in the last decade, the molecular mechanisms driving chloroplast ribosome biogenesis remain largely elusive. Here, we show that RNA helicase 22 (RH22), a putative DEAD RNA helicase, is involved in chloroplast ribosome assembly in Arabidopsis (Arabidopsis thaliana). A loss of RH22 was lethal, whereas a knockdown of RH22 expression resulted in virescent seedlings with clear defects in chloroplast ribosomal RNA (rRNA) accumulation. The precursors of 23S and 4.5S, but not 16S, rRNA accumulated in rh22 mutants. Further analysis showed that RH22 was associated with the precursors of 50S ribosomal subunits. These results suggest that RH22 may function in the assembly of 50S ribosomal subunits in chloroplasts. In addition, RH22 interacted with the 50S ribosomal protein RPL24 through yeast two-hybrid and pull-down assays, and it was also bound to a small 23S rRNA fragment encompassing RPL24-binding sites. This action of RH22 may be similar to, but distinct from, that of SrmB, a DEAD RNA helicase that is involved in the ribosomal assembly in Escherichia coli, which suggests that DEAD RNA helicases and rRNA structures may have coevolved with respect to ribosomal assembly and function.
RI He, Baoye/AAK-8040-2021
OI Zhang, Lixin/0000-0003-0268-6774
SN 0032-0889
EI 1532-2548
PD FEB
PY 2012
VL 158
IS 2
BP 693
EP 707
DI 10.1104/pp.111.186775
UT WOS:000300054300013
PM 22170977
ER

PT C
AU Gauesan, K
   Panwar, D
   John, LK
AF Gauesan, Karthik
   Panwar, Deepak
   John, Lizy K.
BE Kaeli, D
   Sachs, K
TI Generation, Validation and Analysis of SPEC CPU2006 Simulation Points
   Based on Branch, Memory and TLB Characteristics
SO COMPUTER PERFORMANCE EVALUATION AND BENCHMARKING, PROCEEDINGS
SE Lecture Notes in Computer Science
CT SPEC Benchmark Workshop
CY JAN 25, 2009
CL Austin, TX
SP Springer, Standard Performance Evaluat Corp, IEEE Tech Comm Comp Architect
AB The SPEC CPU2006 suite, released in Aug 2006 is the current industry-standard, CPU-intensive benchmark suite, created from a collection of popular modern workloads. But, these workloads take machine weeks to months of time when fed to cycle accurate simulators and have widely varying behavior even over large scales of time [1]. It is to be noted that we do not see simulation based papers using SPEC CPU2006 even after 1.5 years of its release. A well known technique to solve this problem is the using of simulation points [2]. We have generated the simulation points for SPEC CPU2006 and made it available at [3]. We also report the accuracies of these simulation points based on the CPI, branch misspredictions, cache & TLB miss ratios by comparing with the full runs for a subset of the benchmarks. It is to be noted that the simulation points were only used for cache, branch and CPI studies until now and this is the first attempt towards validating them for TLB studies. They have also been found to be equally representative in depicting the TLB characteristics. Using the generated simulation points, we provide an analysis of the behavior of the workloads in the suite for different. branch predictor & cache configurations and report the optimally performing configurations. The simulations for the. different TLB configurations revealed that usage of large page sizes significantly reduce the translation misses and aid in improving the overall CPU of the modern workloads.
SN 0302-9743
EI 1611-3349
BN 978-3-540-93798-2
PY 2009
VL 5419
BP 121
EP 137
UT WOS:000263515000008
ER

PT J
AU FAN, PH
   ANAYIOTOS, A
   NANDA, NC
   YOGANATHAN, AP
   CAPE, EG
AF FAN, PH
   ANAYIOTOS, A
   NANDA, NC
   YOGANATHAN, AP
   CAPE, EG
TI INTRAMACHINE AND INTERMACHINE VARIABILITY IN TRANSESOPHAGEAL COLOR
   DOPPLER IMAGES OF PULSATILE JETS IN-VITRO STUDIES
SO CIRCULATION
AB Background Color Doppler flow mapping is widely used as a marker of severity of valvular regurgitation, and the transesophageal approach has provided high-quality images in patients with poor acoustic windows. However, different instruments produce significantly variable images. Techniques that use jet spatial information to determine the severity of the lesion may need to be derived specifically for the instrument used. Given a lack of standardization of the many commonly used instruments, the goal of this study was to quantify variability between instruments by imaging well-defined jet flow fields created in vitro.
   Methods and Results Pulsatile jets were created in vitro using a blood analogue fluid through physiological orifice diameters and imaged from a distal window using six commonly used color Doppler instruments. Transesophageal transducers (5.0 MHz) were used with all instruments studied. Peak jet areas were planimetered and averaged with systematic variations in Nyquist limit, color filter, and sector angle (which produced variations in frame rate). Changes in instrument settings produced significant variation in jet size for all instruments studied. Comparisons within instruments and among instruments were difficult because of preset and ambiguous setting levels. When comparisons were possible between similar settings, variability was dramatic (eg, 57% variability between instruments with very similar Nyquist limits).
   Conclusions A lack of standardized color Doppler instrument settings prohibits translation of jet area techniques from one instrument to another. This should be taken into consideration when using different machines for clinical study.
RI Anayiotos, Andreas/AFE-8497-2022; Anayiotos, Andreas/AAE-9728-2022
OI Anayiotos, Andreas/0000-0003-4471-7604; Anayiotos,
   Andreas/0000-0003-4471-7604
SN 0009-7322
PD MAY
PY 1994
VL 89
IS 5
BP 2141
EP 2149
DI 10.1161/01.CIR.89.5.2141
UT WOS:A1994NL67500030
PM 8181139
ER

PT J
AU He, GL
   Chi, CY
   Zhan, YY
AF He, G. L.
   Chi, C. Y.
   Zhan, Y. Y.
TI Combining N-gram Statistical Model with Pre-trained Model to Correct
   Chinese Sentence Error
SO ENGINEERING LETTERS
AB There have been a fund of studies on Chinese Grammatical Error Correction (CGEC) since it was proposed by NLPCC 2018 shared task 2. In previous studies, most researchers regarded this task as a Neural Machine Translation (NMT) task, which treated erroneous sentences as source-language and correct sentences as target-language. But this method relies on large-scale parallel corpus. In recent years, Bidirectional Encoder Representations from Transformers (BERT) and its variants have made an exciting breakthrough on various NLP tasks and inspire NLP practitioners to explore the utilization of pre-trained model. However, BERT performs better on Natural Language Understanding (NLU) benchmarks (e.g., SQuAD v1.1), the applications on generative tasks are inadequate. In NLP-TEA CGED Shared Task 2020, many methods based on BERT Pre-trained model have emerged. Unlike CGED tasks, whose purpose is to detect error position and error types in a sentence, are usually regarded as sequence labelling or binary classification problem. CGEC is a sequence generation task. In this study, we leverage n-gram statistical language model as a spelling checker and BERT-based pre-trained model as the encoder in sequence-to-sequence (seq2seq) structure to solve CGEC problem. Our baseline is Transformer. The experimental results demonstrate that our method outperforms the other three participating teams but also some latest methods, and we analyze how different checkpoints affect our results.
SN 1816-093X
EI 1816-0948
PD MAY 16
PY 2022
VL 30
IS 2
UT WOS:000803688800038
ER

PT J
AU Amiri, B
   Karimianghadim, R
   Yazdanjue, N
   Hossain, L
AF Amiri, Babak
   Karimianghadim, Ramin
   Yazdanjue, Navid
   Hossain, Liaquat
TI Research topics and trends of the hashtag recommendation domain
SO SCIENTOMETRICS
AB In microblogging platforms, hashtags are used to annotate the microblogs for a more convenient categorization and analysis of the published contents. Due to the fast growth of the social network, the hashtag recommendation field has attracted the researchers' attention most recently. In this study, a review of existing works in the hashtag recommendation filed is presented. After collecting all the papers in this field, the author keywords are exploited in order to extract popular topics and explore the evolution of them since their inception. In this regard, statistical analysis of the keywords, keyword-pairs co-occurrences, and the cluster analysis through the co-word data (co-word analysis) are performed. The obtained results demonstrate that there are four evolved thematic areas in this research field, including "SIMILARITY", "HASHTAG-RECOMMENDATION", "MACHINE-LEARNING", and "POPULARITY-PREDICTION". Besides, there are some popular themes in each thematic area, such as the "DEEP_LEARNING", which has excellent future development potential. Similarly, the "SIMILARITY" and "TOPIC-MODEL" are two motor themes that have gained increased interest from researchers in recent studies. Eventually, the analysis results of the related works in the hashtag recommendation domain are utilized to extract the main approaches in this research area involving "DEEP LEARNING", "TOPIC MODELING", "SIMILARITY", "CLASSIFICATION", and "TOPICAL TRANSLATION". The results' implications and the future research directions determined that the researchers' interest in the field of hashtag recommendation will increase rapidly.
RI Yazdanjue, Navid/AEC-3593-2022; Yazdanjue, Navid/AFW-0585-2022; amiri,
   babak/U-7672-2018; /E-7946-2010
OI Yazdanjue, Navid/0000-0001-9670-8422; Yazdanjue,
   Navid/0000-0001-9670-8422; /0000-0002-7616-9182
SN 0138-9130
EI 1588-2861
PD APR
PY 2021
VL 126
IS 4
BP 2689
EP 2735
DI 10.1007/s11192-021-03874-6
EA FEB 2021
UT WOS:000617856300001
ER

PT C
AU Gruss, D
   Maurice, C
   Fogh, A
   Lipp, M
   Mangard, S
AF Gruss, Daniel
   Maurice, Clementine
   Fogh, Anders
   Lipp, Moritz
   Mangard, Stefan
GP ACM
TI Prefetch Side-Channel Attacks: Bypassing SMAP and Kernel ASLR
SO CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND
   COMMUNICATIONS SECURITY
CT 23rd ACM Conference on Computer and Communications Security (CCS)
CY OCT 24-28, 2016
CL Vienna, AUSTRIA
SP Assoc Comp Machinery, ACM Special Interest Grp Secur Audit & Control
AB Modern operating systems use hardware support to protect against control-flow hijacking attacks such as code-injection attacks. Typically, write access to executable pages is prevented and kernel mode execution is restricted to kernel code pages only. However, current CPUs provide no protection against code-reuse attacks like ROP. ASLR is used to prevent these attacks by making all addresses unpredictable for an attacker. Hence, the kernel security relies fundamentally on preventing access to address information.
   We introduce Prefetch Side-Channel Attacks, a new class of generic attacks exploiting major weaknesses in prefetch instructions. This allows unprivileged attackers to obtain address information and thus compromise the entire system by defeating SMAP, SMEP, and kernel ASLR. Prefetch can fetch inaccessible privileged memory into various caches on Intel x86. It also leaks the translation-level for virtual addresses on both Intel x86 and ARMv8-A. We build three attacks exploiting these properties. Our first attack retrieves an exact image of the full paging hierarchy of a process, defeating both user space and kernel space ASLR. Our second attack resolves virtual to physical addresses to bypass SMAP on 64-bit Linux systems, enabling ret2dir attacks. We demonstrate this from unprivileged user programs on Linux and inside Amazon EC2 virtual machines. Finally, we demonstrate how to defeat kernel ASLR on Windows 10, enabling ROP attacks on kernel and driver binary code. We propose a new form of strong kernel isolation to protect commodity systems incuring an overhead of only 0. 06-5.09%.
OI Gruss, Daniel/0000-0002-7977-3246; Maurice,
   Clementine/0000-0002-8896-9494
BN 978-1-4503-4139-4
PY 2016
BP 368
EP 379
DI 10.1145/2973749.2978356
UT WOS:000387820900017
ER

PT J
AU Elad, T
   Belkin, S
AF Elad, Tal
   Belkin, Shimshon
TI Broad spectrum detection and "barcoding" of water pollutants by a
   genome-wide bacterial sensor array
SO WATER RESEARCH
AB An approach for the rapid detection and classification of a broad spectrum of water pollutants, based on a genome-wide reporter bacterial live cell array, is proposed and demonstrated. An array of ca. 2000 Escherichia call fluorescent transcriptional reporters was exposed to 25 toxic compounds as well as to unpolluted water, and its responses were recorded after 3 h. The 25 toxic compounds represented 5 pollutant classes: genotoxicants, metals, detergents, alcohols, and monoaromatic hydrocarbons. Identifying unique gene expression patterns, a nearest neighbour-based model detected pollutant presence and predicted class attribution with an estimated accuracy of 87%. Sensitivity and positive predictive values varied among classes, being higher for pollutant classes that were defined by mode of action than for those defined by structure only. Sensitivity for unpolluted water was 0.90 and the positive predictive value was 0.79. All pollutant classes induced the transcription of a statistically significant proportion of membrane associated genes; in addition, the sets of genes responsive to genotoxicants, detergents and alcohols were enriched with genes involved in DNA repair, iron utilization and the translation machinery, respectively. Following further development, a methodology of the type described herein may be suitable for integration in water monitoring schemes in conjunction with existing analytical and biological detection techniques. (C) 2013 Elsevier Ltd. All rights reserved.
RI Belkin, Shimshon/L-3469-2019
OI Elad, Tal/0000-0003-4221-7411; Belkin, Shimshon/0000-0001-8283-1673
SN 0043-1354
PD JUL 1
PY 2013
VL 47
IS 11
BP 3782
EP 3790
DI 10.1016/j.watres.2013.04.011
UT WOS:000320497500024
PM 23726715
ER

PT J
AU Sommerville, J
   Brumwell, CL
   Politz, JCR
   Pederson, T
AF Sommerville, J
   Brumwell, CL
   Politz, JCR
   Pederson, T
TI Signal recognition particle assembly in relation to the function of
   amplified nucleoli of Xenopus oocytes
SO JOURNAL OF CELL SCIENCE
AB The signal recognition particle (SRP) is a ribonucleoprotein machine that controls the translation and intracellular sorting of membrane and secreted proteins. The SRP contains a core RNA subunit with which six proteins are assembled. Recent work in both yeast and mammalian cells has identified the nucleolus as a possible initial site of SRP assembly. In the present study, SRP RNA and protein components were identified in the extrachromosomal, amplified nucleoli of Xenopus laevis oocytes. Fluorescent SRP RNA microinjected into the oocyte nucleus became specifically localized in the nucleoli, and endogenous SRP RNA was also detected in oocyte nucleoli by RNA in situ hybridization. An initial step in the assembly of SRP involves the binding of the SRP19 protein to SRP RNA. When green fluorescent protein (GFP)-tagged SRP19 protein was injected into the oocyte cytoplasm it was imported into the nucleus and became concentrated in the amplified nucleoli. After visiting the amplified nucleoli, GFP-tagged SRP19 protein was detected in the cytoplasm in a ribonucleoprotein complex, having a sedimentation coefficient characteristic of the SRP. These results suggest that the amplified nucleoli of Xenopus oocytes produce maternal stores not only of ribosomes, the classical product of nucleoli, but also of SRP, presumably as a global developmental strategy for stockpiling translational machinery for early embryogenesis.
OI Ritland, Joan/0000-0001-5229-0087
SN 0021-9533
EI 1477-9137
PD MAR 15
PY 2005
VL 118
IS 6
BP 1299
EP 1307
DI 10.1242/jcs.01726
UT WOS:000228493000023
PM 15741230
ER

PT C
AU Niu, T
   Hashimoto, K
   Zhou, YB
   Xiong, CM
AF Niu, Tong
   Hashimoto, Kazuma
   Zhou, Yingbo
   Xiong, Caiming
GP Assoc Computa Linguist
TI OneAligner: Zero-shot Cross-lingual Transfer with One Rich-Resource
   Language Pair for Low-Resource Sentence Retrieval
SO FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022)
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB Aligning parallel sentences in multilingual corpora is essential to curating data for downstream applications such as Machine Translation. In this work, we present OneAligner, an alignment model specially designed for sentence retrieval tasks. This model is able to train on only one language pair and transfers, in a cross-lingual fashion, to low-resource language pairs with negligible degradation in performance. When trained with all language pairs of a large-scale parallel multilingual corpus (OPUS-100), this model achieves the state-of-the-art result on the Tateoba dataset, outperforming an equally-sized previous model by 8.0 points in accuracy while using less than 0.6% of their parallel data. When finetuned on a single rich-resource language pair, be it English-centered or not, our model is able to match the performance of the ones finetuned on all language pairs under the same data budget with less than 2.0 points decrease in accuracy. Furthermore, with the same setup, scaling up the number of rich-resource language pairs monotonically improves the performance, reaching a minimum of 0.4 points discrepancy in accuracy, making it less mandatory to collect any low-resource parallel data. Finally, we conclude through empirical results and analyses that the performance of the sentence alignment task depends mostly on the monolingual and parallel data size, up to a certain size threshold, rather than on what language pairs are used for training or evaluation.
BN 978-1-955917-25-4
PY 2022
BP 2869
EP 2882
UT WOS:000828767402074
ER

PT J
AU Hu, XW
   Zhao, J
   Antonio-Lopez, JE
   Fan, SL
   Correa, RA
   Schulzgen, A
AF Hu, Xiaowen
   Zhao, Jian
   Antonio-Lopez, Jose E.
   Fan, Shengli
   Correa, Rodrigo Amezcua
   Schulzgen, Axel
TI Robust Imaging-Free Object Recognition Through Anderson Localizing
   Optical Fiber
SO JOURNAL OF LIGHTWAVE TECHNOLOGY
CT Optical Fiber Communications Conference (OFC)
CY MAR 08-12, 2020
CL San Diego, CA
AB Recognizing objects directly from optical fiber output images is useful in endoscopic applications when forming a clear image of the object is unnecessary or rather difficult. Conventional fiber-optic systems, such as multicore-fiber-based and multimode-fiber-based systems, suffer from the sensitivity of the fiber to external perturbations. For example, a slight movement of the fiber (a-few-millimeters translation of the tip for meter-long multicore fibers or multimode fibers) can greatly change the output images of the system. In this work, we utilize the light guidance stability of recently proposed glass-air Anderson localizing optical fiber (GALOF) to achieve robust imaging-free objection recognition. We transport five classes of cell images through an 80-cm straight GALOF. A deep convolutional neural network is trained to classify the output images and tested on images never seen, namely, images collected when the fiber is bent or when the fiber facet is placed several millimeters away from the object without any distal optics. Bending-invariant high classification accuracy (86.8% on average) is observed all the way to the maximum bending offset distance of 45 cm (similar to 74thinsp;degrees bending angle). High classification accuracy (91.2%) is also preserved when the fiber facet is 0.5 mm away from the object.
RI Schulzgen, Axel/A-9514-2008; ZHAO, JIAN/C-7785-2019
OI Schulzgen, Axel/0000-0003-4569-2349; ZHAO, JIAN/0000-0002-3947-4049
SN 0733-8724
EI 1558-2213
PD FEB 15
PY 2021
VL 39
IS 4
BP 920
EP 926
DI 10.1109/JLT.2020.3029416
UT WOS:000616310600009
ER

PT C
AU Pan, YL
   Bai, YQ
AF Pan, Yulei
   Bai, Yongqiang
BE Fu, J
   Sun, J
TI Target tracking algorithm with adaptive learning rate complementary
   filtering
SO PROCEEDINGS OF THE 39TH CHINESE CONTROL CONFERENCE
SE Chinese Control Conference
CT 39th Chinese Control Conference (CCC)
CY JUL 27-29, 2020
CL Shenyang, PEOPLES R CHINA
AB The Correlation filtering algorithm is not effective for fast deformation and fast movement. It is easy to lose when encountering problems such as occlusion. However, it has a good advantage of dealing with situations such as motion blur and lighting changes. A tracking algorithm based on color statistical features has a good effect on the rotation and translation of objects.The Staple algorithm combines the two algorithms to track using complementary fusion, but it also does not handle the occlusion and other issues well. In this paper, based on the Staple algorithm, the average peak correlation energy (APCE) and the maximum response are introduced. The value is used as the tracking confidence, and a detector using a support vector machine (SVM) is added.When the tracking confidence is low, the target is blocked or moved violently. At this time, the detector works, and the search area is expanded around the original area for the target. At the same time, because the traditional tracking algorithm uses a fixed learning rate to update the template, this paper uses an adaptive tracking learning rate. When the tracking confidence is low, the update speed of the target model is reduced, which can effectively deal with the occlusion deformation in the tracking process. OTB100 benchmark experiments show that this method can solve the occlusion problem during target tracking. The degree of change is robust and stability.
SN 2161-2927
BN 978-988-15639-0-3
PY 2020
BP 6618
EP 6623
UT WOS:000629243506133
ER

PT J
AU Liang, QK
   Zhu, W
   Sun, W
   Yu, Z
   Wang, YN
   Zhang, D
AF Liang, Qiaokang
   Zhu, Wei
   Sun, Wei
   Yu, Zhun
   Wang, Yaonan
   Zhang, Dan
TI In-line inspection solution for codes on complex backgrounds for the
   plastic container industry
SO MEASUREMENT
AB Machine vision technologies have been widely used for automating the product quality control, but the defect inspection for codes on complex backgrounds is still a challenging task in the plastic container industry. In this work, an efficient and accurate inspection solution based on deep learning was proposed aiming at the detection of codes on complex backgrounds for the plastic container such as beverage packages. Firstly, image processing algorithms such as the region translation method, morphological processing, and image matching technology based on SIFT (Scale Invariant Feature Transform) features were implemented to generate synthetic defective samples, which moderated the class-imbalance problem. Data augmentation strategies were used to increase the amount of training data. Secondly, the ShuffleNet V2 framework was adapted to inspect inkjet codes on complex backgrounds. Additionally, the transfer learning was used to transfer the trained model to other inspection tasks for different kinds of packages. Finally, the proposed approach was built onto an in-line code inspection apparatus for the plastic container industry, and an accuracy of 0.9988 was achieved. The in-line testing results of false detection and omission detection rates demonstrated that the proposed solution can fully meet the production requirements. To the best of our knowledge, this report describes the first time that deep learning has been applied to the industrial defect inspection for the plastic container industry. (C) 2019 Elsevier Ltd. All rights reserved.
RI Zhang, Dan/AFA-2608-2022
OI Zhang, Dan/0000-0002-7295-4837
SN 0263-2241
EI 1873-412X
PD DEC
PY 2019
VL 148
AR 106965
DI 10.1016/j.measurement.2019.106965
UT WOS:000487930000067
ER

PT J
AU Khan, N
   Akram, A
   Mahmood, A
   Ashraf, S
   Murtaza, K
AF Khan, Nazar
   Akram, Arbish
   Mahmood, Arif
   Ashraf, Sania
   Murtaza, Kashif
TI Masked Linear Regression for Learning Local Receptive Fields for Facial
   Expression Synthesis
SO INTERNATIONAL JOURNAL OF COMPUTER VISION
AB Compared to facial expression recognition, expression synthesis requires a very high-dimensional mapping. This problem exacerbates with increasing image sizes and limits existing expression synthesis approaches to relatively small images. We observe that facial expressions often constitute sparsely distributed and locally correlated changes from one expression to another. By exploiting this observation, the number of parameters in an expression synthesis model can be significantly reduced. Therefore, we propose a constrained version of ridge regression that exploits the local and sparse structure of facial expressions. We consider this model as masked regression for learning local receptive fields. In contrast to the existing approaches, our proposed model can be efficiently trained on larger image sizes. Experiments using three publicly available datasets demonstrate that our model is significantly better than regression, SVD based approaches, and kernelized regression in terms of mean-squared-error, visual quality as well as computational and spatial complexities. The reduction in the number of parameters allows our method to generalize better even after training on smaller datasets. The proposed algorithm is also compared with state-of-the-art GANs including Pix2Pix, CycleGAN, StarGAN and GANimation. These GANs produce photo-realistic results as long as the testing and the training distributions are similar. In contrast, our results demonstrate significant generalization of the proposed algorithm over out-of-dataset human photographs, pencil sketches and even animal faces.
RI Khan, Nazar/AAH-8807-2019
OI Khan, Nazar/0000-0002-9470-2120; Mahmood, Arif/0000-0001-5986-9876
SN 0920-5691
EI 1573-1405
PD MAY
PY 2020
VL 128
IS 5
BP 1433
EP 1454
DI 10.1007/s11263-019-01256-3
EA NOV 2019
UT WOS:000493640700001
ER

PT J
AU Hung, VC
   Gonzalez, AJ
AF Hung, Victor C.
   Gonzalez, Avelino J.
TI Context-Centric Speech-Based Human-Computer Interaction
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
AB This paper describes research that addresses the problem of dialog management from a strong, context-centric approach. We further present a quantitative method of measuring the importance of contextual cues when dealing with speech-based human-computer interactions. It is generally accepted that using context in conjunction with a human input, such as spoken speech, enhances a machine's understanding of the user's intent as a means to pinpoint an adequate reaction. For this work, however, we present a context-centric approach in which the use of context is the primary basis for understanding and not merely an auxiliary process. We employ an embodied conversation agent that facilitates the seamless engagement of a speech-based information-deployment entity by its human end user. This dialog manager emphasizes the use of context to drive its mixed-initiative discourse model. Atypical, modern automatic speech recognizer (ASR) was incorporated to handle the speech-to-text translations. As is the nature of these ASR systems, the recognition rate is consistently less than perfect, thus emphasizing the need for contextual assistance. The dialog system was encapsulated into a speech-based embodied conversation agent platform for prototyping and testing purposes. Experiments were performed to evaluate the robustness of its performance, namely through measures of naturalness and usefulness, with respect to the emphasized use of context. The contribution of this work is to provide empirical evidence of the importance of conversational context in speech-based human-computer interaction using a field-tested context-centric dialog manager. (C) 2013 Wiley Periodicals, Inc.
SN 0884-8173
EI 1098-111X
PD OCT
PY 2013
VL 28
IS 10
BP 1010
EP 1037
DI 10.1002/int.21614
UT WOS:000322579900005
ER

PT C
AU Le, DD
   Satoh, S
   Houle, ME
   Nguyen, DPT
AF Le, Duy-Dinh
   Satoh, Shin'ichi
   Houle, Michael E.
   Nguyen, Dat Phuoc Tat
GP IEEE
TI Finding important people in large news video databases using multimodal
   and clustering analysis
SO 2007 IEEE 23RD INTERNATIONAL CONFERENCE ON DATA ENGINEERING WORKSHOP,
   VOLS 1-2
SE IEEE International Conference on Data Engineering Workshop
CT IEEE 23rd International Conference on Data Engineering Workshop
CY APR 17-20, 2007
CL Istanbul, TURKEY
SP IEEE
AB The wide availability of large scale databases requires more efficient and scalable tools for data understanding and knowledge discovery. In this paper we present a method to find important people who have appeared repeatedly in a certain time period from large news video databases. Specifically, we investigate two issues: how to group similar faces to find dominant groups and how to label these groups by the corresponding names for identification.
   These are challenging problems because firstly people can appear with large appearance variations such as hair styles, illumination conditions and poses that make comparing between similar faces more difficult; secondly, the number of people and their occurrence frequencies that are unknown make finding dominant and useful groups more complicated; and finally, the fact that in news video faces and names usually do not appear together can make troubles in aligning faces and names.
   To handle above problems, we propose using the relevant set correlation based clustering model which can efficiently handle dataset of millions of objects represented in thousands or even millions of dimensions to find groups of similar faces from the large and noisy face dataset. Then in order to identify faces in clusters, names extracted from the transcripts are filtered and used to find the best correspondences by using methods developed in the statistical machine translation literature.
   Experiments on large video datasets containing hundreds of hours showed that our system can efficiently find out important people by not only their appearance but also their identification.
OI Houle, Michael/0000-0001-8486-8015
SN 1943-2895
BN 978-1-4244-0831-3
PY 2007
BP 127
EP +
DI 10.1109/ICDEW.2007.4400982
UT WOS:000254288100015
ER

PT J
AU Chamot, D
   Colvin, KR
   Kujat-Choy, SL
   Owttrim, GW
AF Chamot, D
   Colvin, KR
   Kujat-Choy, SL
   Owttrim, GW
TI RNA structural rearrangement via unwinding and annealing by the
   cyanobacterial RNA helicase, CrhR
SO JOURNAL OF BIOLOGICAL CHEMISTRY
AB Rearrangement of RNA secondary structure is crucial for numerous biological processes. RNA helicases participate in these rearrangements through the unwinding of duplex RNA. We report here that the redox-regulated cyanobacterial RNA helicase, CrhR, is a bona fide RNA helicase possessing both RNA-stimulated ATPase and bidirectional ATP-stimulated RNA helicase activity. The processivity of the unwinding reaction appears to be low, because RNA substrates containing duplex regions of 41 bp are not unwound. CrhR also catalyzes the annealing of complementary RNA into intermolecular duplexes. Uniquely and in contrast to other proteins that perform annealing, the CrhR-catalyzed reactions require ATP hydrolysis. Through a combination of the unwinding and annealing activities, CrhR also catalyzes RNA strand exchange resulting in the formation of RNA secondary structures that are too stable to be resolved by helicase activity. RNA strand exchange most probably occurs through the CrhR-dependent formation and resolution of an RNA branch migration structure. Demonstration that another cyanobacterial RNA helicase, CrhC, does not catalyze annealing indicates that this activity is not a general biochemical characteristic of RNA helicases. Biochemically, CrhR resembles RecA and related proteins that catalyze strand exchange and branch migration on DNA substrates, a characteristic that is reflected in the recently reported structural similarities between these proteins. The data indicate the potential for CrhR to catalyze dynamic RNA secondary structure rearrangements through a combination of RNA helicase and annealing activities.
RI Owttrim, George/L-4605-2013
OI Owttrim, George/0000-0002-4709-2091
SN 0021-9258
EI 1083-351X
PD JAN 21
PY 2005
VL 280
IS 3
BP 2036
EP 2044
DI 10.1074/jbc.M409700200
UT WOS:000226341700038
PM 15542859
ER

PT J
AU Domonkos, MT
   Gallimore, AD
   Marrese, CM
   Haas, JM
AF Domonkos, MT
   Gallimore, AD
   Marrese, CM
   Haas, JM
TI Very-near-field plume investigation of the anode layer thruster
SO JOURNAL OF PROPULSION AND POWER
CT AIAA/ASME/SAE/ASEE 33rd Joint Propulsion Conference
CY JUL 06-09, 1997
CL SEATTLE, WASHINGTON
SP Amer Inst Aeronaut & Astronaut, ASME, SAE, ASEE
AB The plasma properties of the very-near-field (10-50 mm) plume of the D55 anode layer thruster (TAL) were measured, The D55 is the 1.35-kW TAL counterpart to the SPT-100 and was made by the Central Scientific Research Institute of Machine Building of Kaliningrad, Russia. The thruster was tested in the 6 m diameter x 9 m long vacuum chamber at the University of Michigan's Plasmadynamics and Electric Propulsion Laboratory, and the diagnostic probes were positioned using a three-axis translation table system. Water-cooled Hail probes, a Faraday probe, emissive probes, and langmuir probes were used to examine the near-field plasma properties. Water-cooled Hall probes were employed to explore the effect of the closed-drift current on the radial magnetic field. The change in the magnetic field during thruster operation was found to be less than 5% over the region examined, which indicated that the Hall current was limited to several tens of amperes. Evidence also indicated that the closed-drift current extended between 5 and 10 mm downstream of the anode. Ion current density profiles showed that the annular beam focuses within 40 mm of the thruster exit plane. Plasma potential measurements indicated that ion acceleration occurred primarily within 10 mm of the anode. The highest electron temperature measured in this investigation occurred immediately downstream of the anode, and the temperature decreased with axial distance from the thruster. The low-energy electrons were confined to the high-density core of the plasma beam.
SN 0748-4658
PD JAN-FEB
PY 2000
VL 16
IS 1
BP 91
EP 98
DI 10.2514/2.5536
UT WOS:000084766800014
ER

PT J
AU Hussain, I
   Ahmad, R
   Muhammad, S
   Ullah, K
   Shah, H
   Namoun, A
AF Hussain, Ibrar
   Ahmad, Riaz
   Muhammad, Siraj
   Ullah, Khalil
   Shah, Habib
   Namoun, Abdallah
TI PHTI: Pashto Handwritten Text Imagebase for Deep Learning Applications
SO IEEE ACCESS
AB Document Image Analysis (DIA) is one of the research areas of Artificial Intelligence (AI) that converts document images into machine-readable codes. In DIA systems, Optical Character Recognition (OCR) plays a key role in digitizing document images. The output of an OCR system is further used in many applications including, Natural Language Processing (NLP), Sentiment Analysis, Speech Recognition, and Translation Services. However, standard datasets are an essential requirement for the development, evaluation and comparison of different text recognition techniques. Pashto is one of such low resource languages that lacks availability regarding standard dataset of handwritten text. This paper therefore, addresses the unavailability of standard dataset for the Pashto handwritten text by developing a dataset named Pashto Handwritten Text Imagebase (PHTI). The PHTI is created by collecting handwritten samples from diverse genre of the Pashto language including poetry, religion, short stories, articles, novels, sports, culture and news. The dataset consists of 4,000 scanned images, written by 400 writers including 200 males and 200 females. These 4,000 images are further segmented into 36,082 text-line images. Each text-line image is annotated/ transcribed with UTF-8 codecs. The dataset can be used for many deep learning-based applications including, text recognition, skew detection, gender classification and age-groups classification.
RI Namoun, Abdallah/AAT-1905-2021; shah, habib/HTM-1745-2023
OI Namoun, Abdallah/0000-0002-7050-0532; Shah, Habib/0000-0003-2078-6285;
   ullah, khalil/0000-0001-7265-7325
SN 2169-3536
PY 2022
VL 10
BP 113149
EP 113157
DI 10.1109/ACCESS.2022.3216881
UT WOS:000878111500001
ER

PT J
AU Chachar, S
   Chachar, M
   Riaz, A
   Shaikh, AA
   Li, XL
   Li, XX
   Guan, CF
   Zhang, PX
AF Chachar, Sadaruddin
   Chachar, Muzafaruddin
   Riaz, Adeel
   Shaikh, Aamir Ali
   Li, Xiulan
   Li, Xiaoxue
   Guan, Changfei
   Zhang, Pingxian
TI Epigenetic modification for horticultural plant improvement comes of age
SO SCIENTIA HORTICULTURAE
AB Our era has witnessed tremendous technique advances and mechanically epigenetic improvement in plant epigenetics, mainly including histone post-translational modifications (PTMs) and DNA methylation, which have been characterized as playing vital roles in development processes and plant response to environmental factors. Recently, chemical modifications on RNAs like 5-methylcytosine (m5C) and N6-methyladenosine (m6A) have been revealed as a new layer of epigenetic marks to regulate gene translation efficiency in model plant Arabidopsis thaliana and with later discovery of horticultural species like tomato (Solanum lycopersicum) and poplar (Populus trichocarpa). In model plants, these epigenetic modifications on DNA, RNA, and histone tails largely trigger innumerable studies on how epigenetic mechanisms are involved in gene regulation and biological functions. As an emerging research field in horticultural plants, epigenetic modifications have bloomed in fruit development and ripening, grafting, and bud dormancy. In this Review, we have demonstrated recent advances of high-throughput sequencing methods, summarized epigenetic enzymatic systems to install, remove and recognize epigenetic marks, discussed essential roles of epigenetic regulation, and proposed how innovative computation techniques like machine learning and deep learning are set to understanding epigenetic regulation mechanisms in horticultural plants. We also raise future perspectives on how epigenetic modifications act as new additions for understanding their roles in gene expression that is required for development and environmental adaptation in horticultural plants.
RI Riaz, Adeel/AAU-1555-2020; Zhang, Pingxian/ABA-6779-2020; Chachar,
   Sadaruddin/U-7841-2018; Chachar, Muzafaruddin/ABD-3261-2021
OI Riaz, Adeel/0000-0002-8957-4099; Zhang, Pingxian/0000-0001-6305-1006;
   Chachar, Sadaruddin/0000-0002-9714-7775; Chachar,
   Muzafaruddin/0000-0003-2123-2110
SN 0304-4238
EI 1879-1018
PD JAN 27
PY 2022
VL 292
AR 110633
DI 10.1016/j.scienta.2021.110633
EA OCT 2021
UT WOS:000709718200008
ER

PT J
AU Zhao, BS
AF Zhao, Binsheng
TI Understanding Sources of Variation to Improve the Reproducibility of
   Radiomics
SO FRONTIERS IN ONCOLOGY
AB Radiomics is the method of choice for investigating the association between cancer imaging phenotype, cancer genotype and clinical outcome prediction in the era of precision medicine. The fast dispersal of this new methodology has benefited from the existing advances of the core technologies involved in radiomics workflow: image acquisition, tumor segmentation, feature extraction and machine learning. However, despite the rapidly increasing body of publications, there is no real clinical use of a developed radiomics signature so far. Reasons are multifaceted. One of the major challenges is the lack of reproducibility and generalizability of the reported radiomics signatures (features and models). Sources of variation exist in each step of the workflow; some are controllable or can be controlled to certain degrees, while others are uncontrollable or even unknown. Insufficient transparency in reporting radiomics studies further prevents translation of the developed radiomics signatures from the bench to the bedside. This review article first addresses sources of variation, which is illustrated using demonstrative examples. Then, it reviews a number of published studies and progresses made to date in the investigation and improvement of feature reproducibility and model performance. Lastly, it discusses potential strategies and practical considerations to reduce feature variability and improve the quality of radiomics study. This review focuses on CT image acquisition, tumor segmentation, quantitative feature extraction, and the disease of lung cancer.
SN 2234-943X
PD MAR 29
PY 2021
VL 11
AR 633176
DI 10.3389/fonc.2021.633176
UT WOS:000639133700001
PM 33854969
ER

PT J
AU Bertoni, D
   Isaiah, A
AF Bertoni, Dylan
   Isaiah, Amal
TI Towards Patient-centered Diagnosis of Pediatric Obstructive Sleep
   Apnea-A Review of Biomedical Engineering Strategies
SO EXPERT REVIEW OF MEDICAL DEVICES
AB Introduction: Obstructive sleep apnea in children has a prevalence of 5%. Polysomnography is considered to be the gold standard for diagnosis and stratification of the condition. However, it is resource-intensive, expensive and uncomfortable for children and their families.Areas covered: We focus this review on technical developments in sensor technology, materials and predictive analytics for translation to (i) patient comfort and compliance in the laboratory and (ii) validation of home sleep apnea testing in children. Key developments in adult polysomnography that could be considered for adoption in children are also highlighted. This review is organized by Sleep, Cardiovascular, Oximetry, Position, Effort, and Respiratory (SCOPER) parameters of interest.Expert opinion: In the past decade, improvements in respiratory sensors and signal processing strategies have transitioned sleep apnea testing in adults from the laboratory to home, thus reducing costs and improving access. Unfortunately, such benefits have not been observed for children principally due to the lack of high-quality studies. The increasing cost of diagnosis of sleep apnea in children needs urgent attention. Recent technical developments as described in this review have the potential to support further evaluation of home sleep apnea testing while improving the current circumstances of in-lab polysomnography for children.
OI Isaiah, Amal/0000-0003-3064-6964
SN 1743-4440
EI 1745-2422
PD JUL 3
PY 2019
VL 16
IS 7
BP 617
EP 629
DI 10.1080/17434440.2019.1626233
UT WOS:000473789900008
PM 31159603
ER

PT C
AU Rubin, SH
   Chen, SC
   Law, JB
AF Rubin, Stuart H.
   Chen, Shu-Ching
   Law, James B.
BE Zhang, D
   Khoshgoftaar, TM
   Joshi, BD
TI T2K2: A type II kaser
SO IRI 2006: PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON
   INFORMATION REUSE AND INTEGRATION
CT IEEE International Conference on Information Reuse and Intergration (IRI
   2006)
CY SEP 16-18, 2006
CL Waikoloa, HI
SP IEEE
AB The transformational methodology described in this paper induces new knowledge, which may be open under any deductive process. The method of transposition is used to maintain a maximum size for the application as well as meta-rule bases. The "move to head" method is used by both the application and meta-rule bases for hypotheses formation. Whenever an application rule is fired, it is transposed on the transposition list and also moved to the head on the other list. If any meta-rule on a solution path individually leads to a contradiction on the application rule base, then the offending meta-rule is expunged. Then, when the system is idle enter dream mode, whereby rule i double right arrow rule j is generated by the 3-2-1 skewed twister as a candidate most-specific meta-rule. Candidate most-specific meta-rules are "cored" to create one generalization per candidate. These candidate meta-rules are tested for application to each rule in the application domain rule base. In order to he saved in the meta base, they may not map any existing rule in the application domain rule base to one having the same antecedent as another in this base, but a different consequent (as found by hashing). In addition, all candidate meta-rules must map at least one rule in the application base to another distinct one there, or be symmetrically induced from meta-rules that so map.
BN 0-7803-9788-6
PY 2006
BP 147
EP +
UT WOS:000242108800027
ER

PT J
AU Ellsworth, D
   Finnen, RL
   Flint, SJ
AF Ellsworth, D
   Finnen, RL
   Flint, SJ
TI Superimposed promoter sequences of the adenoviral E2 early RNA
   polymerase III and RNA polymerase II transcription units
SO JOURNAL OF BIOLOGICAL CHEMISTRY
AB The human adenovirus type 2 E2 early (E2E) transcriptional control region contains an efficient RNA polymerase III promoter, in addition to the well characterized promoter for RNA polymerase II. To determine whether this promoter includes intragenic sequences, we examined the effects of precise substitutions introduced between positions +2 and +62 on E2E transcription in an RNA polymerase III-specific, in vitro system. Two noncontiguous sequences within this region were necessary for efficient or accurate transcription by this enzyme. The sequence and properties of the functional element proximal to the sites of initiation identified it as an A box. Although a B box sequence could not be unambiguously located, substitutions between positions +42 and +62 that severely impaired transcription also inhibited binding of the human general initiation protein TFIIIC, Thus, this region of the RNA polymerase III E2E promoter contains a B box sequence. We also identified previously unrecognized intragenic sequences of the E2E RNA polymerase II promoter. In conjunction with our previous observations, these data establish that RNA polymerase II and RNA polymerase III promoter sequences are superimposed from approximately positions -30 to +20 of the complex E2E transcriptional control region. The alterations in transcription induced by certain mutations suggest that components of the RNA polymerase II and RNA polymerase III transcriptional machines compete for access to overlapping binding sites in the E2E template.
SN 0021-9258
EI 1083-351X
PD JAN 5
PY 2001
VL 276
IS 1
BP 827
EP 834
DI 10.1074/jbc.M007036200
UT WOS:000166280700111
PM 11031267
ER

PT J
AU Shao, MW
   Wang, P
   Wang, YJ
AF Shao, Mingwei
   Wang, Pan
   Wang, Yanjun
TI Phase-Based Calibration Method for a Binocular Vision Sensor
SO IEEE ACCESS
AB In this paper, a phase based method to calibrate a binocular vision sensor is presented. In this method, only a surface plate is utilized. A series of phase shifting patterns are projected onto the surface plate. In this case, fundamental matrix can be calculated out from point correspondences on two image planes. As intrinsic parameters of each camera have been obtained according to related calibration method, essential matrix can be worked out. Then, rotation matrix and translation matrix with a coefficient are deduced based on singular value decomposition of the essential matrix. As size of the pattern can be confirmed from a look-up table, the coefficient is determined. So far, the binocular vision sensor is calibrated. In our proposed method, only one planar target without any pattern is necessary, which is with high precision and easy machined. As the calibration method is based on related phase algorithm, the calibration process is not affected by the ambient light which makes our calibration method robust. Experiment results show the precision of our proposed method. When we utilized a laser displacement sensor with a precision of 0.01 mm to determine size of the pattern, root mean square error of our calibration method is 0.103 mm with regard to the measurement area of about 100 x 80 mm. Moreover, as planar features are widely existing, our proposed method is very suitable for on-site calibration and auto-calibration.
RI Wang, Ying/HJI-2509-2023; wang, yi/HOF-6668-2023; Wang,
   Yanbo/HFZ-8018-2022; wangwangwang, yuanyaunyuan/HHN-6432-2022; Wang,
   Yu/GZL-9655-2022; wang, yan/GSE-6489-2022; Wang, Yin/HCI-9352-2022;
   Wang, Yuan/HHC-1520-2022
OI Shao, Mingwei/0000-0003-1630-8985
SN 2169-3536
PY 2021
VL 9
BP 44354
EP 44362
DI 10.1109/ACCESS.2021.3066379
UT WOS:000633370100001
ER

PT C
AU Gao, HY
   Mao, JH
   Zhou, J
   Huang, ZH
   Wang, L
   Xu, W
AF Gao, Haoyuan
   Mao, Junhua
   Zhou, Jie
   Huang, Zhiheng
   Wang, Lei
   Xu, Wei
BE Cortes, C
   Lawrence, ND
   Lee, DD
   Sugiyama, M
   Garnett, R
TI Are You Talking to a Machine? Dataset and Methods for Multilingual Image
   Question Answering
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 28 (NIPS 2015)
SE Advances in Neural Information Processing Systems
CT 29th Annual Conference on Neural Information Processing Systems (NIPS)
CY DEC 07-12, 2015
CL Montreal, CANADA
AB In this paper, we present the mQA model, which is able to answer questions about the content of an image. The answer can be a sentence, a phrase or a single word. Our model contains four components: a Long Short-Term Memory (LSTM) to extract the question representation, a Convolutional Neural Network (CNN) to extract the visual representation, an LSTM for storing the linguistic context in an answer, and a fusing component to combine the information from the first three components and generate the answer. We construct a Freestyle Multilingual Image Question Answering (FM-IQA) dataset to train and evaluate our mQA model. It contains over 150,000 images and 310,000 freestyle Chinese question-answer pairs and their English translations. The quality of the generated answers of our mQA model on this dataset is evaluated by human judges through a Turing Test. Specifically, we mix the answers provided by humans and our model. The human judges need to distinguish our model from the human. They will also provide a score (i.e. 0, 1, 2, the larger the better) indicating the quality of the answer. We propose strategies to monitor the quality of this evaluation process. The experiments show that in 64.7% of cases, the human judges cannot distinguish our model from humans. The average score is 1.454 (1.918 for human). The details of this work, including the FM-IQA dataset, can be found on the project page: http://idl.baidu.com/FM-IQA.html.
RI liu, feng/HPC-8076-2023
SN 1049-5258
PY 2015
VL 28
UT WOS:000450913100009
ER

PT J
AU Glikson, E
   Asscher, O
AF Glikson, Ella
   Asscher, Omri
TI AI-mediated apology in a multilingual work context: Implications for
   perceived authenticity and willingness to forgive
SO COMPUTERS IN HUMAN BEHAVIOR
AB As Artificial Intelligence-Mediated Communication (AI-MC) technology is increasingly used to facilitate communication worldwide, its implications for interpersonal relationships in multinational working environ-ments have become more significant. In particular, knowing that AI-MC tools are used by the communicator might reduce recipients' perceptions of the authenticity of emotionally charged messages, such as an apology. Across three scenario-based studies rooted in an interpersonal work-related conflict, we examined the effects of the choice to use AI-MC tools to communicate an apology, focusing on people's perceptions of the genuineness of the apology, and their ensuing tendency to forgive the person apologizing. We consistently found that the choice to use AI-MC tools diminished perceptions of the apology's authenticity and the consequent willingness to forgive, and that self-disclosing the use of AI-MC on the part of the communicator did not mitigate this effect. However, making limited use of AI-MC (selecting to use only one of three available tools) had no negative impact on the perceived authenticity of the apology, suggesting that limiting the use of AI-MC signals a diminished distance between the original intention of the person apologizing and the final formulation of the message of apology, leading to perceptions of a more genuine apology.
SN 0747-5632
EI 1873-7692
PD MAR
PY 2023
VL 140
AR 107592
DI 10.1016/j.chb.2022.107592
UT WOS:000906433800001
ER

PT J
AU Wang, WY
   Hsu, MJ
   Chien, YH
   Hsu, CC
   Chiang, HH
   Yu, LA
AF Wang, Wei-Yen
   Hsu, Min-Jie
   Chien, Yi-Hsing
   Hsu, Chen-Chien
   Chiang, Hsin-Han
   Yu, Li-An
TI Cognitive System of a Virtual Robot Based on Perception, Memory, and
   Hypothesis Models for Calligraphy Writing Task
SO IEEE ACCESS
AB In this paper, we propose a robotic cognitive system which can learn itself to do a specific assignment by accumulating experiences through bottom-up thinking to make decision by itself via top-down thinking according to the experiences. That is, the cognitive system has a self-learning ability which can accumulate its experiences to make itself smarter. In essence, the cognitive system possesses a perception model, a memory model, and a hypothesis model. The perception model converts image information into perception codes. The memory model stores experiences in the past and present to provide to the perception model and the hypothesis model. The hypothesis model, which generates the next decision according to the experiences from the memory model, is the most important part of the proposed cognitive system. To validate the performance of the proposed system, we utilize Chinese calligraphy writing tasks by a virtual robot through simulation to evaluate the abilities of the cognitive system. In order to generate the coordinates of the writing brush, we made the virtual robot practice to learn Chinese calligraphy through bottom-up thinking to construct the writing patterns. The illustrative examples in this paper show that the virtual robot can learn to write Chinese calligraphy by top-down thinking according to its own experiences.
OI Chiang, Hsin-Han/0000-0003-0795-0490; Wang, Wei-Yen/0000-0003-1579-8265;
   Hsu, Min-Jie/0009-0009-7633-0931
SN 2169-3536
PY 2022
VL 10
BP 117782
EP 117795
DI 10.1109/ACCESS.2022.3219547
UT WOS:000886307600001
ER

PT J
AU Zhao, SC
   Chen, XB
   Yue, XY
   Lin, C
   Xu, PF
   Krishna, R
   Yang, JF
   Ding, GG
   Sangiovanni-Vincentelli, AL
   Keutzer, K
AF Zhao, Sicheng
   Chen, Xuanbai
   Yue, Xiangyu
   Lin, Chuang
   Xu, Pengfei
   Krishna, Ravi
   Yang, Jufeng
   Ding, Guiguang
   Sangiovanni-Vincentelli, Alberto L.
   Keutzer, Kurt
TI Emotional Semantics-Preserved and Feature-Aligned CycleGAN for Visual
   Emotion Adaptation
SO IEEE TRANSACTIONS ON CYBERNETICS
AB Thanks to large-scale labeled training data, deep neural networks (DNNs) have obtained remarkable success in many vision and multimedia tasks. However, because of the presence of domain shift, the learned knowledge of the well-trained DNNs cannot be well generalized to new domains or datasets that have few labels. Unsupervised domain adaptation (UDA) studies the problem of transferring models trained on one labeled source domain to another unlabeled target domain. In this article, we focus on UDA in visual emotion analysis for both emotion distribution learning and dominant emotion classification. Specifically, we design a novel end-to-end cycle-consistent adversarial model, called CycleEmotionGAN++. First, we generate an adapted domain to align the source and target domains on the pixel level by improving CycleGAN with a multiscale structured cycle-consistency loss. During the image translation, we propose a dynamic emotional semantic consistency loss to preserve the emotion labels of the source images. Second, we train a transferable task classifier on the adapted domain with feature-level alignment between the adapted and target domains. We conduct extensive UDA experiments on the Flickr-LDL and Twitter-LDL datasets for distribution learning and ArtPhoto and Flickr and Instagram datasets for emotion classification. The results demonstrate the significant improvements yielded by the proposed CycleEmotionGAN++ compared to state-of-the-art UDA approaches.
RI kumar, ravi/HPH-9508-2023; Patel, Neel/HPD-6064-2023;
   Sangiovanni-Vincentelli, Alberto/F-5742-2018
OI Sangiovanni-Vincentelli, Alberto/0000-0003-1298-8389; Yue,
   Xiangyu/0000-0002-6887-2046
SN 2168-2267
EI 2168-2275
PD OCT
PY 2022
VL 52
IS 10
BP 10000
EP 10013
DI 10.1109/TCYB.2021.3062750
EA MAR 2021
UT WOS:000732124700001
PM 33760749
ER

PT C
AU Cao, Y
   Feng, Y
   Yang, YT
   Chen, YJ
   Lei, B
   Zhao, LS
AF Cao Yu
   Feng Ying
   Yang Yun-tao
   Chen Yun-jin
   Lei Bing
   Zhao Li-shuang
BE Ikeda, M
   Wu, N
   Zhang, G
   Ai, K
TI Monocular Visual Odometry based on Inverse Perspective Mapping
SO INTERNATIONAL SYMPOSIUM ON PHOTOELECTRONIC DETECTION AND IMAGING 2011:
   ADVANCES IN IMAGING DETECTORS AND APPLICATIONS
SE Proceedings of SPIE
CT International Symposium on Photoelectronic Detection and Imaging 2011 -
   Advances in Imaging Detectors and Applications
CY MAY 24-26, 2011
CL Beijing, PEOPLES R CHINA
SP Photoelect Technol Profess Comm, CSA, Tianjin Jinhang Inst Tech Phys, CASIC, Sci & Technol Low Light Level Night Vis Lab, Chinese Soc Astronaut, SPIE
AB The monocular vision odometry simplifies the hardware and the software as opposed to the stereo vision odometry, but it also has defect. When the vehicle is in motion, the camera's attitude changes inevitably, what lead that the method's performance degrades. To solve this problem, we proposed a monocular visual odometry based on the inverse perspective mapping (IPM). Attitude of the camera is monitored in real time by the attitude sensor when the vehicle is moving. Then the images of road surface photographed by camera became top view by using the IPM algorithm, after that, the characters of images can be calculated by the Speeded Up Robust Features (SURF) algorithm. By the random sample consensus (RANSAC) algorithm, the amounts of translation and rotation between two adjacent images can be concluded. Accordingly, the movement distance and the course of the vehicle can be worked out. In order to test the ranging accuracy of the method, both static and dynamic experiments were implemented. Static experiment showed that the average accuracy of ranging of this method achieved 1.6 parts per thousand. Dynamic experiment showed that the ranging accuracy achieved 6 parts per thousand, and the heading measurement error is less than 1.3 degrees. Therefore, the method proposed in this paper is easy to operate, time-efficient, low cost, and the accuracy of the method in ranging and heading measurement are demonstrated.
RI Lei, Bing/P-1513-2014
SN 0277-786X
EI 1996-756X
BN 978-0-81948-835-0
PY 2011
VL 8194
AR 819418
DI 10.1117/12.900010
UT WOS:000295076300043
ER

PT J
AU Mao, PL
   Liu, TF
   Kueh, K
   Wu, P
AF Mao, PL
   Liu, TF
   Kueh, K
   Wu, P
TI Predicting the efficiency of UAG translational stop signal through
   studies of physicochemical properties of its composite mono- and
   dinucleotides
SO COMPUTATIONAL BIOLOGY AND CHEMISTRY
AB In this study, we explored the problem of predicting the UAG stop-codon read-through efficiency. The reported nucleotide sequences were first converted into physicochemical property vectors before being presented to a machine learning algorithm. Two sets of physicochemical properties were applied: one for mononucleosides (in terms of steric bulk, hydrophobicity and electronics) and another for dinucleotides. To the best of our knowledge, this is the first report of how dinucleotides are converted into principle components derived from NMR chemical shift data. A few efficiency prediction models were then derived and a comparison between mononucleoside and dinucleotide-based models was shown. In the derived models, the coefficients of these property based predictors lend themselves to bio-physical interpretations, an advantage which is demonstrated in this study via a prediction model based on the steric bulk factor. Although it is quite simple, the steric bulk factor model explained well the effect of sequence variations surrounding the amber stop codon and the tRNA bearing UCCU anticodon. We further proposed new alternatives at position -1 and +4 of a UAG stop codon sequence to enhance the readthrough efficiency. This research may contribute to a better understanding of the readthrough mechanisms and may also help to study the normal translation termination process. (C) 2004 Elsevier Ltd. All rights reserved.
RI Wu, Ping/AAX-3767-2020
OI Wu, Ping/0000-0002-0788-6268
SN 1476-9271
EI 1476-928X
PD OCT
PY 2004
VL 28
IS 4
BP 245
EP 256
DI 10.1016/j.compbiolchem.2004.05.003
UT WOS:000226382800001
PM 15548451
ER

PT J
AU Cheon, J
   Baek, S
   Paik, SB
AF Cheon, Jeonghwan
   Baek, Seungdae
   Paik, Se-Bum
TI Invariance of object detection in untrained deep neural networks
SO FRONTIERS IN COMPUTATIONAL NEUROSCIENCE
AB The ability to perceive visual objects with various types of transformations, such as rotation, translation, and scaling, is crucial for consistent object recognition. In machine learning, invariant object detection for a network is often implemented by augmentation with a massive number of training images, but the mechanism of invariant object detection in biological brains-how invariance arises initially and whether it requires visual experience-remains elusive. Here, using a model neural network of the hierarchical visual pathway of the brain, we show that invariance of object detection can emerge spontaneously in the complete absence of learning. First, we found that units selective to a particular object class arise in randomly initialized networks even before visual training. Intriguingly, these units show robust tuning to images of each object class under a wide range of image transformation types, such as viewpoint rotation. We confirmed that this "innate" invariance of object selectivity enables untrained networks to perform an object-detection task robustly, even with images that have been significantly modulated. Our computational model predicts that invariant object tuning originates from combinations of non-invariant units via random feedforward projections, and we confirmed that the predicted profile of feedforward projections is observed in untrained networks. Our results suggest that invariance of object detection is an innate characteristic that can emerge spontaneously in random feedforward networks.
EI 1662-5188
PD NOV 3
PY 2022
VL 16
AR 1030707
DI 10.3389/fncom.2022.1030707
UT WOS:000885937100001
PM 36405785
ER

PT J
AU Zhao, J
   Zhu, T
   Xiao, S
   Gao, ZQ
   Sun, H
AF Zhao, Juan
   Zhu, Tong
   Xiao, Shuo
   Gao, Zongqian
   Sun, Hao
TI Actor-Critic for Multi-Agent Reinforcement Learning with Self-Attention
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
AB The rapid development of deep reinforcement learning makes it widely used in multi-agent environments to solve the multi-agent cooperation problem. However, due to the instability of multi-agent environments, the performance is insufficient when using deep reinforcement learning algorithms to train each agent independently. In this work, we use the framework of centralized training with decentralized execution to extend the maximum entropy deep reinforcement learning algorithm Soft Actor-Critic (SAC) and proposes the multi-agent deep reinforcement learning algorithm MASAC based on the maximum entropy framework. Proposed model treats all the agents as part of the environment, it can effectively solve the problem of poor convergence of algorithms due to environmental instability. At the same time, we have noticed the shortcoming of centralized training, using all the information of the agents as input of critics, and it is easy to lose the information related to the current agent. Inspired by the application of self-attention mechanism in machine translation, we use the self-attention mechanism to improve the critic and propose the ATT-MASAC algorithm. Each agent can discover their relationship with other agents through encoder operation and attention calculation as part of the critic networks. Compared with the recent multi-agent deep reinforcement learning algorithms, ATT-MASAC has better convergence effect. Also, it has better stability when the number of agents in the environment increases.
SN 0218-0014
EI 1793-6381
PD JUL
PY 2022
VL 36
IS 09
AR 2252014
DI 10.1142/S0218001422520140
UT WOS:000835907600010
ER

PT J
AU Masood, H
   Zafar, A
   Ali, MU
   Khan, MA
   Ahmed, S
   Tariq, U
   Kang, BG
   Nam, Y
AF Masood, Haris
   Zafar, Amad
   Ali, Muhammad Umair
   Khan, Muhammad Attique
   Ahmed, Salman
   Tariq, Usman
   Kang, Byeong-Gwon
   Nam, Yunyoung
TI Recognition and Tracking of Objects in a Clustered Remote Scene
   Environment
SO CMC-COMPUTERS MATERIALS & CONTINUA
AB Object recognition and tracking are two of the most dynamic research sub-areas that belong to the field of Computer Vision. Computer vision is one of the most active research fields that lies at the intersection of deep learning and machine vision. This paper presents an efficient ensemble algorithm for the recognition and tracking of fixed shape moving objects while accommodating the shift and scale invariances that the object may encounter. The first part uses the Maximum Average Correlation Height (MACH) filter for object recognition and determines the bounding box coordinates. In case the correlation based MACH filter fails, the algorithms switches to a much reliable but computationally complex feature based object recognition technique i.e., affine scale invariant feature transform (ASIFT). ASIFT is used to accommodate object shift and scale object variations. ASIFT extracts certain features from the object of interest, providing invariance in up to six affine parameters, namely translation (two parameters), zoom, rotation and two camera axis orientations. However, in this paper, only the shift and scale invariances are used. The second part of the algorithm demonstrates the use of particle filters based Approximate Proximal Gradient (APG) technique to periodically update the coordinates of the object encapsulated in the bounding box. At the end, a comparison of the proposed algorithm with other stateof-the-art tracking algorithms has been presented, which demonstrates the effectiveness of the proposed algorithm with respect to the minimization of tracking errors.
RI khan, sajid/HGE-2406-2022; Tariq, Usman/AAF-8954-2020; Khan, Dr.
   Muhammad Attique/AAX-2644-2021; Tariq, Usman/AAE-8037-2022; Zafar,
   Amad/HJB-1978-2022; Tariq, Usman/GZL-9946-2022; Umair Ali,
   Muhammad/AAD-2202-2019
OI Khan, Dr. Muhammad Attique/0000-0002-6347-4890; Tariq,
   Usman/0000-0001-7672-1187; Umair Ali, Muhammad/0000-0002-7326-1813
SN 1546-2218
EI 1546-2226
PY 2022
VL 70
IS 1
BP 1699
EP 1719
DI 10.32604/cmc.2022.019572
UT WOS:000709118000018
ER

PT J
AU Li, TF
   Zhao, ZB
   Sun, C
   Cheng, L
   Chen, XF
   Yan, RQ
   Gao, RX
AF Li, Tianfu
   Zhao, Zhibin
   Sun, Chuang
   Cheng, Li
   Chen, Xuefeng
   Yan, Ruqiang
   Gao, Robert X.
TI WaveletKernelNet: An Interpretable Deep Neural Network for Industrial
   Intelligent Diagnosis
SO IEEE TRANSACTIONS ON SYSTEMS MAN CYBERNETICS-SYSTEMS
AB Convolutional neural network (CNN), with the ability of feature learning and nonlinear mapping, has demonstrated its effectiveness in prognostics and health management (PHM). However, an explanation on the physical meaning of a CNN architecture has rarely been studied. In this article, a novel wavelet-driven deep neural network, termed as WaveletKernelNet (WKN), is presented, where a continuous wavelet convolutional (CWConv) layer is designed to replace the first convolutional layer of the standard CNN. This enables the first CWConv layer to discover more meaningful kernels. Furthermore, only the scale parameter and translation parameter are directly learned from raw data at this CWConv layer. This provides a very effective way to obtain a customized kernel bank, specifically tuned for extracting defect-related impact component embedded in the vibration signal. In addition, three experimental studies using data from laboratory environment are carried out to verify the effectiveness of the proposed method for mechanical fault diagnosis. The experimental results show that the accuracy of the WKNs is higher than CNN by more than 10%, which indicate the importance of the designed CWConv layer. Besides, through theoretical analysis and feature map visualization, it is found that the WKNs are interpretable, have fewer parameters, and have the ability to converge faster within the same training epochs.
RI Gao, Robert X/O-9339-2014; Yan, Ruqiang/A-9776-2012; Li,
   Tianfu/AAV-9975-2020
OI Gao, Robert X/0000-0003-3595-3728; Yan, Ruqiang/0000-0003-4341-6535; Li,
   Tianfu/0000-0003-4388-9578; Yan, Ruqiang/0000-0002-1250-4084; Zhao,
   Zhibin/0000-0003-4180-7137
SN 2168-2216
EI 2168-2232
PD APR
PY 2022
VL 52
IS 4
BP 2302
EP 2312
DI 10.1109/TSMC.2020.3048950
EA JAN 2021
UT WOS:000732143700001
ER

PT J
AU Liang, SQ
   Stockinger, K
   de Farias, TM
   Anisimova, M
   Gil, M
AF Liang, Shiqi
   Stockinger, Kurt
   de Farias, Tarcisio Mendes
   Anisimova, Maria
   Gil, Manuel
TI Querying knowledge graphs in natural language
SO JOURNAL OF BIG DATA
AB Knowledge graphs are a powerful concept for querying large amounts of data. These knowledge graphs are typically enormous and are often not easily accessible to end-users because they require specialized knowledge in query languages such as SPARQL. Moreover, end-users need a deep understanding of the structure of the underlying data models often based on the Resource Description Framework (RDF). This drawback has led to the development of Question-Answering (QA) systems that enable end-users to express their information needs in natural language. While existing systems simplify user access, there is still room for improvement in the accuracy of these systems. In this paper we propose a new QA system for translating natural language questions into SPARQL queries. The key idea is to break up the translation process into 5 smaller, more manageable sub-tasks and use ensemble machine learning methods as well as Tree-LSTM-based neural network models to automatically learn and translate a natural language question into a SPARQL query. The performance of our proposed QA system is empirically evaluated using the two renowned benchmarks-the 7th Question Answering over Linked Data Challenge (QALD-7) and the Large-Scale Complex Question Answering Dataset (LC-QuAD). Experimental results show that our QA system outperforms the state-of-art systems by 15% on the QALD-7 dataset and by 48% on the LC-QuAD dataset, respectively. In addition, we make our source code available.
OI Mendes de Farias, Tarcisio/0000-0002-3175-5372; Gil,
   Manuel/0000-0001-7089-6285; Anisimova, Maria/0000-0001-8145-7966
EI 2196-1115
PD JAN 6
PY 2021
VL 8
IS 1
AR 3
DI 10.1186/s40537-020-00383-w
UT WOS:000610410900005
PM 33489717
ER

PT C
AU Wei, YZ
   Fu, XH
   Wang, SX
   Xie, WH
   He, JW
   Zhao, YL
AF Wei, Yanzhi
   Fu, Xianghua
   Wang, Shuxin
   Xie, Wenhao
   He, Jianwei
   Zhao, Yonglin
BE Qiu, M
TI Aspect-Level Sentiment Difference Feature Interaction Matching Model
   Based on Multi-round Decision Mechanism
SO ALGORITHMS AND ARCHITECTURES FOR PARALLEL PROCESSING, ICA3PP 2020, PT II
SE Lecture Notes in Computer Science
CT 20th International Conference on Algorithms and Architectures for
   Parallel Processing (ICA3PP)
CY OCT 02-04, 2020
CL New York, NY
SP Springer LNCS, Columbia Univ, N Amer Chinese Talents Assoc, Longxiang High Tech Grp Inc
AB Sentence matching is a key problem in natural language understanding, so the research on sentence matching can be applied to a large number of known natural language processing tasks, such as information retrieval, automatic question and answer, machine translation, dialogue system, paraphrase identification etc. In a series of natural language processing tasks, we need to rely on the participation and collaboration of the sentence matching model. The performance of the sentence matching model can greatly affect the final performance of these natural language processing tasks. We propose the Al-SFIM model, which improves the matching model from the perspective of word interaction. First, we propose sentiment attention mechanism based on the distribution of aspect-level sentiment difference to improve the interaction between cross-sentence words, and use the sentiment space position perception vector to improve the interaction between intra-sentence words, so that the model has the ability to perceive the subjective sentiment difference in the process of intra-sentence word interaction and cross-sentence word interaction. Then, we introduce a multi-round decision mechanism based on the accumulation of memory state, which iteratively updates the working memory state to make matching decisions in multiple rounds, so that the model can better understand the semantic of complex sentence. Experiment results show that the AL-SFIM model has made progress in sentence matching and has better matching performance for complex, long and incomprehensible sentences.
SN 0302-9743
EI 1611-3349
BN 978-3-030-60239-0; 978-3-030-60238-3
PY 2020
VL 12453
BP 477
EP 491
DI 10.1007/978-3-030-60239-0_32
UT WOS:000719292600032
ER

PT C
AU Venkataramani, S
   Srinivasan, V
   Choi, J
   Heidelberger, P
   Chang, L
   Gopalakrishnan, K
AF Venkataramani, Swagath
   Srinivasan, Vijayalakshmi
   Choi, Jungwook
   Heidelberger, Philip
   Chang, Leland
   Gopalakrishnan, Kailash
GP IEEE
TI Memory and Interconnect Optimizations for Peta-Scale Deep Learning
   Systems
SO 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING,
   DATA, AND ANALYTICS (HIPC)
CT 26th International Conference on High Performance Computing, Data and
   Analytics (HiPCW)
CY DEC 17-20, 2019
CL Hyderabad, INDIA
SP IEEE Comp Soc, IEEE, AMD & Shell, Boston, Google, Infosys, Intel, Samsung, SREE Vidyanikethan, Xilinx, IEEE Comp Soc Tech Comm Parallel Proc
AB Hardware accelerators are a promising solution to the stringent computational requirements of Deep Neural Networks (DNNs). Ranging from low-power IP cores to server class systems, various accelerator architectures with high TOPS/W peak processing efficiencies and flexibility to execute different DNN topologies have been proposed. Prior efforts improve core utilization through better data-flows and computation sequencing, but little effort has thus far been devoted to systematically programming DNN accelerators to extract best possible system utilization, particularly for DNN training, which can be parallelized across peta-scale systems. In this work, we address the hitherto open challenge of systematically mapping computations onto Peta-scale accelerator systems, comprising many (thousands of) processing cores spanning many chips, while maximizing overall system performance. We achieve this by characterizing the design space of possible mapping configurations, building a detailed performance model that incorporates every computation and data-transfer involved in DNN training, and using a design space exploration tool called DEEPSPATIALMATRIX to identify the performance optimal configuration. We highlight 4 key optimizations built within DEEPSPATIALMATRIX - hybrid data-model parallelism, inter-layer memory reuse, time-step pipelining, and dynamic spatial minibatching - each of which improve system utilization by carefully managing the available memory capacity and interconnect bandwidth to balance the compute vs. communication costs. On a 8-peta-FLOP accelerator system, we demonstrate 1.36x -32x improvement in training performance through our design space exploration and optimizations across image recognition (VGG16, ResNet50) and machine translation (GNMT) DNN models.
RI Venkataramani, Swagath/AAA-9473-2022
BN 978-1-7281-4535-8
PY 2019
BP 225
EP 234
DI 10.1109/HiPC.2019.00036
UT WOS:000574772000025
ER

PT C
AU Rakholia, RM
   Saini, JR
AF Rakholia, Rajnish M.
   Saini, Jatinderkumar R.
BE Satapathy, SC
   Bhateja, V
   Joshi, A
TI Automatic Language Identification and Content Separation from Indian
   Multilingual Documents Using Unicode Transformation Format
SO PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON DATA ENGINEERING AND
   COMMUNICATION TECHNOLOGY, ICDECT 2016, VOL 1
SE Advances in Intelligent Systems and Computing
CT 1st International Conference on Data Engineering and Communication
   Technology (ICDECT)
CY MAR 10-11, 2016
CL Christ Inst Management, Lavasa, INDIA
SP Aspire Res Fdn
HO Christ Inst Management
AB In Natural Language Processing (NLP), language identification is the problem of determining which natural language(s) are used in written script. This paper presents a methodology for Language Identification from multilingual document written in Indian language(s). The main objective of this research is to automatically, quickly, and accurately recognize the language from the multilingual document written in Indian language(s) and then separate the content according to types of language, using Unicode Transformation Format (UTF). The proposed methodology is applicable for preprocessing step in document classification and a number of applications such as POS-Tagging, Information Retrieval, Search Engine Optimization, and Machine Translation for Indian languages. Sixteen different Indian languages have been used for empirical purpose. The corpus texts were collected randomly from web and 822 documents were prepared, comprising of 300 Portable Document Format (PDF) files and 522 text files. Each of 822 documents contained more than 800 words written in different and multiple Indian languages at the sentence level. The proposed methodology has been implemented using UTF-8 through free and open-source programming language Java Server Pages (JSP). The obtained results with an execution of 522 Text file documents yielded an accuracy of 99.98 %, whereas 300 PDF documents yielded an accuracy of 99.28 %. The accuracy of text files is more than PDF files by 0.70 %, due to corrupted texts appearing in PDF files.
RI Saini, Jatinderkumar R./M-5584-2013
OI Saini, Jatinderkumar R./0000-0001-5205-5263; Rakholia,
   Rajnish/0000-0001-7991-1621
SN 2194-5357
EI 2194-5365
BN 978-981-10-1675-2; 978-981-10-1674-5
PY 2017
VL 468
BP 369
EP 378
DI 10.1007/978-981-10-1675-2_37
UT WOS:000399005000037
ER

PT J
AU Han, XS
   Gan, YX
AF Han, Xuesong
   Gan, Yong X.
TI Analysis the complex interaction among flexible nanoparticles and
   materials surface in the mechanical polishing process
SO APPLIED SURFACE SCIENCE
AB Mechanical polishing (MP), being the important technique of realizing the surface planarization, has already been widely applied in the area of microelectronic manufacturing and computer manufacturing technology. The surface planarization in the MP is mainly realized by mechanical process which depended on the microdynamic behavior of nanoparticle. The complex multibody interaction among nanoparticles and materials surface is different from interaction in the macroscopic multibody system which makes the traditional classical materials machining theory cannot accurately uncover the mystery of the surface generation in the MP. Large-scale classical molecular dynamic (MD) simulation of interaction among nanoparticles and solid surface has been carried out to investigate the physical essence of surface planarization. The particles with small impact angle can generate more uniform global planarization surface but the materials removal rate is lower. The shear interaction between particle and substrate may induce large friction torque and lead to the rotation of particle. The translation plus rotation makes the nanoparticle behaved like micro-milling tool. The results show that the nanoparticles may aggregrate together and form larger cluster thus deteriorate surface the quality. This MD simulation results illuminate that the final planarized surface can only be acquired by synergic behavior of all particles using various means such as cutting, impacting, scratching, indentation and so on. (C) 2010 Elsevier B.V. All rights reserved.
SN 0169-4332
EI 1873-5584
PD FEB 1
PY 2011
VL 257
IS 8
BP 3363
EP 3373
DI 10.1016/j.apsusc.2010.11.026
UT WOS:000286179800037
ER

PT J
AU Hernandez-Alias, X
   Benisty, H
   Radusky, LG
   Serrano, L
   Schaefer, MH
AF Hernandez-Alias, Xavier
   Benisty, Hannah
   Radusky, Leandro G.
   Serrano, Luis
   Schaefer, Martin H.
TI Using protein-per-mRNA differences among human tissues in codon
   optimization
SO GENOME BIOLOGY
AB BackgroundCodon usage and nucleotide composition of coding sequences have profound effects on protein expression. However, while it is recognized that different tissues have distinct tRNA profiles and codon usages in their transcriptomes, the effect of tissue-specific codon optimality on protein synthesis remains elusive.ResultsWe leverage existing state-of-the-art transcriptomics and proteomics datasets from the GTEx project and the Human Protein Atlas to compute the protein-to-mRNA ratios of 36 human tissues. Using this as a proxy of translational efficiency, we build a machine learning model that identifies codons enriched or depleted in specific tissues. We detect two clusters of tissues with an opposite pattern of codon preferences. We then use these identified patterns for the development of CUSTOM, a codon optimizer algorithm which suggests a synonymous codon design in order to optimize protein production in a tissue-specific manner. In human cell-line models, we provide evidence that codon optimization should take into account particularities of the translational machinery of the tissues in which the target proteins are expressed and that our approach can design genes with tissue-optimized expression profiles.ConclusionsWe provide proof-of-concept evidence that codon preferences exist in tissue-specific protein synthesis and demonstrate its application to synthetic gene design. We show that CUSTOM can be of benefit in biological and biotechnological applications, such as in the design of tissue-targeted therapies and vaccines.
RI ; Benisty, Hannah/M-6747-2015
OI Radusky, Leandro/0000-0001-5841-1273; Hernandez-Alias,
   Xavier/0000-0001-8633-499X; Benisty, Hannah/0000-0002-7835-9115
SN 1474-760X
PD FEB 24
PY 2023
VL 24
IS 1
AR 34
DI 10.1186/s13059-023-02868-2
UT WOS:000939958900003
PM 36829202
ER

PT J
AU Castaldo, R
   Garbino, N
   Cavaliere, C
   Incoronato, M
   Basso, L
   Cuocolo, R
   Pace, L
   Salvatore, M
   Franzese, M
   Nicolai, E
AF Castaldo, Rossana
   Garbino, Nunzia
   Cavaliere, Carlo
   Incoronato, Mariarosaria
   Basso, Luca
   Cuocolo, Renato
   Pace, Leonardo
   Salvatore, Marco
   Franzese, Monica
   Nicolai, Emanuele
TI A Complex Radiomic Signature in Luminal Breast Cancer from a Weighted
   Statistical Framework: A Pilot Study
SO DIAGNOSTICS
AB Radiomics is rapidly advancing in precision diagnostics and cancer treatment. However, there are several challenges that need to be addressed before translation to clinical use. This study presents an ad-hoc weighted statistical framework to explore radiomic biomarkers for a better characterization of the radiogenomic phenotypes in breast cancer. Thirty-six female patients with breast cancer were enrolled in this study. Radiomic features were extracted from MRI and PET imaging techniques for malignant and healthy lesions in each patient. To reduce within-subject bias, the ratio of radiomic features extracted from both lesions was calculated for each patient. Radiomic features were further normalized, comparing the z-score, quantile, and whitening normalization methods to reduce between-subjects bias. After feature reduction by Spearman's correlation, a methodological approach based on a principal component analysis (PCA) was applied. The results were compared and validated on twenty-seven patients to investigate the tumor grade, Ki-67 index, and molecular cancer subtypes using classification methods (LogitBoost, random forest, and linear discriminant analysis). The classification techniques achieved high area-under-the-curve values with one PC that was calculated by normalizing the radiomic features via the quantile method. This pilot study helped us to establish a robust framework of analysis to generate a combined radiomic signature, which may lead to more precise breast cancer prognosis.
RI Basso, Luca/AAC-3477-2019; Cuocolo, Renato/G-3147-2018; Incoronato,
   Mariarosaria/K-8727-2016; Pace, Leonardo/S-6136-2016; Cavaliere,
   Carlo/K-6544-2016; Salvatore, Marco/K-8083-2016
OI Cuocolo, Renato/0000-0002-1452-1574; Incoronato,
   Mariarosaria/0000-0001-7019-0581; Basso, Luca/0000-0002-1774-0924; Pace,
   Leonardo/0000-0002-5741-543X; Cavaliere, Carlo/0000-0002-3297-2213;
   Salvatore, Marco/0000-0001-9734-7702; Garbino,
   Nunzia/0000-0001-6863-7313; Franzese, Monica/0000-0002-6490-7694
EI 2075-4418
PD FEB
PY 2022
VL 12
IS 2
AR 499
DI 10.3390/diagnostics12020499
UT WOS:000778193400001
PM 35204589
ER

PT J
AU Huang, SZ
   Tang, EH
   Li, S
   Ping, XZ
   Chen, RQ
AF Huang, Shizhen
   Tang, Enhao
   Li, Shun
   Ping, Xiangzhan
   Chen, Ruiqi
TI Hardware-friendly compression and hardware acceleration for transformer:
   A survey
SO ELECTRONIC RESEARCH ARCHIVE
AB The transformer model has recently been a milestone in artificial intelligence. The algorithm has enhanced the performance of tasks such as Machine Translation and Computer Vision to a level previously unattainable. However, the transformer model has a strong performance but also requires a high amount of memory overhead and enormous computing power. This significantly hinders the deployment of an energy-efficient transformer system. Due to the high parallelism, low latency, and low power consumption of field-programmable gate arrays (FPGAs) and application specific integrated circuits (ASICs), they demonstrate higher energy efficiency than Graphics Processing Units (GPUs) and Central Processing Units (CPUs). Therefore, FPGA and ASIC are widely used to accelerate deep learning algorithms. Several papers have addressed the issue of deploying the Transformer on dedicated hardware for acceleration, but there is a lack of comprehensive studies in this area. Therefore, we summarize the transformer model compression algorithm based on the hardware accelerator and its implementation to provide a comprehensive overview of this research domain. This paper first introduces the transformer model framework and computation process. Secondly, a discussion of hardware-friendly compression algorithms based on self-attention and Transformer is provided, along with a review of a state-of-the-art hardware accelerator framework. Finally, we considered some promising topics in transformer hardware acceleration, such as a high-level design framework and selecting the optimum device using reinforcement learning.
OI Chen, Ruiqi/0000-0001-6837-5675
EI 2688-1594
PY 2022
VL 30
IS 10
BP 3755
EP 3785
DI 10.3934/era.2022192
UT WOS:000843281800001
ER

PT C
AU Silfa, F
   Arnau, JM
   Gonzalez, A
AF Silfa, Franyell
   Maria Arnau, Jose
   Gonzalez, Antonio
GP IEEE
TI Boosting LSTM Performance Through Dynamic Precision Selection
SO 2020 IEEE 27TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING,
   DATA, AND ANALYTICS (HIPC 2020)
SE International Conference on High Performance Computing
CT 27th IEEE International Conference on High Performance Computing, Data,
   and Analytics (HiPC)
CY DEC 16-18, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, IEEE Comp Soc, Tech Comm Parallel Proc, KLA, NEC, ARM, Google
AB The use of low numerical precision is a fundamental optimization included in modern accelerators for Deep Neural Networks (DNNs). The number of bits of the numerical representation is set to the minimum precision that is able to retain accuracy based on an offline profiling, and it is kept constant for DNN inference.
   In this work, we explore the use of dynamic precision selection during DNN inference. We focus on Long Short Term Memory (LSTM) networks, which represent the state-of-the-art networks for applications such as machine translation and speech recognition. Unlike conventional DNNs, LSTM networks remember information from previous evaluations by storing data in the LSTM cell state. Our key observation is that the cell state determines the amount of precision required: time-steps where the cell state changes significantly require higher precision, whereas time-steps where the cell state is stable can be computed with lower precision without any loss in accuracy.
   We propose a novel hardware scheme that tracks the evolution of the elements in the LSTM cell state and dynamically selects the appropriate precision on each time-step. For a set of popular LSTM networks, it chooses the lowest precision for 57% of the time, outperforming systems that fix the precision statically. We evaluate our proposal on top of a modern highly-optimized LSTM accelerator, and show that it provides 1.46x speedup and 19.2% energy savings on average without degrading the model accuracy. Our scheme has an overhead of less than 8%.
SN 1094-7256
BN 978-1-6654-2292-5
PY 2020
BP 323
EP 333
DI 10.1109/HIPC50609.2020.00046
UT WOS:000672611900033
ER

PT J
AU Hentschel, M
   Delcroix, M
   Ogawa, A
   Iwata, T
   Nakatani, T
AF Hentschel, Michael
   Delcroix, Marc
   Ogawa, Atsunori
   Iwata, Tomoharu
   Nakatani, Tomohiro
TI Feature Based Domain Adaptation for Neural Network Language Models with
   Factorised Hidden Layers
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
AB Language models are a key technology in various tasks, such as, speech recognition and machine translation. They are usually used on texts covering various domains and as a result domain adaptation has been a long ongoing challenge in language model research. With the rising popularity of neural network based language models, many methods have been proposed in recent years. These methods can be separated into two categories: model based and feature based adaptation methods. Feature based domain adaptation has compared to model based domain adaptation the advantage that it does not require domain labels in the corpus. Most existing feature based adaptation methods are based on bias adaptation. We propose a novel feature based domain adaptation technique using hidden layer factorisation. This method is fundamentally different from existing methods because we use the domain features to calculate a linear combination of linear layers. These linear layers can capture domain specific information and information common to different domains. In the experiments, we compare our proposed method with existing adaptation methods. The compared adaptation techniques are based on two different ideas, that is, bias based adaptation and gating of hidden units. All language models in our comparison use state-of-the-art long short-term memory based recurrent neural networks. We demonstrate the effectiveness of the proposed method with perplexity results for the well-known Penn Treebank and speech recognition results for a corpus of TED talks.
RI Delcroix, Marc/ABF-1957-2020
OI Delcroix, Marc/0000-0002-5175-7834
SN 0916-8532
EI 1745-1361
PD MAR
PY 2019
VL E102D
IS 3
BP 598
EP 608
DI 10.1587/transinf.2018EDP7222
UT WOS:000460116300021
ER

PT J
AU Kuwayama, S
   Ayatsuka, Y
   Yanagisono, D
   Uta, T
   Usui, H
   Kato, A
   Takase, N
   Ogura, Y
   Yasukawa, T
AF Kuwayama, Soichiro
   Ayatsuka, Yuji
   Yanagisono, Daisuke
   Uta, Takaki
   Usui, Hideaki
   Kato, Aki
   Takase, Noriaki
   Ogura, Yuichiro
   Yasukawa, Tsutomu
TI Automated Detection of Macular Diseases by Optical Coherence Tomography
   and Artificial Intelligence Machine Learning of Optical Coherence
   Tomography Images
SO JOURNAL OF OPHTHALMOLOGY
AB Purpose. Although optical coherence tomography (OCT) is essential for ophthalmologists, reading of findings requires expertise. The purpose of this study is to test deep learning with image augmentation for automated detection of chorioretinal diseases. Methods. A retina specialist diagnosed 1,200 OCT images. The diagnoses involved normal eyes (n=570) and those with wet age-related macular degeneration (AMD) (n=136), diabetic retinopathy (DR) (n=104), epiretinal membranes (ERMs) (n=90), and another 19 diseases. Among them, 1,100 images were used for deep learning training, augmented to 59,400 by horizontal flipping, rotation, and translation. The remaining 100 images were used to evaluate the trained convolutional neural network (CNN) model. Results. Automated disease detection showed that the first candidate disease corresponded to the doctor's decision in 83 (83%) images and the second candidate disease in seven (7%) images. The precision and recall of the CNN model were 0.85 and 0.97 for normal eyes, 1.00 and 0.77 for wet AMD, 0.78 and 1.00 for DR, and 0.75 and 0.75 for ERMs, respectively. Some of rare diseases such as Vogt-Koyanagi-Harada disease were correctly detected by image augmentation in the CNN training. Conclusion. Automated detection of macular diseases from OCT images might be feasible using the CNN model. Image augmentation might be effective to compensate for a small image number for training.
OI Yasukawa, Tsutomu/0000-0001-9913-1905
SN 2090-004X
EI 2090-0058
PY 2019
VL 2019
AR 6319581
DI 10.1155/2019/6319581
UT WOS:000465305300001
PM 31093370
ER

PT J
AU Jacoby, DMP
   Papastamatiou, YP
   Freeman, R
AF Jacoby, David M. P.
   Papastamatiou, Yannis P.
   Freeman, Robin
TI Inferring animal social networks and leadership: applications for
   passive monitoring arrays
SO JOURNAL OF THE ROYAL SOCIETY INTERFACE
AB Analyses of animal social networks have frequently benefited from techniques derived from other disciplines. Recently, machine learning algorithms have been adopted to infer social associations from time-series data gathered using remote, telemetry systems situated at provisioning sites. We adapt and modify existing inference methods to reveal the underlying social structure of wide-ranging marine predators moving through spatial arrays of passive acoustic receivers. From six months of tracking data for grey reef sharks (Carcharhinus amblyrhynchos) at Palmyra atoll in the Pacific Ocean, we demonstrate that some individuals emerge as leaders within the population and that this behavioural coordination is predicted by both sex and the duration of co-occurrences between conspecifics. In doing so, we provide the first evidence of long-term, spatially extensive social processes in wild sharks. To achieve these results, we interrogate simulated and real tracking data with the explicit purpose of drawing attention to the key considerations in the use and interpretation of inference methods and their impact on resultant social structure. We provide a modified translation of the GMMEvents method for R, including new analyses quantifying the directionality and duration of social events with the aim of encouraging the careful use of these methods more widely in less tractable social animal systems but where passive telemetry is already widespread.
OI Jacoby, David/0000-0003-2729-3811
SN 1742-5689
EI 1742-5662
PD NOV 1
PY 2016
VL 13
IS 124
AR 20160676
DI 10.1098/rsif.2016.0676
UT WOS:000389816300013
PM 27881803
ER

PT J
AU De Silva, D
   Tu, YT
   Amunts, A
   Fontanesi, F
   Barrientos, A
AF De Silva, Dasmanthie
   Tu, Ya-Ting
   Amunts, Alexey
   Fontanesi, Flavia
   Barrientos, Antoni
TI Mitochondrial ribosome assembly in health and disease
SO CELL CYCLE
AB The ribosome is a structurally and functionally conserved macromolecular machine universally responsible for catalyzing protein synthesis. Within eukaryotic cells, mitochondria contain their own ribosomes (mitoribosomes), which synthesize a handful of proteins, all essential for the biogenesis of the oxidative phosphorylation system. High-resolution cryo-EM structures of the yeast, porcine and human mitoribosomal subunits and of the entire human mitoribosome have uncovered a wealth of new information to illustrate their evolutionary divergence from their bacterial ancestors and their adaptation to synthesis of highly hydrophobic membrane proteins. With such structural data becoming available, one of the most important remaining questions is that of the mitoribosome assembly pathway and factors involved. The regulation of mitoribosome biogenesis is paramount to mitochondrial respiration, and thus to cell viability, growth and differentiation. Moreover, mutations affecting the rRNA and protein components produce severe human mitochondrial disorders. Despite its biological and biomedical significance, knowledge on mitoribosome biogenesis and its deviations from the much-studied bacterial ribosome assembly processes is scarce, especially the order of rRNA processing and assembly events and the regulatory factors required to achieve fully functional particles. This article focuses on summarizing the current available information on mitoribosome assembly pathway, factors that form the mitoribosome assembly machinery, and the effect of defective mitoribosome assembly on human health.
RI Amunts, A./AAZ-2279-2020
OI Amunts, A./0000-0002-5302-1740; Fontanesi, Flavia/0000-0003-0509-3835
SN 1538-4101
EI 1551-4005
PD JUL 18
PY 2015
VL 14
IS 14
BP 2226
EP 2250
DI 10.1080/15384101.2015.1053672
UT WOS:000358126400015
PM 26030272
ER

PT C
AU Xu, G
   Lei, YQ
AF Xu, Gang
   Lei, Yuqing
GP IEEE
TI A New Image Recognition Algorithm Based on Skeleton
SO 2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks
CY JUN 01-08, 2008
CL Hong Kong, PEOPLES R CHINA
SP IEEE
AB Traditional recognition methods which mainly match object images with their skeleton couldn't resolve well complex objects' recognition problems. So in the paper, with an introduction and improvement of moment invariants, a new image recognition method is proposed with the combination of skeleton and moment invariants. Firstly, the paper analyses the thoughts of method. Then, the concept of object main skeleton and its extraction method is described, and with view to the characteristics of the skeleton, an extended Hu moment invariants algorithm is brought forward to calculate moment invariants of the skeleton. At the recognition stage, a two-layer generalized regression radial Basis (RBF) neural network is adopted to do machine self-learning and target- identifying. Compared with the present recognition methods based on similarity matching with skeleton, the algorithm doesn't need to face many problems such as the difficulties in matching and realizing based on skeleton graph, the complexity of the Shock Graphs, the object selectivity of the Reeb Graphs and the order of the nodes which can't be guaranteed in SA-tree and so on. Compared with traditional moment recognition methods, the method not only can make calculation results meet scale, translation and rotation invariance, but also can reduce the number of related efficient pixels during moment calculation. In the meanwhile, it overcomes the difficulties that traditional moment recognition methods encountered when they deal with the fuzzy object boundary, and thus is effective. Finally, some experiments prove that the algorithm has better results for general object recognition.
RI Xu, Gang/HNI-9325-2023
SN 2161-4393
BN 978-1-4244-1820-6
PY 2008
BP 777
EP 782
DI 10.1109/IJCNN.2008.4633884
UT WOS:000263827200127
ER

PT J
AU Jeppesen, JO
   Vignon, SA
   Stoddart, JF
AF Jeppesen, JO
   Vignon, SA
   Stoddart, JF
TI In the Twilight Zone between [2]pseudorotaxanes and [2]rotaxanes
SO CHEMISTRY-A EUROPEAN JOURNAL
AB A [2]pseudorotaxane, based on a semi-dumbbell-shaped component containing asymmetrically substituted monopyrrolotetrathiafulvalene and 1,5-dioxynaphthalene recognition sites for encirclement by cyclobis(paraquat-p-phenylene) and with a "speed bump" in the form of a thiomethyl group situated between the two recognition sites, has been self-assembled. This supramolecular entity is a mixture in solution of two slowly interconverting [2]pseudorotaxanes, one of which is on the verge of being a [2]rotaxane at room temperature, allowing it to be isolated by employing flash column chromatography. These two [2]pseudorotaxanes were both characterized in solution by UV/Vis and H-1 NMR spectroscopies (113 and 213) and also by differential pulse voltammetry. The spectroscopic and electrochemical data reveal that one of the complexes behaves wholly as a [2]pseudorotaxane, while the other has some [2]rotaxane character to it. The kinetics of the shuttling of cyclobis(paraquat-p-phenylene) between the monopyrrolotetrathiafulvalene and the 1,5-dioxynaphthalene recognition sites have been investigated at different temperatures. The shuttling processes, which are accompanied by detectable color changes, can be monitored using UV/Vis and H-1 NMR spectroscopies; the spectroscopic data have been employed in the determination of the rate constants, free energies of activation, enthalpies of activation, and the entropies of activation for the translation of cyclobis(paraquat-p-phenylene) between the two recognition sites.
RI Stoddart, James Fraser/H-1518-2011
OI Stoddart, James Fraser/0000-0003-3161-3697
SN 0947-6539
EI 1521-3765
PD OCT 6
PY 2003
VL 9
IS 19
BP 4611
EP 4625
DI 10.1002/chem.200304798
UT WOS:000185933100005
PM 14566866
ER

PT J
AU Yang, BS
   Wang, LY
   Wong, DF
   Shi, SM
   Tu, ZP
AF Yang, Baosong
   Wang, Longyue
   Wong, Derek F.
   Shi, Shuming
   Tu, Zhaopeng
TI Context-aware Self-Attention Networks for Natural Language Processing
SO NEUROCOMPUTING
AB Recently, Self-Attention Networks (SANs) have shown its flexibility in parallel computation and effectiveness of modeling both short-and long-term dependencies. However, SANs face two problems: 1) the weighted averaging inhibits relations among neighboring words (i.e., local context); and 2) it calculates dependencies between representations without considering contextual information (i.e., global context). Both local and global contexts have proven useful for modeling dependencies among neural representations in a variety of natural language processing tasks. Accordingly, we augment SANs with the ability of capturing usefully local and global context, and meanwhile maintain their simplicity and flexibility. Firstly, we cast local context modeling as a learnable Gaussian bias, which indicates the central and scope of the local region to be paid more attention. The bias is then incorporated into the original attention distribution to form a revised version. Secondly, we leverage the internal representations that embed sentence-level information as the global context. Specifically, we propose to contextualize the transformations of query and key layers, which are used to calculate the relevance between elements. Since the two approaches are potentially complementary to each other, we propose to combine them to further improve the performance. Empirical results on machine translation and linguistics probing tasks demonstrate the effectiveness and universality of the proposed approaches. Further analyses confirm that our approaches successfully capture contextual information as expected. (c) 2021 Elsevier B.V. All rights reserved.
RI Wong, Derek F/CAI-7740-2022
SN 0925-2312
EI 1872-8286
PD OCT 11
PY 2021
VL 458
BP 157
EP 169
DI 10.1016/j.neucom.2021.06.009
EA JUN 2021
UT WOS:000691559800013
ER

PT J
AU Kashirina, DN
   Kononikhin, AS
   Ratushnyy, AY
   Nikolaev, EN
   Larina, IM
   Buravkova, LB
AF Kashirina, Daria N.
   Kononikhin, Alexey S.
   Ratushnyy, Andrey Yu
   Nikolaev, Evgeny N.
   Larina, Irina M.
   Buravkova, Ludmila B.
TI Proteomic profile of cultured human endothelial cells after exposition
   to simulated microgravity
SO ACTA ASTRONAUTICA
AB The proteome of human umbilical vein endothelial cells (HUVEC) cultured under static conditions and simulated microgravity (s mu G) using Random Positioning Machine (RPM) for 24 h was studied by chromatography-mass spectrometry. It was revealed that the percentage of ribosomal proteins and proteins involved in intercellular adhesion, regulation of actin cytoskeleton, various pathways of cell signaling mediated by G-proteins, apoptosis and ubiquitin-dependent protein catabolism increased under s mu G. At the same time the number of proteins associated with cell growth reduced. A significant increase in the peak intensities of proteins associated with maintaining the cytoskeleton and stress fibers (myristoylated alanine-rich C-kinase substrate, filamin-A, alpha-actinin-1 and myosin light polypeptide 6) and proteins involved in response to unfolded protein (serpin H1, 78 kDa glucose-regulated protein, transitional endoplasmic reticulum ATPase) was shown. At the same time, a significant decrease in the peak intensity of cofilin 1, which is capable of breaking actin filaments, was revealed. Thus, the most pronounced effect of microgravity is on the proteins associated with the actin cytoskeleton, as well as on adhesion proteins, whose properties also depend on the structure of the cytoskeleton. At the same time, the number of proteins which prevent improper protein folding increases, and the translation apparatus is rearranged under s mu G.
RI Kashirina, Daria N/T-7332-2017; Buravkova, Ludmila/B-2211-2017;
   Ratushnyy, Andrey/R-2740-2017
OI Kashirina, Daria N/0000-0002-9646-7275; Ratushnyy,
   Andrey/0000-0002-3913-6584
SN 0094-5765
EI 1879-2030
PD FEB
PY 2021
VL 179
BP 11
EP 19
DI 10.1016/j.actaastro.2020.10.014
UT WOS:000604254600002
ER

PT J
AU Besler, E
   Wang, YC
   Sahakian, AV
AF Besler, Emre
   Wang, Yearnchee Curtis
   Sahakian, Alan V.
TI Real-Time Radiofrequency Ablation Lesion Depth Estimation Using
   Multi-frequency Impedance With a Deep Neural Network and Tree-Based
   Ensembles
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
AB Objective: Design and optimization of statistical models for use in methods for estimating radiofrequency ablation (RFA) lesion depths in soft real-time performance. Methods: Using tissue multi-frequency complex electrical impedance data collected froma low-cost embedded system, a deep neural network (NN) and tree-based ensembles (TEs) were trained for estimating the RFA lesion depth via regression. Results: Addition of frequency sweep data, previous depth data, and previous RF power state data boosted accuracy of the statistical models. The root mean square errors were 2 mm for NN and 0.5 mm for TEs for previous statistical models and the root mean square errors were 0.4 mm for NN and 0.04 mm for TEs for the statistical models presented in this paper. Simulation ablation performance showed a mean difference against physical measurements of 0.5 +/- 0.2 mm for the NN-based depth estimation method and 0.7 +/- 0.4 mm for the TE-based depth estimation method. Conclusion: The results show that multi-frequency data significantly improves the depth estimation performance of the statistical models. Significance: The RFA lesion depth estimation methods presented in this work achieve millimeter-resolution accuracy with soft realtime performance on an ARMv7-based embedded system for potential translation to clinical RFA technologies.
RI Sahakian, Alan V/B-7268-2009
OI Besler, Emre/0000-0001-9274-2500; Sahakian, Alan/0000-0003-3090-0328
SN 0018-9294
EI 1558-2531
PD JUL
PY 2020
VL 67
IS 7
BP 1890
EP 1899
DI 10.1109/TBME.2019.2950342
UT WOS:000544063000008
PM 31675310
ER

PT J
AU Manciu, M
   Cardenas, M
   Bennet, KE
   Maran, A
   Yaszemski, MJ
   Maldonado, TA
   Magiricu, D
   Manciu, FS
AF Manciu, Marian
   Cardenas, Mario
   Bennet, Kevin E.
   Maran, Avudaiappan
   Yaszemski, Michael J.
   Maldonado, Theresa A.
   Magiricu, Diana
   Manciu, Felicia S.
TI Assessment of Renal Osteodystrophy via Computational Analysis of
   Label-free Raman Detection of Multiple Biomarkers
SO DIAGNOSTICS
AB Accurate clinical evaluation of renal osteodystrophy (ROD) is currently accomplished using invasive in vivo transiliac bone biopsy, followed by in vitro histomorphometry. In this study, we demonstrate that an alternative method for ROD assessment is through a fast, label-free Raman recording of multiple biomarkers combined with computational analysis for predicting the minimally required number of spectra for sample classification at defined accuracies. Four clinically relevant biomarkers: the mineral-to-matrix ratio, the carbonate-to-matrix ratio, phenylalanine, and calcium contents were experimentally determined and simultaneously considered as input to a linear discriminant analysis (LDA). Additionally, sample evaluation was performed with a linear support vector machine (LSVM) algorithm, with a 300 variable input. The computed probabilities based on a single spectrum were only marginally different (similar to 80% from LDA and similar to 87% from LSVM), both providing an unacceptable classification power for a correct sample assignment. However, the Type I and Type II assignment errors confirm that a relatively small number of independent spectra (7 spectra for Type I and 5 spectra for Type II) is necessary for a p < 0.05 error probability. This low number of spectra supports the practicality of future in vivo Raman translation for a fast and accurate ROD detection in clinical settings.
RI Manciu, Marian/C-7247-2017
OI Manciu, Marian/0000-0003-4821-4131
EI 2075-4418
PD FEB
PY 2020
VL 10
IS 2
AR 79
DI 10.3390/diagnostics10020079
UT WOS:000519541300021
PM 32023980
ER

PT C
AU Vogiatzi, M
   Keratidis, C
   Schinas, M
   Diplaris, S
   Yumlu, S
   Forbes, P
   Papadopoulos, S
   Syropoulou, P
   Apostolidis, L
   Kompatsiaris, I
   Symeonidou, M
AF Vogiatzi, Maria
   Keratidis, Christodoulos
   Schinas, Manos
   Diplaris, Sotiris
   Yumlu, Serdar
   Forbes, Paula
   Papadopoulos, Symeon
   Syropoulou, Panagiota
   Apostolidis, Lazaros
   Kompatsiaris, Ioannis
   Symeonidou, Machi
BE Kompatsiaris, I
   Cave, J
   Satsiou, A
   Carle, G
   Passani, A
   Kontopoulos, E
   Diplaris, S
   McMillan, D
TI The STEP Project: Societal and Political Engagement of Young People in
   Environmental Issues
SO INTERNET SCIENCE
SE Lecture Notes in Computer Science
CT 4th International Conference on Internet Science (INSCI)
CY NOV 22-24, 2017
CL Thessaloniki, GREECE
AB Decisions on environmental topics taken today are going to have long-term consequences that will affect future generations. Young people will have to live with the consequences of these decisions and undertake special responsibilities. Moreover, as tomorrow's decision makers, they themselves should learn how to negotiate and debate issues before final decisions are made. Therefore, any participation they can have in environmental decision making processes will prove essential in developing a sustainable future for the community.
   However, recent data indicate that the young distance themselves from community affairs, mainly because the procedures involved are 'wooden', politicians' discourse alienates the young and the whole experience is too formalized to them. Authorities are aware of this fact and try to establish communication channels to ensure transparency and use a language that speaks to new generations of citizens. This is where STEP project comes in.
   STEP (www.step4youth.eu) is a digital Platform (web/mobile) enabling youth Societal and Political e-Participation in decision-making procedures concerning environmental issues. STEP is enhanced with web/social media mining, gamification, machine translation, and visualisation features.
   Six pilots in real contexts are being organised for the deployment of the STEP solution in 4 European Countries: Italy, Spain, Greece, and Turkey. Pilots are implemented with the direct participation of one regional authority, four municipalities, and one association of municipalities, and include decision-making procedures on significant environmental questions.
RI Papadopoulos, Symeon/AET-0683-2022; Kompatsiaris, Ioannis/P-8594-2015
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Diplaris,
   Sotiris/0000-0002-9969-6436; Papadopoulos, Symeon/0000-0002-5441-7341;
   Forbes, Paula/0000-0003-1737-9929
SN 0302-9743
EI 1611-3349
BN 978-3-319-70284-1; 978-3-319-70283-4
PY 2017
VL 10673
BP 148
EP 156
DI 10.1007/978-3-319-70284-1_12
UT WOS:000440850000012
ER

PT J
AU Lin, H
   Deng, EZ
   Ding, H
   Chen, W
   Chou, KC
AF Lin, Hao
   Deng, En-Ze
   Ding, Hui
   Chen, Wei
   Chou, Kuo-Chen
TI iPro54-PseKNC: a sequence-based predictor for identifying sigma-54
   promoters in prokaryote with pseudo k-tuple nucleotide composition
SO NUCLEIC ACIDS RESEARCH
AB The sigma 54 promoters are unique in prokaryotic genome and responsible for transcripting carbon and nitrogen-related genes. With the avalanche of genome sequences generated in the postgenomic age, it is highly desired to develop automated methods for rapidly and effectively identifying the sigma 54 promoters. Here, a predictor called 'iPro54-PseKNC' was developed. In the predictor, the samples of DNA sequences were formulated by a novel feature vector called 'pseudo k-tuple nucleotide composition', which was further optimized by the incremental feature selection procedure. The performance of iPro54-PseKNC was examined by the rigorous jackknife cross-validation tests on a stringent benchmark data set. As a user-friendly web-server, iPro54-PseKNC is freely accessible at http://lin.uestc.edu.cn/server/iPro54-PseKNC. For the convenience of the vast majority of experimental scientists, a step-by-step protocol guide was provided on how to use the web-server to get the desired results without the need to follow the complicated mathematics that were presented in this paper just for its integrity. Meanwhile, we also discovered through an in-depth statistical analysis that the distribution of distances between the transcription start sites and the translation initiation sites were governed by the gamma distribution, which may provide a fundamental physical principle for studying the sigma 54 promoters.
RI Chou, Kuo-Chen/A-8340-2009; Lin, Hao/B-2066-2012; Chen, Wei/W-8311-2019;
   Ding, Hui/A-8160-2016; Chen, Wei/O-6774-2017
OI Lin, Hao/0000-0001-6265-2862; Chen, Wei/0000-0002-6857-7696
SN 0305-1048
EI 1362-4962
PD DEC 1
PY 2014
VL 42
IS 21
BP 12961
EP 12972
DI 10.1093/nar/gku1019
UT WOS:000347914600008
PM 25361964
ER

PT J
AU Solorzano, C
   Tsai, DM
AF Solorzano, Carlos
   Tsai, Du-Ming
TI Environment-Adaptable Printed-Circuit Board Positioning Using Deep
   Reinforcement Learning
SO IEEE TRANSACTIONS ON COMPONENTS PACKAGING AND MANUFACTURING TECHNOLOGY
AB Vision-based object positioning is very important in the electronic industry for assembly and inspection tasks. Many methods have been proposed to tackle the problem, either by traditional machine vision or by deep learning (DL) techniques. The traditional methods rely on template matching or feature point correspondence. They are computationally intensive and are easily affected by illumination changes and noise. DL models such as convolutional neural networks (CNNs) are computationally very efficient but are also sensitive against environmental changes. In this article, a deep reinforcement learning (DRL) model based on the Actor-Critic style Proximal Policy Optimization algorithm(s) (AC-PPO) is proposed. The proposed method is applied for the positioning of printed circuit boards (PCBs). The model uses as the current environment the sensed image and the reference template as a guide. It requires only a single manually marked template in the reference image. All possible training images are automatically and randomly generated during the neural network training without human intervention. The proposed reinforcement learning (RL) model is shown to be adaptive to environmental changes, including illumination, noise, de-focusing, and template occlusion, compared with the CNN regressor. Experimental results indicate that the proposed model on average can achieve estimation errors less than 1 pixel in translation and 1 degrees in orientation, with fast evaluation for the real-time PCB positioning task.
OI Solorzano, Carlos/0000-0002-7507-8190
SN 2156-3950
EI 2156-3985
PD FEB
PY 2022
VL 12
IS 2
BP 382
EP 390
DI 10.1109/TCPMT.2022.3142033
UT WOS:000761210100024
ER

PT J
AU Lee, I
   Kim, D
   Lee, S
AF Lee, Inwoong
   Kim, Doyoung
   Lee, Sanghoon
TI 3-D Human Behavior Understanding Using Generalized TS-LSTM Networks
SO IEEE TRANSACTIONS ON MULTIMEDIA
AB This paper addresses the problems of skeleton feature representation and the modeling of temporal dynamics to recognize human actions consisting of poses. In contrast to traditional methods which generally used relative coordinate systems dependent on some joints, or modeled only the long-term dependency, we attempt to understand 3D human behavior with observation by taking temporally different windows. Instead of taking raw skeletons as the input, we transform the skeletons into another coordinate system to obtain the robustness to scale, rotation and translation, and extract motion features between adjacent skeletons, which finally constructs an efficient hybrid-stream combining both pose and motion streams. We propose novel generalized Temporal Sliding Long Short-term Memory (TS-LSTM) networks. The proposed networks are composed of multiple TS-LSTM networks with various hyper-parameters, which can capture various temporal dynamics of actions. We also propose a novel hyper-parameter searching method, which finds decent hyper-parameters of generalized TS-LSTM to handle temporal dynamics of actions. In the experiment, we evaluate the proposed networks to verify the effectiveness of the proposed methods, and compare them with the other methods on three challenging datasets. Additionally, we analyze a relation between the recognized actions and the hyper-parameters, and visualize the layers of the proposed models.
RI Cataldi, Antonio/AAM-7411-2021
OI Kim, Doyoung/0000-0002-8156-9738; Lee, Sanghoon/0000-0001-9895-5347;
   Lee, Inwoong/0000-0003-4356-7616
SN 1520-9210
EI 1941-0077
PY 2021
VL 23
BP 415
EP 428
DI 10.1109/TMM.2020.2978637
UT WOS:000601877600033
ER

PT J
AU Singh, S
   Mahmood, A
AF Singh, Sushant
   Mahmood, Ausif
TI The NLP Cookbook: Modern Recipes for Transformer Based Deep Learning
   Architectures
SO IEEE ACCESS
AB In recent years, Natural Language Processing (NLP) models have achieved phenomenal success in linguistic and semantic tasks like text classification, machine translation, cognitive dialogue systems, information retrieval via Natural Language Understanding (NLU), and Natural Language Generation (NLG). This feat is primarily attributed due to the seminal Transformer architecture, leading to designs such as BERT, GPT (I, II, III), etc. Although these large-size models have achieved unprecedented performances, they come at high computational costs. Consequently, some of the recent NLP architectures have utilized concepts of transfer learning, pruning, quantization, and knowledge distillation to achieve moderate model sizes while keeping nearly similar performances as achieved by their predecessors. Additionally, to mitigate the data size challenge raised by language models from a knowledge extraction perspective, Knowledge Retrievers have been built to extricate explicit data documents from a large corpus of databases with greater efficiency and accuracy. Recent research has also focused on superior inference by providing efficient attention to longer input sequences. In this paper, we summarize and examine the current state-of-the-art (SOTA) NLP models that have been employed for numerous NLP tasks for optimal performance and efficiency. We provide a detailed understanding and functioning of the different architectures, a taxonomy of NLP designs, comparative evaluations, and future directions in NLP.
OI Mahmood, Ausif/0000-0002-8991-4268; Singh, Sushant/0000-0002-9159-5198
SN 2169-3536
PY 2021
VL 9
BP 68675
EP 68702
DI 10.1109/ACCESS.2021.3077350
UT WOS:000650448200001
ER

PT J
AU Liu, HTD
   Kim, VG
   Chaudhuri, S
   Aigerman, N
   Jacobson, A
AF Liu, Hsueh-Ti Derek
   Kim, Vladimir G.
   Chaudhuri, Siddhartha
   Aigerman, Noam
   Jacobson, Alec
TI Neural Subdivision
SO ACM TRANSACTIONS ON GRAPHICS
AB This paper introduces Neural Subdivision, a novel framework for data-driven coarse-to-fine geometry modeling. During inference, our method takes a coarse triangle mesh as input and recursively subdivides it to a finer geometry by applying the fixed topological updates of Loop Subdivision, but predicting vertex positions using a neural network conditioned on the local geometry of a patch. This approach enables us to learn complex non-linear subdivision schemes, beyond simple linear averaging used in classical techniques. One of our key contributions is a novel self-supervised training setup that only requires a set of high-resolution meshes for learning network weights. For any training shape, we stochastically generate diverse low-resolution discretizations of coarse counterparts, while maintaining a bijective mapping that prescribes the exact target position of every new vertex during the subdivision process. This leads to a very efficient and accurate loss function for conditional mesh generation, and enables us to train a method that generalizes across discretizations and favors preserving the manifold structure of the output. During training we optimize for the same set of network weights across all local mesh patches, thus providing an architecture that is not constrained to a specific input mesh, fixed genus, or category. Our network encodes patch geometry in a local frame in a rotationand translation-invariant manner. Jointly, these design choices enable our method to generalize well, and we demonstrate that even when trained on a single high-resolution mesh our method generates reasonable subdivisions for novel shapes.
SN 0730-0301
EI 1557-7368
PD JUL
PY 2020
VL 39
IS 4
AR 124
DI 10.1145/3386569.3392418
UT WOS:000583700300097
ER

PT J
AU McLennan, HJ
   Saini, A
   Dunning, KR
   Thompson, JG
AF McLennan, H. J.
   Saini, A.
   Dunning, K. R.
   Thompson, J. G.
TI Oocyte and embryo evaluation by AI and multi-spectral auto-fluorescence
   imaging: Livestock embryology needs to catch-up to clinical practice
SO THERIOGENOLOGY
AB A highly accurate 'non-invasive quantitative embryo assessment for pregnancy' (NQEAP) technique that determines embryo quality has been an elusive goal. If developed, NQEAP would transform the selection of embryos from both Multiple Ovulation and Embryo Transfer (MOET), and even more so, in vitro produced (IVP) embryos for livestock breeding. The area where this concept is already having impact is in the field of clinical embryology, where great strides have been taken in the application of morphokinetics and artificial intelligence (AI); while both are already in practice, rigorous and robust evidence of efficacy is still required. Even the translation of advances in the qualitative scoring of human IVF embryos have yet to be translated to the livestock IVP industry, which remains dependent on the MOET-standardised 3-point scoring system. Furthermore, there are new ways to interrogate the biochemistry of individual embryonic cells by using new, light-based methodologies, such as FLIM and hyperspectral microscopy. Combinations of these technologies, in particular combining new imaging systems with AI, will lead to very accurate NQEAP predictive tools, improving embryo selection and recipient pregnancy success. Crown Copyright (C) 2020 Published by Elsevier Inc. All rights reserved.
RI Dunning, Kylie/GLU-0471-2022
OI Dunning, Kylie/0000-0002-0462-6479; McLennan, Hanna/0000-0002-2058-2488
SN 0093-691X
EI 1879-3231
PD JUL 1
PY 2020
VL 150
BP 255
EP 262
DI 10.1016/j.theriogenology.2020.01.061
UT WOS:000533539400036
PM 32088032
ER

PT J
AU Li, R
   Cao, WM
   Wu, S
   Wong, HS
AF Li, Rui
   Cao, Wenming
   Wu, Si
   Wong, Hau-San
TI Generating Target Image-Label Pairs for Unsupervised Domain Adaptation
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
AB Deep learning demonstrates its impressive success across various machine learning problems. However, its performance often suffers in the case where the training and test data sets follow different distributions, due to the domain shift. Most current domain adaptation methods minimize the discrepancy between the source and target domains by enforcing the alignment of their marginal distributions without considering the class-level matching. Consequently, data from different classes may become close together after mapping. To address this issue, we propose an unsupervised domain adaptation method by generating image-label pairs in the target domain, in which the model is augmented with the generated target pairs and achieve class-level transfer. Specifically, we integrate generative adversarial networks (GAN) into the model predictor, where the generator fed with labels aims to produce corresponding target domain images with a well-designed semantic loss. Meanwhile, compared to previous methods which focus on discrepancy reduction across domains, i.e., image to image translation, our model focuses on semantic preservation during image generation. Our model is straightforward yet effective for unsupervised domain adaptation problems. Without any labels in the target domain in all the experiments, we demonstrate the validity of our approach by presenting the plausible generated target image-label pairs. In addition, our proposed method achieves the best or comparable performance on multiple unsupervised domain adaptation datasets which include image classification and semantic segmentation.
OI LI, Rui/0000-0002-8224-7888; WONG, Hau-San/0000-0002-1530-7529
SN 1057-7149
EI 1941-0042
PY 2020
VL 29
BP 7997
EP 8011
DI 10.1109/TIP.2020.3009853
UT WOS:000554885000001
ER

PT C
AU Zhang, XY
   Jiang, WW
   Hu, JT
AF Zhang, Xinyi
   Jiang, Weiwen
   Hu, Jingtong
GP IEEE Comp Soc
TI Achieving Full Parallelism in LSTM via a Unified Accelerator Design
SO 2020 IEEE 38TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD 2020)
SE Proceedings IEEE International Conference on Computer Design
CT 38th IEEE International Conference on Computer Design (ICCD)
CY OCT 18-21, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, IEEE Circuit & Syst Soc
AB Recently, Long Short-Term Memory (LSTM), a type of recurrent neural network, has been widely employed in real-time applications, such as speech recognition, word segmentation, machine translation, etc. While existing works demonstrate that LSTM can be efficiently deployed in cloud platforms, the high communication latency between cloud and edge will drastically reduce its efficiency. Therefore, efficient LSTM accelerators at the edge are highly demanded. The limited resource in edge devices and the heterogeneous operations in LSTM (e.g., LSTM gates) bring challenges for the LSTM accelerator design. It seems straightforward to implement each operation as a specific hardware kernel. However, the data dependency among gates leads to significant running stalls in the existing heterogeneous-kernel accelerator, resulting in low parallelism and low resource utilization. To overcome the above challenges, this work proposes a novel generic LSTM accelerator design for Field-programmable Gate Array (FPGA) and Application-specific Integrated Circuit (ASIC) platforms, where two fundamental computing patterns (i.e., element-wise multiplication and addition) are incorporated in a unified computing kernel to execute operations in all LSTM gates simultaneously. Thus, the running stalls caused by heterogeneous kernels can be eliminated, achieving full parallelism in LSTM. The proposed technique and architecture are validated on Xilinx PYNQ-Z1 FPGA which can fully utilize the available resource, achieving 10x faster in inference time and 15.2x improvement in computing power efficiency compared with the state-of-the-art LSTM accelerator.
RI Zhang, Xinyi/ADO-0487-2022
OI Zhang, Xinyi/0000-0002-9307-1654
SN 1063-6404
BN 978-1-7281-9710-4
PY 2020
BP 469
EP 477
DI 10.1109/ICCD50377.2020.00086
UT WOS:000652198500074
ER

PT J
AU Prud'hommeaux, E
   Roark, B
AF Prud'hommeaux, Emily
   Roark, Brian
TI Graph-Based Word Alignment for Clinical Language Evaluation
SO COMPUTATIONAL LINGUISTICS
AB Among the more recent applications for natural language processing algorithms has been the analysis of spoken language data for diagnostic and remedial purposes, fueled by the demand for simple, objective, and unobtrusive screening tools for neurological disorders such as dementia. The automated analysis of narrative retellings in particular shows potential as a component of such a screening tool since the ability to produce accurate and meaningful narratives is noticeably impaired in individuals with dementia and its frequent precursor, mild cognitive impairment, as well as other neurodegenerative and neurodevelopmental disorders. In this article, we present a method for extracting narrative recall scores automatically and highly accurately from a word-level alignment between a retelling and the source narrative. We propose improvements to existing machine translation-based systems for word alignment, including a novel method of word alignment relying on random walks on a graph that achieves alignment accuracy superior to that of standard expectation maximization-based techniques for word alignment in a fraction of the time required for expectation maximization. In addition, the narrative recall score features extracted from these high-quality word alignments yield diagnostic classification accuracy comparable to that achieved using manually assigned scores and significantly higher than that achieved with summary-level text similarity metrics used in other areas of NLP. These methods can be trivially adapted to spontaneous language samples elicited with non-linguistic stimuli, thereby demonstrating the flexibility and generalizability of these methods.
SN 0891-2017
EI 1530-9312
PD DEC
PY 2015
VL 41
IS 4
BP 549
EP 578
DI 10.1162/COLI_a_00232
UT WOS:000367813400001
PM 34334943
ER

PT J
AU Fine, D
   Grattoni, A
   Goodall, R
   Bansal, SS
   Chiappini, C
   Hosali, S
   van de Ven, AL
   Srinivasan, S
   Liu, XW
   Godin, B
   Brousseau, L
   Yazdi, IK
   Fernandez-Moure, J
   Tasciotti, E
   Wu, HJ
   Hu, Y
   Klemm, S
   Ferrari, M
AF Fine, Daniel
   Grattoni, Alessandro
   Goodall, Randy
   Bansal, Shyam S.
   Chiappini, Ciro
   Hosali, Sharath
   van de Ven, Anne L.
   Srinivasan, Srimeenkashi
   Liu, Xuewu
   Godin, Biana
   Brousseau, Louis, III
   Yazdi, Iman K.
   Fernandez-Moure, Joseph
   Tasciotti, Ennio
   Wu, Hung-Jen
   Hu, Ye
   Klemm, Steve
   Ferrari, Mauro
TI Silicon Micro- and Nanofabrication for Medicine
SO ADVANCED HEALTHCARE MATERIALS
AB This manuscript constitutes a review of several innovative biomedical technologies fabricated using the precision and accuracy of silicon micro- and nanofabrication. The technologies to be reviewed are subcutaneous nanochannel drug delivery implants for the continuous tunable zero-order release of therapeutics, multi-stage logic embedded vectors for the targeted systemic distribution of both therapeutic and imaging contrast agents, silicon and porous silicon nanowires for investigating cellular interactions and processes as well as for molecular and drug delivery applications, porous silicon (pSi) as inclusions into biocomposites for tissue engineering, especially as it applies to bone repair and regrowth, and porous silica chips for proteomic profiling. In the case of the biocomposites, the specifically designed pSi inclusions not only add to the structural robustness, but can also promote tissue and bone regrowth, fight infection, and reduce pain by releasing stimulating factors and other therapeutic agents stored within their porous network. The common material thread throughout all of these constructs, silicon and its associated dielectrics (silicon dioxide, silicon nitride, etc.), can be precisely and accurately machined using the same scalable micro- and nanofabrication protocols that are ubiquitous within the semiconductor industry. These techniques lend themselves to the high throughput production of exquisitely defined and monodispersed nanoscale features that should eliminate architectural randomness as a source of experimental variation thereby potentially leading to more rapid clinical translation.
RI Yazdi, Iman/G-9595-2014; Chiappini, Ciro/I-6256-2019; Chiappini,
   Ciro/A-6382-2013; Yazdi, Iman K/F-4297-2014; Yazdi, Iman/AAP-5957-2020;
   Godin, Biana/AAB-3190-2020; Tasciotti, Ennio/CAF-7476-2022; Tasciotti,
   Ennio/J-8309-2015; Wu, Hung-Jen/H-3769-2016
OI Yazdi, Iman/0000-0002-0020-6960; Chiappini, Ciro/0000-0002-9893-4359;
   Chiappini, Ciro/0000-0002-9893-4359; Yazdi, Iman K/0000-0002-0020-6960;
   Yazdi, Iman/0000-0002-0020-6960; Tasciotti, Ennio/0000-0003-1187-3205;
   van de Ven, Anne/0000-0002-0347-4004; Fernandez-Moure,
   Joseph/0000-0003-1397-6320; Godin, Biana/0000-0001-6089-6695; Wu,
   Hung-Jen/0000-0003-3082-7431
SN 2192-2640
EI 2192-2659
PD MAY
PY 2013
VL 2
IS 5
BP 632
EP 666
DI 10.1002/adhm.201200214
UT WOS:000318312200003
PM 23584841
ER

PT J
AU Miki, T
   Kamikawa, Y
   Kurono, S
   Kaneko, Y
   Katahira, J
   Yoneda, Y
AF Miki, Takashi
   Kamikawa, Yasunao
   Kurono, Sadamu
   Kaneko, Yuka
   Katahira, Jun
   Yoneda, Yoshihiro
TI Cell type-dependent gene regulation by Staufen2 in conjunction with Upf1
SO BMC MOLECULAR BIOLOGY
AB Background: Staufen2 (Stau2), a double-stranded RNA-binding protein, is a component of neuronal RNA granules, which are dendritic mRNA transport machines. Although Stau2 is thought to be involved in the dendritic targeting of several mRNAs in neurons, the mechanism whereby Stau2 regulates these mRNAs is unknown. To elucidate the functions of Stau2, we screened for novel binding partners by affinity purification of GST-tagged Stau2 from 293F cells.
   Results: Three RNA helicases, RNA helicase A, Upf1 and Mov10, were identified in Stau2-containing complexes. We focused our studies on Upf1, a key player in nonsense-mediated mRNA decay. Stau2 was found to bind directly to Upf1 in an RNA-independent manner in vitro. Tethering Stau2 to the 3'-untranslated region (UTR) of a reporter gene had little effect on its expression in HeLa cells. In contrast, when the same tethering assay was performed in 293F cells, we observed an increase in reporter protein levels. This upregulation of protein expression by Stau2 turned out to be dependent on Upf1. Moreover, we found that in 293F cells, Stau2 upregulates the reporter mRNA level in an Upf1-independent manner.
   Conclusions: These results indicate that the recruitment of Stau2 alone or in combination with Upf1 differentially affects the fate of mRNAs. Moreover, the results suggest that Stau2-mediated fate determination could be executed in a cell type-specific manner.
RI Miki, Takashi/AGV-9237-2022; Miki, Takashi/S-7569-2018
OI Miki, Takashi/0000-0003-3715-7039; Miki, Takashi/0000-0003-3715-7039;
   Katahira, Jun/0000-0001-5188-0368
SN 1471-2199
PD NOV 16
PY 2011
VL 12
AR 48
DI 10.1186/1471-2199-12-48
UT WOS:000297479000001
PM 22087843
ER

PT J
AU You, Y
   He, YX
   Rajbhandari, S
   Wang, WH
   Hsieh, CJ
   Keutzer, K
   Demmel, J
AF You, Yang
   He, Yuxiong
   Rajbhandari, Samyam
   Wang, Wenhan
   Hsieh, Cho-Jui
   Keutzer, Kurt
   Demmel, James
TI Fast LSTM by dynamic decomposition on cloud and distributed systems
SO KNOWLEDGE AND INFORMATION SYSTEMS
AB Long short-term memory (LSTM) is a powerful deep learning technique that has been widely used in many real-world data-mining applications such as language modeling and machine translation. In this paper, we aim to minimize the latency of LSTM inference on cloud systems without losing accuracy. If an LSTM model does not fit in cache, the latency due to data movement will likely be greater than that due to computation. In this case, we reduce model parameters. If, as in most applications we consider, the LSTM models are able to fit the cache of cloud server processors, we focus on reducing the number of floating point operations, which has a corresponding linear impact on the latency of the inference calculation. Thus, in our system, we dynamically reduce model parameters or flops depending on which most impacts latency. Our inference system is based on singular value decomposition and canonical polyadic decomposition. Our system is accurate and low latency. We evaluate our system based on models from a series of real-world applications like language modeling, computer vision, question answering, and sentiment analysis. Users of our system can use either pre-trained models or start from scratch. Our system achieves 15x average speedup for six real-world applications without losing accuracy in inference. We also design and implement a distributed optimization system with dynamic decomposition, which can significantly reduce the energy cost and accelerate the training process.
SN 0219-1377
EI 0219-3116
PD NOV
PY 2020
VL 62
IS 11
BP 4169
EP 4197
DI 10.1007/s10115-020-01487-8
EA JUL 2020
UT WOS:000550108500001
ER

PT J
AU Petersen, T
   Kluner, T
AF Petersen, Thorben
   Kluener, Thorsten
TI Photodesorption of H2O from Anatase-TiO2(101): A Combined Quantum
   Chemical and Quantum Dynamical Study
SO JOURNAL OF PHYSICAL CHEMISTRY C
AB A theoretical study to clarify the photodesorption process of water on anatase-TiO2(101) was pursued in this study using a combined approach based on quantum chemical calculations and quantum dynamical simulations assisted by machine learning of artificial neural networks. First, an embedded cluster model was used to assess three-dimensional potential energy surfaces of ground and excited state of molecular water adsorption. The excited state addressed herein consists of a photogenerated hole which oxidizes the adsorbed water molecule. Next, the approximately 23 000 data points for each surface were fitted using artificial neural networks to generate a dense grid of the data. These fits are a prerequisite for our subsequent quantum dynamical simulations based on the propagation of wavepackets. Eventually, the photodesorption process of water on anatase-TiO2(101) was found to consist of a multidimensional mechanism involving a lateral translation of the water molecule toward the bridging oxygen row. Upon relaxation to the ground state, the maximum possible photodesorption probability of 85% was calculated through analyzing specific resonance lifetimes of the charge-transfer state. By comparison with experimental velocity distributions, long resonance lifetimes of over 60 fs can be ascribed to the studied system. Moreover, temperature effects by studying the population of vibronically excited states were included, which turned out to play a minor role in the photodesorption process.
OI Petersen, Thorben/0000-0003-2052-0567
SN 1932-7447
EI 1932-7455
PD MAY 28
PY 2020
VL 124
IS 21
BP 11444
EP 11455
DI 10.1021/acs.jpcc.0c01926
UT WOS:000614615900006
ER

PT C
AU Hakimov, S
   Jebbara, S
   Cimiano, P
AF Hakimov, Sherzod
   Jebbara, Soufian
   Cimiano, Philipp
BE DAmato, C
   Fernandez, M
   Tamma, V
   Lecue, F
   CudreMauroux, P
   Sequeda, J
   Lange, C
   Heflin, J
TI AMUSE: Multilingual Semantic Parsing for Question Answering over Linked
   Data
SO SEMANTIC WEB - ISWC 2017, PT I
SE Lecture Notes in Computer Science
CT 16th International Semantic Web Conference (ISWC)
CY OCT 21-25, 2017
CL Vienna, AUSTRIA
SP IBM, Elsevier, Semant Web Co, Metaphacts, Big Data Europe, Oracle, Siemens, Data World, Thomson Reuters, Onto Text, Onto Force, Videolectures Net, Inria, Google, Kapsch, Vienna Univ Econ & Business, TU Wien, SBA Res
AB The task of answering natural language questions over RDF data has received wide interest in recent years, in particular in the context of the series of QALD benchmarks. The task consists of mapping a natural language question to an executable form, e.g. SPARQL, so that answers from a given KB can be extracted. So far, most systems proposed are (i) monolingual and (ii) rely on a set of hard-coded rules to interpret questions and map them into a SPARQL query. We present the first multilingual QALD pipeline that induces a model from training data for mapping a natural language question into logical form as probabilistic inference. In particular, our approach learns to map universal syntactic dependency representations to a language-independent logical form based on DUDES (Dependency-based Underspecified Discourse Representation Structures) that are then mapped to a SPARQL query as a deterministic second step. Our model builds on factor graphs that rely on features extracted from the dependency graph and corresponding semantic representations. We rely on approximate inference techniques, Markov Chain Monte Carlo methods in particular, as well as Sample Rank to update parameters using a ranking objective. Our focus lies on developing methods that overcome the lexical gap and present a novel combination of machine translation and word embedding approaches for this purpose. As a proof of concept for our approach, we evaluate our approach on the QALD-6 datasets for English, German & Spanish.
OI Cimiano, Philipp/0000-0002-4771-441X
SN 0302-9743
EI 1611-3349
BN 978-3-319-68288-4; 978-3-319-68287-7
PY 2017
VL 10587
BP 329
EP 346
DI 10.1007/978-3-319-68288-4_20
UT WOS:000521384100020
ER

PT J
AU Dang, MP
   Le, HG
   Chau, NL
   Dao, TP
AF Dang, Minh Phung
   Le, Hieu Giang
   Chau, Ngoc Le
   Dao, Thanh-Phong
TI An Optimized Design of New XY theta Mobile Positioning Microrobotic
   Platform for Polishing Robot Application Using Artificial Neural Network
   and Teaching-Learning Based Optimization
SO COMPLEXITY
AB Compliant mechanisms with flexure hinges have been widely applied for positioners, bioengineering, and aerospace. In this study, a new optimized design method for the mobile microrobotic platform was developed for the polishing robot system. A metaheuristic-based machine learning technique in combination with finite element analysis (FEA) was developed. The designed platform allows three degrees of freedom with two x-and-y translations and one z-axis rotation. A new hybrid displacement amplification mechanism was also developed using Scott-Russell and two-lever mechanisms to magnify the workspace of the platform. The leaf hinges were employed due to their large rotation, and the right circular hinges were adopted because of their high accuracy. In modeling the behaviors of the developed platform, the artificial neural network is formulated in combination with the teaching-learning-based optimization (TLBO) method. The ANN architecture was optimized through TLBO to a better approximation. And then, three optimized case studies were conducted by the TLBO. The data is collected through FEA simulation. The modeling results from the TLBO-based ANN were well established with excellent metrics of R, R-2, and MSE. The optimized results found that the proposed MPM platform achieves a max-y stroke of 1568.1 mu m, max-x stroke of 735.55 mu m, and max-theta rotation angle of 2.26 degrees. The proposed MPM platform can operate at a high displacement amplification ratio of over 9.
SN 1076-2787
EI 1099-0526
PD NOV 7
PY 2022
VL 2022
AR 2132005
DI 10.1155/2022/2132005
UT WOS:000888564900001
ER

PT J
AU Man, CY
   Palmer, DA
   Qian, JX
AF Man, Chun-Yin
   Palmer, David A.
   Qian, Junxi
TI The Belt and Road Initiative on Twitter: An annotated dataset
SO DATA IN BRIEF
AB Initiated by the Chinese president Xi Jinping in 2013, the Belt and Road initiative (BRI) is a multi-trillion-dollar agenda for facilitating trade and investment, especially massive infrastructural developments. In recent years, discussions around the BRI have been increasing as more than 130 countries and 30 international organizations have officially joined the initiative [1], collaborating in a series of transnational infrastructure projects funded by Chinese companies or the Chinese state. This dataset provides 500,711 posts and 714,794 reposting threads related to the BRI on Twitter. The dataset was collected through the Twitter API by applying a set of keywords: "belt and road", "one belt one road", "new silk road", "maritime silk road", and "silk road economic belt", which included the words and their hashtag forms to download the raw data from Twitter. The time series of the dataset is from 7 September 2013 to 30 November 2021. Furthermore, the dataset is annotated in terms of languages, emotional polarity, geopolitical entities, and credibility by employing textual analytics in language detection, neural machine translation, and lexicon-based sentiment analysis. To facilitate future research, we classified the dataset into three databases that can be analyzed separately and reused in research related to various fields, such as political science, network science, and sociology to study public opinions about the BRI and their dissemination patterns. (C) 2022 The Author(s). Published by Elsevier Inc.
SN 2352-3409
PD DEC
PY 2022
VL 45
AR 108711
DI 10.1016/j.dib.2022.108711
EA NOV 2022
UT WOS:000883587700022
PM 36426018
ER

PT C
AU Metzner, S
   Hausotte, T
AF Metzner, Sebastian
   Hausotte, Tino
BE Harding, KG
   Zhang, S
TI Extension of the registration possibilities and determination of the
   positioning precision of a multi-scale fringe projection system
SO DIMENSIONAL OPTICAL METROLOGY AND INSPECTION FOR PRACTICAL APPLICATIONS
   IX
SE Proceedings of SPIE
CT Conference on Dimensional Optical Metrology and Inspection for Practical
   Applications IX
CY APR 27-MAY 08, 2020
CL ELECTR NETWORK
SP SPIE
AB For providing holistic and complete dataset of sheet bulk metal-formed parts, an optical detection with a fringe projection system is useful. By combining several sensors with varying measuring ranges, the workpiece is captured with adapted spatial resolution depending on the forming zone and geometric requirements. The sensors are registered by a two-dimensional point calibration and registration process. The registration process has already been shown in.(1) In this article, the calibration procedure is transferred to the measurement setup with three fringe projection sensors with different measurement resolution. A calibration plate with dot patterns is applied to the positioning unit, which is a high precision hexapod in this set-up. This extended calibration plate allows a continuous control of the registration quality as the sensors are able to capture the calibration plate at any time. For determining the positioning accuracy of the hexapod, a procedure following the DIN EN ISO 10360-3 procedure with three spheres mounted on the hexapod was investigated. Therefore the hexapod was fixed at a coordinate measuring machine Zeiss UPMC 1200 and moved in all 6 degrees of freedom. After each movement, the spheres were measured with a probe, which allows the absolute position precision to be calculated. Comparison of the measurements with the specified translation and rotation movement of the hexapod show a positioning precision of less than 10 mu m in the positioning directions x and y.
RI Hausotte, Tino/AAJ-8478-2021
OI Hausotte, Tino/0000-0002-2923-3217
SN 0277-786X
EI 1996-756X
BN 978-1-5106-3572-2; 978-1-5106-3571-5
PY 2020
VL 11397
AR 1139703
DI 10.1117/12.2558029
UT WOS:000589916000002
ER

PT J
AU Baek, S
   Park, DS
   Cho, J
   Lee, YB
AF Baek, S
   Park, DS
   Cho, J
   Lee, YB
TI A robot endeffector tracking system based on feedforward neural networks
SO ROBOTICS AND AUTONOMOUS SYSTEMS
AB In this paper, we describe a robot endeffector tracking system based on two neural networks. The designed networks are to recognize the current position and to estimate the next position of the endeffector. This tracking system can be very useful in controlling a robot at a remote site.
   A multilayer feedforward neural network is employed to recognize the endeffector covering the situation of translation, rotating and scaling types of motion. The features used to recognize the endeffector are 2D edge information from preprocessed images. The output of the neural network recognizer represents the probability of the endeffector for a specific position. The trained neural network recognizer can search for a maximum value to find the position with the highest likelihood within a limited search space. To predict the next position of the endeffector, information from the last prediction and the current position are used. Instead of analyzing data sets and modeling a prediction system, a neural network can learn the typical dynamics of the robot by way of training with patterns obtained from a series of experiments, The neural network predictor uses a smearing function to represent a real value precisely.
   Combining the two neural networks, for recognizing the robot endeffector and for estimating the motion, with the preprocessing stage, the whole system keeps tracking of the robot endeffector effectively with a high precision. (C) 1999 Elsevier Science B.V. All rights reserved.
SN 0921-8890
PD JUL 31
PY 1999
VL 28
IS 1
BP 43
EP 52
DI 10.1016/S0921-8890(99)00028-7
UT WOS:000081979900005
ER

PT J
AU Antonov, A
   Fomin, A
   Glazunov, V
   Kiselev, S
   Carbone, G
AF Antonov, Anton
   Fomin, Alexey
   Glazunov, Victor
   Kiselev, Sergey
   Carbone, Giuseppe
TI Inverse and forward kinematics and workspace analysis of a novel 5-DOF
   (3T2R) parallel-serial (hybrid) manipulator
SO INTERNATIONAL JOURNAL OF ADVANCED ROBOTIC SYSTEMS
AB The proposed study provides a solution of the inverse and forward kinematic problems and workspace analysis for a five-degree-of-freedom parallel-serial manipulator, in which the parallel kinematic chain is made in the form of a tripod and the serial kinematic chain is made in the form of two carriages displaced in perpendicular directions. The proposed manipulator allows to realize five independent movements-three translations and two rotations motion pattern (3T2R). Analytical relationships between the coordinates of the end-effector and five controlled movements provided by manipulator's drives (generalized coordinates) were determined. The approach of reachable workspace calculation was defined with respect to available design constraints of the manipulator based on the obtained algorithms of the inverse and forward kinematics. Case studies are considered based on the obtained algorithms of inverse and forward kinematics. For the inverse kinematic problem, the solution is obtained in accordance with the given laws of position and orientation change of the end-effector, corresponding to the motion along a spiral-helical trajectory. For the forward kinematic problem, various assemblies of the manipulator are obtained at the same given values of the generalized coordinates. An example of reachable workspace designing finalizes the proposed study. Dimensions and extreme values of the end-effector orientation angles are calculated.
RI Antonov, Anton/V-6528-2019; Fomin, Alexey/H-8336-2016; Carbone,
   Giuseppe/J-5846-2012
OI Antonov, Anton/0000-0002-3928-5440; Fomin, Alexey/0000-0003-4071-8407;
   Carbone, Giuseppe/0000-0003-0831-8358
SN 1729-8814
PD MAR
PY 2021
VL 18
IS 2
AR 1729881421992963
DI 10.1177/1729881421992963
UT WOS:000634793200001
ER

PT C
AU Stacewicz, P
   Greif, H
AF Stacewicz, Pawel
   Greif, Hajo
BE Watrobski, J
   Salabun, W
   Toro, C
   Zanni-Merk, C
   Howlett, RJ
   Jain, LC
TI Concepts as decision functions. The issue of epistemic opacity of
   conceptual representations in artificial computing systems
SO KNOWLEDGE-BASED AND INTELLIGENT INFORMATION & ENGINEERING SYSTEMS (KSE
   2021)
SE Procedia Computer Science
CT 25th KES International Conference on Knowledge-Based and Intelligent
   Information & Engineering Systems (KES)
CY SEP 08-10, 2021
CL Szczecin, POLAND
SP KES Int
AB The treatment of concepts as decision functions characteristic for computer science and Artificial Intelligence has its roots in the logical tradition of Gottlob Frege. In its modern incarnation, decision functions, embedded in concrete knowledge representations, describe either crisp or vague assignments of categorization decisions to objects. In order to allow for effective communication between humans and computer systems, these decisions should be either effectively explained by the system or explainable with respect to the system, which in turn depends on the degree of epistemic transparency of the computer system and the conceptual representations it uses. In this, paper we distinguish between two basic types of representation: logic-based and nature-based. With respect to the latter, we identify five contributing factors to their relative epistemic opacity: A. structural complexity, B. learning procedures, C. operating on uncertain data, D. lack of translation procedures for low-level rules and representations, and E. lack of complete knowledge about natural computing systems. We consider the fourth factor (D.) to be the most important source of opacity on the level of computer systems and the fifth (E.) the main contributing factor on the level of human knowledge. (C) 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://crativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the scientific committee of KES International.
SN 1877-0509
PY 2021
VL 192
BP 4120
EP 4127
DI 10.1016/j.procs.2021.09.187
UT WOS:000720289004019
ER

PT J
AU Ruan, YP
   Ling, ZH
   Zhu, XD
   Liu, Q
   Gu, JC
AF Ruan, Yu-Ping
   Ling, Zhen-Hua
   Zhu, Xiaodan
   Liu, Quan
   Gu, Jia-Chen
TI Generating diverse conversation responses by creating and ranking
   multiple candidates
SO COMPUTER SPEECH AND LANGUAGE
AB This paper introduces our systems built for Track 2 of Dialog System Technology Challenge 7 (DSTC7). This challenge track aimed to evaluate the response generation methods using fully data-driven conversation models in a knowledge-grounded setting, where textual facts were provided as the knowledge for each context-response pair. The sequence-to-sequence models have achieved impressive results in machine translation and have also been widely used for end-to-end generative conversation modelling. However, they tended to output dull and repeated responses in previous studies. Our work aims to promote the diversity of end-to-end conversation response generation by adopting a two-stage pipeline. 1) Create multiple responses for an input context together with its textual facts. At this stage, two different models are designed, i.e., a variational generative (VariGen) model and a retrieval-based (Retrieval) model. 2) Rank and return the most relevant response by training a topic coherence discrimination (TCD) model for calculating ranking scores. In our experiments, we demonstrated the effectiveness of the response ranking strategy and the external textual knowledge for generating better responses. According to the official evaluation results, our Retrieval and VariGen systems ranked first and second respectively among all participant systems on Entropy metrics which measured the objective diversity of generated responses. Besides, the VariGen system ranked second on NIST and METEOR metrics which measured the objective quality of generated responses. (C) 2020 Elsevier Ltd. All rights reserved.
RI Furtado, Kássia/AAU-5007-2020; Liu, Quan/AAR-3894-2021
OI Ruan, Yu-Ping/0000-0002-9800-3271
SN 0885-2308
EI 1095-8363
PD JUL
PY 2020
VL 62
AR 101071
DI 10.1016/j.csl.2020.101071
UT WOS:000516784300004
ER

PT J
AU Wu, L
   Li, T
   Wang, L
   Yan, YH
AF Wu, Long
   Li, Ta
   Wang, Li
   Yan, Yonghong
TI Improving Hybrid CTC/Attention Architecture with Time-Restricted
   Self-Attention CTC for End-to-End Speech Recognition
SO APPLIED SCIENCES-BASEL
AB As demonstrated in hybrid connectionist temporal classification (CTC)/Attention architecture, joint training with a CTC objective is very effective to solve the misalignment problem existing in the attention-based end-to-end automatic speech recognition (ASR) framework. However, the CTC output relies only on the current input, which leads to the hard alignment issue. To address this problem, this paper proposes the time-restricted attention CTC/Attention architecture, which integrates an attention mechanism with the CTC branch. "Time-restricted" means that the attention mechanism is conducted on a limited window of frames to the left and right. In this study, we first explore time-restricted location-aware attention CTC/Attention, establishing the proper time-restricted attention window size. Inspired by the success of self-attention in machine translation, we further introduce the time-restricted self-attention CTC/Attention that can better model the long-range dependencies among the frames. Experiments with wall street journal (WSJ), augmented multiparty interaction (AMI), and switchboard (SWBD) tasks demonstrate the effectiveness of the proposed time-restricted self-attention CTC/Attention. Finally, to explore the robustness of this method to noise and reverberation, we join a train neural beamformer frontend with the time-restricted attention CTC/Attention ASR backend in the CHIME-4 dataset. The reduction of word error rate (WER) and the increase of perceptual evaluation of speech quality (PESQ) approve the effectiveness of this framework.
EI 2076-3417
PD NOV
PY 2019
VL 9
IS 21
AR 4639
DI 10.3390/app9214639
UT WOS:000498058600164
ER

PT C
AU Awad, A
   Nagaty, K
AF Awad, Ahmed
   Nagaty, Khaled
GP Assoc Comp Machinery
TI Commit Message Generation from Code Differences using Hidden Markov
   Models
SO PROCEEDINGS OF 2019 8TH INTERNATIONAL CONFERENCE ON SOFTWARE AND
   INFORMATION ENGINEERING (ICSIE 2019)
CT 8th International Conference on Software and Information Engineering
   (ICSIE)
CY APR 09-12, 2019
CL British Univ Egypt, Cairo, EGYPT
HO British Univ Egypt
AB Commit messages are developer-written messages that document code changes. Such change might be adding features, fixing bugs or simply code updates. Although these messages help in understanding the evolution of any software, it is quite often that developers disregard the process of writing these messages, when making a change. Many automated methods have been proposed to generate commit messages. Due to the inability of those techniques to represent higher order understanding of code changes, the quality of these messages in terms of logic and context representation is very low as opposed to developer written messages. To solve this problem, previous work used deep learning models-specifically, sequence-to-sequence models- were used to automate that task. This model delivered promising results on translating code differences to commit messages. However, after the model's performance was thoroughly investigated in previous work. It was found out that code differences corresponding to almost every high quality commit messages generated by the model were very similar to one or more training sample code differences on a token level. Motivated by that observation, a k-nearest neighbor algorithm that outputs the same exact message of the nearest code difference was proposed in previous work. Inspired by the traditional solution to sequence modeling; Hidden Markov Models, we show that HMMs outperforms sequence-to-sequence models without outputting the same exact message of the nearest code diff, our experiments show an enhancement of 4% against sequence to sequence models.
BN 978-1-4503-6105-7
PY 2019
BP 96
EP 99
DI 10.1145/3328833.3328873
UT WOS:000507625200019
ER

PT C
AU Guzman, NT
   Orjuela-Canon, AD
   Alarcon, ALJ
AF Triana Guzman, Nayid
   David Orjuela-Canon, Alvaro
   Jutinico Alarcon, Andres Leonardo
BE Nystrom, I
   Heredia, YH
   Nunez, VM
TI Incremental Training of Neural Network for Motor Tasks Recognition Based
   on Brain-Computer Interface
SO PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS, COMPUTER VISION, AND
   APPLICATIONS (CIARP 2019)
SE Lecture Notes in Computer Science
CT 24th Iberoamerican Congress on Pattern Recognition (CIARP)
CY OCT 28-31, 2019
CL Havana, CUBA
SP Int Assoc Pattern Recognit, Univ Ciencias Informaticas, Cuban Assoc Pattern Recognit
AB Brain-computer interfaces (BCI) based on motor imagery tasks (MI) have been established as a promising solution for restoring communication and control of people with motor disabilities. Physically impaired people may perform different motor imagery tasks which could be recorded in a non-invasive way using electroencephalography (EEG). However, the success of the MI-BCI systems depends on the reliable processing of the EEG signals and the adequate selection of the features used to characterize the brain activity signals for effective classification of MI activity and translation into corresponding actions. The multilayer perceptron (MLP) has been the neural network most widely used for classification in BCI technologies. The fact that MLP is a universal approximator makes this classifier sensitive to overtraining, especially with such noisy, non-linear, and non-stationary data as EEG. Traditional training techniques, as well as more recent ones, have mainly focused on the machine-learning aspects of BCI training. As a novel alternative for BCI training, this work proposes an incremental training process. Preliminary results with a non-disabled individual demonstrate that the proposed method has been able to improve the BCI training performance in comparison with the cross-validation technique. Best results showed that the incremental training proposal allowed an increase of the performance by at least 10% in terms of classification compared to a conventional cross-validation technique, which indicates the potential application for classification models of BCI's systems.
RI ; JUTINICO ALARCON, ANDRES LEONARDO/M-2022-2018
OI Orjuela-Canon, Alvaro David/0000-0002-2057-7603; JUTINICO ALARCON,
   ANDRES LEONARDO/0000-0001-9146-9637; Triana Guzman,
   Nayid/0000-0002-3367-5544
SN 0302-9743
EI 1611-3349
BN 978-3-030-33904-3; 978-3-030-33903-6
PY 2019
VL 11896
BP 610
EP 619
DI 10.1007/978-3-030-33904-3_57
UT WOS:000582428400056
ER

PT J
AU Ma, ST
   Zhang, YY
   Zhang, CZ
AF Ma, Shutian
   Zhang, Yingyi
   Zhang, Chengzhi
TI Using multiple Web resources and inference rules to classify Chinese
   word semantic relation
SO INFORMATION DISCOVERY AND DELIVERY
AB Purpose The purpose of this paper is to classify Chinese word semantic relations, which are synonyms, antonyms, hyponyms and meronymys.
   Design/methodology/approach Basically, four simple methods are applied, ontology-based, dictionary-based, pattern-based and morpho-syntactic method. The authors make good use of search engine to build lexical and semantic resources for dictionary-based and pattern-based methods. To improve classification performance with more external resources, they also classify the given word pairs in Chinese and in English at the same time by using machine translation.
   Findings Experimental results show that the approach achieved an average F1 score of 50.87 per cent, an average accuracy of 70.36 per cent and an average recall of 40.05 per cent over all classification tasks. Synonym and antonym classification achieved high accuracy, i.e. above 90 per cent. Moreover, dictionary-based and pattern-based approaches work effectively on final data set.
   Originality/value For many natural language processing (NLP) tasks, the step of distinguishing word semantic relation can help to improve system performance, such as information extraction and knowledge graph generation. Currently, common methods for this task rely on large corpora for training or dictionaries and thesauri for inference, where limitation lies in freely data access and keeping built lexical resources up-date. This paper builds a primary system for classifying Chinese word semantic relations by seeking new ways to obtain the external resources efficiently.
RI Zhang, Chengzhi/AAK-9998-2020; Ma, Shutian/ABF-8426-2020
OI Zhang, Chengzhi/0000-0001-9522-2914; Ma, Shutian/0000-0002-8339-6412
SN 2398-6247
PY 2018
VL 46
IS 2
BP 120
EP 126
DI 10.1108/IDD-03-2018-0010
UT WOS:000440861900005
ER

PT C
AU Bandyopadhyay, S
   Sarkar, S
   Banerjee, K
AF Bandyopadhyay, Soumyadip
   Sarkar, Santonu
   Banerjee, Kunal
BE Cardoso, J
   Maciaszek, L
   VanSinderen, M
   Cabello, E
TI An End-to-end Formal Verifier for Parallel Programs
SO ICSOFT: PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON SOFTWARE
   TECHNOLOGIES
CT 12th International Joint Conference on Software Technologies (ICSOFT)
CY JUL 24-26, 2017
CL Madrid, SPAIN
AB Among the various models of computation (MoCs) which have been used to model parallel programs, Petri net has been one of the mostly adopted MoC. The traditional Petri net model is extended into the PRES+ model which is specially equipped to precisely represent parallel programs running on heterogeneous and embedded systems. With the inclusion of mtdticore and multiprocessor systems in the domain of embedded systems, it has become important to validate the optimizing and parallelizing transformations which system specifications go through before deployment. Although PRES+ model based equivalence checkers for validating such transformations already exist, construction of the PRES models from the original and the translated programs was carried out manually in these equivalence checkers. thereby leaving scope for inaccurate representation of the programs due to human intervention. Furthermore, PRES+ model tends to grow more rapidly with the program size when compared to other MoCs, such as FSMD. To alleviate these drawbacks, we propose a method for automated construction of PRES+ models from high-level language programs and use an existing translation scheme to convert PRES+ models to FSMD models to validate the transformations using a stale-of-the-art FSMD equivalence checker. Thus, we have composed an end-to-end fully automated equivalence checker for validating optimizing and parallelizing transformations as demonstrated by our experimental results.
OI Bandyopadhyay, Soumyadip/0000-0001-5865-9754
BN 978-989-758-262-2
PY 2017
BP 388
EP 393
DI 10.5220/0006464503880393
UT WOS:000684957900039
ER

PT J
AU Ekpenyong, ME
   Urua, EAE
   Akpan, AD
   Adeoye, OS
   Suleiman, AA
AF Ekpenyong, Moses Effiong
   Urua, Eno-Abasi Essien
   Akpan, Aniefon Daniel
   Adeoye, Olufemi Sunday
   Suleiman, Aminu Alhaji
TI A TEMPLATE-BASED APPROACH TO INTELLIGENT MULTILINGUAL CORPORA
   TRANSCRIPTION
SO INTERNATIONAL JOURNAL OF HUMANITIES AND ARTS COMPUTING-A JOURNAL OF
   DIGITAL HUMANITIES
AB Emerging linguistic problems are data-driven and multidisciplinary, requiring richly transcribed corpora. Accurate corpus transcription therefore demands intelligent protocols that satisfy the following important criteria: 1) acceptability by end-users, computers/machines; 2) conformity to existing language standards, rules and structures; and 3) representation within the context of the intended language domain. To demonstrate the feasibility of these criteria, a template-based framework for multilingual transcription was proposed and implemented. The first version of the developed transcription tool, also called SCAnnAL (Speech Corpus Annotator for African Languages), applies signal processing to pre-segment waveforms of a recorded speech corpus, into word, syllable and phoneme units, resulting in a pre-segmented TextGrid file with empty labels. Using preformatted templates, the front-end or linguistic aspects/datasets (the text corpus, vowels inventory, consonants inventory, and a set of syllabification rules) are specified in a default language. A Natural Language Understanding (NLU) algorithm then uses these datasets with a data-driven syllabification algorithm to relabel subtrees of the TextGrid file. Tone pattern models were finally constructed from translations of experimental data, using the Ibadan 400 words (a list of basic items of a language), for four Nigerian tone languages. Integration of the tone pattern models into the transcription system is expected in a future paper. This research will benefit emerging digital humanists and computational linguists working on language data, as well as open new opportunities for improved African tone language speech processing systems.
OI Ekpenyong, Moses/0000-0001-6774-5259
SN 1753-8548
EI 1755-1706
PD OCT
PY 2022
VL 16
IS 2
SI SI
BP 182
EP 213
DI 10.3366/ijhac.2022.0290
UT WOS:000878413800007
ER

PT J
AU Li, B
   Fan, YL
   Sataer, Y
   Gao, ZQ
   Gui, YC
AF Li, Bin
   Fan, Yunlong
   Sataer, Yikemaiti
   Gao, Zhiqiang
   Gui, Yaocheng
TI Improving Semantic Dependency Parsing with Higher-Order Information
   Encoded by Graph Neural Networks
SO APPLIED SCIENCES-BASEL
AB Featured Application Semantic dependency parsing could be applied in many downstream tasks of natural language processing, including named entity recognition, information extraction, machine translation, sentiment analysis, question generation, question answering, etc. Higher-order information brings significant accuracy gains in semantic dependency parsing. However, modeling higher-order information is non-trivial. Graph neural networks (GNNs) have been demonstrated to be an effective tool for encoding higher-order information in many graph learning tasks. Inspired by the success of GNNs, we investigate improving semantic dependency parsing with higher-order information encoded by multi-layer GNNs. Experiments are conducted on the SemEval 2015 Task 18 dataset in three languages (Chinese, English, and Czech). Compared to the previous state-of-the-art parser, our parser yields 0.3% and 2.2% improvement in average labeled F1-score on English in-domain (ID) and out-of-domain (OOD) test sets, 2.6% improvement on Chinese ID test set, and 2.0% and 1.8% improvement on Czech ID and OOD test sets. Experimental results show that our parser outperforms the previous best one on the SemEval 2015 Task 18 dataset in three languages. The outstanding performance of our parser demonstrates that the higher-order information encoded by GNNs is exceedingly beneficial for improving SDP. Dataset:https://doi.org/10.18653/v1/s15-2153.
OI Li, Bin/0000-0002-1038-7494
EI 2076-3417
PD APR
PY 2022
VL 12
IS 8
AR 4089
DI 10.3390/app12084089
UT WOS:000786276300001
ER

PT J
AU Lin, JF
   Liu, YL
   Cleland-Huang, J
AF Lin, Jinfeng
   Liu, Yalin
   Cleland-Huang, Jane
TI Information retrieval versus deep learning approaches for generating
   traceability links in bilingual projects
SO EMPIRICAL SOFTWARE ENGINEERING
AB Software traceability links are established between diverse artifacts of the software development process in order to support tasks such as compliance analysis, safety assurance, and requirements validation. However, practice has shown that it is difficult and costly to create and maintain trace links in non-trivially sized projects. For this reason, many researchers have proposed and evaluated automated approaches based on information retrieval and deep-learning. Generating trace links automatically can also be challenging - especially in multi-national projects which include artifacts written in multiple languages. The intermingled language use can reduce the efficiency of automated tracing solutions. In this work, we analyze patterns of intermingled language that we observed in several different projects, and then comparatively evaluate different tracing algorithms. These include Information Retrieval techniques, such as the Vector Space Model (VSM), Latent Semantic Indexing (LSI), Latent Dirichlet Allocation (LDA), and various models that combine mono- and cross-lingual word embeddings with the Generative Vector Space Model (GVSM), and a deep-learning approach based on a BERT language model. Our experimental analysis of trace links generated for 14 Chinese-English projects indicates that our MultiLingual Trace-BERT approach performed best in large projects with close to 2-times the accuracy of the best IR approach, while the IR-based GVSM with neural machine translation and a monolingual word embedding performed best on small projects.
SN 1382-3256
EI 1573-7616
PD JAN
PY 2022
VL 27
IS 1
AR 5
DI 10.1007/s10664-021-10050-0
UT WOS:000710136400002
ER

PT J
AU Cserdi, Z
   Kenesei, Z
AF Cserdi, Zsofia
   Kenesei, Zsofia
TI Attitudes to forced adoption of new technologies in public
   transportation services
SO RESEARCH IN TRANSPORTATION BUSINESS AND MANAGEMENT
AB With the advancement of technology and the need for the continuous development of service quality, the introduction of new systems in local or nationwide public transportation is a practice that passengers must accept from time to time. When these new systems are introduced along with the elimination of the old system, passengers may feel frustrated and unsatisfied. This study develops and tests a conceptual model that places the forced use of technology-based self-service at its center. Although the effects of mandatory usage of one option of a delivery mode have already been investigated, the antecedents of the acceptance of forced use are yet to be fully researched. This study provides a solid framework for the underlying factors behind the acceptance of forcing users to channel migration in public transportation. Through a real-life case of a public transportation company forcing its passengers to use exclusively self-service ticket vending machines while closing face-to-face ticket counters, we conducted a survey on the acceptance of the new mode of ticket purchase. Our results predominantly demonstrated that the perceived performance, ease of use of the new kiosks, and the need for interaction by consumers have a positive impact on the acceptance of forced use, while this acceptance plays a significant positive role in the formulation of satisfaction with the company.
SN 2210-5395
EI 2210-5409
PD DEC
PY 2021
VL 41
AR 100611
DI 10.1016/j.rtbm.2020.100611
EA DEC 2021
UT WOS:000731750700002
ER

PT J
AU Gerovac, M
   Vogel, J
   Smirnov, A
AF Gerovac, Milan
   Vogel, Jorg
   Smirnov, Alexandre
TI The World of Stable Ribonucleoproteins and Its Mapping With Grad-Seq and
   Related Approaches
SO FRONTIERS IN MOLECULAR BIOSCIENCES
AB Macromolecular complexes of proteins and RNAs are essential building blocks of cells. These stable supramolecular particles can be viewed as minimal biochemical units whose structural organization, i.e., the way the RNA and the protein interact with each other, is directly linked to their biological function. Whether those are dynamic regulatory ribonucleoproteins (RNPs) or integrated molecular machines involved in gene expression, the comprehensive knowledge of these units is critical to our understanding of key molecular mechanisms and cell physiology phenomena. Such is the goal of diverse complexomic approaches and in particular of the recently developed gradient profiling by sequencing (Grad-seq). By separating cellular protein and RNA complexes on a density gradient and quantifying their distributions genome-wide by mass spectrometry and deep sequencing, Grad-seq charts global landscapes of native macromolecular assemblies. In this review, we propose a function-based ontology of stable RNPs and discuss how Grad-seq and related approaches transformed our perspective of bacterial and eukaryotic ribonucleoproteins by guiding the discovery of new RNA-binding proteins and unusual classes of noncoding RNAs. We highlight some methodological aspects and developments that permit to further boost the power of this technique and to look for exciting new biology in understudied and challenging biological models.
RI Vogel, Jörg/D-5574-2011; Gerovac, Milan/AAY-4427-2021; Smirnov,
   Alexandre/H-4253-2019
OI Vogel, Jörg/0000-0003-2220-1404; Gerovac, Milan/0000-0002-6929-7178;
   Smirnov, Alexandre/0000-0002-9142-7979
EI 2296-889X
PD APR 7
PY 2021
VL 8
AR 661448
DI 10.3389/fmolb.2021.661448
UT WOS:000641575000001
PM 33898526
ER

PT C
AU Nguyen, PM
   Than, K
   Nguyen, ML
AF Phuong Minh Nguyen
   Khoat Than
   Minh Le Nguyen
BE Mothe, J
   Son, LH
   Vinh, NTQ
TI Marking Mechanism in Sequence-to-sequence Model for Mapping Language to
   Logical Form
SO PROCEEDINGS OF 2019 11TH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND
   SYSTEMS ENGINEERING (KSE 2019)
SE International Conference on Knowledge and Systems Engineering
CT 11th International Conference on Knowledge and Systems Engineering (KSE)
CY OCT 24-26, 2019
CL Da Nang, VIETNAM
SP IEEE, IEEE Vietnam Sect, Natl Fdn Sci & Technol Dev, Univ Da Nang Univ Sci & Educ, Peoples Comm Da Nang City, Univ Educ
AB Semantic parsing in Natural language processing (NLP) is a challenging task, which has been studied for many years. The main purpose is to model the language as a logical form like a machine translation task. Recently, an approach which uses a Neural network with Sequence to sequence model (Seq2seq) has achieved positive results. However, there are many challenges which have not been solved thoroughly yet, especially in the problem of rare words. Rare words in a natural sentence are usually the name of an object, a place or number, time, etc. Although these words are very various and difficult for the model to capture meaning, it holds a key information role in human communication (for example: name all the rivers in colorado ?). There are some methods to solve this problem such as using Attention or using Copy mechanism. However, these methods still difficult to copy phrase rare words, especially in case these phrases are variable in size. This paper proposes a novel approach to solve this problem, namely Marking mechanism in Seq2seq. The main idea is to label special words which are rare-words in a sentence by the encoder (marking step) and the decoder represents the logical form based on those labels (transforming step). Our experiments demonstrate that this approach works effectively, achieved a competitive result with old methods on all 3 datasets Geo, Atis, Jobs and special outperformed on our Artificial dataset.
SN 2164-2508
BN 978-1-7281-3003-3
PY 2019
BP 168
EP 174
UT WOS:000561727900027
ER

PT J
AU Sidler, HJ
   Duvenage, J
   Anderson, EJ
   Ng, J
   Hageman, DJ
   Tate, MLK
AF Sidler, Hans Joerg
   Duvenage, Jacob
   Anderson, Eric J.
   Ng, Joanna
   Hageman, Daniel J.
   Tate, Melissa L. Knothe
TI Prospective Design, Rapid Prototyping, and Testing of Smart Dressings,
   Drug Delivery Patches, and Replacement Body Parts Using Microscopy Aided
   Design and ManufacturE (MADAME)
SO FRONTIERS IN MEDICINE
AB Natural materials exhibit smart properties including gradients in biophysical properties that engender higher order functions, as well as stimuli-responsive properties which integrate sensor and/ or actuator capacities. Elucidation of mechanisms underpinning such smart material properties (i), and translation of that understanding (ii), represent two of the biggest challenges in emulating natural design paradigms for design and manufacture of disruptive materials, parts, and products. Microscopy Aided Design And ManufacturE (MADAME) stands for a computer-aided additive manufacturing platform that incorporates multidimensional (multi-D) printing and computer-controlled weaving. MADAME enables the creation of composite design motifs emulating e.g., patterns of woven protein fibers as well as gradients in different caliber porosities, mechanical, and molecular properties, found in natural tissues, from the skin on bones (periosteum) to tree bark. Insodoing, MADAME provides a means to manufacture a new genre of smart materials, products and replacement body parts that exhibit advantageous properties both under the influence of as well as harnessing dynamic mechanical loads to activate material properties (mechanoactive properties). This Technical Report introduces the MADAME technology platform and its associated machine-based workflow (pipeline), provides basic technical background of the novel technology and its applications, and discusses advantages and disadvantages of the approach in context of current 3 and 4D printing platforms.
RI Knothe Tate, Melissa L./K-5133-2012
OI Knothe Tate, Melissa L./0000-0002-3552-2525
EI 2296-858X
PD DEC 13
PY 2018
VL 5
AR 348
DI 10.3389/fmed.2018.00348
UT WOS:000453242300001
PM 30619859
ER

PT J
AU Suebchua, T
   Manaskasemsak, B
   Rungsawang, A
   Yamana, H
AF Suebchua, Tanaphol
   Manaskasemsak, Bundit
   Rungsawang, Arnon
   Yamana, Hayato
TI Efficient Topical Focused Crawling Through Neighborhood Feature
SO NEW GENERATION COMPUTING
AB A focused web crawler is an essential tool for gathering domain-specific data used by national web corpora, vertical search engines, and so on, since it is more efficient than general Breadth-First or Depth-First crawlers. The problem in focused crawling research is the prioritization of unvisited web pages in the crawling frontier followed by crawling these web pages in the order of their priority. The most common feature, adopted in many focused crawling researches, to prioritize an unvisited web page is the relevancy of the set of its source web pages, i.e., its in-linked web pages. However, this feature is limited, because we cannot estimate the relevancy of the unvisited web page correctly if we have few source web pages. To solve this problem and enhance the efficiency of focused web crawlers, we propose a new feature, called the "neighborhood feature". This enables the adoption of additional already-downloaded web pages to estimate the priority of a target web page. The additionally adopted web pages consist both of web pages located at the same directory as that of the target web page and web pages whose directory paths are similar to that of the target web page. Our experimental results show that our enhanced focused crawlers outperform the crawlers not utilizing the neighborhood feature as well as the state-of-the-art focused crawlers, including HMM crawler.
RI Manaskasemsak, Bundit/HGC-6818-2022
OI Manaskasemsak, Bundit/0000-0001-8075-2787; YAMANA,
   Hayato/0000-0001-7542-4826
SN 0288-3635
EI 1882-7055
PD APR
PY 2018
VL 36
IS 2
BP 95
EP 118
DI 10.1007/s00354-017-0029-8
UT WOS:000429463700002
ER

PT C
AU He, XL
   Xu, QK
   Lyu, LJ
   Wu, FZ
   Wang, CG
AF He, Xuanli
   Xu, Qiongkai
   Lyu, Lingjuan
   Wu, Fangzhao
   Wang, Chenguang
GP Assoc Advancement Artificial Intelligence
TI Protecting Intellectual Property of Language Generation APIs with
   Lexical Watermark
SO THIRTY-SIXTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FOURTH
   CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE /
   TWELVETH SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 36th AAAI Conference on Artificial Intelligence / 34th Conference on
   Innovative Applications of Artificial Intelligence / 12th Symposium on
   Educational Advances in Artificial Intelligence
CY FEB 22-MAR 01, 2022
CL ELECTR NETWORK
SP Assoc Advancement Artificial Intelligence
AB Nowadays, due to the breakthrough in natural language generation (NLG), including machine translation, document summarization, image captioning, etc., NLG models have been encapsulated in cloud APIs to serve over half a billion people worldwide and process over one hundred billion word generations per day.Thus, NLG APIs have already become essential profitable services in many commercial companies. Due to the substantial financial and intellectual investments, service providers adopt a pay-as-you-use policy to promote sustainable market growth. However, recent works have shown that cloud platforms suffer from financial losses imposed by model extraction attacks, which aim to imitate the functionality and utility of the victim services, thus violating the intellectual property (IP) of cloud APIs. This work targets at protecting IP of NLG APIs by identifying the attackers who have utilized watermarked responses from the victim NLG APIs. However, most existing watermarking techniques are not directly amenable for IP protection of NLG APIs. To bridge this gap, we first present a novel watermarking method for text generation APIs by conducting lexical modification to the original outputs. Compared with the competitive baselines, our watermark approach achieves better identifiable performance in terms of p-value, with fewer semantic losses. In addition, our watermarks are more understandable and intuitive to humans than the baselines. Finally, the empirical studies show our approach is also applicable to queries from different domains, and is effective on the attacker trained on a mixture of the corpus which includes less than 10% watermarked samples.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-876-3
PY 2022
BP 10758
EP 10766
UT WOS:000893639103085
ER

PT J
AU Netisopakul, P
   Wohlgenannt, G
   Pulich, A
   Hlaing, ZZ
AF Netisopakul, Ponrudee
   Wohlgenannt, Gerhard
   Pulich, Aleksei
   Hlaing, Zar Zar
TI Improving the state-of-the-art in Thai semantic similarity using
   distributional semantics and ontological information
SO PLOS ONE
AB Research into semantic similarity has a long history in lexical semantics, and it has applications in many natural language processing (NLP) tasks like word sense disambiguation or machine translation. The task of calculating semantic similarity is usually presented in the form of datasets which contain word pairs and a human-assigned similarity score. Algorithms are then evaluated by their ability to approximate the gold standard similarity scores. Many such datasets, with different characteristics, have been created for English language. Recently, four of those were transformed to Thai language versions, namely WordSim-353, SimLex-999, SemEval-2017-500, and R&G-65. Given those four datasets, in this work we aim to improve the previous baseline evaluations for Thai semantic similarity and solve challenges of unsegmented Asian languages (particularly the high fraction of out-of-vocabulary (OOV) dataset terms). To this end we apply and integrate different strategies to compute similarity, including traditional word-level embeddings, subword-unit embeddings, and ontological or hybrid sources like WordNet and ConceptNet. With our best model, which combines self-trained fastText subword embeddings with ConceptNet Numberbatch, we managed to raise the state-of-the-art, measured with the harmonic mean of Pearson on Spearman rho, by a large margin from 0.356 to 0.688 for TH-WordSim-353, from 0.286 to 0.769 for TH-SemEval-500, from 0.397 to 0.717 for TH-SimLex-999, and from 0.505 to 0.901 for TWS-65.
RI Netisopakul, Ponrudee/HMD-2087-2023
OI Netisopakul, Ponrudee/0000-0003-1409-9729
SN 1932-6203
PD FEB 17
PY 2021
VL 16
IS 2
AR e0246751
DI 10.1371/journal.pone.0246751
UT WOS:000620633200041
PM 33596220
ER

PT J
AU Adekile, A
   Anie, KA
   Ben Hamda, C
   Brown, B
   Bukini, D
   Campbell, A
   Chaouch, M
   Chimusa, E
   Chunda-Liyoka, C
   Dennis-Antwi, J
   Derebail, VK
   Flor-Park, M
   Geard, A
   Ghedira, K
   Haendel, M
   Hanchard, NA
   Hotchkiss, J
   Jonas, M
   Ibrahim, M
   Ingram, C
   Inusa, B
   Jimoh, AO
   Jupp, S
   Kamga, K
   Kashim, ZA
   Knight-Madden, J
   Landoure, G
   Lopez-Sall, P
   Makani, J
   Malasa, L
   Masekoameng, T
   Mazandu, G
   Mnika, K
   Mulder, N
   Munung, NS
   Munube, D
   Mwita, L
   Nembaware, V
   Nnodu, O
   Ofori-Acquah, S
   Ohene-Frempong, K
   Osei-Akoto, A
   Paintsil, V
   Panji, S
   Rahimy, MC
   Royal, C
   Sangeda, RZ
   Tayo, B
   Tiouiri, I
   Tluway, F
   Treadwell, M
   Tshilolo, L
   Vasilevsky, N
   Waiswa, KM
   Wonkam, A
AF Adekile, Adekunle
   Anie, Kofi A.
   Ben Hamda, Cherif
   Brown, Biobele
   Bukini, Daima
   Campbell, Andrew
   Chaouch, Melek
   Chimusa, Emile
   Chunda-Liyoka, Catherine
   Dennis-Antwi, Jemima
   Derebail, Vimal K.
   Flor-Park, Miriam
   Geard, Amy
   Ghedira, Kais
   Haendel, Melissa
   Hanchard, Neil A.
   Hotchkiss, Jade
   Jonas, Mario
   Ibrahim, Muntaser
   Ingram, Clair
   Inusa, Baba
   Jimoh, Adijat Ozohu
   Jupp, Simon
   Kamga, Karen
   Kashim, Zainab Abimbola
   Knight-Madden, Jennifer
   Landoure, Guida
   Lopez-Sall, Philomene
   Makani, Julie
   Malasa, Leonard
   Masekoameng, Tshepiso
   Mazandu, Gaston
   Mnika, Khuthala
   Mulder, Nicola
   Munung, Nchangwi Syntia
   Munube, Deogratias
   Mwita, Liberata
   Nembaware, Victoria
   Nnodu, Obiageli
   Ofori-Acquah, Solomon
   Ohene-Frempong, Kwaku
   Osei-Akoto, Alex
   Paintsil, Vivian
   Panji, Sumir
   Rahimy, Mohamed Cherif
   Royal, Charmaine
   Sangeda, Raphael Z.
   Tayo, Bamidele
   Tiouiri, Ines
   Tluway, Furahini
   Treadwell, Marsha
   Tshilolo, Leon
   Vasilevsky, Nicole
   Waiswa, Kasadhakawo Musa
   Wonkam, Ambroise
CA Sickle Cell Dis Ontology Working G
TI The Sickle Cell Disease Ontology: enabling universal sickle cell-based
   knowledge representation
SO DATABASE-THE JOURNAL OF BIOLOGICAL DATABASES AND CURATION
AB Sickle cell disease (SCD) is one of the most common monogenic diseases in humans with multiple phenotypic expressions that can manifest as both acute and chronic complications. Although described more than a century ago, challenges in comprehensive disease management and collaborative research on this disease are compounded by the complex molecular and clinical phenotypes of SCD, environmental and psychosocial factors, limited therapeutic options and ambiguous terminology. This ambiguous terminology has hampered the integration and interoperability of existing SCD knowledge, and SCD research translation. The SCD Ontology (SCDO), which is a community-driven integrative and universal knowledge representation system for SCD, overcomes this issue by providing a controlled vocabulary developed by a group of experts in both SCD and ontology design. SCDO is the first and most comprehensive standardized human- and machine-readable resource that unambiguously represents terminology and concepts about SCD for researchers, patients and clinicians. It is built around the central concept 'hemoglobinopathy', allowing inclusion of non-SCD haemoglobinopathies, such as thalassaemias, which may interfere with or influence SCD phenotypic manifestations. This collaboratively developed ontology constitutes a comprehensive knowledge management system and standardized terminology of various SCD-related factors. The SCDO will promote interoperability of different research datasets, facilitate seamless data sharing and collaborations, including meta-analyses within the SCD community, and support the development and curation of data-basing and clinical informatics in SCD. Availability: Ontology URL https://bioportal.bioontology.org/ontologies/SCDO.
RI Chaouch, Melek/HTN-5701-2023; Sangeda, Raphael Zozimus/V-6624-2018;
   Campbell, Andrew/AAX-8590-2020; Chaouch, Melek/AAL-8888-2021; Mnika,
   Khuthala/ABM-9590-2022; Hanchard, Neil/AAY-9075-2021; Jimoh,
   Adijat/HGA-5290-2022; NNODU, OBIAGELI Eunice/AGG-9921-2022; Chaouch,
   Melek/AAF-8954-2019; Chunda-Liyoka, Catherine/AAD-6343-2021; Wonkam,
   Ambroise/AFU-6901-2022; Emile Rugamika, Chimusa/T-3048-2017
OI Chaouch, Melek/0000-0001-5868-4204; Sangeda, Raphael
   Zozimus/0000-0002-6574-5308; Campbell, Andrew/0000-0002-8829-0043;
   Chaouch, Melek/0000-0001-5868-4204; Hanchard, Neil/0000-0003-1925-2665;
   Royal, Charmaine/0000-0003-3593-851X; Bukini, Daima/0000-0002-1376-4654;
   Haendel, Melissa/0000-0001-9114-8737; Jimoh, Adijat/0000-0002-1458-1454;
   Ben Hamda, Cherif/0000-0003-0985-4881; Tshilolo,
   Leon/0000-0002-6318-0227; Vasilevsky, Nicole/0000-0001-5208-3432; Emile
   Rugamika, Chimusa/0000-0001-8846-2047; Munung, Nchangwi
   Syntia/0000-0003-1498-3602; Mazandu, Gaston
   Kuzamunu/0000-0002-6441-8006; Derebail, Vimal/0000-0002-7662-7497
SN 1758-0463
PD NOV 26
PY 2019
AR baz118
DI 10.1093/database/baz118
UT WOS:000559976900001
PM 31769834
ER

PT J
AU Sun, XC
   Gui, G
   Li, YQ
   Liu, RP
   An, YL
AF Sun, Xiaochuan
   Gui, Guan
   Li, Yingqi
   Liu, Ren Ping
   An, Yongli
TI ResInNet: A Novel Deep Neural Network With Feature Reuse for Internet of
   Things
SO IEEE INTERNET OF THINGS JOURNAL
AB Deep neural networks (DNNs) have widely used in various Internet-of-Things (IoT) applications. Pursuing superior performance is always a hot spot in the field of DNN modeling. Recently, feature reuse provides an effective means of achieving favorable nonlinear approximation performance in deep learning. Existing implementations utilizes a multilayer perception (MLP) to act as a functional unit for feature reuse. However, determining connection weight and bias of MLP is a rather intractable problem, since the conventional back-propagation learning approach encounters the limitations of slow convergence and local optimum. To address this issue, this paper develops a novel DNN considering a well-behaved alternative called reservoir computing, i.e., reservoir in network (ResInNet). In this structure, the built-in reservoir has two notable functions. First, it behaves as a bridge between any two restricted Boltzmann machines in the feature learning part of ResInNet, performing a feature abstraction once again. Such reservoir-based feature translation provides excellent starting points for the following nonlinear regression. Second, it serves as a nonlinear approximation, trained by a simple linear regression using the most representative (learned) features. Experimental results over various benchmark datasets show that ResInNet can achieve the superior nonlinear approximation performance in comparison to the baseline models, and produce the excellent dynamic characteristics and memory capacity. Meanwhile, the merits of our approach is further demonstrated in the network traffic prediction related to real-world IoT application.
RI Liu, Ren Ping/B-7505-2011; Gui, Guan/AAG-3593-2019
OI Liu, Ren Ping/0000-0001-7001-6305; Gui, Guan/0000-0001-7428-4980; Sun,
   Xiaochuan/0000-0002-5101-5953
SN 2327-4662
PD FEB
PY 2019
VL 6
IS 1
BP 679
EP 691
DI 10.1109/JIOT.2018.2853663
UT WOS:000459709500057
ER

PT J
AU Jackson, JB
AF Jackson, J. Baz
TI Natural pH Gradients in Hydrothermal Alkali Vents Were Unlikely to Have
   Played a Role in the Origin of Life
SO JOURNAL OF MOLECULAR EVOLUTION
AB The hypothesis that a natural pH gradient across inorganic membranes lying between the ocean and fluid issuing from hydrothermal alkali vents provided energy to drive chemical reactions during the origin of life has an attractive parallel with chemiosmotic ATP synthesis in present-day organisms. However, arguments raised in this review suggest that such natural pH gradients are unlikely to have played a part in life's origin. There is as yet no evidence for thin inorganic membranes holding sharp pH gradients in modern hydrothermal alkali vents at Lost City near the Mid-Atlantic Ridge. Proposed models of nonprotein forms of the H+-pyrophosphate synthase that could have functioned as a molecular machine utilizing the energy of a natural pH gradient are unsatisfactory. Some hypothetical designs of non-protein motors utilizing a natural pH gradient to drive redox reactions are plausible but complex, and such motors are deemed unlikely to have assembled by chance in prebiotic times. Small molecular motors comprising a few hundred atoms would have been unable to function in the relatively thick (>1 mu m) inorganic membranes that have hitherto been used as descriptive models for the natural pH gradient hypothesis. Alternative hypotheses for the evolution of chemiosmotic systems following the emergence of error-prone gene replication and translation are more likely to be correct.
SN 0022-2844
EI 1432-1432
PD AUG
PY 2016
VL 83
IS 1-2
BP 1
EP 11
DI 10.1007/s00239-016-9756-6
UT WOS:000387133500001
PM 27534947
ER

PT C
AU Bashford, GR
   Morse, JL
   Melander, JR
AF Bashford, GR
   Morse, JL
   Melander, JR
BE Luk, FT
TI Novel fusion algorithms for medical ultrasound tomography
SO ADVANCED SIGNAL PROCESSING ALGORITHMS, ARCHITECTURES, AND
   IMPLEMENTATIONS XIV
SE PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)
CT Conference on Advanced Signal Processing Algorithms, Architectures, and
   Implementations XIV
CY AUG 04-06, 2004
CL Denver, CO
SP SPIE
AB Ultrasound tomography is a bioimaging method that combines the geometry of X-ray computed tomography with the non-ionizing energy of ultrasound. This modality has potential clinical utility in breast cancer screening and diagnosis. In conventional ultrasound tomography, data sets from different interrogation angles are used to reconstruct an estimate of a biomechanical property of the tissue, such as sound velocity, in the form of an image. Here we describe an alternative method of reconstruction using novel algorithms which weight the data based on a "quality" score. The quality score is derived from beamforming characteristics, for example, the weighting of angle-dependent data by its distance from the transmit focal zones. The new approach is that for each data set (taken at a different view angle), the reliability of the data (in the range dimension) is assumed to vary. By fusing (combining) the data based on the quality score, a complete image is formed. In this paper, we describe the construction of a rotational translation stage and tissue-mimicking phantoms that are used in conjunction with a commercial medical ultrasound machine to test our reconstruction algorithms. The new algorithms were found to increase the contrast-to-speckle ratio of simulated cysts by 114% from raw data over a 77% improvement by spatial compounding (averaging), and to decrease wire target width by 54% over a 39% reduction by spatial compounding alone. The new method shows promise as a computationally efficient method of improving contrast and resolution in ultrasound images.
SN 0277-786X
BN 0-8194-5497-4
PY 2004
VL 5559
BP 392
EP 400
DI 10.1117/12.560042
UT WOS:000225812400038
ER

PT J
AU Zhang, J
   Budhdeo, S
   William, W
   Cerrato, P
   Shuaib, H
   Sood, H
   Ashrafian, H
   Halamka, J
   Teo, JT
AF Zhang, Joe
   Budhdeo, Sanjay
   William, Wasswa
   Cerrato, Paul
   Shuaib, Haris
   Sood, Harpreet
   Ashrafian, Hutan
   Halamka, John
   Teo, James T.
TI Moving towards vertically integrated artificial intelligence development
SO NPJ DIGITAL MEDICINE
AB Substantial interest and investment in clinical artificial intelligence (AI) research has not resulted in widespread translation to deployed AI solutions. Current attention has focused on bias and explainability in AI algorithm development, external validity and model generalisability, and lack of equity and representation in existing data. While of great importance, these considerations also reflect a model-centric approach seen in published clinical AI research, which focuses on optimising architecture and performance of an AI model on best available datasets. However, even robustly built models using state-of-the-art algorithms may fail once tested in realistic environments due to unpredictability of real-world conditions, out-of-dataset scenarios, characteristics of deployment infrastructure, and lack of added value to clinical workflows relative to cost and potential clinical risks. In this perspective, we define a vertically integrated approach to AI development that incorporates early, cross-disciplinary, consideration of impact evaluation, data lifecycles, and AI production, and explore its implementation in two contrasting AI development pipelines: a scalable "AI factory" (Mayo Clinic, Rochester, United States), and an end-to-end cervical cancer screening platform for resource poor settings (Paps AI, Mbarara, Uganda). We provide practical recommendations for implementers, and discuss future challenges and novel approaches (including a decentralised federated architecture being developed in the NHS (AI4VBH, London, UK)). Growth in global clinical AI research continues unabated, and introduction of vertically integrated teams and development practices can increase the translational potential of future clinical AI projects.
RI Teo, James/D-9696-2011; william, wasswa/HPD-7802-2023
OI Teo, James/0000-0002-6899-8319; william, wasswa/0000-0002-0202-1230;
   Zhang, Joe/0000-0001-6040-2122; Halamka, John/0000-0003-2305-6755;
   Ashrafian, Hutan/0000-0003-1668-0672; Shuaib, Haris/0000-0001-6975-5960
SN 2398-6352
PD SEP 15
PY 2022
VL 5
IS 1
AR 143
DI 10.1038/s41746-022-00690-x
UT WOS:000853854400001
PM 36104535
ER

PT J
AU Zhang, SL
   Shi, HY
AF Zhang, Shengli
   Shi, Hongyan
TI iR5hmcSC: Identifying RNA 5-hydroxymethylcytosine with multiple features
   based on stacking learning
SO COMPUTATIONAL BIOLOGY AND CHEMISTRY
AB RNA 5-hydroxymethylcytosine (5hmC) modification is the basis of the translation of genetic information and the biological evolution. The study of its distribution in transcriptome is fundamentally crucial to reveal the biological significance of 5hmC. Biochemical experiments can use a variety of sequencing-based technologies to achieve high-throughput identification of 5hmC; however, they are labor-intensive, time-consuming, as well as expensive. Therefore, it is urgent to develop more effective and feasible computational methods. In this paper, a novel and powerful model called iR5hmcSC is designed for identifying 5hmC. Firstly, we extract the different features by K-mer, Pseudo Structure Status Composition and One-Hot encoding. Subsequently, the combination of chi-square test and logistic regression is utilized as the feature selection method to select the optimal feature sets. And then stacking learning, an ensemble learning method including random forest (RF), extra trees (EX), AdaBoost (Ada), gradient boosting decision tree (GBDT), and support vector machine (SVM), is used to recognize 5hmC and non-5hmC. Finally, 10-fold cross-validation test is performed to evaluate the model. The accuracy reaches 85.27% and 79.92% on benchmark dataset and independent dataset, respectively. The result is better than the state-of-the-art methods, which indicates that our model is a feasible tool to identify 5hmC. The datasets and source code are freely available at https://github.com/HongyanShi026/iR5hmcSC.
OI Zhang, Shengli/0000-0001-8786-0940
SN 1476-9271
EI 1476-928X
PD DEC
PY 2021
VL 95
AR 107583
DI 10.1016/j.compbiolchem.2021.107583
EA SEP 2021
UT WOS:000703021900005
PM 34562726
ER

PT J
AU Balacco, DL
   Soller, M
AF Balacco, Dario L.
   Soller, Matthias
TI The m(6)A Writer: Rise of a Machine for Growing Tasks
SO BIOCHEMISTRY
AB The central dogma of molecular biology introduced by Crick describes a linear flow of information from DNA to mRNA to protein. Since then it has become evident that RNA undergoes several maturation steps such as capping, splicing, 3'-end processing, and editing. Likewise, nucleotide modifications are common in mRNA and are present in all organisms impacting on the regulation of gene expression. The most abundant modification found in mRNA is N6-methyladenosine (m(6)A). Deposition of m(6)A is a nuclear process and is performed by a megadalton writer complex primarily on mRNAs, but also on microRNAs and lncRNAs. The m(6)A methylosome is composed of the enzymatic core components METTL3 and METTL14, and several auxiliary proteins necessary for its correct positioning and functioning, which are WTAP, VIRMA, FLACC, RBM15, and HAKAI. The m(6)A epimark is decoded by YTH domain-containing reader proteins YTHDC and YTHDF, but METTLs can act as "readers" as well. Eraser proteins, such as FTO and ALKBH5, can remove the methyl group. Here we review recent progress on the role of m6A in regulating gene expression in light of Crick's central dogma of molecular biology. In particular, we address the complexity of the writer complex from an evolutionary perspective to obtain insights into the mechanism of ancient m(6)A methylation and its regulation.
RI Balacco, Dario Leonardo/AAV-8054-2020; Soller, Matthias/J-4844-2017
OI Balacco, Dario Leonardo/0000-0002-7648-1213; Soller,
   Matthias/0000-0003-3844-0258
SN 0006-2960
PD FEB 5
PY 2019
VL 58
IS 5
SI SI
BP 363
EP 378
DI 10.1021/acs.biochem.8b01166
UT WOS:000458220500010
PM 30557013
ER

PT J
AU Fernando, T
   Denman, S
   McFadyen, A
   Sridharan, S
   Fookes, C
AF Fernando, Tharindu
   Denman, Simon
   McFadyen, Aaron
   Sridharan, Sridha
   Fookes, Clinton
TI Tree Memory Networks for modelling long-term temporal dependencies
SO NEUROCOMPUTING
AB In the domain of sequence modelling, Recurrent Neural Networks (RNN) have been capable of achieving impressive results in a variety of application areas including visual question answering, part-of-speech tagging and machine translation. However this success in modelling short term dependencies has not successfully transitioned to application areas such as trajectory prediction, which require capturing both short term and long term relationships. In this paper, we propose a Tree Memory Network (TMN) for jointly modelling both long term relationships between multiple sequences and short term relationships within a sequence, in sequence-to-sequence mapping problems. The proposed network architecture is composed of an input module, controller and a memory module. In contrast to related literature which models the memory as a sequence of historical states, we model the memory as a recursive tree structure. This structure more effectively captures temporal dependencies across both short and long term time periods through its hierarchical structure. We demonstrate the effectiveness and flexibility of the proposed TMN in two practical problems: aircraft trajectory modelling and pedestrian trajectory modelling in a surveillance setting. In both cases the proposed approach outperforms the current state-of-the-art. Furthermore, we perform an in depth analysis on the evolution of the memory module content over time and provide visual evidence on how the proposed TMN is able to map both short and long term relationships efficiently via a hierarchical structure. (c) 2018 Elsevier B.V. All rights reserved.
RI Fookes, Clinton/I-9786-2012; McFadyen, Aaron/AHE-3512-2022; Fernando,
   Tharindu/AAJ-1974-2020
OI Fookes, Clinton/0000-0002-8515-6324; McFadyen,
   Aaron/0000-0002-9158-0412; Fernando, Tharindu/0000-0002-6935-1816;
   Sridharan, Sridha/0000-0003-4316-9001
SN 0925-2312
EI 1872-8286
PD AUG 23
PY 2018
VL 304
BP 64
EP 81
DI 10.1016/j.neucom.2018.03.040
UT WOS:000432492800005
ER

PT J
AU Hogenboom, A
   Heerschop, B
   Frasincar, F
   Kaymak, U
   de Jong, F
AF Hogenboom, Alexander
   Heerschop, Bas
   Frasincar, Flavius
   Kaymak, Uzay
   de Jong, Franciska
TI Multi-lingual support for lexicon-based sentiment analysis guided by
   semantics
SO DECISION SUPPORT SYSTEMS
AB Many sentiment analysis methods rely on sentiment lexicons, containing words and their associated sentiment, and are tailored to one specific language. Yet, the ever-growing amount of data in different languages on the Web renders multi-lingual support increasingly important. In this paper, we assess various methods for supporting an additional target language in lexicon-based sentiment analysis. As a baseline, we automatically translate text into a reference language for which a sentiment lexicon is available, and subsequently analyze the translated text. Second, we consider mapping sentiment scores from a semantically enabled sentiment lexicon in the reference language to a new target sentiment lexicon, by traversing relations between language-specific semantic lexicons. Last, we consider creating a target sentiment lexicon by propagating sentiment of seed words in a semantic lexicon for the target language. When extending sentiment analysis from English to Dutch, mapping sentiment across languages by exploiting relations between semantic lexicons yields a significant performance improvement over the baseline of about 29% in terms of accuracy and macro-level F-1 on our data. Propagating sentiment in language-specific semantic lexicons can outperform the baseline by up to about 47%, depending on the seed set of sentiment-carrying words. This indicates that sentiment is not only linked to word meanings, but tends to have a language-specific dimension as well. (C) 2014 Elsevier B.V. All rights reserved.
RI Frasincar, Flavius/AAC-8253-2021; Frasincar, Flavius/D-3171-2011;
   Kaymak, Uzay/A-3364-2008
OI Frasincar, Flavius/0000-0002-8031-758X; Kaymak,
   Uzay/0000-0002-4500-9098; Heerschop, Bas/0000-0002-2113-2606
SN 0167-9236
EI 1873-5797
PD JUN
PY 2014
VL 62
BP 43
EP 53
DI 10.1016/j.dss.2014.03.004
UT WOS:000336825900005
ER

PT J
AU Benalcazar, ME
   Brun, M
   Ballarin, VL
AF Benalcazar, Marco E.
   Brun, Marcel
   Ballarin, Virginia L.
TI Artificial neural networks applied to statistical design of window
   operators
SO PATTERN RECOGNITION LETTERS
AB The design of binary W-operators, morphological operators that are translation-invariant and locally defined by a finite neighborhood window, corresponds to the problem of designing Boolean functions, or their characteristic functions. One of the main issues regarding the automatic design of W-operators, based on samples, is the one of generalization. Considering the designing of W-operators as a particular case of designing a pattern recognition system, in this paper we propose a new approach for the automatic design of binary W-operators. The approach consists on a functional representation of the class membership conditional probability for the whole set of patterns viewed through a given window, instead of generalizing the class labels (or the characteristic function values). The estimation of parameters for the functional representation uses a nonlinear regression performed by an artificial feed-forward neural network. The network training is based on the weighted mean square error cost function, allowing us to use the marginal probability of each pattern viewed by a given window. Experimental results, consisting on noise filtering in images of retinal angiographies, edge detection in noise images, texture identification and character recognition, show that the proposed approach outperforms not only pyramidal multiresolution, the best existing method for generalization of characteristic functions of W-operators, but also classical classifiers based on support vector machines, k-nearest neighbor and convolutional neural networks. (C) 2013 Elsevier B.V. All rights reserved.
RI Laura, Virginia/AAC-7511-2019
OI Laura, Virginia/0000-0002-5648-6463; Brun, Marcel/0000-0002-6452-5856;
   Benalcazar, Marco E./0000-0002-5275-7262
SN 0167-8655
PD JUL 1
PY 2013
VL 34
IS 9
BP 970
EP 979
DI 10.1016/j.patrec.2013.01.029
UT WOS:000318889800003
ER

PT J
AU Soriano, JMP
   Ioannidou, E
   Wang, J
   Thornton, JC
   Horlick, MN
   Gallagher, D
   Heymsfield, SB
   Pierson, RN
AF Soriano, JMP
   Ioannidou, E
   Wang, J
   Thornton, JC
   Horlick, MN
   Gallagher, D
   Heymsfield, SB
   Pierson, RN
TI Pencil-beam vs fan-beam dual-energy X-ray absorptiometry comparisons
   across four systems
SO JOURNAL OF CLINICAL DENSITOMETRY
AB We compared bone mineral density (BMD) and body fat percentage (%fat) between two pencil-beam (Lunar DPX and DPX-L) and two fan-beam (Lunar Prodigy, Hologic DelphiA) dual-energy X-ray absorptiometry (DXA) systems. We examined these values in the total-body, spine, femur, and forearm scans in 78 healthy adults across these four DXA systems. BMD and %fat values were highly correlated among the four instruments. DPX-L gave the lowest mean %fat and Prodigy gave the highest mean %fat for both sexes. The means were system dependent for %fat estimates across the four DXA machines. There was a significant difference detected in BMD estimates across manufacturers, with the DelphiA providing systematically lower values than the Lunar systems in the whole body, spine, and femur sites but higher values than the Lunar systems in the forearm. The present study results show that both %fat and bone mineral estimates between pencil-beam and fan-beam systems are highly correlated, but vary by system. Significant differences exist between the instruments, especially between different manufacturers, and most of the comparisons are sex dependent. We conclude that longitudinal studies should always be evaluated on the same system when possible, and translation models should be used to assess cross-instrument differences.
RI Heymsfield, Steven B/N-1968-2017
OI Heymsfield, Steven B/0000-0003-1127-9425; Gallagher,
   Dympna/0000-0003-1769-9754
SN 1094-6950
EI 1559-0747
PD FAL
PY 2004
VL 7
IS 3
BP 281
EP 289
DI 10.1385/JCD:7:3:281
UT WOS:000223627800005
PM 15319498
ER

PT J
AU Bogatu, L
   Turco, S
   Mischi, M
   Schmitt, L
   Woerlee, P
   Bezemer, R
   Bouwman, AR
   Korsten, EHHM
   Muehlsteff, J
AF Bogatu, Laura
   Turco, Simona
   Mischi, Massimo
   Schmitt, Lars
   Woerlee, Pierre
   Bezemer, Rick
   Bouwman, Arthur R.
   Korsten, Erik H. H. M.
   Muehlsteff, Jens
TI New Hemodynamic Parameters in Peri-Operative and Critical
   Care-Challenges in Translation
SO SENSORS
AB Hemodynamic monitoring technologies are evolving continuously-a large number of bedside monitoring options are becoming available in the clinic. Methods such as echocardiography, electrical bioimpedance, and calibrated/uncalibrated analysis of pulse contours are becoming increasingly common. This is leading to a decline in the use of highly invasive monitoring and allowing for safer, more accurate, and continuous measurements. The new devices mainly aim to monitor the well-known hemodynamic variables (e.g., novel pulse contour, bioreactance methods are aimed at measuring widely-used variables such as blood pressure, cardiac output). Even though hemodynamic monitoring is now safer and more accurate, a number of issues remain due to the limited amount of information available for diagnosis and treatment. Extensive work is being carried out in order to allow for more hemodynamic parameters to be measured in the clinic. In this review, we identify and discuss the main sensing strategies aimed at obtaining a more complete picture of the hemodynamic status of a patient, namely: (i) measurement of the circulatory system response to a defined stimulus; (ii) measurement of the microcirculation; (iii) technologies for assessing dynamic vascular mechanisms; and (iv) machine learning methods. By analyzing these four main research strategies, we aim to convey the key aspects, challenges, and clinical value of measuring novel hemodynamic parameters in critical care.
OI Bouwman, R. Arthur/0000-0002-2051-5947; Mischi,
   Massimo/0000-0002-1179-5385
EI 1424-8220
PD FEB
PY 2023
VL 23
IS 4
AR 2226
DI 10.3390/s23042226
UT WOS:000940589100001
PM 36850819
ER

PT J
AU Relier, S
   Amalric, A
   Attina, A
   Koumare, IB
   Rigau, V
   Vandenbos, FB
   Fontaine, D
   Baroncini, M
   Hugnot, JP
   Duffau, H
   Bauchet, L
   Hirtz, C
   Rivals, E
   David, A
AF Relier, S.
   Amalric, A.
   Attina, A.
   Koumare, I. B.
   Rigau, V.
   Vandenbos, F. Burel
   Fontaine, D.
   Baroncini, M.
   Hugnot, J. P.
   Duffau, H.
   Bauchet, L.
   Hirtz, C.
   Rivals, E.
   David, A.
TI Multivariate Analysis of RNA Chemistry Marks Uncovers
   Epitranscriptomics-Based Biomarker Signature for Adult Diffuse Glioma
   Diagnostics
SO ANALYTICAL CHEMISTRY
AB One of the main challenges in cancer management relates to the discovery of reliable biomarkers, which could guide decision-making and predict treatment outcome. In particular, the rise and democratization of high-throughput molecular profiling technologies bolstered the discovery of "biomarker signatures" that could maximize the prediction performance. Such an approach was largely employed from diverse OMICs data (i.e., genomics, transcriptomics, proteomics, metabolomics) but not from epitranscriptomics, which encompasses more than 100 biochemical modifications driving the post-transcriptional fate of RNA: stability, splicing, storage, and translation. We and others have studied chemical marks in isolation and associated them with cancer evolution, adaptation, as well as the response to conventional therapy. In this study, we have designed a unique pipeline combining multiplex analysis of the epitranscriptomic landscape by high-perform-ance liquid chromatography coupled to tandem mass spectrometry with statistical multivariate analysis and machine learning approaches in order to identify biomarker signatures that could guide precision medicine and improve disease diagnosis. We applied this approach to analyze a cohort of adult diffuse glioma patients and demonstrate the existence of an "epitranscriptomics-based signature" that permits glioma grades to be discriminated and predicted with unmet accuracy. This study demonstrates that epitranscriptomics (co)evolves along cancer progression and opens new prospects in the field of omics molecular profiling and personalized medicine.
RI David, Alexandre/B-2447-2013; Hirtz, Christophe/R-9255-2017
OI David, Alexandre/0000-0003-3365-1339; Rivals, Eric/0000-0003-3791-3973;
   Hirtz, Christophe/0000-0002-7313-0629; Amalric,
   Amandine/0000-0002-2856-1446; RELIER, Sebastien/0000-0003-2670-9125
SN 0003-2700
EI 1520-6882
PD SEP 6
PY 2022
VL 94
IS 35
BP 11967
EP 11972
DI 10.1021/acs.analchem.2c01526
EA AUG 2022
UT WOS:000848122200001
PM 35998076
ER

PT J
AU Min, YZ
   Hu, J
   Sun, TF
AF Min Yongzhi
   Hu Jie
   Sun Tianfang
TI Calibration Method of Position-Pose Relation Between Cameras in Transfer
   Station of Image-Based Subgrade Monitoring System
SO LASER & OPTOELECTRONICS PROGRESS
AB The position-pose relation between cameras is the main factor that affects the accuracy of an image-based ballastless track subgrade monitoring system. Each camera in the monitoring station must face the corresponding monitoring target surface, so there is often no public field of view between the cameras. According to the equivalence between the hand-eye calibration problem in robot vision and the calibration of position-pose relation between cameras, a position-pose calibration method based on feature points is proposed. Four feature points with square distribution are set on the monitoring target surface. A set of cameras is moved twice in small step and takes the pictures of the target surface in three different positions. The P4P (perspective-four-point) algorithm is used to solve the position-pose relation between the camera and the target, and then obtains the movement trajectory of the camera. The matrix rearrangement method is used to obtain the pose conversion matrix between the cameras, and the Levenberg-Marquardt algorithm is used for nonlinear optimization. Simulation results indicate that the angle error is less than 0.03 degrees and the translation error is less than 0.3 cm when the noise variance is less than 1 pixel. The effectiveness and practicability of the method in this paper are verified by simulation, and the method in this paper can meet the needs of the settlement measurement of the ballastless track subgrade.
SN 1006-4125
PD JUN
PY 2021
VL 58
IS 12
AR 1215007
DI 10.3788/LOP202158.1215007
UT WOS:000686490800048
ER

PT J
AU Aghamohammadi, A
   Izadi, M
   Heydarnoori, A
AF Aghamohammadi, Alireza
   Izadi, Maliheh
   Heydarnoori, Abbas
TI Generating summaries for methods of event-driven programs: An Android
   case study
SO JOURNAL OF SYSTEMS AND SOFTWARE
AB The lack of proper documentation makes program comprehension a cumbersome process for developers. Source code summarization is one of the existing solutions to this problem. Many approaches have been proposed to summarize source code in recent years. A prevalent weakness of these solutions is that they do not pay much attention to interactions among elements of software. An element is simply a callable code snippet such as a method or even a clickable button. As a result, these approaches cannot be applied to event-driven programs, such as Android applications, because they have specific features such as numerous interactions between their elements. To tackle this problem, we propose a novel approach based on deep neural networks and dynamic call graphs to generate summaries for methods of event-driven programs. First, we collect a set of comment/code pairs from Github and train a deep neural network on the set. Afterward, by exploiting a dynamic call graph, the Pagerank algorithm, and the pre-trained deep neural network, we generate summaries. An empirical evaluation with 14 real-world Android applications and 42 participants indicates 32.3% BLEU4 which is a definite improvement compared to the existing state-of-the-art techniques. We also assessed the informativeness and naturalness of our generated summaries from developers' perspectives and showed they are sufficiently understandable and informative. (C) 2020 Elsevier Inc. All rights reserved.
OI Izadi, Maliheh/0000-0001-5093-5523; Heydarnoori,
   Abbas/0000-0001-9785-2880
SN 0164-1212
EI 1873-1228
PD DEC
PY 2020
VL 170
AR 110800
DI 10.1016/j.jss.2020.110800
UT WOS:000579355800002
ER

PT J
AU Alhawarat, M
   Aseeri, AO
AF Alhawarat, M.
   Aseeri, Ahmad O.
TI A Superior Arabic Text Categorization Deep Model (SATCDM)
SO IEEE ACCESS
AB Categorizing Arabic text documents is considered an important research topic in the field of Natural Language Processing (NLP) and Machine Learning (ML). The number of Arabic documents is tremendously increasing daily as new web pages, news articles, social media contents are added. Hence, classifying such documents in specific classes is of high importance to many people and applications. Convolutional Neural Network (CNN) is a class of deep learning that has been shown to be useful for many NLP tasks, including text translation and text categorization for the English language. Word embedding is a text representation currently used to represent text terms as real-valued vectors in vector space that represent both syntactic and semantic traits of text. Current research studies in classifying Arabic text documents use traditional text representation such as bag-of-words and TF-IDF weighting, but few use word embedding. Traditional ML algorithms have already been used in Arabic text categorization, and good results are achieved. In this study, we present a Multi-Kernel CNN model for classifying Arabic news documents enriched with n-gram word embedding, which we call A Superior Arabic Text Categorization Deep Model (SATCDM). The proposed solution achieves very high accuracy compared to current research in Arabic text categorization using 15 of freely available datasets. The model achieves an accuracy ranging from 97.58% to 99.90%, which is superior to similar studies on the Arabic document classification task.
RI Alhawarat, Mohammad/I-5951-2019; Aseeri, Ahmad O./GPP-1108-2022; Aseeri,
   Ahmad O./AAY-1700-2020
OI Alhawarat, Mohammad/0000-0002-2608-6573; Aseeri, Ahmad
   O./0000-0001-9863-4551; Aseeri, Ahmad O./0000-0001-9863-4551
SN 2169-3536
PY 2020
VL 8
BP 24653
EP 24661
DI 10.1109/ACCESS.2020.2970504
UT WOS:000524653300009
ER

PT J
AU Wang, MQ
   Wang, ZS
   Lu, JM
   Lin, J
   Wang, ZF
AF Wang, Meiqi
   Wang, Zhisheng
   Lu, Jinming
   Lin, Jun
   Wang, Zhongfeng
TI E-LSTM: An Efficient Hardware Architecture for Long Short-Term Memory
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
AB Long Short-Term Memory (LSTM) and its variants have been widely adopted in many sequential learning tasks, such as speech recognition and machine translation. Significant accuracy improvements can be achieved using complex LSTM model with a large memory requirement and high computational complexity, which is time-consuming and energy demanding. The low-latency and energy-efficiency requirements of the realworld applications make model compression and hardware acceleration for LSTM an urgent need. In this paper, several hardware-efficient network compression schemes are introduced first, including structured top-k pruning, clipped gating, and multiplication-free quantization, to reduce the model size and the number of matrix operations by 32x and 21.6x, respectively, with negligible accuracy loss. Furthermore, efficient hardware architectures for accelerating the compressed LSTM are proposed, which support the inference of multi-layer and multiple time steps. The computation process is judiciously reorganized and the memory access pattern is well optimized, which alleviate the limited memory bandwidth bottleneck and enable higher throughput. Moreover, the parallel processing strategy is carefully designed to make full use of the sparsity introduced by pruning and clipped gating with high hardware utilization efficiency. Implemented on Intel Arria10 SX660 FPCA running at 200MHz, the proposed design is able to achieve 1.4-2.2x energy efficiency and requires significantly less hardware resources compared with the state-of-the-art LSTM implementations.
RI Lu, Jinming/AAV-8396-2021
OI Lu, Jinming/0000-0002-7134-6514; Wang, Meiqi/0000-0001-9553-3640; Wang,
   Zhongfeng/0000-0002-7227-4786
SN 2156-3357
EI 2156-3365
PD JUN
PY 2019
VL 9
IS 2
BP 280
EP 291
DI 10.1109/JETCAS.2019.2911739
UT WOS:000471693500004
ER

PT C
AU Serpa, YR
   Rodrigues, MAF
AF Serpa, Ygor Reboucas
   Formico Rodrigues, Maria Andreia
GP IEEE
TI Towards Machine-Learning Assisted Asset Generation for Games: A Study on
   Pixel Art Sprite Sheets
SO 2019 18TH BRAZILIAN SYMPOSIUM ON COMPUTER GAMES AND DIGITAL
   ENTERTAINMENT (SBGAMES 2019)
SE Brazilian Symposium on Games and Digital Entertainment SBGAMES
CT 18th Brazilian Symposium on Computer Games and Digital Entertainment
   (SBGames)
CY OCT 28-31, 2019
CL Rio De Janeiro, BRAZIL
SP CAPES, Conselho Nacl Desenvolvimento Cientifico Tecnologico, Fundacao Carlos Chagas Filho Amparo Pesquisa Estado Rio Janeiro
AB Game development is simultaneously a technical and an artistic challenge. The past two decades have brought many improvements to general-purpose game engines, reducing the new games development effort considerably. However, the amount of artistic work per title has continuously grown ever since, as a result of increased audience's expectations. The cost of asset-making is further increased based on the aesthetics chosen by the design team and the availability of professionals capable of understanding the nuances of the specific visual language chosen. In this paper, we dig into the topic of deep-learning assets generation to reduce the costs of the asset making pipeline, a major concern for game development teams. More specifically, we tackle the challenge of generating pixel art sprites from line art sketches using state-of-the-art image translation techniques. We set this work within the pipeline of Trajes Fatais: Suits of Fate, a 2D pixel-art fighting game inspired by the late nineties classics of the fighting genre. The results show that our deep-learning assets generation technique is able to generate sprites that look similar to those created by the artists' team. Moreover, by means of qualitative and quantitative analyses, as well as character designers evaluation, we demonstrate the similarity of the generated results to the ground truth.
SN 2159-6654
EI 2159-6662
BN 978-1-7281-4637-9
PY 2019
BP 182
EP 191
DI 10.1109/SBGames.2019.00032
UT WOS:000522226400019
ER

PT J
AU Laurent, A
   Meignier, S
   Deleglise, P
AF Laurent, Antoine
   Meignier, Sylvain
   Deleglise, Paul
TI Improving recognition of proper nouns in ASR through generating and
   filtering phonetic transcriptions
SO COMPUTER SPEECH AND LANGUAGE
AB Accurate phonetic transcription of proper nouns can be an important resource for commercial applications that embed speech technologies, such as audio indexing and vocal phone directory lookup. However, an accurate phonetic transcription is more difficult to obtain for proper nouns than for regular words. Indeed, phonetic transcription of a proper noun depends on both the origin of the speaker pronouncing it and the origin of the proper noun itself.
   This work proposes a method that allows the extraction of phonetic transcriptions of proper nouns using actual utterances of those proper nouns, thus yielding transcriptions based on practical use instead of mere pronunciation rules.
   The proposed method consists in a process that first extracts phonetic transcriptions, and then iteratively filters them. In order to initialize the process, an alignment dictionary is used to detect word boundaries. A rule-based grapheme-to-phoneme generator (LIA_PHON), a knowledge-based approach (JSM), and a Statistical Machine Translation based system were evaluated for this alignment. As a result, compared to our reference dictionary (BDLEX supplemented by LIA_PHON for missing words) on the ESTER 1 French broadcast news corpus, we were able to significantly decrease the Word Error Rate (WER) on segments of speech with proper nouns, without negatively affecting the WER on the rest of the corpus. (C) 2014 Elsevier Ltd. All rights reserved.
SN 0885-2308
EI 1095-8363
PD JUL
PY 2014
VL 28
IS 4
BP 979
EP 996
DI 10.1016/j.csl.2014.02.006
UT WOS:000336694200009
ER

PT J
AU Rabe, F
AF Rabe, Florian
TI A logical framework combining model and proof theory
SO MATHEMATICAL STRUCTURES IN COMPUTER SCIENCE
AB Mathematical logic and computer science have driven the design of a growing number of logics and related formalisms such as set theories and type theories. In response to this population explosion, logical frameworks have been developed as formal meta-languages in which to represent, structure, relate and reason about logics.
   Research on logical frameworks has diverged into separate communities, often with conflicting backgrounds and philosophies. In particular, two of the most important logical frameworks are the framework of institutions, from the area of model theory based on category theory, and the Edinburgh Logical Framework LF, from the area of proof theory based on dependent type theory. Even though their ultimate motivations overlap - for example in applications to software verification - they have fundamentally different perspectives on logic.
   In the current paper, we design a logical framework that integrates the frameworks of institutions and LF in a way that combines their complementary advantages while retaining the elegance of each of them. In particular, our framework takes a balanced approach between model theory and proof theory, and permits the representation of logics in a way that comprises all major ingredients of a logic: syntax, models, satisfaction, judgments and proofs. This provides a theoretical basis for the systematic study of logics in a comprehensive logical framework. Our framework has been applied to obtain a large library of structured and machine-verified encodings of logics and logic translations.
OI Rabe, Florian/0000-0003-3040-3655
SN 0960-1295
EI 1469-8072
PD OCT
PY 2013
VL 23
IS 5
BP 945
EP 1001
DI 10.1017/S0960129512000424
UT WOS:000323817000001
ER

PT J
AU Lai, YW
   Hamann, S
   Ehmann, M
   Ludwig, A
AF Lai, Y. W.
   Hamann, S.
   Ehmann, M.
   Ludwig, A.
TI High-throughput characterization of stresses in thin film materials
   libraries using Si cantilever array wafers and digital holographic
   microscopy
SO REVIEW OF SCIENTIFIC INSTRUMENTS
AB We report the development of an advanced high-throughput stress characterization method for thin film materials libraries sputter-deposited on micro-machined cantilever arrays consisting of around 1500 cantilevers on 4-inch silicon-on-insulator wafers. A low-cost custom-designed digital holographic microscope (DHM) is employed to simultaneously monitor the thin film thickness, the surface topography and the curvature of each of the cantilevers before and after deposition. The variation in stress state across the thin film materials library is then calculated by Stoney's equation based on the obtained radii of curvature of the cantilevers and film thicknesses. DHM with nanometer-scale out-of-plane resolution allows stress measurements in a wide range, at least from several MPa to several GPa. By using an automatic x-y translation stage, the local stresses within a 4-inch materials library are mapped with high accuracy within 10 min. The speed of measurement is greatly improved compared with the prior laser scanning approach that needs more than an hour of measuring time. A high-throughput stress measurement of an as-deposited Fe-Pd-W materials library was evaluated for demonstration. The fast characterization method is expected to accelerate the development of (functional) thin films, e. g., (magnetic) shape memory materials, whose functionality is greatly stress dependent. (C) 2011 American Institute of Physics. [doi:10.1063/1.3600594]
RI Hamann, Sven/E-8837-2011; Ludwig, Alfred G/G-1111-2011
OI Ludwig, Alfred G/0000-0003-2802-6774
SN 0034-6748
EI 1089-7623
PD JUN
PY 2011
VL 82
IS 6
AR 063903
DI 10.1063/1.3600594
UT WOS:000292334000039
PM 21721705
ER

PT J
AU Tilevich, E
   Smaragdakis, Y
AF Tilevich, Eli
   Smaragdakis, Yannis
TI J-Orchestra: Enhancing Java Programs with Distribution Capabilities
SO ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY
AB J-Orchestra is a system that enhances centralized Java programs with distribution capabilities. Operating at the bytecode level, J-Orchestra transforms a centralized Java program (i.e., running on a single Java Virtual Machine (JVM)) into a distributed one (i.e., running across multiple JVMs). This transformation effectively separates distribution concerns from the core functionality of a program. J-Orchestra follows a semiautomatic transformation process. Through a GUI, the user selects program elements (at class granularity) and assigns them to network locations. Based on the user's input, the J-Orchestra backend automatically partitions the program through compiler-level techniques, without changes to the JVM or to the Java Runtime Environment (JRE) classes. By means of bytecode engineering and code generation, J-Orchestra substitutes method calls with remote method calls, direct object references with proxy references, etc. It also translates Java language features (e.g., static methods and fields, inheritance, inner classes, new object construction, etc.) for efficient distributed execution.
   We detail the main technical issues that J-Orchestra addresses, including its mechanism for program transformation in the presence of unmodifiable code (e.g., in JRE classes) and the translation of concurrency and synchronization constructs to work correctly over the network. We further discuss a case study of transforming a large, commercial, third-party application for efficient execution in a client server environment and outline the architectural characteristics of centralized programs that are amenable to automated distribution with J-Orchestra.
RI Smaragdakis, Yannis/AAM-2851-2021
OI Tilevich, Eli/0000-0003-2415-6926
SN 1049-331X
EI 1557-7392
PD AUG
PY 2009
VL 19
IS 1
AR 1
DI 10.1145/1555392.1555394
UT WOS:000269266700001
ER

PT J
AU Dinh, TN
   Pham, P
   Nguyen, GL
   Vo, B
AF Dinh, Thi N. N.
   Pham, Phu
   Nguyen, Giang L. L.
   Vo, Bay
TI Enhanced context-aware citation recommendation with auxiliary textual
   information based on an auto-encoding mechanism
SO APPLIED INTELLIGENCE
AB The process of retrieving suitable papers which are related to an interesting topic while doing research normally takes a lot of time and effort. Citation recommendation is frequently used to solve this problem by automatically suggesting a list of candidate papers that should match with the user's references or topics of interest. Applying the recent research results of deep learning in multiple disciplines, the performance of citation recommendation systems has been significantly improved with the facilitation of powerful deep neural data analysis and representation learning techniques. However, most of the recent Neural Citation Network (NCN) model-based techniques still encounter limitations related to the capability of integrating auxiliary information to assist the citation contextual learning process. Thus, in this paper, we propose a novel context-aware NCN-based model with the extra textual data integration and Bidirectional Encoder Representations from Transformers (BERT) model to improve the performance of the citation recommendation task. To do this, an extensive deep neural auto-encoding mechanism with a self-attention-based mechanism is utilized in our proposed model to flexibly learn both associated textual and citation contextual data in the given dataset. These enriched citation contextual information representations are then utilized to improve the performance of the citation recommendation task as the end-to-end neural learning process. Extensive experiments in the standard arXiv dataset show the effectiveness and good performance of the proposed model.
RI Vo, Bay/D-2121-2019
OI Vo, Bay/0000-0002-2723-1138
SN 0924-669X
EI 1573-7497
DI 10.1007/s10489-022-04423-1
EA JAN 2023
UT WOS:000907068800001
ER

PT J
AU AlMousa, M
   Benlamri, R
   Khoury, R
AF AlMousa, Mohannad
   Benlamri, Rachid
   Khoury, Richard
TI Exploiting non-taxonomic relations for measuring semantic similarity and
   relatedness in WordNet
SO KNOWLEDGE-BASED SYSTEMS
AB Various applications in computational linguistics and artificial intelligence employ semantic similarity to solve challenging tasks, such as word sense disambiguation, text classification, information retrieval, machine translation, and document clustering. To our knowledge, research to date rely solely on the taxonomic relation "ISA'' to evaluate semantic similarity and relatedness between terms. This paper explores the benefits of using all types of non-taxonomic relations in large linked data, such as WordNet knowledge graph, to enhance existing semantic similarity and relatedness measures. We propose a holistic poly-relational approach based on a new relation-based information content and non-taxonomic-based weighted paths to devise a comprehensive semantic similarity and relatedness measure. To demonstrate the benefits of exploiting non-taxonomic relations in a knowledge graph, we used three strategies to deploy non-taxonomic relations at different granularity levels. We conduct experiments on four well-known gold standard datasets. The results of our proposed method demonstrate an improvement over the benchmark semantic similarity methods, including the state-of-the-art knowledge graph embedding techniques, that ranged from 3.8%-23.8%, 1.3%-18.3%, 31.8%-117.2%, and 19.1%-111.1%, on all gold standard datasets MC, RG, WordSim, and Mturk, respectively. These results demonstrate the robustness and scalability of the proposed semantic similarity and relatedness measure, significantly improving existing similarity measures. (C) 2020 Elsevier B.V. All rights reserved.
RI Almousa, Mohannad/AAI-5036-2021
OI Almousa, Mohannad/0000-0003-0087-1941
SN 0950-7051
EI 1872-7409
PD JAN 5
PY 2021
VL 212
AR 106565
DI 10.1016/j.knosys.2020.106565
UT WOS:000604525200014
ER

PT J
AU Jahangir, R
   Teh, YW
   Hanif, F
   Mujtaba, G
AF Jahangir, Rashid
   Teh, Ying Wah
   Hanif, Faiqa
   Mujtaba, Ghulam
TI Deep learning approaches for speech emotion recognition: state of the
   art and research challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
AB Speech emotion recognition (SER) systems identify emotions from the human voice in the areas of smart healthcare, driving a vehicle, call centers, automatic translation systems, and human-machine interaction. In the classical SER process, discriminative acoustic feature extraction is the most important and challenging step because discriminative features influence the classifier performance and decrease the computational time. Nonetheless, current handcrafted acoustic features suffer from limited capability and accuracy in constructing a SER system for real-time implementation. Therefore, to overcome the limitations of handcrafted features, in recent years, variety of deep learning techniques have been proposed and employed for automatic feature extraction in the field of emotion prediction from speech signals. However, to the best of our knowledge, there is no in-depth review study is available that critically appraises and summarizes the existing deep learning techniques with their strengths and weaknesses for SER. Hence, this study aims to present a comprehensive review of deep learning techniques, uniqueness, benefits and their limitations for SER. Moreover, this review study also presents speech processing techniques, performance measures and publicly available emotional speech databases. Furthermore, this review also discusses the significance of the findings of the primary studies. Finally, it also presents open research issues and challenges that need significant research efforts and enhancements in the field of SER systems.
RI Mujtaba, Ghulam/AAW-4254-2021; Jahangir, Rashid/AAT-6804-2021; TEH, YING
   WAH/B-9938-2010
OI TEH, YING WAH/0000-0002-3202-7035; JAHANGIR, RASHID/0000-0003-1129-6006
SN 1380-7501
EI 1573-7721
PD JUL
PY 2021
VL 80
IS 16
BP 23745
EP 23812
DI 10.1007/s11042-020-09874-7
EA JAN 2021
UT WOS:000604225300001
ER

PT J
AU Jenner, AL
   Aogo, RA
   Davis, CL
   Smith, AM
   Craig, M
AF Jenner, Adrianne L.
   Aogo, Rosemary A.
   Davis, Courtney L.
   Smith, Amber M.
   Craig, Morgan
TI Leveraging Computational Modeling to Understand Infectious Diseases
SO CURRENT PATHOBIOLOGY REPORTS
AB Purpose of Review Computational and mathematical modeling have become a critical part of understanding in-host infectious disease dynamics and predicting effective treatments. In this review, we discuss recent findings pertaining to the biological mechanisms underlying infectious diseases, including etiology, pathogenesis, and the cellular interactions with infectious agents. We present advances in modeling techniques that have led to fundamental disease discoveries and impacted clinical translation.
   Recent Findings Combining mechanistic models and machine learning algorithms has led to improvements in the treatment ofShigellaand tuberculosis through the development of novel compounds. Modeling of the epidemic dynamics of malaria at the within-host and between-host level has afforded the development of more effective vaccination and antimalarial therapies. Similarly, in-host and host-host models have supported the development of new HIV treatment modalities and an improved understanding of the immune involvement in influenza. In addition, large-scale transmission models of SARS-CoV-2 have furthered the understanding of coronavirus disease and allowed for rapid policy implementations on travel restrictions and contract tracing apps.
   Summary Computational modeling is now more than ever at the forefront of infectious disease research due to the COVID-19 pandemic. This review highlights how infectious diseases can be better understood by connecting scientists from medicine and molecular biology with those in computer science and applied mathematics.
RI Jenner, Adrianne/ABE-4991-2021
OI Jenner, Adrianne/0000-0001-9103-7092; Craig, Morgan/0000-0003-4852-4770;
   Davis, Courtney/0000-0002-3274-5707
EI 2167-485X
PD DEC
PY 2020
VL 8
IS 4
BP 149
EP 161
DI 10.1007/s40139-020-00213-x
EA SEP 2020
UT WOS:000574576100001
PM 32989410
ER

PT J
AU Gridach, M
AF Gridach, Mourad
TI A framework based on (probabilistic) soft logic and neural network for
   NLP
SO APPLIED SOFT COMPUTING
AB Deep neural networks have emerged as a flexible framework that achieved state-of-the-art performance in many NLP applications such as machine translation, named entity recognition, sentiment analysis, and part-of-speech tagging. The main advantage of these neural models is their ability to learn useful representations without hand-engineering features. While this success, these models still suffer from the interpretability issue. More recently, probabilistic soft logic (PSL) is a promising framework based on first-order logic that achieves interesting results in both computer vision and NLP by capturing semantic relationships between entities. Moreover, unifying knowledge-driven modeling approaches and data-driven approaches is a promising framework that will have an exciting impact on structured prediction problems. In this paper, we developed NeuralGLogic a generalization framework of the previous model proposed by Huet al. (2016) that combines deep neural networks with logic rules built either using Soft Logic (SL) or Probabilistic Soft Logic (PSL). Furthermore, we evaluate our framework on different neural network architectures applied to two NLP tasks: sentiment classification and part-of-speech tagging. Experimental results showed that we were able to improve the results over the baselines and outperformed all the previous state-of-the-art systems emphasizing the utility of both SL and PSL rules in reducing the uninterpretability of the neural models thus validating our intuition. (C) 2020 Elsevier B.V. All rights reserved.
OI Gridach, Mourad/0000-0002-7998-0448
SN 1568-4946
EI 1872-9681
PD AUG
PY 2020
VL 93
AR 106232
DI 10.1016/j.asoc.2020.106232
UT WOS:000554903300018
ER

PT J
AU Palasundram, K
   Sharef, NM
   Nasharuddin, NA
   Kasmiran, KA
   Azman, A
AF Palasundram, Kulothunkan
   Sharef, Nurfadhlina Mohd
   Nasharuddin, Nurul Amelina
   Kasmiran, Khairul Azhar
   Azman, Azreen
TI Sequence to Sequence Model Performance for Education Chatbot
SO INTERNATIONAL JOURNAL OF EMERGING TECHNOLOGIES IN LEARNING
AB Chatbot for education has great potential to complement human educators and education administrators. For example, it can be around the clock tutor to answer and clarify any questions from students who may have missed class. A chatbot can be implemented either by ruled based or artificial intelligence based. However, unlike the ruled-based chatbots, artificial intelligence based chatbots can learn and become smarter overtime and is more scalable and has become the popular choice for chatbot researchers recently. Recurrent Neural Network based Sequence-to-sequence (Seq2Seq) model is one of the most commonly researched model to implement artificial intelligence chatbot and has shown great progress since its introduction in 2014. However, it is still in infancy and has not been applied widely in educational chatbot development. Introduced originally for neural machine translation, the Seq2Seq model has been adapted for conversation modelling including question-answering chatbots. However, indepth research and analysis of optimal settings of the various components of Seq2Seq model for natural answer generation problem is very limited. Additionally, there has been no experiments and analysis conducted to understand how Seq2Seq model handles variations is questions posed to it to generate correct answers. Our experiments add to the empirical evaluations on Seq2Seq literature and provides insights to these questions. Additionally, we provide insights on how a curated dataset can be developed and questions designed to train and test the performance of a Seq2Seq based question-answer model.
RI /FSKTM, NURFADHLINA BINTI MOHD SHAREF/AAK-2591-2020; Nasharuddin, Nurul
   Amelina/D-4579-2017
OI /FSKTM, NURFADHLINA BINTI MOHD SHAREF/0000-0003-4335-0513; Nasharuddin,
   Nurul Amelina/0000-0003-2872-5110; Palasundram,
   Kulothunkan/0000-0001-8043-3620
SN 1863-0383
PY 2019
VL 14
IS 24
BP 56
EP 68
DI 10.3991/ijet.v14i24.12187
UT WOS:000503721300006
ER

PT J
AU Vrejoiu, MH
AF Vrejoiu, Mihnea Horia
TI Deep Reinforcement Learning. Case Study: Deep Q-Network
SO ROMANIAN JOURNAL OF INFORMATION TECHNOLOGY AND AUTOMATIC CONTROL-REVISTA
   ROMANA DE INFORMATICA SI AUTOMATICA
AB Artificial Intelligence (AI) became today perhaps the most up-to-date topic in many areas. One of the main goals of AI is to create completely autonomous agents able to interact with the surrounding world and learn by trial and error optimal behaviors in different contexts, perfectible in time. Among the machine learning methods of AI, reinforcement learning (RL) by repetitive interactions with the environment while targeting a purpose plays a particularly important role, besides supervised and unsupervised learning. However, classical RL methods have important limitations in scalability to higher-dimensionality problems. In recent years, supervised and unsupervised learning technologies based on deep learning, using deep neural networks with remarkable properties of approximating complex functions on multi-dimensional spaces, as well as the learning of characteristic hierarchical representations automatically extracted directly from data, with significant dimensional reduction, have had an explosive development, producing astonishing results comparable with, or even surpasing human performance in areas such as object / image recognition, speech recognition, automatic translation etc. The combination of RL with deep learning methods has led to what is now called deep reinforcement learning (DRL), providing new possibilities for producing autonomous agents in multidimensional spaces. This paper is proposing a brief presentation of the DRL field, while also studying and analyzing in detail one of the first successful DRL methods, namely Deep Q-Network developed by Google DeepMind.
SN 1220-1758
EI 1841-4303
PY 2019
VL 29
IS 3
BP 65
EP 78
DI 10.33436/v29i3y201906
UT WOS:000489010300006
ER

PT J
AU Sadtler, PT
   Ryu, SI
   Tyler-Kabara, EC
   Yu, BM
   Batista, AP
AF Sadtler, P. T.
   Ryu, S. I.
   Tyler-Kabara, E. C.
   Yu, B. M.
   Batista, A. P.
TI Brain-computer interface control along instructed paths
SO JOURNAL OF NEURAL ENGINEERING
AB Objective. Brain-computer interfaces (BCIs) are being developed to assist paralyzed people and amputees by translating neural activity into movements of a computer cursor or prosthetic limb. Here we introduce a novel BCI task paradigm, intended to help accelerate improvements to BCI systems. Through this task, we can push the performance limits of BCI systems, we can quantify more accurately how well a BCI system captures the user's intent, and we can increase the richness of the BCI movement repertoire. Approach. We have implemented an instructed path task, wherein the user must drive a cursor along a visible path. The instructed path task provides a versatile framework to increase the difficulty of the task and thereby push the limits of performance. Relative to traditional point-to-point tasks, the instructed path task allows more thorough analysis of decoding performance and greater richness of movement kinematics. Main results. We demonstrate that monkeys are able to perform the instructed path task in a closed-loop BCI setting. We further investigate how the performance under BCI control compares to native arm control, whether users can decrease their movement variability in the face of a more demanding task, and how the kinematic richness is enhanced in this task. Significance. The use of the instructed path task has the potential to accelerate the development of BCI systems and their clinical translation.
RI Tyler-Kabara, Elizabeth/H-4930-2013
OI Tyler-Kabara, Elizabeth/0000-0003-3286-1094; Batista,
   Aaron/0000-0002-1719-0061
SN 1741-2560
EI 1741-2552
PD FEB
PY 2015
VL 12
IS 1
AR 016015
DI 10.1088/1741-2560/12/1/016015
UT WOS:000348762500017
PM 25605498
ER

PT C
AU Tiedemann, J
AF Tiedemann, Jorg
BE Gelbukh, A
TI Improved Text Extraction from PDF Documents for Large-Scale Natural
   Language Processing
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING, CICLING 2014,
   PT I
SE Lecture Notes in Computer Science
CT 15th Annual Conference on Intelligent Text Processing and Computational
   Linguistics (CICLing)
CY APR 06-12, 2014
CL Ctr Commun & Dev, Kathmandu, NEPAL
SP Inst Politecnico Nacl Centro Invest Computac Nat Language &Text Proc Lab, Mexican Soc Artificial Intelligence
HO Ctr Commun & Dev
AB The inability of reliable text extraction from arbitrary documents is often an obstacle for large scale NLP based on resources crawled from the Web. One of the largest problems in the conversion of PDF documents is the detection of the boundaries of common textual units such as paragraphs, sentences and words. PDF is a file format optimized for printing and encapsulates a complete description of the layout of a document including text, fonts, graphics and so on. This paper describes a tool for extracting texts from arbitrary PDF files for the support of large-scale data-driven natural language processing. Our approach combines the benefits of several existing solutions for the conversion of PDF documents to plain text and adds a language-independent post-processing procedure that cleans the output for further linguistic processing. In particular, we use the PDF-rendering libraries pdfXtk, Apache Tika and Poppler in various configurations. From the output of these tools we recover proper boundaries using on-the-fly language models and language-independent extraction heuristics. In our research, we looked especially at publications from the European Union, which constitute a valuable multilingual resource, for example, for training statistical machine translation models. We use our tool for the conversion of a large multilingual database crawled from the EU bookshop with the aim of building parallel corpora. Our experiments show that our conversion software is capable of fixing various common issues leading to cleaner data sets in the end.
OI Tiedemann, Jorg/0000-0003-3065-7989
SN 0302-9743
BN 978-3-642-54905-2; 978-3-642-54906-9
PY 2014
VL 8403
BP 102
EP 112
UT WOS:000342989200009
ER

PT C
AU Khanna, N
   Abdollahian, G
   Brame, B
   Boutin, M
   Delp, EJ
AF Khanna, Nitin
   Abdollahian, Golnaz
   Brame, Ben
   Boutin, Mireille
   Delp, Edward J.
BE Bouman, CA
   Pollak, I
   Wolfe, PJ
TI Arabic Word Recognizer for Mobile Applications
SO COMPUTATIONAL IMAGING IX
SE Proceedings of SPIE
CT Conference on Computational Imaging IX
CY JAN 24-25, 2011
CL San Francisco, CA
SP Soc Imaging Sci & Technol, SPIE, GE Healthcare
AB When traveling in a region where the local language is not written using a "Roman alphabet," translating written text (e. g., documents, road signs, or placards) is a particularly difficult problem since the text cannot be easily entered into a translation device or searched using a dictionary. To address this problem, we are developing the "Rosetta Phone," a handheld device (e. g., PDA or mobile telephone) capable of acquiring an image of the text, locating the region (word) of interest within the image, and producing both an audio and a visual English interpretation of the text. This paper presents a system targeted for interpreting words written in Arabic script. The goal of this work is to develop an autonomous, segmentation-free Arabic phrase recognizer, with computational complexity low enough to deploy on a mobile device. A prototype of the proposed system has been deployed on an iPhone with a suitable user interface. The system was tested on a number of noisy images, in addition to the images acquired from the iPhone's camera. It identifies Arabic words or phrases by extracting appropriate features and assigning "codewords" to each word or phrase. On a dictionary of 5,000 words, the system uniquely mapped (word-image to codeword) 99.9% of the words. The system has a 82% recognition accuracy on images of words captured using the iPhone's built-in camera.
RI Khanna, Nitin/A-2068-2013; Delp, Edward J/C-3616-2013
OI Khanna, Nitin/0000-0001-7571-9130; Delp, Edward J/0000-0002-2909-7323;
   Boutin, Mireille/0000-0002-0837-6577
SN 0277-786X
EI 1996-756X
BN 978-0-8194-8410-9
PY 2011
VL 7873
AR 78730J
DI 10.1117/12.876810
UT WOS:000293787600015
ER

PT C
AU Wang, W
   Li, BC
   King, I
AF Wang, Wei
   Li, Baichuan
   King, Irwin
GP IEEE
TI Improving Question Retrieval in Community Question Answering with Label
   Ranking
SO 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY JUL 31-AUG 05, 2011
CL San Jose, CA
SP Int Neural Network Soc (INNS), IEEE Computat Intelligence Soc (CIS), Natl Sci Fdn (NSF), Cognimem Technol, Inc, Univ Cincinnati Coll Engn & Appl Sci, Toyota Res Inst N Amer, Univ Cincinnati, Sch Elect & Compu Syst
AB Community question answering services (CQA), which provides a platform for people with diverse backgrounds to share information and knowledge, has become an increasingly popular research topic recently as made popular by sites such as Yahoo! Answers(1), answerbag(2), zhidao(3), etc. Question retrieval (QR) in CQA can automatically find the most relevant and recent questions that have been solved by other users. Current QR approaches typically consider using diverse retrieval models, but they fail to analyze users' intention. User intentions such as finding facts, interacting with others, seeking reasons, etc. reflect what the users really want to know. Hence, we propose to integrate user intention analysis into QR. Firstly, we classify questions into different and multiple types of users' intentions. Another practical problem is that there naturally exist some preferences among the possible questions types. The more relevant type should be ranked higher than types which are not so relevant. Therefore, we propose to utilize a novel label ranking method, which is a machine learning algorithm that aims to predict a ranking among all the possible labels, to perform question classification. Secondly, based on the result of question classification, we integrate user intentions with translation-based language models to explore whether a user's intention does help to improve the performance. We conduct a series of experiments with Yahoo data, and the experimental results demonstrate that our proposed improved question retrieval can indeed enhance the performance of traditional question retrieval model.
RI King, Irwin/C-9681-2015
OI King, Irwin/0000-0001-8106-6447
BN 978-1-4244-9636-5
PY 2011
BP 349
EP 356
UT WOS:000297541200052
ER

PT J
AU Wang, HD
   Shen, X
   Tu, M
   Zhuang, YM
   Liu, ZY
AF Wang, Huadong
   Shen, Xin
   Tu, Mei
   Zhuang, Yimeng
   Liu, Zhiyuan
TI Improved Transformer With Multi-Head Dense Collaboration
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB Recently, the attention mechanism boosts the performance of many neural network models in Natural Language Processing (NLP). Among the various attention mechanisms, Multi-Head Attention (MHA) is a powerful and popular variant. MHA helps the model to attend to different feature subspaces independently which is an essential component of Transformer. Despite its success, we conjecture that the different heads of the existing MHA may not collaborate properly. To validate this assumption and further improve the performance of Transformer, we study the collaboration problem for MHA in this paper. First, we propose the Single-Layer Collaboration (SLC) mechanism to help each attention head improve its attention distribution based on the feedback of other heads. Furthermore, we extend SLC to the cross-layer Multi-Head Dense Collaboration (MHDC) mechanism. MHDC helps each MHA layer learn the attention distributions considering the knowledge from the other MHA layers. Both SLC and MHDC are implemented as lightweight modules with very few additional parameters. When equipped with these modules, our new framework, i.e., Collaborative TransFormer (CollFormer), significantly outperforms the vanilla Transformer on a range of NLP tasks, including machine translation, sentence semantic relatedness, natural language inference, sentence classification, and reading comprehension. Besides, we also carry out extensive quantitative experiments to analyze the properties of the MHDC in different settings. The experimental results validate the effectiveness and universality of MHDC as well as CollFormer.
OI Liu, Zhiyuan/0000-0002-7709-2543
SN 2329-9290
EI 2329-9304
PY 2022
VL 30
BP 2754
EP 2767
DI 10.1109/TASLP.2022.3199648
UT WOS:000848214900002
ER

PT C
AU Athanasiou, LS
   Olender, ML
   Hernandez, JMD
   Ben-Assa, E
   Edelman, ER
AF Athanasiou, Lambros S.
   Olender, Max L.
   de la Torre Hernandez, Jose M.
   Ben-Assa, Eyal
   Edelman, Elazer R.
BE Mori, K
   Hahn, HK
TI A deep learning approach to classify atherosclerosis using intracoronary
   optical coherence tomography
SO MEDICAL IMAGING 2019: COMPUTER-AIDED DIAGNOSIS
SE Proceedings of SPIE
CT Conference on Medical Imaging - Computer-Aided Diagnosis
CY FEB 17-20, 2019
CL San Diego, CA
SP SPIE
AB Optical coherence tomography (OCT) is a fiber-based intravascular imaging modality that produces high-resolution tomographic images of artery lumen and vessel wall morphology. Manual analysis of the diseased arterial wall is time consuming and sensitive to inter-observer variability; therefore, machine-learning methods have been developed to automatically detect and classify mural composition of atherosclerotic vessels. However, none of the tissue classification methods include in their analysis the outer border of the OCT vessel, they consider the whole arterial wall as pathological, and they do not consider in their analysis the OCT imaging limitations, e.g. shadowed areas. The aim of this study is to present a deep learning method that subdivides the whole arterial wall into six different classes: calcium, lipid tissue, fibrous tissue, mixed tissue, non-pathological tissue or media, and no visible tissue. The method steps include defining wall area (WAR) using previously developed lumen and outer border detection methods, and automatic characterization of the WAR using a convolutional neural network (CNN) algorithm. To validate this approach, 700 images of diseased coronary arteries from 28 patients were manually annotated by two medical experts, while the non-pathological wall and media was automatically detected based on the Euclidian distance of the lumen to the outer border of the WAR. Using the proposed method, an overall classification accuracy 96% is reported, indicating great promise for clinical translation.
RI Athanasiou, Lambros/AGI-1375-2022; Ben Assa, Eyal/GXG-1374-2022;
   Olender, Max/AAV-3393-2021
OI Athanasiou, Lambros/0000-0002-8029-1332; Ben Assa,
   Eyal/0000-0003-2677-9107; Olender, Max/0000-0002-0936-5300
SN 0277-786X
EI 1996-756X
BN 978-1-5106-2548-8
PY 2019
VL 10950
AR UNSP 109500N
DI 10.1117/12.2513078
UT WOS:000491309500022
ER

PT C
AU Passi, S
   Barocas, S
AF Passi, Samir
   Barocas, Solon
GP Assoc Comp Machinery
TI Problem Formulation and Fairness
SO FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY,
   AND TRANSPARENCY
CT ACM Conference on Fairness, Accountability, and Transparency (FAT)
CY JAN 29-31, 2019
CL Atlanta, GA
SP Assoc Comp Machinery
AB Formulating data science problems is an uncertain and difficult process. It requires various forms of discretionary work to translate high-level objectives or strategic goals into tractable problems, necessitating, among other things, the identification of appropriate target variables and proxies. While these choices are rarely self-evident, normative assessments of data science projects often take them for granted, even though different translations can raise profoundly different ethical concerns. Whether we consider a data science project fair often has as much to do with the formulation of the problem as any property of the resulting model. Building on six months of ethnographic fieldwork with a corporate data science team-and channeling ideas from sociology and history of science, critical data studies, and early writing on knowledge discovery in databases-we describe the complex set of actors and activities involved in problem formulation. Our research demonstrates that the specification and operationalization of the problem are always negotiated and elastic, and rarely worked out with explicit normative considerations in mind. In so doing, we show that careful accounts of everyday data science work can help us better understand how and why data science problems are posed in certain ways-and why specific formulations prevail in practice, even in the face of what might seem like normatively preferable alternatives. We conclude by discussing the implications of our findings, arguing that effective normative interventions will require attending to the practical work of problem formulation.
RI Passi, Samir/L-3182-2019
OI Passi, Samir/0000-0002-7921-3820; Barocas, Solon/0000-0003-4577-466X
BN 978-1-4503-6125-5
PY 2019
BP 39
EP 48
DI 10.1145/3287560.3287567
UT WOS:000473814700005
ER

PT J
AU Anand, S
   Sutanto, J
   Baker, MS
   Okandan, M
   Muthuswamy, J
AF Anand, Sindhu
   Sutanto, Jemmy
   Baker, Michael S.
   Okandan, Murat
   Muthuswamy, Jit
TI Electrothermal Microactuators With Peg Drive Improve Performance for
   Brain Implant Applications
SO JOURNAL OF MICROELECTROMECHANICAL SYSTEMS
AB This paper presents a new actuation scheme for in-plane bidirectional translation of polysilicon micro-electrodes. The new Chevron-peg actuation scheme uses micro-electromechanical systems (MEMS) based electrothermal microactuators to move microelectrodes for brain implant applications. The design changes were motivated by specific needs identified by the in vivo testing of an earlier generation of MEMS microelectrodes that were actuated by the Chevron-latch type of mechanism. The microelectrodes actuated by the Chevron-peg mechanism discussed here show improved performance in the following key areas: higher force generation capability (111 mu N per heat strip compared to 50 mu N), reduced power consumption (91 mW compared to 360 mW), and reliable performance with consistent forward and backward movements of microelectrodes. Failure analysis of the Chevron-latch and the Chevron-peg type of actuation schemes showed that the latter is more robust to wear over four million cycles of operation. The parameters for the activation waveforms for Chevron-peg actuators were optimized using statistical analysis. Waveforms with a 1-ms time period and a 1-Hz frequency of operation showed minimal error between the expected and the actual movement of the microelectrodes. The new generation of Chevron-peg actuators and microelectrodes are therefore expected to enhance the longevity and performance of implanted microelectrodes in the brain.
OI Muthuswamy, Jit/0000-0003-3924-9869
SN 1057-7157
EI 1941-0158
PD OCT
PY 2012
VL 21
IS 5
BP 1172
EP 1186
DI 10.1109/JMEMS.2012.2203789
UT WOS:000309731400021
PM 24431926
ER

PT J
AU Zhang, SJ
   To, S
   Cheung, CF
   Du, JJ
AF Zhang, Shao-Jian
   To, Suet
   Cheung, Chi-Fai
   Du, Jian-Jun
TI Novel Auto-regressive Measurement of Diamond Tool Wear in
   Ultra-precision Raster Milling
SO INTERNATIONAL JOURNAL OF PRECISION ENGINEERING AND MANUFACTURING
AB In this paper, a new auto-regressive algorithm is proposed to reconstruct 3D topographic surface for diamond tool wear, using its in-process image. First, based on digital image processing technique, tool wear lands are separated from a tool wear image captured by a CCD camera under a 100X optical system; Second, a traverse search method of arc translation is put forward to eliminate feigned wear lands, and a least square polynomial method is adopted to fit inner- and outer-contours of the wear lands, self-adaptively filtering noises and connecting the discontinuous wear lands; Finally, the auto-regressive calibration method is developed to reconstruct its 3D topographic surface. The wear land is extracted self-adaptively, and the wear area, maximal wear width, average wear width and worn volume can be determined automatically by the algorithm. The reconstructed 3D topography of the tool wear land can be identified, based on the tool wear image captured by SEM The result indicates that the method is capable of reconstructing 3D topography of the tool wear land and provides a possibility for in-process 3D-wear measurement in ultra-precision raster milling (UPRM and the algorithm reliability is validated finally And the influence of tool wear on surface roughness is discussed.
RI Cheung, Chi Fai/B-1146-2008; To, Sandy/M-2815-2015; Fai, Cheung
   Chi/ABC-1100-2020
OI Cheung, Chi Fai/0000-0002-6066-7419; To, Sandy/0000-0002-1676-7770; Fai,
   Cheung Chi/0000-0002-6066-7419; Zhang, Shaojian/0000-0002-5740-4765
SN 2234-7593
PD SEP
PY 2012
VL 13
IS 9
BP 1661
EP 1670
DI 10.1007/s12541-012-0218-9
UT WOS:000308447100021
ER

PT J
AU Artusi, X
   Niazi, IK
   Lucas, MF
   Farina, D
AF Artusi, Xavier
   Niazi, Imran Khan
   Lucas, Marie-Francoise
   Farina, Dario
TI Performance of a Simulated Adaptive BCI Based on Experimental
   Classification of Movement-Related and Error Potentials
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
AB New paradigms for brain-computer interfacing (BCI), such as based on imagination of task characteristics, require long training periods, have limited accuracy, and lack adaptation to the changes in the users' conditions. Error potentials generated in response to an error made by the translation algorithm can be used to improve the performance of a BCI, as a feedback extracted from the user and fed into the BCI system. The present study addresses the inclusion of error potentials in a BCI system based on the decoding of movement-related cortical potentials (MRCPs) associated to the speed of a task. First, we theoretically quantified the improvement in accuracy of a BCI system when using error potentials for correcting the output decision, in the general case of multiclass BCI. The derived theoretical expressions can be used during the design phase of any BCI system. They were applied to experimentally estimated accuracies in decoding MRCPs and error potentials. Second we studied in simulation the performance of the closed-loop system in order to evaluate its ability to adapt to the changes in the mental states of the user. By setting the parameters of the simulator to experimentally determined values, we showed that updating the learning set with the examples estimated as correct based on the decoding of error potentials leads to convergence to the optimal solution.
RI Farina, Dario/AAB-2648-2019; Niazi, Imran Khan/M-3346-2019
OI Niazi, Imran Khan/0000-0001-8752-7224
SN 2156-3357
PD DEC
PY 2011
VL 1
IS 4
BP 480
EP 488
DI 10.1109/JETCAS.2011.2177920
UT WOS:000208972600006
ER

PT J
AU Chew, PA
   Bader, BW
   Helmreich, S
   Abdelali, A
   Verzi, SJ
AF Chew, Peter A.
   Bader, Brett W.
   Helmreich, Stephen
   Abdelali, Ahmed
   Verzi, Stephen J.
TI An information-theoretic, vector-space-model approach to cross-language
   information retrieval
SO NATURAL LANGUAGE ENGINEERING
AB In this article, we demonstrate several novel ways in which insights from information theory (IT) and computational linguistics (CL) can be woven into a vector-space-model (VSM) approach to information retrieval (IR). Our proposals focus, essentially, on three areas: preprocessing (morphological analysis), term weighting, and alternative geometrical models to the widely used term-by-document matrix. The latter include (1) PARAFAC2 decomposition of a term-by-document-by-language tensor, and (2) eigenvalue decomposition of a term-by-term matrix (inspired by Statistical Machine Translation). We evaluate all proposals, comparing them to a 'standard' approach based on Latent Semantic Analysis, on a multilingual document clustering task. The evidence suggests that proper consideration of IT within IR is indeed called for: in all cases, our best results are achieved using the information-theoretic variations upon the standard approach. Furthermore, we show that different information-theoretic options can be combined for still better results. A key function of language is to encode and convey information, and contributions of IT to the field of CL can be traced back a number of decades. We think that our proposals help bring I R and CL more into line with one another. In our conclusion, we suggest that the fact that our proposals yield empirical improvements is not coincidental given that they increase the theoretical transparency of VSM approaches to ER; on the contrary, they help shed light on why aspects of these approaches work as they do.
RI Verzi, Stephen/AAA-8442-2022
OI Abdelali, Ahmed/0000-0002-4160-8181; Verzi, Stephen/0000-0003-2152-851X
SN 1351-3249
EI 1469-8110
PD JAN
PY 2011
VL 17
BP 37
EP 70
DI 10.1017/S1351324910000185
PN 1
UT WOS:000286996800002
ER

PT J
AU Yellaboina, S
   Goyal, K
   Mande, SC
AF Yellaboina, Sailu
   Goyal, Kshama
   Mande, Shekhar C.
TI Inferring genome-wide functional linkages in E-coli by combining
   improved genome context methods: Comparison with high-throughput
   experimental data
SO GENOME RESEARCH
AB Cellular functions are determined by interactions among proteins in the cells. Recognition of these interactions forms an important step in understanding biology at the systems level. Here, we report an interaction network of Escherichia coli, obtained by training a Support Vector Machine on the high quality of interactions in the EcoCyc database, and with the assumption that the periplasmic and cytoplasmic proteins may not interact with each other. The data features included correlation coefficient between bit score phylogenetic profiles, frequency of their co-occurrence in predicted operons, and a new measure - the distance between translational start sites of the genes. The combined genome context methods show a high accuracy of prediction on the test data and predict a total of 78,122 binary interactions. The majority of the interactions identified by high-throughput experimental methods correspond to indirect interaction (interactions through neighbors) in the predicted network. Correlation of the predicted network with the gene essentiality data shows that the essential genes in E. coli exhibit a high linking number, whereas the nonessential genes exhibit a low linking number. Furthermore, our predicted protein - protein interaction network shows that the proteins involved in replication, DNA repair, transcription, translation, and cell wall synthesis are highly connected. We therefore believe that our predicted network will serve as a useful resource in understanding prokaryotic biology.
RI Mande, Shekhar/C-2136-2012
SN 1088-9051
EI 1549-5469
PD APR
PY 2007
VL 17
IS 4
BP 527
EP 535
DI 10.1101/gr.5900607
UT WOS:000245397300015
PM 17339371
ER

PT C
AU Wilks, Y
   Catizone, R
AF Wilks, Y
   Catizone, R
BE Bramer, M
   Macintosh, A
   Coenen, F
TI Can we make Information Extraction more adaptive?
SO RESEARCH AND DEVELOPMENT IN INTELLIGENT SYSTEMS XVI
SE B C S CONFERENCE SERIES
CT 19th SGES International Conference on Knowledge-Based Systems and
   Applied Artificial Intelligence (ES99)
CY DEC 13-15, 1999
CL CAMBRIDGE, ENGLAND
SP SGES, Appl AI
AB It seems widely agreed that IE (Information Extraction) is now a tested language technology that has reached precision+recall values that put it in about the same position as Information Retrieval and Machine translation, both of which are widely used commercially. There is also a clear range of practical applications that would be eased by the sort of template-style data that IE provides. The problem for wider deployment of the technology is adaptability: the ability to customize IE rapidly to new domains.
   In this paper we discuss some methods that have been tried to ease this problem, and to create something more rapid than the bench-mark one-month figure, which was roughly what ARPA teams in IE needed to adapt an existing system by hand to a new domain of corpora and templates. An important distinction in discussing the issue is the degree to which a user can be assumes to know what is wanted, to have pre-existing templates ready to hand, as opposed to a user whoa has a vague idea of what is needed from a corpus.
   We shall discuss attempts to derive templates directly from corpora; to derive knowledge structures and lexicons directly from corpora, including discussion of the recent LE project ECRAN which attempts to tune existing lexicons to new corpora. An important issue is how far established methods in Information Retrieval of tuning to a user's needs with feedback at an interface can be transferred to IE.
BN 1-85233-231-X
PY 2000
BP 3
EP 20
UT WOS:000086321700001
ER

PT J
AU Wibowo, AP
   Adha, A
   Kurniawan, IF
   Laory, I
AF Wibowo, Andi Prasetiyo
   Adha, Augusta
   Kurniawan, Ibnu F.
   Laory, Irwanda
TI Wall Crack Multiclass Classification: Expertise-Based Dataset
   Construction and Learning Algorithms Performance Comparison
SO BUILDINGS
AB Wall crack detection is one of the primary tasks in determining the structural integrity of a building for both restorative and preventive attempts. Machine learning techniques, such as deep learning (DL) with computer vision capabilities, have gradually become more prevalent as they can provide expert assessments with an acceptable performance when the crack detection involves a considerable number of structures. Despite such a prospective application, classification on different types of wall cracks is relatively less common, possibly due to the absence of the professional-standard-to-dataset translation. In this work, we utilised a complete pipeline, starting from novel dataset construction, ground truth formulation based on civil engineering standards, and training and testing steps. Our work focused on multi-class classification with regard to the binary classification (i.e., determining only two categories) used in previous studies. We implemented transfer learning based on VGG16 and RestNET50 for feature extraction, combined them with an ANN and kNN for the classifier, and compared their prediction performances. Our results indicate that the developed models can distinguish images that contain wall cracks into three categories of features based on the degree of damage: light, medium, and severe. Furthermore, since greyscale images offer more precise readings and predictions, the use of augmentation in dataset generation is critical. Although ResNet50 is the most stable network in terms of accuracy, it performs better when paired with kNN.
OI Adha, Augusta/0000-0002-7363-9417; Wibowo, Andi
   Prasetiyo/0000-0003-0060-3728; Kurniawan, Ibnu Febry/0000-0002-5584-2390
EI 2075-5309
PD DEC
PY 2022
VL 12
IS 12
AR 2135
DI 10.3390/buildings12122135
UT WOS:000902249100001
ER

PT J
AU Eryigit, G
   Sentas, A
   Monti, J
AF Eryigit, GulSen
   Sentas, Ali
   Monti, Johanna
TI Gamified crowdsourcing for idiom corpora construction
SO NATURAL LANGUAGE ENGINEERING
AB Learning idiomatic expressions is seen as one of the most challenging stages in second-language learning because of their unpredictable meaning. A similar situation holds for their identification within natural language processing applications such as machine translation and parsing. The lack of high-quality usage samples exacerbates this challenge not only for humans but also for artificial intelligence systems. This article introduces a gamified crowdsourcing approach for collecting language learning materials for idiomatic expressions; a messaging bot is designed as an asynchronous multiplayer game for native speakers who compete with each other while providing idiomatic and nonidiomatic usage examples and rating other players' entries. As opposed to classical crowd-processing annotation efforts in the field, for the first time in the literature, a crowd-creating & crowd-rating approach is implemented and tested for idiom corpora construction. The approach is language-independent and evaluated on two languages in comparison to traditional data preparation techniques in the field. The reaction of the crowd is monitored under different motivational means (namely, gamification affordances and monetary rewards). The results reveal that the proposed approach is powerful in collecting the targeted materials, and although being an explicit crowdsourcing approach, it is found entertaining and useful by the crowd. The approach has been shown to have the potential to speed up the construction of idiom corpora for different natural languages to be used as second-language learning material, training data for supervised idiom identification systems, or samples for lexicographic studies.
RI Eryiğit, Gülşen/O-4106-2016; Alidadi, Mehdi/HJZ-0235-2023
OI Eryiğit, Gülşen/0000-0003-4607-7305; Alidadi, Mehdi/0000-0001-5183-7829
SN 1351-3249
EI 1469-8110
AR PII S1351324921000401
DI 10.1017/S1351324921000401
EA JAN 2022
UT WOS:000744690600001
ER

PT C
AU Ezennaya-Gomez, S
   Vielhauer, C
   Dittmann, J
AF Ezennaya-Gomez, Salatiel
   Vielhauer, Claus
   Dittmann, Jana
BE Katsikas, S
   Lambrinoudakis, C
   Cuppens, N
   Mylopoulos, J
   Kalloniatis, C
   Meng, W
   Furnell, S
   Pallas, F
   Pohle, J
   Sasse, MA
   Abie, H
   Ranise, S
   Verderame, L
   Cambiaso, E
   Vidal, JM
   Monge, MAS
TI A Semantic Model for Embracing Privacy as Contextual Integrity in the
   Internet of Things (Short Paper)
SO COMPUTER SECURITY: ESORICS 2021 INTERNATIONAL WORKSHOPS
SE Lecture Notes in Computer Science
CT 26th European Symposium on Research in Computer Security (ESORICS) /
   16th Data Privacy Management International Workshop (DPM) / 5th
   International Workshop on Cryptocurrencies and Blockchain Technology
   (CBT)
CY OCT 04-08, 2021
CL Natl Res Ctr Appl Cybersecur, Fraunhofer Inst Secure Informat Technol,
   ELECTR NETWORK
SP Inst Mines Telecom, Inst Polytechnique Paris, Univ Autonoma Barcelona, Univ Politecnica Catalunya, UNESCO Chair Data Privacy, Cybercat, Inria, IRT SYSTEMX, Bandit
HO Natl Res Ctr Appl Cybersecur, Fraunhofer Inst Secure Informat Technol
AB Due to the increasing number of complaints alleging privacy violations against companies to data protection authorities, the translation of business goals to system design goals and the subsequent consequences for customers' privacy poses a challenge for many companies. For this reason, there is a need to bridge the economics of privacy and threats to privacy. To this end, our work relies on the concept of privacy as contextual integrity. This framework defines privacy as appropriate information flows subjected to social norms within particular social contexts or spheres. In this paper, we introduce a preliminary version of a semantic model which aims to relate and provide understanding on how well-established business goals may affect their customers' privacy by designing IoT devices with permission access, data acquired by sensors, among other factors. Finally, we provide a use case application showing how to use the semantic model. The model aims to be an educational tool for professionals in business informatics during the modeling and designing process of a product which may gather sensitive data or may infer sensitive information, giving an understanding of the interaction of the product and its footprint with diverse actors (humans or machines). In the future, a further complete model of the presented may also target other groups, such as law enforcement bodies, as part of their educational training in such systems.
SN 0302-9743
EI 1611-3349
BN 978-3-030-95484-0; 978-3-030-95483-3
PY 2022
VL 13106
BP 413
EP 423
DI 10.1007/978-3-030-95484-0_24
UT WOS:000771723100024
ER

PT J
AU Zhou, Z
   Li, FM
   Yang, SQ
AF Zhou, Zhou
   Li, Fangmin
   Yang, Shuiqiao
TI A Novel Resource Optimization Algorithm Based on Clustering and Improved
   Differential Evolution Strategy Under a Cloud Environment
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB Resource optimization algorithm based on clustering and improved differential evolution strategy, as a new global optimized algorithm, has wide applications in language translation, language processing, document understanding, cloud computing, and edge computing due to high efficiency. With the development of deep learning technology and the rise of big data, the resource optimization algorithm encounters a series of challenges, such as the workload imbalance and low resource utilization. To address the preceding problems, this study proposes a novel resource optimization algorithm based on clustering and an improved differential evolution strategy (Multi-objective Task Scheduling Strategy (MTSS)). Three indexes, namely task completion time, execution cost, and workload, of virtual machines are selected and used to build the fitness function of the MTSS algorithm. At the same time, the preprocessing state is set up to cluster according to the resource and task characteristics to reduce the magnitude of their matching scale. Moreover, to solve the workload imbalance among different resource sets, local resource tasks are reallocated using the Q-value method in the MTSS strategy to achieve workload balance of global resources and improve the resource utilization rate. Experiments are carried out to evaluate the effectiveness of the proposed algorithm. Results show that the proposed algorithm outperforms other algorithms in terms of task completion time, execution cost, and workload balancing.
RI zhou, zhou/HPE-9525-2023; zhou, zhou/GYU-9809-2022
OI zhou, zhou/0000-0002-4787-9660
SN 2375-4699
EI 2375-4702
PD SEP
PY 2021
VL 20
IS 5
AR 91
DI 10.1145/3462761
UT WOS:000721584900021
ER

PT J
AU Petit, J
   Jiang, Z
   Polit, O
   Palin-Luc, T
AF Petit, J.
   Jiang, Z.
   Polit, O.
   Palin-Luc, T.
TI Optimisation of an ultrasonic torsion fatigue system for high strength
   materials
SO INTERNATIONAL JOURNAL OF FATIGUE
AB The bearable shear stress amplitude in very high cycle fatigue regime (VHCF) is of interest for many applications in mechanics (springs, crankshafts, ball bearings, etc.) when a very high repetition of load cycles occur. This paper proposes to optimise an existing torsion gigacycle fatigue testing system, developed fifteen years ago by the Pr C. Bathias' research team. The aim is to increase the shear stress amplitude applied to the investigated specimen and, consequently, meet the expectations from industries about fatigue life for high strength materials under shear loading. The system differs from other ultrasonic torsion fatigue machines that can be found in the literature, by the combination of two amplification horns, transforming a translation movement into a rotational one. In this work, there are two optimisation objective functions: (i) maximize the shear stress level in the specimen and (ii) minimize the stress level in the fatigue system and mainly in the pin connecting the two horns. The development of the optimised device is essentially carried out by a parametric study and numerical simulations through modal and harmonic analysis. Numerical results are compared with the analytical 1D solution and with experimental results obtained from the new real experimental set-up. Finally, new results in the gigacycle domain are presented concerning the torsion fatigue strength of high strength steels (50CrV4 and 16MnCr5) and discussed.
SN 0142-1123
EI 1879-3452
PD OCT
PY 2021
VL 151
AR 106395
DI 10.1016/j.ijfatigue.2021.106395
EA JUL 2021
UT WOS:000677986700001
ER

PT C
AU Alkhatib, M
   Monem, AA
   Shaalan, K
AF Alkhatib, Manar
   Monem, Azza Abdel
   Shaalan, Khaled
BE Shaalan, K
   ElBeltagy, SR
TI A Rich Arabic WordNet Resource for Al-Hadith Al-Shareef
SO ARABIC COMPUTATIONAL LINGUISTICS (ACLING 2017)
SE Procedia Computer Science
CT 3rd Arabic Computational Linguistics Conference (ACLing)
CY NOV 05-06, 2017
CL British Univ Dubai, Dubai, U ARAB EMIRATES
HO British Univ Dubai
AB Most Arabic computational linguistics researchers have focused on Modern Standard Arabic. Linguistic resources and tools for Classical Arabic, especially Al-Hadith Al-Shareef (i.e. the Prophet Muhammad's saying), remain relatively unexplored, despite its importance as a reference, in addition to its use in the holy Qur'an, used by all Muslims worldwide. Computational linguistics research tools for Al-Hadith Al-Shareef would be useful for both Islamic scholars and learners. Arabic WordNet is a remarkable language resource on its own, allowing a user to determine the relationships among words. It has proven its importance in many of language processing tasks needing an understanding of the meaning of language, including Information Retrieval, Word Sense Disambiguation, Machine Translation, Question Answering, Text Classification, and Text Summarization. In this paper, we propose an approach for developing a WordNet linguistic resource for Al-Hadith Al-Shareef that serves its purposes for various Arabic natural language processing tasks. In particular, we establish semantic connections between words in order to achieve a good understanding of the meanings of the Al-Hadith words. Our approach employs Classical Arabic dictionaries and Al-Hadith ontology. Al-Hadith WordNet has demonstrated its capability in a text classification task that we developed for evaluation proposes. The classifier has been applied on around 8500 synsets that include 6126 nominal, 1990 verbal, 310 adjectival, and 71 adverbial expressions. (C) 2017 The Authors. Published by Elsevier B.V.
RI Shaalan, Khaled/E-7377-2016
OI Shaalan, Khaled/0000-0003-0823-8390
SN 1877-0509
PY 2017
VL 117
BP 101
EP 110
DI 10.1016/j.procs.2017.10.098
UT WOS:000425029300013
ER

PT J
AU Rompf, T
   Odersky, M
AF Rompf, Tiark
   Odersky, Martin
TI Lightweight Modular Staging: A Pragmatic Approach to Runtime Code
   Generation and Compiled DSLs
SO COMMUNICATIONS OF THE ACM
AB Good software engineering practice demands generalization and abstraction, whereas high performance demands specialization and concretization. These goals are at odds, and compilers can only rarely translate expressive high-level programs to modern hardware platforms in a way that makes best use of the available resources.
   Generative programming is a promising alternative to fully automatic translation. Instead of writing down the target program directly, developers write a program generator, which produces the target program as its output. The generator can be written in a high-level, generic style and can still produce efficient, specialized target programs. In practice, however, developing high-quality program generators requires a very large effort that is often hard to amortize.
   We present lightweight modular staging (LMS), a generative programming approach that lowers this effort significantly. LMS seamlessly combines program generator logic with the generated code in a single program, using only types to distinguish the two stages of execution. Through extensive use of component technology, LMS makes a reusable and extensible compiler framework available at the library level, allowing programmers to tightly integrate domain-specific abstractions and optimizations into the generation process, with common generic optimizations provided by the framework.
   LMS is well suited to develop embedded domain-specific languages (DSLs) and has been used to develop powerful performance-oriented DSLs for demanding domains such as machine learning, with code generation for heterogeneous platforms including GPUs. LMS has also been used to generate SQL for embedded database queries and JavaScript for web applications.
OI Rompf, Tiark/0000-0002-2068-3238
SN 0001-0782
EI 1557-7317
PD JUN
PY 2012
VL 55
IS 6
BP 121
EP 130
DI 10.1145/2184319.2184345
UT WOS:000304442000032
ER

PT C
AU d'Amorim, M
   Sobeih, A
   Marinov, D
AF d'Amorim, Marcelo
   Sobeih, Ahmed
   Marinov, Darko
BE Liu, Z
   He, J
TI Optimized execution of deterministic blocks in Java PathFinder
SO FORMAL METHODS AND SOFTWARE ENGINEERING, PROCEEDINGS
SE Lecture Notes in Computer Science
CT 8th International Conference on Formal Engineering Methods (ICFEM 2006)
CY NOV 01-03, 2006
CL Macao, PEOPLES R CHINA
SP United Nat Univ, Int Inst Software Technol, Univ Macau, Macai Polytech Inst
AB Java PathFinder (JPF) is an explicit-state model checker for Java programs. It explores all executions that a given program can have due to different thread interleavings and nondeterministic choices. JPF implements a backtracking Java Virtual Machine (JVM) that executes Java bytecodes using a special representation of JVM states. This special representation enables JPF to quickly store, restore, and compare states; it is crucial for making the overall state exploration efficient. However, this special representation creates overhead for each execution, even execution of deterministic blocks that have no thread interleavings or nondeterministic choices.
   We propose mixed execution, a technique that reduces execution time of deterministic blocks in JPF. JPF is written in Java as a special JVM that runs on top of a regular, host JVM. Mixed execution works by translating the state between the special JPF representation and the host JVM representation. We also present lazy translation, an optimization that speeds up mixed execution by translating only the parts of the state that a specific execution dynamically depends on. We evaluate mixed execution on six programs that use JPF for generating tests for data structures and on one case study for verifying a network protocol. The results show that mixed execution can improve the overall time for state exploration up to 36.98%, while improving the execution time of deterministic blocks up to 69.15%. Although we present mixed execution in the context of JPF and Java, it generalizes to any model checker that uses a special state representation.
SN 0302-9743
EI 1611-3349
BN 3-540-47460-9
PY 2006
VL 4260
BP 549
EP +
UT WOS:000243128400030
ER

PT J
AU Jain, T
AF Jain, Tushar
TI Industrial objects recognition in intelligent manufacturing for computer
   vision
SO INTERNATIONAL JOURNAL OF INTELLIGENT UNMANNED SYSTEMS
AB Purpose The overall goal of this research is to develop algorithms for feature-based recognition of 2D parts from intensity images. Most present industrial vision systems are custom-designed systems, which can only handle a specific application. This is not surprising, since different applications have different geometry, different reflectance properties of the parts. Design/methodology/approach Computer vision recognition has attracted the attention of researchers in many application areas and has been used to solve many ranges of problems. Object recognition is a type of pattern recognition. Object recognition is widely used in the manufacturing industry for the purpose of inspection. Machine vision techniques are being applied in areas ranging from medical imaging to remote sensing, industrial inspection to document processing and nanotechnology to multimedia databases. In this work, recognition of objects manufactured in mechanical industry is considered. Mechanically manufactured parts have recognition difficulties due to manufacturing process including machine malfunctioning, tool wear and variations in raw material. This paper considers the problem of recognizing and classifying the objects of such mechanical part. Red, green and blue RGB images of five objects are used as an input. The Fourier descriptor technique is used for recognition of objects. Artificial neural network (ANN) is used for classification of five different objects. These objects are kept in different orientations for invariant rotation, translation and scaling. The feed forward neural network with back-propagation learning algorithm is used to train the network. This paper shows the effect of different network architecture and numbers of hidden nodes on the classification accuracy of objects as well as the effect of learning rate and momentum. Findings One important finding is that there is not any considerable change in the network performances after 500 iterations. It has been found that for data smaller network structure, smaller learning rate and momentum are required. The relative sample size also has a considerable effect on the performance of the classifier. Further studies suggest that classification accuracy is achieved with the confusion matrix of the data used. Hence, with these results the proposed system can be used efficiently for more objects. Depending upon the manufacturing product and process used, the dimension verification and surface roughness may be integrated with proposed technique to develop a comprehensive vision system. The proposed technique is also highly suitable for web inspections, which do not require dimension and roughness measurement and where desired accuracy is to be achieved at a given speed. In general, most recognition problems provide identity of object with pose estimation. Therefore, the proposed recognition (pose estimation) approach may be integrated with inspection stage. Originality/value This paper considers the problem of recognizing and classifying the objects of such mechanical part. RGB images of five objects are used as an input. The Fourier descriptor technique is used for recognition of objects. ANN is used for classification of five different objects. These objects are kept in different orientations for invariant rotation, translation and scaling. The feed forward neural network with back-propagation learning algorithm is used to train the network.
   This paper shows the effect of different network architecture and numbers of hidden nodes on the classification accuracy of objects as well as the effect of learning rate and momentum.
RI Jain, Tushar/AAZ-6813-2021
SN 2049-6427
EI 2049-6435
PD NOV 22
PY 2022
VL 10
IS 4
BP 401
EP 415
DI 10.1108/IJIUS-04-2020-0004
EA APR 2021
UT WOS:000646297100001
ER

PT J
AU Jucevicius, M
   Oziunas, R
   Narvydas, G
   Jegelevicius, D
AF Jucevicius, Mantas
   Oziunas, Rimantas
   Narvydas, Gintautas
   Jegelevicius, Darius
TI Permanent Magnet Tracking Method Resistant to Background Magnetic Field
   for Assessing Jaw Movement in Wearable Devices
SO SENSORS
AB There is a large gap between primitive bruxism detectors and sophisticated clinical machines for jaw kinematics evaluation. Large, expensive clinical appliances can precisely record jaw motion, but completely restrain the patient for the duration of the test. Wearable bruxism detectors allow continuously counting and recording bites, but provide no information about jaw movement trajectories. Previously, we developed a permanent magnet and three-axis magnetometer-based method for wearable, intra-oral continuous jaw position registration. In this work, we present an effective solution of the two main drawbacks of the method. Firstly, a two-adjacent-magnetometer approach is able to compensate for background magnetic fields with no reference sensor outside of the system's magnetic field. Secondly, jaw rotational angles were included in the position calculations, by applying trigonometric equations that link the translation of the jaw to its rotation. This way, we were able to use a three-degree-of-freedom (3-DOF) magnetic position determination method to track the positions of the 5-DOF human masticatory system. To validate the method, finite element modeling and a 6-DOF robotic arm (0.01 mm, 0.01 degrees) were used, which showed a 37% decrease in error in the average RMSE = 0.17 mm. The method's potentially can be utilized in small-scale, low-power, wearable intra-oral devices for continuous jaw motion recording.
RI ; Jegelevicius, Darius/P-5535-2018
OI Oziunas, Rimantas/0000-0002-2154-6833; Jucevicius,
   Mantas/0000-0002-6537-0606; Jegelevicius, Darius/0000-0002-5999-7744
EI 1424-8220
PD FEB
PY 2022
VL 22
IS 3
AR 971
DI 10.3390/s22030971
UT WOS:000759502400001
PM 35161716
ER

PT J
AU Callery, EL
   Rowbottom, AW
AF Callery, Emma L.
   Rowbottom, Anthony W.
TI Vibrational spectroscopy and multivariate analysis techniques in the
   clinical immunology laboratory: a review of current applications and
   requirements for diagnostic use
SO APPLIED SPECTROSCOPY REVIEWS
AB Laboratory tests are essential for clinicians to reach an accurate diagnosis and informing appropriate treatments. The expansion in the use of immunotherapies has highlighted the gap between the knowledge of molecular pathways and targeted therapies with availability of laboratory tests. The translation of vibrational spectroscopic techniques such as Fourier-transform infrared (FTIR) spectroscopy and Raman spectroscopy into clinical practice offer rapid-, noninvasive and inexpensive methods to obtain information on the molecular composition of biological samples. Advances in instrumentation, data analysis and machine learning techniques are key developments that have permitted the availability of results to clinicians in an appropriate timescale. Immunological disorders are complex, often demonstrating interaction across multiple molecular pathways which results in delayed diagnosis. Vibrational spectroscopy is being applied in many fields and here we present a review of its potential use in clinical immunology. This review addresses the potential use of spectroscopy in clinical immunology. Potential benefits that these novel techniques offer, including enhanced definition of molecular process and its use in disease diagnosis, monitoring and treatment response is discussed. Whilst not covered extensively, an overview of the method principle, quality control processes, and the requirements for multivariate data analysis is included to provide the reader with sufficient understanding of its application in the clinical setting.
OI Callery, Emma/0000-0003-0786-9182
SN 0570-4928
EI 1520-569X
PD MAY 28
PY 2022
VL 57
IS 5
BP 411
EP 440
DI 10.1080/05704928.2021.1958337
EA JUL 2021
UT WOS:000681183500001
ER

PT J
AU Jaiswal, AK
   Tiwari, P
   Garg, S
   Hossain, MS
AF Jaiswal, Amit Kumar
   Tiwari, Prayag
   Garg, Sahil
   Hossain, M. Shamim
TI Entity-aware capsule network for multi-class classification of big data:
   A deep learning approach
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
AB Named entity recognition (NER) is one of the most challenging natural language processing (NLP) tasks, as its performance is related to constantly evolving languages and dependency on expert (human) annotation. The diverse and dynamic content on the web significantly raises the need for a more generalized approach-one that is capable of correctly classifying terms in a corpus and feeding subsequent NLP tasks, such as machine translation, query expansion, and many other applications. Although extensively researched in recent times, the variety of public corpora available nowadays provides room for new and more accurate methods to tackle the NER problem. This paper presents a novel method that uses deep learning techniques based on the capsule network architecture for predicting entities in a corpus. This type of network groups neurons into so-called capsules to detect specific features of an object without reducing the original input unlike convolutional neural networks and their 'max-pooling' strategy. Our extensive evaluation on several benchmarked datasets demonstrates how competitive our method is in comparison with state-of-the-art techniques and how the usage of the proposed architecture may represent a significant benefit to further NLP tasks, especially in cases where experts are needed. Also, we explore NER using a theoretical framework that leverages big data for security. For the sake of reproducibility, we make the codebase open-source(2) (C) 2020 Elsevier B.V. All rights reserved.
RI Tiwari, Prayag/N-6261-2017; Hossain, M. Shamim/K-1362-2014; Guizani,
   Mohsen/AAX-4534-2021
OI Tiwari, Prayag/0000-0002-2851-4260; Hossain, M.
   Shamim/0000-0001-5906-9422; Guizani, Mohsen/0000-0002-8972-8094
SN 0167-739X
EI 1872-7115
PD APR
PY 2021
VL 117
BP 1
EP 11
DI 10.1016/j.future.2020.11.012
UT WOS:000612106900001
ER

PT C
AU Makris, D
   Agres, KR
   Herremans, D
AF Makris, Dimos
   Agres, Kat R.
   Herremans, Dorien
GP IEEE
TI Generating Lead Sheets with Affect: A Novel Conditional seq2seq
   Framework
SO 2021 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY JUL 18-22, 2021
CL ELECTR NETWORK
SP Int Neural Network Soc, IEEE Computat Intelligence Soc
AB The field of automatic music composition has seen great progress in the last few years, much of which can be attributed to advances in deep neural networks. There are numerous studies that present different strategies for generating sheet music from scratch. The inclusion of high-level musical characteristics (e.g., perceived emotional qualities), however, as conditions for controlling the generation output remains a challenge. In this paper, we present a novel approach for calculating the valence (the positivity or negativity of the perceived emotion) of a chord progression within a lead sheet, using pre-defined mood tags proposed by music experts. Based on this approach, we propose a novel strategy for conditional lead sheet generation that allows us to steer the music generation in terms of valence, phrasing, and time signature. Our approach is similar to a Neural Machine Translation (NMT) problem, as we include high-level conditions in the encoder part of the sequence-to-sequence architectures used (i.e., long-short term memory networks, and a Transformer network). We conducted experiments to thoroughly analyze these two architectures. The results show that the proposed strategy is able to generate lead sheets in a controllable manner, resulting in distributions of musical attributes similar to those of the training dataset. We also verified through a subjective listening test that our approach is effective in controlling the valence of a generated chord progression.
RI Herremans, Dorien/G-9599-2018
OI Herremans, Dorien/0000-0001-8607-1640
SN 2161-4393
BN 978-0-7381-3366-9
PY 2021
DI 10.1109/IJCNN52387.2021.9533474
UT WOS:000722581701064
ER

PT C
AU Chen, ZP
   Shen, S
   Hu, ZN
   Lu, X
   Mei, QZ
   Liu, XZ
AF Chen, Zhenpeng
   Shen, Sheng
   Hu, Ziniu
   Lu, Xuan
   Mei, Qiaozhu
   Liu, Xuanzhe
GP Assoc Comp Machinery
TI Emoji-Powered Representation Learning for Cross-Lingual Sentiment
   Classification
SO WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW
   2019)
CT World Wide Web Conference (WWW)
CY MAY 13-17, 2019
CL San Francisco, CA
SP Assoc Comp Machinery, Microsoft, Amazon, Bloomberg, Google, Criteo AI Lab, CISCO, NTENT, Spotify, Yahoo Res, Wikimedia Fdn, Baidu, DiDi, eBay, Facebook, LinkedIn, Megagon Labs, Mix, Mozilla, Netflix Res, NE Univ, Khoury Coll Comp Sci, Pinterest, Quora, Visa Res, Walmart Labs, Airbnb, Letgo, Gordon & Betty Moore Fdn, Webcastor
AB Sentiment classification typically relies on a large amount of labeled data. In practice, the availability of labels is highly imbalanced among different languages, e.g., more English texts are labeled than texts in any other languages, which creates a considerable inequality in the quality of related information services received by users speaking different languages. To tackle this problem, cross-lingual sentiment classification approaches aim to transfer knowledge learned from one language that has abundant labeled examples (i.e., the source language, usually English) to another language with fewer labels (i.e., the target language). The source and the target languages are usually bridged through off-the-shelf machine translation tools. Through such a channel, cross-language sentiment patterns can be successfully learned from English and transferred into the target languages. This approach, however, often fails to capture sentiment knowledge specific to the target language, and thus compromises the accuracy of the downstream classification task. In this paper, we employ emojis, which are widely available in many languages, as a new channel to learn both the cross-language and the language-specific sentiment patterns. We propose a novel representation learning method that uses emoji prediction as an instrument to learn respective sentiment-aware representations for each language. The learned representations are then integrated to facilitate cross-lingual sentiment classification. The proposed method demonstrates state-of-the-art performance on benchmark datasets, which is sustained even when sentiment labels are scarce.
RI Hu, Ziniu/HJI-4899-2023
OI Mei, Qiaozhu/0000-0002-8640-1942
BN 978-1-4503-6674-8
PY 2019
BP 251
EP 262
DI 10.1145/3308558.3313600
UT WOS:000483508400026
ER

PT C
AU Bertini, JR
   Kasahara, VA
   Nicoletti, MC
AF Bertini Jr, Joao R.
   Kasahara, Viviani A.
   Nicoletti, Maria C.
GP IEEE
TI Approaching miRNA Family Classification Through Constructive Neural
   Networks
SO 2018 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY JUL 08-13, 2018
CL Rio de Janeiro, BRAZIL
AB MicroRNAs (or miRNAs) are non-coding RNA molecules associated to gene expression, acting in post-transcriptional regulation, either by inhibiting the translation of messenger RNAs or by promoting its degradation. Since the discovery of the first miRNA, a considerable number of miRNAs, found in plants, worms, vertebrates, etc. have been described in the literature. The experimental determination of their corresponding functionality, however, has been restricted to a much smaller number. A considerable volume of miRNA sequences have been categorized into families, based on their associated mature sequence or on the structure of their pre-MicroRNA. Considering that members of the same family have the tendency of biologically function in similar ways, a structured family can help to detect functions still not associated with existing families or, via an induced classifier, assign potential candidates to families, based on their feature values. This paper investigates the use of five constructive neural network (CoNN) algorithms, the Tower, Pyramid, Tiling, Perceptron Cascade and the BabCoNN, in the miRNA knowledge domain, aiming at evaluating how well they perform on MicroRNA data, as far as classification of new miRNA sequences is concerned. Also, the paper comparatively discusses the CoNN results with those obtained using the Multi-layer Perceptron (MLP), Random Forest (RF) and Support Vector Machines (SVM) algorithms. Results show that CoNN algorithms are an efficient alternative for miRNA classification when a suitable combination of dimensionality reduction algorithm and number of dimensions for describing the data is considered.
RI Bertini, João Roberto/I-5568-2012; do Carmo Nicoletti,
   Maria/AAP-7704-2021
OI Bertini, João Roberto/0000-0002-1679-3151; do Carmo Nicoletti,
   Maria/0000-0003-4528-7984
SN 2161-4393
BN 978-1-5090-6014-6
PY 2018
UT WOS:000585967404051
ER

PT J
AU Sovacool, BK
AF Sovacool, Benjamin K.
TI Experts, theories, and electric mobility transitions: Toward an
   integrated conceptual framework for the adoption of electric vehicles
SO ENERGY RESEARCH & SOCIAL SCIENCE
AB I expand and integrate a theory of mobility (Automobility) with one of science and technology (Actor Network Theory) and one about social acceptance and user adoption (UTAUT). I apply this integrative framework to the diffusion (and non-diffusion) of electric vehicles and the process of electric mobility. I begin by presenting my methods, namely semi-structured qualitative research interviews with social theorists. Then, I present the three theories deemed most relevant by respondents. Automobility holds that, on a cultural or social level, automobiles exist as part of a complex, one that involves hardware and infrastructure-a hybridity between drivers and machines-along with patterns of identity and attitudes about driving pleasure. Actor Network Theory (ANT) involves the concepts of network assemblage, translation, enrollment, and actants and lieutenants. The Unified Theory of Acceptance and Use of Technology, or UTAUT, states that on an individual level, the adoption of new technologies will be predicated on interconnected factors such as performance expectancy, effort expectancy, and other facilitating conditions. Based largely on the original interview data supplemented with peer-reviewed studies, I propose a conceptual framework of user acceptance consisting of motile pleasure, sociality, sociotechnical commensurability, and habitual momentum. I conclude with implications for research and policy. (C) 2017 Elsevier Ltd. All rights reserved.
RI Sovacool, Benjamin/Y-2392-2019
OI Sovacool, Benjamin/0000-0002-4794-9403
SN 2214-6296
EI 2214-6326
PD MAY
PY 2017
VL 27
BP 78
EP 95
DI 10.1016/j.erss.2017.02.014
UT WOS:000404769900010
ER

PT C
AU Gupta, V
AF Gupta, Vishal
BE Thampi, SM
   Gelbukh, A
   Mukhopadhyay, J
TI Automatic Stemming of Words for Punjabi Language
SO ADVANCES IN SIGNAL PROCESSING AND INTELLIGENT RECOGNITION SYSTEMS
SE Advances in Intelligent Systems and Computing
CT International Symposium on Signal Processing and Intelligent Recognition
   Systems (SIRS)
CY MAR 13-15, 2014
CL Trivandrum, INDIA
SP Indian Inst Informat Technol & Management Kerala
AB The major task of a stemmer is to find root words that are not in original form and are hence absent in the dictionary. The stemmer after stemming finds the word in the dictionary. If a match of the word is not found, then it may be some incorrect word or a name, otherwise the word is correct. For any language in the world, stemmer is a basic linguistic resource required to develop any type of application in Natural Language Processing (NLP) with high accuracy such as machine translation, document classification, document clustering, text question answering, topic tracking, text summarization and keywords extraction etc. This paper concentrates on complete automatic stemming of Punjabi words covering Punjabi nouns, verbs, adjectives, adverbs, pronouns and proper names. A suffix list of 18 suffixes for Punjabi nouns and proper names and a number of other suffixes for Punjabi verbs, adjectives and adverbs and different stemming rules for Punjabi nouns, verbs, adjectives, adverbs, pronouns and proper names have been generated after analysis of corpus of Punjabi. It is first time that complete Punjabi stemmer covering Punjabi nouns, verbs, adjectives, adverbs, pronouns, and proper names has been proposed and it will be useful for developing other Punjabi NLP applications with high accuracy. A portion of Punjabi stemmer of proper names and nouns has been implemented as a part of Punjabi text summarizer in MS Access as back end and ASP. NET as front end with 87.37% efficiency
SN 2194-5357
EI 2194-5365
BN 978-3-319-04960-1; 978-3-319-04959-5
PY 2014
VL 264
BP 73
EP 84
DI 10.1007/978-3-319-04960-1_7
UT WOS:000391155100007
ER

PT J
AU Barone, S
   Paoli, A
   Razionale, AV
AF Barone, Sandro
   Paoli, Alessandro
   Razionale, Armando Viviano
TI 3D Reconstruction and Restoration Monitoring of Sculptural Artworks by a
   Multi-Sensor Framework
SO SENSORS
AB Nowadays, optical sensors are used to digitize sculptural artworks by exploiting various contactless technologies. Cultural Heritage applications may concern 3D reconstructions of sculptural shapes distinguished by small details distributed over large surfaces. These applications require robust multi-view procedures based on aligning several high resolution 3D measurements. In this paper, the integration of a 3D structured light scanner and a stereo photogrammetric sensor is proposed with the aim of reliably reconstructing large free form artworks. The structured light scanner provides high resolution range maps captured from different views. The stereo photogrammetric sensor measures the spatial location of each view by tracking a marker frame integral to the optical scanner. This procedure allows the computation of the rotation-translation matrix to transpose the range maps from local view coordinate systems to a unique global reference system defined by the stereo photogrammetric sensor. The artwork reconstructions can be further augmented by referring metadata related to restoration processes. In this paper, a methodology has been developed to map metadata to 3D models by capturing spatial references using a passive stereo-photogrammetric sensor. The multi-sensor framework has been experienced through the 3D reconstruction of a Statue of Hope located at the English Cemetery in Florence. This sculptural artwork has been a severe test due to the non-cooperative environment and the complex shape features distributed over a large surface.
RI Razionale, Armando Viviano/C-2335-2018
OI Razionale, Armando Viviano/0000-0001-7110-3857; Barone,
   Sandro/0000-0003-4055-4799; PAOLI, ALESSANDRO/0000-0002-1918-3033
SN 1424-8220
PD DEC
PY 2012
VL 12
IS 12
BP 16785
EP 16801
DI 10.3390/s121216785
UT WOS:000312607500045
PM 23223079
ER

PT J
AU Lin, LT
   Guo, JQ
   Li, YT
   Gelfand, SB
   Delp, EJ
   Bhadra, A
   Richards, EA
   Hennessy, E
   Eicher-Miller, HA
AF Lin, Luotao
   Guo, Jiaqi
   Li, Yitao
   Gelfand, Saul B.
   Delp, Edward J.
   Bhadra, Anindya
   Richards, Elizabeth A.
   Hennessy, Erin
   Eicher-Miller, Heather A.
TI The Discovery of Data-Driven Temporal Dietary Patterns and a Validation
   of Their Description Using Energy and Time Cut-Offs
SO NUTRIENTS
AB Data-driven temporal dietary patterning (TDP) methods were previously developed. The objectives were to create data-driven temporal dietary patterns and assess concurrent validity of energy and time cut-offs describing the data-driven TDPs by determining their relationships to BMI and waist circumference (WC). The first day 24-h dietary recall timing and amounts of energy for 17,915 U.S. adults of the National Health and Nutrition Examination Survey 2007-2016 were used to create clusters representing four TDPs using dynamic time warping and the kernel k-means clustering algorithm. Energy and time cut-offs were extracted from visualization of the data-derived TDPs and then applied to the data to find cut-off-derived TDPs. The strength of TDP relationships with BMI and WC were assessed using adjusted multivariate regression and compared. Both methods showed a cluster, representing a TDP with proportionally equivalent average energy consumed during three eating events/day, associated with significantly lower BMI and WC compared to the other three clusters that had one energy intake peak/day at 13:00, 18:00, and 19:00 (all p < 0.0001). Participant clusters of the methods were highly overlapped (>83%) and showed similar relationships with obesity. Data-driven TDP was validated using descriptive cut-offs and hold promise for obesity interventions and translation to dietary guidance.
RI Guo, Jiaqi/GSO-0702-2022
OI Richards, Elizabeth/0000-0002-6574-2393; Delp,
   Edward/0000-0002-2909-7323; Eicher-Miller, Heather/0000-0002-1261-4291
EI 2072-6643
PD SEP
PY 2022
VL 14
IS 17
AR 3483
DI 10.3390/nu14173483
UT WOS:000851636300001
PM 36079740
ER

PT J
AU Granata, V
   Fusco, R
   Setola, SV
   Simonetti, I
   Cozzi, D
   Grazzini, G
   Grassi, F
   Belli, A
   Miele, V
   Izzo, F
   Petrillo, A
AF Granata, Vincenza
   Fusco, Roberta
   Setola, Sergio Venazio
   Simonetti, Igino
   Cozzi, Diletta
   Grazzini, Giulia
   Grassi, Francesca
   Belli, Andrea
   Miele, Vittorio
   Izzo, Francesco
   Petrillo, Antonella
TI An update on radiomics techniques in primary liver cancers
SO INFECTIOUS AGENTS AND CANCER
AB Background Radiomics is a progressing field of research that deals with the extraction of quantitative metrics from medical images. Radiomic features detention indirectly tissue features such as heterogeneity and shape and can, alone or in combination with demographic, histological, genomic, or proteomic data, be used for decision support system in clinical setting. Methods This article is a narrative review on Radiomics in Primary Liver Cancers. Particularly, limitations and future perspectives are discussed. Results In oncology, assessment of tissue heterogeneity is of particular interest: genomic analysis have demonstrated that the degree of tumour heterogeneity is a prognostic determinant of survival and an obstacle to cancer control. Therefore, that Radiomics could support cancer detection, diagnosis, evaluation of prognosis and response to treatment, so as could supervise disease status in hepatocellular carcinoma (HCC) and Intrahepatic Cholangiocarcinoma (ICC) patients. Radiomic analysis is a convenient radiological image analysis technique used to support clinical decisions as it is able to provide prognostic and / or predictive biomarkers that allow a fast, objective and repeatable tool for disease monitoring. Conclusions Although several studies have shown that this analysis is very promising, there is little standardization and generalization of the results, which limits the translation of this method into the clinical context. The limitations are mainly related to the evaluation of data quality, repeatability, reproducibility, overfitting of the model. Trial registration: Not applicable.
RI Belli, Andrea/AHI-8182-2022; Fusco, Roberta/I-4062-2018; Belli,
   Andrea/AHI-1827-2022; Belli, Andrea/AHE-21806-2022; Cozzi,
   Diletta/AEC-8045-2022; Grazzini, Giulia/AAW-5224-2021
OI Belli, Andrea/0000-0002-6252-573X; Fusco, Roberta/0000-0002-0469-9969;
   Belli, Andrea/0000-0002-6252-573X; Belli, Andrea/0000-0002-6252-573X; 
SN 1750-9378
PD MAR 4
PY 2022
VL 17
IS 1
AR 6
DI 10.1186/s13027-022-00422-6
UT WOS:000764813800001
PM 35246207
ER

PT J
AU Chen, I
   Chen, MY
   Goedegebuure, SP
   Gillanders, WE
AF Chen, Ina
   Chen, Michael Y.
   Goedegebuure, S. Peter
   Gillanders, William E.
TI Challenges targeting cancer neoantigens in 2021: a systematic literature
   review
SO EXPERT REVIEW OF VACCINES
AB Introduction: Cancer neoantigens represent important targets of cancer immunotherapy. The goal of cancer neoantigen vaccines is to induce neoantigen-specific immune responses and antitumor immunity while minimizing the potential for autoimmune toxicity. Advances in sequencing technologies, neoantigen prediction algorithms, and other technologies have dramatically improved the ability to identify and prioritize cancer neoantigens. Unfortunately, results from preclinical studies and early phase clinical trials highlight important challenges to the successful clinical translation of neoantigen cancer vaccines. Areas covered: In this review, we provide an overview of current strategies for the identification and prioritization of cancer neoantigens with a particular emphasis on the two most common strategies used for neoantigen identification: (1) direct identification of peptide ligands eluted from peptide-MHC complexes, and (2) next-generation sequencing combined with neoantigen prediction algorithms. We highlight the limitations of current neoantigen prediction pipelines, and discuss broader challenges associated with cancer neoantigen vaccines including tumor purity/heterogeneity and the immunosuppressive tumor microenvironment. Expert opinion: Despite current limitations, neoantigen prediction is likely to improve rapidly based on advances in sequencing, machine learning, and information sharing. The successful development of robust cancer neoantigen prediction strategies is likely to have a significant impact, with the potential to facilitate cancer neoantigen vaccine design.
SN 1476-0584
EI 1744-8395
PD JUL 3
PY 2021
VL 20
IS 7
BP 827
EP 837
DI 10.1080/14760584.2021.1935248
EA JUN 2021
UT WOS:000659328900001
PM 34047245
ER

PT C
AU Henry, G
   Palangpour, P
   Thomson, M
   Gardner, JS
   Arden, B
   Donahue, J
   Houck, K
   Johnson, J
   O'Brien, K
   Petersen, S
   Seroussi, B
   Walker, T
AF Henry, Glenn
   Palangpour, Parviz
   Thomson, Michael
   Gardner, J. Scott
   Arden, Bryce
   Donahue, Jim
   Houck, Kimble
   Johnson, Jonathan
   O'Brien, Kyle
   Petersen, Scott
   Seroussi, Benjamin
   Walker, Tyler
GP IEEE
TI High-Performance Deep-Learning Coprocessor Integrated into x86 SoC with
   Server-Class CPUs
SO 2020 ACM/IEEE 47TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2020)
SE ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE
CT 47th ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY MAY 30-JUN 03, 2020
CL ELECTR NETWORK
SP IEEE, ACM, IEEE Comp Soc
AB Demand for high performance deep learning (DL) inference in software applications is growing rapidly. DL workloads run on myriad platforms, including general purpose processors (CPU), system-on-chip (SoC) with accelerators, graphics processing units (GPU), and neural processing unit (NPU) add-in cards. DL software engineers typically must choose between relatively slow general hardware (e.g., CPUs, SoCs) or relatively expensive, large, power-hungry hardware (e.g., GPUs, NPUs).
   This paper describes Centaur Technology's Ncore, the industry's first high-performance DL coprocessor technology integrated into an x86 SoC with server-class CPUs. Ncore's 4096 byte-wide SIMD architecture supports INT8, UINT8, INT16, and BF16 datatypes, with 20 tera-operations-per-second compute capability. Ncore shares the SoC ring bus for low-latency communication and work sharing with eight 64-bit x86 cores, offering flexible support for new and evolving models. The x86 SoC platform can further scale out performance via multiple sockets, systems, or third-party PCIe accelerators. Ncore's software stack automatically converts quantized models for Ncore consumption and leverages existing DL frameworks.
   In MLPerf's Inference v0.5 closed division benchmarks, Ncore achieves 1218 IPS throughput and 1.05ms latency on ResNet-50v1.5 and achieves lowest latency of all Mobilenet-V1 submissions (329 mu s). Ncore yields 23x speedup over other x86 vendor percore throughput, while freeing its own x86 cores for other work. Ncore is the only integrated solution among the memory intensive neural machine translation (NMT) submissions.
OI Thomson, Michael/0000-0002-6051-8544
SN 0884-7495
BN 978-1-7281-4661-4
PY 2020
BP 15
EP 26
DI 10.1109/ISCA45697.2020.00013
UT WOS:000617734800002
ER

PT C
AU Yadav, N
   Ganguly, AR
AF Yadav, Nishant
   Ganguly, Auroop R.
GP ACM
TI A Deep Learning Approach to Short-Term Quantitative Precipitation
   Forecasting
SO PROCEEDINGS OF 2020 10TH INTERNATIONAL CONFERENCE ON CLIMATE INFORMATICS
   (CI2020)
CT 10th International Conference on Climate Informatics (CI)
CY SEP 20-25, 2020
CL ELECTR NETWORK
SP Univ Oxford, IMIRACLI
AB Short-term, spatially distributed quantitative precipitation forecasting (SD-QPF), or 'precipitation nowcasting', is important for hydrological and water resources applications, such as flash flood warning systems and operations of dams and reservoirs. The stateof-the-art methods in SD-QPF include radar extrapolations, numerical weather prediction (NWP) models, and hybrid methods that combine the two. Despite the diversity of methods that have been used, SD-QPF remains difficult: even sophisticated methods may not be able to consistently outperform relatively simple baselines such as Persistence. Methods in Deep Learning (DL) have demonstrated significant and often unexpected improvements across a wide variety of domains ranging from image and video processing to machine translation and speech recognition. Emerging research has suggested that that DL may improve point predictions in the context of very short-term - 0-2 hours - distributed QPF (VSD-QPF) by taking advantage of growing data from in-situ weather sensors as well as remote sensors such as radar and satellites, along with advances in computing. Here we examine the hypothesis that DL can improve VSD-QPF, specifically point predictions, based on observed hourly precipitation data over the contiguous United States, by leveraging a Convolutional Long Short-Term Memory (LSTM) recurrent neural network for 1-hour precipitation nowcasting. We find the DL approach performs better than the baseline method of Persistence and a state-of-the-art method using Optical Flow.
BN 978-1-4503-8848-1
PY 2020
BP 8
EP 14
DI 10.1145/3429309.3429311
UT WOS:000724517700002
ER

PT C
AU Huang, C
   Wasmund, SL
   Yamaguchi, T
   Knighton, N
   Hitchcock, RW
   Polejaeva, IA
   White, KL
   Marrouche, NF
   Sachse, FB
AF Huang, Chao
   Wasmund, Stephen L.
   Yamaguchi, Takanori
   Knighton, Nathan
   Hitchcock, Robert W.
   Polejaeva, Irina A.
   White, Kenneth L.
   Marrouche, Nassir F.
   Sachse, Frank B.
BE Coudiere, Y
   Ozenne, V
   Vigmond, E
   Zemzemi, N
TI Towards Automated Quantification of Atrial Fibrosis in Images from
   Catheterized Fiber-Optics Confocal Microscopy Using Convolutional Neural
   Networks
SO FUNCTIONAL IMAGING AND MODELING OF THE HEART, FIMH 2019
SE Lecture Notes in Computer Science
CT 10th International Conference on Functional Imaging and Modeling of the
   Heart (FIMH)
CY JUN 06-08, 2019
CL Bordeaux, FRANCE
SP Siemens Healthineers, inHEART, Electrophysiol & Heart Modeling Inst, Univ Bordeaux, French Natl Ctr Sci Res, UMR 5251 Inst Math Bordeaux & GDR Mamovi, Natl Inst Res Comp Sci & Automat, France Life Imaging, Bordeaux INP
AB Clinical approaches for quantification of atrial fibrosis are currently based on digital image processing of magnetic resonance images. Here, we introduce and evaluate a comprehensive framework based on convolutional neural networks for quantifying atrial fibrosis from images acquired with catheterized fiber-optics confocal microscopy (FCM). FCM images in three regions of the atria were acquired in the beating heart in situ in an established transgenic animal model of atrial fibrosis. Fibrosis in the imaged regions was histologically assessed in excised tissue. FCM images and their corresponding histologically-assessed fibrosis levels were used for training of a convolutional neural network. We evaluated the utility and performance of the convolutional neural networks by varying parameters including image dimension and training batch size. In general, we observed that the root-mean square error (RMSE) of the predicted fibrosis was decreased with increasing image dimension. We achieved a RMSE of 2.6% and a Pearson correlation coefficient of 0.953 when applying a network trained on images with a dimension of 400 x 400 pixels and a batch size of 128 to our test image set. The findings indicate feasibility of our approach for fibrosis quantification from images acquired with catheterized FCM using convolutional neural networks. We suggest that the developed framework will facilitate translation of catheterized FCM into a clinical approach that complements current approaches for quantification of atrial fibrosis.
RI Yamaguchi, Takanori/G-1278-2018
OI Yamaguchi, Takanori/0000-0002-0613-8591; Polejaeva,
   Irina/0000-0002-0858-5889; Sachse, Frank/0000-0003-4987-705X
SN 0302-9743
EI 1611-3349
BN 978-3-030-21949-9; 978-3-030-21948-2
PY 2019
VL 11504
BP 168
EP 176
DI 10.1007/978-3-030-21949-9_19
UT WOS:000495643700019
PM 31245795
ER

PT C
AU Serikova, MG
   Pantyushin, AV
   Gorbunova, EV
   Anisimov, AG
AF Serikova, Mariya G.
   Pantyushin, Anton V.
   Gorbunova, Elena V.
   Anisimov, Andrei G.
BE Beyerer, J
   Leon, FP
TI Retroreflective microprismatic materials in image-based control
   applications
SO AUTOMATED VISUAL INSPECTION AND MACHINE VISION
SE Proceedings of SPIE
CT Conference on Automated Visual Inspection and Machine Vision
CY JUN 24, 2015
CL Munich, GERMANY
SP SPIE
AB This work addresses accurate position measurement of reference marks made of retroreflective microprismatic materials by image-based systems. High reflection microprismatic technology implies tiny hermetically sealed pockets, which improve material reflectivity, but result in non-reflective preprinted netting pattern. The mark pattern to be used for measuring can be simply printed on the reflective material as an opaque area with predefined shape. However, the non-reflecting pattern acts as a spatial filter that affects resultant spatial reflectivity of the mark. When an image of the mark is taken, the desired mark shape can be deformed by the netting pattern. This deformational may prevent accurate estimation of the mark position in the image. In this paper experimental comparison of three image filtering approaches (median filtering, morphological close and filtering in a frequency domain) in order to minimize the affection of the netting pattern is provided. These filtering approaches were experimentally evaluated by processing of the images of the mark that was translated in a camera field of view. For that a developed experimental setup including a camera with LED backlight and the mark placed on a translation stage was used. The experiment showed that median filtering provided better netting pattern elimination and higher accuracy of key features position estimation (approximately 0.1 pix) in the condition of the experiment. The ways of future use of reference marks based on microprismatic material in image-based control applications are discussed.
RI Pantiushin, Anton/L-3074-2016; Anisimov, Andrei/P-1341-2016; Gorbunova,
   Elena/H-5995-2016
OI Pantiushin, Anton/0000-0001-9890-622X; Anisimov,
   Andrei/0000-0002-0804-9103; Gorbunova, Elena/0000-0003-4799-8210
SN 0277-786X
EI 1996-756X
BN 978-1-62841-690-9
PY 2015
VL 9530
AR 95300E
DI 10.1117/12.2184831
UT WOS:000357945800013
ER

PT J
AU Zou, HB
   Xia, RB
   Zhao, JB
   Zhang, T
   Zhang, TY
   Chen, YL
   Fu, SP
AF Zou, Hangbo
   Xia, Renbo
   Zhao, Jibin
   Zhang, Tao
   Zhang, Tianyu
   Chen, Yueling
   Fu, Shengpeng
TI Extrinsic calibration method for 3D scanning system with four coplanar
   laser profilers
SO MEASUREMENT SCIENCE AND TECHNOLOGY
AB 3D scanning is a crucial step to ensuring the machining quality of the workpiece and is an essential part of intelligent manufacturing. However, existing scanning systems usually have only one profiler, which must be combined with a dynamic tracking system to achieve a complete scan of a workpiece. This scanning method has low efficiency and complicated path planning for ring-shaped workpieces. Therefore, in this article, an efficient and high-accuracy 3D scanning system composed of a linear translation stage and four uniformly distributed laser profilers is built, and its extrinsic calibration method is studied. At first, based on the working parameters and spatial layout of multiple profilers, a stereoscopic calibrator composed of three non-collinear target balls (TBs) is designed. Then, a multi-profiler data fusion method is proposed, which utilizes a linear encoder to trigger the four profilers synchronously. Finally, by simultaneously using all data from the multiple profilers and the spherical constraint of each TB, all extrinsic parameters are accurately calibrated at the same time. Experimental results show that the average probing size error of the TB with a 38.1 mm diameter is stable at about 0.007 mm, and its extended uncertainty is about 0.100 mm (k = 2). In addition, standard cylinders and bend tubes are scanned. The results show that the proposed method can meet the high-accuracy calibration requirements of the tube-bending deformation detection system.
OI Zou, Hangbo/0000-0001-5440-7226
SN 0957-0233
EI 1361-6501
PD JAN 1
PY 2023
VL 34
IS 1
AR 015906
DI 10.1088/1361-6501/ac9076
UT WOS:000870856000001
ER

PT C
AU Mahalingam, G
   Jiao, T
   Schneider-Mizell, C
   Bodor, A
   Torres, R
   Takeno, M
   Buchanan, J
   Bumbarger, D
   Yin, WJ
   Brittain, D
   Reid, C
   Da Costa, N
AF Mahalingam, Gayathri
   Jiao, Tong
   Schneider-Mizell, Casey
   Bodor, Agnes
   Torres, Russel
   Takeno, Marc
   Buchanan, JoAnn
   Bumbarger, Daniel
   Yin, Wenjing
   Brittain, Derrick
   Reid, Clay
   Da Costa, Nuno
GP IEEE
TI ANOMALY DETECTION IN EM IMAGES - A ZERO-SHOT LEARNING APPROACH
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (IEEE ISBI 2022)
SE IEEE International Symposium on Biomedical Imaging
CT 19th IEEE International Symposium on Biomedical Imaging (IEEE ISBI)
CY MAR 28-31, 2022
CL Kolkata, INDIA
SP Inst Elect & Elect Engineers, IEEE Engn Med & Biol Soc, IEEE Signal Proc Soc, GE, Intel, Aira Matrix, Verasonics, TCS Res, Siemens Healthineers, Bharat Biotech, Google
AB Reconstructing dense neural wiring diagrams in the brain require 2D registration and 3D alignment ([1]) of thousands of serial sections imaged using a serial section electron microscopy (ssEM). Each serial section imaged comprise of thousands of high resolution images that include both the tissue, film, and resin regions. The stitching accuracy is challenged by the presence of anomalies (film and resin), which causes misalignments between the images that represent them. Detection of such anomalies is required to achieve a high quality stitching and alignment. Automated pixel based segmentation of such anomalies requires training machine learning models on dataset-specific ground truth, which is tedious to acquire. In this work, we propose a zero-shot learning approach to perform pixel based segmentation of resin and film regions on unknown datasets without ground truth. Our pipeline consists of a segmentation network based on U-Net architecture coupled with an unsupervised imageto-image translation method that uses Cycle GAN to translate the input image to match the style of images used for training the U-Net. Performance results on various EM datasets show that the segmentation class accuracy of resin and film improve significantly. By eliminating the need for ground-truth annotations, we facilitate the process of stitching and alignment by automation of detecting anomalies. Our zeroshot learning approach can potentially be utilized in scenarios where ground truth annotations are hard to acquire.
SN 1945-7928
BN 978-1-6654-2923-8
PY 2022
DI 10.1109/ISBI52829.2022.9761659
UT WOS:000836243800256
ER

PT J
AU Goel, R
   Ozdemir, RA
   Nakagome, S
   Contreras-Vidal, JL
   Paloski, WH
   Parikh, PJ
AF Goel, Rahul
   Ozdemir, Recep A.
   Nakagome, Sho
   Contreras-Vidal, Jose L.
   Paloski, William H.
   Parikh, Pranav J.
TI Effects of speed and direction of perturbation on
   electroencephalographic and balance responses
SO EXPERIMENTAL BRAIN RESEARCH
AB The modulation of perturbation-evoked potential (PEP) N1 as a function of different biomechanical characteristics of perturbation has been investigated before. However, it remains unknown whether the PEP N1 modulation contributes to the shaping of the functional postural response. To improve this understanding, we examined the modulation of functional postural response in relation to the PEP N1 response in ten healthy young subjects during unpredictable perturbations to their upright stance-translations of the support surface in a forward or backward direction at two different amplitudes of constant speed. Using independent components from the fronto-central region, obtained from subject-specific head models created from the MRI, our results show that the latency of onset of the functional postural response after the PEP N1 response was faster for forward than backward perturbations at a constant speed but was not affected by the speed of perturbation. Further, our results reinforce some of the previous findings that suggested that the N1 peak amplitude and peak latency are both modulated by the speed of perturbation but not by the direction of the perturbation. Our results improve the understanding of the relation between characteristics of perturbation and the neurophysiology of reactive balance control and may have implications for the design of brain-machine interfaces for populations with a higher risk of falls.
RI Goel, Rahul/C-4480-2016; Contreras-Vidal, Jose L/AAW-9299-2020
OI Goel, Rahul/0000-0002-3516-6938; Contreras-Vidal, Jose
   L/0000-0002-6499-1208
SN 0014-4819
EI 1432-1106
PD JUL
PY 2018
VL 236
IS 7
BP 2073
EP 2083
DI 10.1007/s00221-018-5284-5
UT WOS:000435783300021
PM 29752486
ER

PT C
AU Zhang, WE
   Sheng, QZ
   Lau, JH
   Abebe, E
AF Zhang, Wei Emma
   Sheng, Quan Z.
   Lau, Jey Han
   Abebe, Ermyas
GP ACM
TI Detecting Duplicate Posts in Programming QA Communities via Latent
   Semantics and Association Rules
SO PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB
   (WWW'17)
CT 26th International Conference on World Wide Web (WWW)
CY MAY 03-07, 2017
CL Perth, AUSTRALIA
SP Assoc Comp Machinery, Int World Wide Web Conf Comm, ACM SIGWEB, Curtin Univ, Edith Cowan Univ, Murdoch Univ, Univ Western Australia, Bankwest, Atamo Elect Prod Solut, Enesis, Google, Illuminance, Yahoo Res
AB Programming community-based question-answering (PCQA) websites such as Stack Overflow enable programmers to find working solutions to their questions. Despite detailed posting guidelines, duplicate questions that have been answered are frequently created. To tackle this problem, Stack Overflow provides a mechanism for reputable users to manually mark duplicate questions. This is a laborious effort, and leads to many duplicate questions remain undetected. Existing duplicate detection methodologies from traditional community based question-answering (CQA) websites are difficult to be adopted directly to PCQA, as PCQA posts often contain source code which is linguistically very different from natural languages. In this paper, we propose a methodology designed for the PCQA domain to detect duplicate questions. We model the detection as a classification problem over question pairs. To extract features for question pairs, our methodology leverages continuous word vectors from the deep learning literature, topic model features and phrases pairs that co-occur frequently in duplicate questions mined using machine translation systems. These features capture semantic similarities between questions and produce a strong performance for duplicate detection. Experiments on a range of real-world datasets demonstrate that our method works very well; in some cases over 30% improvement compared to state-of-the-art benchmarks. As a product of one of the proposed features, the association score feature, we have mined a set of associated phrases from duplicate questions on Stack Overflow and open the dataset to the public.
RI Sheng, Quan Z./B-8169-2008
OI Sheng, Quan Z./0000-0002-3326-4147; ZHANG, WEI/0000-0002-0406-5974; Lau,
   Jey Han/0000-0002-1647-4628
BN 978-1-4503-4913-0
PY 2017
BP 1221
EP 1229
DI 10.1145/3038912.3052701
UT WOS:000461544900126
ER

PT J
AU Glitzner, M
   Crijns, SPM
   de Senneville, BD
   Lagendijk, JJW
   Raaymakers, BW
AF Glitzner, M.
   Crijns, S. P. M.
   de Senneville, B. Denis
   Lagendijk, J. J. W.
   Raaymakers, B. W.
TI On the suitability of Elekta's Agility 160 MLC for tracked radiation
   delivery: closed-loop machine performance
SO PHYSICS IN MEDICINE AND BIOLOGY
AB For motion adaptive radiotherapy, dynamic multileaf collimator tracking can be employed to reduce treatment margins by steering the beam according to the organ motion.
   The Elekta Agility 160 MLC has hitherto not been evaluated for its tracking suitability. Both dosimetric performance and latency are key figures and need to be assessed generically, independent of the used motion sensor.
   In this paper, we propose the use of harmonic functions directly fed to the MLC to determine its latency during continuous motion. Furthermore, a control variable is extracted from a camera system and fed to the MLC. Using this setup, film dosimetry and subsequent. statistics are performed, evaluating the response when tracking (MRI)-based physiologic motion in a closed-loop. The delay attributed to the MLC itself was shown to be a minor contributor to the overall feedback chain as compared to the impact of imaging components such as MRI sequences. Delay showed a linear phase behaviour of the MLC employed in continuously dynamic applications, which enables a general MLC-characterization. Using the exemplary feedback chain, dosimetry showed a vast increase in pass rate employing. statistics.
   In this early stage, the tracking performance of the Agility using the test bench yielded promising results, making the technique eligible for translation to tracking using clinical imaging modalities.
OI Denis de Senneville, Baudouin/0000-0001-5284-8474
SN 0031-9155
EI 1361-6560
PD MAR 7
PY 2015
VL 60
IS 5
BP 2005
EP 2017
DI 10.1088/0031-9155/60/5/2005
UT WOS:000349530700017
PM 25675279
ER

PT J
AU Fu, XM
   Shi, XD
   Yan, LX
   Zhang, HL
   Chang, ZY
AF Fu, Xinmiao
   Shi, Xiaodong
   Yan, Linxuan
   Zhang, Hanlin
   Chang, Zengyi
TI In Vivo Substrate Diversity and Preference of Small Heat Shock Protein
   IbpB as Revealed by Using a Genetically Incorporated Photo-cross-linker
SO JOURNAL OF BIOLOGICAL CHEMISTRY
AB Small heat shock proteins (sHSPs), as ubiquitous molecular chaperones found in all forms of life, are known to be able to protect cells against stresses and suppress the aggregation of a variety of model substrate proteins under in vitro conditions. Nevertheless, it is poorly understood what natural substrate proteins are protected by sHSPs in living cells. Here, by using a genetically incorporated photo-cross-linker (p-benzoyl-L-phenylalanine), we identified a total of 95 and 54 natural substrate proteins of IbpB (an sHSP from Escherichia coli) in living cells with and without heat shock, respectively. Functional profiling of these proteins (110 in total) suggests that IbpB, although binding to a wide range of cellular proteins, has a remarkable substrate preference for translation-related proteins (e. g. ribosomal proteins and amino-acyl tRNA synthetases) and moderate preference for metabolic enzymes. Furthermore, these two classes of proteins were found to be more prone to aggregation and/or inactivation in cells lacking IbpB under stress conditions (e. g. heat shock). Together, our in vivo data offer novel insights into the chaperone function of IbpB, or sHSPs in general, and suggest that the preferential protection on the protein synthesis machine and metabolic enzymes may dominantly contribute to the well known protective effect of sHSPs on cell survival against stresses.
RI Fu, Xinmiao/ABE-9050-2020; Zhang, Han/HQZ-4797-2023
OI Fu, Xinmiao/0000-0003-3361-6904; Zhang, Hanlin/0000-0001-9353-6071
EI 1083-351X
PD NOV 1
PY 2013
VL 288
IS 44
BP 31646
EP 31654
DI 10.1074/jbc.M113.501817
UT WOS:000330596200023
PM 24045939
ER

PT J
AU Verma, S
   Kim, WJ
   Shakir, H
AF Verma, S
   Kim, WJ
   Shakir, H
TI Multi-axis maglev nanopositioner for precision manufacturing and
   manipulation applications
SO IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS
CT 39th Annual Meeting of the IEEE-Industry-Applications-Society
CY OCT 03-07, 2004
CL Seattle, WA
SP IEEE Ind Applicat Soc
AB We present a six-axis magnetic-levitation (maglev) stage capable of precision positioning down to several nanometers. This stage has a simple and compact mechanical structure advantageous to meet the performance requirements in the next-generation nanomanufacturing. It uses the minimum number of linear actuators required to generate all six axis motions. In this paper, we describe the electromechanical design, modeling, and control, and the electronic instrumentation to control this maglev system. The stage has a light moving-part mass of 0.2126 kg. It is capable of generating translation of 300 mu m in the x, y, and z axes, and rotation of 3 mrad about the three orthogonal axes. The stage demonstrates position resolution better than 5 nm rms and position noise less than 2 nm rms. Experimental results presented in this paper show that the stage can carry, orient, and precisely position a payload as heavy as 0.4 kg. The pull-out force was found to be 8.08 N in the vertical direction. Furthermore, under a load variation of 0.14 N, the nanopositioner recovers its regulated position within 0.6 s. All these experimental results match quite closely with the calculated values because of the accurate plant model and robust controller design. This device can be used as a positioning stage for numerous applications, including photolithography for semiconductor manufacturing, microscopic scanning, fabrication and assembly of nanostructures, and microscale rapid prototyping.
SN 0093-9994
EI 1939-9367
PD SEP-OCT
PY 2005
VL 41
IS 5
BP 1159
EP 1167
DI 10.1109/TIA.2005.853374
UT WOS:000232012000004
ER

PT C
AU Hou, SF
   Chen, LW
   Ye, YF
AF Hou, Shifu
   Chen, Lingwei
   Ye, Yanfang
GP IEEE
TI Summarizing Source Code from Structure and Context
SO 2022 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / IEEE World
   Congress on Computational Intelligence (IEEE WCCI) / International Joint
   Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary
   Computation (IEEE CEC)
CY JUL 18-23, 2022
CL Padua, ITALY
SP IEEE, Int Neural Network Soc, IEEE Computat Intelligence Soc, Evolutionary Programming Soc, IET, Univ Padova, Dept Math Tullio Levi Civita, European Space Agcy, expert.ai, Elsevier, Springer Nature, Google, Baker & Hughes, NVIDIA
AB Modern software developers tend to engage in social coding platforms to reuse code snippets to expedite the development process, while the codes on such platforms are often suffering from comments being mismatched, missing or outdated. This puts the code search and comprehension in difficulty, and increases the burden of maintenance for software building upon these codes. As summarizing code is beneficial yet it is very expensive for manual operation, in this paper, we elaborate an automatic and effective code summarization paradigm to address this laborious challenge. We represent a given code snippet as an abstract syntax tree (AST), and generate a set of compositional root-to-leaf paths to make the AST accessible regarding code context and structure in a less complex yet expressive way. Accordingly, we design a tree-based transformer model, called TreeXFMR, on these paths to summarize source code in a hierarchical attention operation. This yields two advantages on code representation learning: (1) attention mechanisms at token- and path-level attend the semantics and interactions of source code from different aspects; (2) bi-level positional encodings introduced reveal the intra- and inter-path structure of AST and improve the unambiguity of the representations. During decoding, TreeXFMR attends such learned representations to produce each output of natural language word. We further pre-train the transformer to achieve faster and better training convergence results. Extensive experiments on the code collection from GitHub demonstrate the effectiveness of TreeXFMR, which significantly outperforms state-of-the-art baselines.
SN 2161-4393
BN 978-1-7281-8671-9
PY 2022
DI 10.1109/IJCNN55064.2022.9892013
UT WOS:000867070901023
ER

PT J
AU Wardhana, H
   Ashari, A
   Sari, AK
AF Wardhana, Helna
   Ashari, Ahmad
   Sari, Anny Kartika
TI Transformation of SysML Requirement Diagram into OWL Ontologies
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
AB The Requirement Diagrams are used by the System Modeling Language (SysML) to depict and model non-functional requirements, such as response time, size, or system functionality, which cannot be accommodated in the Unified Modeling Language (UML). Nevertheless, SysML still lacks the capability to represent the semantic contexts within the design. Web Ontology Language (OWL) can be used to capture the semantic context of system design; hence, the transformation of SysML diagrams into OWL is needed. The current method of SysML Diagrams transformation into OWL is still done manually so that it is very vulnerable to errors, and the translation process requires more time and effort for system engineers. This research proposes a model that can automatically transform a SysML Requirement Diagram into an OWL file so that system designs can be easily understood by both humans and machines. It also allows users to extract knowledge contained in the previous diagrams. The transformation process makes use of a transformation rule and an algorithm that can be used to change a SysML Requirement Diagram into an OWL ontology file. XML Metadata Interchange (XMI) serialization is used as the bridge to perform the transformation. The produced ontology can be viewed in Protege. The class and subclass hierarchy, as well as the object properties and data properties, are clearly shown. In the experiment, it is also shown that the model can conduct the transformation correctly.
RI Ashari, Ahmad/AAB-6758-2021; Sari, Anny Kartika/E-6774-2019
OI Sari, Anny Kartika/0000-0002-7038-7349
SN 2158-107X
EI 2156-5570
PD APR
PY 2020
VL 11
IS 4
BP 106
EP 114
UT WOS:000537489900015
ER

PT J
AU Cai, HH
   Zhu, JJ
   Yu, YQ
AF Cai, Huanhuan
   Zhu, Jiajia
   Yu, Yongqiang
TI Robust prediction of individual personality from brain functional
   connectome
SO SOCIAL COGNITIVE AND AFFECTIVE NEUROSCIENCE
AB Neuroimaging studies have linked inter-individual variability in the brain to individualized personality traits. However, only one or several aspects of personality have been effectively predicted based on brain imaging features. The objective of this study was to construct a reliable prediction model of personality in a large sample by using connectome-based predictive modeling (CPM), a recently developed machine learning approach. High-quality resting-state functional magnetic resonance imaging data of 810 healthy young participants from the Human Connectome Project dataset were used to construct large-scale brain networks. Personality traits of the five-factor model (FFM) were assessed by the NEO Five Factor Inventory. We found that CPM successfully and reliably predicted all the FFM personality factors (agreeableness, openness, conscientiousness and neuroticism) other than extraversion in novel individuals. At the neural level, we found that the personality-associated functional networks mainly included brain regions within default mode, frontoparietal executive control, visual and cerebellar systems. Although different feature selection thresholds and parcellation strategies did not significantly influence the prediction results, some findings lost significance after controlling for confounds including age, gender, intelligence and head motion. Our finding of robust personality prediction from an individual's unique functional connectome may help advance the translation of 'brain connectivity fingerprinting' into real-world personality psychological settings.
SN 1749-5016
EI 1749-5024
PD MAR
PY 2020
VL 15
IS 3
BP 359
EP 369
DI 10.1093/scan/nsaa044
UT WOS:000537536300010
PM 32248238
ER

PT C
AU van Schaik, S
   Milburn, A
   Osterlund, S
   Frigo, P
   Maisuradze, G
   Razavi, K
   Bos, H
   Giuffrida, C
AF van Schaik, Stephan
   Milburn, Alyssa
   Osterlund, Sebastian
   Frigo, Pietro
   Maisuradze, Giorgi
   Razavi, Kaveh
   Bos, Herbert
   Giuffrida, Cristiano
GP IEEE
TI RIDL: Rogue In-Flight Data Load
SO 2019 IEEE SYMPOSIUM ON SECURITY AND PRIVACY (SP 2019)
SE IEEE Symposium on Security and Privacy
CT 40th IEEE Symposium on Security and Privacy (SP)
CY MAY 19-23, 2019
CL San Francisco, CA
SP IEEE, IEEE Comp Soc, CS Financial
AB We present Rogue In-flight Data Load (RIDL), a new class of speculative unprivileged and constrained attacks to leak arbitrary data across address spaces and privilege boundaries (e.g., process, kernel, SGX, and even CPU-internal operations). Our reverse engineering efforts show such vulnerabilities originate from a variety of micro-optimizations pervasive in commodity (Intel) processors, which cause the CPU to speculatively serve loads using extraneous CPU-internal in-flight data (e.g., in the line fill buffers). Contrary to other state-of-the-art speculative execution attacks, such as Spectre, Meltdown and Foreshadow, RIDL can leak this arbitrary in-flight data with no assumptions on the state of the caches or translation data structures controlled by privileged software.
   The implications are worrisome. First, RIDL attacks can be implemented even from linear execution with no invalid page faults, eliminating the need for exception suppression mechanisms and enabling system-wide attacks from arbitrary unprivileged code (including JavaScript in the browser). To exemplify such attacks, we build a number of practical exploits that leak sensitive information from victim processes, virtual machines, kernel, SGX and CPU-internal components. Second, and perhaps more importantly, RIDL bypasses all existing "spot" mitigations in software (e.g., KPTI, PTE inversion) and hardware (e.g., speculative store bypass disable) and cannot easily be mitigated even by more heavyweight defenses (e.g., L1D flushing or disabling SMT). RIDL questions the sustainability of a per-variant, spot mitigation strategy and suggests more fundamental mitigations are needed to contain ever-emerging speculative execution attacks.
RI Giuffrida, Cristiano/GYE-2013-2022
OI Giuffrida, Cristiano/0000-0002-8329-5929; Razavi,
   Kaveh/0000-0002-8588-7100; Bos, Herbert/0000-0001-6179-1510; van Schaik,
   Stephan/0000-0003-4609-7103; Osterlund, Sebastian/0000-0003-0636-9848
SN 1081-6011
BN 978-1-5386-6660-9
PY 2019
BP 88
EP 105
DI 10.1109/SP.2019.00087
UT WOS:000510006100006
ER

PT J
AU Speier, W
   Arnold, C
   Pouratian, N
AF Speier, W.
   Arnold, C.
   Pouratian, N.
TI Integrating language models into classifiers for BCI communication: a
   review
SO JOURNAL OF NEURAL ENGINEERING
AB Objective. The present review systematically examines the integration of language models to improve classifier performance in brain-computer interface (BCI) communication systems. Approach. The domain of natural language has been studied extensively in linguistics and has been used in the natural language processing field in applications including information extraction, machine translation, and speech recognition. While these methods have been used for years in traditional augmentative and assistive communication devices, information about the output domain has largely been ignored in BCI communication systems. Over the last few years, BCI communication systems have started to leverage this information through the inclusion of language models. Main results. Although this movement began only recently, studies have already shown the potential of language integration in BCI communication and it has become a growing field in BCI research. BCI communication systems using language models in their classifiers have progressed down several parallel paths, including: word completion; signal classification; integration of process models; dynamic stopping; unsupervised learning; error correction; and evaluation. Significance. Each of these methods have shown significant progress, but have largely been addressed separately. Combining these methods could use the full potential of language model, yielding further performance improvements. This integration should be a priority as the field works to create a BCI system that meets the needs of the amyotrophic lateral sclerosis population.
RI Speier, William/H-9974-2019
OI Speier, William/0000-0002-0890-8684; Pouratian,
   Nader/0000-0002-0426-3241
SN 1741-2560
EI 1741-2552
PD JUN
PY 2016
VL 13
IS 3
AR 031002
DI 10.1088/1741-2560/13/3/031002
UT WOS:000375701200002
PM 27153565
ER

PT J
AU Basirat, A
   Faili, H
AF Basirat, Ali
   Faili, Heshaam
TI Bridge the gap between statistical and hand-crafted grammars
SO COMPUTER SPEECH AND LANGUAGE
AB LTAG is a rich formalism for performing NLP tasks such as semantic interpretation, parsing, machine translation and information retrieval. Depend on the specific NLP task, different kinds of LTAGs for a language may be developed. Each of these LTAGs is enriched with some specific features such as semantic representation and statistical information that make them suitable to be used in that task. The distribution of these capabilities among the LTAGs makes it difficult to get the benefit from all of them in NLP applications.
   This paper discusses a statistical model to bridge between two kinds LTAGs for a natural language in order to benefit from the capabilities of both kinds. To do so, an HMM was trained that links an elementary tree sequence of a source LTAG onto an elementary tree sequence of a target LTAG. Training was performed by using the standard HMM training algorithm called Baum-Welch. To lead the training algorithm to a better solution, the initial state of the HMM was also trained by a novel EM-based semi-supervised bootstrapping algorithm.
   The model was tested on two English LTAGs, XTAG (XTAG-Group, 2001) and MICA's grammar (Bangalore et al., 2009) as the target and source LTAGs, respectively. The empirical results confirm that the model can provide a satisfactory way for linking these LTAGs to share their capabilities together. (C) 2013 Elsevier Ltd. All rights reserved.
OI Basirat, Ali/0000-0002-4718-886X
SN 0885-2308
EI 1095-8363
PD AUG
PY 2013
VL 27
IS 5
BP 1085
EP 1104
DI 10.1016/j.csl.2013.02.001
UT WOS:000318139300003
ER

PT J
AU Sen, MK
   Steffen, T
   Beckman, L
   Tsantrizos, A
   Reindl, R
   Aebi, M
AF Sen, MK
   Steffen, T
   Beckman, L
   Tsantrizos, A
   Reindl, R
   Aebi, M
TI Atlantoaxial fusion using anterior transarticular screw fixation of
   C1-C2: technical innovation and biomechanical study
SO EUROPEAN SPINE JOURNAL
AB This study is an attempt to describe a new technique for anterior transarticular screw fixation of the atlantoaxial joints, and to compare the stability of this construct to posterior transarticular screw fixation with and without laminar cerclage wiring. Nine human cadaveric specimens were included in this study. The C1 - C2 motion segment was instrumented using either anterior transarticular screws ( group 1), posterior transarticular screws alone ( group 2), or posterior screws with interlaminar cerclage wires ( group 3). Using an unconstrained mechanical testing machine, the specimens were tested in rotation, lateral bending, and flexion-extension using nondestructive loads of +/- 2 N m. The specimens were also tested in translation using nondestructive loads of +/- 100 N. All values for the three groups with regards to anterior-posterior displacement, rotation, and lateral bending were similar as determined using a Kruskal - Wallis rank sum test with a significance level of p< 0.05. The only significant difference was registered in flexion-extension where the cerclage wire added some strength to the construct. Anterior transarticular screw fixation of the atlantoaxial spine has several advantages over posterior fixation techniques, and is as stable as posterior transarticular fixation in all clinically significant planes of motion. The addition of posterior interlaminar cerclage wiring further improves resistance to flexion-extension forces. Anterior transarticular screw fixation of the atlantoaxial joint is a useful technique for achieving C1 - C2 stabilization.
SN 0940-6719
EI 1432-0932
PD JUN
PY 2005
VL 14
IS 5
BP 512
EP 518
DI 10.1007/s00586-004-0823-0
UT WOS:000229876200012
PM 15668776
ER

PT J
AU Wilks, Y
   Catizone, R
AF Wilks, Y
   Catizone, R
TI Can we make information extraction more adaptive?
SO INFORMATION EXTRACTION: TOWARDS SCALABLE, ADAPTABLE SYSTEMS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
AB It seems widely agreed that IE (Information Extraction) is now a tested language technology that has reached precision + recall values that put it in about the same position as Information Retrieval and Machine Translation, both of which are widely used commercially. There is also a clear range of practical applications that would be eased by the sort of template-style data that IE provides. The problem for wider deployment of the technology is adaptability: the ability to customize 1E rapidly to new domains.
   In this paper we discuss some methods that have been tried to ease this problem, and to create something more rapid than the bench-mark one-month figure, which was roughly what ARPA teams in IE needed to adapt an existing system by hand to a new domain of corpora and templates. An important distinction in discussing the issue is the degree to which a user can be assumed to know what is wanted, to have preexisting templates ready to hand, as opposed to a user who has a vague idea of what is needed from a corpus.
   We shall discuss attempts to derive templates directly from corpora; to derive knowledge structures and lexicons directly from corpora, including discussion of the recent LE project ECRAN which attempted to tune existing lexicons to new corpora. An important issue is how far established methods in Information Retrieval of tuning to a user's needs with feedback at an interface can be transferred to IE.
SN 0302-9743
PY 1999
VL 1714
BP 1
EP 16
UT WOS:000089103600001
ER

PT J
AU Xu, RY
   Zhou, XH
   Han, JQ
   Dwight, RP
   Xiao, H
AF Xu, Ruiying
   Zhou, Xu-Hui
   Han, Jiequn
   Dwight, Richard P.
   Xiao, Heng
TI A PDE-free, neural network-based eddy viscosity model coupled with RANS
   equations
SO INTERNATIONAL JOURNAL OF HEAT AND FLUID FLOW
AB In fluid dynamics, constitutive models are often used to describe the unresolved turbulence and to close the Reynolds averaged Navier-Stokes (RANS) equations. Traditional PDE-based constitutive models are usually too rigid to calibrate with a large set of high-fidelity data. Moreover, commonly used turbulence models are based on the weak equilibrium assumption, which cannot adequately capture the nonlocal physics of turbulence. In this work, we propose using a vector-cloud neural network (VCNN) to learn the nonlocal constitutive model, which maps a regional mean flow field to the local turbulence quantities without solving the transport PDEs. The network is strictly invariant to coordinate translation, rotation, and uniform motion, as well as ordering of the input points. The VCNN-based nonlocal constitutive model is trained and evaluated on flows over a family of parameterized periodic hills. Numerical results demonstrate its predictive capability on target turbulence quantities of turbulent kinetic energy k and dissipation ". More importantly, we investigate the robustness and stability of the method by coupling the trained model back to RANS solver. The solver shows good convergence with the simulated velocity field comparable to that based on k-" model when starting from a reasonable initial condition. This study, as a proof of concept, highlights the feasibility of using a nonlocal, frame-independent, neural network-based constitutive model to close the RANS equations, paving the way for the further emulation of the Reynolds stress transport models.
RI Xiao, Heng/B-6620-2014
OI Xiao, Heng/0000-0002-3323-4028; Zhou, Xu-Hui/0000-0003-1156-332X
SN 0142-727X
EI 1879-2278
PD DEC
PY 2022
VL 98
AR 109051
DI 10.1016/j.ijheatfluidflow.2022.109051
EA OCT 2022
UT WOS:000867752100005
ER

PT J
AU Morimoto, K
   Wu, ML
   Ardelean, A
   Charbon, E
AF Morimoto, Kazuhiro
   Wu, Ming-Lo
   Ardelean, Andrei
   Charbon, Edoardo
TI Superluminal Motion-Assisted Four-Dimensional Light-in-Flight Imaging
SO PHYSICAL REVIEW X
AB Advances in high-speed imaging techniques have opened new possibilities for capturing ultrafast phenomena such as light propagation in air or through media. Capturing light in flight in three-dimensional xyt space has been reported based on various types of imaging systems, whereas reconstruction of light-in-flight information in the fourth dimension z has been a challenge. We demonstrate the four-dimensional light-in-flight imaging based on the observation of a superluminal motion captured by a new time-gated megapixel single-photon avalanche diode camera. A high-resolution light-in-flight video is generated without laser scanning, camera translation, interpolation, or dark noise subtraction. An unsupervised machine-learning technique is applied to analyze the measured spatiotemporal data set. A theoretical formula is introduced to perform least-square regression for numerically solving a nonlinear inverse problem, and extra-dimensional information is recovered without prior knowledge. The algorithm relies on the mathematical formulation equivalent to the superluminal motion in astrophysics, which is scaled by a factor of a quadrillionth. The reconstructed light-in-flight trajectory shows good agreement with the actual geometry of the light path. Applicability of the reconstruction approach to more complex scenes with multiple overlapped light trajectories is verified based on a data set generated by Monte Carlo simulations. Our approach could potentially provide novel functionalities to high-speed imaging applications such as non-line-of-sight imaging and time-resolved optical tomography.
OI Wu, Ming-Lo/0000-0001-8198-1901; Morimoto, Kazuhiro/0000-0002-8953-6041
SN 2160-3308
PD JAN 8
PY 2021
VL 11
IS 1
AR 011005
DI 10.1103/PhysRevX.11.011005
UT WOS:000606324800001
ER

PT J
AU Kanwal, S
   Malik, K
   Shahzad, K
   Aslam, F
   Nawaz, Z
AF Kanwal, Safia
   Malik, Kamran
   Shahzad, Khurram
   Aslam, Faisal
   Nawaz, Zubair
TI Urdu Named Entity Recognition: Corpus Generation and Deep Learning
   Applications
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB Named Entity Recognition (NER) plays a pivotal role in various natural language processing tasks, such as machine translation and automatic question-answering systems. Recognizing the importance of NER, a plethora of NER techniques for Western and Asian languages have been developed. However, despite having over 490 million Urdu language speakers worldwide, NER resources for Urdu are either non-existent or inadequate. To fill this gap, this article makes four key contributions. First, we have developed the largest Urdu NER corpus, which contains 926,776 tokens and 99,718 carefully annotated NEs. The developed corpus has at least doubled the number of manually tagged NEs as compared to any of the existing Urdu NER corpora. Second, we have generated six new word embeddings using three different techniques, fastText, Word2vec, and Glove, on two corpora of Urdu text. These are the only publicly available embeddings for the Urdu language, besides the recently released Urdu word embeddings by Facebook. Third, we have pioneered in the application of deep learning techniques, NN and RNN, for Urdu named entity recognition. Finally, we have performed 10-folds of 32 different experiments using the combinations of a traditional supervised learning and deep learning techniques, seven types of word embeddings, and two different Urdu NER datasets. Based on the analysis of the results, several valuable insights are provided about the effectiveness of deep learning techniques, the impact of word embeddings, and variations of datasets.
RI Shahzad, Khurram/AAT-6431-2020
OI kanwal, safia/0000-0003-2041-9696; Shahzad, Dr.
   Khurram/0000-0001-8433-6705
SN 2375-4699
EI 2375-4702
PD JAN
PY 2020
VL 19
IS 1
AR 8
DI 10.1145/3329710
UT WOS:000512296500008
ER

PT J
AU Amancio, DR
   Nunes, MGV
   Oliveira, ON
   Costa, LD
AF Amancio, Diego R.
   Nunes, Maria G. V.
   Oliveira, Osvaldo N., Jr.
   Costa, Luciano da F.
TI Extractive summarization using complex networks and syntactic dependency
SO PHYSICA A-STATISTICAL MECHANICS AND ITS APPLICATIONS
AB The realization that statistical physics methods can be applied to analyze written texts represented as complex networks has led to several developments in natural language processing, including automatic summarization and evaluation of machine translation. Most importantly, so far only a few metrics of complex networks have been used and therefore there is ample opportunity to enhance the statistics-based methods as new measures of network topology and dynamics are created. In this paper, we employ for the first time the metrics betweenness, vulnerability and diversity to analyze written texts in Brazilian Portuguese. Using strategies based on diversity metrics, a better performance in automatic summarization is achieved in comparison to previous work employing complex networks. With an optimized method the Rouge score (an automatic evaluation method used in summarization) was 0.5089, which is the best value ever achieved for an extractive summarizer with statistical methods based on complex networks for Brazilian Portuguese. Furthermore, the diversity metric can detect keywords with high precision, which is why we believe it is suitable to produce good summaries. It is also shown that incorporating linguistic knowledge through a syntactic parser does enhance the performance of the automatic summarizers, as expected, but the increase in the Rouge score is only minor. These results reinforce the suitability of complex network methods for improving automatic summarizers in particular, and treating text in general. (C) 2011 Elsevier B.V. All rights reserved.
RI Oliveira, Osvaldo N./A-1714-2008; da F. Costa, Luciano/H-5475-2011;
   Amancio, Diego Raphael/I-1071-2012
OI Oliveira, Osvaldo N./0000-0002-5399-5860; da F. Costa,
   Luciano/0000-0001-5203-4366; 
SN 0378-4371
EI 1873-2119
PD FEB 15
PY 2012
VL 391
IS 4
BP 1855
EP 1864
DI 10.1016/j.physa.2011.10.015
UT WOS:000300459700091
ER

PT J
AU Mehta, N
   Shaik, S
   Prasad, A
   Chaichi, A
   Sahu, SP
   Liu, QL
   Hasan, SMA
   Donnarumma, F
   Murray, KK
   Devireddy, R
   Gartia, MR
   Sheikh, E
   Fu, X
AF Mehta, Nishir
   Shaik, Shahensha
   Prasad, Alisha
   Chaichi, Ardalan
   Sahu, Sushant P.
   Liu, Qianglin
   Hasan, Syed Mohammad Abid
   Donnarumma, Fabrizio
   Murray, Kermit K.
   Devireddy, Ram
   Gartia, Manas Ranjan
   Sheikh, Elnaz
   Fu, Xing
TI Multimodal Label-Free Monitoring of Adipogenic Stem Cell Differentiation
   Using Endogenous Optical Biomarkers
SO ADVANCED FUNCTIONAL MATERIALS
AB Stem cell-based therapies carry significant promise for treating human diseases. However, clinical translation of stem cell transplants for effective treatment requires precise non-destructive evaluation of the purity of stem cells with high sensitivity (<0.001% of the number of cells). Here, a novel methodology using hyperspectral imaging (HSI) combined with spectral angle mapping-based machine learning analysis is reported to distinguish differentiating human adipose-derived stem cells (hASCs) from control stem cells. The spectral signature of adipogenesis generated by the HSI method enables identifying differentiated cells at single-cell resolution. The label-free HSI method is compared with the standard techniques such as Oil Red O staining, fluorescence microscopy, and qPCR that are routinely used to evaluate adipogenic differentiation of hASCs. HSI is successfully used to assess the abundance of adipocytes derived from transplanted cells in a transgenic mice model. Further, Raman microscopy and multiphoton-based metabolic imaging is performed to provide complementary information for the functional imaging of the hASCs. Finally, the HSI method is validated using matrix-assisted laser desorption/ionization-mass spectrometry imaging of the stem cells. The study presented here demonstrates that multimodal imaging methods enable label-free identification of stem cell differentiation with high spatial and chemical resolution.
RI Sheikh, Elnaz/GRX-1406-2022
SN 1616-301X
EI 1616-3028
PD OCT
PY 2021
VL 31
IS 43
AR 2103955
DI 10.1002/adfm.202103955
EA AUG 2021
UT WOS:000681610100001
PM 34924914
ER

PT C
AU Fu, ZT
   Gao, HJ
   Guo, WW
   Jha, SK
   Jia, J
   Liu, XW
   Long, B
   Shi, J
   Wang, SD
   Zhou, MZ
AF Fu, Zhoutong
   Gao, Huiji
   Guo, Weiwei
   Jha, Sandeep Kumar
   Jia, Jun
   Liu, Xiaowei
   Long, Bo
   Shi, Jun
   Wang, Sida
   Zhou, Mingzhou
GP ASSOC COMP MACHINERY
TI Deep Learning for Search and Recommender Systems in Practice
SO KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY & DATA MINING
CT 26th ACM SIGKDD International Conference on Knowledge Discovery and Data
   Mining (KDD)
CY AUG 23-27, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGMOD, ACM SIGKDD
AB In this talk, we will go over the components of personalized search and recommender systems and demonstrate the applications of various deep learning techniques along the way.
   Search and recommender systems are probably the most prevalent ML powered application across the industry. They share most of the components composition and provide a user a ranked list of items, while there is subtle difference that a search system typically acts passively with a clear user intention in terms of queries and a recommender system acts more proactively.
   Deep learning has been wildly successful in solving complex tasks such as image recognition, speech recognition, natural language processing and understanding, machine translation, etc. In the area of personalized recommender systems, deep learning has been showing tremendous impact in recent years.
   Search and recommender systems can be staged roughly in three phases: 1. User and query understanding, where a query or a user profile are processed so that the systems can use the processed information to 2. retrieve all the related items (high recall) and 3. rank the items by the order of the most relevance to the user's intent (high precision). Each phase has its unique challenges but deep learning has been ubiquitously pushing beyond the limit.
   After walking through the talk, we hope the audience would gain some first-hand experience building a personalized search/recommender system using deep learning techniques.
BN 978-1-4503-7998-4
PY 2020
BP 3515
EP 3516
DI 10.1145/3394486.3406709
UT WOS:000749552303063
ER

PT C
AU Nogalski, M
   Fohl, W
AF Nogalski, Malte
   Fohl, Wolfgang
BE Hollerer, T
   Interrante, V
   Lecuyer, A
   Suma, E
TI Acoustic Redirected Walking with Auditory Cues by Means of Wave Field
   Synthesis
SO 2016 IEEE VIRTUAL REALITY CONFERENCE (VR)
SE Proceedings of the IEEE Virtual Reality Annual International Symposium
CT IEEE Virtual Reality Conference (IEEE VR)
CY MAR 19-23, 2016
CL Greenville, SC
SP IEEE, IEEE Comp Soc, IEEE Comp Soc Visualizat & Graph Tech Comm, Clemson Univ
AB We present an experiment to identify detection thresholds for acoustic redirected walking by means of wave field synthesis. The most natural way to navigate an avatar through an immersive virtual environment (IVE) is by copying the tracked physical movements of a user. Redirected walking offers an approach to tackle the discrepancy between the potentially infinite IVE and the generally limited available physical space or tracking area, by applying manipulations, such as rotations or translations, to the IVE in form of gains to the users movements. 39 blindfolded test subjects performed a total of 2777 constant stimulus trials with various amounts of rotation and curvature gains. The test subjects were divided into four groups with different knowledge of the experiment, and one group performed two-alternative-forced-choice tasks, while the others could give feedback freely. The detection thresholds were greatly dependent on the groups i.e., the knowledge of the experiment. The 25% detection threshold was reached by the most relevant test group at gains that up-scaled rotations by 5%, down-scaled them by 37.5%, and bend a straight path into a circle with a radius of 5.71 meters. Almost no signs of simulator sickness could be observed.
SN 1087-8270
BN 978-1-5090-0836-0
PY 2016
BP 245
EP 246
UT WOS:000386307300063
ER

PT J
AU Zou, BW
   Huang, RT
   Xu, ZZ
   Hong, Y
   Zhou, GD
AF Zou, Bo-Wei
   Huang, Rong-Tao
   Xu, Zeng-Zhuang
   Hong, Yu
   Zhou, Guo-Dong
TI Language Adaptation for Entity Relation Classification via Adversarial
   Neural Networks
SO JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY
AB Entity relation classification aims to classify the semantic relationship between two marked entities in a given sentence, and plays a vital role in various natural language processing applications. However, existing studies focus on exploiting mono-lingual data in English, due to the lack of labeled data in other languages. How to effectively benefit from a richly-labeled language to help a poorly-labeled language is still an open problem. In this paper, we come up with a language adaptation framework for cross-lingual entity relation classification. The basic idea is to employ adversarial neural networks (AdvNN) to transfer feature representations from one language to another. Especially, such a language adaptation framework enables feature imitation via the competition between a sentence encoder and a rival language discriminator to generate effective representations. To verify the effectiveness of AdvNN, we introduce two kinds of adversarial structures, dual-channel AdvNN and single-channel AdvNN. Experimental results on the ACE 2005 multilingual training corpus show that our single-channel AdvNN achieves the best performance on both unsupervised and semi-supervised scenarios, yield- ing an improvement of 6.61% and 2.98% over the state-of-the-art, respectively. Compared with baselines which directly adopt a machine translation module, we find that both dual-channel and single-channel AdvNN significantly improve the performances (F1) of cross-lingual entity relation classification. Moreover, extensive analysis and discussion demonstrate the appropriateness and effectiveness of different parameter settings in our language adaptation framework.
OI zhou, guodong/0000-0002-7887-5099
SN 1000-9000
EI 1860-4749
PD JAN
PY 2021
VL 36
IS 1
BP 207
EP 220
DI 10.1007/s11390-020-9713-0
UT WOS:000615566300013
ER

PT J
AU Xu, LM
   Chen, GL
   Ye, W
   Li, QC
AF Xu, Lingmin
   Chen, Genliang
   Ye, Wei
   Li, Qinchuan
TI Design, analysis and optimization of Hex4, a new 2R1T overconstrained
   parallel manipulator with actuation redundancy
SO ROBOTICA
AB PMs with two rotations and one translation (2R1T) have been used as skeletons in various advanced manufacturing equipment where high accuracy and stiffness are basic requirements. Considering the advantages of redundant actuation and overconstrained structure, such as reduced singularities and improved stiffness, a new 2R1T overconstrained PM with actuation redundancy, called Hex4, is proposed in this paper. This is a 2-(P) under bar UR/2-R (P) under barU PM (where (P) under bar denotes an actuated prismatic joint, U a universal joint, and R a revolute joint) that is actuated by four prismatic joints. Compared with some existing 2R1T overconstrained PMs with actuation redundancy, the main advantage of the proposed PM is that the heavy motors of two limbs are mounted on the base to reduce the movable mass and improve dynamic response. First, mobility analysis, inverse kinematics, and velocity analysis are presented. Then, the local transmission index and good transmission workspace are used to evaluate the motion/force transmissibility of the Hex4 PM. The variation tendencies of the two indices with different link parameters are investigated. The singularity is then discussed by considering the motion/force transmissibility. Finally, link parameters are optimized to obtain an improved good transmission workspace. It is shown that the proposed PM has a good potential for high precision applications.
SN 0263-5747
EI 1469-8668
PD FEB
PY 2019
VL 37
IS 2
BP 358
EP 377
DI 10.1017/S0263574718001054
UT WOS:000454417500009
ER

PT J
AU Koppen, M
   Langer, T
AF Koppen, Mirko
   Langer, Thomas
TI Protein degradation within mitochondria: Versatile activities of AAA
   proteases and other peptidases
SO CRITICAL REVIEWS IN BIOCHEMISTRY AND MOLECULAR BIOLOGY
AB Cell survival depends on essential processes in mitochondria. Various proteases within these organelles regulate mitochondrial biogenesis and ensure the complete degradation of excess or damaged proteins. Many of these proteases are highly conserved and ubiquitous in eukaryotic cells. They can be assigned to three functional classes: processing peptidases, which cleave off mitochondrial targeting sequences of nuclearly encoded proteins and process mitochondrial proteins with regulatory functions; ATP-dependent proteases, which either act as processing peptidases with regulatory functions or as quality-control enzymes degrading non-native polypeptides to peptides; and oligopeptidases, which degrade these peptides and mitochondrial targeting sequences to amino acids. Disturbances of protein degradation within mitochondria cause severe phenotypes in various organisms and can lead to the induction of apoptotic programmes and cell-specific neuro degeneration in mammals. After an overview of the proteolytic system of mitochondria, we will focus on versatile functions of ATP-dependent AAA proteases in the inner membrane. These conserved proteolytic machines conduct protein quality surveillance of mitochondrial inner membrane proteins, mediate vectorial protein dislocation from membranes, and, acting as processing enzymes, control ribosome assembly, mitochondrial protein synthesis, and mitochondrial fusion. Implications of these functions for cell-specific axonal degeneration in hereditary spastic paraplegia will be discussed.
OI Langer, Thomas/0000-0003-1250-1462
SN 1040-9238
EI 1549-7798
PD MAY-JUN
PY 2007
VL 42
IS 3
BP 221
EP 242
DI 10.1080/10409230701380452
UT WOS:000247781600003
PM 17562452
ER

PT C
AU Shu, WH
   Shi, DM
   Qian, GL
   Wang, FS
AF Shu, WH
   Shi, DM
   Qian, GL
   Wang, FS
GP IEEE
   IEEE
TI An extension matrix approach to Chinese character recognition
SO SMC 2000 CONFERENCE PROCEEDINGS: 2000 IEEE INTERNATIONAL CONFERENCE ON
   SYSTEMS, MAN & CYBERNETICS, VOL 1-5
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
CT IEEE International Conference on Systems, Man and Cybernetics
CY OCT 08-11, 2000
CL NASHVILLE, TN
SP IEEE Inc, Syst Man & Cybernet Soc
AB Optical Character Recognition (OCR) provides a solution to acquire, archive and retrieve a large amount of paper-based information which is still commonly used in our daily life. The process of a classical optical character recognition system consists of a series of stages, such as format analysis, text segmentation, feature extraction and classification. This paper will. focus on the last two stages, and two contributions can be claimed: First, Rapid transformed stroke density features (SDF) are used for preliminary classification and outline primitive structural features for final classification. Second, the original extension matrix algorithm is improved by heuristic path searching on the basis of information entropy as well as Laplace error rate evaluation function. Our experimental results prove that the Rapid Transformed SDFs are insensitive to image translation or rotation, and that the improved extension matrix algorithm outperform other inductive approaches based on AE1 and AQ15. The excellent performance with respect to a large data set also indicates our proposed approach is effective and efficient. Taking into consideration of both the image and structural information, our proposed approach is able to solve the problem of noise which unavoidably exists in the practical case of handwritten Chinese character recognition. However, on account of great distortion and connection of strokes in low-constrained handwritten Chinese character recognition, we consider that it is necessary to incorporate the context-based post processing into character recognition so that the system will suit for practical use.
RI Shi, Daming/F-6017-2013
SN 1062-922X
BN 0-7803-6583-6
PY 2000
BP 2763
EP 2768
UT WOS:000166106900481
ER

PT C
AU Kaeser-Chen, C
   Dubois, E
   Schuur, F
   Moss, E
AF Kaeser-Chen, Christine
   Dubois, Elizabeth
   Schuur, Friederike
   Moss, Emanuel
GP Assoc Comp Machinery
TI Translation Tutorial: Positionality-Aware Machine Learning
SO FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS,
   ACCOUNTABILITY, AND TRANSPARENCY
CT ACM Conference on Fairness, Accountability, and Transparency (FAT)
CY JAN 27-30, 2020
CL Barcelona, SPAIN
SP Assoc Comp Machinery
AB world which is shaped by social and political contexts. Machine Learning (ML) systems have positionality, too, as a consequence of the choices we make when we develop ML systems. Being positionality-aware is key for ML practitioners to acknowledge and embrace the necessary choices embedded in ML by its creators. When groups form a shared view of the world, or group positionality, they have the power to embed and institutionalize their unique perspectives in artifacts such as standards and ontologies. For example, the international standard for reporting diseases and health conditions (International Classification of Diseases, ICD) is shaped by a distinctly medical, European and North American perspective. It dictates how we collect data, and limits what questions we can ask of data and what ML systems we can develop. Researchers struggle to study the effects of social factors on health outcomes because of what the ICD renders legible (usually in medicalized terms) and what it renders invisible (usually social contexts) in data. The ICD, as with all information infrastructures, promotes and propagates the perspective(s) of its creators. Over time, it establishes what counts as "truth".
   Positionality, and how it embeds itself in standards, ontologies, and data collection, is the root for bias in our data and algorithms. Every perspective has its limits - there is no view from nowhere. Without an awareness of positionality, the current debate on bias in machine learning is quite limited: adding more data to the set cannot remove bias. Instead, we propose positionality-aware ML, a new workflow focused on continuous evaluation and improvement of the fit between the positionality embedded in ML systems and the scenarios within which it is deployed.
   To demonstrate how to uncover positionality in standards, ontologies, data, and ML systems, we discuss recent work on online harassment of Canadian journalists and politicians on Twitter. Using legal definitions of hate speech and harassment, Twitter's community standards, and insight from interviews with journalists and politicians, we created standards and annotation guidelines for labeling the intensity of harassment in tweets. We then hand labeled a sample of data and through this process identified instances where positionality impacts choices about how many categories of harassment should exist, howto label boundary cases, and howto interpret messy data. We take three perspectives-technical, systems, socio-technical-that when combined illuminate areas of tension which serve as a signal of misalignment between the positionality embedded in the ML system and the deployment context. We demonstrate how the concept of positionality allows us to delineate sets of use cases that may not be suited for automated, ML solutions. Finally, we discuss strategies for developing positionality-aware ML systems, which embed a positionality appropriate for the application context, and continuously evolve to maintain this contextual fit, with an emphasis on the need for of democratic, egalitarian dialogues between knowledge-producing groups.
BN 978-1-4503-6936-7
PY 2020
BP 704
EP 704
DI 10.1145/3351095.3375666
UT WOS:000620151400094
ER

PT C
AU Suh, S
   Cho, H
AF Suh, Sungho
   Cho, Hansang
BE Tescher, AG
TI Registration of Point Cloud Data for HDD Stamped Base Inspection
SO APPLICATIONS OF DIGITAL IMAGE PROCESSING XXXVIII
SE Proceedings of SPIE
CT Conference on Applications of Digital Image Processing XXXVIII
CY AUG 10-13, 2015
CL San Diego, CA
SP SPIE
AB As a part of the HDD manufacturing process, HDD stamped base, an exterior container, is one of the most essential components in which various parts become assembled to compose a hard disk drive (HDD). Height errors that are caused by pressing, breaking or cracking can occur on the base, because it is designed by a stamping method. In order to detect the height errors, the inspection process is essential in the production fields. In the current industry, CMM (Coordinate Measurement Machine) is one of the representative machines that inspect certain regions on the product. The machine probes a designated point by an operator and judges the defect by comparing the height of the point to the originally designed height. However, the method takes much time to inspect each designated point resulting in a total of 17 minutes. In order to reduce the total inspection time, we propose an inspection method using 3D point cloud data acquired from a holographic sensor. To compare the height from acquired 3D point cloud data with the one from the originally designed CAD data, the exact point cloud registration is important. There are differences between 2D image registration and 3D point cloud registration, such as translation on each plane, rotation, tilt, and nonlinear transformations. The relationship between the acquired 3D point cloud data and the originally designed CAD data can be obtained by projective transformation. If the projective transformation matrix between the two is obtained, 3D point cloud data registration can be performed. In order to calculate 3D projective transformation matrix, corresponding points between 3D point cloud data and CAD data are required. To find the corresponding points, we use the height map which is projected from 3D point cloud data onto XY plane. The height map has pixel intensity from the height value of each point. If the height maps from 3D point cloud data and CAD data are matched, corresponding points can be estimated. As one of the features of the HDD stamped base, there are multiple circles on the base. In this paper, we find the corresponding points between 3D point cloud data and CAD data using circle fitting, and obtain 2D Affine transformation matrix from the corresponding points. By applying 2D Affine transformation matrix to height map, the corresponding points on the 3D coordinate can be obtained. Using such points, we propose the method designed to achieve 3D projective transformation matrix. To find the proper 3D projective transformation matrix, we formulate a cost function which uses the relationship of the corresponding points. Also the proper 3D projective transformation matrix can be calculated by minimizing the cost function. Then the 3D point cloud data can be matched to CAD data and the height values of each point of 3D point cloud can be compared to the CAD data.
RI Suh, Sungho/AAQ-3354-2021
OI Suh, Sungho/0000-0003-3723-1980
SN 0277-786X
EI 1996-756X
BN 978-1-62841-765-4
PY 2015
VL 9599
AR 95991P
DI 10.1117/12.2186246
UT WOS:000366385200049
ER

PT J
AU Pibiri, GE
   Venturini, R
AF Pibiri, Giulio Ermanno
   Venturini, Rossano
TI Handling Massive N-Gram Datasets Efficiently
SO ACM TRANSACTIONS ON INFORMATION SYSTEMS
AB Two fundamental problems concern the handling of large n-gram language models: Indexing, that is, compressing the n-grams and associated satellite values without compromising their retrieval speed, and estimation, that is, computing the probability distribution of the n-grams extracted from a large textual source.
   Performing these two tasks efficiently is vital for several applications in the fields of Information Retrieval, Natural Language Processing, and Machine Learning, such as auto-completion in search engines and machine translation.
   Regarding the problem of indexing, we describe compressed, exact, and lossless data structures that simultaneously achieve high space reductions and no time degradation with respect to the state-of-the-art solutions and related software packages. In particular, we present a compressed trie data structure in which each word of an n-gram following a context of fixed length k, that is, its preceding k words, is encoded as an integer whose value is proportional to the number of words that follow such context. Since the number of words following a given context is typically very small in natural languages, we lower the space of representation to compression levels that were never achieved before, allowing the indexing of billions of strings. Despite the significant savings in space, our technique introduces a negligible penalty at query time.
   Specifically, the most space-efficient competitors in the literature, which are both quantized and lossy, do not take less than our trie data structure and are up to 5 times slower. Conversely, our trie is as fast as the fastest competitor but also retains an advantage of up to 65% in absolute space.
   Regarding the problem of estimation, we present a novel algorithm for estimating modified Kneser-Ney language models that have emerged as the de-facto choice for language modeling in both academia and industry thanks to their relatively low perplexity performance. Estimating such models from large textual sources poses the challenge of devising algorithms that make a parsimonious use of the disk.
   The state-of-the-art algorithm uses three sorting steps in external memory: we show an improved construction that requires only one sorting step by exploiting the properties of the extracted n-gram strings. With an extensive experimental analysis performed on billions of n-grams, we show an average improvement of 4.5 times on the total runtime of the previous approach.
OI Pibiri, Giulio Ermanno/0000-0003-0724-7092
SN 1046-8188
EI 1558-2868
PD MAR
PY 2019
VL 37
IS 2
AR 25
DI 10.1145/3302913
UT WOS:000474861800012
ER

PT J
AU Gunasekeran, DV
   Zheng, FH
   Lim, GYS
   Chong, CCY
   Zhang, SH
   Ng, WY
   Keel, S
   Xiang, YF
   Park, KH
   Park, SJ
   Chandra, A
   Wu, L
   Campbel, JP
   Lee, AY
   Keane, PA
   Denniston, A
   Lam, DSC
   Fung, AT
   Chan, PRV
   Sadda, SR
   Loewenstein, A
   Grzybowski, A
   Fong, KCS
   Wu, WC
   Bachmann, LM
   Zhang, XL
   Yam, JC
   Cheung, CY
   Pongsachareonnont, P
   Ruamviboonsuk, P
   Raman, R
   Sakamoto, T
   Habash, R
   Girard, M
   Milea, D
   Ang, M
   Tan, GSW
   Schmetterer, L
   Cheng, CY
   Lamoureux, E
   Lin, HT
   van Wijngaarden, P
   Wong, TY
   Ting, DSW
AF Gunasekeran, Dinesh V. V.
   Zheng, Feihui
   Lim, Gilbert Y. S.
   Chong, Crystal C. Y.
   Zhang, Shihao
   Ng, Wei Yan
   Keel, Stuart
   Xiang, Yifan
   Park, Ki Ho
   Park, Sang Jun
   Chandra, Aman
   Wu, Lihteh
   Campbel, J. Peter
   Lee, Aaron Y. Y.
   Keane, Pearse A. A.
   Denniston, Alastair
   Lam, Dennis S. C.
   Fung, Adrian T. T.
   Chan, Paul R. V.
   Sadda, SriniVas R.
   Loewenstein, Anat
   Grzybowski, Andrzej
   Fong, Kenneth C. S.
   Wu, Wei-chi
   Bachmann, Lucas M.
   Zhang, Xiulan
   Yam, Jason C.
   Cheung, Carol Y. Y.
   Pongsachareonnont, Pear
   Ruamviboonsuk, Paisan
   Raman, Rajiv
   Sakamoto, Taiji
   Habash, Ranya
   Girard, Michael
   Milea, Dan
   Ang, Marcus
   Tan, Gavin S. W.
   Schmetterer, Leopold
   Cheng, Ching-Yu
   Lamoureux, Ecosse
   Lin, Haotian
   van Wijngaarden, Peter
   Wong, Tien Y. Y.
   Ting, Daniel S. W.
TI Acceptance and Perception of Artificial Intelligence Usability in Eye
   Care (APPRAISE) for Ophthalmologists: A Multinational Perspective
SO FRONTIERS IN MEDICINE
AB BackgroundMany artificial intelligence (AI) studies have focused on development of AI models, novel techniques, and reporting guidelines. However, little is understood about clinicians' perspectives of AI applications in medical fields including ophthalmology, particularly in light of recent regulatory guidelines. The aim for this study was to evaluate the perspectives of ophthalmologists regarding AI in 4 major eye conditions: diabetic retinopathy (DR), glaucoma, age-related macular degeneration (AMD) and cataract. MethodsThis was a multi-national survey of ophthalmologists between March 1st, 2020 to February 29th, 2021 disseminated via the major global ophthalmology societies. The survey was designed based on microsystem, mesosystem and macrosystem questions, and the software as a medical device (SaMD) regulatory framework chaired by the Food and Drug Administration (FDA). Factors associated with AI adoption for ophthalmology analyzed with multivariable logistic regression random forest machine learning. ResultsOne thousand one hundred seventy-six ophthalmologists from 70 countries participated with a response rate ranging from 78.8 to 85.8% per question. Ophthalmologists were more willing to use AI as clinical assistive tools (88.1%, n = 890/1,010) especially those with over 20 years' experience (OR 3.70, 95% CI: 1.10-12.5, p = 0.035), as compared to clinical decision support tools (78.8%, n = 796/1,010) or diagnostic tools (64.5%, n = 651). A majority of Ophthalmologists felt that AI is most relevant to DR (78.2%), followed by glaucoma (70.7%), AMD (66.8%), and cataract (51.4%) detection. Many participants were confident their roles will not be replaced (68.2%, n = 632/927), and felt COVID-19 catalyzed willingness to adopt AI (80.9%, n = 750/927). Common barriers to implementation include medical liability from errors (72.5%, n = 672/927) whereas enablers include improving access (94.5%, n = 876/927). Machine learning modeling predicted acceptance from participant demographics with moderate to high accuracy, and area under the receiver operating curves of 0.63-0.83. ConclusionOphthalmologists are receptive to adopting AI as assistive tools for DR, glaucoma, and AMD. Furthermore, ML is a useful method that can be applied to evaluate predictive factors on clinical qualitative questionnaires. This study outlines actionable insights for future research and facilitation interventions to drive adoption and operationalization of AI tools for Ophthalmology.
RI yifan, xiang/HNJ-1517-2023; CHENG, FREYA/GOH-0443-2022; Cheng,
   Ching-Yu/Y-2229-2019; Tan, Gavin/HNS-5461-2023; Yam, Jason/I-5682-2014
OI CHENG, FREYA/0000-0001-9179-3461; Cheng, Ching-Yu/0000-0003-0655-885X;
   Yam, Jason/0000-0002-2156-1486; Keane, Pearse/0000-0002-9239-745X
EI 2296-858X
PD OCT 13
PY 2022
VL 9
AR 875242
DI 10.3389/fmed.2022.875242
UT WOS:000876385000001
PM 36314006
ER

PT J
AU Jensen, M
   Kristensen, R
   Andersen, SS
   Bendixen, D
   Jeppesen, JO
AF Jensen, Morten
   Kristensen, Rikke
   Andersen, Sissel S.
   Bendixen, Dan
   Jeppesen, Jan O.
TI Probing the Electrostatic Barrier of Tetrathiafulvalene Dications using
   a Tetra-stable Donor-Acceptor [2]Rotaxane
SO CHEMISTRY-A EUROPEAN JOURNAL
AB A tetra-stable donor-acceptor [2]rotaxane 1.4PF(6) has been synthesized. The dumbbell component is comprised of an oxyphenylene (OP), a tetrathiafulvalene (TTF), a monopyrrolo-TTF (MPTTF), and a hydroquinone (HQ) unit, which can act as recognition sites (stations) for the tetra-cationic cyclophane cyclobis(paraquat-p-phenylene) (CBPQT(4+)). The TTF and the MPTTF stations are located in the middle of the dumbbell component and are connected by a triethylene glycol (TEG) chain in such a way that the pyrrole moiety of the MPTTF station points toward the TTF station, while the TTF and MPTTF stations are flanked by the OP and HQ stations on their left hand side and right hand side, respectively. The [2]rotaxane was characterized in solution by H-1 NMR spectroscopy and cyclic voltammetry. The spectroscopic data revealed that the majority (77 %) of the tetra-stable [2]rotaxane 1(4+) exist as the translational isomer 1.MPTTF4+ in which the CBPQT(4+) ring encircles the MPTTF station. The electrochemical studies showed that CBPQT(4+) in 1.MPTTF4+ undergoes ring translation as result of electrostatic repulsion from the oxidized MPTTF unit. Following tetra-oxidation of 1.MPTTF4+, a high-energy state of 1(8+) was obtained (i.e., 1.TEG(8+)) in which the CBPQT(4+) ring was located on the TEG linker connecting the di-oxidized TTF2+ and MPTTF2+ units. H-1 NMR spectroscopy carried out in CD3CN at 298 K on a chemically oxidized sample of 1.MPTTF4+ revealed that the metastable state 1.TEG(8+) is only short-lived with a lifetime of a few minutes and it was found that 70 % of the positively charged CBPQT(4+) ring moved from 1.TEG(8+) to the HQ station, while 30 % moved to the much weaker OP station. These results clearly demonstrate that the CBPQT(4+) ring can cross both an MPTTF2+ and a TTF2+ electrostatic barrier and that the free energy of activation required to cross MPTTF2+ is ca. 0.5 kcal mol(-1) smaller as compared to TTF2+.
OI Jeppesen, Jan Oskar/0000-0002-3088-2994; Kristensen,
   Rikke/0000-0003-3730-3024
SN 0947-6539
EI 1521-3765
PD MAY 15
PY 2020
VL 26
IS 28
BP 6165
EP 6175
DI 10.1002/chem.202000302
EA APR 2020
UT WOS:000528881900001
PM 32049376
ER

PT J
AU Shi, Y
   Prieto, PL
   Zepel, T
   Grunert, S
   Hein, JE
AF Shi, Yao
   Prieto, Paloma L.
   Zepel, Tara
   Grunert, Shad
   Hein, Jason E.
TI Automated Experimentation Powers Data Science in Chemistry
SO ACCOUNTS OF CHEMICAL RESEARCH
AB Data science has revolutionized chemical research and continues to break down barriers with new interdisciplinary studies. The introduction of computational models and machine learning (ML) algorithms in combination with automation and traditional experimental techniques has enabled scientific advancement across nearly every discipline of chemistry, from materials discovery, to process optimization, to synthesis planning. However, predictive tools powered by data science are only as good as their data sets and, currently, many of the data sets used to train models suffer from several limitations, including being sparse, limited in scope and requiring human curation. Likewise, computational data faces limitations in terms of accurate modeling of nonideal systems and can suffer from low translation fidelity from simulation to real conditions. The lack of diverse data and the need to be able to test it experimentally reduces both the accuracy and scope of the predictive models derived from data science. This Account contextualizes the need for more complex and diverse experimental data and highlights how the seamless integration of robotics, machine learning, and data-rich monitoring techniques can be used to access it with minimal human labor.
   We propose three broad categories of data in chemistry: data on fundamental properties, data on reaction outcomes, and data on reaction mechanics. We highlight flexible, automated platforms that can be deployed to acquire and leverage these data. The first platform combines solid- and liquid-dosing modules with computer vision to automate solubility screening, thereby gathering fundamental data that are necessary for almost every experimental design. Using computer vision offers the additional benefit of creating a visual record, which can be referenced and used to further interrogate and gain insight on the data collected. The second platform iteratively tests reaction variables proposed by a ML algorithm in a closed-loop fashion. Experimental data related to reaction outcomes are fed back into the algorithm to drive the discovery and optimization of new materials and chemical processes. The third platform uses automated process analytical technology to gather real-time data related to reaction kinetics. This system allows the researcher to directly interrogate the reaction mechanisms in granular detail to determine exactly how and why a reaction proceeds, thereby enabling reaction optimization and deployment.
OI Hein, Jason/0000-0002-4345-3005; Prieto, Paloma/0000-0002-7700-2085;
   SHI, YAO/0000-0002-1471-961X
SN 0001-4842
EI 1520-4898
PD FEB 2
PY 2021
VL 54
IS 3
BP 546
EP 555
DI 10.1021/acs.accounts.0c00736
EA JAN 2021
UT WOS:000618081800008
PM 33471522
ER

PT J
AU Aswiga, RV
   Shanthi, AP
AF Aswiga, R., V
   Shanthi, A. P.
TI A Multilevel Transfer Learning Technique and LSTM Framework for
   Generating Medical Captions for Limited CT and DBT Images
SO JOURNAL OF DIGITAL IMAGING
AB Medical image captioning has been recently attracting the attention of the medical community. Also, generating captions for images involving multiple organs is an even more challenging task. Therefore, any attempt toward such medical image captioning becomes the need of the hour. In recent years, the rapid developments in deep learning approaches have made them an effective option for the analysis of medical images and automatic report generation. But analyzing medical images that are scarce and limited is hard, and it is difficult even with machine learning approaches. The concept of transfer learning can be employed in such applications that suffer from insufficient training data. This paper presents an approach to develop a medical image captioning model based on a deep recurrent architecture that combines Multi Level Transfer Learning (MLTL) framework with a Long Short-Term-Memory (LSTM) model. A basic MLTL framework with three models is designed to detect and classify very limited datasets, using the knowledge acquired from easily available datasets. The first model for the source domain uses the abundantly available non-medical images and learns the generalized features. The acquired knowledge is then transferred to the second model for the intermediate and auxiliary domain, which is related to the target domain. This information is then used for the final target domain, which consists of medical datasets that are very limited in nature. Therefore, the knowledge learned from a non-medical source domain is transferred to improve the learning in the target domain that deals with medical images. Then, a novel LSTM model, which is used for sequence generation and machine translation, is proposed to generate captions for the given medical image from the MLTL framework. To improve the captioning of the target sentence further, an enhanced multi-input Convolutional Neural Network (CNN) model along with feature extraction techniques is proposed. This enhanced multi-input CNN model extracts the most important features of an image that help in generating a more precise and detailed caption of the medical image. Experimental results show that the proposed model performs well with an accuracy of 96.90%, with BLEU score of 76.9%, even with very limited datasets, when compared to the work reported in literature.
OI R V, ASWIGA/0000-0002-0242-1015
SN 0897-1889
EI 1618-727X
PD JUN
PY 2022
VL 35
IS 3
BP 564
EP 580
DI 10.1007/s10278-021-00567-7
EA FEB 2022
UT WOS:000778485600002
PM 35217942
ER

PT J
AU REIF, J
   SHARIR, M
AF REIF, J
   SHARIR, M
TI MOTION PLANNING IN THE PRESENCE OF MOVING OBSTACLES
SO JOURNAL OF THE ACM
AB This paper investigates the computational complexity of planning the motion of a body B in 2-D or 3-D space, so as to avoid collision with moving obstacles of known, easily computed, trajectories. Dynamic movement problems are of fundamental importance to robotics, but their computational complexity has not previously been investigated.
   We provide evidence that the 3-D dynamic movement problem is intractable even if B has only a constant number of degrees of freedom of movement. In particular, we prove the problem is PSPACE-hard if B is given a velocity modulus bound on its movements and is NP-hard even if B has no velocity modulus bound, where, in both cases, B has 6 degrees of freedom. To prove these results, we use a unique method of simulation of a Turing machine that uses time to encode configurations (whereas previous lower bound proofs in robotic motion planning used the system position to encode configurations and so required unbounded number of degrees of freedom).
   We also investigate a natural class of dynamic problems that we call asteroid avoidance problems: B, the object we wish to move, is a convex polyhedron that is free to move by translation with bounded velocity modulus, and the polyhedral obstacles have known translational trajectories but cannot rotate. This problem has many applications to robot, automobile, and aircraft collision avoidance. Our main positive results are polynomial time algorithms for the 2-D asteroid avoidance problem, where B is a moving polygon and we assume a constant number of obstacles, as well as single exponential time or polynomial space algorithms for the 3-D asteroid avoidance problem, where B is a convex polyhedron and there are arbitrarily many obstacles. Our techniques for solving these asteroid avoidance problems use ''normal path'' arguments, which are an interesting generalization of techniques previously used to solve static shortest path problems.
   We also give some additional positive results for various other dynamic movers problems, and in particular give polynomial time algorithms for the case in which B has no velocity bounds and the movements of obstacles are algebraic in space-time.
RI Reif, John H/C-2684-2008
SN 0004-5411
EI 1557-735X
PD JUL
PY 1994
VL 41
IS 4
BP 764
EP 790
DI 10.1145/179812.179911
UT WOS:A1994PG18600007
ER

PT J
AU Berridge, C
   Grigorovich, A
AF Berridge, Clara
   Grigorovich, Alisa
TI Algorithmic harms and digital ageism in the use of surveillance
   technologies in nursing homes
SO FRONTIERS IN SOCIOLOGY
AB Ageism has not been centered in scholarship on AI or algorithmic harms despite the ways in which older adults are both digitally marginalized and positioned as targets for surveillance technology and risk mitigation. In this translation paper, we put gerontology into conversation with scholarship on information and data technologies within critical disability, race, and feminist studies and explore algorithmic harms of surveillance technologies on older adults and care workers within nursing homes in the United States and Canada. We start by identifying the limitations of emerging scholarship and public discourse on "digital ageism" that is occupied with the inclusion and representation of older adults in AI or machine learning at the expense of more pressing questions. Focusing on the investment in these technologies in the context of COVID-19 in nursing homes, we draw from critical scholarship on information and data technologies to deeply understand how ageism is implicated in the systemic harms experienced by residents and workers when surveillance technologies are positioned as solutions. We then suggest generative pathways and point to various possible research agendas that could illuminate emergent algorithmic harms and their animating force within nursing homes. In the tradition of critical gerontology, ours is a project of bringing insights from gerontology and age studies to bear on broader work on automation and algorithmic decision-making systems for marginalized groups, and to bring that work to bear on gerontology. This paper illustrates specific ways in which important insights from critical race, disability and feminist studies helps us draw out the power of ageism as a rhetorical and analytical tool. We demonstrate why such engagement is necessary to realize gerontology's capacity to contribute to timely discourse on algorithmic harms and to elevate the issue of ageism for serious engagement across fields concerned with social and economic justice. We begin with nursing homes because they are an understudied, yet socially significant and timely setting in which to understand algorithmic harms. We hope this will contribute to broader efforts to understand and redress harms across sectors and marginalized collectives.
EI 2297-7775
PD SEP 16
PY 2022
VL 7
AR 957246
DI 10.3389/fsoc.2022.957246
UT WOS:000862457600001
PM 36189442
ER

PT J
AU Qureshi, SA
   Raza, SEA
   Hussain, L
   Malibari, AA
   Nour, MK
   ul Rehman, A
   Al-Wesabi, FN
   Hilal, AM
AF Qureshi, Shahzad Ahmad
   Raza, Shan E. Ahmed
   Hussain, Lal
   Malibari, Areej A.
   Nour, Mohamed K.
   ul Rehman, Aziz
   Al-Wesabi, Fahd N.
   Hilal, Anwer Mustafa
TI Intelligent Ultra-Light Deep Learning Model for Multi-Class Brain Tumor
   Detection
SO APPLIED SCIENCES-BASEL
AB The diagnosis and surgical resection using Magnetic Resonance (MR) images in brain tumors is a challenging task to minimize the neurological defects after surgery owing to the non-linear nature of the size, shape, and textural variation. Radiologists, clinical experts, and brain surgeons examine brain MRI scans using the available methods, which are tedious, error-prone, time-consuming, and still exhibit positional accuracy up to 2-3 mm, which is very high in the case of brain cells. In this context, we propose an automated Ultra-Light Brain Tumor Detection (UL-BTD) system based on a novel Ultra-Light Deep Learning Architecture (UL-DLA) for deep features, integrated with highly distinctive textural features, extracted by Gray Level Co-occurrence Matrix (GLCM). It forms a Hybrid Feature Space (HFS), which is used for tumor detection using Support Vector Machine (SVM), culminating in high prediction accuracy and optimum false negatives with limited network size to fit within the average GPU resources of a modern PC system. The objective of this study is to categorize multi-class publicly available MRI brain tumor datasets with a minimum time thus real-time tumor detection can be carried out without compromising accuracy. Our proposed framework includes a sensitivity analysis of image size, One-versus-All and One-versus-One coding schemes with stringent efforts to assess the complexity and reliability performance of the proposed system with K-fold cross-validation as a part of the evaluation protocol. The best generalization achieved using SVM has an average detection rate of 99.23% (99.18%, 98.86%, and 99.67%), and F-measure of 0.99 (0.99, 0.98, and 0.99) for (glioma, meningioma, and pituitary tumors), respectively. Our results have been found to improve the state-of-the-art (97.30%) by 2%, indicating that the system exhibits capability for translation in modern hospitals during real-time surgical brain applications. The method needs 11.69 ms with an accuracy of 99.23% compared to 15 ms achieved by the state-of-the-art to earlier to detect tumors on a test image without any dedicated hardware providing a route for a desktop application in brain surgery.
RI Nour, Mohammad/CAE-8486-2022; Qureshi, Dr. Shahzad Ahmad/GPX-4641-2022;
   Qureshi, Dr. Shahzad Ahmad/GRX-6931-2022; Al-Wesabi, Fahd
   N./AAV-6279-2020; Hilal, Anwer Mustafa/ABF-7667-2021; Malibari,
   Areej/HIZ-9993-2022; Malibari, Areej/HJG-9556-2022
OI Nour, Mohammad/0000-0002-5768-5392; Qureshi, Dr. Shahzad
   Ahmad/0000-0001-8213-1431; Qureshi, Dr. Shahzad
   Ahmad/0000-0001-8213-1431; Al-Wesabi, Fahd N./0000-0002-4389-4927;
   Malibari, Areej/0000-0002-7123-8548; Hilal, Anwer/0000-0002-4658-8941;
   Hussain, Lal/0000-0003-1103-4938
EI 2076-3417
PD APR
PY 2022
VL 12
IS 8
AR 3715
DI 10.3390/app12083715
UT WOS:000785317900001
ER

PT J
AU Tripathi, A
   Xu, ZZ
   Xue, J
   Poulsen, O
   Gonzalez, A
   Humphrey, G
   Meehan, MJ
   Melnik, AV
   Ackermann, G
   Zhou, D
   Malhotra, A
   Haddad, GG
   Dorrestein, PC
   Knight, R
AF Tripathi, Anupriya
   Xu, Zhenjiang Zech
   Xue, Jin
   Poulsen, Orit
   Gonzalez, Antonio
   Humphrey, Gregory
   Meehan, Michael J.
   Melnik, Alexey, V
   Ackermann, Gail
   Zhou, Dan
   Malhotra, Atul
   Haddad, Gabriel G.
   Dorrestein, Pieter C.
   Knight, Rob
TI Intermittent Hypoxia and Hypercapnia Reproducibly Change the Gut
   Microbiome and Metabolome across Rodent Model Systems
SO MSYSTEMS
AB Studying perturbations in the gut ecosystem using animal models of disease continues to provide valuable insights into the role of the microbiome in various pathological conditions. However, understanding whether these changes are consistent across animal models of different genetic backgrounds, and hence potentially translatable to human populations, remains a major unmet challenge in the field. Nonetheless, in relatively limited cases have the same interventions been studied in two animal models in the same laboratory. Moreover, such studies typically examine a single data layer and time point. Here, we show the power of utilizing time series microbiome (16S rRNA amplicon profiling) and metabolome (untargeted liquid chromatography-tandem mass spectrometry [LC-MS/MS]) data to relate two different mouse models of atherosclerosis-ApoE(-/-) (n = 24) and Ldlr(-/-) (n = 16)-that are exposed to intermittent hypoxia and hypercapnia (IHH) longitudinally (for 10 and 6 weeks, respectively) to model chronic obstructive sleep apnea. Using random forest classifiers trained on each data layer, we show excellent accuracy in predicting IHH exposure within ApoE(-/-) and Ldlr(-/-) knockout models and in crossapplying predictive features found in one animal model to the other. The key microbes and metabolites that reproducibly predicted IHH exposure included bacterial species from the families Mogibacteriaceae, Clostridiaceae, bile acids, and fatty acids, providing a refined set of biomarkers associated with IHH. The results highlight that time series multiomics data can be used to relate different animal models of disease using supervised machine learning techniques and can provide a pathway toward identifying robust microbiome and metabolome features that underpin translation from animal models to human disease.
   IMPORTANCE Reproducibility of microbiome research is a major topic of contemporary interest. Although it is often possible to distinguish individuals with specific diseases within a study, the differences are often inconsistent across cohorts, often due to systematic variation in analytical conditions. Here we study the same intervention in two different mouse models of cardiovascular disease (atherosclerosis) by profiling the microbiome and metabolome in stool specimens over time. We demonstrate that shared microbial and metabolic changes are involved in both models with the intervention. We then introduce a pipeline for finding similar results in other studies. This work will help find common features identified across different model systems that are most likely to apply in humans.
RI Dorrestein, Pieter/ABF-2930-2020; Gonzalez, Antonio/A-6421-2018; Xu,
   Zhenjiang Zech/F-6493-2012
OI Xu, Zhenjiang Zech/0000-0003-1080-024X; Zhou, Dan/0000-0001-6401-9040;
   Knight, Rob/0000-0002-0975-9019
SN 2379-5077
PD MAR-APR
PY 2019
VL 4
IS 2
AR e00058
DI 10.1128/mSystems.00058-19
UT WOS:000467083600021
PM 31058230
ER

PT J
AU Bai, O
   Lin, P
   Vorbach, S
   Li, J
   Furlani, S
   Hallett, M
AF Bai, Ou
   Lin, Peter
   Vorbach, Sherry
   Li, Jiang
   Furlani, Steve
   Hallett, Mark
TI Exploration of computational methods for classification of movement
   intention during human voluntary movement from single trial EEG
SO CLINICAL NEUROPHYSIOLOGY
AB Objective: To explore effective combinations of computational methods for the prediction of movement intention preceding the production of self-paced right and left hand movements from single trial scalp electroencephalogram (EEG).
   Methods: Twelve naive subjects performed self-paced movements consisting of three key strokes with either hand. EEG was recorded from 128 channels. The exploration was performed offline on single trial EEG data. We proposed that a successful computational procedure for classification would consist of spatial filtering, temporal filtering, feature selection, and pattern classification. A systematic investigation was performed with combinations of spatial filtering using principal component analysis (PCA), independent component analysis (ICA), common spatial patterns analysis (CSP), and surface Laplacian derivation (SLD); temporal filtering using power spectral density estimation (PSD) and discrete wavelet transform (DWT); pattern classification using linear Mahalanobis distance classifier (LMD), quadratic Mahalanobis distance classifier (QMD), Bayesian classifier (BSC), multi-layer perceptron neural network (MLP), probabilistic neural network (PNN), and support vector machine (SVM). A robust multivariate feature selection strategy using a genetic algorithm was employed.
   Results: The combinations of spatial filtering using ICA and SLD, temporal filtering using PSD and DWT, and classification methods using LMD, QMD, BSC and SVM provided higher performance than those of other combinations. Utilizing one of the better combinations of ICA, PSD and SVM, the discrimination accuracy was as high as 75%. Further feature analysis showed that beta band EEG activity of the channels over right sensorimotor cortex was most appropriate for discrimination of right and left hand movement intention.
   Conclusions: Effective combinations of computational methods provide possible classification of human movement intention from single trial EEG. Such a method could be the basis for a potential brain-computer interface based on human natural movement, which might reduce the requirement of long-term training.
   Significance: Effective combinations of computational methods can classify human movement intention from single trial EEG with reasonable accuracy. Published by Elsevier Ireland Ltd.
OI Lin, Peter/0000-0003-1198-7763
SN 1388-2457
EI 1872-8952
PD DEC
PY 2007
VL 118
IS 12
BP 2637
EP 2655
DI 10.1016/j.clinph.2007.08.025
UT WOS:000252204900009
PM 17967559
ER

PT J
AU van Bueren, NER
   Reed, TL
   Nguyen, V
   Sheffield, JG
   van der Ven, SHG
   Osborne, MA
   Kroesbergen, EH
   Kadosh, RC
AF van Bueren, Nienke E. R.
   Reed, Thomas L.
   Nguyen, Vu
   Sheffield, James G.
   van der Ven, Sanne H. G.
   Osborne, Michael A.
   Kroesbergen, Evelyn H.
   Kadosh, Roi Cohen
TI Personalized brain stimulation for effective neurointervention across
   participants
SO PLOS COMPUTATIONAL BIOLOGY
AB Accumulating evidence from human-based research has highlighted that the prevalent one-size-fits-all approach for neural and behavioral interventions is inefficient. This approach can benefit one individual, but be ineffective or even detrimental for another. Studying the efficacy of the large range of different parameters for different individuals is costly, time-consuming and requires a large sample size that makes such research impractical and hinders effective interventions. Here an active machine learning technique is presented across participants-personalized Bayesian optimization (pBO)-that searches available parameter combinations to optimize an intervention as a function of an individual's ability. This novel technique was utilized to identify transcranial alternating current stimulation (tACS) frequency and current strength combinations most likely to improve arithmetic performance, based on a subject's baseline arithmetic abilities. The pBO was performed across all subjects tested, building a model of subject performance, capable of recommending parameters for future subjects based on their baseline arithmetic ability. pBO successfully searches, learns, and recommends parameters for an effective neurointervention as supported by behavioral, stimulation, and neural data. The application of pBO in human-based research opens up new avenues for personalized and more effective interventions, as well as discoveries of protocols for treatment and translation to other clinical and non-clinical domains.
   Author summaryThe common one-size-fits-all approach used in biological and behavioral research has shown to be inefficient. This is especially the case in the field of brain stimulation, where many different combinations of stimulation parameters (i.e., frequency and current strength of the applied current) can be used for restorative or enhancement purposes, in clinical and non-clinical populations, respectively. Even intervention protocols that have reported to be effective for certain individuals can be detrimental for others. Here we present an active machine learning method, personalized Bayesian optimization (pBO) that successfully searches, learns, and recommends neurostimulation parameters across individuals. Based on an individual's baseline cognitive ability, the pBO identifies specific combinations of transcranial alternating current stimulation parameters, which are most likely to improve cognitive performance, in which case arithmetic problem solving. This timely approach provides a possible solution for the pressing need for personalization in different disciplines including medicine, psychology, and education.
RI van der Ven, Sanne/GQZ-3381-2022; Cohen Kadosh, Roi/F-7346-2012;
   Kroesbergen, Evelyn/AAE-1655-2019
OI van der Ven, Sanne/0000-0002-4761-0741; Osborne,
   Michael/0000-0003-1959-012X; Cohen Kadosh, Roi/0000-0002-5564-5469;
   Reed, Thomas/0000-0001-7179-8070; Kroesbergen,
   Evelyn/0000-0001-9856-096X; van Bueren, Nienke/0000-0002-0198-7252
SN 1553-734X
EI 1553-7358
PD SEP
PY 2021
VL 17
IS 9
AR e1008886
DI 10.1371/journal.pcbi.1008886
UT WOS:000720144700002
PM 34499639
ER

PT J
AU Kukic, P
   Mirabello, C
   Tradigo, G
   Walsh, I
   Veltri, P
   Pollastri, G
AF Kukic, Predrag
   Mirabello, Claudio
   Tradigo, Giuseppe
   Walsh, Ian
   Veltri, Pierangelo
   Pollastri, Gianluca
TI Toward an accurate prediction of inter-residue distances in proteins
   using 2D recursive neural networks
SO BMC BIOINFORMATICS
AB Background: Protein inter-residue contact maps provide a translation and rotation invariant topological representation of a protein. They can be used as an intermediary step in protein structure predictions. However, the prediction of contact maps represents an unbalanced problem as far fewer examples of contacts than non-contacts exist in a protein structure.
   In this study we explore the possibility of completely eliminating the unbalanced nature of the contact map prediction problem by predicting real-value distances between residues. Predicting full inter-residue distance maps and applying them in protein structure predictions has been relatively unexplored in the past.
   Results: We initially demonstrate that the use of native-like distance maps is able to reproduce 3D structures almost identical to the targets, giving an average RMSD of 0.5 angstrom. In addition, the corrupted physical maps with an introduced random error of +/- 6 angstrom are able to reconstruct the targets within an average RMSD of 2 angstrom.
   After demonstrating the reconstruction potential of distance maps, we develop two classes of predictors using two-dimensional recursive neural networks: an ab initio predictor that relies only on the protein sequence and evolutionary information, and a template-based predictor in which additional structural homology information is provided. We find that the ab initio predictor is able to reproduce distances with an RMSD of 6 angstrom, regardless of the evolutionary content provided. Furthermore, we show that the template-based predictor exploits both sequence and structure information even in cases of dubious homology and outperforms the best template hit with a clear margin of up to 3.7 angstrom.
   Lastly, we demonstrate the ability of the two predictors to reconstruct the CASP9 targets shorter than 200 residues producing the results similar to the state of the machine learning art approach implemented in the Distill server.
   Conclusions: The methodology presented here, if complemented by more complex reconstruction protocols, can represent a possible path to improve machine learning algorithms for 3D protein structure prediction. Moreover, it can be used as an intermediary step in protein structure predictions either on its own or complemented by NMR restraints.
RI Mirabello, Claudio/AAF-2451-2020; Walsh, Ian/HCH-9412-2022
OI Mirabello, Claudio/0000-0001-7868-034X; Walsh, Ian/0000-0003-3994-5522;
   Pollastri, Gianluca/0000-0002-5825-4949; VELTRI,
   Pierangelo/0000-0003-2494-0294
SN 1471-2105
PD JAN 10
PY 2014
VL 15
AR 6
DI 10.1186/1471-2105-15-6
UT WOS:000329908200001
PM 24410833
ER

PT C
AU Chien, JT
AF Chien, Jen-Tzung
GP ACM
TI Deep Bayesian Data Mining
SO PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA
   MINING (WSDM '20)
CT 13th Annual ACM International Conference on Web Search and Data Mining
   (WSDM)
CY FEB 03-07, 2020
CL Houston, TX
SP Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD, ACM SIGMOD
AB This tutorial addresses the fundamentals and advances in deep Bayesian mining and learning for natural language with ubiquitous applications ranging from speech recognition [7, 55] to document summarization [8], text classification [5, 75], text segmentation [18], information extraction [50], image caption generation [69, 72], sentence generation [25, 46], dialogue control [22, 76], sentiment classification, recommendation system, question answering [58] and machine translation [2], to name a few. Traditionally, "deep learning" is taken to be a learning process where the inference or optimization is based on the real-valued deterministic model. The "semantic structure" in words, sentences, entities, actions and documents drawn from a large vocabulary may not be well expressed or correctly optimized in mathematical logic or computer programs. The "distribution function" in discrete or continuous latent variable model for natural language may not be properly decomposed or estimated. This tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced Bayesian models and deep models including hierarchical Dirichlet process [61], Chinese restaurant process [4], hierarchical Pitman-Yor process [60], Indian buffet process [35], recurrent neural network (RNN) [26, 41, 48, 65], long short-term memory, sequence-to-sequence model [59], variational auto-encoder (VAE) [44], generative adversarial network (GAN) [36], attention mechanism [27, 56], memory-augmented neural network [39, 58], skip neural network [6], temporal difference VAE [40], stochastic neural network [3, 47], stochastic temporal convolutional network [1], predictive state neural network [31], and policy neural network [49, 74]. Enhancing the prior/posterior representation is addressed [53, 62]. We present how these models are connected and why they work for a variety of applications on symbolic and complex patterns in natural language. The variational inference and sampling method are formulated to tackle the optimization for complicated models [54]. The word and sentence embeddings, clustering and co-clustering are merged with linguistic and semantic constraints. A series of case studies, tasks and applications are presented to tackle different issues in deep Bayesian mining, searching, learning and understanding. At last, we will point out a number of directions and outlooks for future studies. This tutorial serves the objectives to introduce novices to major topics within deep Bayesian learning, motivate and explain a topic of emerging importance for data mining and natural language understanding, and present a novel synthesis combining distinct lines of machine learning work.
OI Chien, Jen-Tzung/0000-0003-3466-8941
BN 978-1-4503-6822-3
PY 2020
BP 865
EP 868
DI 10.1145/3336191.3371870
UT WOS:000531489300106
ER

PT J
AU Xue, H
   Wei, Z
   Chen, KQ
   Tang, YJ
   Wu, XY
   Su, JL
   Meng, J
AF Xue, Hao
   Wei, Zhen
   Chen, Kunqi
   Tang, Yujiao
   Wu, Xiangyu
   Su, Jionglong
   Meng, Jia
TI Prediction of RNA Methylation Status From Gene Expression Data Using
   Classification and Regression Methods
SO EVOLUTIONARY BIOINFORMATICS
AB RNAN(6)-methyladenosine (m(6)A) has emerged as an important epigenetic modification for its role in regulating the stability, structure, processing, and translation of RNA. Instability of m(6)A homeostasis may result in flaws in stem cell regulation, decrease in fertility, and risk of cancer. To this day, experimental detection and quantification of RNA m(6)A modification are still time-consuming and labor-intensive. There is only a limited number of epitranscriptome samples in existing databases, and a matched RNA methylation profile is not often available for a biological problem of interests. As gene expression data are usually readily available for most biological problems, it could be appealing if we can estimate the RNA methylation status from gene expression data usingin silicomethods. In this study, we explored the possibility of computational prediction of RNA methylation status from gene expression data using classification and regression methods based on mouse RNA methylation data collected from 73 experimental conditions. Elastic Net-regularized Logistic Regression (ENLR), Support Vector Machine (SVM), and Random Forests (RF) were constructed for classification. Both SVM and RF achieved the best performance with the mean area under the curve (AUC) = 0.84 across samples; SVM had a narrower AUC spread. Gene Site Enrichment Analysis was conducted on those sites selected by ENLR as predictors to access the biological significance of the model. Three functional annotation terms were found statistically significant: phosphoprotein, SRC Homology 3 (SH3) domain, and endoplasmic reticulum. All 3 terms were found to be closely related to m(6)A pathway. For regression analysis, Elastic Net was implemented, which yielded a mean Pearson correlation coefficient = 0.68 and a mean Spearman correlation coefficient = 0.64. Our exploratory study suggested that gene expression data could be used to construct predictors for m(6)A methylation status with adequate accuracy. Our work showed for the first time that RNA methylation status may be predicted from the matched gene expression data. This finding may facilitate RNA modification research in various biological contexts when a matched RNA methylation profile is not available, especially in the very early stage of the study.
RI chen, kunqi/ABE-1421-2020
OI chen, kunqi/0000-0002-6025-8957; Xue, Hao/0000-0003-1231-4747; Meng,
   Jia/0000-0003-3455-205X
SN 1176-9343
PD APR
PY 2020
VL 16
AR 1176934320915707
DI 10.1177/1176934320915707
UT WOS:000554539500001
PM 32733123
ER

PT J
AU Lamarine, M
   Hager, J
   Saris, WHM
   Astrup, A
   Valsesia, A
AF Lamarine, Marc
   Hager, Jorg
   Saris, Wim H. M.
   Astrup, Arne
   Valsesia, Armand
TI Fast and Accurate Approaches for Large-Scale, Automated Mapping of Food
   Diaries on Food Composition Tables
SO FRONTIERS IN NUTRITION
AB Aim of Study: The use of weighed food diaries in nutritional studies provides a powerful method to quantify food and nutrient intakes Yet, mapping these records onto food composition tables (FCTs) is a challenging, time-consuming and error-prone process Experts make this effort manually and no automation has been previously proposed Our study aimed to assess automated approaches to map food items onto FCTs.
   Methods: We used food diaries (similar to 170,000 records pertaining to 4,200 unique food items) from the DiOGenes randomized clinical trial We attempted to map these items onto six FCTs available from the EuroFIR resource Two approaches were tested the first was based solely on food name similarity (fuzzy matching) The second used a machine learning approach (C5.0 classifier) combining both fuzzy matching and food energy We tested mapping food items using their original names and also an English-translation Top matching pairs were reviewed manually to derive performance metrics precision (the percentage of correctly mapped items) and recall (percentage of mapped items)
   Results: The simpler approach fuzzy matching, provided very good performance Under a relaxed threshold (score 50%), this approach enabled to remap 99.49% of the items with a precision of 88.75% With a slightly more stringent threshold (score > 63%), the precision could be significantly improved to 96.81% while keeping a recall rate > 95% (i.e., only 5% of the queried items would not be mapped) The machine learning approach did not lead to any improvements compared to the fuzzy matching. However, it could increase substantially the recall rate for food items without any clear equivalent in the FCTs (+7 and +20% when mapping items using their original or English-translated names) Our approaches have been implemented as R packages and are freely available from GitHub.
   Conclusion: This study is the first to provide automated approaches for large-scale food item mapping onto FCTs We demonstrate that both high precision and recall can be achieved Our solutions can be used with any FCT and do not require any programming background These methodologies and findings are useful to any small or large nutritional study (observational as well as interventional).
RI Astrup, Arne/B-1407-2015
OI Astrup, Arne/0000-0001-8968-8996
SN 2296-861X
PD MAY 9
PY 2018
VL 5
AR 38
DI 10.3389/fnut.2018.00038
UT WOS:000436361200001
PM 29868600
ER

PT C
AU Bhowmick, SS
   Saha, I
   Maulik, U
   Bhattacharjee, D
AF Bhowmick, Shib Sankar
   Saha, Indrajit
   Maulik, Ujjwal
   Bhattacharjee, Debotosh
BE Kumar, C
   Banka, H
   Ramesh, D
TI Identification of miRNA Signature using Next-Generation Sequencing data
   of Prostate Cancer
SO 2016 3rd International Conference on Recent Advances in Information
   Technology (RAIT)
CT 3rd IEEE International Conference on Recent Advances in Information
   Technology (RAIT)
CY MAR 03-05, 2016
CL Dhanbad, INDIA
SP IEEE, Indian Sch Mines, Dept Comp Sci & Engn, IEEE Commun Soc, Kolkata Chapter
AB MicroRNAs (miRNAs) are a class of similar to 22-nucleotide endogenous noncoding RNAs which have critical functions across various biological processes. It is quite well-known that the miRNAs are playing a crucial role for regulating the expression of target gene via repressing translation or promoting messenger RNAs degradation. Therefore, identification of discriminative and differentially expressed miRNA as a signature is an important task for cancer therapy. In this regard, Next-Generation Sequencing (NGS) data of miRNAs, available at The Cancer Research Atlas (TCGA) repository, is analyzed here for prostate cancer. This cancer type is a serious threat to the health of men as found in the literature. Hence, finding miRNA signature using NGS based miRNA expression data for prostate cancer is an important research direction. Generally by motivating this fact, a new miRNA signature identification method for prostate cancer is proposed. The proposed method uses a global optimization technique, called Simulated Annealing (SA), Principal Component Analysis (PCA) and Support Vector Machine (SVM) classifier. Here SA encodes L number of features, in this case miRNAs. Similar number of top L key principal components of the original dataset is extracted using PCA. Thereafter, such components are multiplied with the reduced subset of data so that the classification task can be done on diverse dataset using SVM. Here the classification accuracy of SVM is considered as an underlying objective to optimize using SA. The proposed method can be seen as feature section technique in order to find potential miRNA signature. Finally, the experimental results provide a set of miRNAs with optimal classification accuracy. However, due to the stochastic nature of this algorithm a list of miRNAs is prepared. From the top 15 miRNAs of that list, four miRNAs, hsa-mir-152, hsa-mir-23a, hsa-mir-302f and hsa-mir-101-1, are associated with prostate cancer. Moreover, the performance of the proposed method has also been compared with other widely used state-of-the-art techniques. Furthermore, the obtained results have been justified by means of statistical test along with biological significance tests for the selected miRNAs.
RI Bhattacharjee, Debotosh/Q-4065-2019; Bhattacharjee,
   Debotosh/L-8521-2015; Maulik, Ujjwal/AAO-8754-2020
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; Bhowmick, ShibSankar/0000-0002-3058-0478
BN 978-1-4799-8579-1
PY 2016
BP 528
EP 533
UT WOS:000389274300091
ER

PT J
AU Zheng, YM
   Wang, HH
   Zhang, Y
   Gao, X
   Xing, EP
   Xu, M
AF Zheng, Yumin
   Wang, Haohan
   Zhang, Yang
   Gao, Xin
   Xing, Eric P.
   Xu, Min
TI Poly(A)-DG: A deep-learning-based domain generalization method to
   identify cross-species Poly(A) signal without prior knowledge from
   target species
SO PLOS COMPUTATIONAL BIOLOGY
AB In eukaryotes, polyadenylation (poly(A)) is an essential process during mRNA maturation. Identifying the cis-determinants of poly(A) signal (PAS) on the DNA sequence is the key to understand the mechanism of translation regulation and mRNA metabolism. Although machine learning methods were widely used in computationally identifying PAS, the need for tremendous amounts of annotation data hinder applications of existing methods in species without experimental data on PAS. Therefore, cross-species PAS identification, which enables the possibility to predict PAS from untrained species, naturally becomes a promising direction. In our works, we propose a novel deep learning method named Poly(A)-DG for cross-species PAS identification. Poly(A)-DG consists of a Convolution Neural Network-Multilayer Perceptron (CNN-MLP) network and a domain generalization technique. It learns PAS patterns from the training species and identifies PAS in target species without re-training. To test our method, we use three species and build cross-species training sets with two of them and evaluate the performance of the remaining one. Moreover, we test our method against insufficient data and imbalanced data issues and demonstrate that Poly(A)-DG not only outperforms state-of-the-art methods but also maintains relatively high accuracy when it comes to a smaller or imbalanced training set.
   Author summary
   The key to understanding the mechanism of translation regulation and mRNA metabolism is to identify the cis-determinants of PAS on the DNA sequence. PAS leads to correct identification of Poly(A) sites which play an essential role in understanding human diseases. While many researchers have employed deep learning methods to improve the performance of PAS identification, an underlying problem is the expensive and time-consuming nature of PAS data collection, which makes the application of deep learning models for identifying PAS from a broad range of species a tough task. We attempt to use domain generalization methods, inspired by its thrive in the field of computer vision, to overcome the insufficient annotation data challenge in PAS data. Here, empirical results suggest that our proposed model Poly(A)-DG can extract species-invariant features from multiple training species and be directly applied to the target species without fine-tuning. Furthermore, Poly(A)-DG is a promising practical tool for PAS identification with its stable performance on insufficient or species-imbalanced training data. We share the implementation of our proposed model on the GitHub. (https://github.com/Szym29/PolyADG).
RI Zhang, Yang/U-5562-2019; Gao, Xin/D-5487-2013
OI Zhang, Yang/0000-0002-1483-9195; Gao, Xin/0000-0002-7108-3574; Wang,
   Haohan/0000-0002-1826-4069
SN 1553-734X
EI 1553-7358
PD NOV
PY 2020
VL 16
IS 11
AR e1008297
DI 10.1371/journal.pcbi.1008297
UT WOS:000591317200001
PM 33151940
ER

PT J
AU Sabah, G
AF Sabah, Gerard
TI Natural Language Understanding, Where Are We Going? Where Could We Go?
SO COMPUTER JOURNAL
AB Historically, at the beginning of natural language processing, applications with industrial objectives were preferred, e.g. for a fully automated translation. Soon, during the 1960s, there were attempts to separate applications from basic theoretical research. Since this theoretical research encounters difficulties regarding its status as a separate discipline, and considering the constraints necessary to clarify the concept of 'good application', impossible to satisfy simultaneously (a real problem to solve, in response to a social demand, and a viable solution in terms of reliability, robustness, speed and cost), two main streams have emerged. The first one, as a computer technique, is intended to build applications based on a strict logic, using natural language to facilitate interaction with the computer, but not directly related to the human way of using language (this approach is designated as natural language processing). Such pragmatic research accepts certain kinds of errors, but must lead to concrete results in limited time. The goal is to provide effective systems for real applications, able to respond effectively to requests addressed to them in fairly large areas; these systems are directly related to social and industrial productivity, which is the essential criterion of evaluation. Some technological developments, such as microcomputers, have made available to people specific applications of natural language processing and have enabled the emergence of small specialized firms. This produced, in the second half of the 1980s, the emergence of a 'language industry' and of the field of 'linguistic engineering'. On the other hand, during the late 1960s, the gap between the social demand, the resources invested and the poor performance obtained led to the emergence of theoretical studies intended to formalize languages (as opposed to the more empirical machine translation). This leads to 'pilot systems', aimed at demonstrating the feasibility of complex theoretical approaches, but unable to operate outside a set of rather limited examples. The limits may be at different levels: more or less limited vocabulary or accepted sentences, knowledge about the field more or less complete, more or less developed reasoning and so on. These limits have a significant impact on communication itself. For natural language processing systems to be effective, they must make appropriate inferences from what is said and, conversely their behavior should allow the inferences that the users usually do when using their language. Thus, this position paper stresses that understanding the surface meaning of a natural language is not sufficient but that the goals, intentions and strategies of the participants in a dialogue must be understood.
SN 0010-4620
EI 1460-2067
PD SEP
PY 2011
VL 54
IS 9
SI SI
BP 1505
EP 1513
DI 10.1093/comjnl/bxq060
UT WOS:000294499600007
ER

PT J
AU Michael, J
   Morton, D
   Batchelar, D
   Hilts, M
   Crook, J
   Fenster, A
AF Michael, Justin
   Morton, Daniel
   Batchelar, Deidre
   Hilts, Michelle
   Crook, Juanita
   Fenster, Aaron
TI Development of a 3D ultrasound guidance system for permanent breast seed
   implantation
SO MEDICAL PHYSICS
AB PurposePermanent breast seed implantation (PBSI) is a promising radiotherapy technique for early-stage breast cancer, completed in a single visit by permanently implanting Pd-103 seeds using needles inserted through a template and guided by two-dimensional (2D) ultrasound (US). However, operator dependence has been highlighted as a limitation of this procedure. Consequently, we propose and have developed an intraoperative guidance system using three-dimensional (3D) US and an instrumented mechanical arm to provide intraoperative 3D imaging and needle template tracking.
   MethodsA mechatronic 3D US scanner reconstructs a 3D image from 150 2D images. A tracked mechanical arm mounted to the scanner locates four fiducial points on the template, registering the template to the 3D image. 3D reconstruction was validated for linear and volumetric measurement accuracy using phantoms of known geometry. In vivo breast US image quality was evaluated in a healthy volunteer. The encoded arm was calibrated and validated using a jig with divots at known locations relative to the scanner and the scanner registered to the 3D US image using intersecting strings in a fluid-filled test jig. Template registration accuracy was assessed using a machined test jig. Tracking accuracy was assessed in a liquid medium by comparing tracked and imaged needle tip positions. Finally, the system was used to guide a mock procedure in a patient-specific phantom and micro-CT imaging used to evaluate its accuracy.
   ResultsGeometric validation showed median distances within 1.1% of expected values and volumetric validation showed differences of 4.1%. Tracking arm point measurements showed an average error of 0.43mm and 3D US volume registration showed target registration error 0.9mm. Mean template registration accuracy in each axis of translation/rotation was 1.3mm/1.0 degrees. Mean needle-targeting error was 2.5mm and 1.6 degrees for needle tips and trajectories, respectively. Mean needle tip and angular errors of the phantom procedure were 2.1mm and 2.6 degrees. Modeled seed displacement of the phantom procedure showed mean error of 2.6mm and a maximum of 3.8mm.
   ConclusionsA 3D US guidance system for PBSI has been developed. Benchtop performance and image quality in volunteer scans are satisfactory. A phantom PBSI procedure was successfully delivered using the system with maximum seed error within dosimetric benchmarks (<5mm). Translation of the device into the clinic is forthcoming.
RI FENSTER, Aaron/K-4337-2013; Crook, Juanita/AAL-1874-2021
SN 0094-2405
EI 2473-4209
PD AUG
PY 2018
VL 45
IS 8
BP 3481
EP 3495
DI 10.1002/mp.12990
UT WOS:000441292000003
PM 29791029
ER

PT J
AU Hildebrand, KA
   Holmberg, M
   Shrive, N
AF Hildebrand, KA
   Holmberg, M
   Shrive, N
TI A new method to measure post-traumatic joint contractures in the rabbit
   knee
SO JOURNAL OF BIOMECHANICAL ENGINEERING-TRANSACTIONS OF THE ASME
AB A new device and method to measure rabbit knee joint angles are described. The method was used to measure rabbit knee joint angles in normal specimens and in knee joints with obvious contractures. The custom-designed and manufactured gripping device has two clamps. The femoral clamp sits on a pinion gear that is driven by a rack attached to a materials testing system. A 100 N load cell in series with the rack gives force feedback. The tibial clamp is attached to a rotatory potentiometer The system allows the knee joint multiple degrees-of-freedom (DOF). There are two independent DOF (compression-distraction and internal-external rotation) and two coupled motions (medial-lateral translation coupled with varus-valgus rotation; anterior-posterior translation coupled with flexion-extension rotation). Knee joint extension-flexion motion is measured, which is a combination of the materials testing system displacement (converted to degrees of motion) and the potentiometer values (calibrated to degrees). Internal frictional forces were determined to be at maximum 2% of measured loading. Two separate experiments were performed to evaluate rabbit knees. First, normal right and left pairs of knees from four New Zealand White (NZW) rabbits were subjected to cyclic loading. An extension torque of 0.2 Nm was applied to each knee. The average change in knee joint extension from the first to the fifth cycle was 1.9 deg +/- 1.5 deg (mean +/-sd) with a total of 49 tests of these eight knees. The maximum extension of the four left knees (tested 23 times) was 14.6 deg +/-7.1 deg, and of the four right knees (tested 26 times) was 12.0 deg +/-10.9 deg. There was no significant difference in the maximum extension between normal le and right knees. In the second experiment, nine skeletally mature NZW rabbits had stable fractures of the femoral condyles of the right knee that were immobilized for five, six or 10 weeks. The left knee served as an unoperated control. Loss of knee joint extension (flexion contracture) was demonstrated for the experimental knees using the new methodology where the maximum extension was 35 deg +/-9 deg, compared to the unoperated knee maximum extension a 11 deg +/-7 deg, 10 or 12 weeks after the immobilization was discontinued. The custom gripping device coupled to a materials testing machine will serve as a measurement test for future studies characterizing a rabbit knee model of post-traumatic joint contractures.
RI Hildebrand, Kevin/N-8394-2015
OI Hildebrand, Kevin/0000-0001-8786-9021
SN 0148-0731
PD DEC
PY 2003
VL 125
IS 6
BP 887
EP 892
DI 10.1115/1.1634285
UT WOS:000188499600017
PM 14986415
ER

PT J
AU Pietsch, M
   Ho, A
   Bardanzellu, A
   Zeidan, AMA
   Chappell, LC
   Hajnal, JV
   Rutherford, M
   Hutter, J
AF Pietsch, Maximilian
   Ho, Alison
   Bardanzellu, Alessia
   Zeidan, Aya Mutaz Ahmad
   Chappell, Lucy C.
   Hajnal, Joseph, V
   Rutherford, Mary
   Hutter, Jana
TI APPLAUSE: Automatic Prediction of PLAcental health via U-net
   Segmentation and statistical Evaluation
SO MEDICAL IMAGE ANALYSIS
AB Purpose: Artificial-intelligence population-based automated quantification of placental maturation and health from a rapid functional Magnetic Resonance scan. The placenta plays a crucial role for any successful human pregnancy. Deviations from the normal dynamic maturation throughout gestation are closely linked to major pregnancy complications. Antenatal assessment in-vivo using T2 * relaxometry has shown great promise to inform management and possible interventions but clinical translation is hampered by time consuming manual segmentation and analysis techniques based on comparison against normative curves over gestation. Methods: This study proposes a fully automatic pipeline to predict the biological age and health of the placenta based on a free-breathing rapid (sub-30 second) T2 * scan in two steps: Automatic segmentation using a U-Net and a Gaussian process regression model to characterize placental maturation and health. These are trained and evaluated on 108 3T MRI placental data sets, the evaluation included 20 high-risk pregnancies diagnosed with pre-eclampsia and/or fetal growth restriction. An independent cohort imaged at 1.5 T is used to assess the generalization of the training and evaluation pipeline. Results: Across low-and high-risk groups, automatic segmentation performs worse than inter-rater performance (mean Dice coefficients of 0.58 and 0.68, respectively) but is sufficient for estimating placental mean T2 * (0.986 Pearson Correlation Coefficient). The placental health prediction achieves an excellent ability to differentiate cases of placental insufficiency between 27 and 33 weeks. High abnormality scores correlate with low birth weight, premature birth and histopathological findings. Retrospective application on a different cohort imaged at 1.5 T illustrates the ability for direct clinical translation. Conclusion: The presented automatic pipeline facilitates a fast, robust and reliable prediction of placental maturation. It yields human-interpretable and verifiable intermediate results and quantifies uncertainties on the cohort-level and for individual predictions. The proposed machine-learning pipeline runs in close to real-time and, deployed in clinical settings, has the potential to become a cornerstone of diagnosis and intervention of placental insufficiency. APPLAUSE generalizes to an independent cohort imaged at 1.5 T, demonstrating robustness to different operational and clinical environments. (c) 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ )
RI Hajnal, Joseph/P-6251-2018
OI Hajnal, Joseph/0000-0002-2690-5495; Hutter, Jana/0000-0003-3476-3500
SN 1361-8415
EI 1361-8423
PD AUG
PY 2021
VL 72
AR 102145
DI 10.1016/j.media.2021.102145
EA JUL 2021
UT WOS:000681133000002
PM 34229190
ER

PT J
AU Wong, LW
   Mak, SH
   Goh, BH
   Lee, WL
AF Wong, Le-Wei
   Mak, Siow-Hui
   Goh, Bey-Hing
   Lee, Wai-Leng
TI The Convergence of FTIR and EVs: Emergence Strategy for Non-Invasive
   Cancer Markers Discovery
SO DIAGNOSTICS
AB In conjunction with imaging analysis, pathology-based assessments of biopsied tissue are the gold standard for diagnosing solid tumors. However, the disadvantages of tissue biopsies, such as being invasive, time-consuming, and labor-intensive, have urged the development of an alternate method, liquid biopsy, that involves sampling and clinical assessment of various bodily fluids for cancer diagnosis. Meanwhile, extracellular vesicles (EVs) are circulating biomarkers that carry molecular profiles of their cell or tissue origins and have emerged as one of the most promising biomarkers for cancer. Owing to the biological information that can be obtained through EVs' membrane surface markers and their cargo loaded with biomolecules such as nucleic acids, proteins, and lipids, EVs have become useful in cancer diagnosis and therapeutic applications. Fourier-transform infrared spectroscopy (FTIR) allows rapid, non-destructive, label-free molecular profiling of EVs with minimal sample preparation. Since the heterogeneity of EV subpopulations may result in complicated FTIR spectra that are highly diverse, computational-assisted FTIR spectroscopy is employed in many studies to provide fingerprint spectra of malignant and non-malignant samples, allowing classification with high accuracy, specificity, and sensitivity. In view of this, FTIR-EV approach carries a great potential in cancer detection. The progression of FTIR-based biomarker identification in EV research, the rationale of the integration of a computationally assisted approach, along with the challenges of clinical translation are the focus of this review.
RI Lee, Wai-Leng/F-5895-2014
OI Lee, Wai-Leng/0000-0002-0036-2859; Wong, Le Wei/0000-0002-8873-2526;
   Goh, Bey Hing/0000-0003-1006-3649
EI 2075-4418
PD JAN
PY 2023
VL 13
IS 1
AR 22
DI 10.3390/diagnostics13010022
UT WOS:000909858600001
PM 36611313
ER

PT C
AU Campos, S
   Silva, DC
AF Campos, Sandro
   Silva, Daniel Castro
BE Rocha, AP
   Steels, L
   VandenHerik, J
TI Aerial Fire Image Synthesis and Detection
SO ICAART: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON AGENTS AND
   ARTIFICIAL INTELLIGENCE - VOL 2
SE ICAART
CT 14th International Conference on Agents and Artificial Intelligence
   (ICAART)
CY FEB 03-05, 2022
CL ELECTR NETWORK
AB Unmanned Aerial Vehicles appear as efficient platforms for fire detection and monitoring due to their low cost and flexibility features. Detecting flames and smoke from above is performed visually or by employing onboard temperature and gas concentration sensors. However, approaches based on computer vision and machine learning techniques have identified a pertinent problem of class imbalance in the fire image domain, which hinders detection performance. To represent fires visually and in an automated fashion, a residual neural network generator based on CycleGAN is implemented to perform unpaired image-to-image translation of non-fire images obtained from Bing Maps to the fire domain. Additionally, the adaptation of ERNet, a lightweight disaster classification network trained on the real fire domain, enables simulated aircraft to carry out fire detection along their trajectories. We do so under an environment comprised of a multi-agent distributed platform for aircraft and environmental disturbances, which helps tackle the previous inconvenience by accelerating artificial aerial fire imagery acquisition. The generator was tested using the metric of Frechet Inception Distance, and qualitatively, resorting to the opinion of 122 subjects. The images were considered diverse and of good quality, particularly for the forest and urban scenarios, and their anomalies were highlighted to identify further improvements. The detector performance was evaluated in interaction with the simulation platform. It was proven to be compatible with real-time requirements, processing detection requests at around 100 ms, reaching an accuracy of 90.2% and a false positive rate of 4.5%.
RI Silva, Daniel Castro/O-3205-2013
OI Silva, Daniel Castro/0000-0001-9293-0341
SN 2184-433X
BN 978-989-758-547-0
PY 2022
BP 273
EP 284
DI 10.5220/0010829400003116
UT WOS:000774441800024
ER

PT C
AU Guo, C
   Zuo, XX
   Wang, S
   Cheng, L
AF Guo, Chuan
   Zuo, Xinxin
   Wang, Sen
   Cheng, Li
BE Avidan, S
   Brostow, G
   Cisse, M
   Farinella, GM
   Hassner, T
TI TM2T: Stochastic and Tokenized Modeling for the Reciprocal Generation of
   3D Human Motions and Texts
SO COMPUTER VISION - ECCV 2022, PT XXXV
SE Lecture Notes in Computer Science
CT 17th European Conference on Computer Vision (ECCV)
CY OCT 23-27, 2022
CL Tel Aviv, ISRAEL
AB Inspired by the strong ties between vision and language, the two intimate human sensing and communication modalities, our paper aims to explore the generation of 3D human full-body motions from texts, as well as its reciprocal task, shorthanded for text2motion and motion2text, respectively. To tackle the existing challenges, especially to enable the generation of multiple distinct motions from the same text, and to avoid the undesirable production of trivial motionless pose sequences, we propose the use of motion token, a discrete and compact motion representation. This provides one level playing ground when considering both motions and text signals, as the motion and text tokens, respectively. Moreover, our motion2text module is integrated into the inverse alignment process of our text2motion training pipeline, where a significant deviation of synthesized text from the input text would be penalized by a large training loss; empirically this is shown to effectively improve performance. Finally, the mappings in-between the two modalities of motions and texts are facilitated by adapting the neural model for machine translation (NMT) to our context. This autoregressive modeling of the distribution over discrete motion tokens further enables non-deterministic production of pose sequences, of variable lengths, from an input text. Our approach is flexible, could be used for both text2motion and motion2text tasks. Empirical evaluations on two benchmark datasets demonstrate the superior performance of our approach on both tasks over a variety of state-of-the-art methods. Project page: https://ericguo5513.github.io/TM2T/
SN 0302-9743
EI 1611-3349
BN 978-3-031-19832-8; 978-3-031-19833-5
PY 2022
VL 13695
BP 580
EP 597
DI 10.1007/978-3-031-19833-5_34
UT WOS:000903538700034
ER

PT C
AU Htike, ZZ
   Win, SL
AF Htike, Zaw Zaw
   Win, Shoon Lei
BE Cho, SB
   Chan, JH
   Hwang, KB
TI Classification of eukaryotic splice-junction genetic sequences using
   averaged one-dependence estimators with subsumption resolution
SO 4TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SYSTEMS-BIOLOGY AND
   BIOINFORMATICS (CSBIO2013)
SE Procedia Computer Science
CT 4th International Conference on Computational Systems-Biology and
   Bioinformatics (CSBio)
CY NOV 07-09, 2013
CL Seoul, SOUTH KOREA
SP Yonsei Univ, Asia Pacific Neural Network Assembly, Int Neural Network Soc
AB DNA is the building block of life, which contains encoded genetic instructions for building living organisms. Because of the fact that proteins are constructed in accordance with the genetic instructions encoded in DNAs, errors in RNA synthesis and translation into proteins can cause genetic disorders. Therefore, understanding and recognizing genetic sequences is one step towards the treatment of these genetic disorders. Since the discovery of DNA, there has been a growing interest in the problem of genetic sequence recognition, motivated by its enormous potential to cure a wide range of genetic disorders. The completion of the human genome project in the last decade has generated a strong demand in computational analysis techniques in order to fully exploit the acquired human genome database. This paper describes a state-of-the-art machine learning based approach called averaged one-dependence estimators with subsumption resolution to tackle the problem of recognizing an important class of genetic sequences known as eukaryotic splice junctions. To lower the computational complexity and to increase the generalization capability of the system, we employ a genetic algorithm to select relevant nucleotides that are directly responsible for splice-junction recognition. We carried out experiments on a dataset extracted from the biological literature. This proposed system has achieved an accuracy of 96.68% in classifying splice-junction genetic sequences. The experimental results demonstrate the efficacy of our framework and encourage us to apply the framework on other types of genetic sequences. (C) 2013 The Authors. Published by Elsevier B.V.
SN 1877-0509
PY 2013
VL 23
BP 36
EP 43
DI 10.1016/j.procs.2013.10.006
UT WOS:000342613800004
ER

PT J
AU Vadakkepat, P
   Lim, P
   De Silva, LC
   Jing, L
   Ling, LL
AF Vadakkepat, Prahlad
   Lim, Peter
   De Silva, Liyanage C.
   Jing, Liu
   Ling, Li Li
TI Multimodal approach to human-face detection and tracking
SO IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS
AB The constructive need for robots to coexist with humans requires human-machine interaction. It is a challenge to operate these robots in such dynamic environments, which requires continuous decision-making and environment-attribute update in real-time. An autonomous robot guide is well suitable in places such as museums, libraries, schools, hospital, etc. This paper addresses a scenario where a robot tracks and follows a human. A neural network is utilized to learn the skin and nonskin colors; The skin-color probability map is utilized for skin classification and morphology-based preprocessing. Heuristic rule is used for face-ratio analysis and Bayesian cost analysis for label classification. A face-detection module, based on a 2-D color model in the YCrCb and YUV color space, is selected over the traditional skin-color model in a 3-D color space. A modified Continuously Adaptive Mean Shift tracking mechanism in a 1-D Hue, Saturation, and Value color space is developed and implemented onto the mobile robot. In addition to the visual cues, the tracking process considers 16 sonar scan and tactile sensor readings from the robot to generate a robust measure of the person's distance from the robot. The robot thus decides an appropriate action, namely, to follow the human subject and perform obstacle avoidance. The proposed approach is orientation invariant under varying lighting conditions and invariant to natural transformations such as translation, rotation, and scaling. Such a multimodal solution is effective for face detection and tracking.
RI De Silva, Liyanage/A-2175-2009
OI De Silva, Liyanage/0000-0001-7128-5945; Vadakkepat,
   Prahlad/0000-0003-2649-9893
SN 0278-0046
EI 1557-9948
PD MAR
PY 2008
VL 55
IS 3
BP 1385
EP 1393
DI 10.1109/TIE.2007.903993
UT WOS:000253872900040
ER

PT J
AU Garg, A
   Degiovanni, R
   Jimenez, M
   Cordy, M
   Papadakis, M
   Le Traon, Y
AF Garg, Aayush
   Degiovanni, Renzo
   Jimenez, Matthieu
   Cordy, Maxime
   Papadakis, Mike
   Le Traon, Yves
TI Learning from what we know: How to perform vulnerability prediction
   using noisy historical data
SO EMPIRICAL SOFTWARE ENGINEERING
AB Vulnerability prediction refers to the problem of identifying system components that are most likely to be vulnerable. Typically, this problem is tackled by training binary classifiers on historical data. Unfortunately, recent research has shown that such approaches underperform due to the following two reasons: a) the imbalanced nature of the problem, and b) the inherently noisy historical data, i.e., most vulnerabilities are discovered much later than they are introduced. This misleads classifiers as they learn to recognize actual vulnerable components as non-vulnerable. To tackle these issues, we propose TROVON, a technique that learns from known vulnerable components rather than from vulnerable and non-vulnerable components, as typically performed. We perform this by contrasting the known vulnerable, and their respective fixed components. This way, TROVON manages to learn from the things we know, i.e., vulnerabilities, hence reducing the effects of noisy and unbalanced data. We evaluate TROVON by comparing it with existing techniques on three security-critical open source systems, i.e., Linux Kernel, OpenSSL, and Wireshark, with historical vulnerabilities that have been reported in the National Vulnerability Database (NVD). Our evaluation demonstrates that the prediction capability of TROVON significantly outperforms existing vulnerability prediction techniques such as Software Metrics, Imports, Function Calls, Text Mining, Devign, LSTM, and LSTM-RF with an improvement of 40.84% in Matthews Correlation Coefficient (MCC) score under Clean Training Data Settings, and an improvement of 35.52% under Realistic Training Data Settings.
RI Garg, Aayush/GQZ-7100-2022
OI Garg, Aayush/0000-0002-2507-8846
SN 1382-3256
EI 1573-7616
PD DEC
PY 2022
VL 27
IS 7
AR 169
DI 10.1007/s10664-022-10197-4
UT WOS:000859469500005
ER

PT J
AU Ain, Q
   Mehmood, MA
AF Ain, Qurrat
   Mehmood, Muhammad Amir
TI Runtime performance evaluation and optimization of type-2 hypervisor for
   MIPS64 architecture
SO JOURNAL OF KING SAUD UNIVERSITY-COMPUTER AND INFORMATION SCIENCES
AB Over the last decade, virtualization technologies have seen unprecedented growth in the system-level domain and promptly have moved to the embedded system domain. While there are numerous applications of virtualization for off-the-shelf hardware such as security, sandboxing, testing tools, etc. However, there are few open-source virtualization solutions available for embedded systems. For real-time virtualization, good runtime performance is a deterministic factor for its practical use in the embedded domain. In this paper, the internal architecture of HTTM (an open-source type-2 hypervisor for MIPS64 architecture) was thoroughly analyzed. ISA virtualization unit and execution cycle control were two primary units that were profiled and explored for optimization. Dynamic Binary Translation (DBT) unit was modified to generate highly efficient code. While the reduction in switching between the translated code and management layer improved the overall execution cycle. The implementation of these strategies resulted in a 72-91% improvement in bandwidth benchmarks. Similarly, latency benchmarks show a 2-92% improvement from its vanilla version. Collectively producing an overall 1-5 times the improvement in execution time. The performance of optimized HTTM is also compared with Quick Emulator (QEMU). HTTM performs 44-80% better than QEMU in bandwidth benchmarks while QEMU performs better in latency operations. (c) 2019 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
SN 1319-1578
EI 2213-1248
PD FEB
PY 2022
VL 34
IS 2
BP 295
EP 307
DI 10.1016/j.jksuci.2019.11.006
EA FEB 2022
UT WOS:000758918900012
ER

PT J
AU Wei, C
   Zhang, JY
   Yuan, XG
AF Wei, Chao
   Zhang, Junying
   Yuan, Xiguo
TI Enhancing the prediction of protein coding regions in biological
   sequence via a deep learning framework with hybrid encoding
SO DIGITAL SIGNAL PROCESSING
AB Protein coding regions prediction is a very important but overlooked subtask for tasks such as prediction of complete gene structure, coding/noncoding RNA. Many machine learning methods have been proposed for this problem, they first encode a biological sequence into numerical values and then feed them into a classifier for final prediction. However, encoding schemes directly influence the classifier's capability to capture coding features and how to choose a proper encoding scheme remains uncertain. Recently, we proposed a protein coding region prediction method in transcript sequences based on a bidirectional recurrent neural network with non-overlapping 3-mer feature, and achieved considerable improvement over existing methods, but there is still much room to improve the performance. First, 3-mer feature that counts the occurrence frequency of trinucleotides in a biological sequence only reflects local sequence order information between the most contiguous nucleotides, which loses almost all the global sequence order information. Second, kmer features of length k larger than three (e.g., hexamer) may also contain useful information. Based on the two points, we here present a deep learning framework with hybrid encoding for protein coding regions prediction in biological sequences, which effectively exploit global sequence order information, non-overlapping gapped kmer (gkm) features and statistical dependencies among coding labels. 3-fold cross-validation tests on human and mouse biological sequence demonstrate that our proposed method significantly outperforms existing state-of-the-art methods. (c) 2022 Published by Elsevier Inc.
SN 1051-2004
EI 1095-4333
PD APR 30
PY 2022
VL 123
AR 103430
DI 10.1016/j.dsp.2022.103430
EA JAN 2022
UT WOS:000782680300011
ER

PT J
AU Deng, JL
   Song, W
   Liu, D
   Li, Q
   Lin, GH
   Wang, HM
AF Deng, Junlan
   Song, Wei
   Liu, Dan
   Li, Qin
   Lin, Ganghua
   Wang, Haimin
TI Improving the Spatial Resolution of Solar Images Using Generative
   Adversarial Network and Self-attention Mechanism*
SO ASTROPHYSICAL JOURNAL
AB In recent years, the new physics of the Sun has been revealed using advanced data with high spatial and temporal resolutions. The Helioseismic and Magnetic Imager (HMI) on board the Solar Dynamic Observatory has accumulated abundant observation data for the study of solar activity with sufficient cadence, but their spatial resolution (about 1 '') is not enough to analyze the subarcsecond structure of the Sun. On the other hand, high-resolution observation from large-aperture ground-based telescopes, such as the 1.6 m Goode Solar Telescope (GST) at the Big Bear Solar Observatory, can achieve a much higher resolution on the order of 0.'' 1 (about 70 km). However, these high-resolution data only became available in the past 10 yr, with a limited time period during the day and with a very limited field of view. The Generative Adversarial Network (GAN) has greatly improved the perceptual quality of images in image translation tasks, and the self-attention mechanism can retrieve rich information from images. This paper uses HMI and GST images to construct a precisely aligned data set based on the scale-invariant feature transform algorithm and t0 reconstruct the HMI continuum images with four times better resolution. Neural networks based on the conditional GAN and self-attention mechanism are trained to restore the details of solar active regions and to predict the reconstruction error. The experimental results show that the reconstructed images are in good agreement with GST images, demonstrating the success of resolution improvement using machine learning.
SN 0004-637X
EI 1538-4357
PD DEC
PY 2021
VL 923
IS 1
AR 76
DI 10.3847/1538-4357/ac2aa2
UT WOS:000729599600001
ER

PT J
AU Haiderbhai, M
   Ledesma, S
   Lee, SC
   Seibold, M
   Furnstahl, P
   Navab, N
   Fallavollita, P
AF Haiderbhai, Mustafa
   Ledesma, Sergio
   Lee, Sing Chun
   Seibold, Matthias
   Fuernstahl, Phillipp
   Navab, Nassir
   Fallavollita, Pascal
TI pix2xray: converting RGB images into X-rays using generative adversarial
   networks
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
AB Purpose We propose a novel methodology for generating synthetic X-rays from 2D RGB images. This method creates accurate simulations for use in non-diagnostic visualization problems where the only input comes from a generic camera. Traditional methods are restricted to using simulation algorithms on 3D computer models. To solve this problem, we propose a method of synthetic X-ray generation using conditional generative adversarial networks (CGANs). Methods We create a custom synthetic X-ray dataset generator to generate image triplets for X-ray images, pose images, and RGB images of natural hand poses sampled from the NYU hand pose dataset. This dataset is used to train two general-purpose CGAN networks, pix2pix and CycleGAN, as well as our novel architecture called pix2xray which expands upon the pix2pix architecture to include the hand pose into the network. Results Our results demonstrate that our pix2xray architecture outperforms both pix2pix and CycleGAN in producing higher-quality X-ray images. We measure higher similarity metrics in our approach, with pix2pix coming in second, and CycleGAN producing the worst results. Our network performs better in the difficult cases which involve high occlusion due to occluded poses or large rotations. Conclusion Overall our work establishes a baseline that synthetic X-rays can be simulated using 2D RGB input. We establish the need for additional data such as the hand pose to produce clearer results and show that future research must focus on more specialized architectures to improve overall image clarity and structure.
RI Seibold, Matthias/ABD-6003-2021
OI Furnstahl, Philipp/0000-0001-6484-6206; LEE, Sing
   Chun/0000-0002-3486-5665
SN 1861-6410
EI 1861-6429
PD JUN
PY 2020
VL 15
IS 6
SI SI
BP 973
EP 980
DI 10.1007/s11548-020-02159-2
EA APR 2020
UT WOS:000528998100001
PM 32342258
ER

PT J
AU Saeedi, P
   Faili, H
   Shakery, A
AF Saeedi, Parisa
   Faili, Heshaam
   Shakery, Azadeh
TI Semantic role induction in Persian: An unsupervised approach by using
   probabilistic models
SO DIGITAL SCHOLARSHIP IN THE HUMANITIES
AB Semantic roles describe the relation between a predicate (typically a verb) and its arguments. Semantic role labeling is a Natural Language Processing task that extracts these relations in the sentences. Different applications such as machine translation and question answering benefit from this level of semantic analysis. The creation of semantic role-annotated data is an obstacle to develop supervised learning systems, so we present a novel unsupervised approach to semantic role induction task. In our approach, which is formulized as a clustering method, the argument instances of the verb are clustered into semantic role classes specified for that verb. We present a Bayesian model for learning argument structure from un-annotated text and estimate the model parameters using expectation maximization method. Clustering of argument instances of a verb, which have semantic and syntactic similarities, can be a promising approach for unsupervised learning of their semantic roles. The only linguistic knowledge, which is prepared for linking the argument instances to semantic clusters is extracted from a verb valance lexicon. Our evaluation results on Persian language show that our system in both small and large training datasets works better than a strong baseline proposed by (Lang and Lapata 2010) which its idea is developed in Persian. We have used purity and inverse purity measures to assess the quality of the proposed semantic role clustering method. The results indicate the improvement about 9.73 and 1.65% in small dataset and 2.85 and 0.67% in large dataset in purity and inverse purity, respectively.
RI saeedi, parisa/AAZ-1638-2020
OI saeedi, parisa/0000-0003-1268-9522
SN 2055-7671
EI 2055-768X
PD APR
PY 2016
VL 31
IS 1
BP 181
EP 203
DI 10.1093/llc/fqu044
UT WOS:000378144700012
ER

PT J
AU Zhang, X
   Zhou, XQ
   Liu, QZ
   Xu, P
AF Zhang, Xu
   Zhou, Xiaoqin
   Liu, Qiang
   Xu, Pengzi
TI The analysis and measurement of motion errors of the linear slide in
   fast tool servo diamond turning machine
SO ADVANCES IN MECHANICAL ENGINEERING
AB This article proposes a novel method for identifying the motion errors (mainly straightness error and angular error) of a linear slide, which is based on the laser interferometry technique integrated with the shifting method. First, the straightness error of a linear slide incorporated with angular error (pitch error in the vertical direction and yaw error in the horizontal direction) is schematically explained. Then, a laser interferometry-based system is constructed to measure the motion errors of a linear slide, and an algorithm of error separation technique for extracting the straightness error, angular error, and tilt angle error caused by the motion of the reflector is developed. In the proposed method, the reflector is mounted on the slide moving along the guideway. The light-phase variation of two interfering laser beams can identify the lateral translation error of the slide. The differential outputs sampled with shifting initial point at the same datum line are applied to evaluate the angular error of the slide. Furthermore, the yaw error of the slide is measured by a laser interferometer in laboratory environment and compared with the evaluated values. Experimental results demonstrate that the proposed method possesses the advantages of reducing the effects caused by the assembly error and the tilt angle errors caused by movement of the reflector, adapting to long-or short-range measurement, and operating the measurement experiment conveniently and easily.
RI Zhou, Xiaoqin/K-9861-2013
OI Zhou, Xiaoqin/0000-0003-3639-1173
SN 1687-8132
EI 1687-8140
PD MAR
PY 2015
VL 7
IS 3
AR 1687814015575456
DI 10.1177/1687814015575456
UT WOS:000354084900046
ER

PT J
AU Sujeeth, AK
   Brown, KJ
   Lee, H
   Rompf, T
   Chafi, H
   Odersky, M
   Olukotun, K
AF Sujeeth, Arvind K.
   Brown, Kevin J.
   Lee, Hyoukjoong
   Rompf, Tiark
   Chafi, Hassan
   Odersky, Martin
   Olukotun, Kunle
TI Delite: A Compiler Architecture for Performance-Oriented Embedded
   Domain-Specific Languages
SO ACM TRANSACTIONS ON EMBEDDED COMPUTING SYSTEMS
AB Developing high-performance software is a difficult task that requires the use of low-level, architecture-specific programming models (e.g., OpenMP for CMPs, CUDA for GPUs, MPI for clusters). It is typically not possible to write a single application that can run efficiently in different environments, leading to multiple versions and increased complexity. Domain-Specific Languages (DSLs) are a promising avenue to enable programmers to use high-level abstractions and still achieve good performance on a variety of hardware. This is possible because DSLs have higher-level semantics and restrictions than general-purpose languages, so DSL compilers can perform higher-level optimization and translation. However, the cost of developing performance-oriented DSLs is a substantial roadblock to their development and adoption. In this article, we present an overview of the Delite compiler framework and the DSLs that have been developed with it. Delite simplifies the process of DSL development by providing common components, like parallel patterns, optimizations, and code generators, that can be reused in DSL implementations. Delite DSLs are embedded in Scala, a general-purpose programming language, but use metaprogramming to construct an Intermediate Representation (IR) of user programs and compile to multiple languages (including C++, CUDA, and OpenCL). DSL programs are automatically parallelized and different parts of the application can run simultaneously on CPUs and GPUs. We present Delite DSLs for machine learning, data querying, graph analysis, and scientific computing and show that they all achieve performance competitive to or exceeding C++ code.
OI Rompf, Tiark/0000-0002-2068-3238; Olukotun, Kunle/0000-0002-8779-0636
SN 1539-9087
EI 1558-3465
PD JUL
PY 2014
VL 13
SU 4
SI SI
AR 134
DI 10.1145/2584665
UT WOS:000341390100017
ER

PT J
AU Varma, SD
   Kovtun, S
AF Varma, Shambhu D.
   Kovtun, Svitlana
TI Protective effect of caffeine against high sugar-induced transcription
   of microRNAs and consequent gene silencing: A study using lenses of
   galactosemic mice
SO MOLECULAR VISION
AB Purpose: Previous studies have shown that caffeine prevents the formation of cataracts induced by a high-galactose diet and consequent oxidative stress. The objective of this study was to investigate if this protective effect is reflected in the attenuation of the transcription of microRNAs (miRNAs) known to induce apoptosis and cell death by gene silencing.
   Methods: Young CD-1 mice were fed either a normal laboratory diet or a diet containing 25% galactose with or without 1% caffeine. One week later, the animals were euthanized, and the lenses isolated and promptly processed for RNA isolation and subsequent preparation of cDNAs by reverse transcriptase reaction. Mature miRNA (miR)-specific cDNAs were then quantified with PCR in a 96-well microRNA-specific cassette using an ABI7900HT PCR machine.
   Results: As expected from previous studies, the lenses were positive for all 84 miRs corresponding to the miRNA probes present in the cassette wells. However, the levels of at least 19 miRs were significantly elevated in galactosemic lenses compared to those in the normal lenses. The majority are proapoptotic. Such elevation was inhibited by caffeine. This has been demonstrated for the first time.
   Conclusions: Since aberrant elevation of miRNAs silences various genes and consequently deactivates protein translation, and since caffeine downregulates such aberration, the beneficial effect of caffeine could be attributed to its ability to suppress elevation of toxic miRs and consequent gene silencing.
SN 1090-0535
PD FEB 25
PY 2013
VL 19
BP 493
EP 500
UT WOS:000315493100004
PM 23441122
ER

PT J
AU Urena-Lopez, LA
   Buenaga, M
   Gomez, JM
AF Urena-Lopez, LA
   Buenaga, M
   Gomez, JM
TI Integrating linguistic resources in TC through WSD
SO COMPUTERS AND THE HUMANITIES
AB Information access methods must be improved to overcome the information overload that most professionals face nowadays. Text classification tasks, like Text Categorization. help the users to access to the great amount of text they find in the Internet and their organizations. TC is the classification of documents into a predefined set of categories. Most approaches to automatic TC are based on the utilization of a training collection, which is a set of manually classified documents. Other linguistic resources that are emerging, like lexical databases, can also be used for classification tasks. This article describes an approach to TC based on the integration of a training collection (Reuters-21578) and a lexical database (WORDNET 1.6) as knowledge sources. Lexical databases accumulate information on the lexical items of one or several languages. This information must be filtered in order to make an effective use of it in our model of TC. This filtering process is a Word Sense Disambiguation task. WSD is the identification of the sense of words in context. This task is an intermediate process in many natural language processing tasks like machine translation or multi-lingual information retrieval. We present the utilization of WSD as an aid for TC. Our approach to WSD is also based on the integration of two linguistic resources: a training collection (SEMCOR and Reuters-21578) and a lexical database (WORDNET 1.6). We have developed a series of experiments that show that: TC and WSD based on the integration of linguistic resources are very effective; and, WSD is necessary to effectively integrate linguistic resources in TC.
RI Ureña López, Alfonso/G-9999-2015; de Buenaga, Manuel/M-2399-2014
OI Ureña López, Alfonso/0000-0001-7540-4059; de Buenaga,
   Manuel/0000-0003-4705-1836
SN 0010-4817
PD MAY
PY 2001
VL 35
IS 2
BP 215
EP 230
DI 10.1023/A:1002632712378
UT WOS:000167733600007
ER

PT J
AU Uhrin, M
AF Uhrin, Martin
TI Through the eyes of a descriptor: Constructing complete, invertible
   descriptions of atomic environments
SO PHYSICAL REVIEW B
AB In this work we apply methods for describing three-dimensional images to the problem of encoding atomic environments in a way that is invariant to rotations, translations, and permutations of the atoms and, crucially, can be decoded back into the original environment modulo global orientation without the need for training a model. From the point of view of decoding, the descriptor is optimally complete and can be extended to arbitrary order, allowing for a systematic convergence of the fidelity of the description. In experiments on molecules ranging from 3 to 29 atoms in size, we demonstrate that positions can be decoded with a 97% success rate and positions plus species with a 70% rate of success, rising to 95% if a second fingerprint is used. In all cases, consistent recovery is observed for molecules with 17 or fewer atoms. Additionally, we evaluate the descriptor's performance in predicting the energies and forces of bulk Ni, Cu, Li, Mo, Si, and Ge by means of a neural network model trained on DFT data. When comparing to six machine learning interaction potential methods that use various descriptors and regression schemes, our descriptor is found to be competitive, in several cases outperforming well established methods. The combined ability to both decode and make property predictions from a representation that does not need to be learned lays the foundations for a novel way of building generative models that are tasked with solving the inverse problem of predicting atomic arrangements that are statistically likely to have certain desired properties.
RI Uhrin, Martin/ABA-8195-2021
OI Uhrin, Martin/0000-0001-6902-1289
SN 2469-9950
EI 2469-9969
PD OCT 26
PY 2021
VL 104
IS 14
AR 144110
DI 10.1103/PhysRevB.104.144110
UT WOS:000748417000002
ER

PT J
AU Shi, MJ
   Liang, YB
   Zhang, MF
   Huang, ZQ
   Feng, L
   Zhou, ZQ
AF Shi, Mingjiang
   Liang, Yanbing
   Zhang, Mengfei
   Huang, Zhiqiang
   Feng, Lin
   Zhou, Zhengquan
TI Pipeline Damage Detection Based on Metal Magnetic Memory
SO IEEE TRANSACTIONS ON MAGNETICS
AB The metal magnetic memory detection technology can detect early stress concentration and invisible damage of the pipeline. It can be detected under the action of the geomagnetic field, without the need to magnetize the pipeline in advance, which has the advantage of non-destructive testing. Since the magnetic memory signal is relatively weak, the actual detected signal will be affected by environmental noise, sensor jitter, and pipeline surface deposits. Therefore, the magnetic memory signal needs to be denoised. In this article, the translation invariant wavelet denoising method, which is improved based on the wavelet threshold denoising method, is used to denoise the collected pipeline magnetic memory signals. The experimental results show that the signal-to-noise ratio (SNR) obtained by this method is 1.15% higher than the unmodified wavelet threshold denoising, and the signal obtained is more stable. To solve the problem of fewer data samples for magnetic memory detection, three methods including support vector regression machine, back propagation (BP) neural network, and particle swarm optimization multiple output least-squares support vector regression (MLS-SVR) are compared and analyzed to inverse the overall defect size of pipeline defects. The experiments show that the MLS-SVR inversion result based on particle swarm optimization is the best, and the overall mean square error reaches 0.27 mm. In the end, a pipeline damage detection system is built to detect the magnetic memory signals of pipelines with different sizes of defects, and the defect depth and radius are inverted.
OI MingJiang, Shi/0000-0001-9637-3503
SN 0018-9464
EI 1941-0069
PD AUG
PY 2021
VL 57
IS 8
AR 6200615
DI 10.1109/TMAG.2021.3084808
UT WOS:000675203800004
ER

PT J
AU Phan, THV
   Do, P
AF Phan, Truong H., V
   Phuc Do
TI BERT+vnKG: Using Deep Learning and Knowledge Graph to Improve Vietnamese
   Question Answering System
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
AB A question answering (QA) system based on natural language processing and deep learning is a prominent area and is being researched widely. The Long Short-Term Memory (LSTM) model that is a variety of Recurrent Neural Network (RNN) used to be popular in machine translation, and question answering system. However, that model still has certainly limited capabilities, so a new model named Bidirectional Encoder Representation from Transformer (BERT) emerged to solve these restrictions. BERT has more advanced features than LSTM and shows state-of-the-art results in many tasks, especially in multilingual question answering system over the past few years. Nevertheless, we tried applying multilingual BERT model for a Vietnamese QA system and found that BERT model still has certainly limitation in term of time and precision to return a Vietnamese answer. The purpose of this study is to propose a method that solved above restriction of multilingual BERT and applied for question answering system about tourism in Vietnam. Our method combined BERT and knowledge graph to enhance accurately and find quickly for an answer. We experimented our crafted QA data about Vietnam tourism on three models such as LSTM, BERT fine-tuned multilingual for QA (BERT for QA), and BERT+ vnKG. As a result, our model outperformed two previous models in terms of accuracy and time. This research can also be applied to other fields such as finance, e-commerce, and so on.
RI Phan, Truong H. V./HGC-7169-2022
OI Phan, Truong H. V./0000-0003-1773-6703
SN 2158-107X
EI 2156-5570
PD JUL
PY 2020
VL 11
IS 7
BP 480
EP 487
UT WOS:000568850200062
ER

PT C
AU Olivastri, S
   Singh, G
   Cuzzolin, F
AF Olivastri, Silvio
   Singh, Gurkirt
   Cuzzolin, Fabio
GP IEEE
TI End-to-End Video Captioning
SO 2019 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS
   (ICCVW)
SE IEEE International Conference on Computer Vision Workshops
CT IEEE/CVF International Conference on Computer Vision (ICCV)
CY OCT 27-NOV 02, 2019
CL Seoul, SOUTH KOREA
SP IEEE, IEEE Comp Soc, CVF
AB Building correspondences across different modalities, such as video and language, has recently become critical in many visual recognition applications, such as video captioning. Inspired by machine translation, recent models tackle this task using an encoder-decoder strategy. The (video) encoder is traditionally a Convolutional Neural Network (CNN), while the decoding (for language generation) is done using a Recurrent Neural Network (RNN). Current state-of-the-art methods, however, train encoder and decoder separately. CNNs are pretrained on object and/or action recognition tasks and used to encode video-level features. The decoder is then optimised on such static features to generate the video's description. This disjoint setup is arguably sub-optimal for input (video) to output (description) mapping.
   In this work, we propose to optimise both encoder and decoder simultaneously in an end-to-end fashion. In a two stage training setting, we first initialise our architecture using pre-trained encoders and decoders then, the entire network is trained end-to-end in a fine-tuning stage to learn the most relevant features for video caption generation. In our experiments, we use GoogLeNet and Inception-ResNetv2 as encoders and an original Soft-Attention (SA-) LSTM as a decoder. Analogously to gains observed in other computer vision problems, we show that end-to-end training significantly improves over the traditional, disjoint training process. We evaluate our End-to-End (EtENet) Networks on the Microsoft Research Video Description (MSVD) and the MSR Video to Text (MSR-VTT) benchmark datasets, showing how EtENet achieves state-of-the-art performance across the board.
SN 2473-9936
BN 978-1-7281-5023-9
PY 2019
BP 1474
EP 1482
DI 10.1109/ICCVW.2019.00185
UT WOS:000554591601067
ER

PT J
AU Tsai, FS
   Hsu, SY
   Shih, MH
AF Tsai, Feng-Sheng
   Hsu, Sheng-Yi
   Shih, Mau-Hsiang
TI Adaptive Tracking Control for Robots With an Interneural Computing
   Scheme
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
AB Adaptive tracking control of mobile robots requires the ability to follow a trajectory generated by a moving target. The conventional analysis of adaptive tracking uses energy minimization to study the convergence and robustness of the tracking error when the mobile robot follows a desired trajectory. However, in the case that the moving target generates trajectories with uncertainties, a common Lyapunov-like function for energy minimization may be extremely difficult to determine. Here, to solve the adaptive tracking problem with uncertainties, we wish to implement an interneural computing scheme in the design of a mobile robot for behavior-based navigation. The behavior-based navigation adopts an adaptive plan of behavior patterns learning from the uncertainties of the environment. The characteristic feature of the interneural computing scheme is the use of neural path pruning with rewards and punishment interacting with the environment. On this basis, the mobile robot can be exploited to change its coupling weights in paths of neural connections systematically, which can then inhibit or enhance the effect of flow elimination in the dynamics of the evolutionary neural network. Such dynamical flow translation ultimately leads to robust sensory-to-motor transformations adapting to the uncertainties of the environment. A simulation result shows that the mobile robot with the interneural computing scheme can perform fault-tolerant behavior of tracking by maintaining suitable behavior patterns at high frequency levels.
OI Tsai, Feng-Sheng/0000-0002-1972-2471
SN 2162-237X
EI 2162-2388
PD APR
PY 2018
VL 29
IS 4
BP 832
EP 844
DI 10.1109/TNNLS.2017.2647819
UT WOS:000427859600006
PM 28129188
ER

PT J
AU Xiang, YH
   Xiang, PP
   Zhang, LY
   Li, YY
   Zhang, J
AF Xiang, Yunhui
   Xiang, Pinpin
   Zhang, Liuyun
   Li, Yanying
   Zhang, Juan
TI A narrative review for platelets and their RNAs in cancers: New concepts
   and clinical perspectives
SO MEDICINE
AB Recent years have witnessed a growing body of evidence suggesting that platelets are involved in several stages of the metastatic process via direct or indirect interactions with cancer cells, contributing to the progression of neoplastic malignancies. Cancer cells can dynamically exchange components with platelets in and out of blood vessels, and directly phagocytose platelets to hijack their proteome, transcriptome, and secretome, or be remotely regulated by metabolites or microparticles released by platelets, resulting in phenotypic, genetic, and functional modifications. Moreover, platelet interactions with stromal and immune cells in the tumor microenvironment lead to alterations in their components, including the ribonucleic acid (RNA) profile, and complicate the impact of platelets on cancers. A deeper understanding of the roles of platelets and their RNAs in cancer will contribute to the development of anticancer strategies and the optimization of clinical management. Encouragingly, advances in high-throughput sequencing, bioinformatics data analysis, and machine learning have allowed scientists to explore the potential of platelet RNAs for cancer diagnosis, prognosis, and guiding treatment. However, the clinical application of this technique remains controversial and requires larger, multicenter studies with standardized protocols. Here, we integrate the latest evidence to provide a broader insight into the role of platelets in cancer progression and management, and propose standardized recommendations for the clinical utility of platelet RNAs to facilitate translation and benefit patients.
SN 0025-7974
EI 1536-5964
PD DEC 30
PY 2022
VL 101
IS 52
DI 10.1097/MD.0000000000032539
UT WOS:000906956700061
PM 36596034
ER

PT J
AU Ponsiglione, A
   Stanzione, A
   Spadarella, G
   Baran, A
   Cappellini, LA
   Lipman, KG
   Van Ooijen, P
   Cuocolo, R
AF Ponsiglione, Andrea
   Stanzione, Arnaldo
   Spadarella, Gaia
   Baran, Agah
   Cappellini, Luca Alessandro
   Lipman, Kevin Groot
   Van Ooijen, Peter
   Cuocolo, Renato
TI Ovarian imaging radiomics quality score assessment: an EuSoMII radiomics
   auditing group initiative
SO EUROPEAN RADIOLOGY
AB Objective To evaluate the methodological rigor of radiomics-based studies using noninvasive imaging in ovarian setting. Methods Multiple medical literature archives (PubMed, Web of Science, and Scopus) were searched to retrieve original studies focused on computed tomography (CT), magnetic resonance imaging (MRI), ultrasound (US), or positron emission tomography (PET) radiomics for ovarian disorders' assessment. Two researchers in consensus evaluated each investigation using the radiomics quality score (RQS). Subgroup analyses were performed to assess whether the total RQS varied according to first author category, study aim and topic, imaging modality, and journal quartile. Results From a total of 531 items, 63 investigations were finally included in the analysis. The studies were greatly focused (94%) on the field of oncology, with CT representing the most used imaging technique (41%). Overall, the papers achieved a median total RQS 6 (IQR, -0.5 to 11), corresponding to a percentage of 16.7% of the maximum score (IQR, 0-30.6%). The scoring was low especially due to the lack of prospective design and formal validation of the results. At subgroup analysis, the 4 studies not focused on oncological topic showed significantly lower quality scores than the others. Conclusions The overall methodological rigor of radiomics studies in the ovarian field is still not ideal, limiting the reproducibility of results and potential translation to clinical setting. More efforts towards a standardized methodology in the workflow are needed to allow radiomics to become a viable tool for clinical decision-making.
RI Cuocolo, Renato/G-3147-2018; Ponsiglione, Andrea/AAR-3677-2020; van
   Ooijen, Peter/B-9150-2008
OI Cuocolo, Renato/0000-0002-1452-1574; Ponsiglione,
   Andrea/0000-0002-0105-935X; cappellini, luca
   alessandro/0000-0001-7604-5625; van Ooijen, Peter/0000-0002-8995-1210
SN 0938-7994
EI 1432-1084
PD MAR
PY 2023
VL 33
IS 3
BP 2239
EP 2247
DI 10.1007/s00330-022-09180-w
EA OCT 2022
UT WOS:000874394400001
PM 36303093
ER

PT J
AU Wang, QY
   Liao, J
   Lapata, M
   Macleod, M
AF Wang, Qianying
   Liao, Jing
   Lapata, Mirella
   Macleod, Malcolm
TI Risk of bias assessment in preclinical literature using natural language
   processing
SO RESEARCH SYNTHESIS METHODS
AB We sought to apply natural language processing to the task of automatic risk of bias assessment in preclinical literature, which could speed the process of systematic review, provide information to guide research improvement activity, and support translation from preclinical to clinical research. We use 7840 full-text publications describing animal experiments with yes/no annotations for five risk of bias items. We implement a series of models including baselines (support vector machine, logistic regression, random forest), neural models (convolutional neural network, recurrent neural network with attention, hierarchical neural network) and models using BERT with two strategies (document chunk pooling and sentence extraction). We tune hyperparameters to obtain the highest F1 scores for each risk of bias item on the validation set and compare evaluation results on the test set to our previous regular expression approach. The F1 scores of best models on test set are 82.0% for random allocation, 81.6% for blinded assessment of outcome, 82.6% for conflict of interests, 91.4% for compliance with animal welfare regulations and 46.6% for reporting animals excluded from analysis. Our models significantly outperform regular expressions for four risk of bias items. For random allocation, blinded assessment of outcome, conflict of interests and animal exclusions, neural models achieve good performance; for animal welfare regulations, BERT model with a sentence extraction strategy works better. Convolutional neural networks are the overall best models. The tool is publicly available which may contribute to the future monitoring of risk of bias reporting for research improvement activities.
RI ; Macleod, Malcolm Robert/B-2052-2010
OI L, Jing/0000-0002-9591-8070; Macleod, Malcolm Robert/0000-0001-9187-9839
SN 1759-2879
EI 1759-2887
PD MAY
PY 2022
VL 13
IS 3
BP 368
EP 380
DI 10.1002/jrsm.1533
EA NOV 2021
UT WOS:000714691800001
PM 34709718
ER

PT J
AU Coemert, S
   Roth, R
   Strauss, G
   Schmitz, PM
   Lueth, TC
AF Coemert, Suat
   Roth, Robert
   Strauss, Gero
   Schmitz, Pia M.
   Lueth, Tim C.
TI A handheld flexible manipulator system for frontal sinus surgery
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
AB Purpose Draf drainage is the standard treatment procedure for frontal sinus diseases. In this procedure, rigid angled endoscopes and rigid curved instruments are used. However, laterally located pathologies in the frontal sinus cannot be reached with rigid instrumentation. In order to assist surgeons with such complicated cases, we propose a novel handheld flexible manipulator system. Methods A cross section of 3 mm x 4.6 mm enables transnasal guiding of a flexible endoscope with 1.4 mm diameter and a standard flexible surgical instrument with up to 1.8 mm diameter into the frontal sinus with increased reachability. The developed system consists of an electrical discharge-machined flexure hinge-based nitinol manipulator arm and a purely mechanical handheld control unit. The corresponding control unit enables upward and left-right bending of the manipulator arm, translation, rolling, actuation and also quick exchange of the surgical instrument. In order to verify the fulfillment of performance requirements, tests regarding reachability and payload capacity were conducted. Results Reachability tests showed that the manipulator arm can be inserted into the frontal sinus and reach its lateral regions following a Draf IIa procedure. The system can exert forces of at least 2 N in the vertical direction and 1 N in the lateral direction which is sufficient for manipulation of frontal sinus pathologies. Conclusion Considering the fact that the anatomical requirements of the frontal sinus are not addressed satisfactorily in the development of prospective flexible instruments, the proposed system shows great potential in terms of therapeutic use owing to its small cross section and dexterity.
RI Coemert, Suat/AGZ-0593-2022
OI Coemert, Suat/0000-0001-5589-6690; Lueth, Tim C./0000-0001-8949-5764
SN 1861-6410
EI 1861-6429
PD SEP
PY 2020
VL 15
IS 9
BP 1549
EP 1559
DI 10.1007/s11548-020-02220-0
EA JUL 2020
UT WOS:000544853800001
PM 32613601
ER

PT J
AU Gal, D
   Thijs, B
   Glanzel, W
   Sipido, KR
AF Gal, Diane
   Thijs, Bart
   Glanzel, Wolfgang
   Sipido, Karin R.
TI Hot topics and trends in cardiovascular research
SO EUROPEAN HEART JOURNAL
AB Aims Comprehensive data on research undertaken in cardiovascular medicine can inform the scientific community and can support policy building. We used the publication output from 2004 to 2013 and the 2014 references to these documents, to identify research topics and trends in the field of cardiovascular disease.
   Methods and results Text fragments were extracted from the titles and abstracts of 478 000 publications using natural language processing. Through machine-learning algorithms, these text fragments combined to identify specific topics across all publications. A second method, which included cross-references, assigned each publication document to a specific cluster. Experts named the topics and document clusters based on various outputs from these semi-automatic methods. We identified and labelled 175 cardiovascular topics and 20 large document clusters, with concordance between the approaches. Overarching, strongly growing topics in clinical and population sciences are evidence-based guidance for treatment, research on outcomes, prognosis, and risk factors. 'Hot' topics include novel treatments in valve disease and in coronary artery disease, and imaging. Basic research decreases its share over time but sees substantial growth of research on stem cells and tissue engineering, as well as in translational research. Inflammation, biomarkers, metabolic syndrome, obesity, and lipids are hot topics across population, clinical and basic research, supporting integration across the cardiovascular field.
   Conclusion Growth in clinical and population research emphasizes improving patient outcomes through novel treatments, risk stratification, and prevention. Translation and innovation redefine basic research in cardiovascular disease. Medical need, funding and publishing policies, and scientific opportunities are potential drivers for these evolutions.
RI Thijs, Bart CM/C-2995-2008; Glanzel, Wolfgang/AAE-4395-2021; Glanzel,
   Wolfgang/A-6280-2008
OI Thijs, Bart CM/0000-0003-0446-8332; Glanzel,
   Wolfgang/0000-0001-7529-5198; Sipido, Karin/0000-0001-9609-5507
SN 0195-668X
EI 1522-9645
PD JUL 21
PY 2019
VL 40
IS 28
BP 2363
EP 2374
DI 10.1093/eurheartj/ehz282
UT WOS:000490143900019
PM 31162536
ER

PT J
AU Leno, IJ
   Sankar, SS
   Ponnambalam, SG
AF Leno, I. Jerin
   Sankar, S. Saravana
   Ponnambalam, S. G.
TI MIP model and elitist strategy hybrid GA-SA algorithm for layout design
SO JOURNAL OF INTELLIGENT MANUFACTURING
AB It is most important for any manufacturing industry to have an efficient layout for their production environment to participate in global competition. One of the prime objectives of such an organisation is to decide an optimal arrangement of their facilities (machines or departments) in a two-dimensional planar region satisfying desired objectives, which is termed facility layout problem. To overcome the drawbacks of traditional layout design methodology, it is attempted to solve three important layout design problems such as inter-cell layout design, determination of optimum location for input/output stations and flow path layout design of material handling system simultaneously in an integrated manner. The quality of the final layout is evaluated by minimizing the total material handling cost, where the perimeter distance metric is used for the distance measurement. Sequence-pair, an elegant representation technique is used for layout encoding. The translation from sequence-pair to layout is efficiently done by longest common subsequence computation methodology. Due to the non-polynomial hard nature of the problem considered, an elitist strategy based hybrid genetic algorithm that uses simulated annealing as local search mechanism (ESHGA) is developed and tested with test problem instances available in the literature. The results indicate that proposed integrated methodology with developed mixed integer programming based mathematical model along with ESHGA could generate realistic layouts compared to reported result.
RI Govindarajan, Ponnambalam Sivalinga/F-6406-2012; leno,
   jerin/AFL-9117-2022
OI Govindarajan, Ponnambalam Sivalinga/0000-0003-4973-733X; leno,
   jerin/0000-0001-5518-6664
SN 0956-5515
EI 1572-8145
PD FEB
PY 2018
VL 29
IS 2
BP 369
EP 387
DI 10.1007/s10845-015-1113-x
UT WOS:000424642800007
ER

PT J
AU Fattah, MA
   Bracewell, DB
   Ren, F
   Kuroiwa, S
AF Fattah, Mohamed Abdel
   Bracewell, David B.
   Ren, Fuji
   Kuroiwa, Shingo
TI Sentence alignment using P-NNT and GMM
SO COMPUTER SPEECH AND LANGUAGE
AB Parallel corpora have become an essential resource for work in multilingual natural language processing. However, sentence aligned parallel corpora are more efficient than non-aligned parallel corpora for cross-language information retrieval and machine translation applications. In this paper, we present two new approaches to align English-Arabic sentences in bilingual parallel corpora based on probabilistic neural network (P-NNT) and Gaussian mixture model (GMM) classifiers. A feature vector is extracted from the text pair under consideration. This vector contains text features such as-length, punctuation score, and cognate score values. A set of manually prepared training data was assigned to train the probabilistic neural network and Gaussian mixture model. Another set of data was used for testing. Using the probabilistic neural network and Gaussian mixture model approaches, we could achieve error reduction of 27% and 50%, respectively, over the length based approach when applied on a set of parallel English-Arabic documents. In addition, the results of (P-NNT) and (GMM) outperform the results of the combined model which exploits length, punctuation and cognates in a dynamic framework. The GMM approach outperforms Melamed and Moore's approaches too. Moreover these new approaches are valid for any languages pair and are quite flexible since the feature vector may contain more, less or different features, such as a lexical matching feature and Hanzi characters in Japanese-Chinese texts, than the ones used in the current research. (c) 2007 Elsevier Ltd. All rights reserved.
SN 0885-2308
EI 1095-8363
PD OCT
PY 2007
VL 21
IS 4
BP 594
EP 608
DI 10.1016/j.csl.2007.01.002
UT WOS:000247462200002
ER

PT J
AU Friedmann, B
AF Friedmann, Birgit
TI Muscular adaptations to different strength training methods
SO DEUTSCHE ZEITSCHRIFT FUR SPORTMEDIZIN
AB Strength can be effectively trained by combined concentric/eccentric dynamic muscle actions in single- or multiple joint exercises performed with free weight or using training machines. For strength development, a variation of training load, repetition numbers and velocity as well as rest intervals is recommended. After onset of strength training, there is a rapid initial increase in strength due to neural adaptations. Adaptive changes of the exercised skeletal muscles, such as hypertrophy and an increase in the percentage area of fast type IIA-fibres, only take place following at least several weeks of training. These morphological muscular adaptations are caused by mechanical and/or metabolic stress of the exercised skeletal muscles and by hormonal regulation which, on the molecular level, lead to alterations of translation and transcription as well as to proliferation and incorporation of satellite cells. The results of some recently-published controlled studies suggest that two newly-developed strength training regimens might increase and modify neural and morphological adaptations. Computer-guided strength training with eccentric overload (desmodromic training) seems to increase the recruitment of fast muscle fibres during strength training, leading to distinct adaptations towards a faster muscle phenotype. Application of vibration during strength training apparently increases the neuromuscular adaptations and thereby causes acute strength and power enhancement and increased training effects. However, there still is a lack of controlled studies for desmodromic training as well as for vibration training, and additional investigations are needed before recommendations can be made for these training methods.
SN 0344-5925
PD JAN
PY 2007
VL 58
IS 1
BP 12
EP 18
UT WOS:000243781500001
ER

PT J
AU Li, J
   Zhang, LC
   He, SD
   Guo, F
   Zou, Q
AF Li, Jing
   Zhang, Lichao
   He, Shida
   Guo, Fei
   Zou, Quan
TI SubLocEP: a novel ensemble predictor of subcellular localization of
   eukaryotic mRNA based on machine learning
SO BRIEFINGS IN BIOINFORMATICS
AB Motivation: mRNA location corresponds to the location of protein translation and contributes to precise spatial and temporal management of the protein function. However, current assignment of subcellular localization of eukaryotic mRNA reveals important limitations: (1) turning multiple classifications into multiple dichotomies makes the training process tedious; (2) the majority of the models trained by classical algorithm are based on the extraction of single sequence information; (3) the existing state-of-the-art models have not reached an ideal level in terms of prediction and generalization ability. To achieve better assignment of subcellular localization of eukaryotic mRNA, a better and more comprehensive model must be developed.
   Results: In this paper, SubLocEP is proposed as a two-layer integrated prediction model for accurate prediction of the location of sequence samples. Unlike the existing models based on limited features, SubLocEP comprehensively considers additional feature attributes and is combined with LightGBM to generated single feature classifiers. The initial integration model (single-layer model) is generated according to the categories of a feature. Subsequently, two single-layer integration models are weighted (sequence-based: physicochemical properties = 3:2) to produce the final two-layer model. The performance of SubLocEP on independent datasets is sufficient to indicate that SubLocEP is an accurate and stable prediction model with strong generalization ability. Additionally, an online tool has been developed that contains experimental data and can maximize the user convenience for estimation of subcellular localization of eukaryotic mRNA.
OI Zou, Quan/0000-0001-6406-1142
SN 1467-5463
EI 1477-4054
PD SEP
PY 2021
VL 22
IS 5
AR bbaa401
DI 10.1093/bib/bbaa401
EA JAN 2021
UT WOS:000709461800017
PM 33388743
ER

PT C
AU Kumar, SD
   Reshma, EU
   Sunitha, C
   Ganesh, A
AF Kumar, Sreedhi Deleep
   Reshma, E. U.
   Sunitha, C.
   Ganesh, Amal
BE Hemanth, J
   Fernando, X
   Lafata, P
   Baig, Z
TI Semantic Representation of Malayalam Text Documents in Cricket Domain
   Using WordNet
SO INTERNATIONAL CONFERENCE ON INTELLIGENT DATA COMMUNICATION TECHNOLOGIES
   AND INTERNET OF THINGS, ICICI 2018
SE Lecture Notes on Data Engineering and Communications Technologies
CT International Conference on Intelligent Data Communication Technologies
   and Internet of Things (ICICI)
CY AUG 07-08, 2018
CL Coimbatore, INDIA
AB Semantic representation is an abstract language for representing the meaning of text. It is used for representing the sentences semantically which can be employed in various applications such as Question Answering System, Information Extraction, Summarization, Machine translation etc. Various methods are employed to represent text document. But only limited works are done in Malayalam language. A specific domain is chosen (Cricket Domain) so as to obtain better results in semantic representation. A lexical database in Malayalam (WordNet), will be used as a resource for obtaining the required information. WordNet is a hierarchical information base in any language. In this project, semantic representation is extracted from a single Malayalam text document. It generates an abstractive representation of the given input. Semantic representation can be effectively extracted after going through different stages. Tokenization involves separation of words from sentences as tokens whereas POS Tagging deals with tagging of these tokens as corresponding Nouns, Verbs, Adjectives etc. The so got tagged tokens will undergo Morphological analysis. Morphological analysis is the process of finding the stem word for each of the generated tokens. After the analysis, the details regarding the stem words are obtained by searching in the WordNet. Next, the Semantic triplets (Subject, Object, Predicate) are extracted from the sentence. These triplets will be helpful for obtaining the semantic representation. For representation, the verb is taken as the root element. The aim of this project is semantic representation of Malayalam text documents pertaining to cricket domain using the database WordNet.
OI C, Dr. Sunitha/0000-0001-7759-2444; Ganesh, Amal/0000-0002-6611-7565
SN 2367-4512
BN 978-3-030-03146-6; 978-3-030-03145-9
PY 2019
VL 26
BP 439
EP 447
DI 10.1007/978-3-030-03146-6_49
UT WOS:000674929900049
ER

PT J
AU Murray, KE
   Nibert, ML
AF Murray, Kenneth E.
   Nibert, Max L.
TI Guanidine hydrochloride inhibits mammalian orthoreovirus growth by
   reversibly blocking the synthesis of double-stranded RNA
SO JOURNAL OF VIROLOGY
AB Millimolar concentrations of guanidine hydrochloride (GuHCl) are known to inhibit the replication of many plant and animal viruses having positive-sense RNA genomes. For example, GuHCl reversibly interacts with the nucleotide-binding region of poliovirus protein 2C(ATPase), resulting in a specific inhibition of viral negative-sense RNA synthesis. The use of GuHCl thereby allows for the spatiotemporal separation of poliovirus gene expression and RNA replication and provides a powerful tool to synchronize the initiation of negative-sense RNA synthesis during in vitro replication reactions. In the present study, we examined the effect of GuHCl on mammalian orthoreovirus (MRV), a double-stranded RNA (dsRNA) virus from the family Reoviridae. MRV growth in murine L929 cells was reversibly inhibited by 15 mM GuHCl. Furthermore, 15 mM GuHCl provided specific inhibition of viral dsRNA synthesis while sparing both positive-sense RNA synthesis and viral mRNA translation. By using GuHCl to provide temporal separation of MRV gene expression and genome replication, we obtained evidence that MRV primary transcripts support sufficient protein synthesis to assemble morphologically normal viral factories containing functional replicase complexes. In addition, the coordinated use of GuHCl and cycloheximide allowed us to demonstrate that MRV dsRNA synthesis can occur in the absence of ongoing protein synthesis, although to only a limited extent. Future studies utilizing the reversible inhibition of MRV dsRNA synthesis will focus on elucidating the target of GuHCl, as well as the components of the MRV replicase complexes.
SN 0022-538X
PD MAY
PY 2007
VL 81
IS 9
BP 4572
EP 4584
DI 10.1128/JVI.02106-06
UT WOS:000246501900021
PM 17301147
ER

PT J
AU Abbas, S
   Khan, MU
   Lee, SUJ
   Abbas, A
   Bashir, AK
AF Abbas, Shanza
   Khan, Muhammad Umair
   Lee, Scott Uk-Jin
   Abbas, Asad
   Bashir, Ali Kashif
TI A Review of NLIDB With Deep Learning: Findings, Challenges and Open
   Issues
SO IEEE ACCESS
AB Relational databases are storage for a massive amount of data. Knowledge of structured query language is a prior requirement to access that data. That is not possible for all non-technical personals, leading to the need for a system that translates text to SQL query itself rather than the user. Text to SQL task is also crucial because of its economic and industrial value. Natural Language Interface to Database (NLIDB) is the system that supports the text-to-SQL task. Developing the NLIDB system is a long-standing problem. Previously they were built based on domain-specific ontologies via pipelining methods. Recently a rising variety of Deep learning ideas and techniques brought this area to the attention again. Now end to end Deep learning models is being proposed for the task. Some publicly available datasets are being used for experimentation of the contributions, making the comparison process convenient. In this paper, we review the current work, summarize the research trends, and highlight challenging issues of NLIDB with Deep learning models. We discussed the importance of datasets, prediction model approaches and open challenges. In addition, methods and techniques are also summarized, along with their influence on the overall structure and performance of NLIDB systems. This paper can help future researchers start having prior knowledge of findings and challenges in NLIDB with Deep learning approaches.
RI Lee, Scott Uk-Jin/G-4359-2017
OI Lee, Scott Uk-Jin/0000-0002-8457-3097; Bashir, Ali
   Kashif/0000-0003-2601-9327
SN 2169-3536
PY 2022
VL 10
BP 14927
EP 14945
DI 10.1109/ACCESS.2022.3147586
UT WOS:000754221100001
ER

PT J
AU Boulos, LJ
   Mendes, A
   Delmas, A
   Kaadoud, IC
AF Boulos, Laura Joy
   Mendes, Alexandre
   Delmas, Alexandra
   Kaadoud, Ikram Chraibi
TI An Iterative and Collaborative End-to-End Methodology Applied to Digital
   Mental Health
SO FRONTIERS IN PSYCHIATRY
AB Artificial intelligence (AI) algorithms together with advances in data storage have recently made it possible to better characterize, predict, prevent, and treat a range of psychiatric illnesses. Amid the rapidly growing number of biological devices and the exponential accumulation of data in the mental health sector, the upcoming years are facing a need to homogenize research and development processes in academia as well as in the private sector and to centralize data into federalizing platforms. This has become even more important in light of the current global pandemic. Here, we propose an end-to-end methodology that optimizes and homogenizes digital research processes. Each step of the process is elaborated from project conception to knowledge extraction, with a focus on data analysis. The methodology is based on iterative processes, thus allowing an adaptation to the rate at which digital technologies evolve. The methodology also advocates for interdisciplinary (from mathematics to psychology) and intersectoral (from academia to the industry) collaborations to merge the gap between fundamental and applied research. We also pinpoint the ethical challenges and technical and human biases (from data recorded to the end user) associated with digital mental health. In conclusion, our work provides guidelines for upcoming digital mental health studies, which will accompany the translation of fundamental mental health research to digital technologies.
OI Chraibi Kaadoud, Ikram/0000-0001-8393-1262
SN 1664-0640
PD SEP 23
PY 2021
VL 12
AR 574440
DI 10.3389/fpsyt.2021.574440
UT WOS:000705152500001
PM 34630171
ER

PT J
AU Masmoudi, A
   Aloulou, C
   Abdellahi, AGS
   Belguith, LH
AF Masmoudi, Abir
   Aloulou, Chafik
   Abdellahi, Abdel Ghader Sidi
   Belguith, Lamia Hadrich
TI Automatic diacritization of Tunisian dialect text using SMT model
SO INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY
AB Unlike other tongues, Arabic language is characterized by its written form which is essentially consonant and may not have short vowels. One of the major functions of short vowels is to determine and facilitate the meaning of words or sentences. However, MSA texts are generally written without vowels. This fact gives rise to a great deal of morphological, semantic, and syntactic ambiguities. Thus, this ambiguity problem is not only associated with Modern Standard Arabic (MSA) but also related to Arabic dialects in general and Tunisian Dialect (TD) in particular. Compared to MSA, TD suffers from the unavailability of basic tools and linguistic resources, like sufficient amount of corpora, multilingual dictionaries, morphological and syntactic analyzers of these resources makes the processing of this language a great challenge (Masmoudi et al., 2020). Despite the numerous efforts currently underway, still some shortages persist in this field. Hence, we tried to challenge this lack by presenting our work that investigates the automatic diacritization of TD texts. In this respect, we regard the diacritization problem as a simplified phrase-based SMT (Statistical Machine Translation) task. The source language is the undiacritic text while the target language is the diacritic text. We initially go deeper into the details of TD corpus creation. This corpus is finally approved and used to build a diacritic restoration system for the TD. It is called TDTACHKIL and it can achieve a Word Error Rate (WER) of 16.7% and Diacritic Error Rate (DER) of 8.89%.
RI Belguith, Lamia Hadrich/GWU-9641-2022
OI Belguith, Lamia Hadrich/0000-0002-4868-657X
SN 1381-2416
EI 1572-8110
PD MAR
PY 2022
VL 25
IS 1
SI SI
BP 89
EP 104
DI 10.1007/s10772-021-09864-6
EA AUG 2021
UT WOS:000682808500001
ER

PT C
AU Biswas, K
   Kumar, S
   Banerjee, S
   Pandey, AK
AF Biswas, Koushik
   Kumar, Sandeep
   Banerjee, Shilpak
   Pandey, Ashish Kumar
BE Farkas, I
   Masulli, P
   Otte, S
   Wermter, S
TI EIS - Efficient and Trainable Activation Functions for Better Accuracy
   and Performance
SO ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING - ICANN 2021, PT II
SE Lecture Notes in Computer Science
CT 30th International Conference on Artificial Neural Networks (ICANN)
CY SEP 14-17, 2021
CL ELECTR NETWORK
AB Activation functions play a pivotal role in function learning using neural networks. The non-linearity in a neural network is achieved by repeated use of the activation function. Over the years, numerous activation functions have been proposed to improve neural network performance in several deep learning tasks. Basic functions like ReLU, Sigmoid, Tanh, or Softplus have been favorites among the deep learning community because of their simplicity. In recent years, several novel activation functions arising from these basic functions have been proposed, which have improved accuracy in some challenging datasets. We propose three activation functions with trainable parameters, namely EIS-1, EIS-2, and EIS-3. We show these three activation functions outperform widely used activation functions on some well-known datasets and models. For example, EIS-1, EIS-2, and EIS-3 beats ReLU by 5.55%, 5.32%, and 5.60% on ResNet V2 34, 5.27%, 5.24%, and 5.76% on VGG 16, 2.02%, 1.93%, and 2.01% on Wide-Res-Net 28-10, 2.30%, 2.11%, and 2.50% on Shufflenet V2 in CIFAR100 dataset while 1.40%, 1.27%, and 1.45% on ResNet V2 34, 1.21%, 1.09%, and 1.17% on VGG 16, 1.10%, 1.04%, and 1.16% on Wide-Res-Net 28-10, 1.85%, 1.60%, and 1.67% on Shufflenet V2 in CIFAR10 dataset respectively. The proposed functions also perform better than traditional activation functions like ReLU, Leaky ReLU, Swish, etc. in Object detection, Semantic segmentation, and Machine Translation problems.
OI Banerjee, Shilpak/0000-0003-1036-9576; Biswas,
   Koushik/0000-0002-9818-8966; Kumar, Sandeep/0000-0002-5464-929X
SN 0302-9743
EI 1611-3349
BN 978-3-030-86340-1; 978-3-030-86339-5
PY 2021
VL 12892
BP 260
EP 272
DI 10.1007/978-3-030-86340-1_21
UT WOS:000711922300021
ER

PT C
AU Li, SF
   Liu, H
   Dong, T
   Zhao, BZH
   Xue, MH
   Zhu, HJ
   Lu, JL
AF Li, Shaofeng
   Liu, Hui
   Dong, Tian
   Zhao, Benjamin Zi Hao
   Xue, Minhui
   Zhu, Haojin
   Lu, Jialiang
GP ASSOC COMP MACHINERY
TI Hidden Backdoors in Human-Centric Language Models
SO CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND
   COMMUNICATIONS SECURITY
CT ACM SIGSAC Conference on Computer and Communications Security (ACM CCS)
CY NOV 15-19, 2021
CL ELECTR NETWORK
SP ACM SIGSAC, Assoc Comp Machinery
AB Natural language processing (NLP) systems have been proven to be vulnerable to backdoor attacks, whereby hidden features (backdoors) are trained into a language model and may only be activated by specific inputs (called triggers), to trick the model into producing unexpected behaviors. In this paper, we create covert and natural triggers for textual backdoor attacks, hidden backdoors, where triggers can fool both modern language models and human inspection. We deploy our hidden backdoors through two state-of-the-art trigger embedding methods. The first approach via homograph replacement, embeds the trigger into deep neural networks through the visual spoofing of lookalike character replacement. The second approach uses subtle differences between text generated by language models and real natural text to produce trigger sentences with correct grammar and highfluency. We demonstrate that the proposed hidden backdoors can be effective across three downstream security-critical NLP tasks, representative of modern human-centric NLP systems, including toxic comment detection, neural machine translation (NMT), and question answering (QA). Our two hidden backdoor attacks can achieve an Attack Success Rate (ASR) of at least 97% with an injection rate of only 3% in toxic comment detection, 95.1% ASR in NMT with less than 0.5% injected data, and finally 91.12% ASR against QA updated with only 27 poisoning data samples on a model previously trained with 92,024 samples (0.029%). We are able to demonstrate the adversary's high success rate of attacks, while maintaining functionality for regular users, with triggers inconspicuous by the human administrators.
BN 978-1-4503-8454-4
PY 2021
BP 3123
EP 3140
DI 10.1145/3460120.3484576
UT WOS:000768478303010
ER

PT J
AU Tang, YB
   Anandasabapathy, S
   Richards-Kortum, R
AF Tang, Yubo
   Anandasabapathy, Sharmila
   Richards-Kortum, Rebecca
TI Advances in optical gastrointestinal endoscopy: a technical review
SO MOLECULAR ONCOLOGY
AB Optical endoscopy is the primary diagnostic and therapeutic tool for management of gastrointestinal (GI) malignancies. Most GI neoplasms arise from precancerous lesions; thus, technical innovations to improve detection and diagnosis of precancerous lesions and early cancers play a pivotal role in improving outcomes. Over the last few decades, the field of GI endoscopy has witnessed enormous and focused efforts to develop and translate accurate, user-friendly, and minimally invasive optical imaging modalities. From a technical point of view, a wide range of novel optical techniques is now available to probe different aspects of light-tissue interaction at macroscopic and microscopic scales, complementing white light endoscopy. Most of these new modalities have been successfully validated and translated to routine clinical practice. Herein, we provide a technical review of the current status of existing and promising new optical endoscopic imaging technologies for GI cancer screening and surveillance. We summarize the underlying principles of light-tissue interaction, the imaging performance at different scales, and highlight what is known about clinical applicability and effectiveness. Furthermore, we discuss recent discovery and translation of novel molecular probes that have shown promise to augment endoscopists' ability to diagnose GI lesions with high specificity. We also review and discuss the role and potential clinical integration of artificial intelligence-based algorithms to provide decision support in real time. Finally, we provide perspectives on future technology development and its potential to transform endoscopic GI cancer detection and diagnosis.
OI Tang, Yubo/0000-0003-2568-8940
SN 1574-7891
EI 1878-0261
PD OCT
PY 2021
VL 15
IS 10
BP 2580
EP 2599
DI 10.1002/1878-0261.12792
EA SEP 2020
UT WOS:000570881500001
PM 32915503
ER

PT J
AU van Wijk, RC
   Alsoud, RA
   Lennernas, H
   Simonsson, USH
AF van Wijk, Rob C.
   Alsoud, Rami Ayoun
   Lennernas, Hans
   Simonsson, Ulrika S. H.
TI Model-Informed Drug Discovery and Development Strategy for the Rapid
   Development of Anti-Tuberculosis Drug Combinations
SO APPLIED SCIENCES-BASEL
AB The increasing emergence of drug-resistant tuberculosis requires new effective and safe drug regimens. However, drug discovery and development are challenging, lengthy and costly. The framework of model-informed drug discovery and development (MID3) is proposed to be applied throughout the preclinical to clinical phases to provide an informative prediction of drug exposure and efficacy in humans in order to select novel anti-tuberculosis drug combinations. The MID3 includes pharmacokinetic-pharmacodynamic and quantitative systems pharmacology models, machine learning and artificial intelligence, which integrates all the available knowledge related to disease and the compounds. A translational in vitro-in vivo link throughout modeling and simulation is crucial to optimize the selection of regimens with the highest probability of receiving approval from regulatory authorities. In vitro-in vivo correlation (IVIVC) and physiologically-based pharmacokinetic modeling provide powerful tools to predict pharmacokinetic drug-drug interactions based on preclinical information. Mechanistic or semi-mechanistic pharmacokinetic-pharmacodynamic models have been successfully applied to predict the clinical exposure-response profile for anti-tuberculosis drugs using preclinical data. Potential pharmacodynamic drug-drug interactions can be predicted from in vitro data through IVIVC and pharmacokinetic-pharmacodynamic modeling accounting for translational factors. It is essential for academic and industrial drug developers to collaborate across disciplines to realize the huge potential of MID3.
RI van Wijk, Rob/AAS-9679-2020; Simonsson, Ulrika/D-6024-2018
OI van Wijk, Rob/0000-0001-7247-1360; Simonsson,
   Ulrika/0000-0002-3424-9686; Lennernas, Hans/0000-0002-1578-5184
EI 2076-3417
PD APR
PY 2020
VL 10
IS 7
AR 2376
DI 10.3390/app10072376
UT WOS:000533356200175
ER

PT C
AU Nair, AA
   Tran, TD
   Reiter, A
   Bell, MAL
AF Nair, Arun Asokan
   Tran, Trac D.
   Reiter, Austin
   Bell, Muyinatu A. Lediju
GP IEEE
TI A Generative Adversarial Neural Network for Beamforming Ultrasound
   Images
SO 2019 53RD ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS)
CT 53rd Annual Conference on Information Sciences and Systems (CISS)
CY MAR 20-22, 2019
CL Baltimore, MD
AB Plane wave ultrasound imaging is an ideal approach to achieve maximum real-time frame rates. However, multiple plane wave insonifications at different angles are often combined to improve image quality, reducing the throughput of the system. We are exploring deep learning-based ultrasound image formation methods as an alternative to this beamforming process by extracting critical information directly from raw radio-frequency channel data from a single plane wave insonification prior to the application of receive time delays. In this paper, we investigate a Generative Adversarial Network (GAN) architecture for the proposed task. This network was trained with over 50,000 Field-II simulations, each containing a single cyst in tissue insonified by a single plane wave. The GAN is trained to produce two outputs - a Deep Neural Network (DNN) B-mode image trained to match a Delay-and-Sum (DAS) beamformed B-mode image and a DNN segmentation trained to match the true segmentation of the cyst from surrounding tissue. We systematically investigate the benefits of feature sharing and discriminative loss during GAN training. Our overall best performing network architecture (with feature sharing and discriminative loss) obtained a PSNR score of 29:38 dB with the simulated test set and 14:86 dB with a tissue-mimicking phantom. The DSC scores were 0:908 and 0:79 for the simulated and phantom data, respectively. The successful translation of the feature representations learned by the GAN to phantom data demonstrates the promise that deep learning holds as an alternative to the traditional ultrasound information extraction pipeline.
BN 978-1-7281-1151-3
PY 2019
UT WOS:000493551600025
ER

PT J
AU Bishop, W
   Chestek, CC
   Gilja, V
   Nuyujukian, P
   Foster, JD
   Ryu, SI
   Shenoy, KV
   Yu, BM
AF Bishop, William
   Chestek, Cynthia C.
   Gilja, Vikash
   Nuyujukian, Paul
   Foster, Justin D.
   Ryu, Stephen I.
   Shenoy, Krishna V.
   Yu, Byron M.
TI Self-recalibrating classifiers for intracortical brain-computer
   interfaces
SO JOURNAL OF NEURAL ENGINEERING
AB Objective. Intracortical brain-computer interface (BCI) decoders are typically retrained daily to maintain stable performance. Self-recalibrating decoders aim to remove the burden this may present in the clinic by training themselves autonomously during normal use but have only been developed for continuous control. Here we address the problem for discrete decoding (classifiers). Approach. We recorded threshold crossings from 96-electrode arrays implanted in the motor cortex of two rhesus macaques performing center-out reaches in 7 directions over 41 and 36 separate days spanning 48 and 58 days in total for offline analysis. Main results. We show that for the purposes of developing a self-recalibrating classifier, tuning parameters can be considered as fixed within days and that parameters on the same electrode move up and down together between days. Further, drift is constrained across time, which is reflected in the performance of a standard classifier which does not progressively worsen if it is not retrained daily, though overall performance is reduced by more than 10% compared to a daily retrained classifier. Two novel self-recalibrating classifiers produce a similar to 15% increase in classification accuracy over that achieved by the non-retrained classifier to nearly recover the performance of the daily retrained classifier. Significance. We believe that the development of classifiers that require no daily retraining will accelerate the clinical translation of BCI systems. Future work should test these results in a closed-loop setting.
OI Nuyujukian, Paul/0000-0001-7778-5473
SN 1741-2560
EI 1741-2552
PD APR
PY 2014
VL 11
IS 2
AR 026001
DI 10.1088/1741-2560/11/2/026001
UT WOS:000333419400006
PM 24503597
ER

PT J
AU Chen, AN
   Pan, TR
AF Chen, Arnold
   Pan, Tingrui
TI Three-dimensional fit-to-flow microfluidic assembly
SO BIOMICROFLUIDICS
AB Three-dimensional microfluidics holds great promise for large-scale integration of versatile, digitalized, and multitasking fluidic manipulations for biological and clinical applications. Successful translation of microfluidic toolsets to these purposes faces persistent technical challenges, such as reliable system-level packaging, device assembly and alignment, and world-to-chip interface. In this paper, we extended our previously established fit-to-flow (F2F) world-to-chip interconnection scheme to a complete system-level assembly strategy that addresses the three-dimensional microfluidic integration on demand. The modular F2F assembly consists of an interfacial chip, pluggable alignment modules, and multiple monolithic layers of microfluidic channels, through which convoluted three-dimensional microfluidic networks can be easily assembled and readily sealed with the capability of reconfigurable fluid flow. The monolithic laser-micromachining process simplifies and standardizes the fabrication of single-layer pluggable polymeric modules, which can be mass-produced as the renowned Lego (R) building blocks. In addition, interlocking features are implemented between the plug-and-play microfluidic chips and the complementary alignment modules through the F2F assembly, resulting in facile and secure alignment with average misalignment of 45 mu m. Importantly, the 3D multilayer microfluidic assembly has a comparable sealing performance as the conventional single-layer devices, providing an average leakage pressure of 38.47 kPa. The modular reconfigurability of the system-level reversible packaging concept has been demonstrated by re-routing microfluidic flows through interchangeable modular microchannel layers. (C) 2011 American Institute of Physics. [doi: 10.1063/1.3670368]
EI 1932-1058
PD DEC
PY 2011
VL 5
IS 4
AR 046505
DI 10.1063/1.3670368
UT WOS:000298638700026
PM 22276088
ER

PT J
AU Perron, MP
   Provost, P
AF Perron, Marjorie P.
   Provost, Patrick
TI Protein interactions and complexes in human microRNA biogenesis and
   function
SO FRONTIERS IN BIOSCIENCE-LANDMARK
AB Encoded in the genome of most eukaryotes, microRNAs (miRNAs) have been proposed to regulate specifically up to 90% of human genes through a process known as miRNA-guided RNA silencing. The aim of this review is to present this process as the integration of a succession of specialized molecular machines exerting well defined functions. The nuclear microprocessor complex initially recognizes and processes its primary miRNA substrate into a miRNA precursor (pre-miRNA). This structure is then exported to the cytoplasm by the Exportin-5 complex where it is presented to the pre-miRNA processing complex. Following pre-miRNA conversion into a miRNA: miRNA* duplex, this complex is assembled into a miRNA-containing ribonucleoprotein (miRNP) complex, after which the miRNA strand is selected. The degree of complementarity of the miRNA for its messenger RNA (mRNA) target guides the recruitment of the miRNP complex. Initially repressing its translation, the miRNP-silenced mRNA is directed to the P-bodies, where the mRNA is either released from its inhibition upon a cellular signal and/or actively degraded. The potency and specificity of miRNA biogenesis and function rely on the distinct protein center dot protein, protein center dot RNA and RNA: RNA interactions found in different complexes, each of which fulfill a specific function in a well orchestrated process.
RI Provost, Patrick/G-2786-2010
OI Provost, Patrick/0000-0002-6099-6562
SN 1093-9946
EI 1093-4715
PD JAN 1
PY 2008
VL 13
BP 2537
EP 2547
DI 10.2741/2865
UT WOS:000255775700209
PM 17981733
ER

PT J
AU Barral, JM
   Bauer, CC
   Ortiz, I
   Epstein, HF
AF Barral, JM
   Bauer, CC
   Ortiz, I
   Epstein, HF
TI Unc-45 mutations in Caenorhabditis elegans implicate a CRO1/She4p-like
   domain in myosin assembly
SO JOURNAL OF CELL BIOLOGY
AB The Caenorhabditis elegans unc-45 locus has been proposed to encode a protein machine for myosin assembly. The UNC-45 protein is predicted to contain an NH2-terminal domain with three tetratricopeptide repeat motifs, a unique central region, and a COOH-terminal domain homologous to CRO1 and She4p. CRO1 and She4p are fungal proteins required for the segregation of other molecules in budding, endocytosis, and septation. Three mutations that lead to temperature-sensitive (ts) alleles have been localized to conserved residues within the CRO1/She4p-like domain, and two lethal alleles were found to result from stop codon mutations in the central region that would prevent translation of the COOH-terminal domain. Electron microscopy shows that thick filament accumulation in vivo is decreased by similar to 50% in the CB286 ts mutant grown at the restrictive temperature. The thick filaments that assemble have abnormal structure. Immunofluorescence and immunoelectron microscopy show that myosins A and B are scrambled, in contrast to their assembly into distinct regions at the permissive temperature and in wild type. This abnormal structure correlates with the high degree of instability of the filaments in vitro as reflected by their extremely low yields and shortened lengths upon isolation. These results implicate the UNC-45 CRO1/She4p-like region in the assembly of myosin isoforms in C. elegans and suggest a possible common mechanism for the function of this UCS (UNC-45/CRO1/She4p) protein family.
SN 0021-9525
PD NOV 30
PY 1998
VL 143
IS 5
BP 1215
EP 1225
DI 10.1083/jcb.143.5.1215
UT WOS:000077398300007
PM 9832550
ER

PT J
AU Zhang, Q
   Deng, LF
AF Zhang, Qi
   Deng, Linfeng
TI An Intelligent Fault Diagnosis Method of Rolling Bearings Based on
   Short-Time Fourier Transform and Convolutional Neural Network
SO JOURNAL OF FAILURE ANALYSIS AND PREVENTION
AB The rolling bearing is the key component of rotating machinery, and fault diagnosis for rolling bearings can ensure the safe operation of rotating machinery. Fault diagnosis technology based on deep learning has been largely studied for bearing fault diagnosis. However, for the deep learning model based on convolutional neural network, there are some intrinsic problems of producing inconspicuous features and useful feature information loss in the process of feature extraction of the raw fault vibration signals. In this work, an intelligent fault diagnosis method of rolling bearings based on short-time Fourier transform and convolutional neural network (STFT-CNN) is proposed. The one-dimensional vibration signals are converted into time-frequency images by STFT. Then, time-frequency images are inputted into STFT-CNN model for fault feature learning and fault identification. For the STFT of the vibration signals, the window type, window width and translation overlap width of the five typical window functions are studied and optimal one is obtained. And in the STFT-CNN model, the stacked double convolutional layers are adopted to improve the nonlinear expression capability of the model. To verify the effectiveness of the proposed method, experiments are carried out on the Case Western Reserve University (CWRU) and the Machine Failure Prevention Technology (MFPT) Society bearing datasets. The results show that the proposed method outperforms other comparative methods and reaches the identification accuracy of 100% and 99.96% for CWRU and MFPT, respectively.
SN 1547-7029
EI 1864-1245
DI 10.1007/s11668-023-01616-9
EA FEB 2023
UT WOS:000928896900001
ER

PT J
AU Yeung, M
   Rundo, L
   Nan, Y
   Sala, E
   Schonlieb, CB
   Yang, G
AF Yeung, Michael
   Rundo, Leonardo
   Nan, Yang
   Sala, Evis
   Schonlieb, Carola-Bibiane
   Yang, Guang
TI Calibrating the Dice Loss to Handle Neural Network Overconfidence for
   Biomedical Image Segmentation
SO JOURNAL OF DIGITAL IMAGING
AB The Dice similarity coefficient (DSC) is both a widely used metric and loss function for biomedical image segmentation due to its robustness to class imbalance. However, it is well known that the DSC loss is poorly calibrated, resulting in overconfident predictions that cannot be usefully interpreted in biomedical and clinical practice. Performance is often the only metric used to evaluate segmentations produced by deep neural networks, and calibration is often neglected. However, calibration is important for translation into biomedical and clinical practice, providing crucial contextual information to model predictions for interpretation by scientists and clinicians. In this study, we provide a simple yet effective extension of the DSC loss, named the DSC++ loss, that selectively modulates the penalty associated with overconfident, incorrect predictions. As a standalone loss function, the DSC++ loss achieves significantly improved calibration over the conventional DSC loss across six well-validated open-source biomedical imaging datasets, including both 2D binary and 3D multi-class segmentation tasks. Similarly, we observe significantly improved calibration when integrating the DSC++ loss into four DSC-based loss functions. Finally, we use softmax thresholding to illustrate that well calibrated outputs enable tailoring of recall-precision bias, which is an important post-processing technique to adapt the model predictions to suit the biomedical or clinical task. The DSC++ loss overcomes the major limitation of the DSC loss, providing a suitable loss function for training deep learning segmentation models for use in biomedical and clinical practice. Source code is available at .
OI Rundo, Leonardo/0000-0003-3341-5483
SN 0897-1889
EI 1618-727X
PD APR
PY 2023
VL 36
IS 2
BP 739
EP 752
DI 10.1007/s10278-022-00735-3
EA DEC 2022
UT WOS:000894744300002
PM 36474089
ER

PT J
AU Yang, HY
   Xiao, XM
   Huang, Q
   Zheng, GL
   Yi, WL
AF Yang Hongyun
   Xiao Xiaomei
   Huang Qiong
   Zheng Guoliang
   Yi Wenlong
TI Rice Pest Identification Based on Convolutional Neural Network and
   Transfer Learning
SO LASER & OPTOELECTRONICS PROGRESS
AB In order to realize rapid and accurate identification of rice pests, a rice pest identification method based on transfer learning and convolutional neural network was proposed in this paper. First, the images of rice pests were preprocessed. Preprocessing methods include translation, inversion, rotation, and scaling. According to the characteristics of the pests, the images were divided into six categories, namely, rice leaf roller, rice planthopper, rice plant thopper, rice leaf roller, rice plant thopper, rice plant thopper, rice locust, and rice weevil. Then, based on the transfer learning method, the weight parameters trained by the VGG16 model on the image data set ImageNet were transferred to the recognition of rice pests. The convolution layer and the pooling layer of VGG16 were used as the feature extraction layer. Meanwhile, the top layer was redesigned as the global average pooling layer and a softmax output layer. Part of the convolutional layer is frozen during training. The experimental results show that the average test accuracy of this model is 99. 05%, the training time is about 1/2 of the original model, and the model size is only 74. 2 MB. The F1 values of six insect pests, namely, rice grasshopper, rice planthopper, rice weevil, striped rice borer, the rice leaf roller, and yellow rice borer, were 0. 898, 0. 99, 0. 99, 0. 99, 1. 00, 0. 99, respectively. The experimental results show that this method has high identification efficiency, good identification effect and strong portability, which can provide a reference for the efficient and rapid diagnosis of crop pests.
SN 1006-4125
PD AUG
PY 2022
VL 59
IS 16
AR 1615004
DI 10.3788/LOP202259.1615004
UT WOS:000834824700032
ER

PT J
AU Khare, M
   Khare, A
AF Khare, Manish
   Khare, Ashish
TI Integration of complex wavelet transform and Zernike moment for
   multi-class classification
SO EVOLUTIONARY INTELLIGENCE
AB Multiclass object classification is a crucial problem in computer vision research and have different emerging applications such as video surveillance. The task of multiclass object classification has more challenges because of highly variable nature and real time processing requirement of data. For tackling the multiclass object classification task, several existing methods adopt one feature or combination of features to classify objects. In this work, we propose a new combination of features-based algorithm for object classification. In the combination, the two features: (1) Daubechies complex wavelet transform (DCxWT) and (2) Zernike moments (ZM) have been used. The shift-invariance and symmetry properties of DCxWT facilitate the object classification in the wavelet domain. Specifically, the shift-invariance property of DCxWT is effective for translated object representation whereas the symmetry property yields perfect reconstruction for retaining object boundaries (i.e., edges). Moreover, translation and rotation-invariance properties of ZM are especially beneficial for the representation of varying pose and orientation of the objects. For these reasons, the composite of the two features brings about significant synthesized benefits over each single feature and the other widely used features. The multi-class support vector machine classifier is used for classifying different objects. The proposed method has been tested on standard datasets as well as our own dataset prepared by authors of this paper. Experimental results demonstrated the significant outperformance of the proposed method through quantitative evaluations and also suggest that the proposed hybridization of features is preferable for the classification problem.
RI Khare, Manish/AAF-4582-2019
OI Khare, Manish/0000-0002-2296-2732
SN 1864-5909
EI 1864-5917
PD JUN
PY 2021
VL 14
IS 2
SI SI
BP 1151
EP 1162
DI 10.1007/s12065-021-00575-0
EA FEB 2021
UT WOS:000616995700002
ER

PT J
AU Hemalatha, M
   Rukmanidevi, S
AF Hemalatha, M.
   Rukmanidevi, S.
TI Real time prefix matching based IP lookup and update mechanism for
   efficient routing in networks
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
AB IPv6 is another form of the inter networking convention intended to address the inadequacies of the present standard, IPv4. The deliver space is restricted to just 32-bits in IPv4 though IPv6 has 128-bits deliver not withstanding versatility requirement and system layer security. The principle issue is that IPv4 and IPv6 are not good at directly. Along with comprising lines, plans and structures to one standard can't express with those meant for the other. The lookup issue of IPv6 change enables the clients to service their hosts to IPv6, and the system administrators to send IPv6 in switches, with next to no coordination between the two. In the meantime, it has to rely on address translation mechanisms which facilitate communication between IPv4/IPv6 networks since migration from IPv4 to IPv6 cannot take place all of a sudden. Various lookup problem change tools have been produced to address interoperability of IPv4 and IPv6 systems and frameworks. Be that as it may, none of the current devices address basic issues like the noninvasive movement of basic heritage IPv4-just frameworks to IPv6, and operation of IPv4-just frameworks on IPv6-just center systems. This work exhibits an answer for these IP lookup issues. This paper address the problem of IPv6 address lookup problem and present a routing algorithm for both IPv4 and IPv6 machines which uses address prefix matching algorithm. The proposed method improves the performance of address lookup and reduces the latency as well.
RI Dams, ruks/V-9152-2019
OI Dams, ruks/0000-0002-0153-6283; , Dr.M.Hemalatha/0000-0002-2071-0224
SN 1868-5137
EI 1868-5145
PD MAR
PY 2021
VL 12
IS 3
SI SI
BP 3669
EP 3678
DI 10.1007/s12652-019-01646-y
EA DEC 2019
UT WOS:000574442300002
ER

PT J
AU Hashmi, MA
   Mahmood, MA
   Mahmood, MI
AF Hashmi, Muhammad Ahmad
   Mahmood, Muhammad Asim
   Mahmood, Muhammad Ilyas
TI Analysis of Lecxico-Semantic Relations of Punjabi Shahmukhi Nouns: A
   Corpus Based Study
SO INTERNATIONAL JOURNAL OF ENGLISH LINGUISTICS
AB The current study is an effort in the development of Lecxico-semantic relations among Punjabi Shahmukhi nouns. Semantic relations are those nets, which are found among nouns on the bases of word meanings. Development of semantic nets is taken as a key part while developing WordNet of any language. The WordNet of Punjabi Shahmukhi is not developed yet. The digital exposure and progress of Punjabi Shahmukhi is very slow in comparison to other languages of the world. The present study explores the kind of semantic relations found among the nouns of Punjabi Shahmukhi WordNet organizes words on the basis of word meanings rather than word forms. WordNet of English includes four open class categories including; nouns, verbs, adverbs and adjectives, but present study is limited to the analysis of nouns. A corpus of 2 million words of Punjabi Shahmukhi was taken from different sources. Then, it was POS tagged and a list of 846 nouns was generated. Then, each noun was analyzed individually to develop its Lecxico-semantic relations including: synonymy, antonymy, meronyms, holonymy, hyponymy, hypernymy, singular, plural, masculine, feminine and HAS a part. The present research is significant and useful in the development of WordNet for Punjabi Shahmukhi With the development of WordNet, it will be possible to run digital applications in Punjabi Shahmukhi including: machine translation, information retrieval, querying archive and report generation to automatic speech recognition, data mining, read aloud, robotics and many more. On the other hand, WordNet will help to maintain an international status for Punjabi Shahmukhi.
RI Mahmood, Muhammad Ilyas/AAN-5556-2020
SN 1923-869X
EI 1923-8703
PY 2019
VL 9
IS 3
BP 357
EP 364
DI 10.5539/ijel.v9n3p357
UT WOS:000469984200033
ER

PT J
AU Yeh, JY
   Lin, JY
AF Yeh, Jen-Yuan
   Lin, Jung-Yi
TI LEARNING RANKING FUNCTIONS FOR INFORMATION RETRIEVAL USING LAYERED
   MULTI-POPULATION GENETIC PROGRAMMING
SO MALAYSIAN JOURNAL OF COMPUTER SCIENCE
AB Ranking plays a key role in many applications, such as document retrieval, recommendation, question answering, and machine translation. In practice, a ranking function (or model) is exploited to determine the rank-order relations between objects, with respect to a particular criterion. In this paper, a layered multi-population genetic programming based method, known as RankMGP, is proposed to learn ranking functions for document retrieval by incorporating various types of retrieval models into a singular one with high effectiveness. RankMGP represents a potential solution (i.e., a ranking function) as an individual in a population of genetic programming and aims to directly optimize information retrieval evaluation measures in the evolution process. Overall, RankMGP consists of a set of layers and a sequential workflow running through the layers. In one layer, multiple populations evolve independently to generate a set of the best individuals. When the evolution process is completed, a new training dataset is created using the best individuals and the input training set of the layer. Then, the populations in the next layer evolve with the new training dataset. In the final layer, the best individual is obtained as the output ranking function. The proposed method is evaluated using the LETOR datasets and is found to be superior to classical information retrieval models, such as Okapi BM25. It is also statistically competitive with the state-of-the-art methods, including Ranking SVM, ListNet, AdaRank and RankBoost.
SN 0127-9084
PY 2017
VL 30
IS 1
BP 27
EP 47
DI 10.22452/mjcs.vol30no1.3
UT WOS:000400007600003
ER

PT J
AU Peterson, SM
   Thompson, JA
   Ufkin, ML
   Sathyanarayana, P
   Liaw, L
   Congdon, CB
AF Peterson, Sarah M.
   Thompson, Jeffrey A.
   Ufkin, Melanie L.
   Sathyanarayana, Pradeep
   Liaw, Lucy
   Congdon, Clare Bates
TI Common features of microRNA target prediction tools
SO FRONTIERS IN GENETICS
AB The human genome encodes for over 1800 microRNAs (miRNAs), which are short non-coding RNA molecules that function to regulate gene expression post-transcriptionally. Due to the potential for one miRNA to target multiple gene transcripts, miRNAs are recognized as a major mechanism to regulate gene expression and mRNA translation. Computational prediction of miRNA targets is a critical initial step in identifying miRNA:mRNA target interactions for experimental validation. The available tools for miRNA target prediction encompass a range of different computational approaches, from the modeling of physical interactions to the incorporation of machine learning. This review provides an overview of the major computational approaches to miRNA target prediction. Our discussion highlights three tools for their ease of use, reliance on relatively updated versions of miRBase, and range of capabilities, and these are DIANA-microT-CDS, miRanda-mirSVR, and TargetScan. In comparison across all miRNA target prediction tools, four main aspects of the miRNA:mRNA target interaction emerge as common features on which most target prediction is based: seed match, conservation, free energy, and site accessibility. This review explains these features and identifies how they are incorporated into currently available target prediction tools. MiRNA target prediction is a dynamic field with increasing attention on development of new analysis tools. This review attempts to provide a comprehensive assessment of these tools in a manner that is accessible across disciplines. Understanding the basis of these prediction methodologies will aid in user selection of the appropriate tools and interpretation of the tool output
EI 1664-8021
PD FEB 18
PY 2014
VL 5
AR 23
DI 10.3389/fgene.2014.00023
UT WOS:000346986300001
PM 24600468
ER

PT C
AU Cai, HX
   Shao, Z
   Vaynberg, A
AF Cai, Hongxu
   Shao, Zhong
   Vaynberg, Alexander
GP ACM
TI Certified Self-Modifying Code
SO PLDI'07: PROCEEDINGS OF THE 2007 ACM SIGPLAN CONFERENCE ON PROGRAMMING
   LANGUAGE DESIGN AND IMPLEMENTATION
CT Conference on Programming Language Design and Implementation
CY JUN 10-13, 2007
CL San Diego, CA
SP ACM SIGPLAN
AB Self-modifying code (SMC), in this paper, broadly refers to any program that loads, generates, or mutates code at runtime. It is widely used in many of the world's critical software systems to support runtime code generation and optimization, dynamic loading and linking, OS boot loader, just-in-time compilation, binary translation, or dynamic code encryption and obfuscation. Unfortunately, SMC is also extremely difficult to reason about: existing formal verification techniques-including Hoare logic and type system-consistently assume that program code stored in memory is fixed and immutable; this severely limits their applicability and power.
   This paper presents a simple but novel Hoare-logic-like framework that supports modular verification of general von-Neumann machine code with runtime code manipulation. By dropping the assumption that code memory is fixed and immutable, we are forced to apply local reasoning and separation logic at the very beginning, and treat program code uniformly as regular data structure. We address the interaction between separation and code memory and show how to establish the frame rules for local reasoning even in the presence of SMC. Our framework is realistic, but designed to be highly generic, so that it can support assembly code under all modern CPUs (including both x86 and MIPS). Our system is expressive and fully mechanized. We prove its soundness in the Coq proof assistant and demonstrate its power by certifying a series of realistic examples and applications-all of which can directly run on the SPIM simulator or any stock x86 hardware.
OI Shao, Zhong/0000-0001-8184-7649
BN 978-1-59593-633-2
PY 2007
BP 66
EP 77
DI 10.1145/1250734.1250743
UT WOS:000266485500007
ER

PT J
AU Roux, P
   De Rosny, J
   Fink, M
   Rose, JH
AF Roux, P
   De Rosny, J
   Fink, M
   Rose, JH
TI Time-reversal mirrors and rough surfaces: Experiment
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
AB A novel acoustic time-reversal technique has been tested for determining the surface-height autocorrelation function and rms height of rough surfaces. A time-reversal mirror (TRM) was used to insonify periodically and "randomly" rough surfaces of otherwise flat samples immersed in water. The standard use of the TRM is as follows: transmit an initial planar pulse, record the signals at each array element, digitally time reverse each signal, and then retransmit the time-reversed signal. As expected from time-reversal symmetry, one approximately recovers the incident planar pulse after the reflection of the retransmitted wave. The new technique is a simple modification of this procedure. Namely, as before, we record and time reverse the initial reflection. However, we next translate the transducer a fixed distance parallel to the surface before retransmitting. For very small displacements, little change is observed in the TRM's signal. For larger and larger translations, the TRM's signal decorrelates, i.e., it less and less resembles the incident pulse. The signal's decorrelation as a function of displacement is directly related to the autocorrelation function of the rough surface-within the limits set by the system's point response function. The TRM was used both in reflection mode and in transmission mode. Samples consisted of "randomly" rough surfaces of metal and plastic plates, as well as metal plates machined to have periodically rough surfaces. Evidence is provided that the time-reversal mirror is sensitive to the surface-height autocorrelation and, in favorable cases, determines the autocorrelation function and rms height. (C) 1999 Acoustical Society of America. [S0001-4966(99)02207-9].
RI Fink, Mathias/M-9437-2016; Roux, Philippe/B-8538-2014
OI Fink, Mathias/0000-0002-8494-7562; Roux, Philippe/0000-0002-5639-8869
SN 0001-4966
PD AUG
PY 1999
VL 106
IS 2
BP 724
EP 732
DI 10.1121/1.427090
UT WOS:000081993700021
ER

PT J
AU Wu, J
   Mayer, AT
   Li, RJ
AF Wu, Jia
   Mayer, Aaron T.
   Li, Ruijiang
TI Integrated imaging and molecular analysis to decipher tumor
   microenvironment in the era of immunotherapy
SO SEMINARS IN CANCER BIOLOGY
AB Radiological imaging is an integral component of cancer care, including diagnosis, staging, and treatment response monitoring. It contains rich information about tumor phenotypes that are governed not only by cancer cellintrinsic biological processes but also by the tumor microenvironment, such as the composition and function of tumor-infiltrating immune cells. By analyzing the radiological scans using a quantitative radiomics approach, robust relations between specific imaging and molecular phenotypes can be established. Indeed, a number of studies have demonstrated the feasibility of radiogenomics for predicting intrinsic molecular subtypes and gene expression signatures in breast cancer based on MRI. In parallel, promising results have been shown for inferring the amount of tumor-infiltrating lymphocytes, a key factor for the efficacy of cancer immunotherapy, from standard-of-care radiological images. Compared with the biopsy-based approach, radiogenomics offers a unique avenue to profile the molecular makeup of the tumor and immune microenvironment as well as its evolution in a noninvasive and holistic manner through longitudinal imaging scans. Here, we provide a systematic review of the state of the art radiogenomics studies in the era of immunotherapy and discuss emerging paradigms and opportunities in AI and deep learning approaches. These technical advances are expected to transform the radiogenomics field, leading to the discovery of reliable imaging biomarkers. This will pave the way for their clinical translation to guide precision cancer therapy.
OI Li, Ruijiang/0000-0002-0232-5998; Wu, Jia/0000-0001-8392-8338
SN 1044-579X
EI 1096-3650
PD SEP
PY 2022
VL 84
SI SI
BP 310
EP 328
DI 10.1016/j.semcancer.2020.12.005
UT WOS:000830066100011
PM 33290844
ER

PT C
AU Jacobs, AZ
   Blodgett, SL
   Barocas, S
   Daume, H
   Wallach, H
AF Jacobs, Abigail Z.
   Blodgett, Su Lin
   Barocas, Solon
   Daume, Hal, III
   Wallach, Hanna
GP Assoc Comp Machinery
TI The Meaning and Measurement of Bias: Lessons from Natural Language
   Processing
SO FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS,
   ACCOUNTABILITY, AND TRANSPARENCY
CT ACM Conference on Fairness, Accountability, and Transparency (FAT)
CY JAN 27-30, 2020
CL Barcelona, SPAIN
SP Assoc Comp Machinery
AB The recent interest in identifying and mitigating bias in computational systems has introduced a wide range of different-and occasionally incomparable-proposals for what constitutes bias in such systems. This tutorial introduces the language of measurement modeling from the quantitative social sciences as a framework for examining how social, organizational, and political values enter computational systems and unpacking the varied normative concerns operationalized in different techniques for measuring "bias." We showthat this framework helps to clarify the way unobservable theoretical constructs-such as "creditworthiness," "risk to society," or "tweet toxicity"-are turned into measurable quantities and how this process may introduce fairness-related harms. In particular, we demonstrate howto systematically assess the construct validity and reliability of these measurements to detect and characterize specific types of harms, which arise from mismatches between constructs and their operationalizations. We then take a critical look at existing approaches to examining "bias" in NLP models, ranging from work on embedding spaces to machine translation and hate speech detection. We show that measurement modeling can help uncover the implicit constructs that suchwork aims to capture when measuring "bias." In so doing, we illustrate the limits of current "debiasing" techniques, which have obscured the specific harms whose measurements they implicitly aim to reduce. By introducing the language of measurement modeling, we provide the FAT* community with a framework for making explicit and testing assumptions about unobservable theoretical constructs embedded in computational systems, thereby clarifying and uniting our understandings of fairness-related harms.
BN 978-1-4503-6936-7
PY 2020
BP 706
EP 706
DI 10.1145/3351095.3375671
UT WOS:000620151400095
ER

PT C
AU Johnson, Z
   Varon, A
   Blanco, J
   Rakvic, R
   Shey, J
   Ngo, H
   Brown, D
   Walker, O
AF Johnson, Zachary
   Varon, Alex
   Blanco, Justin
   Rakvic, Ryan
   Shey, James
   Hau Ngo
   Brown, Dane
   Walker, Owens
GP IEEE
TI Classifying Solid State Drive Firmware Via Side-Channel Current Draw
   Analysis
SO 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH
   IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG
   DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS
   (DASC/PICOM/DATACOM/CYBERSCITECH)
CT 16th IEEE Int Conf on Dependable, Autonom and Secure Comp/16th IEEE Int
   Conf on Pervas Intelligence and Comp/4th IEEE Int Conf on Big Data
   Intelligence and Comp/3rd IEEE Cyber Sci and Technol Congress
   (DASC/PiCom/DataCom/CyberSciTech)
CY AUG 12-15, 2018
CL Athens, GREECE
SP IEEE, IEEE Comp Soc, IEEE Tech Comm Scalable Comp, IEEE Syst Man & Cybernet, Tech Comm Cybermat, IEEE Computat Intelligence Soc, Smart World Tech Comm
AB Solid State Drives (SSDs) are a form of nonvolatile computer memory that have become ubiquitous in the information technology industry, replacing traditional magnetic Hard Disk Drives (HDDs) in numerous conventional systems and enabling new applications in the fields of embedded systems and data infrastructure. Compared to HDDs, modern SSDs have competitive storage density, faster read and write times, lower power consumption, and greater impact resistance. However, compared to HDD technology, SSDs have a more complex data storage architecture, which necessitates integrated firmware that interfaces between a host system and the hardware of the SSD, called the Flash Translation Layer (FTL). Because the host system interacts only with the FTL and not the SSD itself, the SSD can be viewed as a black box system, with known input and output but no information about its inner workings. Characterizing internal operations of an SSD is relevant for forensics, diagnostics, and security applications. One possible solution to this problem is to observe the side-channel current draw of the SSD as it operates. If firmware variants have distinguishable differences in their current signatures, a classifier can be trained to make class predictions. Investigating this proposed solution, the current draw of two firmware versions of a Crucial SSD were analyzed as the drive executed a series of file operations. Identifying relevant signal features, standard machine learning techniques were employed to develop models that correctly classified the firmware loaded on the SSD with over 98% accuracy given only a recording of their current draw signals during file operations.
BN 978-1-5386-7518-2
PY 2018
BP 943
EP 948
DI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.000-5
UT WOS:000450146600143
ER

PT J
AU Spink, T
   Wagstaff, H
   Franke, B
AF Spink, Tom
   Wagstaff, Harry
   Franke, Bjoern
TI Hardware-Accelerated Cross-Architecture Full-System Virtualization
SO ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION
AB Hardware virtualization solutions provide users with benefits ranging from application isolation through server consolidation to improved disaster recovery and faster server provisioning. While hardware assistance for virtualization is supported by all major processor architectures, including Intel, ARM, PowerPC, and MIPS, these extensions are targeted at virtualization of the same architecture, for example, an x86 guest on an x86 host system. Existing techniques for cross-architecture virtualization, for example, an ARM guest on an x86 host, still incur a substantial overhead for CPU, memory, and I/O virtualization due to the necessity for software emulation of these mismatched system components. In this article, we present a new hardwareaccelerated hypervisor called CAPTIVE, employing a range of novel techniques that exploit existing hardware virtualization extensions for improving the performance of full-system cross-platform virtualization. We illustrate how (1) guest memory management unit (MMU) events and operations can be mapped onto host memory virtualization extensions, eliminating the need for costly softwareMMUemulation, (2) a block-based dynamic binary translation engine inside the virtual machine can improve CPU virtualization performance, (3) memory-mapped guest I/O can be efficiently translated to fast I/O specific calls to emulated devices, and (4) the cost for asynchronous guest interrupts can be reduced. For an ARM-based Linux guest system running on an x86 host with Intel VT support, we demonstrate application performance levels, based on SPEC CPU2006 benchmarks, of up to 5.88x over state-of-the-art QEMU and 2.5x on average, achieving a guest dynamic instruction throughput of up to 1280 MIPS (million instructions per second) and 915.52 MIPS, on average.
RI Spink, Tom/GLU-6587-2022
OI Spink, Tom/0000-0002-7662-3146; Franke, Bjorn/0000-0002-1219-8523
SN 1544-3566
EI 1544-3973
PD DEC
PY 2016
VL 13
IS 4
AR 36
DI 10.1145/2996798
UT WOS:000392416400005
ER

PT C
AU Borji, A
   Izadi, S
   Itti, L
AF Borji, Ali
   Izadi, Saeed
   Itti, Laurent
GP IEEE
TI iLab-20M: A large-scale controlled object dataset to investigate deep
   learning
SO 2016 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)
SE IEEE Conference on Computer Vision and Pattern Recognition
CT 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
CY JUN 27-30, 2016
CL Seattle, WA
SP IEEE Comp Soc, Comp Vis Fdn
AB Tolerance to image variations (e.g., translation, scale, pose, illumination, background) is an important desired property of any object recognition system, be it human or machine. Moving towards increasingly bigger datasets has been trending in computer vision especially with the emergence of highly popular deep learning models. While being very useful for learning invariance to object inter-and intra-class shape variability, these large-scale wild datasets are not very useful for learning invariance to other parameters urging researchers to resort to other tricks for training models. In this work, we introduce a large-scale synthetic dataset, which is freely and publicly available, and use it to answer several fundamental questions regarding selectivity and invariance properties of convolutional neural networks. Our dataset contains two parts: a) objects shot on a turntable: 15 categories, 8 rotation angles, 11 cameras on a semi-circular arch, 5 lighting conditions, 3 focus levels, variety of backgrounds (23.4 per instance) generating 1320 images per instance (about 22 million images in total), and b) scenes: in which a robotic arm takes pictures of objects on a 1: 160 scale scene. We study: 1) invariance and selectivity of different CNN layers, 2) knowledge transfer from one object category to another, 3) systematic or random sampling of images to build a train set, 4) domain adaptation from synthetic to natural scenes, and 5) order of knowledge delivery to CNNs. We also discuss how our analyses can lead the field to develop more efficient deep learning methods.
SN 1063-6919
BN 978-1-4673-8851-1
PY 2016
BP 2221
EP 2230
DI 10.1109/CVPR.2016.244
UT WOS:000400012302030
ER

PT C
AU Kadam, AH
   Menon, R
   Williamson, SS
AF Kadam, Arvind H.
   Menon, Rishi
   Williamson, Sheldon S.
GP IEEE
TI Traction Inverter Performance Testing using Mathematical and Real-time
   Controller-in-the-Loop Permanent Magnet Synchronous Motor Emulator
SO PROCEEDINGS OF THE IECON 2016 - 42ND ANNUAL CONFERENCE OF THE IEEE
   INDUSTRIAL ELECTRONICS SOCIETY
SE IEEE Industrial Electronics Society
CT 42nd Annual Conference of the IEEE-Industrial-Electronics-Society
   (IECON)
CY OCT 24-27, 2016
CL Florence, ITALY
SP IEEE Ind Elect Soc, Inst Elect & Elect Engineers
AB In the development stage of electric vehicle drive, simulation plays a vital role. It's a powerful tool which allows the developer to investigate various control strategies and test hardware systems in harmless work environment. The software simulations platform does have constraints. In that the complex mathematical operations take longer time to solve and eventually increases the overall simulation time and cannot perform the real-time operation. This simulation further needs to be converted to the target processor's language, either assembly or C-language, which will operate in the drive system. However, if a real-time simulation environment could be comprehended, then the real processor used in the system could be incorporated in the simulation. This eventually will eliminate the chance of introducing error during code translation as well as reduce simulation time. Also, the target controller could be tested within the simulation before introducing it the actual system. This paper discuss a concept of controller-in-loop simulation, which can be used to simulate the entire system in real-time. A simple dynamic model of Permanent Magnet Synchronous Motor is simulated with MATLAB/Simulink as well as on a TMS320F28069 digital signal processor from Texas Instruments Inc. Comparative study of simulation results of both the platforms, demonstrate that although MATLAB/Simulink provides excellent GUI and functionality, it fails to performs real-time simulation which can be accomplished with controller-in-simulation.
RI Kadam, Arvind H/J-7341-2019
OI Kadam, Arvind H/0000-0003-4008-0765
SN 1553-572X
BN 978-1-5090-3474-1
PY 2016
BP 6651
EP 6656
UT WOS:000399031206155
ER

PT J
AU Palano, G
   Foinquinos, A
   Mullers, E
AF Palano, Giorgia
   Foinquinos, Ariana
   Mullers, Erik
TI In vitro Assays and Imaging Methods for Drug Discovery for Cardiac
   Fibrosis
SO FRONTIERS IN PHYSIOLOGY
AB As a result of stress, injury, or aging, cardiac fibrosis is characterized by excessive deposition of extracellular matrix (ECM) components resulting in pathological remodeling, tissue stiffening, ventricular dilatation, and cardiac dysfunction that contribute to heart failure (HF) and eventually death. Currently, there are no effective therapies specifically targeting cardiac fibrosis, partially due to limited understanding of the pathological mechanisms and the lack of predictive in vitro models for high-throughput screening of antifibrotic compounds. The use of more relevant cell models, three-dimensional (3D) models, and coculture systems, together with high-content imaging (HCI) and machine learning (ML)-based image analysis, is expected to improve predictivity and throughput of in vitro models for cardiac fibrosis. In this review, we present an overview of available in vitro assays for cardiac fibrosis. We highlight the potential of more physiological 3D cardiac organoids and coculture systems and discuss HCI and automated artificial intelligence (AI)-based image analysis as key methods able to capture the complexity of cardiac fibrosis in vitro. As 3D and coculture models will soon be sufficiently mature for application in large-scale preclinical drug discovery, we expect the combination of more relevant models and high-content analysis to greatly increase translation from in vitro to in vivo models and facilitate the discovery of novel targets and drugs against cardiac fibrosis.
RI Palano, Giorgia/AAN-8478-2021; Mullers, Erik/F-4587-2014
OI Mullers, Erik/0000-0002-2176-3248
SN 1664-042X
PD JUL 8
PY 2021
VL 12
AR 697270
DI 10.3389/fphys.2021.697270
UT WOS:000675580300001
PM 34305651
ER

PT C
AU Charikar, M
   Naamad, Y
   Rexford, J
   Zou, XK
AF Charikar, Moses
   Naamad, Yonatan
   Rexford, Jenifer
   Zou, X. Kelvin
BE Disser, Y
   Verykios, VS
TI Multi-commodity Flow with In-Network Processing
SO ALGORITHMIC ASPECTS OF CLOUD COMPUTING (ALGOCLOUD 2018)
SE Lecture Notes in Computer Science
CT 4th International Symposium on Algorithmic Aspects of Cloud Computing
   (ALGOCLOUD)
CY AUG 20-21, 2018
CL Helsinki, FINLAND
AB Modern networks run "middleboxes" that offer services ranging from network address translation and server load balancing to firewalls, encryption, and compression. In an industry trend known as Network Functions Virtualization (NFV), these middleboxes run as virtual machines on any commodity server, and the switches steer traffic through the relevant chain of services. Network administrators must decide how many middleboxes to run, where to place them, and how to direct traffic through them, based on the traffic load and the server and network capacity. Rather than placing specific kinds of middleboxes on each processing node, we argue that server virtualization allows each server node to host all middlebox functions, and simply vary the fraction of resources devoted to each one. This extra flexibility fundamentally changes the optimization problem the network administrators must solve to a new kind of multi-commodity flow problem, where the traffic flows consume bandwidth on the links as well as processing resources on the nodes. We show that allocating resources to maximize the processed flow can be optimized exactly via a linear programming formulation, and to arbitrary accuracy via an efficient combinatorial algorithm. Our experiments with real traffic and topologies show that a joint optimization of node and link resources leads to an efficient use of bandwidth and processing capacity. We also study a class of design problems that decide where to provide node capacity to best process and route a given set of demands, and demonstrate both approximation algorithms and hardness results for these problems.
SN 0302-9743
EI 1611-3349
BN 978-3-030-19759-9; 978-3-030-19758-2
PY 2019
VL 11409
BP 73
EP 101
DI 10.1007/978-3-030-19759-9_6
UT WOS:000769657600006
ER

PT J
AU Schneider, C
   Bohnsack, KE
AF Schneider, Claudia
   Bohnsack, Katherine E.
TI Caught in the act-Visualizing ribonucleases during eukaryotic ribosome
   assembly
SO WILEY INTERDISCIPLINARY REVIEWS-RNA
AB Ribosomes are essential macromolecular machines responsible for translating the genetic information encoded in mRNAs into proteins. Ribosomes are composed of ribosomal RNAs and proteins (rRNAs and RPs) and the rRNAs fulfill both catalytic and architectural functions. Excision of the mature eukaryotic rRNAs from their precursor transcript is achieved through a complex series of endoribonucleolytic cleavages and exoribonucleolytic processing steps that are precisely coordinated with other aspects of ribosome assembly. Many ribonucleases involved in pre-rRNA processing have been identified and pre-rRNA processing pathways are relatively well defined. However, momentous advances in cryo-electron microscopy have recently enabled structural snapshots of various pre-ribosomal particles from budding yeast (Saccharomyces cerevisiae) and human cells to be captured and, excitingly, these structures not only allow pre-rRNAs to be observed before and after cleavage events, but also enable ribonucleases to be visualized on their target RNAs. These structural views of pre-rRNA processing in action allow a new layer of understanding of rRNA maturation and how it is coordinated with other aspects of ribosome assembly. They illuminate mechanisms of target recognition by the diverse ribonucleases involved and reveal how the cleavage/processing activities of these enzymes are regulated. In this review, we discuss the new insights into pre-rRNA processing gained by structural analyses and the growing understanding of the mechanisms of ribonuclease regulation. This article is categorized under: Translation > Ribosome Biogenesis RNA Processing > rRNA Processing
OI Bohnsack, Katherine Elizabeth/0000-0001-6035-4255
SN 1757-7004
EI 1757-7012
DI 10.1002/wrna.1766
EA OCT 2022
UT WOS:000868991900001
PM 36254602
ER

PT C
AU Sankar, KPS
   Raj, PCR
   Jayan, V
AF Sankar, Sruthi K. P.
   Raj, P. C. Reghu
   Jayan, V
BE Viswanathan, C
   Kumar, RS
TI Unsupervised Approach to Word Sense Disambiguation in Malayalam
SO INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ENGINEERING, SCIENCE AND
   TECHNOLOGY (ICETEST - 2015)
SE Procedia Technology
CT 4th International Conference on Emerging Trends in Engineering, Science
   and Technology (ICETEST)
CY DEC 09-11, 2015
CL Trichur, INDIA
SP Govt Engn Coll Trichur
AB Word Sense Disambiguation (WSD) is the task of identifying the correct sense of a word in a specific context when the word has multiple meaning. WSD is very important as an intermediate step in many Natural Language Processing (NLP) tasks, especially in Information Extraction(IE), Machine Translation(MT) and Question/Answering Systems. Word sense ambiguity arises when a particular word has more than one possible sense. The peculiarity of any language is that it includes a lot of ambiguous words. Since the sense of a word depends on its context of use, disambiguation process requires the understanding of word knowledge. Automatic WSD systems are available for structured languages like English, Chinese, etc. But Indian languages are morphologically rich and thus the processing task is very complex. The aim of this work is to develop a WSD system for Malayalam, a language spoken in India, predominantly used in the state of Kerala. The proposed system uses a corpus which is collected from various Malayalam web documents. For each possible sense of the ambiguous word, a relatively small set of training examples (seed sets) are identified which represents the sense. Collocations and most co-occurring words are considered as training examples. Seed set expansion module extends the seed set by adding most similar words to the seed set elements. These extended sets act as sense clusters. The most similar sense cluster to the input text context is considered as the sense of the target word. (C) 2016 The Authors. Published by Elsevier Ltd.
OI Vasudevan, Jayan/0000-0002-1810-6407
SN 2212-0173
PY 2016
VL 24
BP 1507
EP 1513
DI 10.1016/j.protcy.2016.05.106
UT WOS:000387696400197
ER

PT C
AU Oikonomopoulos, A
   Pantic, M
   Patras, I
AF Oikonomopoulos, A.
   Pantic, M.
   Patras, I.
GP IEEE
TI B-spline Polynomial Descriptors for Human Activity Recognition
SO 2008 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN
   RECOGNITION WORKSHOPS, VOLS 1-3
SE IEEE Conference on Computer Vision and Pattern Recognition
CT IEEE Conference on Computer Vision and Pattern Recognition
CY JUN 23-28, 2008
CL Anchorage, AK
SP IEEE Comp Soc
AB The extraction and quantization of local image and video descriptors for the subsequent creation of visual codebooks is a technique that has proved extremely effective for image and video retrieval applications. In this paper we build on this concept and extract a new set of visual descriptors that are derived from spatiotemporal salient points detected on given image sequences and provide local space-time description of the visual activity. The proposed descriptors are based on the geometrical properties of three-dimensional piecewise polynomials, namely B-splines, that are fitted on the spatiotemporal locations of the salient points that are engulfed within a given spatiotemporal neighborhood. Our descriptors are inherently translation invariant, while the use of the scales of the salient points for the definition of the neighborhood dimensions ensures space-time scaling invariance. Subsequently, a clustering algorithm is used in order to cluster our descriptors across the whole dataset and create a codebook of visual verbs, where each verb corresponds to a cluster center We use the resulting codebook in a 'bag of verbs' approach in order to recover the pose and short-term motion of subjects at a short set of successive frames, and we use Dynamic Time Warping (DTW) in order to align the sequences in our dataset and structure in time the recovered poses. We define a kernel based on the similarity measure provided by the DTW to classify our examples in a Relevane Vector Machine classification scheme. We present results in a well established human activity database to verify, the effectiveness of our method.
OI Patras, Ioannis/0000-0003-3913-4738
SN 1063-6919
BN 978-1-4244-2339-2
PY 2008
BP 1622
EP +
UT WOS:000260371900226
ER

PT J
AU Forno, E
   Fra, V
   Pignari, R
   Macii, E
   Urgese, G
AF Forno, Evelina
   Fra, Vittorio
   Pignari, Riccardo
   Macii, Enrico
   Urgese, Gianvito
TI Spike encoding techniques for IoT time-varying signals benchmarked on a
   neuromorphic classification task
SO FRONTIERS IN NEUROSCIENCE
AB Spiking Neural Networks (SNNs), known for their potential to enable low energy consumption and computational cost, can bring significant advantages to the realm of embedded machine learning for edge applications. However, input coming from standard digital sensors must be encoded into spike trains before it can be elaborated with neuromorphic computing technologies. We present here a detailed comparison of available spike encoding techniques for the translation of time-varying signals into the event-based signal domain, tested on two different datasets both acquired through commercially available digital devices: the Free Spoken Digit dataset (FSD), consisting of 8-kHz audio files, and the WISDM dataset, composed of 20-Hz recordings of human activity through mobile and wearable inertial sensors. We propose a complete pipeline to benchmark these encoding techniques by performing time-dependent signal classification through a Spiking Convolutional Neural Network (sCNN), including a signal preprocessing step consisting of a bank of filters inspired by the human cochlea, feature extraction by production of a sonogram, transfer learning via an equivalent ANN, and model compression schemes aimed at resource optimization. The resulting performance comparison and analysis provides a powerful practical tool, empowering developers to select the most suitable coding method based on the type of data and the desired processing algorithms, and further expands the applicability of neuromorphic computational paradigms to embedded sensor systems widely employed in the IoT and industrial domains.
EI 1662-453X
PD DEC 21
PY 2022
VL 16
AR 999029
DI 10.3389/fnins.2022.999029
UT WOS:000907007200001
PM 36620463
ER

PT J
AU Tomioka, M
   Kato, T
   Tamura, A
AF Tomioka, Manaya
   Kato, Tsuneo
   Tamura, Akihiro
TI Analysis on Norms of Word Embedding and Hidden Vectors in Neural
   Conversational Model Based on Encoder-Decoder RNN
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
AB A neural conversational model (NCM) based on an encoder-decoder recurrent neural network (RNN) with an attention mech-anism learns different sequence-to-sequence mappings from what neural machine translation (NMT) learns even when based on the same technique. In the NCM, we confirmed that target-word-to-source-word mappings cap-tured by the attention mechanism are not as clear and stationary as those for NMT. Considering that vector norms indicate a magnitude of information in the processing, we analyzed the inner workings of an encoder-decoder GRU-based NCM focusing on the norms of word embedding vectors and hidden vectors. First, we conducted correlation analyses on the norms of word embedding vectors with frequencies in the training set and with con-ditional entropies of a bi-gram language model to understand what is cor-related with the norms in the encoder and decoder. Second, we conducted correlation analyses on norms of change in the hidden vector of the recur-rent layer with their input vectors for the encoder and decoder, respectively. These analyses were done to understand how the magnitude of information propagates through the network. The analytical results suggested that the norms of the word embedding vectors are associated with their semantic in-formation in the encoder, while those are associated with the predictability as a language model in the decoder. The analytical results further revealed how the norms propagate through the recurrent layer in the encoder and decoder.
SN 0916-8532
EI 1745-1361
PD OCT
PY 2022
VL E105D
IS 10
BP 1780
EP 1789
DI 10.1587/transinf.2021EDP7227
UT WOS:000885942400016
ER

PT J
AU Jain, A
   Arora, A
   Morato, J
   Yadav, D
   Kumar, KV
AF Jain, Arti
   Arora, Anuja
   Morato, Jorge
   Yadav, Divakar
   Kumar, Kumar Vimal
TI Automatic Text Summarization for Hindi Using Real Coded Genetic
   Algorithm
SO APPLIED SCIENCES-BASEL
AB Featured Application This paper provides applicability of the Real Coded Genetic Algorithm to the Natural Language Processing Task, i.e., Text Summarization. The purpose of text summarization is to reduce an extensive document into a concise format such that the essence of the content is retained. By doing so, users can utilize the summarized document for vivid applications such as Question Answering, Machine Translation, Fake News Detection, and Named Entity Recognition to name a selected few. In the present scenario, Automatic Text Summarization (ATS) is in great demand to address the ever-growing volume of text data available online to discover relevant information faster. In this research, the ATS methodology is proposed for the Hindi language using Real Coded Genetic Algorithm (RCGA) over the health corpus, available in the Kaggle dataset. The methodology comprises five phases: preprocessing, feature extraction, processing, sentence ranking, and summary generation. Rigorous experimentation on varied feature sets is performed where distinguishing features, namely- sentence similarity and named entity features are combined with others for computing the evaluation metrics. The top 14 feature combinations are evaluated through Recall-Oriented Understudy for Gisting Evaluation (ROUGE) measure. RCGA computes appropriate feature weights through strings of features, chromosomes selection, and reproduction operators: Simulating Binary Crossover and Polynomial Mutation. To extract the highest scored sentences as the corpus summary, different compression rates are tested. In comparison with existing summarization tools, the ATS extractive method gives a summary reduction of 65%.
RI Arora, Anuja/T-7013-2019; Yadav, DIVAKAR/AAF-1777-2020; Jain,
   Arti/AAD-3795-2020
OI Arora, Anuja/0000-0001-5215-1300; Yadav, DIVAKAR/0000-0001-6051-479X;
   Jain, Arti/0000-0002-3764-8834; Morato, Jorge/0000-0002-7530-9753
EI 2076-3417
PD JUL
PY 2022
VL 12
IS 13
AR 6584
DI 10.3390/app12136584
UT WOS:000824498200001
ER

PT J
AU Zhou, SC
   Liu, W
AF Zhou, Shanchun
   Liu, Wei
TI English Grammar Error Correction Algorithm Based on Classification Model
SO COMPLEXITY
AB English grammar error correction algorithm refers to the use of computer programming technology to automatically recognize and correct the grammar errors contained in English text written by nonnative language learners. Classification model is the core of machine learning and data mining, which can be applied to extracting information from English text data and constructing a reliable grammar correction method. On the basis of summarizing and analyzing previous research works, this paper expounded the research status and significance of English grammar error correction algorithm, elaborated the development background, current status, and future challenges of the classification model, introduced the methods and principles of feature extraction method and dynamic residual structure, constructed a basic model for English grammar error correction based on the classification model, analyzed the classification model and translation model of English grammar error correction, proposed the English grammar error correction algorithm based on the classification model, performed the analyses of the model architecture and model optimizer of the grammar error correction algorithm, and finally conducted a simulation experiment and its result analysis. The study results show that, with the continuous increase of training samples and the continuous progress of learning process, the proposed English grammar error correction algorithm based on the classification model will continue to increase its classification accuracy, further refine its recognition rules, and gradually improve correction efficiency, thereby reducing processing time, saving storage space, and streamlining processing flow. The study results of this paper provide a certain reference for the further research on English grammar error correction algorithm based on the classification model.
OI Liu, Wei/0000-0001-8585-861X
SN 1076-2787
EI 1099-0526
PD JAN 19
PY 2021
VL 2021
AR 6687337
DI 10.1155/2021/6687337
UT WOS:000616107800004
ER

PT C
AU Fenton, K
   Simske, S
AF Fenton, Kevin
   Simske, Steven
GP ACM
TI Engineering of an Artificial Intelligence Safety Data Sheet Document
   Processing System for Environmental, Health, and Safety Compliance
SO PROCEEDINGS OF THE 21ST ACM SYMPOSIUM ON DOCUMENT ENGINEERING (DOCENG
   '21)
CT 21st ACM Symposium on Document Engineering (DocEng)
CY AUG 24-27, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGWEB
AB Chemical Safety Data Sheets (SDS) are the primary method by which chemical manufacturers communicate the ingredients and hazards of their products to the public. These SDSs are used for a wide variety of purposes ranging from environmental calculations to occupational health assessments to emergency response measures. Although a few companies have provided direct digital data transfer platforms using xml or equivalent schemata, the vast majority of chemical ingredient and hazard communication to product users still occurs through the use of millions of PDF documents that are largely loaded through manual data entry into downstream user databases. This research focuses on the reverse engineering of SDS document types to adapt to various layouts and the harnessing of meta-algorithmic and neural network approaches to provide a means of moving industrial institutions towards a digital universal SDS processing methodology. The complexities of SDS documents including the lack of format standardization, text and image combinations, and multi-lingual translation needs, combined, limit the accuracy and precision of optical character recognition tools.
   The approach in this document is to translate entire SDSs from thousands of chemical vendors, each with distinct formatting, to machine-encoded text with a high degree of accuracy and precision. Then the system will "read" and assess these documents as a human would; that is, ensuring that the documents are compliant, determining whether chemical formulations have changed, ensuring reported values are within expected thresholds, and comparing them to similar products for more environmentally friendly alternatives.
OI Fenton, Kevin/0000-0002-0528-6349
BN 978-1-4503-8596-1
PY 2021
DI 10.1145/3469096.3474933
UT WOS:000744481000024
ER

PT J
AU Stolyarov, R
   Burnett, G
   Herr, H
AF Stolyarov, Roman
   Burnett, Gary
   Herr, Hugh
TI Translational Motion Tracking of Leg Joints for Enhanced Prediction of
   Walking Tasks
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
AB Objective: Walking task prediction in powered leg prostheses is an important problem in the development of biomimetic prosthesis controllers. This paper proposes a novel method to predict upcoming walking tasks by estimating the translational motion of leg joints using an integrated inertial measurement unit. Methods: We asked six subjects with unilateral transtibial amputations to traverse flat ground, ramps, and stairs using a powered prosthesis while inertial signals were collected. We then performed an offline analysis in which we simulated a real-time motion tracking algorithm on the inertial signals to estimate knee and ankle joint translations, and then used pattern recognition separately on the inertial and translational signal sets to predict the target walking tasks of individual strides. Results: Our analysis showed that using inertial signals to derive translational signals enabled a prediction error reduction of 6.8% compared to that attained using the original inertial signals. This result was similar to that seen by addition of surface electromyography sensors to integrated sensors in previous work, but was effected without adding any extra sensors. Finally, we reduced the size of the translational set to that of the inertial set and showed that the former still enabled a composite error reduction of 5.8%. Conclusion and Significance: These results indicate that translational motion tracking can be used to substantially enhance walking task prediction in leg prostheses without adding external sensing modalities. Our proposed algorithm can thus be used as a part of a task-adaptive and fully integrated prosthesis controller.
OI Stolyarov, Roman/0000-0001-8561-7330
SN 0018-9294
EI 1558-2531
PD APR
PY 2018
VL 65
IS 4
BP 763
EP 769
DI 10.1109/TBME.2017.2718528
UT WOS:000428526000006
PM 28650802
ER

PT C
AU Callenes-Sloan, J
   McNamara, H
AF Callenes-Sloan, Joseph
   McNamara, Hugh
GP IEEE
TI Algorithm Selection for Error Resilience in Scientific Computing
SO 2014 20TH IEEE PACIFIC RIM INTERNATIONAL SYMPOSIUM ON DEPENDABLE
   COMPUTING (PRDC 2014)
SE IEEE Pacific Rim International Symposium on Dependable Computing
CT 20th IEEE Pacific Rim International Symposium on Dependable Computing
   (PRDC)
CY NOV 19-21, 2014
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc Tech Comm Dependable Comp & Fault Tolerance, IFIP Working Grp 10 4 Dependable Comp & Fault Tolerance, Natl Univ Singapore, Nanyang Technol Univ, Singapore Univ Technol & Design
AB With process scaling and the adoption of post-cmos technologies, reliability and power are becoming a significant concern for future computing systems, especially highly parallel systems. Previous approaches have investigated augmenting applications with additional logic to detect and correct errors efficiently. In this paper, we investigate the impact of different algorithmic designs on error resilience and propose an approach for algorithm selection for a class of equations, i.e. partial differential equations (PDEs), that are at the core of many scientific computing applications, which drive HPC systems. Many different schemes have been devised for the approximation of PDE systems, each with different accuracy, stability, and performance properties. In this paper, there are two primary questions that we address: (1) Does numerical stability translate to error resilience? and (2) How do we design schemes to improve error resilience? If an algorithm's error resilience is correlated with its numerical stability properties, this may allow us to design more resilient applications by leveraging well-established information on numerical stability. Even with a clear translation of numerical stability to error resilience properties, the question of designing these algorithms still remains however, due to the variety of implementations, schemes, and largely input specific nature of the design. In this paper, we propose one approach for automated design using machine-learning. We observe that intelligent selection of the algorithm or a given problem, improves robustness by 20%-50%, on average, over the traditional selection of algorithms, without the addition of any other detection/correction logic.
SN 1555-094X
BN 978-1-4799-6474-1
PY 2014
BP 96
EP 105
DI 10.1109/PRDC.2014.20
UT WOS:000356602600015
ER

PT J
AU Scheiner, S
   Sinibaldi, R
   Pichler, B
   Komlev, V
   Renghini, C
   Vitale-Brovarone, C
   Rustichelli, F
   Hellmich, C
AF Scheiner, Stefan
   Sinibaldi, Raffaele
   Pichler, Bernhard
   Komlev, Vladimir
   Renghini, Chiara
   Vitale-Brovarone, Chiara
   Rustichelli, Franco
   Hellmich, Christian
TI Micromechanics of bone tissue-engineering scaffolds, based on resolution
   error-cleared computer tomography
SO BIOMATERIALS
AB Synchrotron radiation micro-computed tomography (SR mu CT) revealed the microstructure of a CEL2 glass-ceramic scaffold with macropores of several hundred microns characteristic length, in terms of the voxel-by-voxel 3D distribution of the attenuation coefficients throughout the scanned space. The probability density function of all attenuation coefficients related to the macroporous space inside the scaffold gives access to the tomograph-specific machine error included in the SR mu CT measurements (also referred to as instrumental resolution function). After Lorentz function-based clearing of the measured CT data from the systematic resolution error, the voxel-specific attenuation information of the voxels representing the solid skeleton is translated into the composition of the material inside one voxel, in terms of the nanoporosity embedded in a dense CEL2 glass-ceramic matrix. Based on voxel-invariant elastic properties of dense CEL2 glass-ceramic, continuum micromechanics allows for translation of the voxel-specific nanoporosity into voxel-specific elastic properties. They serve as input for Finite Element analyses of the scaffold structure. Young's modulus of a specific CT-scanned macroporous scaffold sample, predicted from a Finite Element simulation of a uniaxial compression test, agrees well with the experimental value obtained from an ultrasonic test on the same sample. This highlights the satisfactory predictive capabilities of the presented approach. (C) 2008 Elsevier Ltd. All rights reserved.
RI Komlev, Vladimir S./F-8678-2010; Brovarone, Chiara Vitale/G-9630-2012
OI Komlev, Vladimir S./0000-0003-2068-7746; Brovarone, Chiara
   Vitale/0000-0003-2413-5594; Christian, Hellmich/0000-0003-0153-4859;
   sinibaldi, raffaele/0000-0002-2137-2351; Pichler,
   Bernhard/0000-0002-6468-1840; Scheiner, Stefan/0000-0003-1078-7807
SN 0142-9612
EI 1878-5905
PD APR
PY 2009
VL 30
IS 12
BP 2411
EP 2419
DI 10.1016/j.biomaterials.2008.12.048
UT WOS:000264512800026
PM 19135717
ER

PT J
AU Samant, RM
   Bachute, MR
   Gite, S
   Kotecha, K
AF Samant, Rahul Manohar
   Bachute, Mrinal R.
   Gite, Shilpa
   Kotecha, Ketan
TI Framework for Deep Learning-Based Language Models Using Multi-Task
   Learning in Natural Language Understanding: A Systematic Literature
   Review and Future Directions
SO IEEE ACCESS
AB Learning human languages is a difficult task for a computer. However, Deep Learning (DL) techniques have enhanced performance significantly for almost all-natural language processing (NLP) tasks. Unfortunately, these models cannot be generalized for all the NLP tasks with similar performance. NLU (Natural Language Understanding) is a subset of NLP including tasks, like machine translation, dialogue-based systems, natural language inference, text entailment, sentiment analysis, etc. The advancement in the field of NLU is the collective performance enhancement in all these tasks. Even though MTL (Multi-task Learning) was introduced before Deep Learning, it has gained significant attention in the past years. This paper aims to identify, investigate, and analyze various language models used in NLU and NLP to find directions for future research. The Systematic Literature Review (SLR) is prepared using the literature search guidelines proposed by Kitchenham and Charters on various language models between 2011 and 2021. This SLR points out that the unsupervised learning method-based language models show potential performance improvement. However, they face the challenge of designing the general-purpose framework for the language model, which will improve the performance of multi-task NLU and the generalized representation of knowledge. Combining these approaches may result in a more efficient and robust multi-task NLU. This SLR proposes building steps for a conceptual framework to achieve goals of enhancing the performance of language models in the field of NLU.
RI Samant, Rahul/AGA-4507-2022; Bachute, Mrinal/AAA-4101-2021; Kotecha,
   K/U-3927-2017
OI Samant, Rahul/0000-0002-5158-9180; Bachute, Mrinal/0000-0002-6647-9347;
   Kotecha, K/0000-0003-2653-3780
SN 2169-3536
PY 2022
VL 10
BP 17078
EP 17097
DI 10.1109/ACCESS.2022.3149798
UT WOS:000756553500001
ER

PT J
AU Fernando, T
   Denman, S
   Sridharan, S
   Fookes, C
AF Fernando, Tharindu
   Denman, Simon
   Sridharan, Sridha
   Fookes, Clinton
TI Soft plus Hardwired attention: An LSTM framework for human trajectory
   prediction and abnormal event detection
SO NEURAL NETWORKS
AB As humans we possess an intuitive ability for navigation which we master through years of practice; however existing approaches to model this trait for diverse tasks including monitoring pedestrian flow and detecting abnormal events have been limited by using a variety of hand-crafted features. Recent research in the area of deep-learning has demonstrated the power of learning features directly from the data; and related research in recurrent neural networks has shown exemplary results in sequence-to-sequence problems such as neural machine translation and neural image caption generation. Motivated by these approaches, we propose a novel method to predict the future motion of a pedestrian given a short history of their, and their neighbours, past behaviour. The novelty of the proposed method is the combined attention model which utilises both "soft attention'' as well as "hard-wired'' attention in order to map the trajectory information from the local neighbourhood to the future positions of the pedestrian of interest. We illustrate how a simple approximation of attention weights (i.e. hard-wired) can be merged together with soft attention weights in order to make our model applicable for challenging real world scenarios with hundreds of neighbours. The navigational capability of the proposed method is tested on two challenging publicly available surveillance databases where our model outperforms the current-state-of-the-art methods. Additionally, we illustrate how the proposed architecture can be directly applied for the task of abnormal event detection without handcrafting the features. (c) 2018 Elsevier Ltd. All rights reserved.
RI Fernando, Tharindu/AAJ-1974-2020
OI Fernando, Tharindu/0000-0002-6935-1816; Sridharan,
   Sridha/0000-0003-4316-9001
SN 0893-6080
EI 1879-2782
PD DEC
PY 2018
VL 108
BP 466
EP 478
DI 10.1016/j.neunet.2018.09.002
UT WOS:000450298900034
PM 30317132
ER

PT J
AU Boucher, MJ
   Ghosh, S
   Zhang, L
   Lal, A
   Jang, SW
   Ju, A
   Zhang, SY
   Wang, XZ
   Ralph, SA
   Zou, J
   Elias, JE
   Yeh, E
AF Boucher, Michael J.
   Ghosh, Sreejoyee
   Zhang, Lichao
   Lal, Avantika
   Jang, Se Won
   Ju, An
   Zhang, Shuying
   Wang, Xinzi
   Ralph, Stuart A.
   Zou, James
   Elias, Joshua E.
   Yeh, Ellen
TI Integrative proteomics and bioinformatic prediction enable a
   high-confidence apicoplast proteome in malaria parasites
SO PLOS BIOLOGY
AB Malaria parasites (Plasmodium spp.) and related apicomplexan pathogens contain a non-photosynthetic plastid called the apicoplast. Derived from an unusual secondary eukaryote- eukaryote endosymbiosis, the apicoplast is a fascinating organelle whose function and biogenesis rely on a complex amalgamation of bacterial and algal pathways. Because these pathways are distinct from the human host, the apicoplast is an excellent source of novel antimalarial targets. Despite its biomedical importance and evolutionary significance, the absence of a reliable apicoplast proteome has limited most studies to the handful of pathways identified by homology to bacteria or primary chloroplasts, precluding our ability to study the most novel apicoplast pathways. Here, we combine proximity biotinylation-based proteomics (BiolD) and a new machine learning algorithm to generate a high-confidence apicoplast proteome consisting of 346 proteins. Critically, the high accuracy of this proteome significantly outperforms previous prediction-based methods and extends beyond other BiolD studies of unique parasite compartments. Half of identified proteins have unknown function, and 77% are predicted to be important for normal blood-stage growth. We validate the apicoplast localization of a subset of novel proteins and show that an ATP-binding cassette protein ABCF1 is essential for blood-stage survival and plays a previously unknown role in apicoplast biogenesis. These findings indicate critical organellar functions for newly discovered apicoplast proteins. The apicoplast proteome will be an important resource for elucidating unique pathways derived from secondary endosymbiosis and prioritizing antimalarial drug targets.
RI Lal, Avantika/H-6176-2019; Ghosh, Sreejoyee/AAQ-8421-2020; Ralph,
   Stuart/C-8590-2014
OI Lal, Avantika/0000-0002-5827-0826; Ralph, Stuart/0000-0003-0114-7808;
   Yeh, Ellen/0000-0003-3974-3816
SN 1544-9173
EI 1545-7885
PD SEP
PY 2018
VL 16
IS 9
AR e2005895
DI 10.1371/journal.pbio.2005895
UT WOS:000446154800013
PM 30212465
ER

PT C
AU Jermyn, M
   Desroches, J
   Mercier, J
   St-Arnaud, K
   Guiot, MC
   Petrecca, K
   Leblond, F
AF Jermyn, Michael
   Desroches, Joannie
   Mercier, Jeanne
   St-Arnaud, Karl
   Guiot, Marie-Christine
   Petrecca, Kevin
   Leblond, Frederic
BE Madsen, SJ
   Yang, VXD
   Jansen, ED
   Luo, Q
   Ding, J
   Roe, AW
   Mohanty, SK
   Thakor, NV
TI Neural networks improve brain cancer detection with Raman spectroscopy
   in the presence of light artifacts
SO CLINICAL AND TRANSLATIONAL NEUROPHOTONICS; NEURAL IMAGING AND SENSING;
   AND OPTOGENETICS AND OPTICAL MANIPULATION
SE Proceedings of SPIE
CT Conference on Clinical and Translational Neurophotonics; Neural Imaging
   and Sensing; and Optogenetics and Optical Manipulation
CY FEB 13-16, 2016
CL San Francisco, CA
SP SPIE
AB It is often difficult to identify cancer tissue during brain cancer ( glioma) surgery. Gliomas invade into areas of normal brain, and this cancer invasion is frequently not detected using standard preoperative magnetic resonance imaging ( MRI). This results in enduring invasive cancer following surgery and leads to recurrence. A hand- held Raman spectroscopy is able to rapidly detect cancer invasion in patients with grade 2- 4 gliomas. However, ambient light sources can produce spectral artifacts which inhibit the ability to distinguish between cancer and normal tissue using the spectral information available. To address this issue, we have demonstrated that artificial neural networks ( ANN) can accurately classify invasive cancer versus normal brain tissue, even when including measurements with significant spectral artifacts from external light sources. The non- parametric and adaptive model used by ANN makes it suitable for detecting complex non- linear spectral characteristics associated with different tissues and the confounding presence of light artifacts. The use of ANN for brain cancer detection with Raman spectroscopy, in the presence of light artifacts, improves the robustness and clinical translation potential for intraoperative use. Integration with the neurosurgical workflow is facilitated by accounting for the effect of light artifacts which may occur, due to operating room lights, neuronavigation systems, windows, or other light sources. The ability to rapidly detect invasive brain cancer under these conditions may reduce residual cancer remaining after surgery, and thereby improve patient survival.
SN 0277-786X
EI 1996-756X
BN 978-1-62841-960-3
PY 2016
VL 9690
AR 96900B
DI 10.1117/12.2208892
UT WOS:000383224700005
ER

PT J
AU Chappell, BA
   Pereira, TMD
AF Chappell, Bruce A.
   Pereira, Tiago M. D.
TI SunnyNet: A neural network approach to 3D non-LTE radiative transfer
SO ASTRONOMY & ASTROPHYSICS
AB Context. Computing spectra from 3D simulations of stellar atmospheres when allowing for departures from local thermodynamic equilibrium (non-LTE) is computationally very intensive. Aims. We develop a machine learning based method to speed up 3D non-LTE radiative transfer calculations in optically thick stellar atmospheres. Methods. Making use of a variety of 3D simulations of the solar atmosphere, we trained a convolutional neural network, SunnyNet, to learn the translation from LTE to non-LTE atomic populations. Non-LTE populations computed with an existing 3D code were considered as the true values. The network was then used to predict non-LTE populations for other 3D simulations, and synthetic spectra were computed from its predicted non-LTE populations. We used a six-level model atom of hydrogen and H alpha spectra as test cases. Results. SunnyNet gives reasonable predictions for non-LTE populations with a dramatic speedup of about 10(5) times when running on a single GPU and compared to existing codes. When using different snapshots of the same simulation for training and testing, SunnyNet's predictions are within 20-40% of the true values for most points, which results in average differences of a few percent in H alpha spectra. Predicted H alpha intensity maps agree very well with existing codes. Most importantly, they show the telltale signs of 3D radiative transfer in the morphology of chromospheric fibrils. The results are not as reliable when the training and testing are done with different families of simulations. SunnyNet is open source and publicly available.
SN 0004-6361
EI 1432-0746
PD FEB 21
PY 2022
VL 658
AR A182
DI 10.1051/0004-6361/202142625
UT WOS:000758370700004
ER

PT J
AU Nahta, R
   Meena, YK
   Gopalani, D
   Chauhan, GS
AF Nahta, Ravi
   Meena, Yogesh Kumar
   Gopalani, Dinesh
   Chauhan, Ganpat Singh
TI Embedding metadata using deep collaborative filtering to address the
   cold start problem for the rating prediction task
SO MULTIMEDIA TOOLS AND APPLICATIONS
AB In recent years, deep learning has yielded success in many research fields including machine translation, natural language processing, computer vision, and social network filtering. The area of deep learning in the recommender system is flourishing. Previous research has relied on incorporating metadata information in various application domains using deep learning techniques to achieve better recommendation accuracy. The use of metadata is desirable to address the cold start problem and better learning the user-item interaction, which is not captured by the user-item rating matrix. Existing methods rely on fixed user-item latent representation and ignore the metadata information. It restricts the model performance to correctly identify actual latent vectors, which results in high rating prediction error. To tackle these problems, we propose a generalized recommendation model named Meta Embedding Deep Collaborative Filtering (MEDCF), which inputs user demographics and item genre as metadata features together with the rating matrix. The proposed framework primarily comprises of Generalized Matrix Factorization (GMF), Multilayer Perceptron (MLP), and Neural Matrix Factorization (NeuMF) methods. GMF is applied to the rating matrix, whereas MLP is applied to metadata. Using NeuMF, the outputs for GMF and MLP are then concatenated and input to a neural network for rating prediction. To prove the effectiveness of proposed model, two metrics are used, Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). The MEDCF model is experimented on MovieLens and Amazon Movies datasets showing a significant improvement over the baseline methods.
RI Chauhan, Ganpat/GLT-3511-2022; Meena, Yogesh/GZH-0796-2022; Nahta,
   Ravi/P-4622-2018
OI Chauhan, Ganpat/0000-0003-0193-4297; Nahta, Ravi/0000-0001-7085-9230
SN 1380-7501
EI 1573-7721
PD MAY
PY 2021
VL 80
IS 12
BP 18553
EP 18581
DI 10.1007/s11042-021-10529-4
EA FEB 2021
UT WOS:000619425300001
ER

PT C
AU Grebenisan, A
   Sedghi, A
   Menard, A
   Izard, J
   Siemens, R
   Mousavi, P
AF Grebenisan, Andrew
   Sedghi, Alireza
   Menard, Alexandre
   Izard, Jason
   Siemens, Robert
   Mousavi, Parvin
BE Fei, B
   Linte, CA
TI Towards Democratizing AI in MR-based Prostate Cancer Diagnosis: 3.0 to
   1.5 Tesla
SO MEDICAL IMAGING 2020: IMAGE-GUIDED PROCEDURES, ROBOTIC INTERVENTIONS,
   AND MODELING
SE Proceedings of SPIE
CT Medical Imaging Conference - Image-Guided Procedures, Robotic
   Interventions, and Modeling
CY FEB 16-19, 2020
CL Houston, TX
SP SPIE
AB In the Western world, nearly 1 in 14 men will be diagnosed with prostate cancer in their lifetimes. The gold standard for detection of PCa is histopathology analysis of biopsy cores taken using trans-rectal ultrasound (TRUS) guidance, a procedure that has a false negative rate of 30 - 45% and serious side effects. Multi-parametric MRI (MP-MRI) is quickly becoming part of the standard of care to detect PCa lesions. According to recent multi-centre studies, it has the potential to decrease false positives for PCa detection and reduce the need for biopsy. At the same time, deep learning approaches for aiding radiologists in PCa diagnosis have been on the rise. Most of the solutions in the literature benefit from abundant high-quality data, which limits their translation to clinical settings. For PCa in particular, close to 83% of clinical MRI systems in Canada are 1.5 T, and many centres may not have the high throughput volume of patients required for building locally accurate machine learning models. In this paper, we present preliminary results from a deep learning framework built using publicly available 3.0 T MP-MRI data and re-purposed for 1.5 T clinical data. We achieve areas under the receiver operating curve of up to 0.76 and provide visualization of the most informative areas of the images for the deep models. Our proposed approach has the potential to allow local hospitals to use pre-built AI models fine-tuned for their own cases, taking advantage of externally available large data sets.
SN 0277-786X
EI 1996-756X
BN 978-1-5106-3398-8
PY 2021
VL 11315
AR 113150R
DI 10.1117/12.2549413
UT WOS:000672559200025
ER

PT J
AU Cimbalnik, J
   Brinkmann, B
   Kremen, V
   Jurak, P
   Berry, B
   Van Gompel, J
   Stead, M
   Worrell, G
AF Cimbalnik, Jan
   Brinkmann, Benjamin
   Kremen, Vaclav
   Jurak, Pavel
   Berry, Brent
   Van Gompel, Jamie
   Stead, Matt
   Worrell, Greg
TI Physiological and pathological high frequency oscillations in focal
   epilepsy
SO ANNALS OF CLINICAL AND TRANSLATIONAL NEUROLOGY
AB ObjectiveThis study investigates high-frequency oscillations (HFOs; 65-600Hz) as a biomarker of epileptogenic brain and explores three barriers to their clinical translation: (1) Distinguishing pathological HFOs (pathHFO) from physiological HFOs (physHFO). (2) Classifying tissue under individual electrodes as epileptogenic (3) Reproducing results across laboratories.
   MethodsWe recorded HFOs using intracranial EEG (iEEG) in 90 patients with focal epilepsy and 11 patients without epilepsy. In nine patients with epilepsy putative physHFOs were induced by cognitive or motor tasks. HFOs were identified using validated detectors. A support vector machine (SVM) using HFO features was developed to classify tissue under individual electrodes as normal or epileptogenic.
   ResultsThere was significant overlap in the amplitude, frequency, and duration distributions for spontaneous physHFO, task induced physHFO, and pathHFO, but the amplitudes of the pathHFO were higher (P<0.0001). High gamma pathHFO had the strongest association with seizure onset zone (SOZ), and were elevated on SOZ electrodes in 70% of epilepsy patients (P<0.0001). Failure to resect tissue generating high gamma pathHFO was associated with poor outcomes (P<0.0001). A SVM classified individual electrodes as epileptogenic with 63.9% sensitivity and 73.7% specificity using SOZ as the target.
   InterpretationA broader range of interictal pathHFO (65-600Hz) than previously recognized are biomarkers of epileptogenic brain, and are associated with SOZ and surgical outcome. Classification of HFOs into physiological or pathological remains challenging. Classification of tissue under individual electrodes was demonstrated to be feasible. The open source data and algorithms provide a resource for future studies.
RI Jurak, Pavel/AAO-3084-2020; Jurák, Pavel/G-1466-2014; Van Gompel,
   Jamie/AAW-4459-2020; Cimbalnik, Jan/H-6831-2016; Kremen,
   Vaclav/G-7612-2017; Cimbalnik, Jan/N-5753-2019
OI Jurak, Pavel/0000-0002-3793-5075; Jurák, Pavel/0000-0002-3793-5075; Van
   Gompel, Jamie/0000-0001-8087-7870; Cimbalnik, Jan/0000-0001-6670-6717;
   Kremen, Vaclav/0000-0001-9844-7617; Cimbalnik, Jan/0000-0001-6670-6717;
   Brinkmann, Benjamin/0000-0002-2392-8608
SN 2328-9503
PD SEP
PY 2018
VL 5
IS 9
BP 1062
EP 1076
DI 10.1002/acn3.618
UT WOS:000444941200005
PM 30250863
ER

PT J
AU Alashban, AA
   Alotaibi, YA
AF Alashban, Adal A.
   Alotaibi, Yousef A.
TI A Deep Learning Approach for Identifying and Discriminating Spoken
   Arabic Among Other Languages
SO IEEE ACCESS
AB Spoken Language Identification (SLID) is an important step in speech-to-speech translation systems and multi-lingual automatic speech recognition. In recent research, deep learning mechanisms have been the prevailing approaches for spoken language identification. This paper aims to study, detect, and analyze spoken languages similar to Arabic in pronouncing certain words and then proposes a deep learning-based architecture, specifically the Bidirectional Long Short Term Memory (BLSTM), for spoken Arabic language identification and discrimination between these similar languages, namely, German, Spanish, French, and Russian, all of which are taken from Mozilla speech corpus languages. Additionally, our work involves a linguistic study of these considered languages. A total of ten thousand speakers are chosen for all five languages, and the BLSTM architecture is designed and implemented using acoustic signal features and applied to five experiments in this paper. The results show a precision of 98.97%, 98.73%, 98.47%, and 99.75% for identifying the spoken Arabic language separately along with German, Spanish, French, and Russian, respectively. Additionally, we achieved an average accuracy of 95.15% for discriminating between all these considered five languages in terms of the pronunciation of words. Our findings confirm that a BLSTM architecture is able to distinguish between observable similar pronunciations of words in considered languages.
SN 2169-3536
PY 2023
VL 11
BP 11613
EP 11628
DI 10.1109/ACCESS.2023.3241855
UT WOS:000932815000001
ER

PT J
AU Wu, B
   Wang, ZK
   Chen, K
   Yan, CG
   Liu, WQ
AF Wu, Bi
   Wang, Zhengkuan
   Chen, Ke
   Yan, Chenggang
   Liu, Weiqiang
TI GBC: An Energy-Efficient LSTM Accelerator With Gating Units Level
   Balanced Compression Strategy
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
AB Recurrent Neural Networks (RNNs) have emerged as one of the most popular neural networks for processing timeseries problems, widely used in machine translation, automatic speech recognition, and other natural language processing applications. However, conventional RNNs suffered from vanishing and exploding gradients, resulting in poor network performance in applications with long-term input information. As a variant of RNN, Long Short-Term Memory (LSTM) had been proposed to tackle this issue. Nevertheless, at the same time, LSTM introduces gating units and many additional parameters, which makes it challenging to be implemented directly on resource-limited platforms, such as Field Programmable Gate Arrays (FPGAs). This work first investigated the overall maximum achievable compression rates of different gating units and their correlations. Then, Gating Units Level Balanced Compression (GBC) strategy is proposed. After Top- k pruning, the proposed GBC strategy can attain a compression rate of 36.6x for LSTM. Further, the theoretical analysis indicates that for the existing gating units level LSTM compression variants, the GBC strategy still has further potential for compression. A complementary compression of the GBC strategy is performed on the existing coupled-gate LSTM to verify the analysis. Experimental results show that GBC achieves an additional 32x (overall 42.7x) compression rate with negligible accuracy loss. Finally, hardware experiments conducted on Xilinx ADM-PCIE-7V3 FPGAs also demonstrate that the accelerator designed in this paper achieves an improvement of 7.4%-191.5% in energy efficiency compared to the state-ofthe-art designs.
OI Wang, Zhengkuan/0000-0002-1999-1065; Wu, Bi/0000-0001-9972-0478; Liu,
   Weiqiang/0000-0001-8398-8648
SN 1549-8328
EI 1558-0806
PD SEP
PY 2022
VL 69
IS 9
BP 3655
EP 3665
DI 10.1109/TCSI.2022.3181975
EA JUN 2022
UT WOS:000826450200001
ER

PT J
AU Choi, J
   Ha Kim, D
   Lee, S
   Lee, SH
   Song, BC
AF Choi, Jaewoong
   Ha Kim, Dae
   Lee, Sanghyuk
   Lee, Sang Hyuk
   Song, Byung Cheol
TI Synthesized rain images for deraining algorithms
SO NEUROCOMPUTING
AB Since most of the rainy scene datasets used for training single image rain removal (SIRR) algorithms are constructed by blending artificial rain streaks with source images, it is difficult for a machine trained with such datasets to understand the patterns of real or realistic rain streaks. So, several studies have been attempted to build a real rainy scene dataset. However, since collecting real rainy scenes itself requires significant costs, the real rainy scene datasets provided by some studies cover only very limited rainy environment(s). This paper presents a new approach to synthesize realistic rainy scenes using GAN, which is a world-first attempt as far as we know. The proposed method builds a representation space to which rain streaks of multiple styles are smoothly mapped by learning the distributions of various rain datasets. The representation space allows control over the generated rain streaks. Also, the proposed method can synthesize multiple rainy scenes per clean (source) scene simultaneously, thereby a synthesized rain image dataset (SyRa) (Dataset can be found here: https://github.com/jaewoong1/SyRaSynthesized_Rain_dataset) consisting of 11 K clean images and 55 K rainy images was constructed. Finally, this paper provides benchmarking results of several SIRR methods trained with SyRa. This result will be very useful for developing SIRR algorithms that can cope well with the actual rain environment.(c) 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
SN 0925-2312
EI 1872-8286
PD JUL 1
PY 2022
VL 492
BP 421
EP 439
DI 10.1016/j.neucom.2022.04.034
EA APR 2022
UT WOS:000796353500003
ER

PT J
AU Mahmood, A
   Khan, HU
   Rehman, ZU
   Iqbal, K
   Faisal, CMS
AF Mahmood, Ahsan
   Khan, Hikmat Ullah
   Rehman, Zahoor Ur
   Iqbal, Khalid
   Faisal, Ch. Muhmmad Shahzad
TI KEFST: a knowledge extraction framework using finite-state transducers
SO ELECTRONIC LIBRARY
AB Purpose The purpose of this research study is to extract and identify named entities from Hadith literature. Named entity recognition (NER) refers to the identification of the named entities in a computer readable text having an annotation of categorization tags for information extraction. NER is an active research area in information management and information retrieval systems. NER serves as a baseline for machines to understand the context of a given content and helps in knowledge extraction. Although NER is considered as a solved task in major languages such as English, in languages such as Urdu, NER is still a challenging task. Moreover, NER depends on the language and domain of study; thus, it is gaining the attention of researchers in different domains. Design/methodology/approach This paper proposes a knowledge extraction framework using finite-state transducers (FSTs) - KEFST - to extract the named entities. KEFST consists of five steps: content extraction, tokenization, part of speech tagging, multi-word detection and NER. An extensive empirical analysis using the data corpus of Urdu translation of Sahih Al-Bukhari, a widely known hadith book, reveals that the proposed method effectively recognizes the entities to obtain better results. Findings The significant performance in terms of f-measure, precision and recall validates that the proposed model outperforms the existing methods for NER in the relevant literature. Originality/value This research is novel in this regard that no previous work is proposed in the Urdu language to extract named entities using FSTs and no previous work is proposed for Urdu hadith data NER.
RI Mahmood, Ahsan/Y-7249-2019; Iqbal, Khalid/AAF-4040-2021; Khan, Hikmat
   Ullah/GZG-2251-2022; rehman, zahoor/AAE-2164-2021
OI Mahmood, Ahsan/0000-0002-1229-7484; rehman, zahoor/0000-0001-9968-0330;
   Khan, Hikmat/0000-0002-8178-6652
SN 0264-0473
EI 1758-616X
PD APR 1
PY 2019
VL 37
IS 2
BP 365
EP 384
DI 10.1108/EL-10-2018-0196
UT WOS:000479299400010
ER

PT S
AU Katuwawala, A
   Ghadermarzi, S
   Kurgan, L
AF Katuwawala, Akila
   Ghadermarzi, Sina
   Kurgan, Lukasz
BE Uversky, VN
TI Computational prediction of functions of intrinsically disordered
   regions
SO DANCING PROTEIN CLOUDS: INTRINSICALLY DISORDERED PROTEINS IN HEALTH AND
   DISEASE, PT A
SE Progress in Molecular Biology and Translational Science
AB Intrinsically disorder regions (IDRs) are abundant in nature, particularly among Eukaryotes. While they facilitate a wide spectrum of cellular functions including signaling, molecular assembly and recognition, translation, transcription and regulation, only several hundred IDRs are annotated functionally. This annotation gap motivates the development of fast and accurate computational methods that predict IDR functions directly from protein sequences. We introduce and describe a comprehensive collection of 25 methods that provide accurate predictions of IDRs that interact with proteins and nucleic acids, that function as flexible linkers and that moonlight multiple functions. Virtually all of these predictors can be accessed online and many were developed in the last few years. They utilize a wide range of predictive architectures and take advantage of modern machine learning algorithms. Our empirical analysis shows that predictors that are available as webservers enjoy high rates of citations, attesting to their practical value and popularity. The most cited methods include DISOPRED3, ANCHOR, alpha-MoRFpred, MoRFpred, fMoRFpred and MoRFCHiBi. We present two case studies to demonstrate that predictions produced by these computational tools are relatively easy to interpret and that they deliver valuable functional clues. However, the current computational tools cover a relatively narrow range of disorder functions. Further development efforts that would cover a broader range of functions should be pursued. We demonstrate that a sufficient amount of functionally annotated IDRs that are associated with several other disorder functions is already available and can be used to design and validate novel predictors.
RI Ghadermarzi, Sina/AAV-7643-2021; Kurgan, Lukasz/B-5721-2009
OI Kurgan, Lukasz/0000-0002-7749-0314
SN 1877-1173
BN 978-0-12-816851-6
PY 2019
VL 166
BP 341
EP 369
DI 10.1016/bs.pmbts.2019.04.006
UT WOS:000486242200010
PM 31521235
ER

PT J
AU Anselmi, F
   Leibo, JZ
   Rosasco, L
   Mutch, J
   Tacchetti, A
   Poggio, T
AF Anselmi, Fabio
   Leibo, Joel Z.
   Rosasco, Lorenzo
   Mutch, Jim
   Tacchetti, Andrea
   Poggio, Tomaso
TI Unsupervised learning of invariant representations
SO THEORETICAL COMPUTER SCIENCE
AB The present phase of Machine Learning is characterized by supervised learning algorithms relying on large sets of labeled examples (n -> infinity). The next phase is likely to focus on algorithms capable of learning from very few labeled examples (n -> 1), like humans seem able to do. We propose an approach to this problem and describe the underlying theory, based on the unsupervised, automatic learning of a "good" representation for supervised learning, characterized by small sample complexity. We consider the case of visual object recognition, though the theory also applies to other domains like speech. The starting point is the conjecture, proved in specific cases, that image representations which are invariant to translation, scaling and other transformations can considerably reduce the sample complexity of learning. We prove that an invariant and selective signature can be computed for each image or image patch: the invariance can be exact in the case of group transformations and approximate under non-group transformations. A module performing filtering and pooling, like the simple and complex cells described by Hubel and Wiesel, can compute such signature. The theory offers novel unsupervised learning algorithms for "deep" architectures for image and speech recognition. We conjecture that the main computational goal of the ventral stream of visual cortex is to provide a hierarchical representation of new objects/images which is invariant to transformations, stable, and selective for recognition and show how this representation may be continuously learned in an unsupervised way during development and visual experience. (C) 2015 Elsevier B.V. All rights reserved.
OI Leibo, Joel/0000-0002-3153-916X; Anselmi, Fabio/0000-0002-0264-4761
SN 0304-3975
EI 1879-2294
PD JUN 20
PY 2016
VL 633
SI SI
BP 112
EP 121
DI 10.1016/j.tcs.2015.06.048
UT WOS:000377840700011
ER

PT J
AU Smyth, F
AF Smyth, Fiona
TI More than "a Machine for living in": Science, noise and experimental
   housing in 1930s Britain
SO CONSTRUCTION HISTORY-INTERNATIONAL JOURNAL OF THE CONSTRUCTION HISTORY
   SOCIETY
AB Burbage House, a four-storey block of flats on the banks of Regent's Canal in London, holds a noteworthy position in the history of building science and acoustics. Designed in the 1930s as a social housing development to replace the slums in Shoreditch, Burbage House was an experimental prototype, constituting one of the earliest developments in Britain wherein new sound insulation techniques were tested under working conditions. The outcomes of the research at Burbage House had implications both for subsequent experimental work on acoustics and sound insulation, and for the translation of that work into guidelines for construction practice.
   Burbage House was designed and constructed against a backdrop of controversy. The detrimental effects on population health of increasing levels of noise pollution were subject to frequent airing in the national press and medical journals. Practical guidelines for mitigating the problem through sound insulation in dwellings, published in a prominent architectural journal in 1935, had been met with some degree of animosity, provoking trenchant and opposing views from the journal's readers. Nevertheless, that furore did contribute to the scientific development of proprietary materials and construction methods for improving standards in sound insulation.
   This paper presents an overview of the social and scientific context in which the earliest British construction standards for sound insulation evolved. It discusses the first official recommendations designed to reduce noise in dwellings, the controversy surrounding their publication, and the experimental work which underpinned the development of minimum performance standards.
SN 0267-7768
PY 2014
VL 29
IS 2
BP 103
EP 120
UT WOS:000358701400008
ER

PT J
AU Chen, XS
   Brown, CM
AF Chen, Xiaowei Sylvia
   Brown, Chris M.
TI Computational identification of new structured cis-regulatory elements
   in the 3'-untranslated region of human protein coding genes
SO NUCLEIC ACIDS RESEARCH
AB Messenger ribonucleic acids (RNAs) contain a large number of cis-regulatory RNA elements that function in many types of post-transcriptional regulation. These cis-regulatory elements are often characterized by conserved structures and/or sequences. Although some classes are well known, given the wide range of RNA-interacting proteins in eukaryotes, it is likely that many new classes of cis-regulatory elements are yet to be discovered. An approach to this is to use computational methods that have the advantage of analysing genomic data, particularly comparative data on a large scale. In this study, a set of structural discovery algorithms was applied followed by support vector machine (SVM) classification. We trained a new classification model (CisRNA-SVM) on a set of known structured cis-regulatory elements from 3'-untranslated regions (UTRs) and successfully distinguished these and groups of cis-regulatory elements not been strained on from control genomic and shuffled sequences. The new method outperformed previous methods in classification of cis-regulatory RNA elements. This model was then used to predict new elements from cross-species conserved regions of human 3'-UTRs. Clustering of these elements identified new classes of potential cis-regulatory elements. The model, training and testing sets and novel human predictions are available at: ext-link-type="uri" xlink:href="http://mRNA.otago.ac.nz/CisRNA-SVM" xmlns:xlink="http://www.w3.org/1999/xlink">http://mRNA.otago.ac.nz/CisRNA-SVM.
OI Brown, Chris M/0000-0003-0079-7067
SN 0305-1048
EI 1362-4962
PD OCT
PY 2012
VL 40
IS 18
BP 8862
EP 8873
DI 10.1093/nar/gks684
UT WOS:000309927100016
PM 22821558
ER

PT J
AU Fernandis, AZ
   Wenk, MR
AF Fernandis, Aaron Zefrin
   Wenk, Markus Rene
TI Lipid-based biomarkers for cancer
SO JOURNAL OF CHROMATOGRAPHY B-ANALYTICAL TECHNOLOGIES IN THE BIOMEDICAL
   AND LIFE SCIENCES
AB Lipids play important and diverse roles in cells. Most obvious functions are storage of chemical energy, provision of structural support of biological membranes and signaling. All these cellular processes are of critical relevance to cells which undergo transformation, cancer progression and metastasis. Thus, it is likely that certain classes of lipids are reflective for the cellular physiology in cancer cells and tissue. Here we discuss key roles of lipids involved in cancer as well as challenges for development of novel lipid-based biomarkers. Special emphasis will be given to mass spectrometry based analysis of lipids. Such technology has been successfully used for qualitative and quantitative analysis of lipids with very different chemistries. Comparative analysis, often in case-control regimes, and either in non-targeted (e.g. by liquid chrormatography-single stage mass spectrometry) or targeted (i.e. by tandem mass spectrometry) fashion yields vast at-rays of information. Uni-variate (such as Student's t-test or Mann-Whitney U-test) and multivariate statistics (principal components analysis, machine learning and regression analysis) are next used to identify variations in individual lipid species and/or to lower dimensions for visualization and grouping of cases and controls. As a result surrogate (single or multi-parameter) markers are identified which form the basis for functional validation as well as potential translation to alternative analytical readouts. (C) 2009 Elsevier B.V. All rights reserved.
RI Fernandis, Aaron/C-3718-2012; Wenk, Markus Rene/D-1441-2014
SN 1570-0232
EI 1873-376X
PD SEP 15
PY 2009
VL 877
IS 26
BP 2830
EP 2835
DI 10.1016/j.jchromb.2009.06.015
UT WOS:000269224200016
PM 19570730
ER

PT J
AU Schalk, G
   Brunner, P
   Gerhardt, LA
   Bischof, H
   Wolpaw, JR
AF Schalk, G.
   Brunner, P.
   Gerhardt, L. A.
   Bischof, H.
   Wolpaw, J. R.
TI Brain-computer interfaces (BCIs): Detection instead of classification
SO JOURNAL OF NEUROSCIENCE METHODS
AB Many studies over the past two decades have shown that people can use brain signals to convey their intent to a computer through brain-computer interfaces (BCIs). These devices operate by recording signals from the brain and translating these signals into device commands. They can be used by people who are severely paralyzed to communicate without any use of muscle activity. One of the major impediments in translating this novel technology into clinical applications is the current requirement for preliminary analyses to identify the brain signal features best suited for communication. This paper introduces and validates signal detection, which does not require such analysis procedures, as a new concept in BCI signal processing. This detection concept is realized with Gaussian mixture models (GMMs) that are used to model resting brain activity so that any change in relevant brain signals can be detected. It is implemented in a package called SIGFRIED (SIGnal modeling For Real-time Identification and Event Detection). The results indicate that SIGFRIED produces results that are within the range of those achieved using a common analysis strategy that requires preliminary identification of signal features. They indicate that such laborious analysis procedures could be replaced by merely recording brain signals during rest. In summary, this paper demonstrates how SIGFRIED could be used to overcome one of the present impediments to translation of laboratory BCI demonstrations into clinically practical applications. (C) 2007 Published by Elsevier B.V.
OI Wolpaw, Jonathan/0000-0003-0805-1315; Bischof,
   Horst/0000-0002-9096-6671; Schalk, Gerwin/0000-0003-3443-9487; Brunner,
   Peter/0000-0002-2588-2754
SN 0165-0270
EI 1872-678X
PD JAN 15
PY 2008
VL 167
IS 1
BP 51
EP 62
DI 10.1016/j.jneumeth.2007.08.010
UT WOS:000252164300007
PM 17920134
ER

PT J
AU Cai, HX
   Shao, Z
   Vaynberg, A
AF Cai, Hongxu
   Shao, Zhong
   Vaynberg, Alexander
TI Certified self-modifying code
SO ACM SIGPLAN NOTICES
CT Conference on Programming Language Design and Implementation
CY JUN 10-13, 2007
CL San Diego, CA
SP ACM SIGPLAN
AB Self-modifying code (SMC), in this paper, broadly refers to any program that loads, generates, or mutates code at runtime. It is widely used in many of the world's critical software systems to support runtime code generation and optimization, dynamic loading and linking, OS boot loader, just-in-time compilation, binary translation, or dynamic code encryption and obfuscation. Unfortunately, SMC is also extremely difficult to reason about: existing formal veri. cation techniques-including Hoare logic and type system consistently assume that program code stored in memory is fixed and immutable; this severely limits their applicability and power.
   This paper presents a simple but novel Hoare-logic-like framework that supports modular veri. cation of general von-Neumann machine code with runtime code manipulation. By dropping the assumption that code memory is fixed and immutable, we are forced to apply local reasoning and separation logic at the very beginning, and treat program code uniformly as regular data structure. We address the interaction between separation and code memory and show how to establish the frame rules for local reasoning even in the presence of SMC. Our framework is realistic, but designed to be highly generic, so that it can support assembly code under all modern CPUs (including both x86 and MIPS). Our system is expressive and fully mechanized. We prove its soundness in the Coq proof assistant and demonstrate its power by certifying a series of realistic examples and applications-all of which can directly run on the SPIM simulator or any stock x86 hardware.
SN 0362-1340
EI 1558-1160
PD JUN
PY 2007
VL 42
IS 6
BP 66
EP 77
DI 10.1145/1273442.1250743
UT WOS:000253409000009
ER

PT J
AU Kimura, N
   Iwatsuki, N
AF Kimura, Naoto
   Iwatsuki, Nobuyuki
TI Design of cable-driven active flexibly-constrained pairs with non-linear
   stiffness in multiple directions
SO MECHANICAL ENGINEERING JOURNAL
AB In order to synthesize a human-friendly flexible machine with a simple structure, the flexibly constrained pair (FCP), which is a passive kinematic pair with a flexible kinematic constraint in multiple directions, has been proposed as a novel type of a kinematic pair (Kimura et al, 2021a). However, structures of robots with FCPs must be limited to only closed-loop mechanisms because the FCP is a passive kinematic pair. As a novel kinematic pair to solve this problem, the active flexibly constrained pair (AFCP) is proposed in this paper. This kinematic pair is used as an underactuated active joint mechanism antagonistically driven with several active elastic elements. As active elastic elements for the AFCP, reeled elastic wires with linear elasticity are used to simplify its design and control. In order to design it, a method to optimally arrange reeled elastic wires between the links of the underactuated joint based on a transmission index is proposed. Besides, a method to specify the stiffness required to perform the task in active degrees of freedom (DOF) and the stiffness to balance both flexibility and motion accuracy in passive DOF is proposed. In addition, a method to analyze the kinetostatic motion between the links is proposed to evaluate the motion accuracy of the designed AFCP. As examples, the AFCP with 1-axial main rotation and the AFCP with 1-axial translation along the specified trajectory are designed and analyzed. Finally, they are prototyped, and their performances are examined by experiments.
SN 2187-9745
DI 10.1299/mej.22-00132
EA OCT 2022
UT WOS:000870141900001
ER

PT J
AU Abdelmotaal, H
   Sharaf, M
   Soliman, W
   Wasfi, E
   Kedwany, SM
AF Abdelmotaal, Hazem
   Sharaf, Mohamed
   Soliman, Wael
   Wasfi, Ehab
   Kedwany, Salma M.
TI Bridging the resources gap: deep learning for fluorescein angiography
   and optical coherence tomography macular thickness map image translation
SO BMC OPHTHALMOLOGY
AB Background To assess the ability of the pix2pix generative adversarial network (pix2pix GAN) to synthesize clinically useful optical coherence tomography (OCT) color-coded macular thickness maps based on a modest-sized original fluorescein angiography (FA) dataset and the reverse, to be used as a plausible alternative to either imaging technique in patients with diabetic macular edema (DME). Methods Original images of 1,195 eyes of 708 nonconsecutive diabetic patients with or without DME were retrospectively analyzed. OCT macular thickness maps and corresponding FA images were preprocessed for use in training and testing the proposed pix2pix GAN. The best quality synthesized images using the test set were selected based on the Frechet inception distance score, and their quality was studied subjectively by image readers and objectively by calculating the peak signal-to-noise ratio, structural similarity index, and Hamming distance. We also used original and synthesized images in a trained deep convolutional neural network (DCNN) to plot the difference between synthesized images and their ground-truth analogues and calculate the learned perceptual image patch similarity metric. Results The pix2pix GAN-synthesized images showed plausible subjectively and objectively assessed quality, which can provide a clinically useful alternative to either image modality. Conclusion Using the pix2pix GAN to synthesize mutually dependent OCT color-coded macular thickness maps or FA images can overcome issues related to machine unavailability or clinical situations that preclude the performance of either imaging technique.
OI Abdelmotaal, Hazem/0000-0002-7429-3796; Sharaf,
   Mohamed/0000-0003-0390-5676
EI 1471-2415
PD SEP 1
PY 2022
VL 22
IS 1
AR 355
DI 10.1186/s12886-022-02577-7
UT WOS:000848742100001
PM 36050661
ER

PT J
AU Romera-Giner, S
   Martinez, ZA
   Garcia-Garcia, F
   Hidalgo, MR
AF Romera-Giner, Sergio
   Andreu Martinez, Zoraida
   Garcia-Garcia, Francisco
   Hidalgo, Marta R.
TI Common pathways and functional profiles reveal underlying patterns in
   Breast, Kidney and Lung cancers
SO BIOLOGY DIRECT
AB Background Cancer is a major health problem which presents a high heterogeneity. In this work we explore omics data from Breast, Kidney and Lung cancers at different levels as signalling pathways, functions and miRNAs, as part of the CAMDA 2019 Hi-Res Cancer Data Integration Challenge. Our goal is to find common functional patterns which give rise to the generic microenvironment in these cancers and contribute to a better understanding of cancer pathogenesis and a possible clinical translation down further studies. Results After a tumor versus normal tissue comparison of the signaling pathways and cell functions, we found 828 subpathways, 912 Gene Ontology terms and 91 Uniprot keywords commonly significant to the three studied tumors. Such features interestingly show the power to classify tumor samples into subgroups with different survival times, and predict tumor state and tissue of origin through machine learning techniques. We also found cancer-specific alternative activation subpathways, such as the ones activating STAT5A in ErbB signaling pathway. miRNAs evaluation show the role of miRNAs, such as mir-184 and mir-206, as regulators of many cancer pathways and their value in prognoses. Conclusions The study of the common functional and pathway activities of different cancers is an interesting approach to understand molecular mechanisms of the tumoral process regardless of their tissue of origin. The existence of platforms as the CAMDA challenges provide the opportunity to share knowledge and improve future scientific research and clinical practice.
RI Hidalgo, Marta R./ABD-4233-2021; García-García, Francisco/N-2263-2019
OI Hidalgo, Marta R./0000-0002-5801-7804; García-García,
   Francisco/0000-0001-8354-5636; Romera Giner, Sergio/0000-0002-5452-8543
EI 1745-6150
PD MAY 26
PY 2021
VL 16
IS 1
AR 9
DI 10.1186/s13062-021-00293-8
UT WOS:000655075700001
PM 34039407
ER

PT C
AU Lushanthan, S
   Weerasinghe, AR
   Herath, DL
AF Lushanthan, S.
   Weerasinghe, A. R.
   Herath, D. L.
GP IEEE
TI Morphological Analyzer and Generator for Tamil Language
SO 14TH INTERNATIONAL CONFERENCE ON ADVANCES IN ICT FOR EMERGING REGIONS
   (ICTER) 2014
SE International Conference on Advances in ICT for Emerging Regions
CT 14th International Conference on Advances in ICT for Emerging Regions
   (ICTer) 2014
CY DEC 10-13, 2014
CL BMICH, Colombo, SRI LANKA
SP IEEE Sri Lanka Sect, CODEGEN, Combio Healthcare Syst, WSO2, IFS
HO BMICH
AB Morphological analysis is an essential component in Natural Language Processing (NLP) applications ranging from spell checker to machine translation. When performing a morphological analysis it leads to segmentation of a word into morphemes, combined with an analysis of the attachments of these morphemes. In English language the complexity of the formation of words is not much higher compared with Indic languages. Hence, Tamil language too does have its complexities when building up a NLP application. The morphemes in the language, the rules how these morphemes are connected and the changes occur when they attach together are the important factors that need to be considered when building up a Morphological Analyzer for any language. Our "Morphological Analyzer and Generator for Tamil Language" will be generating the word forms of a stem/root, given a particular context and at the same time, a surface form in Tamil language should get analyzed into its proper context. This model tries to cover only the nouns and verbs in the Tamil language.
   This paper illustrates how the lexicon and the orthographic rules of Tamil language have been written as regular expressions using only finite state operations and how this approach has been implemented to develop a morphological analyzer/generator. This model is built using the Xerox toolkit, which uses "Two-level Morphology", and almost 2000 noun stems and 96 verb stems have been incorporated into the network. A noun stem now produces about 40 different forms and a verb stem produces up to 240 forms. We have also defined our own transliteration scheme for this purpose.
SN 2377-6854
BN 978-1-4799-7732-1
PY 2014
BP 190
EP 196
UT WOS:000380507000029
ER

PT J
AU Price, J
   Gordon, NC
   Crook, D
   Llewelyn, M
   Paul, J
AF Price, J.
   Gordon, N. Claire
   Crook, D.
   Llewelyn, M.
   Paul, J.
TI The usefulness of whole genome sequencing in the management of
   Staphylococcus aureus infections
SO CLINICAL MICROBIOLOGY AND INFECTION
AB Staphylococcus aureus remains a leading cause of hospital-acquired and community-associated infection worldwide. The burden of disease is exacerbated by the emergence of virulent strains with reduced susceptibility to commonly used antibiotics and their dissemination in healthcare settings and in the community. Whole genome sequencing (WGS) has the potential to revolutionize our understanding and management of S.aureus infection. As a research tool, WGS has provided insights into the origins of antibiotic-resistant strains, the genetic basis of virulence, the emergence and spread of lineages, and the population structure of S.aureus. As a frontline tool, WGS offers the prospect of a method that could be used to predict resistance, assess virulence, and type isolates at the highest possible resolution. The results generated could be used to guide clinical management and infection control practice. Studies using bench-top sequencing machines have already demonstrated the feasibility of such approaches. Infection control management is compromised by our incomplete understanding of transmission, which in turn reflects the suboptimal resolution offered by conventional typing methods. As the costs of sequencing begin to approach those of conventional methods, high-resolution typing with WGS could realistically be implemented for hospital infection control, as well as for local and national surveillance practice. Translation into routine practice will require the development of a knowledge base, reliable automated bioinformatic tools, the capacity to store, exchange and interrogate large volumes of genomic data, and an acceptance of WGS by clinicians, infection control specialists, and laboratory staff.
RI Llewelyn, Martin/Y-1472-2019; Llewelyn, Martin/A-7194-2011
OI Llewelyn, Martin/0000-0002-6811-1124; Gordon,
   Nicola/0000-0001-8266-3630; peto, tim/0000-0003-3477-8307; Price,
   James/0000-0003-2541-8545
SN 1198-743X
EI 1469-0691
PD SEP
PY 2013
VL 19
IS 9
BP 784
EP 789
DI 10.1111/1469-0691.12109
UT WOS:000323201300012
PM 23331482
ER

PT C
AU Chen, QF
   Wu, J
   Huang, FH
   Han, Y
   Zhao, QM
AF Chen, Qingfeng
   Wu, Jing
   Huang, Feihu
   Han, Yu
   Zhao, Qiming
BE Memmi, G
   Yang, B
   Kong, L
   Zhang, T
   Qiu, M
TI Multi-layer LSTM Parallel Optimization Based on Hardware and Software
   Cooperation
SO KNOWLEDGE SCIENCE, ENGINEERING AND MANAGEMENT, PT II
SE Lecture Notes in Artificial Intelligence
CT 15th International Conference on Knowledge Science, Engineering, and
   Management (KSEM)
CY AUG 06-08, 2022
CL Singapore, SINGAPORE
SP Springer, Nanyang Technol Univ, Princeton Univ
AB LSTM's special gate structure and memory unit make it suitable for solving problems that are related to time series. It has excellent performance in the fields of machine translation and reasoning. However, LSTM also has some shortcomings, such as low parallelism, which leads to insufficient computing speed. Some existing optimization ideas only focus on one of the software and hardware. The former mostly focuses on model accuracy, and CPU accelerated LSTM doesn't dynamically adjust to network characteristics; While the latter can be based on the LSTM model structure. Customized accelerators are often limited by the structure of LSTM and cannot fully utilize the advantages of the hardware. This paper proposed a multi-layer LSTM optimization scheme based on the idea of software and hardware collaboration. We used the pruning by row scheme to greatly reduce the number of parameters while ensuring accuracy, making it adapt to the parallel structure of the hardware. From the perspective of software, the multi-layer LSTM module was analyzed. It was concluded that some neurons in different layers could be calculated in parallel. Therefore, this paper redesigned the computational order of the multilayer LSTM so that the model guaranteed its own timing properly and it was hardware friendly at the same time. Experiments showed that our throughput increased by 10x compared with the CPU implementation. Compared with other hardware accelerators, the throughput increased by 1.2x-1.4x, and the latency and resource utilization had also been improved.
SN 0302-9743
EI 1611-3349
BN 978-3-031-10986-7; 978-3-031-10985-0
PY 2022
VL 13369
BP 681
EP 693
DI 10.1007/978-3-031-10986-7_55
UT WOS:000877369500055
ER

PT J
AU Rajgor, AD
   Patel, S
   Mcculloch, D
   Obara, B
   Bacardit, J
   Mcqueen, A
   Aboagye, E
   Ali, T
   O'Hara, J
   Hamilton, DW
AF Rajgor, Amarkumar Dhirajlal
   Patel, Shreena
   Mcculloch, David
   Obara, Boguslaw
   Bacardit, Jaume
   Mcqueen, Andrew
   Aboagye, Eric
   Ali, Tamir
   O'Hara, James
   Hamilton, David Winston
TI The application of radiomics in laryngeal cancer
SO BRITISH JOURNAL OF RADIOLOGY
AB Objectives: Radiomics is the conversion of medical images into quantitative high-dimensional data. Laryngeal cancer, one of the most common head and neck cancers, has risen globally by 58.7%. CT, MRI and PET are acquired during the diagnostic process providing potential data for radiomic analysis and correlation with outcomes.
   This review aims to examine the applications of this technique to laryngeal cancer and the future considerations for translation into clinical practice.
   Methods: A comprehensive systematic review-informed search of the MEDLINE and EMBASE databases was undertaken. Keywords "laryngeal cancer" OR "larynx" OR "larynx cancer" OR "head and neck cancer" were combined with "radiomic" OR "signature" OR ''machine learning" OR "artificial intelligence", Additional articles were obtained from bibliographies using the ''snowball method",
   Results: The included studies (n = 15) demonstrated that radiomic features are significantly associated with various clinical outcomes (including stage, overall survival, treatment response, progression-free survival) and that predictive models incorporating radiomic features are superior to those that do not. Two studies demonstrated radiomics could improve laryngeal cancer staging whilst 12 studies affirmed its predictive capability for clinical outcomes,
   Conclusions: Radiomics has potential for improving multiple aspects of laryngeal cancer care; however, the heterogeneous cohorts and lack of data on laryngeal cancer exclusively inhibits firm conclusions. Large prospective well-designed studies in laryngeal cancer are required to progress this field. Furthermore, to implement radiomics into clinical practice, a unified research effort is required to standardise radiomics practice.
   Advances in knowledge: This review has highlighted the value of radiomics in enhancing laryngeal cancer care (including staging, prognosis and predicting treatment response).
OI Rajgor, Amarkumar D/0000-0002-9323-3107; ABOAGYE,
   Eric/0000-0003-2276-6771; Obara, Boguslaw/0000-0003-4084-7778
SN 0007-1285
EI 1748-880X
PD DEC 1
PY 2021
VL 94
IS 1128
AR 20210499
DI 10.1259/bjr.20210499
UT WOS:000721546400003
PM 34586899
ER

PT J
AU Kalinin, SV
   Kelley, K
   Vasudevan, RK
   Ziatdinov, M
AF Kalinin, Sergei, V
   Kelley, Kyle
   Vasudevan, Rama K.
   Ziatdinov, Maxim
TI Toward Decoding the Relationship between Domain Structure and
   Functionality in Ferroelectrics via Hidden Latent Variables
SO ACS APPLIED MATERIALS & INTERFACES
AB Polarization switching mechanisms in ferroelectric materials are fundamentally linked to local domain structure and the presence of the structural defects, which both can act as nucleation and pinning centers and create local electrostatic and mechanical depolarization fields affecting wall dynamics. However, the general correlative mechanisms between domain structure and polarization dynamics are only weakly explored, precluding insight into the associated physical mechanisms. Here, the correlation between local domain structures and switching behavior in ferroelectric materials is explored using convolutional encoder-decoder networks, enabling image to spectral (im2spec) and spectral to image (spec2im) translations via encoding of latent variables. The latter reflect the assumption that the relationship between domain structure and polarization switching is parsimonious, i.e., is based upon a small number of local mechanisms. The analysis of latent variables distributions and their real-space representations provides insight into the predictability of the local switching behavior and hence associated physical mechanisms. We further pose that the regions where these correlative relationships are violated, i.e., predictability of the polarization dynamics from domain structure is reduced, represent the obvious target for detailed studies, e.g., in the context of automated experiments. This approach provides a workflow to establish the presence of correlation between local spectral responses and local structure and can be universally applied to spectral imaging techniques such as piezoresponse force microscopy (PFM), scanning tunneling microscopy (STM) and spectroscopy, and electron energy loss spectroscopy (EELS) in scanning transmission electron microscopy (STEM).
RI Ziatdinov, Maxim/L-1991-2016; Kalinin, Sergei/I-9096-2012
OI Ziatdinov, Maxim/0000-0003-2570-4592; Kalinin,
   Sergei/0000-0001-5354-6152
SN 1944-8244
EI 1944-8252
PD JAN 13
PY 2021
VL 13
IS 1
BP 1693
EP 1703
DI 10.1021/acsami.0c15085
EA JAN 2021
UT WOS:000611066000165
PM 33397080
ER

PT C
AU Li, BA
   Yan, M
   Xia, X
   Hu, X
   Li, G
   Lo, D
AF Li, Boao
   Yan, Meng
   Xia, Xin
   Hu, Xing
   Li, Ge
   Lo, David
BE Devanbu, P
   Cohen, M
   Zimmermann, T
TI DeepCommenter: A Deep Code Comment Generation Tool with Hybrid Lexical
   and Syntactical Information
SO PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE
   ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE
   ENGINEERING (ESEC/FSE '20)
CT 28th ACM Joint Meeting on European Software Engineering Conference and
   Symposium on the Foundations of Software Engineering (ESEC/FSE)
CY NOV 08-13, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGSOFT
AB As the scale of software projects increases, the code comments are more and more important for program comprehension. Unfortunately, many code comments are missing, mismatched or outdated due to tight development schedule or other reasons. Automatic code comment generation is of great help for developers to comprehend source code and reduce their workload. Thus, we propose a code comment generation tool (DeepCommenter) to generate descriptive comments for Java methods. DeepCommenter formulates the comment generation task as a machine translation problem and exploits a deep neural network that combines the lexical and structural information of Java methods.
   We implement DeepCommenter in the form of an Integrated Development Environment (i.e., Intellij IDEA) plug-in. Such plug-in is built upon a Client/Server architecture. The client formats the code selected by the user, sends request to the server and inserts the comment generated by the server above the selected code. The server listens for client's request, analyzes the requested code using the pre-trained model and sends back the generated comment to the client. The pre-trained model learns both the lexical and syntactical information from source code tokens and Abstract Syntax Trees (AST) respectively and combines these two types of information together to generate comments. To evaluate DeepCommenter, we conduct experiments on a large corpus built from a large number of open source Java projects on GitHub. The experimental results on different metrics show that DeepCommenter outperforms the state-of-the-art approaches by a substantial margin.
RI Lo, David/A-2493-2012
OI Lo, David/0000-0002-4367-7201
BN 978-1-4503-7043-1
PY 2020
BP 1571
EP 1575
DI 10.1145/3368089.3417926
UT WOS:000744432100140
ER

PT J
AU Petre, MA
   Bahrey, L
   Levine, M
   van Rensburg, A
   Crawford, M
   Matava, C
AF Petre, Maria-Alexandra
   Bahrey, Lisa
   Levine, Mark
   van Rensburg, Adriaan
   Crawford, Mark
   Matava, Clyde
TI A national survey on attitudes and barriers on recycling and
   environmental sustainability efforts among Canadian anesthesiologists:
   an opportunity for knowledge translation
SO CANADIAN JOURNAL OF ANESTHESIA-JOURNAL CANADIEN D ANESTHESIE
AB Anesthesia-related activities produce 25% of all operating room (OR) waste and contribute to environmental pollution and climate change. The aim of this study was to document Canadian anesthesiologists' current practice, attitudes towards, and perceived barriers regarding recycling of OR waste and environmental sustainability efforts.
   With Research Ethics Board approval, members of the Canadian Anesthesiologists' Society (CAS) completed an online survey consisting of 25 questions assessing current environmentally sustainable practices in anesthesiology and gaps, barriers, and interest in gaining further knowledge on this topic.
   Four hundred and twenty-six of 2,695 (16%) CAS members responded to the questionnaire. Despite a willingness to recycle at work among most anesthesiologists (393/403, 97.5%), only 122/403 (30.2%) did so. Other sustainability efforts in Canadian ORs included donating unused medical equipment and supplies to medical missions (198/400, 49.5%) and evening shut-off of anesthesia machines and other OR equipment (185/400, 46.3%). Reported barriers to recycling in the OR included a lack of support from hospital/OR leadership (254/400, 63.5%) and inadequate information/education (251/400, 62.8%). Only 122/389 (31.4%) of respondents were aware of any efforts to expand sustainability programs at their institutions but 273/395 (69.1%) of respondents indicated an interest in obtaining further education on the topic.
   Canadian anesthesiologists appear ready to incorporate environmental sustainability in their practice but indicate that significant barriers exist. Our study highlights the need for further educational programs and implementation strategies.
RI Matava, Clyde/AAK-9531-2020
OI Matava, Clyde/0000-0002-9502-0981
SN 0832-610X
EI 1496-8975
PD MAR
PY 2019
VL 66
IS 3
BP 272
EP 286
DI 10.1007/s12630-018-01273-9
UT WOS:000459035100004
PM 30547422
ER

PT J
AU Noah, SAM
   Ali, NM
   Hasan, MS
AF Noah, Shahrul Azman Mohd
   Ali, Nazlena Mohamad
   Hasan, Mohd Sabri
TI Generation of News Headline for Malay Language based on Term Features
SO GEMA ONLINE JOURNAL OF LANGUAGE STUDIES
AB Headline generation is an information extraction process to generate a single sentence that represents the content of a text. In Malay language context, research in this area is limited to machine translation approaches. This study is divided into three phases: analysis of news discourse, development of headline generation technique and evaluation of the quality of generated headlines. The study aims to develop headline using statistical and linguistic methods. The statistic method used to identify significant words and sentences based in term weighting approach. The linguistic method is used to increase its preciseness. 140 news and their corresponding headlines model were constructed. Analysis of the news collection shows that the main idea of written text can be identified based on four characteristics: word location in sentences, sentence location in texts, acronym word types and words that represent the person name. Significant words with main idea of written text are determined based on the words weighted values. The values are determined by combining the frequency of words and word location in sentences. The content of the first two sentences are suitable candidates for recognising important sentences in text. Results showed that mean percentage for important sentence recognition 82.9%, mean quality of generated headlines are 0.3194 (precision), 0.5656 (recall), 0.4012 (F-measure), 0.5656 (ROUGE-N), 0.3392 (ROUGE-L), 0.1186 (ROUGE-W) and 0.1232 (ROUGE-S). In conclusion, the consideration of language factors in headline generation technique is capable of producing quality headlines with higher degree of fidelity as compared to the compared benchmarks.
RI MOHAMAD ALI, NAZLENA/O-2653-2014; ALI, NAZLENA MOHAMAD/V-8532-2019; Mohd
   Noah, Shahrul Azman/ABA-2084-2021
OI MOHAMAD ALI, NAZLENA/0000-0002-2267-8328; ALI, NAZLENA
   MOHAMAD/0000-0002-2267-8328; Mohd Noah, Shahrul
   Azman/0000-0001-7683-4309
SN 1675-8021
PD NOV
PY 2018
VL 18
IS 4
BP 42
EP 59
DI 10.17576/gema-2018-1804-04
UT WOS:000451516200004
ER

PT J
AU Penney, GP
   Weese, J
   Little, JA
   Desmedt, P
   Hill, DLG
   Hawkes, DJ
AF Penney, GP
   Weese, J
   Little, JA
   Desmedt, P
   Hill, DLG
   Hawkes, DJ
TI A comparison of similarity measures for use in 2-D-3-D medical image
   registration
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
AB A comparison of six similarity measures for use in intensity-based two-dimensional-three-dimensional (2-D-3-D) image registration is presented. The accuracy of the similarity measures are compared to a "gold-standard" registration which has been accurately calculated using fiducial markers, The similarity measures are used to register a computed tomography (CT) scan of a spine phantom to a fluoroscopy image of the phantom, The registration is carried out within a region-of-interest in the fluoroscopy image which is user defined to contain a single vertebra. Many of the problems involved in this type of registration are caused by features which mere not modeled by a phantom image alone. More realistic "gold-standard" data sets were simulated using the phantom image with clinical image features overlaid. Results show that the introduction of soft-tissue structures and interventional instruments into the phantom image can have a large effect on the performance of some similarity measures previously applied to 2-D-3-D image registration, Two measures were able to register accurately and robustly even when soft-tissue structures and interventional instruments were present as differences between the images. These measures were pattern intensity and gradient difference, Their registration accuracy, for all the rigid-body parameters except for the source to film translation, was within a root-mean-square (rms) error of 0.54 mm or degrees to the "gold-standard" values. No failures occurred while registering using these measures.
OI Hill, Derek/0000-0003-1970-1432
SN 0278-0062
EI 1558-254X
PD AUG
PY 1998
VL 17
IS 4
BP 586
EP 595
DI 10.1109/42.730403
UT WOS:000077115900010
PM 9845314
ER

PT J
AU Wataganara, T
   Rekhawasin, T
   Sompagdee, N
   Viboonchart, S
   Phithakwatchara, N
   Nawapun, K
AF Wataganara, Tuangsit
   Rekhawasin, Thanapa
   Sompagdee, Nalat
   Viboonchart, Sommai
   Phithakwatchara, Nisarat
   Nawapun, Katika
TI A 10-Year Retrospective Review of Prenatal Applications, Current
   Challenges and Future Prospects of Three-Dimensional Sonoangiography
SO DIAGNOSTICS
AB Realistic reconstruction of angioarchitecture within the morphological landmark with three-dimensional sonoangiography (three-dimensional power Doppler; 3D PD) may augment standard prenatal ultrasound and Doppler assessments. This study aimed to (a) present a technical overview, (b) determine additional advantages, (c) identify current challenges, and (d) predict trajectories of 3D PD for prenatal assessments. PubMed and Scopus databases for the last decade were searched. Although 307 publications addressed our objectives, their heterogeneity was too broad for statistical analyses. Important findings are therefore presented in descriptive format and supplemented with the authors' 3D PD images. Acquisition, analysis, and display techniques need to be personalized to improve the quality of flow-volume data. While 3D PD indices of the first-trimester placenta may improve the prediction of preeclampsia, research is needed to standardize the measurement protocol. In highly experienced hands, the unique 3D PD findings improve the diagnostic accuracy of placenta accreta spectrum. A lack of quality assurance is the central challenge to incorporating 3D PD in prenatal care. Machine learning may broaden clinical translations of prenatal 3D PD. Due to its operator dependency, 3D PD has low reproducibility. Until standardization and quality assurance protocols are established, its use as a stand-alone clinical or research tool cannot be recommended.
RI Phithakwatchara, Nisarat/GNM-8223-2022
OI Wataganara, Tuangsit/0000-0001-7172-053X
EI 2075-4418
PD AUG
PY 2021
VL 11
IS 8
AR 1511
DI 10.3390/diagnostics11081511
UT WOS:000688977400001
PM 34441444
ER

PT J
AU Hsieh, HH
   Lee, JH
   Chandrasekar, S
   Shan, S
AF Hsieh, Hao-Hsuan
   Lee, Jae Ho
   Chandrasekar, Sowmya
   Shan, Shu-ou
TI A ribosome-associated chaperone enables substrate triage in a
   cotranslational protein targeting complex
SO NATURE COMMUNICATIONS
AB Protein biogenesis is essential in all cells and initiates when a nascent polypeptide emerges from the ribosome exit tunnel, where multiple ribosome-associated protein biogenesis factors (RPBs) direct nascent proteins to distinct fates. How distinct RPBs spatiotemporally coordinate with one another to affect accurate protein biogenesis is an emerging question. Here, we address this question by studying the role of a cotranslational chaperone, nascent polypeptide-associated complex (NAC), in regulating substrate selection by signal recognition particle (SRP), a universally conserved protein targeting machine. We show that mammalian SRP and SRP receptors (SR) are insufficient to generate the biologically required specificity for protein targeting to the endoplasmic reticulum. NAC co-binds with and remodels the conformational landscape of SRP on the ribosome to regulate its interaction kinetics with SR, thereby reducing the nonspecific targeting of signalless ribosomes and pre-emptive targeting of ribosomes with short nascent chains. Mathematical modeling demonstrates that the NAC-induced regulations of SRP activity are essential for the fidelity of cotranslational protein targeting. Our work establishes a molecular model for how NAC acts as a triage factor to prevent protein mislocalization, and demonstrates how the macromolecular crowding of RPBs at the ribosome exit site enhances the fidelity of substrate selection into individual protein biogenesis pathways. Biochemistry combined with biophysical measurements and mathematical modeling offer insight into the mechanism by which the cotranslational chaperone, nascent polypeptide-associated complex (NAC), modulates substrate selection by signal recognition particle (SRP) and reduces aberrant, nonspecific targeting of ribosomes to the ER.
OI Lee, Jae Ho/0000-0002-8663-3209
SN 2041-1723
PD NOV 17
PY 2020
VL 11
IS 1
AR 5840
DI 10.1038/s41467-020-19548-5
UT WOS:000594728700017
PM 33203865
ER

PT C
AU Park, Y
   Gu, M
   Yoo, S
   Kim, Y
   Park, S
AF Park, Younghun
   Gu, Minwoo
   Yoo, Sungju
   Kim, Youngjae
   Park, Sungyong
GP IEEE
TI DymGPU: Dynamic Memory Management for Sharing GPUs in Virtualized Clouds
SO 2018 IEEE 3RD INTERNATIONAL WORKSHOPS ON FOUNDATIONS AND APPLICATIONS OF
   SELF* SYSTEMS (FAS*W)
CT 3rd IEEE International Workshops on Foundations and Applications of
   Self* Systems (FAS*W)
CY SEP 03-07, 2018
CL Trento, ITALY
SP IEEE, IEEE Comp Soc
AB gVirt is a full GPU virtualization technique for Intel's integrated GPUs that alleviates the problems of other GPU virtualization techniques such as API remoting and direct pass-through. The original gVirt is known to have an inherent scalability limitation on the number of simultaneous virtual machines (VM). gScale solved this problem by allowing each VM to share a global graphics memory space and copy the entries in a private graphics translation table (GTT) to a physical GTT along with a GPU context switch. However, it still suffers from a large overhead of copying entries between private GTT and physical GTT, which becomes worse when the global graphics memory space allocated for each VM is overlapped.
   In this paper, we identify that the copy overhead caused by GPU context switch is the major bottleneck in performance improvement and propose a dynamic memory management scheme, called DymGPU, that provides two memory allocation algorithms such as size-based and utilization-based algorithms. While the size-based algorithm allocates memory space based on the memory size required by each VM, the utilization-based algorithm considers GPU utilization of each VM to allocate the memory space. DymGPU is also dynamic in the sense that the global graphics memory space used by each VM is rearranged at runtime by periodically checking idle VMs and GPU utilization of each runnable VM. We have implemented our proposed approach in gVirt and confirmed that the proposed scheme reduces GPU context switch time by up to 53% and improved the overall performance of various GPU applications by up to 39%.
BN 978-1-5386-5175-9
PY 2018
BP 51
EP 57
DI 10.1109/FAS-W.2018.00025
UT WOS:000469065900014
ER

PT J
AU Nguyen, VH
   Kim, WJ
AF Vu Huy Nguyen
   Kim, Won-Jong
TI Two-Phase Lorentz Coils and Linear Halbach Array for Multiaxis
   Precision-Positioning Stages With Magnetic Levitation
SO IEEE-ASME TRANSACTIONS ON MECHATRONICS
AB In this paper, a new framework for linear permanent-magnet (PM) machines with applications in precision motion control is proposed and validated. A single forcer generating two independent force components in two perpendicular directions is the fundamental unit of the framework. Each forcer consists of two planar Lorentz coils separated by a 90 degrees or 270 degrees phase difference and parallel to a Halbach magnet array. Many coil pairs can be assembled to the same platen to move over a common magnet matrix, forming a linear or planar PM motor. Advantages of this framework include a linear system model, the capability to magnetically levitate the mover in multiaxis stages, and that to generate long translational motion range. The framework developed herein is validated by a six-degree-of-freedom magnetically levitated (maglev) stage. The dimension of the moving platen's frame is 14.3 cm x 14.3 cm, and its totalmass is 0.75 kg. The achieved positioning resolution in translations along X, Y, and Z is 10 nm. The positioning resolution in out-of-plane rotation is 0.1 mu rad, which is a record in the literature. The maximum travel range in XY with laser interferometers is 56 mm x 35 mm, limited by the size of the precision mirrors. With the coils' total mass of only 0.205 kg, the achieved acceleration is 1.2 m/s(2). Experimental results exhibit reduced perturbations in other axes of in-plane motions.
RI Nguyen, Vu/E-2655-2016
OI Nguyen, Vu/0000-0002-4041-7471
SN 1083-4435
EI 1941-014X
PD DEC
PY 2017
VL 22
IS 6
BP 2662
EP 2672
DI 10.1109/TMECH.2017.2769160
UT WOS:000418372600028
ER

PT C
AU Choi, YK
   Kirchhoff, K
   Turner, AM
AF Choi, Yong K.
   Kirchhoff, Katrin
   Turner, Anne M.
GP IEEE
TI Medical Text Simplification by Medical Trainees: A Feasibility Study
SO 2016 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI)
CT IEEE International Conference on Healthcare Informatics (ICHI)
CY OCT 04-07, 2016
CL Chicago, IL
SP IEEE, GE Digital, IEEE Comp Soc, NSF, Computers, Univ Illinois
AB Current healthcare practice is transitioning from a provider-centered model to a patient-centered model of care, where patients are no longer passive recipients of care, but are encouraged to actively engage in and take greater responsibility for medical decision-making. As part of this trend patients are gaining access to larger and more diverse sets of medical texts through Electronic Medical Record (EMR) systems (e.g., doctor's notes, discharge summaries, etc.). The availability of medical notes that are accurate and easily understandable for patients will be crucial for the success of this new care model. However, medical notes are primarily written for the purpose of providerto-provider communication and are generally difficult for lay persons to understand, especially those individuals with low health literacy. Thus, patients are not fully able to utilize this information due to linguistic and literacy barriers. Our ultimate goal is to develop a health IT intervention that addresses this gap by combining information technology with untapped human expertise, such as knowledge held by medical students and other trainees. This paper describes an initial feasibility study to determine whether medical trainees have sufficient expertise to convert medical reports into understandable, everyday language. We measure the effect of simplifications on objective comprehensibility, patient preferences, and then relate the outcome to linguistic characteristics of the texts. Our results show that comprehensibility improves substantially even without prior task-specific training of medical students, and that student-generated simplifications are strongly preferred over the original medical texts.
BN 978-1-5090-6117-4
PY 2016
BP 334
EP 340
DI 10.1109/ICHI.2016.61
UT WOS:000391422100062
ER

PT J
AU Saikko, V
   Calonius, O
AF Saikko, V
   Calonius, O
TI Simulation of wear rates and mechanisms in total knee prostheses by
   ball-on-flat contact in a five-station, three-axis test rig
SO WEAR
AB A five-station, three-axis knee wear simulator with ball-on-flat contact was designed and built. The motions included in the simulator were flexion-extension (FE), anterior-posterior translation (APT) and inward-outward rotation (IOR). The 10 mm thick, 40 nun diameter test disks were machined from an ultra-high molecular weight polyethylene (GUR 1050) bar. The balls were polished CoCr of 54 mm diameter. The lubricant was diluted calf serum, test length 3.3 million cycles and load 2 kN. Five similar tests were run first with non-irradiated disks, and then with newly gamma-sterilized (2.5-4 Mrad in air), non-aged disks. The principal wear mechanism was adhesive and manifested as burnishing of the wear zone. The mean wear rates and standard deviations for non-irradiated and gamma-irradiated polyethylene were 14.5 +/- 1.6 and 12.0 +/- 0.5 mg per one million cycles, respectively. The p-value of the difference in means was 0.005, strongly suggesting a significant difference. The results agreed with published studies so that initially, before possible deterioration due to ageing, gamma-irradiation improves the wear resistance of polyethylene. This has earlier been observed particularly in hip wear simulations, and has been shown to be due to crosslinking. In conclusion, the new simulator proved to be a valid wear test device for prosthetic knee materials. (C) 2002 Elsevier Science B.V. All rights reserved.
RI Saikko, Vesa/I-1675-2016
OI Saikko, Vesa/0000-0002-0196-0033
SN 0043-1648
PD AUG
PY 2002
VL 253
IS 3-4
BP 424
EP 429
AR PII S0043-1648(02)00154-0
DI 10.1016/S0043-1648(02)00154-0
UT WOS:000178395000011
ER

PT J
AU Kanani, T
   Isherwood, J
   ElSamani, K
   Chung, WY
   West, K
   Oggioni, MR
   Garcea, G
   Dennison, A
AF Kanani, Trisha
   Isherwood, John
   ElSamani, Kareem
   Chung, Wen Y.
   West, Kevin
   Oggioni, Marco R.
   Garcea, Giuseppe
   Dennison, Ashley
TI Development of a Novel Ex Vivo Porcine Hepatic Segmental Perfusion
   Proof-of-Concept Model Towards More Ethical Translational Research
SO CUREUS JOURNAL OF MEDICAL SCIENCE
AB IntroductionEx vivo machine perfusion describes the technique where organs are continuously perfused and oxygenated extracorporeally (at physiological conditions) to maintain the organs' viability. To our knowledge, there are currently no reported studies describing ex vivo perfusion of a single hepatic segment. Here, we describe the development of a porcine ex vivo hepatic segmental perfusion model to demonstrate proof of concept and support further research into the ex vivo perfusion of the human liver using discarded tissue. MethodsWhole livers were retrieved from abattoir-derived pigs and connected to a normothermic extracorporeal perfusion circuit. Constant segmental perfusion via the common or segmental hepatic artery and portal vein with heparinised autologous blood was established. The viability of the perfused organ was assessed by monitoring perfusion pressures, flow rates and histology samples. ResultsFollowing perfusion and optimisation of the model for three hepatic segments, the third perfusion demonstrated viable hepatocytes centrally after 4 h of segmental perfusion. ConclusionEx vivo hepatic segmental perfusion is technically challenging but its success in a porcine model and the principles learned should facilitate the development of an analogous human model using discarded tissue following formal liver resections. The model would use a healthy liver segment following a major formal resection such as a hemi-hepatectomy and ex vivo perfusion performed via a segmental hepatic artery and portal vein. If successful this model would represent a significant development and enable ethical translation research to assess the response of human livers to a variety of stressors, including toxicity and infection.
EI 2168-8184
PD FEB 18
PY 2023
VL 15
IS 2
DI 10.7759/cureus.35143
UT WOS:000944201900006
PM 36949973
ER

PT J
AU Holgate, ST
AF Holgate, Stephen T.
TI Accelerating the transition of clinical science to translational
   medicine
SO CLINICAL SCIENCE
AB The SARS-CoV-2 pandemic has shown the importance of medical research in responding to the urgent prevention and health needs to combat the devastating disease, COVID-19, that this beta-coronavirus unleashed. Equally, it has demonstrated the importance of interdisciplinary working to translate scientific discovery into public and patient benefit. As we come to adjust to live with this new virus, it is important to look back and see what lessons we have learnt in the way scientific medical discoveries can be more effectively and rapidly moved into public benefit. Clinical Science has had a long and distinguished history with this Journal bearing the same name and being an important contributor to the rapidly increasing use of human pathobiological data to gain mechanistic understanding of disease mechanisms leading to new diagnostic tests and treatments. The recognition that many complex diseases engage multiple causal pathways that may vary from patient to patient, and at different times across the lifecourse, has led to the emergence of stratified or precision medicine in which the right treatment is given to the right patient at the right time and, in doing so, minimise 'non-responders' and off-target side effects. Applications of omics technologies, the digitalisation of biology and the applications of machine learning and artificial intelligence (AI) are accelerating disease insights at pace with translation of discoveries into new diagnostic tests and treatments. The future of clinical science, as it morphs into translational medicine, is now creating unique possibilities where even the most intractable diseases are now open to being conquered.
OI holgate, stephen/0000-0003-2658-4617
SN 0143-5221
EI 1470-8736
PD OCT
PY 2021
VL 135
IS 20
BP 2423
EP 2428
DI 10.1042/CS20210846
UT WOS:000720840900006
PM 34709405
ER

PT C
AU Carneiro, ALC
   Silva, LB
   Salvadeo, DHP
AF Cavalcante Carneiro, A. L.
   Silva, L. Brito
   Pinheiro Salvadeo, D. H.
BE Jiang, X
   Fujita, H
TI Efficient Sign Language Recognition System and Dataset Creation Method
   Based on Deep Learning and Image Processing
SO THIRTEENTH INTERNATIONAL CONFERENCE ON DIGITAL IMAGE PROCESSING (ICDIP
   2021)
SE Proceedings of SPIE
CT 13th International Conference on Digital Image Processing (ICDIP)
CY MAY 20-23, 2021
CL ELECTR NETWORK
SP Int Asoc Comp Sci & Informat Technol
AB New deep-learning architectures are created every year, achieving state-of-the-art results in image recognition and leading to the belief that, in a few years, complex tasks such as sign language translation will be considerably easier, serving as a communication tool for the hearing-impaired community. On the other hand, these algorithms still need a lot of data to be trained and the dataset creation process is expensive, time-consuming, and slow. Thereby, this work aims to investigate techniques of digital image processing and machine learning that can be used to create a sign language dataset effectively. We argue about data acquisition, such as the frames per second rate to capture or subsample the videos, the background type, preprocessing, and data augmentation, using convolutional neural networks and object detection to create an image classifier and comparing the results based on statistical tests. Different datasets were created to test the hypotheses, containing 14 words used daily and recorded by different smartphones in the RGB color system. We achieved an accuracy of 96.38% on the test set and 81.36% on the validation set containing more challenging conditions, showing that 30 FPS is the best frame rate subsample to train the classifier, geometric transformations work better than intensity transformations, and artificial background creation is not effective to model generalization. These trade-offs should be considered in future work as a cost-benefit guideline between computational cost and accuracy gain when creating a dataset and training a sign recognition model.
OI Brito Silva, Lucas/0000-0001-6748-5100
SN 0277-786X
EI 1996-756X
BN 978-1-5106-4601-8
PY 2021
VL 11878
AR 1187803
DI 10.1117/12.2601018
UT WOS:000694937300002
ER

PT J
AU Fayer, I
   Granek, R
AF Fayer, Itay
   Granek, Rony
TI Directional Stepping Model for Yeast Dynein: Longitudinal- and Side-Step
   Distributions
SO BIOPHYSICAL JOURNAL
AB Motor proteins are biological machines that convert chemical energy stored in ATP to mechanical work. Kinesin and dynein are microtubule (MT)-associated motor proteins that, among other functions, facilitate intracellular transport. Here, we focus on dynein motility. We deduce the directional step distribution of yeast dynein motor protein on the MT surface by combing intrinsic features of the dynein and MTs. These include the probability distribution of the separation vector between the two microtubule-binding domains, the angular probability distribution of a single microtubule-binding domain translation, the existence of an MT seam defect, MT-binding sites, and theoretical extension that accounts for a load force on the motor. Our predictions are in excellent accord with the measured longitudinal step size distributions at various load forces. Moreover, we predict the side-step distribution and its dependence on longitudinal load forces, which shows a few surprising features. First, the distribution is broad. Second, in the absence of load, we find a small right-handed bias. Third, the side-step bias is susceptible to the longitudinal load force; it vanishes at a load equal to the motor stalling force and changes to a left-hand bias above that value. Fourth, our results are sensitive to the ability of the motor to explore the seam several times during its walk. Although available measurements of side-way distribution are limited, our findings are amenable to experimental check and, moreover, suggest a diversity of results depending on whether the MT seam is viable to motor sampling.
RI GRANEK, RONY/F-1987-2012
OI GRANEK, RONY/0000-0001-6839-5393
SN 0006-3495
EI 1542-0086
PD NOV 19
PY 2019
VL 117
IS 10
BP 1892
EP 1899
DI 10.1016/j.bpj.2019.09.043
UT WOS:000497815800011
PM 31676137
ER

PT J
AU Yu, LX
   Ling, Y
   Wang, HY
AF Yu, Le-Xing
   Ling, Yan
   Wang, Hong-Yang
TI Role of nonresolving inflammation in hepatocellular carcinoma
   development and progression
SO NPJ PRECISION ONCOLOGY
AB Hepatocellular carcinoma (HCC) has become a leading cause of cancer-related death, making the elucidation of its underlying mechanisms an urgent priority. Inflammation is an adaptive response to infection and tissue injury under strict regulations. When the host regulatory machine runs out of control, nonresolving inflammation occurs. Nonresolving inflammation is a recognized hallmark of cancer that substantially contributes to the development and progression of HCC. The HCC-associated inflammation can be initiated and propagated by extrinsic pathways through activation of pattern-recognition receptors (PRRs) by pathogen-associated molecule patterns (PAMPs) derived from gut microflora or damage-associated molecule patterns (DAMPs) released from dying liver cells. The inflammation can also be orchestrated by the tumor itself through secreting factors that recruit inflammatory cells to the tumor favoring the buildup of a microenvironment. Accumulating datas from human and mouse models showed that inflammation promotes HCC development by promoting proliferative and survival signaling, inducing angiogenesis, evading immune surveillance, supporting cancer stem cells, activating invasion and metastasis as well as inducing genomic instability. Targeting inflammation may represent a promising avenue for the HCC treatment. Some inhibitors targeting inflammatory pathways have been developed and under different stages of clinical trials, and one (sorafenib) have been approved by FDA. However, as most of the data were obtained from animal models, and there is a big difference between human HCC and mouse HCC models, it is challenging on successful translation from bench to bedside.
RI Yu, Lexing/AGP-5427-2022
OI Yu, Lexing/0000-0001-9619-8004
EI 2397-768X
PD FEB 23
PY 2018
VL 2
AR 6
DI 10.1038/s41698-018-0048-z
UT WOS:000429472200001
PM 29872724
ER

PT J
AU Arnous, FI
   Narayanan, RM
   Li, BC
AF Arnous, Ferris, I
   Narayanan, Ram M.
   Li, Bing C.
TI Application of multidomain sensor image fusion and training data
   augmentation for enhanced CNN image classification
SO JOURNAL OF ELECTRONIC IMAGING
AB Convolutional neural networks (CNNs) provide the sensing and detection community with a discriminative approach for classifying images. However, one of the largest limitations of deep CNN image classifiers is the need for extensive training datasets containing a variety of image representations. While current methods, such as generative adversarial network data augmentation, additions of noise, rotations, and translations, can allow CNNs to better associate new images and their feature representations to ones of a learned image class, many fail to provide new contexts of ground truth feature information. To expand the association of critical class features within CNN image training datasets, an image pairing and training dataset augmentation paradigm via a multi-sensor domain image data fusion algorithm is proposed. This algorithm uses a mutual information (MI) and merit-based feature selection subroutine to pair highly correlated cross-domain images from multiple sensor domain image datasets. It then reaugments the corresponding cross-domain image pairs into the opposite sensor domain's feature set via a highest MI, cross sensor domain, and image concatenation function. This augmented image set then acts to retrain the CNN to recognize greater generalizations of image class features via cross domain, mixed representations. Experimental results indicated an increased ability of CNNs to generalize and discriminate between image classes during testing of class images from synthetic aperture radar vehicle, solar cell device reliability screening, and lung cancer detection image datasets. (C) 2022 SPIE and IS&T
SN 1017-9909
EI 1560-229X
PD JAN 1
PY 2022
VL 31
IS 1
AR 013014
DI 10.1117/1.JEI.31.1.013014
UT WOS:000762340700018
ER

PT J
AU Byambadorj, Z
   Nishimura, R
   Ayush, A
   Kitaoka, N
AF Byambadorj, Zolzaya
   Nishimura, Ryota
   Ayush, Altangerel
   Kitaoka, Norihide
TI Normalization of Transliterated MongolianWords Using Seq2Seq Model with
   Limited Data
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB The huge increase in social media use in recent years has resulted in new forms of social interaction, changing our daily lives. Due to increasing contact between people from different cultures as a result of globalization, there has also been an increase in the use of the Latin alphabet, and as a result a large amount of transliterated text is being used on social media. In this study, we propose a variety of character level sequence-to-sequence (seq2seq) models for normalizing noisy, transliterated text written in Latin script into Mongolian Cyrillic script, for scenarios in which there is a limited amount of training data available. We applied performance enhancement methods, which included various beam search strategies, N-gram-based context adoption, edit distance-based correction and dictionary-based checking, in novel ways to two basic seq2seq models. We experimentally evaluated these two basic models as well as fourteen enhanced seq2seq models, and compared their noisy text normalization performance with that of a transliteration model and a conventional statistical machine translation (SMT) model. The proposed seq2seq models improved the robustness of the basic seq2seq models for normalizing out-of-vocabulary (OOV) words, and most of our models achieved higher normalization performance than the conventional method. When using test data during our text normalization experiment, our proposed method which included checking each hypothesis during the inference period achieved the lowest word error rate (WER = 13.41%), which was 4.51% fewer errors than when using the conventional SMT method.
OI Byambadorj, Zolzaya/0000-0002-1675-7791
SN 2375-4699
EI 2375-4702
PD NOV
PY 2021
VL 20
IS 6
AR 103
DI 10.1145/3464361
UT WOS:000721586800012
ER

PT J
AU Wang, R
   Wang, Y
AF Wang, Rong
   Wang, Yong
TI Fourier Transform Infrared Spectroscopy in Oral Cancer Diagnosis
SO INTERNATIONAL JOURNAL OF MOLECULAR SCIENCES
AB Oral cancer is one of the most common cancers worldwide. Despite easy access to the oral cavity and significant advances in treatment, the morbidity and mortality rates for oral cancer patients are still very high, mainly due to late-stage diagnosis when treatment is less successful. Oral cancer has also been found to be the most expensive cancer to treat in the United States. Early diagnosis of oral cancer can significantly improve patient survival rate and reduce medical costs. There is an urgent unmet need for an accurate and sensitive molecular-based diagnostic tool for early oral cancer detection. Fourier transform infrared spectroscopy has gained increasing attention in cancer research due to its ability to elucidate qualitative and quantitative information of biochemical content and molecular-level structural changes in complex biological systems. The diagnosis of a disease is based on biochemical changes underlying the disease pathology rather than morphological changes of the tissue. It is a versatile method that can work with tissues, cells, or body fluids. In this review article, we aim to summarize the studies of infrared spectroscopy in oral cancer research and detection. It provides early evidence to support the potential application of infrared spectroscopy as a diagnostic tool for oral potentially malignant and malignant lesions. The challenges and opportunities in clinical translation are also discussed.
RI Wang, Yong/GPX-3217-2022
OI Wang, Yong/0000-0002-2862-5075; Wang, Rose/0000-0002-1607-8094
EI 1422-0067
PD FEB
PY 2021
VL 22
IS 3
AR 1206
DI 10.3390/ijms22031206
UT WOS:000615298600001
PM 33530491
ER

PT C
AU Lin, B
   Wang, SW
   Liu, K
   Mao, XG
   Bissyande, TF
AF Lin, Bo
   Wang, Shangwen
   Liu, Kui
   Mao, Xiaoguang
   Bissyande, Tegawende F.
GP IEEE COMP SOC
TI Automated Comment Update: How Far are We?
SO 2021 IEEE/ACM 29TH INTERNATIONAL CONFERENCE ON PROGRAM COMPREHENSION
   (ICPC 2021)
SE International Conference on Program Comprehension
CT 29th IEEE/ACM International Conference on Program Comprehension (ICPC) /
   18th IEEE/ACM International Conference on Mining Software Repositories
   (MSR)
CY MAY 22-30, 2021
CL ELECTR NETWORK
SP IEEE, Assoc Comp Machinery, IEEE Comp Soc, IEEE Tech Council Software Engn, ACM Special Interest Grp Software Engn
AB Code comments are key to program comprehension. When they are not consistent with the code, maintenance is hindered. Yet developers often forget to update comments along with their code evolution. With recent advances in neural machine translation, the research community is contemplating novel approaches for automatically generating up-to-date comments following code changes. CUP is such an example state-of-the-art approach whose promising performance remains however to be comprehensively assessed. Our study contributes to the literature by performing an in-depth analysis on the effectiveness of CUP. Our analysis revealed that the overall effectiveness of CUP is largely contributed by its success on updating comments via a single token change (96.6%). Several update failures occur when CUP ignores some code change information (10.4%) or when it is otherwise misled by additional information (12.8%). To put in perspective the achievements of CUP, we implement HEBCUP, a straightforward heuristic-based approach for code comment update. Building on our observations on CUP successful and failure cases, we design heuristics for focusing the update on the changed code and for performing token-level comment update. HEBCUP is shown to outperform CUP in terms of Accuracy by more than 60% while being over three orders of magnitude (i.e., 1 700 times) faster. Further empirical analysis confirms that the HEBCUP does not even overfit to the empirical analysis set. Overall, with this study, we call for more research in deep learning based comment update towards achieving state-of-the-art performance that would be unreachable by other less sophisticated techniques.
OI LIU, Kui/0000-0003-0145-615X; Wang, Shangwen/0000-0003-1469-2063
SN 1092-8138
BN 978-1-6654-1403-6
PY 2021
BP 36
EP 46
DI 10.1109/ICPC52881.2021.00013
UT WOS:000693398800006
ER

PT J
AU Tadesse, LF
   Safir, F
   Ho, CS
   Hasbach, X
   Khuri-Yakub, B
   Jeffrey, SS
   Saleh, AAE
   Dionne, J
AF Tadesse, Loza F.
   Safir, Fareeha
   Ho, Chi-Sing
   Hasbach, Ximena
   Khuri-Yakub, Butrus (Pierre)
   Jeffrey, Stefanie S.
   Saleh, Amr A. E.
   Dionne, Jennifer
TI Toward rapid infectious disease diagnosis with advances in
   surface-enhanced Raman spectroscopy
SO JOURNAL OF CHEMICAL PHYSICS
AB In a pandemic era, rapid infectious disease diagnosis is essential. Surface-enhanced Raman spectroscopy (SERS) promises sensitive and specific diagnosis including rapid point-of-care detection and drug susceptibility testing. SERS utilizes inelastic light scattering arising from the interaction of incident photons with molecular vibrations, enhanced by orders of magnitude with resonant metallic or dielectric nanostructures. While SERS provides a spectral fingerprint of the sample, clinical translation is lagged due to challenges in consistency of spectral enhancement, complexity in spectral interpretation, insufficient specificity and sensitivity, and inefficient workflow from patient sample collection to spectral acquisition. Here, we highlight the recent, complementary advances that address these shortcomings, including (1) design of label-free SERS substrates and data processing algorithms that improve spectral signal and interpretability, essential for broad pathogen screening assays; (2) development of new capture and affinity agents, such as aptamers and polymers, critical for determining the presence or absence of particular pathogens; and (3) microfluidic and bioprinting platforms for efficient clinical sample processing. We also describe the development of low-cost, point-of-care, optical SERS hardware. Our paper focuses on SERS for viral and bacterial detection, in hopes of accelerating infectious disease diagnosis, monitoring, and vaccine development. With advances in SERS substrates, machine learning, and microfluidics and bioprinting, the specificity, sensitivity, and speed of SERS can be readily translated from laboratory bench to patient bedside, accelerating point-of-care diagnosis, personalized medicine, and precision health.
RI Saleh, Amr/AAP-4391-2021
OI Saleh, Amr/0000-0001-7136-3683; Safir, Fareeha/0000-0002-8035-5615;
   Jeffrey, Stefanie/0000-0003-4478-2764; Dionne,
   Jennifer/0000-0001-5287-4357; Khuri-Yakub, Butrus/0000-0003-3940-7898;
   Tadesse, Loza/0000-0003-2040-8145
SN 0021-9606
EI 1089-7690
PD JUN 28
PY 2020
VL 152
IS 24
DI 10.1063/1.5142767
UT WOS:000546996900001
PM 32610995
ER

PT J
AU Benavente, P
   Protopapas, P
   Pichara, K
AF Benavente, Patricio
   Protopapas, Pavlos
   Pichara, Karim
TI Automatic Survey-invariant Classification of Variable Stars
SO ASTROPHYSICAL JOURNAL
AB Machine learning techniques have been successfully used to classify variable stars on widely studied astronomical surveys. These data sets have been available to astronomers long enough, thus allowing them to perform deep analysis over several variable sources and generating useful catalogs with identified variable stars. The products of these studies are labeled data that enable supervised learning models to be trained successfully. However, when these models are blindly applied to data from new sky surveys, their performance drops significantly. Furthermore, unlabeled data become available at a much higher rate than their labeled counterpart, since labeling is a manual and time-consuming effort. Domain adaptation techniques aim to learn from a domain where labeled data are available, the source domain, and through some adaptation perform well on a different domain, the target domain. We propose a full probabilistic model that represents the joint distribution of features from two surveys, as well as a probabilistic transformation of the features from one survey to the other. This allows us to transfer labeled data to a study where they are not available and to effectively run a variable star classification model in a new survey. Our model represents the features of each domain as a Gaussian mixture and models the transformation as a translation, rotation, and scaling of each separate component. We perform tests using three different variability catalogs, EROS, MACHO, and HiTS, presenting differences among them, such as the number of observations per star, cadence, observational time, and optical bands observed, among others.
SN 0004-637X
EI 1538-4357
PD AUG 20
PY 2017
VL 845
IS 2
AR 147
DI 10.3847/1538-4357/aa7f2d
UT WOS:000408111400033
ER

PT J
AU Tutek, M
   Snajder, J
AF Tutek, Martin
   Snajder, Jan
TI Toward Practical Usage of the Attention Mechanism as a Tool for
   Interpretability
SO IEEE ACCESS
AB Natural language processing (NLP) has been one of the subfields of artificial intelligence much affected by the recent neural revolution. Architectures such as recurrent neural networks (RNNs) and attention-based transformers helped propel the state of the art across various NLP tasks, such as sequence classification, machine translation, and natural language inference. However, if neural models are to be used in high-stakes decision making scenarios, the explainability of their decisions becomes a paramount issue. The attention mechanism has offered some transparency in the workings of otherwise black-box RNN models: attention weights (scalar values assigned input words) invite to be interpreted as the importance of that word, providing a simple method of interpretability. Recent work, however, has questioned the faithfulness of this practice. Subsequent experiments have shown that faithfulness of attention weights may still be achieved by incorporating word-level objectives in the training process of neural networks. In this article, we present a study that extends the techniques for improving faithfulness of attention based on regularization methods that promote retention of word-level information. We perform extensive experiments on a wide array of recurrent neural architectures and analyze to what extent the explanations provided by inspecting attention weights are correlated with the human notion of importance. We find that incorporating tying regularization consistently improves both the faithfulness (-0.14 F1, +0.07 Brier, on average) and plausibility (+53.6% attention mass on salient tokens) of explanations obtained through inspecting attention weights across analyzed datasets and models.
OI Snajder, Jan/0000-0001-8942-5301
SN 2169-3536
PY 2022
VL 10
BP 47011
EP 47030
DI 10.1109/ACCESS.2022.3169772
UT WOS:000793783900001
ER

PT J
AU Woo, JW
   Lee, W
   Lee, M
AF Woo, Jeong-Woo
   Lee, Wono
   Lee, Minho
TI A Traffic Surveillance System Using Dynamic Saliency Map and SVM
   Boosting
SO INTERNATIONAL JOURNAL OF CONTROL AUTOMATION AND SYSTEMS
AB This paper proposes a traffic surveillance system that can efficiently detect an interesting object and identify vehicles and pedestrians in real traffic situations. The proposed system consists of a moving object detection model and an object identification model. A dynamic saliency map is used for analyzing dynamics of the successive static saliency maps, and can localize an attention area in dynamic scenes to focus on a specific moving object for traffic surveillance purposes. The candidate local areas of a moving object are followed by a blob detection processing including binarization, morphological closing and labeling methods. For identifying a moving object class, the proposed system uses a hybrid of global and local information in each local area. Although the global feature analysis is a compact way to identify an object and provide a good accuracy for non-occluded objects, it is sensitive to image translation and occlusion. Therefore, a local feature analysis is also considered and combined with the global feature analysis. In order to construct an efficient classifier using the global and local features, this study proposes a novel classifier based on boosting of support vector machines. The proposed object identification model can identify a class of moving object and discard unexpected candidate area which does not include an interesting object. As a result, the proposed road surveillance system is able to detect a moving object and identify the class of the moving object. Experimental results show that the proposed traffic surveillance system can successfully detect specific moving objects.
SN 1598-6446
EI 2005-4092
PD OCT
PY 2010
VL 8
IS 5
BP 948
EP 956
DI 10.1007/s12555-010-0503-2
UT WOS:000282403600004
ER

PT J
AU Walker, D
   Mackey, L
   Ligatti, J
   Reis, GA
   August, DI
AF Walker, David
   Mackey, Lester
   Ligatti, Jay
   Reis, George A.
   August, David I.
TI Static typing for a faulty lambda calculus
SO ACM SIGPLAN NOTICES
AB A transient hardware fault occurs when an energetic particle strikes a transistor, causing it to change state. These faults do not cause permanent damage, but may result in incorrect program execution by altering signal transfers or stored values. While the likelihood that such transient faults will cause any significant damage may seem remote, over the last several years transient faults have caused costly failures in high-end machines at America Online, eBay, and the Los Alamos Neutron Science Center, among others [ 6, 44, 15]. Because susceptibility to transient faults is proportional to the size and density of transistors, the problem of transient faults will become increasingly important in the coming decades.
   This paper defines the first formal, type-theoretic framework for studying reliable computation in the presence of transient faults. More specifically, it defines lambda(zap), a lambda calculus that exhibits intermittent data faults. In order to detect and recover from these faults, lambda(zap) programs replicate intermediate computations and use majority voting, thereby modeling software-based fault tolerance techniques studied extensively, but informally [ 10, 20, 30, 31, 32, 33, 41].
   To ensure that programs maintain the proper invariants and use lambda(zap) primitives correctly, the paper defines a type system for the language. This type system guarantees that well-typed programs can tolerate any single data fault. To demonstrate that lambda(zap) can serve as an idealized typed intermediate language, we define a type-preserving translation from a standard simply-typed lambda calculus into lambda(zap).
OI Mackey, Lester/0000-0002-1102-0387
SN 0362-1340
EI 1558-1160
PD SEP
PY 2006
VL 41
IS 9
BP 38
EP 49
DI 10.1145/1160074.1159809
UT WOS:000202972400005
ER

PT C
AU Lucas, CE
   Walters, EA
   Wasynczuk, O
   Lafayette, W
   Lamm, PT
AF Lucas, CE
   Walters, EA
   Wasynczuk, O
   Lafayette, W
   Lamm, PT
BE Trevisani, DA
   Sisti, AF
TI Cross-platform distributed heterogeneous simulation of a more-electric
   aircraft power system
SO Enabling Technologies for Simulation Science IX
SE PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)
CT Conference on Enabling Technologies for Simulation Science IX
CY MAR 29-31, 2005
CL Orlando, FL
SP SPIE, Ball Aerosp & Technol Corp, Univ Cent Florida, Coll Opt & Photon, Florida Space Inst, FOI, Swedish Defense Res Agcy, Univ Central Florida
AB To support research and analysis requirements in the development of future power systems, a flexible and efficient means of predicting the dynamic performance of large-scale multi-disciplinary systems prior to hardware trials is crucial. With the development of Distributed Heterogeneous Simulation (DHS), the technology now exists to enable this type of investigation. Previously, DHS was shown to allow the interconnection of component simulations running on a single-or distributed-computer network and developed using any combination of a variety of commercial-off-the-shelf (COTS) software packages for the Microsoft Windows operating system. However, for large-scale systems, all subsystem models may not be developed in software packages operating under Windows thereby requiring a translation of such models in order to incorporate them within a system simulation. In this paper, the DHS technique is expanded to support the UNIX operating system, thus, allowing subsystem models developed and executed on either UNIX- or Windows-based computers to be interconnected to form a dynamic system simulation. For the purpose of demonstration, a more-electric fighter (MEF) power system, such as that found on the Joint Strike Fighter (JSF), has been selected as a study system. This system is comprised of ten component models each developed using MATLAB/Simulink (TM), EASY5 (TM), or ACSL (TM). Utilizing the system simulation, studies have been performed to illustrate the dynamic interactions between the subsystems when simulated on a heterogeneous computer network containing both Windows- and Unix-based machines.
SN 0277-786X
BN 0-8194-5790-6
PY 2005
VL 5805
BP 328
EP 336
DI 10.1117/12.603833
UT WOS:000231052900031
ER

PT J
AU Jin, B
   Cruz, L
   Goncalves, N
AF Jin, Bo
   Cruz, Leandro
   Goncalves, Nuno
TI Pseudo RGB-D Face Recognition
SO IEEE SENSORS JOURNAL
AB In the last decade, advances and popularity of low-cost RGB-D sensors have enabled us to acquire depth information of objects. Consequently, researchers began to solve face recognition problems by capturing RGB-D face images using these sensors. Until now, it is not easy to acquire the depth of human faces because of limitations imposed by privacy policies, and RGB face images are still more common. Therefore, obtaining the depth map directly from the corresponding RGB image could be helpful to improve the performance of subsequent face processing tasks, such as face recognition. Intelligent creatures can use a large amount of experience to obtain 3D spatial information only from 2D plane scenes. It is machine learning methodology, which is to solve such problems, that can teach computers to generate correct answers by training. To replace the depth sensors by generated pseudo-depth maps, in this article, we propose a pseudo RGB-D face recognition framework and provide data-driven ways to generate the depth maps from 2D face images. Specially we design and implement a generative adversarial network model named "D+GAN" to perform the multiconditional image-to-image translation with face attributes. By this means, we validate the pseudo RGB-D face recognition with experiments on various datasets. With the cooperation of image fusion technologies, especially non-subsampled shearlet transform (NSST), the accuracy of face recognition has been significantly improved.
OI Jin, Bo/0000-0001-9255-5772; Goncalves, Nuno/0000-0002-1854-049X
SN 1530-437X
EI 1558-1748
PD NOV 15
PY 2022
VL 22
IS 22
BP 21780
EP 21794
DI 10.1109/JSEN.2022.3197235
UT WOS:000882008500046
ER

PT C
AU Wu, SL
   Wang, X
   Ning, QY
   Qiu, SG
AF Wu, Shilong
   Wang, Xu
   Ning, Qiuyi
   Qiu, Shigui
GP IEEE
TI Towards mining bilingual lexicons and parallel phrases from large-scale
   monolingual corpora
SO 2021 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY JUL 18-22, 2021
CL ELECTR NETWORK
SP Int Neural Network Soc, IEEE Computat Intelligence Soc
AB Bilingual lexicons and parallel phrases have a great effect on certain tasks of natural language processing (NLP). Recent researches have proved that the high-quality bilingual lexicons can hence the performance of the machine translation. When it comes to some special tasks of NLP, the incorporation of bilingual lexicons can bring about obvious effectiveness. The bilingual lexicons and parallel phrases can be easily extracted from parallel corpora, but in contrast to the monolingual corpora, the number of parallel corpora is still scarce. Actually, the monolingual corpora also have the potential to mine a large amount of parallel word and phrase pairs.
   In this paper, we propose two strategies to extract parallel words and phrases from monolingual corpora. On one hand, we present the indirect mining strategy, Anchored Mining (AM), which injects the anchoring point into each mining procedure to improve the accuracy. On the other hand, inspired by the process of humans learning a foreign language, we further propose another novel, direct algorithm named Bootstrapping Mining (BM), which mimics the human learning process and aims to learn parallel phrases automatically in a self-iterative way. Additionally, we propose a novel metric, phrase probability-sub item average probability (PP-SAP), which is applied to quantitatively evaluate the rationality of each extracted parallel phrase pair in the monolingual corpora.
   We conduct the experiments on large-scale English-Chinese, English-Russia, and English-France monolingual corpora, and the results show that our methods can mine high-quality bilingual lexicons and parallel phrases. We also evaluate our algorithms on low-resource monolingual corpora and get good results as well.
SN 2161-4393
BN 978-0-7381-3366-9
PY 2021
DI 10.1109/IJCNN52387.2021.9534166
UT WOS:000722581706117
ER

PT C
AU Zhang, J
   Yu, HF
   Dhillon, IS
AF Zhang, Jiong
   Yu, Hsiang-Fu
   Dhillon, Inderjit S.
BE Wallach, H
   Larochelle, H
   Beygelzimer, A
   d'Alche-Buc, F
   Fox, E
   Garnett, R
TI AutoAssist: A Framework to Accelerate Training of Deep Neural Networks
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 32 (NIPS 2019)
SE Advances in Neural Information Processing Systems
CT 33rd Conference on Neural Information Processing Systems (NeurIPS)
CY DEC 08-14, 2019
CL Vancouver, CANADA
AB Deep Neural Networks (DNNs) have yielded superior performance in many contemporary applications. However, the gradient computation in a deep model with millions of instances leads to a lengthy training process even with modern GPU/TPU hardware acceleration. In this paper, we propose AutoAssist, a simple framework to accelerate training of a deep neural network. Typically, as the training procedure evolves, the amount of improvement by a stochastic gradient update varies dynamically with the choice of instances in the mini-batch. In AutoAssist, we utilize this fact and design an instance shrinking operation that is used to filter out instances with relatively low marginal improvement to the current model; thus the computationally intensive gradient computations are performed on informative instances as much as possible. Specifically, we train a very lightweight Assistant model jointly with the original deep network, which we refer to as the Boss. The Assistant model is designed to gauge the importance of a given instance with respect to the current Boss model such that the shrinking operation can be applied in the batch generator. With careful design, we train the Boss and Assistant in a non-blocking and asynchronous fashion such that overhead is minimal. To demonstrate the effectiveness of AutoAssist, we conduct experiments on two contemporary applications: image classification using ResNets with varied number of layers, and neural machine translation using LSTMs, ConvS2S and Transformer models. For each application, we verify that AutoAssist leads to significant reduction in training time; in particular, 30% to 40% of the total operation count can be reduced which leads to faster convergence and a corresponding decrease in training time.
SN 1049-5258
PY 2019
VL 32
UT WOS:000534424306005
ER

PT J
AU Du, H
   Song, C
   Li, SY
   Xu, MJ
   Peng, XQ
AF Du, Hang
   Song, Ci
   Li, Shengyi
   Xu, Mingjin
   Peng, Xiaoqiang
TI Optimization technique for rolled edge control process based on the
   acentric tool influence functions
SO APPLIED OPTICS
AB In the process of computer controlled optical surfacing (CCOS), the uncontrollable rolled edge restricts further improvements of the machining accuracy and efficiency. Two reasons are responsible for the rolled edge problem during small tool polishing. One is that the edge areas cannot be processed because of the orbit movement. The other is that changing the tool influence function (TIF) is difficult to compensate for in algorithms, since pressure step appears in the local pressure distribution at the surface edge. In this paper, an acentric tool influence function (A-TIF) is designed to remove the rolled edge after CCOS polishing. The model of A-TIF is analyzed theoretically, and a control point translation dwell time algorithm is used to verify that the full aperture of the workpiece can be covered by the peak removal point of the tool influence functions. Thus, surface residual error in the full aperture can be effectively corrected. Finally, the experiments are carried out. Two fused silica glass samples of 100 mm x 100 mm are polished by traditional CCOS and the A-TIF method, respectively. The rolled edge was clearly produced in the sample polished by the traditional CCOS, while residual errors do not show this problem the sample polished by the A-TIF method. Therefore, the rolled edge caused by the traditional CCOS process is successfully suppressed during the A-TIF process. The ability to suppress the rolled edge of the designed A-TIF has been confirmed. (C) 2017 Optical Society of America
SN 1559-128X
EI 2155-3165
PD MAY 20
PY 2017
VL 56
IS 15
BP 4330
EP 4337
DI 10.1364/AO.56.004330
UT WOS:000401839000016
PM 29047857
ER

PT J
AU Gaspar, J
   Fontul, M
   Henriques, E
   Silva, A
AF Gaspar, Jose
   Fontul, Mihail
   Henriques, Elsa
   Silva, Arlindo
TI Haptics of in-car radio buttons and its relationship with engineering
   parameters
SO INTERNATIONAL JOURNAL OF INDUSTRIAL ERGONOMICS
AB The interaction with in-car interfaces is becoming complex and multidimensional due to the addition of more and more technologies and functionalities, which can have a negative impact on driving safety. The hand exploratory behavior of in-car interfaces has been studied aiming to minimize the mental overload of the driver when looking for radio functions. Also, the subjective and emotional values associated with the interface have been considered. However, the identification and translation of these needs into design specifications is problematic. The objective of this paper is to contribute to a better understanding of these issues by studying the relationships between users' preferences and engineering parameters of in-car radio buttons and, on the other hand, the identification of the more important engineering parameters for a better definition of the in-car interface requirements. The research was done based on an empirical study and the analysis combined exploratory statistics of preference ratings and qualitative content analysis, with partial least squares regressions and artificial neural networks to link the preferences with the buttons' engineering parameters.
   Relevance to industry: This paper proposes a set of haptic engineering parameters for in-car interface buttons in order to help the manufacturers and their clients to better define interface requirements related to subjective needs of the user, and so, with a positive impact on product development costs and delays. The developed methodology can be also used in other products. (C) 2017 Elsevier B.V. All rights reserved.
RI fontul, mihail/E-2888-2017; Henriques, E./B-3756-2013; Silva,
   Arlindo/A-4735-2013; Gaspar, Jose/K-8544-2015
OI fontul, mihail/0000-0001-9959-8724; Henriques, E./0000-0002-4947-101X;
   Silva, Arlindo/0000-0001-5120-3914; Gaspar, Jose/0000-0002-6770-4737
SN 0169-8141
EI 1872-8219
PD MAY
PY 2017
VL 59
BP 29
EP 45
DI 10.1016/j.ergon.2017.03.005
UT WOS:000401600600004
ER

PT J
AU Chen, Z
   Chen, YZ
   Wang, XF
   Wang, C
   Yan, RX
   Zhang, ZD
AF Chen, Zhen
   Chen, Yong-Zi
   Wang, Xiao-Feng
   Wang, Chuan
   Yan, Ren-Xiang
   Zhang, Ziding
TI Prediction of Ubiquitination Sites by Using the Composition of k-Spaced
   Amino Acid Pairs
SO PLOS ONE
AB As one of the most important reversible protein post-translation modifications, ubiquitination has been reported to be involved in lots of biological processes and closely implicated with various diseases. To fully decipher the molecular mechanisms of ubiquitination-related biological processes, an initial but crucial step is the recognition of ubiquitylated substrates and the corresponding ubiquitination sites. Here, a new bioinformatics tool named CKSAAP_UbSite was developed to predict ubiquitination sites from protein sequences. With the assistance of Support Vector Machine (SVM), the highlight of CKSAAP_UbSite is to employ the composition of k-spaced amino acid pairs surrounding a query site (i.e. any lysine in a query sequence) as input. When trained and tested in the dataset of yeast ubiquitination sites (Radivojac et al, Proteins, 2010, 78: 365-380), a 100-fold cross-validation on a 1: 1 ratio of positive and negative samples revealed that the accuracy and MCC of CKSAAP_UbSite reached 73.40% and 0.4694, respectively. The proposed CKSAAP_UbSite has also been intensively benchmarked to exhibit better performance than some existing predictors, suggesting that it can be served as a useful tool to the community. Currently, CKSAAP_UbSite is freely accessible at http://protein.cau.edu.cn/cksaap_ubsite/. Moreover, we also found that the sequence patterns around ubiquitination sites are not conserved across different species. To ensure a reasonable prediction performance, the application of the current CKSAAP_UbSite should be limited to the proteome of yeast.
RI Wang, Chuan/B-7071-2012; , zidingzhang/E-9320-2011
OI Wang, Chuan/0000-0001-5143-1714; , zidingzhang/0000-0002-9296-571X;
   chen, yongzi/0000-0003-3396-7130; Chen, Zhen/0000-0002-9412-9774
SN 1932-6203
PD JUL 29
PY 2011
VL 6
IS 7
AR e22930
DI 10.1371/journal.pone.0022930
UT WOS:000293286500055
PM 21829559
ER

PT J
AU KUTTY, VR
   BALAKRISHNAN, KG
   JAYASREE, AK
   THOMAS, J
AF KUTTY, VR
   BALAKRISHNAN, KG
   JAYASREE, AK
   THOMAS, J
TI PREVALENCE OF CORONARY HEART-DISEASE IN THE RURAL-POPULATION OF
   THIRUVANANTHAPURAM DISTRICT, KERALA, INDIA
SO INTERNATIONAL JOURNAL OF CARDIOLOGY
AB To establish the prevalence, with 95% confidence limits, of some of the indicators of coronary heart disease in the rural population of Thiruvananthapuram district, Kerala state, India, we did a field survey on a cluster sample with probability proportionate to size (PPS sample) of 500 households from five villages. Altogether the sample consisted of 1253 individuals who were more than 25 years of age, of which 1130 responded (90%). The survey instruments included the Malayalam translation of the Rose questionnaire, a standard 12-lead electrocardiogram with a battery operated portable electrocardiograph machine, blood pressure measurements using a mercury sphygmomanometer, and routine anthropometric measurements. The prevalence rates estimated were: (a) ECG changes suggestive of coronary heart disease, 36/1000 (95% C.L., 18, 55), (b) Rose questionnaire angina, 48/1000 (95% C.L. 35, 62), (c) definitive evidence of coronary heart disease, 14/1000 (95% C.L., 7, 21), (d) possible evidence of coronary heart disease, 74/1000 (95% C.L., 55, 93). Prevalence of major risk factors were, (a) hypertension by the WHO criteria, 179/1000 (95% C.L., 137, 221), (b) smoking, 219/1000 (95% C.L., 151, 287), (c) diabetes, 40/1000 (95% C.L., 17, 63), (d) obesity, 5511000 (95% C.L., 6, 104). We have found that objective criteria indicate a lower prevalence of coronary heart disease in rural Thiruvananthapuram district when compared to studies from urban centres in India, but the prevalence of angina by Rose questionnaire is greater.
SN 0167-5273
PD APR
PY 1993
VL 39
IS 1
BP 59
EP 70
UT WOS:A1993LC31800008
PM 8407009
ER

PT J
AU Mabokela, KR
   Celik, T
   Raborife, M
AF Mabokela, Koena Ronny
   Celik, Turgay
   Raborife, Mpho
TI Multilingual Sentiment Analysis for Under-Resourced Languages: A
   Systematic Review of the Landscape
SO IEEE ACCESS
AB Sentiment analysis automatically evaluates people's opinions of products or services. It is an emerging research area with promising advancements in high-resource languages such as Indo-European languages (e.g. English). However, the same cannot be said for languages with limited resources. In this study, we evaluate multilingual sentiment analysis techniques for under-resourced languages and the use of high-resourced languages to develop resources for low-resource languages. The ultimate goal is to identify appropriate strategies for future investigations. We report over 35 studies with different languages demonstrating an interest in developing models for under-resourced languages in a multilingual context. Furthermore, we illustrate the drawbacks of each strategy used for sentiment analysis. Our focus is to critically compare methods, employed datasets and identify research gaps. This study contributes to theoretical literature reviews with complete coverage of multilingual sentiment analysis studies from 2008 to date. Furthermore, we demonstrate how sentiment analysis studies have grown tremendously. Finally, because most studies propose methods based on deep learning approaches, we offer a deep learning framework for multilingual sentiment analysis that does not rely on the machine translation system. According to the meta-analysis protocol of this literature review, we found that, in general, just over 60% of the studies have used deep learning frameworks, which significantly improved the sentiment analysis performance. Therefore, deep learning methods are recommended for the development of multilingual sentiment analysis for under-resourced languages.
SN 2169-3536
PY 2023
VL 11
BP 15996
EP 16020
DI 10.1109/ACCESS.2022.3224136
UT WOS:000937102900001
ER

PT J
AU Wang, R
   Chen, Z
   Yin, FL
AF Wang, Rui
   Chen, Zhe
   Yin, Fuliang
TI DOA-Based Three-Dimensional Node Geometry Calibration in Acoustic Sensor
   Networks and Its Cramer-Rao Bound and Sensitivity Analysis
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB Acoustic sensor networks (ASNs) are widely applied in scenarios like teleconference, teaching, and theatre. ASNs can be used in tracking speakers, enhancing the speaker's speech and human-machine interactions, etc., but the geometric structure of the ASN has to be calibrated. ASN geometry calibration is a challenging task due to the irregular geometric structures of ASNs. A three-dimensional (3D) node geometry calibration approach based on direction of arrival (DOA) measurements and artificial bee colony (ABC) algorithm is proposed in this paper. The theoretical DOAs of sound sources relative to nodes are first derived based on 3D rotation matrices and translation vectors, and the corresponding measured DOAs are estimated by the time-difference-of-arrival. Then, the node geometry calibration problem is formulated as the minimization of a cost function measuring the mismatch between theoretical and measured DOAs, and such non-convex minimization is effectively solved by the ABC algorithm. Next, Cramer-Rao bound is presented to provide a theoretical lower bound for DOA-based node geometry calibration. Finally, the sensitivity of the proposed method to the sound source position error is discussed. The proposed method can calibrate node geometry positions successfully in both 2D plane and 3D space and requires no information transmission among nodes when the positions of few sound sources and the relative geometry of microphones in each node are known. Experimental results reveal the validity of the proposed node geometry calibration method.
RI CHEN, ZHE/B-1176-2011
OI CHEN, ZHE/0000-0002-6822-9667
SN 2329-9290
PD SEP
PY 2019
VL 27
IS 9
BP 1455
EP 1468
DI 10.1109/TASLP.2019.2921892
UT WOS:000473469800005
ER

PT J
AU Mazza, G
   Al-Akkad, W
   Rombouts, K
   Pinzani, M
AF Mazza, Giuseppe
   Al-Akkad, Walid
   Rombouts, Krista
   Pinzani, Massimo
TI Liver Tissue Engineering: From Implantable Tissue to Whole Organ
   Engineering
SO HEPATOLOGY COMMUNICATIONS
AB The term "liver tissue engineering" summarizes one of the ultimate goals of modern biotechnology: the possibility of reproducing in total or in part the functions of the liver in order to treat acute or chronic liver disorders and, ultimately, create a fully functional organ to be transplanted or used as an extracorporeal device. All the technical approaches in the area of liver tissue engineering are based on allocating adult hepatocytes or stem cell-derived hepatocyte-like cells within a three-dimensional structure able to ensure their survival and to maintain their functional phenotype. The hosting structure can be a construct in which hepatocytes are embedded in alginate and/or gelatin or are seeded in a pre-arranged scaffold made with different types of biomaterials. According to a more advanced methodology termed three-dimensional bioprinting, hepatocytes are mixed with a bio-ink and the mixture is printed in different forms, such as tissue-like layers or spheroids. In the last decade, efforts to engineer a cell microenvironment recapitulating the dynamic native extracellular matrix have become increasingly successful, leading to the hope of satisfying the clinical demand for tissue (or organ) repair and replacement within a reasonable timeframe. Indeed, the preclinical work performed in recent years has shown promising results, and the advancement in the biotechnology of bioreactors, ex vivo perfusion machines, and cell expansion systems associated with a better understanding of liver development and the extracellular matrix microenvironment will facilitate and expedite the translation to technical applications.
RI Rombouts, Krista/ABB-2602-2020; Rombouts, Krista/AAE-8179-2020
OI Rombouts, Krista/0000-0001-9440-0571
EI 2471-254X
PD FEB
PY 2018
VL 2
IS 2
BP 131
EP 141
DI 10.1002/hep4.1136
UT WOS:000452332700003
PM 29404520
ER

PT J
AU Li, EZ
   Du, PJ
   Samat, A
   Meng, YP
   Che, MQ
AF Li, Erzhu
   Du, Peijun
   Samat, Alim
   Meng, Yaping
   Che, Meiqin
TI Mid-Level Feature Representation via Sparse Autoencoder for Remotely
   Sensed Scene Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
AB Feature representation is a classic problem in the machine learning community due to the fact that different representations can entangle and hide more or less the different explanatory factors of variation behind the raw data. Especially for scene classification, its performance generally depends on the discriminative power of feature representation. Recently, unsupervised feature learning attracts tremendous attention because of its ability to learn feature representation automatically. However, reliable performance of feature representations by unsupervised learning always requires a large number of features and complex framework of mid-level feature representation. To alleviate such drawbacks, this paper presents a new framework of mid-level feature representation, which does not need learnmany convolutional features during the unsupervised feature learning process, and has few parameter settings. In detail, the unsupervised feature learning method, sparse autoencoder, is employed to learn relatively small number of convolutional features from input dataset, and then extended features are extracted from the learned features by a multiple normalized difference features extraction method to compose a derivative feature set. At mid-level feature representation stage, in order to avoid poor performance of standard pooling technology in solving problems brought by rotation and translation of scene images, global feature descriptors (histogram moments, mean, variance, standard deviation) are utilized to build mid-level feature representations of images. For validation and comparison purposes, the proposed approach is evaluated via experiments with two challenging high-resolution remote sensing datasets. The results demonstrate that the approach is effective, and shows strong performance for remotely sensed scene classification.
RI Samat, Alim/H-5309-2019
OI Samat, Alim/0000-0002-9091-6033; Du, Peijun/0000-0002-2488-2656
SN 1939-1404
EI 2151-1535
PD MAR
PY 2017
VL 10
IS 3
BP 1068
EP 1081
DI 10.1109/JSTARS.2016.2621011
UT WOS:000395876100022
ER

PT C
AU Wei, CW
   Nguyen, TM
   Xia, JJ
   Arnal, B
   Pelivanov, I
   O'Donnell, M
AF Wei, Chen-wei
   Thu-Mai Nguyen
   Xia, Jinjun
   Arnal, Bastien
   Pelivanov, Ivan
   O'Donnell, Matthew
BE Oraevsky, AA
   Wang, LV
TI Real-time interleaved photoacoustic/ultrasound (PAUS) imaging for
   interventional procedure guidance
SO PHOTONS PLUS ULTRASOUND: IMAGING AND SENSING 2015
SE Proceedings of SPIE
CT Conference on Photons Plus Ultrasound - Imaging and Sensing
CY FEB 08-10, 2015
CL San Francisco, CA
SP SPIE, Seno Med Instruments Inc
AB Ultrasound-guided photoacoustic imaging has shown great potential for many clinical applications including vascular visualization, detection of nanoprobes sensing molecular profiles, and guidance of interventional procedures. However, bulky and costly lasers are usually required to provide sufficient pulse energies for deep imaging. The low pulse repetition rate also limits potential real-time applications of integrated photoacoustic/ultrasound (PAUS) imaging. With a compact and low-cost laser operating at a kHz repetition rate, we aim to integrate photoacoustics (PA) into a commercial ultrasound (US) machine utilizing an interleaved scanning approach for clinical translation, with imaging depth up to a few centimeters and frame rates > 30 Hz. Multiple PA sub-frames are formed by scanning laser firings covering a large scan region with a rotating galvo mirror, and then combined into a final frame. Ultrasound pulse-echo beams are interleaved between laser firings/PA receives. The approach was implemented with a diode-pumped laser, a commercial US scanner, and a linear array transducer. Insertion of an 18-gauge needle into a piece of chicken tissue, with subsequent injection of an absorptive agent into the tissue, was imaged with an integrated PAUS frame rate of 30 Hz, covering a 2.8 cm x 2.8 cm imaging plane. Given this real-time image rate and high contrast (> 40 dB at more than 1-cm depth in the PA image), we have demonstrated that this approach is potentially attractive for clinical procedure guidance.
RI Xia, Jinjun/GQQ-9985-2022
OI Arnal, Bastien/0000-0002-4905-2915; Xia, Jinjun/0000-0002-4892-5817
SN 0277-786X
BN 978-1-62841-413-4
PY 2015
VL 9323
AR 93233J
DI 10.1117/12.2084704
UT WOS:000354517500082
PM 36247362
ER

PT J
AU Dakel, M
   Baguet, S
   Dufour, R
AF Dakel, Mzaki
   Baguet, Sebastien
   Dufour, Regis
TI Nonlinear dynamics of a support-excited flexible rotor with hydrodynamic
   journal bearings
SO JOURNAL OF SOUND AND VIBRATION
AB The major purpose of this study is to predict the dynamic behavior of an on-board rotor mounted on hydrodynamic journal bearings in the presence of rigid support movements, the target application being turbochargers of vehicles or rotating machines subject to seismic excitation. The proposed on-board rotor model is based on Timoshenko beam finite elements. The dynamic modeling takes into account the geometric asymmetry of shaft and/or rigid disk as well as the six deterministic translations and rotations of the rotor rigid support. Depending on the type of analysis used for the bearing, the fluid film forces computed with the Reynolds equation are linear/nonlinear. Thus the application of Lagrange's equations yields the linear/nonlinear equations of motion of the rotating rotor in bending with respect to the moving rigid support which represents a non-inertial frame of reference. These equations are solved using the implicit Newmark time-step integration scheme. Due to the geometric asymmetry of the rotor and to the rotational motions of the support, the equations of motion include time-varying parametric terms which can lead to lateral dynamic instability. The influence of sinusoidal rotational or translational motions of the support, the accuracy of the linear 8-coefficient bearing model and the interest of the nonlinear model for a hydrodynamic journal bearing are examined and discussed by means of stability charts, orbits of the rotor, time history responses, fast Fourier transforms, bifurcation diagrams as well as Poincare maps. (C) 2014 Elsevier Ltd. All rights reserved.
RI Dufour, Régis Y/H-9941-2016; Baguet, Sebastien/M-7326-2015
OI Baguet, Sebastien/0000-0002-1821-8476
SN 0022-460X
EI 1095-8568
PD MAY 12
PY 2014
VL 333
IS 10
BP 2774
EP 2799
DI 10.1016/j.jsv.2013.12.021
UT WOS:000333504500006
ER

PT C
AU Boulares, M
   Jemni, M
AF Boulares, Mehrez
   Jemni, Mohamed
GP IEEE
TI Toward a mobile service for hard of hearing people to make information
   accessible anywhere
SO 2013 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND SOFTWARE
   APPLICATIONS (ICEESA)
CT 1st International Conference on Electrical Engineering and Software
   Applications (ICEESA)
CY MAR 21-23, 2013
CL Hammamet, TUNISIA
SP IEEE, IEEE Tunisia Sect, Assoc Tunisienne Tech Numeriques & Automatique, Ministere Enseignement Superieur & Rech Sci & Technologie, Univ Tunis, Ecole Nationale Superieure Ingenieurs Tunis
AB Deaf and hard of hearing people can find it difficult to follow the rapid pace of our daily life. This problem is due to the lack of services that increase access to information. Regarding hearing impairment there is no specific solutions to make information accessible anywhere. Although this community has very specific needs related to the learning and understanding process of any written language. However, hearing impairment is an invisible disability which is quite frequent: it is estimated that more than 8% of world's population suffers from hearing loss. According to many studies reading level of hearing impaired students is lower than reading level of hearing students. In fact many deaf people have difficulties with reading and writing; they cannot read and understand all the information found in a newspaper, in vending machine to take a conveyance, in instruction leaflet etc ... Mainly all visual textual information are not accessible for this category of people with disabilities. However, a number of obstacles still have to be removed to make the information really accessible for all and this is crucial for their personal development and their successful integration.
   In this paper we propose a solution to this problem by providing a mobile translation system using the great technological advances in smart phones to improve the information accessibility anywhere. We rely on text image processing, virtual reality 3D modeling and cloud computing to generate a real-time sign language interpretation by using high virtual character quality.
RI Jemni, Mohamed/HCI-9541-2022
OI Jemni, Mohamed/0000-0001-8841-5224; boulares, mehrez/0000-0001-6338-0301
BN 978-1-4673-6302-0; 978-1-4673-6300-6
PY 2013
BP 183
EP 187
UT WOS:000327207000033
ER

PT J
AU Shoombuatong, W
   Basith, S
   Pitti, T
   Lee, G
   Manavalan, B
AF Shoombuatong, Watshara
   Basith, Shaherin
   Pitti, Thejkiran
   Lee, Gwang
   Manavalan, Balachandran
TI THRONE: A New Approach for Accurate Prediction of Human RNA
   N7-Methyl-guanosine Sites
SO JOURNAL OF MOLECULAR BIOLOGY
AB N-7-methylguanosine (m7G) is an essential, ubiquitous, and positively charged modification at the 50 cap of eukaryotic mRNA, modulating its export, translation, and splicing processes. Although several machine learning (ML)-based computational predictors for m7G have been developed, all utilized specific computational framework. This study is the first instance we explored four different computational frameworks and identified the best approach. Based on that we developed a novel predictor, THRONE (A three layer ensemble predictor for identifying human RNA N-7-methylguanosine sites) to accurately identify m7G sites from the human genome. THRONE employs a wide range of sequence-based features inputted to several ML classifiers and combines these models through ensemble learning. The three step ensemble learning is as follows: 54 baseline models were constructed in the first layer and the predicted probability of m7G was considered as a new feature vector for the sequential step. Subsequently, six meta-models were created using the new feature vector and their predicted probability was yet again considered as novel features. Finally, random forest was deemed as the best super classifier learner for the final prediction using a systematic approach incorporated with novel features. Interestingly, THRONE outperformed other existing methods in the prediction of m7G sites on both cross-validation analysis and independent evaluation. The proposed method is publicly accessible at: http://thegleelab.org/THRONE/ and expects to help the scientific community identify the putative m7G sites and formulate a novel testable biological hypothesis. (C) 2022 Elsevier Ltd. All rights reserved.
SN 0022-2836
EI 1089-8638
PD JUN 15
PY 2022
VL 434
IS 11
AR 167549
DI 10.1016/j.jmb.2022.167549
EA JUN 2022
UT WOS:000814716800013
PM 35662472
ER

PT J
AU Scarpazza, C
   Ha, M
   Baecker, L
   Garcia-Dias, R
   Pinaya, WHL
   Vieira, S
   Mechelli, A
AF Scarpazza, C.
   Ha, M.
   Baecker, L.
   Garcia-Dias, R.
   Pinaya, W. H. L.
   Vieira, S.
   Mechelli, A.
TI Translating research findings into clinical practice: a systematic and
   critical review of neuroimaging-based clinical tools for brain disorders
SO TRANSLATIONAL PSYCHIATRY
AB A pivotal aim of psychiatric and neurological research is to promote the translation of the findings into clinical practice to improve diagnostic and prognostic assessment of individual patients. Structural neuroimaging holds much promise, with neuroanatomical measures accounting for up to 40% of the variance in clinical outcome. Building on these findings, a number of imaging-based clinical tools have been developed to make diagnostic and prognostic inferences about individual patients from their structural Magnetic Resonance Imaging scans. This systematic review describes and compares the technical characteristics of the available tools, with the aim to assess their translational potential into real-world clinical settings. The results reveal that a total of eight tools. All of these were specifically developed for neurological disorders, and as such are not suitable for application to psychiatric disorders. Furthermore, most of the tools were trained and validated in a single dataset, which can result in poor generalizability, or using a small number of individuals, which can cause overoptimistic results. In addition, all of the tools rely on two strategies to detect brain abnormalities in single individuals, one based on univariate comparison, and the other based on multivariate machine-learning algorithms. We discuss current barriers to the adoption of these tools in clinical practice and propose a checklist of pivotal characteristics that should be included in an "ideal" neuroimaging-based clinical tool for brain disorders.
RI Scarpazza, Cristina/AAA-2306-2022; Garcia-Dias, Rafael/AAE-9072-2022;
   Mechelli, Andrea/B-1114-2011; Vieira, Sandra/HNI-7805-2023
OI Scarpazza, Cristina/0000-0002-4126-426X; Ha, Minji/0000-0002-9840-6695;
   Vieira, Sandra/0000-0002-2141-1963; Garcia-Dias,
   Rafael/0000-0001-9332-1580
SN 2158-3188
PD APR 20
PY 2020
VL 10
IS 1
AR 107
DI 10.1038/s41398-020-0798-6
UT WOS:000529213700002
PM 32313006
ER

PT J
AU Atutxa, A
   de Ilarraza, AD
   Gojenola, K
   Oronoz, M
   Perez-de-Vinaspre, O
AF Atutxa, Aitziber
   Diaz de Ilarraza, Arantza
   Gojenola, Koldo
   Oronoz, Maite
   Perez-de-Vinaspre, Olatz
TI Interpretable deep learning to map diagnostic texts to ICD-10 codes
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
AB Background: Automatic extraction of morbid disease or conditions contained in Death Certificates is a critical process, useful for billing, epidemiological studies and comparison across countries. The fact that these clinical documents are written in regular natural language makes the automatic coding process difficult because, often, spontaneous terms diverge strongly from standard reference terminology such as the International Classification of Diseases (ICD).
   Objective: Our aim is to propose a general and multilingual approach to render Diagnostic Terms into the standard framework provided by the ICD. We have evaluated our proposal on a set of clinical texts written in French, Hungarian and Italian.
   Methods: ICD-10 encoding is a multi-class classification problem with an extensive (thousands) number of classes. After considering several approaches, we tackle our objective as a sequence-to-sequence task. According to current trends, we opted to use neural networks. We tested different types of neural architectures on three datasets in which Diagnostic Terms (DTs) have their ICD-10 codes associated.
   Results and conclusions: Our results give a new state-of-the art on multilingual ICD-10 coding, outperforming several alternative approaches, and showing the feasibility of automatic ICD-10 prediction obtaining an F-measure of 0.838, 0.963 and 0.952 for French, Hungarian and Italian, respectively. Additionally, the results are interpretable, providing experts with supporting evidence when confronted with coding decisions, as the model is able to show the alignments between the original text and each output code.
RI Gojenola, Koldo/Z-5616-2019; Atutxa, Aitziber/AAA-2778-2019;
   Perez-de-Viñaspre, Olatz/AAF-9197-2019; Oronoz, Maite/AAA-4858-2019
OI Gojenola, Koldo/0000-0002-2116-6611; Atutxa,
   Aitziber/0000-0003-4512-8633; ORONOZ ANCHORDOQUI,
   MAITE/0000-0001-9097-6047; Perez de Vinaspre, Olatz/0000-0002-0933-2461;
   DIAZ DE ILARRAZA SANCHEZ, MARIA ARANZAZU/0000-0003-3317-8561
SN 1386-5056
EI 1872-8243
PD SEP
PY 2019
VL 129
BP 49
EP 59
DI 10.1016/j.ijmedinf.2019.05.015
UT WOS:000483422400007
PM 31445289
ER

PT J
AU Ahmed, OJ
   Sudhakar, SK
AF Ahmed, Omar J.
   Sudhakar, Shyam Kumar
TI High-Frequency Activity During Stereotyped Low-Frequency Events Might
   Help to Identify the Seizure Onset Zone
SO EPILEPSY CURRENTS
AB High-frequency oscillations in local field potentials recorded with intracranial electroencephalogram are putative biomarkers of seizure-onset zones in epileptic brain. However, localized 80- to 500-Hz oscillations can also be recorded from normal and nonepileptic cerebral structures. When defined only by rate or frequency, physiological high-frequency oscillations are indistinguishable from pathological ones that limit their application in epilepsy presurgical planning. We hypothesized that pathological high-frequency oscillations occur in a repetitive fashion with a similar waveform morphology that specifically indicates seizure onset zones. We investigated the waveform patterns of automatically detected high-frequency oscillations in 13 patients with epilepsy and 5 control subjects, with an average of 73 subdural and intracerebral electrodes recorded per patient. The repetitive oscillatory waveforms were identified using a pipeline of unsupervised machine learning techniques and were then correlated with independently clinician-defined seizure onset zones. Consistently in all patients, the stereotypical high-frequency oscillations with the highest degree of waveform similarity were localized within the seizure onset zones only, whereas the channels generating high-frequency oscillations embedded in random waveforms were found in the functional regions independent of the epileptogenic locations. The repetitive waveform pattern was more evident in fast ripples compared to ripples, suggesting a potential association between waveform repetition and the underlying pathological network. Our findings provided a new tool for the interpretation of pathological high-frequency oscillations that can be efficiently applied to distinguish seizure onset zones from functionally important sites, which is a critical step toward the translation of these signature events into valid clinical biomarkers.
RI Sudhakar, Shyam Kumar/K-9321-2019
SN 1535-7597
EI 1535-7511
PD MAY-JUN
PY 2019
VL 19
IS 3
BP 184
EP 186
DI 10.1177/1535759719842236
UT WOS:000470072500011
PM 31012323
ER

PT J
AU Prakash, O
   Gwak, J
   Khare, M
   Khare, A
   Jeon, M
AF Prakash, Om
   Gwak, Jeonghwan
   Khare, Manish
   Khare, Ashish
   Jeon, Moongu
TI Human detection in complex real scenes based on combination of
   biorthogonal wavelet transform and Zernike moments
SO OPTIK
AB Human detection in real scenes with high complexity is a crucial problem in computer vision research. For tackling the human detection task, several existing methods adopt one feature or combination of features to detect human objects. In this work, we propose a new combination of features based algorithm for human detection, which identifies the presence of a human, in complex real scenes. In the combination, the two features (i) biorthogonal wavelet transform (BWT) and (ii) Zernike moments (ZM) have been used. The approximate shift-invariance and symmetry properties of BWT facilitate the human detection in the wavelet domain. Specifically, the shift-invariance property of BWT is effective for translated object representation whereas the symmetry property yields perfect reconstruction for retaining object boundaries (i.e., edges). Moreover, translation and rotation-invariance properties of ZM are especially beneficial for the representation of varying pose and orientation of the human objects. For these reasons, the composite of the two features brings about significant synthesized benefits over each single feature and the other widely used features. In the experiments for human detection, we used two classifiers, AdaBoost and support vector machines, respectively, for the comparative study purpose, and the standard INRIA dataset and DaimlerChrysler dataset were used for the evaluations. Experimental results demonstrated the significant outperformance of the proposed method through quantitative evaluations and also suggest that the proposed hybridization of features is preferable for the classification problem. (C) 2017 Elsevier GmbH. All rights reserved.
RI Prakash, Om/AAL-4460-2021; Jeon, Moongu/A-1009-2012; Khare,
   Manish/AAF-4582-2019; Khare, Ashish/D-4566-2012
OI Prakash, Om/0000-0001-6395-9989; Khare, Manish/0000-0002-2296-2732;
   Gwak, Jeonghwan/0000-0002-6237-0141
SN 0030-4026
EI 1618-1336
PY 2018
VL 157
BP 1267
EP 1281
DI 10.1016/j.ijleo.2017.12.061
UT WOS:000424186500155
ER

PT J
AU Khan, M
   Hayat, M
   Khan, SA
   Ahmad, S
   Iqbal, N
AF Khan, Muslim
   Hayat, Maqsood
   Khan, Sher Afzal
   Ahmad, Saeed
   Iqbal, Nadeem
TI Bi-PSSM: Position specific scoring matrix based intelligent
   computational model for identification of mycobacterial membrane
   proteins
SO JOURNAL OF THEORETICAL BIOLOGY
AB Mycobacterium is a pathogenic bacterium, which is a causative agent of tuberculosis (TB) and leprosy. These diseases are very crucial and become the cause of death of millions of people every year in the world. So, the characterize structure of membrane proteins of the protozoan play a vital role in the field of drug discovery because, without any knowledge about this Mycobacterium's membrane protein and their types, the scientists are unable to treat this pathogenic protozoan. So, an accurate and competitive computational model is needed to characterize this uncharacterized structure of mycobacterium. Series of attempts were carried out in this connection. Split amino acid compositions, Unbiased-Dipeptide peptide compositions (Unb-DPC), Over-represented tri-peptide compositions, compositions & translation were the few recent encoding techniques followed by different researchers in their publications. Although considerable results have been achieved by these models, still there is a gap which is filled in this study. In this study, an evolutionary feature extraction technique position specific scoring matrix (PSSM) is applied in order to extract evolutionary information from protein sequences. Consequently, 99.6% accuracy was achieved by the learning algorithms. The experimental results demonstrated that the proposed computational model will lead to develop a powerful tool for anti-mycobacterium drugs as well as play a promising rule in proteomic and bioinformatics. (C) 2017 Elsevier Ltd. All rights reserved.
RI IQBAL, Nadeem/AAD-8697-2019; Hayat, Maqsood/M-5941-2018; Hayat,
   Maqsood/ABB-7275-2021; Khan, Sher Afzal/H-2958-2012
OI IQBAL, Nadeem/0000-0003-1050-1792; Khan, Sher Afzal/0000-0003-0273-1248;
   Ahmed, Saeed/0000-0001-6910-7613
SN 0022-5193
EI 1095-8541
PD DEC 21
PY 2017
VL 435
BP 116
EP 124
DI 10.1016/j.jtbi.2017.09.013
UT WOS:000413499000012
PM 28927812
ER

PT J
AU Hajmohammadi, MS
   Ibrahim, R
   Selamat, A
   Fujita, H
AF Hajmohammadi, Mohammad Sadegh
   Ibrahim, Roliana
   Selamat, Ali
   Fujita, Hamido
TI Combination of active learning and self-training for cross-lingual
   sentiment classification with density analysis of unlabelled samples
SO INFORMATION SCIENCES
AB In recent years, research in sentiment classification has received considerable attention by natural language processing researchers. Annotated sentiment corpora are the most important resources used in sentiment classification. However, since most recent research works in this field have focused on the English language, there are accordingly not enough annotated sentiment resources in other languages. Manual construction of reliable annotated sentiment corpora for a new language is a labour-intensive and time-consuming task. Projection of sentiment corpus from one language into another language is a natural solution used in cross-lingual sentiment classification. Automatic machine translation services are the most commonly tools used to directly project information from one language into another. However, since term distribution across languages may be different due to variations in linguistic terms and writing styles, cross-lingual methods cannot reach the performance of monolingual methods. In this paper, a novel learning model is proposed based on the combination of uncertainty-based active learning and semi-supervised self-training approaches to incorporate unlabelled sentiment documents from the target language in order to improve the performance of cross-lingual methods. Further, in this model, the density measures of unlabelled examples are considered in active learning part in order to avoid outlier selection. The empirical evaluation on book review datasets in three different languages shows that the proposed model can significantly improve the performance of cross-lingual sentiment classification in comparison with other existing and baseline methods. (C) 2015 Elsevier Inc. All rights reserved.
RI Fujita, Hamido/D-6249-2012; Selamat, Ali/E-9645-2011; Hajmohammadi,
   Mohammad Sadegh/G-5825-2014
OI Fujita, Hamido/0000-0001-5256-210X; Selamat, Ali/0000-0001-9746-8459;
   Hajmohammadi, Mohammad Sadegh/0000-0002-4270-0035
SN 0020-0255
EI 1872-6291
PD OCT 1
PY 2015
VL 317
BP 67
EP 77
DI 10.1016/j.ins.2015.04.003
UT WOS:000358093400004
ER

PT J
AU Lajer, CB
   Nielsen, FC
   Friis-Hansen, L
   Norrild, B
   Borup, R
   Garnaes, E
   Rossing, M
   Specht, L
   Therkildsen, MH
   Nauntofte, B
   Dabelsteen, S
   von Buchwald, C
AF Lajer, C. B.
   Nielsen, F. C.
   Friis-Hansen, L.
   Norrild, B.
   Borup, R.
   Garnaes, E.
   Rossing, M.
   Specht, L.
   Therkildsen, M. H.
   Nauntofte, B.
   Dabelsteen, S.
   von Buchwald, C.
TI Different miRNA signatures of oral and pharyngeal squamous cell
   carcinomas: a prospective translational study
SO BRITISH JOURNAL OF CANCER
AB BACKGROUND: MicroRNAs (miRNAs) are small non-coding RNAs, which regulate mRNA translation/decay, and may serve as biomarkers. We characterised the expression of miRNAs in clinically sampled oral and pharyngeal squamous cell carcinoma (OSCC and PSCC) and described the influence of human papilloma virus (HPV).
   METHODS: Biopsies obtained from 51 patients with OSCC/PSCC and 40 control patients were used for microarray analysis. The results were correlated to clinical data and HPV status. Supervised learning by support vector machines was employed to generate a diagnostic miRNA signature.
   RESULTS: One hundred and fourteen miRNAs were differentially expressed between OSCC and normal oral epithelium, with the downregulation of miR-375 and upregulation of miR-31 as the most significant aberrations. Pharyngeal squamous cell carcinoma exhibited 38 differentially expressed miRNAs compared with normal pharyngeal epithelium. Differences in the miRNA expression pattern of both normal epithelium and SCC were observed between the oral cavity compared with the pharynx. Human papilloma virus infection revealed perturbations of 21 miRNAs, most significantly in miR-127-3p and miR363. A molecular classifier including 61 miRNAs was generated for OSCC with an accuracy of 93%.
   CONCLUSION: MicroRNAs may serve as useful biomarkers in OSCC and PSCC. The influence of HPV on miRNA may provide a mechanism for the distinct clinical behaviour of HPV-infected tumours. British Journal of Cancer (2011) 104, 830-840. doi:10.1038/bjc. 2011.29 www.bjcancer.com Published online 15 February 2011 (C) 2011 Cancer Research UK
RI Specht, Lena/J-6422-2019; Dabelsteen, Sally/HKM-4772-2023; von Buchwald,
   Christian/D-5336-2016; Nielsen, Finn Cilius/AAA-4926-2020
OI Specht, Lena/0000-0002-6902-2190; Dabelsteen, Sally/0000-0002-4279-8060;
   von Buchwald, Christian/0000-0001-6753-8129; Friis-Hansen,
   Lennart/0000-0002-7222-0163
SN 0007-0920
PD MAR 1
PY 2011
VL 104
IS 5
BP 830
EP 840
DI 10.1038/bjc.2011.29
UT WOS:000287918200012
PM 21326242
ER

PT J
AU Olatunji, JR
   Redding, GP
   Rowe, CL
   East, AR
AF Olatunji, J. R.
   Redding, G. P.
   Rowe, C. L.
   East, A. R.
TI Reconstruction of kiwifruit fruit geometry using a CGAN trained on a
   synthetic dataset
SO COMPUTERS AND ELECTRONICS IN AGRICULTURE
AB Non-destructive crop yield estimation is a major ambition for the development of digital horticulture systems, where the goal is to have a machine that can look at fruit on the vine/tree and estimate key performance metrics such as fruit weight, size and shape. The on-orchard partial occlusion problem is a major obstacle for the creation of such systems, where it is not possible for a single camera/scanner to capture the complete fruit surface due to its limited field of view. In this work, a deep learning approach was taken to solve this problem. Framing the issue as an image-to-image translation problem, a Conditional Generative Adversarial Network was trained to realistically reconstruct the enclosed and complete surface of kiwifruit when supplied with incomplete surface data, where the surface data was missing due to occlusion. Rather than training the deep learning algorithm with empirically collected data, an alternative approach was taken: the model was trained using a synthesised dataset, a large collection of kiwifruit shapes generated computationally via a Monte-Carlo routine. This was an attempt to generalise the approach to be applicable to other crops and other domains, and to provide substantial savings in time, labour and material costs. The trained model was later applied to a smaller population of kiwifruit empirically scanned using an infrared scanner and could predict fruit weight with a mean absolute percentage error of less than 5% and was successful in realistically reconstructing the whole enclosed surface over a range of sizes, shapes and orientations.
OI Olatunji, Jamal/0000-0002-2203-8873
SN 0168-1699
EI 1872-7107
PD OCT
PY 2020
VL 177
AR 105699
DI 10.1016/j.compag.2020.105699
UT WOS:000571756100011
ER

PT J
AU Dehzangi, A
   Lopez, Y
   Taherzadeh, G
   Sharma, A
   Tsunoda, T
AF Dehzangi, Abdollah
   Lopez, Yosvany
   Taherzadeh, Ghazaleh
   Sharma, Alok
   Tsunoda, Tatsuhiko
TI SumSec: Accurate Prediction of Sumoylation Sites Using Predicted
   Secondary Structure
SO MOLECULES
AB Post Translational Modification (PTM) is defined as the modification of amino acids along the protein sequences after the translation process. These modifications significantly impact on the functioning of proteins. Therefore, having a comprehensive understanding of the underlying mechanism of PTMs turns out to be critical in studying the biological roles of proteins. Among a wide range of PTMs, sumoylation is one of the most important modifications due to its known cellular functions which include transcriptional regulation, protein stability, and protein subcellular localization. Despite its importance, determining sumoylation sites via experimental methods is time-consuming and costly. This has led to a great demand for the development of fast computational methods able to accurately determine sumoylation sites in proteins. In this study, we present a new machine learning-based method for predicting sumoylation sites called SumSec. To do this, we employed the predicted secondary structure of amino acids to extract two types of structural features from neighboring amino acids along the protein sequence which has never been used for this task. As a result, our proposed method is able to enhance the sumoylation site prediction task, outperforming previously proposed methods in the literature. SumSec demonstrated high sensitivity (0.91), accuracy (0.94) and MCC (0.88). The prediction accuracy achieved in this study is 21% better than those reported in previous studies. The script and extracted features are publicly available at: https://github.com/YosvanyLopez/SumSec.
RI Tsunoda, Tatsuhiko/K-2061-2014; Sharma, Alok/AAE-4725-2022
OI Tsunoda, Tatsuhiko/0000-0002-5439-7918; Sharma, Alok/0000-0002-7668-3501
EI 1420-3049
PD DEC
PY 2018
VL 23
IS 12
AR 3260
DI 10.3390/molecules23123260
UT WOS:000454523000210
PM 30544729
ER

PT J
AU Fagiani, M
   Principi, E
   Squartini, S
   Piazza, F
AF Fagiani, Marco
   Principi, Emanuele
   Squartini, Stefano
   Piazza, Francesco
TI Signer independent isolated Italian sign recognition based on hidden
   Markov models
SO PATTERN ANALYSIS AND APPLICATIONS
AB Sign languages represent the most natural way to communicate for deaf and hard of hearing. However, there are often barriers between people using this kind of languages and hearing people, typically oriented to express themselves by means of oral languages. To facilitate the social inclusiveness in everyday life for deaf minorities, technology can play an important role. Indeed many attempts have been recently made by the scientific community to develop automatic translation tools. Unfortunately, not many solutions are actually available for the Italian Sign Language (Lingua Italiana dei Segni-LIS) case study, specially for what concerns the recognition task. In this paper, the authors want to face such a lack, in particular addressing the signer-independent case study, i.e., when the signers in the testing set are to included in the training set. From this perspective, the proposed algorithm represents the first real attempt in the LIS case. The automatic recognizer is based on Hidden Markov Models (HMMs) and video features have been extracted using the OpenCV open source library. The effectiveness of the HMM system is validated by a comparative evaluation with Support Vector Machine approach. The video material used to train the recognizer and testing its performance consists in a database that the authors have deliberately created by involving 10 signers and 147 isolated-sign videos for each signer. The database is publicly available. Computer simulations have shown the effectiveness of the adopted methodology, with recognition accuracies comparable to those obtained by the automatic tools developed for other sign languages.
RI squartini, stefano/A-3519-2010; Principi, Emanuele/B-3192-2016
OI squartini, stefano/0000-0001-9374-0128; Principi,
   Emanuele/0000-0002-2835-7277; FAGIANI, MARCO/0000-0002-0414-8040
SN 1433-7541
EI 1433-755X
PD MAY
PY 2015
VL 18
IS 2
BP 385
EP 402
DI 10.1007/s10044-014-0400-z
UT WOS:000352199700011
ER

PT J
AU Xiao, JM
   Li, YZ
   Wang, KL
   Wen, ZN
   Li, ML
   Zhang, LF
   Guang, XM
AF Xiao, Jiamin
   Li, Yizhou
   Wang, Kelong
   Wen, Zhining
   Li, Menglong
   Zhang, Lifang
   Guang, Xuanmin
TI In silico method for systematic analysis of feature importance in
   microRNA-mRNA interactions
SO BMC BIOINFORMATICS
AB Background: MicroRNA (miRNA), which is short non-coding RNA, plays a pivotal role in the regulation of many biological processes and affects the stability and/or translation of mRNA. Recently, machine learning algorithms were developed to predict potential miRNA targets. Most of these methods are robust but are not sensitive to redundant or irrelevant features. Despite their good performance, the relative importance of each feature is still unclear. With increasing experimental data becoming available, research interest has shifted from higher prediction performance to uncovering the mechanism of microRNA-mRNA interactions.
   Results: Systematic analysis of sequence, structural and positional features was carried out for two different data sets. The dominant functional features were distinguished from uninformative features in single and hybrid feature sets. Models were developed using only statistically significant sequence, structural and positional features, resulting in area under the receiver operating curves (AUC) values of 0.919, 0.927 and 0.969 for one data set and of 0.926, 0.874 and 0.954 for another data set, respectively. Hybrid models were developed by combining various features and achieved AUC of 0.978 and 0.970 for two different data sets. Functional miRNA information is well reflected in these features, which are expected to be valuable in understanding the mechanism of microRNA-mRNA interactions and in designing experiments.
   Conclusions: Differing from previous approaches, this study focused on systematic analysis of all types of features. Statistically significant features were identified and used to construct models that yield similar accuracy to previous studies in a shorter computation time.
RI meng, li/GVT-2063-2022
SN 1471-2105
PD DEC 16
PY 2009
VL 10
AR 427
DI 10.1186/1471-2105-10-427
UT WOS:000273838700001
PM 20015389
ER

PT C
AU Singh, S
   Gupta, A
   Maghan, A
   Gowda, D
   Singh, S
   Kim, C
AF Singh, Sachin
   Gupta, Ashutosh
   Maghan, Aman
   Gowda, Dhananjaya
   Singh, Shatrughan
   Kim, Chanwoo
GP IEEE
TI COMPARATIVE STUDY OF DIFFERENT TOKENIZATION STRATEGIES FOR STREAMING
   END-TO-END ASR
SO 2021 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU)
CT IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)
CY DEC 13-17, 2021
CL ELECTR NETWORK
SP Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc
AB Most End-to-End Automatic Speech Recognition (ASR) models use character-based vocabularies: characters, subwords (BPE), or words. While these work well for training a monolingual model, there are certain limitations when applying these to a multilingual model. Rare characters from character-rich languages like Korean can easily result in large vocabulary size, limiting the model's compactness. Representing text at the level of bytes has also been proposed. However, a byte sequence representation of text is often much longer, which increases the decoding time and makes it computationally expensive for on-device use. Byte-based sub-words (BBPE) are proposed in neural machine translation for word representation but are still unexplored in the ASR domain. In this work, we conduct an empirical study comparing the above three tokenization strategies across three metrics: Word Error Rate (WER), model size, and the decoding time, which are critical for an on-device ASR. We did extensive experiments for both monolingual and bilingual, with languages belonging to same (English and Spanish) and different (English and Korean) language families. Our experiments show that BBPE and BPE models yield a similar WER for English and Spanish. While for a character-rich language like Korean, we get 26% and 14% relative WER improvement with BBPE monolingual and bilingual models, respectively. In contrast, the byte models trade-off small model size and a fixed vocabulary at the cost of high xRT. Among all three, we found the BBPE strategy to be the most flexible and optimal for most cases.
BN 978-1-6654-3739-4
PY 2021
BP 388
EP 394
DI 10.1109/ASRU51503.2021.9687921
UT WOS:000792364700052
ER

PT C
AU Oliver-Butler, K
   Epps, ZH
   Rucker, DC
AF Oliver-Butler, Kaitlin
   Epps, Zane H.
   Rucker, Daniel Caleb
BE Webster, RJ
   Fei, B
TI Concentric agonist-antagonist robots for minimally invasive surgeries
SO MEDICAL IMAGING 2017: IMAGE-GUIDED PROCEDURES, ROBOTIC INTERVENTIONS,
   AND MODELING
SE Proceedings of SPIE
CT Conference on Medical Imaging - Image-Guided Procedures, Robotic
   Interventions, and Modeling
CY FEB 14-16, 2017
CL Orlando, FL
SP SPIE, Alpin Med Syst, Siemens Healthineers, No Digital Inc
AB We present a novel continuum robot design concept, Concentric Agonist-Antagonist Robots (CAAR), that uses push-pull, agonist-antagonist action of a pair of concentric tubes. The CAAR tubes are designed to have non central, offset neutral axes, and they are fixed together at their distal ends. Axial base translations then induce bending in the device. A CAAR segment can be created by selectively cutting asymmetric notches into the profile of two stock tubes, which relocates the neutral bending plane away from the center of the inner lumen. Like conventional concentric-tube robots (CTRs) based on counter-rotating precurved tubes, a CAAR can be made at very small scales and contain a large, open lumen. In contrast with CTRs, the CAAR concept has no elastic stability issues, offers a larger range of motion, and has lower overall stiffness. Furthermore, by varying the position of the neutral axes along the length of each tube, arbitrary, variable curvature actuation modes can be achieved. Precurving the tubes can additionally increase the workspace of a single segment. A single two-tube assembly can be used to create 3 degree-of-freedom (DOF) robot segments, and multiple segments can be deployed concentrically. Both additive manufacturing and traditional machining of stock tubes can create and customize the geometry and performance of the CAAR. In this paper, we explore the CAAR concept, provide kinematic and static models, and experimentally evaluate the model with a both a straight and a precurved CAAR. We conclude with a discussion of the significance and our plans for future work.
SN 0277-786X
EI 1996-756X
BN 978-1-5106-0715-6; 978-1-5106-0716-3
PY 2017
VL 10135
AR 1013511
DI 10.1117/12.2255549
UT WOS:000405560700035
ER

PT J
AU Caliva, F
   Namiri, NK
   Dubreuil, M
   Pedoia, V
   Ozhinsky, E
   Majumdar, S
AF Caliva, Francesco
   Namiri, Nikan K.
   Dubreuil, Maureen
   Pedoia, Valentina
   Ozhinsky, Eugene
   Majumdar, Sharmila
TI Studying osteoarthritis with artificial intelligence applied to magnetic
   resonance imaging
SO NATURE REVIEWS RHEUMATOLOGY
AB The 3D nature and soft-tissue contrast of MRI makes it an invaluable tool for osteoarthritis research, by facilitating the elucidation of disease pathogenesis and progression. The recent increasing employment of MRI has certainly been stimulated by major advances that are due to considerable investment in research, particularly related to artificial intelligence (AI). These AI-related advances are revolutionizing the use of MRI in clinical research by augmenting activities ranging from image acquisition to post-processing. Automation is key to reducing the long acquisition times of MRI, conducting large-scale longitudinal studies and quantitatively defining morphometric and other important clinical features of both soft and hard tissues in various anatomical joints. Deep learning methods have been used recently for multiple applications in the musculoskeletal field to improve understanding of osteoarthritis. Compared with labour-intensive human efforts, AI-based methods have advantages and potential in all stages of imaging, as well as post-processing steps, including aiding diagnosis and prognosis. However, AI-based methods also have limitations, including the arguably limited interpretability of AI models. Given that the AI community is highly invested in uncovering uncertainties associated with model predictions and improving their interpretability, we envision future clinical translation and progressive increase in the use of AI algorithms to support clinicians in optimizing patient care.
   In this Review, the authors introduce the application of artificial intelligence, in particular machine learning and deep learning, for improving multiple stages of MRI, including acquisition, processing and post-processing steps, for studying osteoarthritis.
OI Namiri, Nikan/0000-0003-2943-9546; Majumdar,
   Sharmila/0000-0002-0201-871X; Ozhinsky, Eugene/0000-0001-8993-7905
SN 1759-4790
EI 1759-4804
PD FEB
PY 2022
VL 18
IS 2
BP 112
EP 121
DI 10.1038/s41584-021-00719-7
EA NOV 2021
UT WOS:000724071100001
PM 34848883
ER

PT C
AU Yao, QJ
   Liao, XF
   Jin, H
AF Yao, Qiongjie
   Liao, Xiaofei
   Jin, Hai
BE Chen, JJ
   Yang, LT
TI Hierarchical Attention Based Recurrent Neural Network Framework For
   Mobile MOBA Game Recommender Systems
SO 2018 IEEE INT CONF ON PARALLEL & DISTRIBUTED PROCESSING WITH
   APPLICATIONS, UBIQUITOUS COMPUTING & COMMUNICATIONS, BIG DATA & CLOUD
   COMPUTING, SOCIAL COMPUTING & NETWORKING, SUSTAINABLE COMPUTING &
   COMMUNICATIONS
SE IEEE International Symposium on Parallel and Distributed Processing with
   Applications
CT 16th IEEE ISPA / 17th IEEE IUCC / 8th IEEE BDCloud / 11th IEEE SocialCom
   / 8th IEEE SustainCom
CY DEC 11-13, 2018
CL Melbourne, AUSTRALIA
SP IEEE, IEEE Comp Soc
AB The mobile multiplayer online battle arena (MOBA) game is a genre of real-time strategy video games on mobile devices, such as King of Glory. The main business model is to drive players to purchase items like heroes or skins. Recommending items based on player interest is the core task of recommender systems. In the MOBA game, player interest changes over the game experience, which is implied in player behavior based on historical game matches. Match sequences, that consist of every match in the timeline, indicate how players interact with the game and the change process of player interest. Recurrent neural networks (RNNs) are employed by many recommendation scenes to model sequence data to profile user preference for better recommendation accuracy. However, their RNNs based frameworks ignore the interpretability of recommendation results, which is an important requirement for mobile MOBA games.
   To solve this challenge, we propose an interpretable RNN framework based on hierarchical attention in this work, which is inspired by the attention mechanism applied in machine translation. The main component long short-term memory (LSTM), that is the RNN variant, models player interest from historical match sequences, and the hierarchical attention is used to measure the effect factors of matches and behavior events happened in a match. To verify effectiveness, we train several models on real mobile MOBA game King of Glory datasets. Compared to non-sequence models, our model achieves 2% higher accuracy; with hierarchical attention, the proposed model can interpret the recommendation results effectively compared to naive RNN based models.
SN 2158-9178
BN 978-1-7281-1141-4
PY 2018
BP 338
EP 345
DI 10.1109/BDCloud.2018.00060
UT WOS:000467843200046
ER

PT C
AU Moon, T
   Choi, H
   Lee, H
   Song, I
AF Moon, Taesup
   Choi, Heeyoul
   Lee, Hoshik
   Song, Inchul
GP IEEE
TI RNNDROP: A NOVEL DROPOUT FOR RNNS IN ASR
SO 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING
   (ASRU)
CT IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)
CY DEC 13-17, 2015
CL Scottsdale, AR
SP IEEE, IEEE Signal Processing Soc, Inst Elect & Elect Engn
AB Recently, recurrent neural networks (RNN) have achieved the state-of-the-art performance in several applications that deal with temporal data, e.g., speech recognition, handwriting recognition and machine translation. While the ability of handling long-term dependency in data is the key for the success of RNN, combating over-fitting in training the models is a critical issue for achieving the cutting-edge performance particularly when the depth and size of the network increase. To that end, there have been some attempts to apply the dropout, a popular regularization scheme for the feed-forward neural networks, to RNNs, but they do not perform as well as other regularization scheme such as weight noise injection. In this paper, we propose rnnDrop, a novel variant of the dropout tailored for RNNs. Unlike the existing methods where dropout is applied only to the non-recurrent connections, the proposed method applies dropout to the recurrent connections as well in such a way that RNNs generalize well. Our experiments show that rnnDrop is a better regularization method than others including weight noise injection. Namely, when deep bidirectional long short-term memory (LSTM) RNNs were trained with rnnDrop as acoustic models for phoneme and speech recognition, they significantly outperformed the current state-of-the-arts; we achieved the phoneme error rate of 16.29% on the TIMIT core test set for phoneme recognition and the word error rate of 5.53% on the Wall Street Journal (WSJ) dataset, dev93, for speech recognition, which are the best reported results on both of the datasets.
BN 978-1-4799-7291-3
PY 2015
BP 65
EP 70
UT WOS:000380604800010
ER

PT J
AU Martin-Nielsen, J
AF Martin-Nielsen, Janet
TI 'This war for men's minds': the birth of a human science in Cold War
   America
SO HISTORY OF THE HUMAN SCIENCES
AB The past decade has seen an explosion of work on the history of the human sciences during the Cold War. This work, however, does not engage with one of the leading human sciences of the period: linguistics. This article begins to rectify this knowledge gap by investigating the influence of linguistics and its concept of study, language, on American public, political and intellectual life during the postwar and early Cold War years. I show that language emerged in three frameworks in this period: language as tool, language as weapon, and language as knowledge. As America stepped onto the international stage, language and linguistics were at the forefront: the military poured millions of dollars into machine translation, American diplomats were required to master scores of foreign languages, and schoolchildren were exposed to language-learning on a scale never before seen in the United States. Together, I argue, language and linguistics formed a critical part of the rise of American leadership in the new world order - one that provided communities as dispersed as the military, the diplomatic corps, scientists and language teachers with a powerful way of tackling the problems they faced. To date, linguistics has not been integrated into the broader framework of Cold War human sciences. In this article, I aim to bring both language, as concept, and linguistics, as discipline, into this framework. In doing so, I pave the way for future work on the history of linguistics as a human science.
SN 0952-6951
EI 1461-720X
PD DEC
PY 2010
VL 23
IS 5
BP 131
EP 155
DI 10.1177/0952695110378952
UT WOS:000285331100007
PM 21322972
ER

PT J
AU Fiasca, L
   Boncagni, L
   Centioli, C
   Iannone, F
   Panella, M
   Vitale, V
   Zaccarian, L
AF Fiasca, L.
   Boncagni, L.
   Centioli, C.
   Iannone, F.
   Panella, M.
   Vitale, V.
   Zaccarian, L.
TI INTRODUCING A VIRTUALIZATION TECHNOLOGY FOR THE FTU PLASMA CONTROL
   SYSTEM
SO FUSION SCIENCE AND TECHNOLOGY
CT 18th American-Nuclear-Society Topical Meeting on the Technology of
   Fusion Energy
CY SEP 28-OCT 02, 2008
CL San Francisco, CA
SP Amer Nucl Soc, NO California Sect, Amer Nucl Soc, Fusion Energy Div, Atom Energy Soc Japan, Lawrence Livermore Natl Lab
AB The Feedback control system running at FTU has been recently improved by the adoption of an Object-Oriented model, obtaining many advantages regarding the software extensibility, re-usability and testing capabilities. This new structure has been ported into a virtual environment using the QEMU processor emulator, in order to simulate, as close as possible to the hardware level, the control system behavior during the real experiment. This new approach introduces the advantage of decreasing dramatically the risks related to coding errors and operating system bugs arising at runtime, whereas it still supports the real-time control features. Moreover, the Real Time Workshop fast controller prototyping interface eliminates the model-translation related problems thanks to its automatic C code generation tools. The entire project flow is now completed: using Simulink, it is possible to design the diagram implementing a new control law, then synthesize the controller library. At this point, we can transfer the new library to the virtual machine, simulate the plasma control experiment in an open-loop configuration, and finally compare the simulation results to those from the past experiments, for a consistency check. The proposed framework is remotely managed by a new Matlab interface. After a satisfying simulation/validation of the new control model, the module can be easily transferred to the control system and hooked up to the real experiment, where it can operate in closed-loop. In this paper, we illustrate the advantages of this new approach and report on some experimental tests where the actual experimental data is compared to the simulations provided by the above-mentioned virtual environment.
OI iannone, francesco/0000-0002-8620-6354
SN 1536-1055
PD AUG
PY 2009
VL 56
IS 2
BP 994
EP 997
DI 10.13182/FST09-A9040
UT WOS:000268946200071
ER

PT J
AU Bonmassar, G
   Schwartz, EL
AF Bonmassar, G
   Schwartz, EL
TI Fourier analysis and cortical architectures: The exponential chirp
   transform
SO REAL-TIME IMAGING
AB The use of visual representations in which pixel-size and local neighborhood topology are not constant is termed space-variant vision, This is the dominant visual architecture in all higher vertebrate visual systems, and is coming to play an important role in real-time active vision applications in the form of log-polar, foveating pyramid, and related approaches to machine vision.
   The breaking of translation symmetry that is unavoidably associated with space-variant vision presents a major algorithmic complication for image processing. In this paper we use a Lie group approach to derive a kernel which provides a generalization of the Fourier Transform that provides a quasi-shift invariant(dagger) template matching capability in the distorted (range) coordinates of the space-variant mapping. We work out the special case of the log-polar mapping, which is the principle space-variant mapping in use; in this case, we call the associated integral transform the 'exponential chirp transform' (ECT). The method is, however, general for other forms of mapping, or warp, function.
   Examples from the two-dimensional (image processing) log-polar transformation are presented along with the demonstration that the ECT preserves the foveating aspect of the space domain mapping, and therefore provides a quasi-shift invariant realization for the applications of matched filter and phase-only filter. This work provides, for the first time, a conceptual basis for combining global spatial frequency methods with space-variant mappings in a way which is consistent with the anatomical fact that human vision, at the cortical level, takes place in log-polar coordinates. (C) 1997 Academic Press Limited.
SN 1077-2014
PD JUN
PY 1997
VL 3
IS 3
BP 229
EP 237
DI 10.1006/rtim.1996.0054
UT WOS:A1997XJ30300006
ER

PT J
AU Zhang, LL
   Zhou, ZX
   Ji, PY
   Mei, AX
AF Zhang, Lingling
   Zhou, Zhenxiong
   Ji, Pengyu
   Mei, Aoxue
TI Application of Attention Mechanism with Prior Information in Natural
   Language Processing
SO INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS
AB When using deep learning methods to model natural language, a recurrent neural network that can map input sequences to output sequences is usually used. Considering that natural language contains more complicated syntactic structures, and the performance of cyclic neural networks in long sentence processing will decrease, scholars have introduced an attention mechanism into the model, which has improved the above problems to a certain extent. The existing attention mechanism still has some shortcomings, such as the inability to explicitly obtain the known syntactic structure information in the sentence, and the poor interpretability of the output probability. In response to the above problems, this article will improve the attention mechanism in the recurrent neural network model. Firstly, the prior information in the natural language sequence is constructed as a graph model through syntactic analysis and other means, and then the graph structure regularization term is introduced into the sparse mapping. A new function netmax is constructed to replace the softmax function in the traditional attention mechanism, thereby improving the performance of the model and making the degree of association. The input values corresponding to larger input samples are closer, making the output of the attention mechanism easier to understand. The innovation of this paper mainly lies in that the weight calculation method which can be widely used in the attention mechanism is proposed by combining the deep learning model with statistical knowledge, which opens a channel to introduce the prior information for the deep learning model in natural language processing tasks.
RI zhang, lingling/HDM-2189-2022
SN 0218-2130
EI 1793-6349
PD JUN
PY 2022
VL 31
IS 04
AR 2240008
DI 10.1142/S0218213022400085
UT WOS:000812432900001
ER

PT J
AU Stanzione, A
   Galatola, R
   Cuocolo, R
   Romeo, V
   Verde, F
   Mainenti, PP
   Brunetti, A
   Maurea, S
AF Stanzione, Arnaldo
   Galatola, Roberta
   Cuocolo, Renato
   Romeo, Valeria
   Verde, Francesco
   Mainenti, Pier Paolo
   Brunetti, Arturo
   Maurea, Simone
TI Radiomics in Cross-Sectional Adrenal Imaging: A Systematic Review and
   Quality Assessment Study
SO DIAGNOSTICS
AB In this study, we aimed to systematically review the current literature on radiomics applied to cross-sectional adrenal imaging and assess its methodological quality. Scopus, PubMed and Web of Science were searched to identify original research articles investigating radiomics applications on cross-sectional adrenal imaging (search end date February 2021). For qualitative synthesis, details regarding study design, aim, sample size and imaging modality were recorded as well as those regarding the radiomics pipeline (e.g., segmentation and feature extraction strategy). The methodological quality of each study was evaluated using the radiomics quality score (RQS). After duplicate removal and selection criteria application, 25 full-text articles were included and evaluated. All were retrospective studies, mostly based on CT images (17/25, 68%), with manual (19/25, 76%) and two-dimensional segmentation (13/25, 52%) being preferred. Machine learning was paired to radiomics in about half of the studies (12/25, 48%). The median total and percentage RQS scores were 2 (interquartile range, IQR = -5-8) and 6% (IQR = 0-22%), respectively. The highest and lowest scores registered were 12/36 (33%) and -5/36 (0%). The most critical issues were the absence of proper feature selection, the lack of appropriate model validation and poor data openness. The methodological quality of radiomics studies on adrenal cross-sectional imaging is heterogeneous and lower than desirable. Efforts toward building higher quality evidence are essential to facilitate the future translation into clinical practice.
RI Cuocolo, Renato/G-3147-2018; Verde, Francesco/AAF-8234-2019; Stanzione,
   Arnaldo/S-3366-2019
OI Cuocolo, Renato/0000-0002-1452-1574; Verde,
   Francesco/0000-0002-9823-4678; Stanzione, Arnaldo/0000-0002-7905-5789;
   Maurea, Simone/0000-0002-8269-3765; Romeo, Valeria/0000-0002-1603-6396
EI 2075-4418
PD MAR
PY 2022
VL 12
IS 3
AR 578
DI 10.3390/diagnostics12030578
UT WOS:000776995300001
PM 35328133
ER

PT J
AU Wang, JZ
   Peng, XJ
   Qiao, Y
AF Wang, Jiaze
   Peng, Xiaojiang
   Qiao, Yu
TI Cascade multi-head attention networks for action recognition
SO COMPUTER VISION AND IMAGE UNDERSTANDING
AB Long-term temporal information yields crucial cues for video action understanding. Previous researches always rely on sequential models such as recurrent networks, memory units, segmental models, self-attention mechanism to integrate the local temporal features for long-term temporal modeling. Recurrent or memory networks record temporal patterns (or relations) by memory units, which are proved to be difficult to capture long-term information in machine translation. Self-attention mechanisms directly aggregate all local information with attention weights which is more straightforward and efficient than the former. However, the attention weights from self-attention ignore the relations between local information and global information which may lead to unreliable attention. To this end, we propose a new attention network architecture, termed as Cascade multi-head ATtention Network (CATNet), which constructs video representations with two-level attentions, namely multi-head local self-attentions and relation based global attentions. Starting from the segment features generated by backbone networks, CATNet first learns multiple attention weights for each segment to capture the importance of local features in a self-attention manner. With the local attention weights, CATNet integrates local features into several global representations, and then learns the second level attention for the global information by a relation manner. Extensive experiments on Kinetics, HMDB51, and UCF101 show that our CATNet boosts the baseline network with a large margin. With only RGB information, we respectively achieve 75.8%, 75.2%, and 96.0% on these three datasets, which are comparable or superior to the state of the arts.
RI WANG, Jiaze/ABA-2447-2020; Peng, Xiaojiang/AAN-8100-2020; Qiao,
   Yu/ABD-5787-2021
SN 1077-3142
EI 1090-235X
PD MAR
PY 2020
VL 192
AR 102898
DI 10.1016/j.cviu.2019.102898
UT WOS:000514226900005
ER

PT J
AU Pilling, MJ
   Henderson, A
   Gardner, P
AF Pilling, Michael J.
   Henderson, Alex
   Gardner, Peter
TI Quantum Cascade Laser Spectral Histopathology: Breast Cancer Diagnostics
   Using High Throughput Chemical Imaging
SO ANALYTICAL CHEMISTRY
AB Fourier transform infrared (FT-IR) microscopy coupled with machine learning approaches has been demonstrated to be a powerful technique for identifying abnormalities in human tissue. The ability to objectively identify the prediseased state and diagnose cancer with high levels of accuracy has the potential to revolutionize current histopathological practice. Despite recent technological advances in FT-IR microscopy, sample throughput and speed of acquisition are key barriers to clinical translation. Wide-field quantum cascade laser (QCL) infrared imaging systems with large focal plane array detectors utilizing discrete frequency imaging have demonstrated that large tissue microarrays (TMA) can be imaged in a matter of minutes. However, this ground breaking technology is still in its infancy, and its applicability for routine disease diagnosis is, as yet, unproven. In light of this, we report on a large study utilizing a breast cancer TMA comprised of 207 different patients. We show that by using QCL imaging with continuous spectra acquired between 912 and 1800 cm(-1), we can accurately differentiate between 4 different histological classes. We demonstrate that we can discriminate between malignant and nonmalignant stroma spectra with high sensitivity (93.56%) and specificity (85.64%) for an independent test set. Finally, we classify each core in the TMA and achieve high diagnostic accuracy on a patient basis with 100% sensitivity and 86.67% specificity. The absence of false negatives reported here opens up the possibility of utilizing high throughput chemical imaging for cancer screening, thereby reducing pathologist workload and improving patient care.
RI Henderson, Alex/ABE-8192-2021
OI Henderson, Alex/0000-0002-5791-8555
SN 0003-2700
EI 1520-6882
PD JUL 18
PY 2017
VL 89
IS 14
BP 7348
EP 7355
DI 10.1021/acs.analchem.7b00426
UT WOS:000406085300012
PM 28628331
ER

PT J
AU Zhou, GY
   Zhou, Y
   He, TT
   Wu, WS
AF Zhou, Guangyou
   Zhou, Yin
   He, Tingting
   Wu, Wensheng
TI Learning semantic representation with neural networks for community
   question answering retrieval
SO KNOWLEDGE-BASED SYSTEMS
AB In community question answering (cQA), users pose queries (or questions) on portals like Yahoo! Answers which can then be answered by other users who are often knowledgeable on the subject. cQA is increasingly popular on the Web, due to its convenience and effectiveness in connecting users with queries and those with answers. In this article, we study the problem of finding previous queries (e.g., posed by other users) which may be similar to new queries, and adapting their answers as the answers to the new queries. A key challenge here is to the bridge the lexical gap between new queries and old answers. For example, "company" in the queries may correspond to "firm" in the answers. To address this challenge, past research has proposed techniques similar to machine translation that "translate" old answers to ones using the words in the new queries. However, a key limitation of these works is that they assume queries and answers are parallel texts, which is hardly true in reality. As a result, the translated or rephrased answers may not look intuitive.
   In this article, we propose a novel approach to learn the semantic representation of queries and answers by using a neural network architecture. The learned semantic level features are finally incorporated into a learning to rank framework. We have evaluated our approach using a large-scale data set. Results show that the approach can significantly outperform existing approaches. (c) 2015 Elsevier B.V. All rights reserved.
SN 0950-7051
EI 1872-7409
PD FEB 1
PY 2016
VL 93
BP 75
EP 83
DI 10.1016/j.knosys.2015.11.002
UT WOS:000369195100006
ER

PT C
AU Zhen, XJ
   Chakraborty, R
   Yang, L
   Singh, V
AF Zhen, Xingjian
   Chakraborty, Rudrasis
   Yang, Liu
   Singh, Vikas
GP Assoc Advancement Artificial Intelligence
TI Flow-based Generative Models for Learning Manifold to Manifold Mappings
SO THIRTY-FIFTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THIRTY-THIRD
   CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE AND THE
   ELEVENTH SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 35th AAAI Conference on Artificial Intelligence / 33rd Conference on
   Innovative Applications of Artificial Intelligence / 11th Symposium on
   Educational Advances in Artificial Intelligence
CY FEB 02-09, 2021
CL ELECTR NETWORK
SP Assoc Advancement Artificial Intelligence
AB Many measurements or observations in computer vision and machine learning manifest as non-Euclidean data. While recent proposals (like spherical CNN) have extended a number of deep neural network architectures to manifold-valued data, and this has often provided strong improvements in performance, the literature on generative models for manifold data is quite sparse. Partly due to this gap, there are also no modality transfer/translation models for manifold-valued data whereas numerous such methods based on generative models are available for natural images. This paper addresses this gap, motivated by a need in brain imaging - in doing so, we expand the operating range of certain generative models (as well as generative models for modality transfer) from natural images to images with manifold-valued measurements. Our main result is the design of a two-stream version of GLOW (flow-based invertible generative models) that can synthesize information of a field of one type of manifold-valued measurements given another. On the theoretical side, we introduce three kinds of invertible layers for manifold-valued data, which are not only analogous to their functionality in flow-based generative models (e.g., GLOW) but also preserve the key benefits (determinants of the Jacobian are easy to calculate). For experiments, on a large dataset from the Human Connectome Project (HCP), we show promising results where we can reliably and accurately reconstruct brain images of a field of orientation distribution functions (ODF) from diffusion tensor images (DTI), where the latter has a 5x faster acquisition time but at the expense of worse angular resolution.
OI SINGH, VIKAS/0000-0002-8355-6519; Yang, Liu/0000-0001-8629-9784
SN 2159-5399
EI 2374-3468
BN 978-1-57735-866-4
PY 2021
VL 35
BP 11042
EP 11052
UT WOS:000681269802083
PM 34457995
ER

PT C
AU Lee, J
   Watanabe, Y
   Sato, M
AF Lee, Jinpil
   Watanabe, Yutaka
   Sato, Mitsuhisa
BE Fan, X
   DeSupinski, BR
   Sinnen, O
   Giacaman, N
TI OpenMP Task Generation for Batched Kernel APIs
SO OPENMP: CONQUERING THE FULL HARDWARE SPECTRUM, IWOMP 2019
SE Lecture Notes in Computer Science
CT 15th International Workshop on OpenMP (IWOMP)
CY SEP 11-13, 2019
CL Auckland, NEW ZEALAND
AB The demand for calculating many small computation kernels is getting significantly important in the HPC area not only for the traditional numerical applications but also recent machine learning applications. While many-core accelerators such as GPUs are power-efficient compute platforms, a large amount of code modification is required. Batched kernel APIs such as batched BLAS can schedule numerical kernels efficiently on the target hardware while it still needs manual code modification. In this paper, we propose a code translation technique to generate batched kernel APIs in a high-level programming model. We use OpenMP task parallelism to specify dependency among numerical kernels. The user adds the task directives to specify tasks so that the compiler can recognize numerical kernels. The compiler detects conventional numerical kernels in the code and creates a unique batch ID for each kernel. When the task runtime detects tasks with the same batch ID, they are merged into a batch. The current implementation supports NVIDIA GPUs and batched BLAS in cuBLAS. DGEMM kernels can be detected and translated into batched DGEMM. A trivial DGEMM loop and blocked Cholesky decomposition code are used for performance evaluation. The evaluation result shows that batched DGEMM improves the performance when the matrix size is small and the number of DGEMM kernels is large. The time for DGEMMs in blocked Cholesky decomposition is 4 times faster than sequential execution when using batched DGEMM (4096x4096 matrix, tile size 128), however the overall performance is improved 36% because of task/batch management overhead.
SN 0302-9743
EI 1611-3349
BN 978-3-030-28596-8; 978-3-030-28595-1
PY 2019
VL 11718
BP 262
EP 273
DI 10.1007/978-3-030-28596-8_18
UT WOS:000655479100018
ER

PT J
AU Ayoub, A
   Garrahy, A
   Hood, C
   White, J
   Bock, M
   Siebert, JP
   Spencer, R
   Ray, A
AF Ayoub, A
   Garrahy, A
   Hood, C
   White, J
   Bock, M
   Siebert, JP
   Spencer, R
   Ray, A
TI Validation of a vision-based, three-dimensional facial imaging system
SO CLEFT PALATE-CRANIOFACIAL JOURNAL
CT 9th International Congress on Cleft Palate and Related Craniofacial
   Anomalies
CY JUN 25-29, 2001
CL GOTHENBURG, SWEDEN
AB Objective: The aim of this study was to assess the accuracy of a newly developed three-dimensional (3D) imaging system in recording facial morphology.
   Methods: Twenty-one infants with cleft lip each had a full-face alginate impression taken at the time of primary lip repair, and a stone cast was constructed from each impression. Five anthropometric points were marked on each cast. Each cast was digitized, and the 3D co-ordinates of the five points were obtained using a co-ordinate measuring machine (CMM, Ferranti) of documented accuracy (9.53 mum). Each cast was scanned in four positions using a computerized stereophotogrammetry (C3D) system. The five points were located on the 3D images, and their 3D co-ordinates were extracted by three operators. The co-ordinate systems produced by C3D were aligned, via translation and rotation, to match the CMM co-ordinate system using partial ordinary procrustes analysis. The displacements of the adjusted C3D co-ordinates from the reference co-ordinates were then measured. Three different types of errors were identified: operator, system, and registration errors.
   Results: Operator error was within 0.2 mm of the true co-ordinates of the landmarks. C3D was accurate within 0.4 mm. The average displacement of points over the 21 casts at four positions for the three operators was 0.79 mm (median 0.68).
   Conclusions: The presented 3D imaging system is reliable in recording facial deformity and could be utilized in recording cleft deformities and measuring the changes following surgery.
OI Ayoub, Ashraf/0000-0002-2760-6008
SN 1055-6656
EI 1545-1569
PD SEP
PY 2003
VL 40
IS 5
BP 523
EP 529
DI 10.1597/02-067
UT WOS:000185412900012
PM 12943434
ER

PT C
AU Zhang, M
   Pan, LJ
   Duan, JY
   Xu, ZT
   Xu, LH
AF Zhang, Mei
   Pan, Lijian
   Duan, Jianyong
   Xu, Zhitong
   Xu, Lishan
BE Tong, R
   Lu, Y
   Dong, M
   Gong, W
   Li, H
TI Automatic Generation and Evaluation of Chinese Grammar Proofreading
   Corpus
SO 2022 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP 2022)
SE International Conference on Asian Language Processing
CT 26th International Conference on Asian Language Processing (IALP)
CY OCT 27-28, 2022
CL Shenzhen, PEOPLES R CHINA
SP IEEE, Chinese Univ Hong Kong, Chinese & Oriental Languages Informat Proc Soc, IEEE Singapore SMC Chapter, IEEE Syst, Man, & Cybernet Soc
AB The automatic proofreading technology of Chinese text is one of the important application technologies of natural language processing. One of the current challenges of this task is that there is not enough labeled data for model training. In order to solve the problem of insufficient proofreading data, this paper proposes a method for automatically generating Chinese text proofreading corpus. When building a grammar proofing corpus, there are four types of grammar errors, including redundant errors, missing errors, selection errors, and word ordering errors. In order to obtain higher quality labeled data, our paper uses machine translation methods to generate redundant errors, missing errors and word ordering errors setences; our paper uses related methods of proofreading corpora to generate selection errors sentences, including Chinese characters to Pinyin, Pinyin to Chinese characters, and OCR technology; in addition, our paper also uses a rule-based method to generate a grammar proofing corpus, i.e. randomly replace, add, delete or reverse 10% of the characters in the sentence. When evaluating the generated grammar proofreading corpus, a statistical-based method and a grammar-based error detection method were used respectively. The statistical-based method proved that the generated corpus was closer to the real errors. Experiments show that on the published grammar proofreading data NLPTEA2018, the F1 value of the corpus constructed in this paper is improved by about 5.7%. Therefore, the corpus data generated in this paper can better simulate the real error sentences, which is of great help to the Chinese text proofreading task.
SN 2159-1962
EI 2159-1970
BN 978-1-6654-7674-4
PY 2022
BP 433
EP 438
DI 10.1109/IALP57159.2022.9961274
UT WOS:000896159700074
ER

PT J
AU Alonso, L
   Moran, I
   Salvoro, C
   Torrents, D
AF Alonso, Lorena
   Moran, Ignasi
   Salvoro, Cecilia
   Torrents, David
TI In Search of Complex Disease Risk through Genome Wide Association
   Studies
SO MATHEMATICS
AB The identification and characterisation of genomic changes (variants) that can lead to human diseases is one of the central aims of biomedical research. The generation of catalogues of genetic variants that have an impact on specific diseases is the basis of Personalised Medicine, where diagnoses and treatment protocols are selected according to each patient's profile. In this context, the study of complex diseases, such as Type 2 diabetes or cardiovascular alterations, is fundamental. However, these diseases result from the combination of multiple genetic and environmental factors, which makes the discovery of causal variants particularly challenging at a statistical and computational level. Genome-Wide Association Studies (GWAS), which are based on the statistical analysis of genetic variant frequencies across non-diseased and diseased individuals, have been successful in finding genetic variants that are associated to specific diseases or phenotypic traits. But GWAS methodology is limited when considering important genetic aspects of the disease and has not yet resulted in meaningful translation to clinical practice. This review presents an outlook on the study of the link between genetics and complex phenotypes. We first present an overview of the past and current statistical methods used in the field. Next, we discuss current practices and their main limitations. Finally, we describe the open challenges that remain and that might benefit greatly from further mathematical developments.
RI Salvoro, Cecilia/K-9768-2016
OI Salvoro, Cecilia/0000-0003-1070-3220; Moran Castany,
   Ignasi/0000-0002-3307-7106; Alonso, Lorena/0000-0003-3392-5133
EI 2227-7390
PD DEC
PY 2021
VL 9
IS 23
AR 3083
DI 10.3390/math9233083
UT WOS:000734529500001
ER

PT J
AU Emiru, ED
   Xiong, SW
   Li, YX
   Fesseha, A
   Diallo, M
AF Emiru, Eshete Derb
   Xiong, Shengwu
   Li, Yaxing
   Fesseha, Awet
   Diallo, Moussa
TI Improving Amharic Speech Recognition System Using Connectionist Temporal
   Classification with Attention Model and Phoneme-Based
   Byte-Pair-Encodings
SO INFORMATION
AB Out-of-vocabulary (OOV) words are the most challenging problem in automatic speech recognition (ASR), especially for morphologically rich languages. Most end-to-end speech recognition systems are performed at word and character levels of a language. Amharic is a poorly resourced but morphologically rich language. This paper proposes hybrid connectionist temporal classification with attention end-to-end architecture and a syllabification algorithm for Amharic automatic speech recognition system (AASR) using its phoneme-based subword units. This algorithm helps to insert the epithetic vowel lambda[i], which is not included in our Grapheme-to-Phoneme (G2P) conversion algorithm developed using consonant-vowel (CV) representations of Amharic graphemes. The proposed end-to-end model was trained in various Amharic subwords, namely characters, phonemes, character-based subwords, and phoneme-based subwords generated by the byte-pair-encoding (BPE) segmentation algorithm. Experimental results showed that context-dependent phoneme-based subwords tend to result in more accurate speech recognition systems than the character-based, phoneme-based, and character-based subword counterparts. Further improvement was also obtained in proposed phoneme-based subwords with the syllabification algorithm and SpecAugment data augmentation technique. The word error rate (WER) reduction was 18.38% compared to character-based acoustic modeling with the word-based recurrent neural network language modeling (RNNLM) baseline. These phoneme-based subword models are also useful to improve machine and speech translation tasks.
OI Derb Emiru, Eshete/0000-0003-2260-3526; DIALLO,
   Moussa/0000-0001-5292-2902; fesseha, awet/0000-0001-7127-6256
EI 2078-2489
PD FEB
PY 2021
VL 12
IS 2
AR 62
DI 10.3390/info12020062
UT WOS:000622558500001
ER

PT J
AU Lin, KJ
   Xu, YJ
   Pei, JF
   Lai, LH
AF Lin, Kangjie
   Xu, Youjun
   Pei, Jianfeng
   Lai, Luhua
TI Automatic retrosynthetic route planning using template-free models
SO CHEMICAL SCIENCE
AB Retrosynthetic route planning can be considered a rule-based reasoning procedure. The possibilities for each transformation are generated based on collected reaction rules, and then potential reaction routes are recommended by various optimization algorithms. Although there has been much progress in computer-assisted retrosynthetic route planning and reaction prediction, fully data-driven automatic retrosynthetic route planning remains challenging. Here we present a template-free approach that is independent of reaction templates, rules, or atom mapping, to implement automatic retrosynthetic route planning. We treated each reaction prediction task as a data-driven sequence-to-sequence problem using the multi-head attention-based Transformer architecture, which has demonstrated power in machine translation tasks. Using reactions from the United States patent literature, our end-to-end models naturally incorporate the global chemical environments of molecules and achieve remarkable performance in top-1 predictive accuracy (63.0%, with the reaction class provided) and top-1 molecular validity (99.6%) in one-step retrosynthetic tasks. Inspired by the success rate of the one-step reaction prediction, we further carried out iterative, multi-step retrosynthetic route planning for four case products, which was successful. We then constructed an automatic data-driven end-to-end retrosynthetic route planning system (AutoSynRoute) using Monte Carlo tree search with a heuristic scoring function. AutoSynRoute successfully reproduced published synthesis routes for the four case products. The end-to-end model for reaction task prediction can be easily extended to larger or customer-requested reaction databases. Our study presents an important step in realizing automatic retrosynthetic route planning.
OI Pei, Jianfeng/0000-0002-8482-1185
SN 2041-6520
EI 2041-6539
PD MAR 28
PY 2020
VL 11
IS 12
BP 3355
EP 3364
DI 10.1039/c9sc03666k
UT WOS:000528663000024
PM 34122843
ER

PT J
AU Orsolic, I
   Jurada, D
   Pullen, N
   Oren, M
   Eliopoulos, AG
   Volarevic, S
AF Orsolic, Ines
   Jurada, Deana
   Pullen, Nick
   Oren, Moshe
   Eliopoulos, Aristides G.
   Volarevic, Sinisa
TI The relationship between the nucleolus and cancer: Current evidence and
   emerging paradigms
SO SEMINARS IN CANCER BIOLOGY
AB The nucleolus is the most prominent nuclear substructure assigned to produce ribosomes; molecular machines that are responsible for carrying out protein synthesis. To meet the increased demand for proteins during cell growth and proliferation the cell must increase protein synthetic capacity by upregulating ribosome biogenesis. While larger nucleolar size and number have been recognized as hallmark features of many tumor types, recent evidence has suggested that, in addition to overproduction of ribosomes, decreased ribosome biogenesis as well as qualitative changes in this process could also contribute to tumor initiation and cancer progression. Furthermore, the nucleolus has become the focus of intense attention for its involvement in processes that are clearly unrelated to ribosome biogenesis such as sensing and responding to endogenous and exogenous stressors, maintenance of genome stability, regulation of cell-cycle progression, cellular senescence, telomere function, chromatin structure, establishment of nuclear architecture, global regulation of gene expression and biogenesis of multiple ribonucleoprotein particles. The fact that dysregulation of many of these fundamental cellular processes may contribute to the malignant phenotype suggests that normal functioning of the nucleolus safeguards against the development of cancer and indicates its potential as a therapeutic approach. Here we review the recent advances made toward understanding these newly-recognized nucleolar functions and their roles in normal and cancer cells, and discuss possible future research directions. (C) 2015 Elsevier Ltd. All rights reserved.
RI Orsolic, Ines/R-5814-2018; Jurada, Deana/R-6012-2018; Oršolić,
   Ines/AGE-5929-2022; ELIOPOULOS, ARISTIDES/ABI-6632-2020; ELIOPOULOS,
   ARISTIDES/R-9449-2018; Volarevic, Sinisa/O-4349-2018
OI Orsolic, Ines/0000-0003-4517-7187; Jurada, Deana/0000-0001-9581-6165;
   Oršolić, Ines/0000-0003-4517-7187; ELIOPOULOS,
   ARISTIDES/0000-0002-6403-6761; ELIOPOULOS,
   ARISTIDES/0000-0002-6403-6761; Volarevic, Sinisa/0000-0003-4893-389X
SN 1044-579X
EI 1096-3650
PD JUN
PY 2016
VL 37-38
BP 36
EP 50
DI 10.1016/j.semcancer.2015.12.004
UT WOS:000377728000005
PM 26721423
ER

PT C
AU Casutt, S
   Bueeler, M
   Blum, M
   Aschwanden, M
AF Casutt, Selina
   Bueeler, Michael
   Blum, Mark
   Aschwanden, Manuel
BE Digonnet, MJF
   Jiang, S
TI Fast and precise continuous focusing with focus tunable lenses
SO OPTICAL COMPONENTS AND MATERIALS XI
SE Proceedings of SPIE
CT Conference on Optical Components and Materials XI
CY FEB 03-05, 2014
CL San Francisco, CA
SP SPIE
AB Focusing in milliseconds without translational mechanics involved is possible with electrically tunable lenses. Fast shape-changing lenses enable fast imaging systems which can focus at distances from infinity to a few centimeters with a high optical quality. Furthermore, rapid laser processing in three dimensions is realized without mechanical translation of the focusing lens or the sample. With tunable lenses the entire optics can be made compact, robust and abrasion-free.
   Different configurations are discussed, how to integrate the tunable lens in the optical path. For machine vision applications, the achievable optical quality depends on the chosen combination of the tunable lens with a fixed focal length lens and a camera. It is recommended to use a fixed focus lens with a short distance between the stop position and the front of the lens. Furthermore, important points are presented how to achieve optimal performance in laser processing applications such as orientation and position of the tunable lens and the diameter of the beam incident on the lens.
   Additionally, different approaches will be discussed for monitoring the focal length of the tunable lens. The focal length of the tunable lens is sensitive to temperature changes, as the lens material is a fluid. However, in contrast to conventional lenses, the focal length of the tunable lens can be corrected electrically. For that purpose, the tunable lens exhibits an integrated temperature sensor for temperature compensation. Also optical feedback solutions will be presented for applications requiring highest precision and tracking of the absolute focal length value.
SN 0277-786X
EI 1996-756X
BN 978-0-8194-9895-3
PY 2014
VL 8982
AR 89820Y
DI 10.1117/12.2037516
UT WOS:000336036800026
ER

PT J
AU Koutsouleris, N
   Dwyer, DB
   Degenhardt, F
   Maj, C
   Urquijo-Castro, MF
   Sanfelici, R
   Popovic, D
   Oeztuerk, O
   Haas, SS
   Weiske, J
   Ruef, A
   Kambeitz-Ilankovic, L
   Antonucci, LA
   Neufang, S
   Schmidt-Kraepelin, C
   Ruhrmann, S
   Penzel, N
   Kambeitz, J
   Haidl, TK
   Rosen, M
   Chisholm, K
   Riecher-Rossler, A
   Egloff, L
   Schmidt, A
   Andreou, C
   Hietala, J
   Schirmer, T
   Romer, G
   Walger, P
   Franscini, M
   Traber-Walker, N
   Schimmelmann, BG
   Fluckiger, R
   Michel, C
   Rossler, W
   Borisov, O
   Krawitz, PM
   Heekeren, K
   Buechler, R
   Pantelis, C
   Falkai, P
   Salokangas, RKR
   Lencer, R
   Bertolino, A
   Borgwardt, S
   Noethen, M
   Brambilla, P
   Wood, SJ
   Upthegrove, R
   Schultze-Lutter, F
   Theodoridou, A
   Meisenzahl, E
AF Koutsouleris, Nikolaos
   Dwyer, Dominic B.
   Degenhardt, Franziska
   Maj, Carlo
   Urquijo-Castro, Maria Fernanda
   Sanfelici, Rachele
   Popovic, David
   Oeztuerk, Oemer
   Haas, Shalaila S.
   Weiske, Johanna
   Ruef, Anne
   Kambeitz-Ilankovic, Lana
   Antonucci, Linda A.
   Neufang, Susanne
   Schmidt-Kraepelin, Christian
   Ruhrmann, Stephan
   Penzel, Nora
   Kambeitz, Joseph
   Haidl, Theresa K.
   Rosen, Marlene
   Chisholm, Katharine
   Riecher-Rossler, Anita
   Egloff, Laura
   Schmidt, Andre
   Andreou, Christina
   Hietala, Jarmo
   Schirmer, Timo
   Romer, Georg
   Walger, Petra
   Franscini, Maurizia
   Traber-Walker, Nina
   Schimmelmann, Benno G.
   Fluckiger, Rahel
   Michel, Chantal
   Rossler, Wulf
   Borisov, Oleg
   Krawitz, Peter M.
   Heekeren, Karsten
   Buechler, Roman
   Pantelis, Christos
   Falkai, Peter
   Salokangas, Raimo K. R.
   Lencer, Rebekka
   Bertolino, Alessandro
   Borgwardt, Stefan
   Noethen, Markus
   Brambilla, Paolo
   Wood, Stephen J.
   Upthegrove, Rachel
   Schultze-Lutter, Frauke
   Theodoridou, Anastasia
   Meisenzahl, Eva
CA Writing Grp PRONIA Consortium
TI Multimodal Machine Learning Workflows for Prediction of Psychosis in
   Patients With Clinical High-Risk Syndromes and Recent-Onset Depression
SO JAMA PSYCHIATRY
AB Importance Diverse models have been developed to predict psychosis in patients with clinical high-risk (CHR) states. Whether prediction can be improved by efficiently combining clinical and biological models and by broadening the risk spectrum to young patients with depressive syndromes remains unclear. Objectives To evaluate whether psychosis transition can be predicted in patients with CHR or recent-onset depression (ROD) using multimodal machine learning that optimally integrates clinical and neurocognitive data, structural magnetic resonance imaging (sMRI), and polygenic risk scores (PRS) for schizophrenia; to assess models' geographic generalizability; to test and integrate clinicians' predictions; and to maximize clinical utility by building a sequential prognostic system. Design, Setting, and Participants This multisite, longitudinal prognostic study performed in 7 academic early recognition services in 5 European countries followed up patients with CHR syndromes or ROD and healthy volunteers. The referred sample of 167 patients with CHR syndromes and 167 with ROD was recruited from February 1, 2014, to May 31, 2017, of whom 26 (23 with CHR syndromes and 3 with ROD) developed psychosis. Patients with 18-month follow-up (n = 246) were used for model training and leave-one-site-out cross-validation. The remaining 88 patients with nontransition served as the validation of model specificity. Three hundred thirty-four healthy volunteers provided a normative sample for prognostic signature evaluation. Three independent Swiss projects contributed a further 45 cases with psychosis transition and 600 with nontransition for the external validation of clinical-neurocognitive, sMRI-based, and combined models. Data were analyzed from January 1, 2019, to March 31, 2020. Main Outcomes and Measures Accuracy and generalizability of prognostic systems. Results A total of 668 individuals (334 patients and 334 controls) were included in the analysis (mean [SD] age, 25.1 [5.8] years; 354 [53.0%] female and 314 [47.0%] male). Clinicians attained a balanced accuracy of 73.2% by effectively ruling out (specificity, 84.9%) but ineffectively ruling in (sensitivity, 61.5%) psychosis transition. In contrast, algorithms showed high sensitivity (76.0%-88.0%) but low specificity (53.5%-66.8%). A cybernetic risk calculator combining all algorithmic and human components predicted psychosis with a balanced accuracy of 85.5% (sensitivity, 84.6%; specificity, 86.4%). In comparison, an optimal prognostic workflow produced a balanced accuracy of 85.9% (sensitivity, 84.6%; specificity, 87.3%) at a much lower diagnostic burden by sequentially integrating clinical-neurocognitive, expert-based, PRS-based, and sMRI-based risk estimates as needed for the given patient. Findings were supported by good external validation results. Conclusions and Relevance These findings suggest that psychosis transition can be predicted in a broader risk spectrum by sequentially integrating algorithms' and clinicians' risk estimates. For clinical translation, the proposed workflow should undergo large-scale international validation.
   Question Can a transition to psychosis be predicted in patients with clinical high-risk states or recent-onset depression by optimally integrating clinical, neurocognitive, neuroimaging, and genetic information with clinicians' prognostic estimates? Findings In this prognostic study of 334 patients and 334 control individuals, machine learning models sequentially combining clinical and biological data with clinicians' estimates correctly predicted disease transitions in 85.9% of cases across geographically distinct patient populations. The clinicians' lack of prognostic sensitivity, as measured by a false-negative rate of 38.5%, was reduced to 15.4% by the sequential prognostic model. Meaning These findings suggest that an individualized prognostic workflow integrating artificial and human intelligence may facilitate the personalized prevention of psychosis in young patients with clinical high-risk syndromes or recent-onset depression.
   This prognostic study evaluates whether psychosis transition can be predicted in patients with clinical high-risk syndromes or recent-onset depression by multimodal machine learning that optimally integrates clinical and neurocognitive data, structural magnetic resonance imaging, and polygenic risk scores for schizophrenia.
RI brambilla, paolo/B-4184-2010; Neufang, Susanne/GXN-2256-2022; Ruhrmann,
   Stephan/AAG-9470-2020; Schultze-Lutter, Frauke/AAU-1724-2021; Michel,
   Chantal/D-6427-2017; Schmidt, André/C-2948-2014; Kambeitz,
   Joseph/AAR-7087-2021; Lichtenstein, Thorsten/GRX-3305-2022;
   Riecher-Rössler, Anita/ABF-5752-2020; Pantelis, Christos/H-7722-2014;
   Popovic, David/AAV-8507-2020; Upthegrove, Rachel/AAD-9761-2022;
   Borgwardt, Stefan/Q-6168-2018; Wood, Stephen/M-8652-2014; Dwyer,
   Dominic/Z-1225-2018
OI brambilla, paolo/0000-0002-4021-8456; Neufang,
   Susanne/0000-0002-4927-2969; Ruhrmann, Stephan/0000-0002-6022-2364;
   Michel, Chantal/0000-0003-1165-6681; Schmidt, André/0000-0001-6055-8397;
   Kambeitz, Joseph/0000-0002-8988-3959; Lichtenstein,
   Thorsten/0000-0002-4710-2317; Riecher-Rössler,
   Anita/0000-0001-6361-8789; Pantelis, Christos/0000-0002-9565-0238;
   Popovic, David/0000-0002-2367-9437; Upthegrove,
   Rachel/0000-0001-8204-5103; Kambeitz-Ilankovic,
   Lana/0000-0002-8218-0425; Hietala, Jarmo/0000-0002-3179-6780; Ozturk,
   Omer Faruk/0000-0003-3665-0526; Haas, Shalaila/0000-0003-1385-1050;
   Borgwardt, Stefan/0000-0002-5792-3987; Theodoridou,
   Anastasia/0000-0003-4792-385X; Rossler, Wulf/0000-0003-0049-4533;
   Heekeren, Karsten/0000-0001-5105-1922; Lichtenstein, Theresa
   Katharina/0000-0001-5573-1212; Wood, Stephen/0000-0003-4186-5919; Dwyer,
   Dominic/0000-0003-3949-5867
SN 2168-622X
EI 2168-6238
PD FEB
PY 2021
VL 78
IS 2
BP 195
EP 209
DI 10.1001/jamapsychiatry.2020.3604
EA DEC 2020
UT WOS:000596063100004
PM 33263726
ER

PT J
AU Yeo, I
   Patil, L
   Dutta, D
AF Yeo, Il
   Patil, Lalit
   Dutta, Debasish
TI Feedback Matching Framework for Semantic Interoperability of Product
   Data
SO IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING
AB There is a need to promote drastically increased levels of interoperability of product data across a broad spectrum of stakeholders, while ensuring that the semantics of product knowledge are preserved, and when necessary, translated. In order to achieve this, multiple methods have been proposed to determine semantic maps across concepts from different representations. Previous research has focused on developing different individual matching methods, i.e., ones that compute mapping based on a single matching measure. These efforts assume that some weighted combination can be used to obtain the overall maps. We analyze the problem of combination of multiple individual methods to determine requirements specific to product development and propose a solution approach called FEedback Matching Framework with Implicit Training (FEMFIT). FEMFIT provides the ability to combine the different matching approaches using ranking Support Vector Machine (ranking SVM). The method accounts for nonlinear relations between the individual matchers. It overcomes the need to explicitly train the algorithm before it is used, and further reduces the decision-making load on the domain expert by implicitly capturing the expert's decisions without requiring him to input real numbers on similarity. We apply FEMFIT to a subset of product constraints across a commercial system and the ISO standard. We observe that FEMIT demonstrates better accuracy (average correctness of the results) and stability (deviation from the average) in comparison with other existing combination methods commonly assumed to be valid in this domain.
   Note to Practitioners-This paper was motivated by the problem of automating the exchange of meaning associated with the data, among different software systems or information resources in product development. More specifically, it focuses on automatically determining the maps between the concepts from participating system, which is required to ensure that the final physical translation is accurate. Existing approaches either focus on one aspect of product information or a weighted sum of different aspects. However, there is no formal ground to choose a specific method. Furthermore, as we show in this paper, these approaches are unlikely to find the correct matches because of the inherent nonlinearity. We propose a framework, FEMFIT, in which multiple matching methods are automatically combined using inputs from experts obtained through an intuitive, Google search-like, interface. It is evaluated by comparing with known matching methods and FEMFIT shows better matching accuracy on the example cases. Future work focuses on extending the work to handle m:n matches.
RI Patil, Lalit/AAU-9332-2021
SN 1545-5955
EI 1558-3783
PD APR
PY 2012
VL 9
IS 2
BP 436
EP 445
DI 10.1109/TASE.2011.2171950
UT WOS:000304755100024
ER

PT J
AU Mirjalili, S
   Powell, P
   Strunk, J
   James, T
   Duarte, A
AF Mirjalili, Soroush
   Powell, Patrick
   Strunk, Jonathan
   James, Taylor
   Duarte, Audrey
TI Evaluation of classification approaches for distinguishing brain states
   predictive of episodic memory performance from electroencephalography*
   Abbreviated Title: Evaluating methods of classifying memory states from
   EEG
SO NEUROIMAGE
AB Previous studies have attempted to separate single trial neural responses for events a person is likely to remem -ber from those they are likely to forget using machine learning classification methods. Successful single trial classification holds potential for translation into the clinical realm for real-time detection of memory and other cognitive states to provide real-time interventions (i.e., brain-computer interfaces). However, most of these stud-ies -and classification analyses in general - do not make clear if the chosen methodology is optimally suited for the classification of memory-related brain states. To address this problem, we systematically compared different methods for every step of classification (i.e., feature extraction, feature selection, classifier selection) to investi-gate which methods work best for decoding episodic memory brain states -the first analysis of its kind. Using an adult lifespan sample EEG dataset collected during performance of an episodic context encoding and retrieval task, we found that no specific feature type (including Common Spatial Pattern (CSP)-based features, mean, vari -ance, correlation, features based on AR model, entropy, phase, and phase synchronization) outperformed others consistently in distinguishing different memory classes. However, extracting all of these feature types consistently outperformed extracting only one type of feature. Additionally, the combination of filtering and sequential for-ward selection was the optimal method to select the effective features compared to filtering alone or performing no feature selection at all. Moreover, although all classifiers performed at a fairly similar level, LASSO was con-sistently the highest performing classifier compared to other commonly used options (i.e., naive Bayes, SVM, and logistic regression) while naive Bayes was the fastest classifier. Lastly, for multiclass classification (i.e., levels of context memory confidence and context feature perception), generalizing the binary classification using the binary decision tree performed better than the voting or one versus rest method. These methods were shown to outperform alternative approaches for three orthogonal datasets (i.e., EEG working memory, EEG motor imagery, and MEG working memory), supporting their generalizability. Our results provide an optimized methodological process for classifying single-trial neural data and provide important insight and recommendations for a cognitive neuroscientist's ability to make informed choices at all stages of the classification process for predicting memory and other cognitive states.
OI Duarte, Audrey/0000-0001-5293-4049
SN 1053-8119
EI 1095-9572
PD FEB 15
PY 2022
VL 247
AR 118851
DI 10.1016/j.neuroimage.2021.118851
EA DEC 2021
UT WOS:000736962400004
PM 34954026
ER

PT J
AU Peeters, MKR
   Baggerman, G
   Gabriels, R
   Pepermans, E
   Menschaert, G
   Boonen, K
AF Peeters, Marlies K. R.
   Baggerman, Geert
   Gabriels, Ralf
   Pepermans, Elise
   Menschaert, Gerben
   Boonen, Kurt
TI Ion Mobility Coupled to a Time-of-Flight Mass Analyzer Combined With
   Fragment Intensity Predictions Improves Identification of Classical
   Bioactive Peptides and Small Open Reading Frame-Encoded Peptides
SO FRONTIERS IN CELL AND DEVELOPMENTAL BIOLOGY
AB Bioactive peptides exhibit key roles in a wide variety of complex processes, such as regulation of body weight, learning, aging, and innate immune response. Next to the classical bioactive peptides, emerging from larger precursor proteins by specific proteolytic processing, a new class of peptides originating from small open reading frames (sORFs) have been recognized as important biological regulators. But their intrinsic properties, specific expression pattern and location on presumed non-coding regions have hindered the full characterization of the repertoire of bioactive peptides, despite their predominant role in various pathways. Although the development of peptidomics has offered the opportunity to study these peptides in vivo, it remains challenging to identify the full peptidome as the lack of cleavage enzyme specification and large search space complicates conventional database search approaches. In this study, we introduce a proteogenomics methodology using a new type of mass spectrometry instrument and the implementation of machine learning tools toward improved identification of potential bioactive peptides in the mouse brain. The application of trapped ion mobility spectrometry (tims) coupled to a time-of-flight mass analyzer (TOF) offers improved sensitivity, an enhanced peptide coverage, reduction in chemical noise and the reduced occurrence of chimeric spectra. Subsequent machine learning tools (MSPIP)-P-2, predicting fragment ion intensities and DeepLC, predicting retention times, improve the database searching based on a large and comprehensive custom database containing both sORFs and alternative ORFs. Finally, the identification of peptides is further enhanced by applying the post-processing semi-supervised learning tool Percolator. Applying this workflow, the first peptidomics workflow combined with spectral intensity and retention time predictions, we identified a total of 167 predicted sORF-encoded peptides, of which 48 originating from presumed non-coding locations, next to 401 peptides from known neuropeptide precursors, linked to 66 annotated bioactive neuropeptides from within 22 different families. Additional PEAKS analysis expanded the pool of SEPs on presumed non-coding locations to 84, while an additional 204 peptides completed the list of peptides from neuropeptide precursors. Altogether, this study provides insights into a new robust pipeline that fuses technological advancements from different fields ensuring an improved coverage of the neuropeptidome in the mouse brain.
RI Gabriels, Ralf/AAU-5247-2021
OI Gabriels, Ralf/0000-0002-1679-1711; Peeters, Marlies K.
   R./0000-0003-0737-6337
SN 2296-634X
PD SEP 17
PY 2021
VL 9
AR 720570
DI 10.3389/fcell.2021.720570
UT WOS:000717286000001
PM 34604223
ER

PT J
AU Stambuk, N
AF Stambuk, N
TI Universal metric properties of the genetic code
SO CROATICA CHEMICA ACTA
CT 14th Dubrovnik International Course and Conference on the Interfaces
   between Mathematics, Chemistry and Computer Sciences
CY JUN 21-26, 1999
CL DUBROVNIK, CROATIA
SP Inter Univ Ctr, Rugjer Boskovic Inst, Univ Zagreb, Univ Split, Int Soc Math Chem, Int Soc Theoret Chem Phys
AB Universal metric properties of the genetic code (i.e. RNA, DNA and protein coding) are defined by means of the nucleotide base representation on the square with vertices U or T = 00, C = 01, G = 10 and A = 11. It is shown that this notation defines the Canter set and Smale horseshoe map representation of the genetic code, the classic table arrangement and Siemion one-step mutation ring of the code. Gray code solutions to the problem of defining codon positions on the [0, 1] interval, and an extension to the octal coding system, based on the linear block triple check code, are given. This result enables short block (word) decoding of the genetic code patterns. The block code is related to the minimization of errors during transcription and translation processes, which implies that the genetic code is error-correcting and not degenerate. Two algorithms for the representation of codons on the [0, 1] interval and the related binary trees are discussed. It is concluded that the ternary Canter set algorithm is the method of choice for this type of analysis and coding. This procedure enables the analysis of the six dimensional hypercube codon positions by means of a simple time series and/or 'logistic' difference equation. Finally, a unified concept of the genetic code linked to the Canter set and horseshoe map is introduced in the form of a classic combinatorial 4 colour necklace model with three horizontal frames consisting of 64 coloured pearls (bases) and vertically hanging decorations of triplets (codons). Three horizontal necklace frames define Crick's code without comma, and vertical necklace decorations define the evolutional code. Thus, the type of the code depends on the level or direction of observation. The exact location of the mRNA and complementary DNA coding groups of triplets within a frame is determined. The latter enables decoding of long code block (language) patterns within the genetic code. This method of genetic code analysis is named Symbolic Canter Algorithm (SCA). The validity of the method was confirmed by 94% accurate classification of 50 proteins of known secondary structure (25 alpha -helices and 25 beta -sheets) with the C5.0 machine learning system. Nucleotide strings of proteins transcribed by SCA were used for the analysis. Spectral Fourier analysis of Pro-opiomelanocortin and Bone Morphogenetic Protein 6 confirmed that the method might be also applied to the analysis of bioactive hormone and cytokine sequences.
SN 0011-1643
EI 1334-417X
PD DEC
PY 2000
VL 73
IS 4
BP 1123
EP 1139
UT WOS:000165940300018
ER

PT J
AU Legrand, C
   Ahmed, U
   Anwar, A
   Rajpoot, K
   Pasha, S
   Lambert, C
   Davidson, RK
   Clark, IM
   Thornalley, PJ
   Henrotin, Y
   Rabbani, N
AF Legrand, Catherine
   Ahmed, Usman
   Anwar, Attia
   Rajpoot, Kashif
   Pasha, Sabah
   Lambert, Cecile
   Davidson, Rose K.
   Clark, Ian M.
   Thornalley, Paul J.
   Henrotin, Yves
   Rabbani, Naila
TI Glycation marker glucosepane increases with the progression of
   osteoarthritis and correlates with morphological and functional changes
   of cartilage in vivo
SO ARTHRITIS RESEARCH & THERAPY
AB Background: Changes of serum concentrations of glycated, oxidized, and nitrated amino acids and hydroxyproline and anticyclic citrullinated peptide antibody status combined by machine learning techniques in algorithms have recently been found to provide improved diagnosis and typing of early-stage arthritis of the knee, including osteoarthritis (OA), in patients. The association of glycated, oxidized, and nitrated amino acids released from the joint with development and progression of knee OA is unknown. We studied this in an OA animal model as well as interleukin-1 beta-activated human chondrocytes in vitro and translated key findings to patients with OA.
   Methods: Sixty male 3-week-old Dunkin-Hartley guinea pigs were studied. Separate groups of 12 animals were killed at age 4, 12, 20, 28 and 36 weeks, and histological severity of knee OA was evaluated, and cartilage rheological properties were assessed. Human chondrocytes cultured in multilayers were treated for 10 days with interleukin-1 beta. Human patients with early and advanced OA and healthy controls were recruited, blood samples were collected, and serum or plasma was prepared. Serum, plasma, and culture medium were analyzed for glycated, oxidized, and nitrated amino acids.
   Results: Severity of OA increased progressively in guinea pigs with age. Glycated, oxidized, and nitrated amino acids were increased markedly at week 36, with glucosepane and dityrosine increasing progressively from weeks 20 and 28, respectively. Glucosepane correlated positively with OA histological severity (r = 0.58, p < 0.0001) and instantaneous modulus (r = 0.52-0.56; p < 0.0001), oxidation free adducts correlated positively with OA severity (p < 0.0009-0.0062), and hydroxyproline correlated positively with cartilage thickness (p < 0.0003-0.003). Interleukin-1 beta increased the release of glycated and nitrated amino acids from chondrocytes in vitro. In clinical translation, plasma glucosepane was increased 38% in early-stage OA (p < 0.05) and sixfold in patients with advanced OA (p < 0.001) compared with healthy controls.
   Conclusions: These studies further advance the prospective role of glycated, oxidized, and nitrated amino acids as serum biomarkers in diagnostic algorithms for early-stage detection of OA and other arthritic disease. Plasma glucosepane, reported here for the first time to our knowledge, may improve early-stage diagnosis and progression of clinical OA.
RI Clark, Ian M/D-1920-2009; Davidson, Rose/A-4268-2015
OI Thornalley, Paul/0000-0001-7659-443X; Lambert,
   Cecile/0000-0002-2455-4716; Henrotin, Yves/0000-0003-1073-449X;
   Davidson, Rose/0000-0002-6624-4011; Rabbani, Naila/0000-0002-5819-2506
SN 1478-6354
EI 1478-6362
PD JUN 22
PY 2018
VL 20
AR 131
DI 10.1186/s13075-018-1636-6
UT WOS:000435942400001
PM 29929535
ER

PT C
AU Roussinov, D
   Puchnina, N
AF Roussinov, Dmitri
   Puchnina, Nadezhda
GP IEEE
TI Combining Neural Networks and Pattern Matching for Ontology Mining - a
   Meta Learning Inspired Approach
SO 2019 13TH IEEE INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC)
SE IEEE International Conference on Semantic Computing
CT 13th IEEE International Conference on Semantic Computing (ICSC)
CY JAN 30-FEB 01, 2019
CL Newport Beach, CA
SP IEEE, IEEE Comp Soc
AB Several applications dealing with natural language text involve automated validation of the membership in a given category (e.g. France is a country, Gladiator is a movie, but not a country). Meta-learning is a recent and powerful machine learning approach, which goal is to train a model (or a family of models) on a variety of learning tasks, such that it can solve new learning tasks in a more efficient way, e.g. using smaller number of training samples or in less time. We present an original approach inspired by meta-learning and consisting of two tiers of models: for any arbitrary category, our general model supplies high confidence training instances (seeds) for our category-specific models. Our general model is based on pattern matching and optimized for the precision at top N, while its recall is not important. Our category-specific models are based on recurrent neural networks (RNN-s), which recently showed themselves extremely effective in several natural language applications, such as machine translation, sentiment analysis, parsing, and chatbots. By following the meta-learning principles, we are training our highest level (general) model in such a way that our second-tier category-specific models (which are dependent on it) are optimized for the best possible performance in a specific application. This work is important because our approach is capable of verifying membership in an arbitrary category defined by a sequence of words including longer and more complex categories such as Ridley Scott movie or City in southern Germany that are currently not supported by existing manually created ontologies (such as Freebase, Wordnet or Wikidata). Also, our approach uses only raw text, and thus can be useful when there are no such ontologies available, which is a common situation with languages other than English. Even the largest English ontologies are known to have low coverage, insufficient for many practical applications such as automated question answering, which we use here to illustrate the advantages of our approach. We rigorously test it on a number of questions larger than the previous studies and demonstrate that when coupled with a simple answer-scoring mechanism, our meta-learning-inspired approach 1) provides up to 50% improvement over prior approaches that do not use any manually curated knowledge bases and 2) achieves the state of-the-art performance among all the current approaches including those taking advantage of such knowledge bases.
SN 2325-6516
BN 978-1-5386-6783-5
PY 2019
BP 63
EP 70
DI 10.1109/ICOSC.2019.8665528
UT WOS:000467270600009
ER

PT J
AU Mentzel, F
   Kroninger, K
   Lerch, M
   Nackenhorst, O
   Rosenfeld, A
   Tsoi, AC
   Weingarten, J
   Hagenbuchner, M
   Guatelli, S
AF Mentzel, F.
   Kroeinger, K.
   Lerch, M.
   Nackenhorst, O.
   Rosenfeld, A.
   Tsoi, A. C.
   Weingarten, J.
   Hagenbuchner, M.
   Guatelli, S.
TI Small beams, fast predictions: a comparison of machine learning dose
   prediction models for proton minibeam therapy
SO MEDICAL PHYSICS
AB Background Dose calculations for novel radiotherapy cancer treatments such as proton minibeam radiation therapy is often done using full Monte Carlo (MC) simulations. As MC simulations can be very time consuming for this kind of application, deep learning models have been considered to accelerate dose estimation in cancer patients. Purpose This work systematically evaluates the dose prediction accuracy, speed and generalization performance of three selected state-of-the-art deep learning models for dose prediction applied to the proton minibeam therapy. The strengths and weaknesses of those models are thoroughly investigated, helping other researchers to decide on a viable algorithm for their own application. Methods The following recently published models are compared: first, a 3D U-Net model trained as a regression network, second, a 3D U-Net trained as a generator of a generative adversarial network (GAN) and third, a dose transformer model which interprets the dose prediction as a sequence translation task. These models are trained to emulate the result of MC simulations. The dose depositions of a proton minibeam with a diameter of 800 mu m and an energy of 20-100 MeV inside a simple head phantom calculated by full Geant4 MC simulations are used as a case study for this comparison. The spatial resolution is 0.5 mm. Special attention is put on the evaluation of the generalization performance of the investigated models. Results Dose predictions with all models are produced in the order of a second on a GPU, the 3D U-Net models being fastest with an average of 130 ms. An investigated 3D U-Net regression model is found to show the strongest performance with overall 61.0%+/-$\%\pm$0.5% of all voxels exhibiting a deviation in energy deposition prediction of less than 3% compared to full MC simulations with no spatial deviation allowed. The 3D U-Net models are observed to show better generalization performance for target geometry variations, while the transformer-based model shows better generalization with regard to the proton energy. Conclusions This paper reveals that (1) all studied deep learning models are significantly faster than non-machine learning approaches predicting the dose in the order of seconds compared to hours for MC, (2) all models provide reasonable accuracy, and (3) the regression-trained 3D U-Net provides the most accurate predictions.
OI Lerch, Michael/0000-0002-2406-9972
SN 0094-2405
EI 2473-4209
PD DEC
PY 2022
VL 49
IS 12
BP 7791
EP 7801
DI 10.1002/mp.16066
EA NOV 2022
UT WOS:000881274400001
PM 36309820
ER

PT J
AU Lee, EK
   Uppal, K
AF Lee, Eva K.
   Uppal, Karan
TI CERC: an interactive content extraction, recognition, and construction
   tool for clinical and biomedical text
SO BMC MEDICAL INFORMATICS AND DECISION MAKING
AB Background: Automated summarization of scientific literature and patient records is essential for enhancing clinical decision-making and facilitating precision medicine. Most existing summarization methods are based on single indicators of relevance, offer limited capabilities for information visualization, and do not account for user specific interests. In this work, we develop an interactive content extraction, recognition, and construction system (CERC) that combines machine learning and visualization techniques with domain knowledge for highlighting and extracting salient information from clinical and biomedical text.
   Methods: A novel sentence-ranking framework multi indicator text summarization, MINTS, is developed for extractive summarization. MINTS uses random forests and multiple indicators of importance for relevance evaluation and ranking of sentences. Indicative summarization is performed using weighted term frequency-inverse document frequency scores of over-represented domain-specific terms. A controlled vocabulary dictionary generated using MeSH, SNOMED-CT, and PubTator is used for determining relevant terms. 35 full-text CRAFT articles were used as the training set. The performance of the MINTS algorithm is evaluated on a test set consisting of the remaining 32 full-text CRAFT articles and 30 clinical case reports using the ROUGE toolkit.
   Results: The random forests model classified sentences as "good" or "bad" with 87.5% accuracy on the test set. Summarization results from the MINTS algorithm achieved higher ROUGE-1, ROUGE-2, and ROUGE-SU4 scores when compared to methods based on single indicators such as term frequency distribution, position, eigenvector centrality (LexRank), and random selection, p < 0.01. The automatic language translator and the customizable information extraction and pre-processing pipeline for EHR demonstrate that CERC can readily be incorporated within clinical decision support systems to improve quality of care and assist in data-driven and evidence-based informed decision making for direct patient care.
   Conclusions: We have developed a web-based summarization and visualization tool, CERC (), for extracting salient information from clinical and biomedical text. The system ranks sentences by relevance and includes features that can facilitate early detection of medical risks in a clinical setting. The interactive interface allows users to filter content and edit/save summaries. The evaluation results on two test corpuses show that the newly developed MINTS algorithm outperforms methods based on single characteristics of importance.
EI 1472-6947
PD DEC 15
PY 2020
VL 20
SU 14
SI SI
AR 306
DI 10.1186/s12911-020-01330-8
UT WOS:000600129600007
PM 33323109
ER

PT J
AU Palte, HD
   Gayer, S
   Arrieta, E
   Shaw, ES
   Nose, I
   Lee, E
   Arheart, KL
   Dubovy, S
   Birnbach, DJ
   Parel, JM
AF Palte, Howard D.
   Gayer, Steven
   Arrieta, Esdras
   Shaw, Eric Scot
   Nose, Izuru
   Lee, Elizabete
   Arheart, Kristopher L.
   Dubovy, Sander
   Birnbach, David J.
   Parel, Jean-Marie
TI Are Ultrasound-Guided Ophthalmic Blocks Injurious to the Eye? A
   Comparative Rabbit Model Study of Two Ultrasound Devices Evaluating
   Intraorbital Thermal and Structural Changes
SO ANESTHESIA AND ANALGESIA
AB BACKGROUND: Since Atkinson's original description of retrobulbar block in 1936, needle-based anesthetic techniques have become integral to ophthalmic anesthesia. These techniques are unfortunately associated with rare, grave complications such as globe perforation. Ultrasound has gained widespread acceptance for peripheral nerve blockade, but its translation to ocular anesthesia has been hampered because sonic energy, in the guise of thermal or biomechanical insult, is potentially injurious to vulnerable eye tissue. The US Food and Drug Administration (FDA) has defined guidelines for safe use of ultrasound for ophthalmic examination, but most ultrasound devices used by anesthesiologists are not FDA-approved for ocular application because they generate excessive energy. Regulating agencies state that ultrasound examinations can be safely undertaken as long as tissue temperatures do not increase > 1.5 degrees C above physiological levels.
   METHODS: Using a rabbit model, we investigated the thermal and mechanical ocular effects after prolonged ultrasonic exposure to single orbital- and nonorbital-rated devices. In a dual-phase study, aimed at detecting ocular injury, the eyes of 8 rabbits were exposed to continuous 10-minute ultrasound examinations from 2 devices: (1) the Sonosite Micromaxx (nonorbital rated) and (2) the Sonomed VuMax (orbital rated) machines. In phase I, temperatures were continuously monitored via thermocouples implanted within specific eye structures (n = 4). In phase lithe eyes were subjected to ultrasonic exposure without surgical intervention (n = 4). All eyes underwent light microscopy examinations, followed at different intervals by histology evaluations conducted by an ophthalmic pathologist.
   RESULTS: Temperature changes were monitored in the eyes of 4 rabbits. The nonorbital-rated transducer produced increases in ocular tissue temperature that surpassed the safe limit (increases > 1.5 degrees C) in the lens of 3 rabbits (at 5.0, 5.5, and 1.5 minutes) and cornea of 2 rabbits (both at 1.5 minutes). A secondary analysis of temporal temperature differences between the orbital-rated and nonorbital transducers revealed statistically significant differences (Bonferroni-adjusted P < 0.05) in the cornea at 3.5 minutes, the lens at 2.5 minutes, and the vitreous at 4.0 minutes. Light microscopy and histology failed to elicit ocular injury in either group.
   CONCLUSIONS: The nonorbital-rated ultrasound machine (Sonosite Micromaxx) increases the ocular tissue temperature. A larger study is needed to establish safety. Until then, ophthalmic ultrasound-guided blocks should only be performed with ocular-rated devices. (Anesth Analg 2012;115:194-201)
SN 0003-2999
PD JUL
PY 2012
VL 115
IS 1
BP 194
EP 201
DI 10.1213/ANE.0b013e318253622e
UT WOS:000305600800033
PM 22504211
ER

PT J
AU Kumar, AV
   Ali, RFM
   Cao, Y
   Krishnan, VV
AF Kumar, Arun V.
   Ali, Rehana F. M.
   Cao, Yu
   Krishnan, V. V.
TI Application of data mining tools for classification of protein
   structural class from residue based averaged NMR chemical shifts
SO BIOCHIMICA ET BIOPHYSICA ACTA-PROTEINS AND PROTEOMICS
AB The number of protein sequences deriving from genome sequencing projects is outpacing our knowledge about the function of these proteins. With the gap between experimentally characterized and uncharacterized proteins continuing to widen, it is necessary to develop new computational methods and tools for protein structural information that is directly related to function. Nuclear magnetic resonance (NMR) provides powerful means to determine three-dimensional structures of proteins in the solution state. However, translation of the NMR spectral parameters to even low-resolution structural information such as protein class requires multiple time consuming steps. In this paper, we present an unorthodox method to predict the protein structural class directly by using the residue's averaged chemical shifts (ACS) based on machine learning algorithms. Experimental chemical shift information from 1491 proteins obtained from Biological Magnetic Resonance Bank (BMRB) and their respective protein structural classes derived from structural classification of proteins (SCOP) were used to construct a data set with 119 attributes and 5 different classes. Twenty four different classification schemes were evaluated using several performance measures. Overall the residue based ACS values can predict the protein structural classes with 80% accuracy measured by Matthew correlation coefficient. Specifically protein classes defined by mixed alpha beta or small proteins are classified with >90% correlation. Our results indicate that this NMR-based method can be utilized as a low-resolution tool for protein structural class identification without any prior chemical shift assignments. (C) 2015 Elsevier B.V. All rights reserved.
SN 1570-9639
EI 0006-3002
PD OCT
PY 2015
VL 1854
IS 10
BP 1545
EP 1552
DI 10.1016/j.bbapap.2015.02.016
PN A
UT WOS:000362307500034
PM 25758094
ER

PT J
AU Feichtinger, W
AF Feichtinger, W
TI Follicle aspiration with interactive threedimensional digital imaging
   (Voluson): a step toward real-time puncturing under three-dimensional
   ultrasound control
SO FERTILITY AND STERILITY
CT 1st World Congress on Three-dimensional Ultrasound in Obstetrics and
   Gynecology
CY SEP 05-06, 1997
CL MAINZ, GERMANY
AB Objective: To evaluate the possibility of performing puncturing procedures under three-dimensional ultrasound (US) control in close to real time using a new commercially available system and to describe the technique.
   Design: Descriptive case study.
   Setting: Private outpatient infertility clinic.
   Patient(s): A volunteer undergoing IVF-ET treatment.
   Intervention(s): Transvaginal needle-guided aspiration of 10 follicles using a newly developed US machine with a built-in rapid and powerful calculation software program for three-dimensional interactive volume and flow translation during operation. Interactive three-dimensional imaging was carried out during the aspiration of each follicle,
   Main Outcome Measure(s): The delays caused by volume acquisition and the search for the needle tip with and without "power Doppler" were estimated and compared.
   Result(s): Oocyte recovery was successful from all follicles. There was a mean (+/-SD) delay of 5.00 +/- 1.22 seconds from coasting to resuming real-rime US scanning during interactive volume calculation and the search for the needle tip in the three-dimensional mode. This did not delay the procedure remarkably but enabled the precise localization of both the needle and its tip after each penetration. The integration of flow signals allowed an impressive color-coded demonstration of the needle within the tissue, but the delay was significantly longer for color-coded volume acquisition (18.40 +/- 4.56 seconds).
   Conclusion(s): Recent technology enables the performance of three-dimensional puncture procedures in close to real time: this technology is demonstrated for follicle punctures but will be of more importance in fields such as fetal medicine, oncology, and surgery. (Fertil Steril(R) 1998;70:374-7. (C)1998 by American Society for Reproductive Medicine.).
SN 0015-0282
PD AUG
PY 1998
VL 70
IS 2
BP 374
EP 377
DI 10.1016/S0015-0282(98)00131-9
UT WOS:000075092100037
PM 9696241
ER

PT J
AU Kennedy, EE
   Bowles, KH
   Aryal, S
AF Kennedy, Erin E.
   Bowles, Kathryn H.
   Aryal, Subhash
TI Systematic review of prediction models for postacute care destination
   decision-making
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
AB Objective: This article reports a systematic review of studies containing development and validation of models predicting postacute care destination after adult inpatient hospitalization, summarizes clinical populations and variables, evaluates model performance, assesses risk of bias and applicability, and makes recommendations to reduce bias in future models.
   Materials and Methods: A systematic literature review was conducted following PRISMA guidelines and the Cochrane Prognosis Methods Group criteria. Online databases were searched in June 2020 to identify all published studies in this area. Data were extracted based on the CHARMS checklist, and studies were evaluated based on predictor variables, validation, performance in validation, risk of bias, and applicability using the Prediction Model Risk of Bias Assessment Tool (PROBAST) tool.
   Results: The final sample contained 28 articles with 35 models for evaluation. Models focused on surgical (22), medical (5), or both (8) populations. Eighteen models were internally validated, 10 were externally validated, and 7 models underwent both types. Model performance varied within and across populations. Most models used retrospective data, the median number of predictors was 8.5, and most models demonstrated risk of bias.
   Discussion and Conclusion: Prediction modeling studies for postacute care destinations are becoming more prolific in the literature, but model development and validation strategies are inconsistent, and performance is variable. Most models are developed using regression, but machine learning methods are increasing in frequency. Future studies should ensure the rigorous variable selection and follow TRIPOD guidelines. Only 14% of the models have been tested or implemented beyond original studies, so translation into practice requires further investigation.
SN 1067-5027
EI 1527-974X
PD JAN
PY 2021
VL 29
IS 1
BP 176
EP 186
DI 10.1093/jamia/ocab197
EA NOV 2021
UT WOS:000740719600022
PM 34757383
ER

PT J
AU Briend, Y
   Chatelet, E
   Dufour, R
   Andrianoely, MA
   Legrand, F
   Baudin, S
AF Briend, Yvon
   Chatelet, Eric
   Dufour, Regis
   Andrianoely, Marie-Ange
   Legrand, Franck
   Baudin, Sophie
TI Dynamics of on-board rotors on finite-length journal bearings subject to
   multi-axial and multi-frequency excitations: numerical and experimental
   investigations
SO MECHANICS & INDUSTRY
AB On-board rotating machinery subject to multi-axial excitations is encountered in a wide variety of high-technology applications. Such excitations combined with mass unbalance forces play a considerable role in their integrity because they can cause parametric instability and rotor-stator interactions. Consequently, predicting the rotordynamics of such machines is crucial to avoid triggering undesirable phenomena or at least limiting their impacts. In this context, the present paper proposes an experimental validation of a numerical model of a rotor-shaft-hydrodynamic bearings system mounted on a moving base. The model is based on a finite element approach with Timoshenko beam elements having six degrees of freedom (DOF) per node to account for the bending, torsion and axial motions. Classical 2D rectangular finite elements are also employed to obtain the pressure field acting inside the hydrodynamic bearing. The finite element formulation is based on a variational inequality approach leading to the Reynolds boundary conditions. The experimental validation of the model is carried out with a rotor test rig, designed, built, instrumented and mounted on a 6-DOF hydraulic shaker. The rotor's dynamic behavior in bending, torsion and axial motions is assessed with base motions consisting of mono- and multi-axial translations and rotations with harmonic, random and chirp sine profiles. The comparison of the predicted and measured results achieved in terms of shaft orbits, full spectrums, transient history responses and power spectral densities is very satisfactory, permitting the experimental validation of the model proposed.
OI Dufour, Regis/0000-0002-4131-1441
SN 2257-7777
EI 2257-7750
PD MAY 28
PY 2021
VL 22
AR 35
DI 10.1051/meca/2021034
UT WOS:000659063000001
ER

PT J
AU Gonzalez, A
   Corsini, G
   Lobos, S
   Seelenfreund, D
   Tello, M
AF Gonzalez, Alex
   Corsini, Gino
   Lobos, Sergio
   Seelenfreund, Daniela
   Tello, Mario
TI Metabolic Specialization and Codon Preference of Lignocellulolytic Genes
   in the White Rot Basidiomycete Ceriporiopsis subvermispora
SO GENES
AB Ceriporiopsis subvermispora is a white-rot fungus with a high specificity towards lignin mineralization when colonizing dead wood or lignocellulosic compounds. Its lignocellulose degrading system is formed by cellulose hydrolytic enzymes, manganese peroxidases, and laccases that catalyze the efficient depolymerization and mineralization of lignocellulose. To determine if this metabolic specialization has modified codon usage of the lignocellulolytic system, improving its adaptation to the fungal translational machine, we analyzed the adaptation to host codon usage (CAI), tRNA pool (tAI, and AAtAI), codon pair bias (CPB), and the number of effective codons (Nc). These indexes were correlated with gene expression of C. subvermispora, in the presence of glucose and Aspen wood. General gene expression was not correlated with the index values. However, in media containing Aspen wood, the induction of expression of lignocellulose-degrading genes, showed significantly (p < 0.001) higher values of CAI, AAtAI, CPB, tAI, and lower values of Nc than non-induced genes. Cellulose-binding proteins and manganese peroxidases presented the highest adaptation values. We also identified an expansion of genes encoding glycine and glutamic acid tRNAs. Our results suggest that the metabolic specialization to use wood as the sole carbon source has introduced a bias in the codon usage of genes involved in lignocellulose degradation. This bias reduces codon diversity and increases codon usage adaptation to the tRNA pool available in C. subvermispora. To our knowledge, this is the first study showing that codon usage is modified to improve the translation efficiency of a group of genes involved in a particular metabolic process.
RI González, Alex/GYU-3220-2022; Tello, Mario/N-4198-2019
OI Tello, Mario/0000-0003-4573-6460; Gonzalez, Alex/0000-0001-9968-8623;
   Corsini, Gino/0000-0002-0418-8616
EI 2073-4425
PD OCT
PY 2020
VL 11
IS 10
AR 1227
DI 10.3390/genes11101227
UT WOS:000586843700001
PM 33092062
ER

PT J
AU Geertsema, EE
   Visser, GH
   Sander, JW
   Kalitzin, SN
AF Geertsema, Evelien E.
   Visser, Gerhard H.
   Sander, Josemir W.
   Kalitzin, Stiliyan N.
TI Automated non-contact detection of central apneas using video
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
AB Central apneas occurring in the aftermath of epileptic seizures may lead to sudden death. Contact-sensors currently used to detect apneas are not always suitable or tolerated. We developed a robust automated non-contact algorithm for real-time detection of central apneas using video cameras. One video recording with simulated apneas and nine with real-life apneas associated with epileptic seizures, each recorded from 3 to 4 angles, were used to develop the algorithm. Videos were preprocessed using optical flow, from which translation, dilatation and shear rates were extracted. Presence of breathing motions was quantified in the time-frequency spectrum by calculating the relative power in the respiratory range (0.1-1 Hz). Sigmoid modulation was calculated over different scales to quantify sigmoid-like drops in respiratory range power. Each sigmoid modulation maximum constitutes a possible apnea event. Two event features were calculated to enable distinction between apnea events and movements: modulation maximum amplitude and total spectral power modulation at the time of the event. An ensemble support vector machine was trained to classify events using a bagging procedure and validated in a leave-one-subject-out cross validation procedure. All apnea episodes were detected in the signals from at least one camera angle. Integrating camera inputs capturing different angles increased overall detection sensitivity (>90%). Overall detection specificity of >99% was achieved with both individual cameras and integrated camera inputs. These results suggest that it is feasible to detect central apneas automatically in video, using this algorithm. When validated, the algorithm might be used as an online remote apnea detector for safety monitoring. (C) 2019 Elsevier Ltd. All rights reserved.
RI Sander, Josemir W/C-1576-2008
OI Sander, Josemir W/0000-0001-6041-9661
SN 1746-8094
EI 1746-8108
PD JAN
PY 2020
VL 55
AR 101658
DI 10.1016/j.bspc.2019.101658
UT WOS:000502893200034
ER

PT C
AU Toporek, G
   Naidu, RS
   Xie, H
   Simicich, A
   Gades, T
   Raju, B
AF Toporek, Grzegorz
   Naidu, Raghavendra Srinivasa
   Xie, Hua
   Simicich, Adriana
   Gades, Tony
   Raju, Balasundar
BE Shen, D
   Liu, T
   Peters, TM
   Staib, LH
   Essert, C
   Zhou, S
   Yap, PT
   Khan, A
TI User Guidance for Point-of-Care Echocardiography Using a Multi-task Deep
   Neural Network
SO MEDICAL IMAGE COMPUTING AND COMPUTER ASSISTED INTERVENTION - MICCAI
   2019, PT V
SE Lecture Notes in Computer Science
CT 10th International Workshop on Machine Learning in Medical Imaging
   (MLMI) / 22nd International Conference on Medical Image Computing and
   Computer-Assisted Intervention (MICCAI)
CY OCT 13-17, 2019
CL Shenzhen, PEOPLES R CHINA
AB Echocardiography is a challenging sonographic examination with high user-dependence and the need for significant training and experience. To improve the use of ultrasound in emergency management, especially by nonexpert users, we propose a solely image-based machine-learning algorithm that does not rely on any external tracking devices. This algorithm guides the motion of the probe towards clinically relevant views, such as an apical four-chamber or long axis parasternal view, using a multi-task deep convolutional neural network (CNN). This network was trained on 27 human subjects using a multi-task learning paradigm to: (a) detect and exclude ultrasound frames where quality is not sufficient for the guidance, (b) identify one of three typical imaging windows, including the apical, parasternal, and subcostal to guide the user through the exam workflow, and (c) predict 6-DOF motion of the transducer towards a target view i.e. rotational and translational motion. And besides that, by deploying relatively lightweight architecture we ensured the operation of the algorithm at approximately 25 frames per second on a commercially available mobile device. Evaluation of the system on three unseen human subjects demonstrated that the method can guide an ultrasound transducer to a target view with an average rotational and translation accuracy of 3.3 +/- 2.6 degrees and 2.0 +/- 1.6 mm respectively, when the probe is close to the target (<5 mm). We believe that this accuracy would be sufficient to find the image on which the user can make quick, qualitative evaluations such as the detection of pericardial effusion, cardiac activity (squeeze, mitral valve motion, cardiac arrest, etc.), as well as performing quantitative calculations such as ejection fraction.
SN 0302-9743
EI 1611-3349
BN 978-3-030-32254-0; 978-3-030-32253-3
PY 2019
VL 11768
BP 309
EP 317
DI 10.1007/978-3-030-32254-0_35
UT WOS:000548735200035
ER

PT J
AU Murtas, G
AF Murtas, Giovanni
TI Early self-reproduction, the emergence of division mechanisms in
   protocells
SO MOLECULAR BIOSYSTEMS
AB Synthetic Biology approaches are proposing model systems and providing experimental evidences that life can arise as spontaneous chemical self-assembly process where the ability to reproduce itself is an essential feature of the living system. The appearance of early cells has required an amphiphilic membrane compartment to confine molecular information against diffusion, and the ability to self-replicate the boundary layer and the genetic information. The initial spontaneous self-replication mechanisms based on thermodynamic instability would have evolved in a prebiotic and later biological catalysis. Early studies demonstrate that fatty acids spontaneously assemble into bilayer membranes, building vesicles able to grow by incorporation of free lipid molecules and divide. Early replication mechanisms may have seen inorganic molecules playing a role as the first catalysts. The emergence of a short ribozyme or short catalytic peptide may have initiated the first prebiotic membrane lipid synthesis required for vesicle growth. The evolution of early catalysts towards the simplest translation machine to deliver proteins from RNA sequences was likely to give early birth to one single enzyme controlling protocell membrane division. The cell replication process assisted by complex enzymes for lipid synthesis is the result of evolved pathways in early cells. Evolution from organic molecules to protocells and early cells, thus from chemistry to biology, may have occurred in and out of the boundary layer. Here we review recent experimental work describing membrane and vesicle division mechanisms based on chemico-physical spontaneous processes, inorganic early catalysis and enzyme based mechanisms controlling early protocell division and finally the feedback from minimal genome studies.
RI Murtas, Giovanni/H-4873-2012
OI Murtas, Giovanni/0000-0002-1930-2389
SN 1742-206X
EI 1742-2051
PY 2013
VL 9
IS 2
BP 195
EP 204
DI 10.1039/c2mb25375e
UT WOS:000312945700004
PM 23232904
ER

PT J
AU Pahkamaa, A
   Warmefjord, K
   Karlsson, L
   Soderberg, R
   Goldak, J
AF Pahkamaa, Andreas
   Warmefjord, Kristina
   Karlsson, Lennart
   Soderberg, Rikard
   Goldak, John
TI Combining Variation Simulation With Welding Simulation for Prediction of
   Deformation and Variation of a Final Assembly
SO JOURNAL OF COMPUTING AND INFORMATION SCIENCE IN ENGINEERING
AB In most variation simulations, i.e., simulations of geometric variations in assemblies, the influence from heating and cooling processes, generated when two parts are welded together, is not taken into consideration. In most welding simulations, the influence from geometric tolerances on parts is not taken into consideration, i.e., the simulations are based on nominal parts. In this paper, these two aspects, both crucial for predicting the final outcome of an assembly, are combined. Monte Carlo simulation is used to generate a number of different non-nominal parts in a software for variation simulation. The translation and rotation matrices, representing the deviations from the nominal geometry due to positioning error, are exported to a software for welding simulation, where the effects from welding are applied. The final results are then analyzed with respect to both deviation and variation. The method is applied on a simple case, a T-weld joint, with available measurements of residual stresses and deformations. The effect of the different sources of deviation on the final outcome is analyzed and the difference between welding simulations applied to nominal parts and to disturbed (non-nominal) parts is investigated. The study shows that, in order to achieve realistic results, variation simulations should be combined with welding simulations. It does also show that welding simulations should be applied to a set of non-nominal parts since the difference between deviation of a nominal part and deviation of a non-nominal part due to influence of welding can be quite large. [DOI: 10.1115/1.4005720]
RI Wärmefjord, Kristina/U-7540-2019; Wärmefjord, Kristina/J-3815-2015;
   Söderberg, Rikard/F-2198-2015
OI Wärmefjord, Kristina/0000-0003-1556-3319; Wärmefjord,
   Kristina/0000-0003-1556-3319; Söderberg, Rikard/0000-0002-9138-4075
SN 1530-9827
PD JUN
PY 2012
VL 12
IS 2
AR 021002
DI 10.1115/1.4005720
UT WOS:000304816300002
ER

PT J
AU Li, J
   Wei, DQ
   Wang, JF
   Yu, ZT
   Chou, KC
AF Li, Jue
   Wei, Dong-Qing
   Wang, Jing-Fang
   Yu, Zheng-Tian
   Chou, Kuo-Chen
TI Molecular Dynamics Simulations of CYP2E1
SO MEDICINAL CHEMISTRY
AB CYP2E1, as a member of the cytochrome P450s (CYPs) super-family, is in charge of six percent drug metabolism involving a diversity of drugs distinct in structures and chemical properties, such as alcohols, monocyclic compounds (e. g., acetaminophen, benzene, p-nitrophenol), bicyclic heterocycles (e. g., coumarin, caffeine) and even fatty acids. The aromatic molecules form a vital species catalyzed by CYP2E1. To investigate the mechanism of metabolizing a diversity of aromatic molecules, five representative aromatic substrates were selected: (1) benzene, the non-polar simple ring; (2) aniline, the monocyclic substrate with smallest substitution on the phenyl ring; (3) acetaminophen, a large monocyclic substrate with highly active reactivity; (4) chlorzoxazone, and (5) theophylline, the bicyclic substrates with low or high catalytic activities. They were docked into X-ray structure of CYP2E1, after which all-atom molecular dynamics simulations of 5 ns were performed on each model. It was found that the active site interact with the aromatic substrates mainly through pi-pi stacking, supplied by five hydrophobic phenylalanines in the active site. Our simulations also illustrated the specific movement of different kinds of aromatic substrates in the pocket. Small monocyclic substrates show highly frequent self-rotation and limited translation movement. Substrates with single catalytic position are less movable in the pocket than substrates with multiple products. All these findings are quite useful for understanding the catalytic mechanism of CYP2E1, stimulating novel strategies for conducting further mutagenesis studies for specific drug design.
RI Chou, Kuo-Chen/A-8340-2009; Wang, Jingfang/Q-2597-2018
OI Wang, Jingfang/0000-0002-1355-5481
SN 1573-4064
EI 1875-6638
PD MAR
PY 2012
VL 8
IS 2
BP 208
EP 221
DI 10.2174/157340612800493692
UT WOS:000302993200010
PM 22385180
ER

PT C
AU Wang, SJ
   Yao, JH
   Petrick, N
   Summers, RM
AF Wang, Shijun
   Yao, Jianhua
   Petrick, Nicholas
   Summers, Ronald M.
BE Karssemeijer, N
   Giger, ML
TI Combining heterogeneous features for colonic polyp detection in CTC
   based on semi-definite programming
SO MEDICAL IMAGING 2009: COMPUTER-AIDED DIAGNOSIS
SE Proceedings of SPIE
CT Conference on Medical Imaging - Computer-Aided Diagnosis
CY FEB 10-12, 2009
CL Lake Buena Vista, FL
SP SPIE
AB Colon cancer is the second leading cause of cancer-related deaths in the United States. Computed tomographic colonography (CTC) combined with a computer aided detection system provides a feasible combination for improving colonic polyps detection and increasing the use of CTC for colon cancer screening. To distinguish true polyps from false positives, various features extracted from polyp candidates have been proposed. Most of these features try to capture the shape information of polyp candidates or neighborhood knowledge about the surrounding structures (fold, colon wall, etc.). In this paper, we propose a new set of shape descriptors for polyp candidates based on statistical curvature information. These features, called histogram of curvature features, are rotation, translation and scale invariant and can be treated as complementing our existing feature set. Then in order to make full use of the traditional features (defined as group A) and the new features (group B) which are highly heterogeneous, we employed a multiple kernel learning method based on semi-definite programming to identify an optimized classification kernel based on the combined set of features. We did leave-one-patient-out test on a CTC dataset which contained scans from 50 patients (with 90 6-9mm polyp detections). Experimental results show that a support vector machine (SVM) based on the combined feature set and the semi-definite optimization kernel achieved higher FROC performance compared to SVMs using the two groups of features separately. At a false positive per patient rate of 7, the sensitivity on 6-9mm polyps using the combined features improved from 0.78 (Group A) and 0.73 (Group B) to 0.82 (p<=0.01).
RI Yao, Jianhua/GQZ-6627-2022
OI Yao, Jianhua/0000-0001-9157-9596
SN 0277-786X
EI 1996-756X
BN 978-0-8194-7511-4
PY 2009
VL 7260
AR 72602R
DI 10.1117/12.811219
UT WOS:000784108700088
ER

PT J
AU Budd, S
   Daskalogiannakis, J
   Tompson, BD
AF Budd, Steven
   Daskalogiannakis, John
   Tompson, Bryan D.
TI A study of the frictional characteristics of four commercially available
   self-ligating bracket systems
SO EUROPEAN JOURNAL OF ORTHODONTICS
AB The objective of this investigation was to assess and compare the in vitro tribological behaviour of four commercially available self-ligating bracket systems. The frictional characteristics of the Damon3 (TM), Speed (TM), In-Ovation R (TM), and Time2 (TM) bracket systems were studied using a jig that mimics the three-dimensional movements that occur during sliding mechanics. Each bracket system was tested on the following stainless steel archwires: 0.016 x 0.022, 0.019 x 0.025, 0.020 round, and 0.021 x 0.021 inch Speed (TM) D-wire. An Instron testing machine with a 50 N load cell was used to measure the frictional resistance for each bracket/tooth assembly. The crosshead speed was set at a constant rate of 1 mm/minute, and each typodont tooth was moved along a fixed wire segment for a distance of 8 mm. Descriptive statistical analysis for each bracket/archwire combination with regard to frictional resistance was performed with a two-way, balanced analysis of variance for bracket type and wire size.
   The Damon3 (TM) bracket consistently demonstrated the lowest frictional resistance to sliding, while the Speed (TM) bracket produced significantly (P < 0.001) more frictional resistance than the other brackets tested for any given archwire.
   The self-ligation design (passive versus active) appears to be the primary variable responsible for the frictional resistance generated by self-ligating brackets during translation. Passively ligated brackets produce less frictional resistance; however, this decreased friction may result in decreased control compared with actively ligated systems.
SN 0141-5387
EI 1460-2210
PD DEC
PY 2008
VL 30
IS 6
BP 645
EP 653
DI 10.1093/ejo/cjn058
UT WOS:000261459100014
PM 18974067
ER

PT J
AU Salvador, M
   Regazzoni, F
   Dede, L
   Quarteroni, A
AF Salvador, Matteo
   Regazzoni, Francesco
   Dede, Luca
   Quarteroni, Alfio
TI Fast and robust parameter estimation with uncertainty quantification for
   the cardiac function
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
AB Background and objectives: Parameter estimation and uncertainty quantification are crucial in computa-tional cardiology, as they enable the construction of digital twins that faithfully replicate the behavior of physical patients. Many model parameters regarding cardiac electromechanics and cardiovascular hemo-dynamics need to be robustly fitted by starting from a few, possibly non-invasive, noisy observations. Moreover, short execution times and a small amount of computational resources are required for the effective clinical translation. Methods: In the framework of Bayesian statistics, we combine Maximum a Posteriori estimation and Hamiltonian Monte Carlo to find an approximation of model parameters and their posterior distributions. Fast simulations and minimal memory requirements are achieved by using an accurate and geometry -specific Artificial Neural Network surrogate model for the cardiac function, matrix-free methods, auto-matic differentiation and automatic vectorization. Furthermore, we account for the surrogate modeling error and measurement error. Results: We perform three different in silico test cases, ranging from the ventricular function to the en-tire cardiocirculatory system, involving whole-heart mechanics, arterial and venous hemodynamics. By employing a single central processing unit on a standard laptop, we attain highly accurate estimations for all model parameters in short computational times. Furthermore, we obtain posterior distributions that contain the true values inside the 90% credibility regions. Conclusions: Many model parameters regarding the entire cardiovascular system can be fastly and ro-bustly identified with minimal hardware requirements. This can be achieved when a small amount of non-invasive data is available and when high levels of signal-to-noise ratio are present in the quanti-ties of interest. With these features, our approach meets the requirements for clinical exploitation, while being compliant with Green Computing practices.
RI ; Regazzoni, Francesco/V-4074-2017
OI Salvador, Matteo/0000-0002-4937-5538; Regazzoni,
   Francesco/0000-0002-4207-1400
SN 0169-2607
EI 1872-7565
PD APR
PY 2023
VL 231
AR 107402
DI 10.1016/j.cmpb.2023.107402
EA FEB 2023
UT WOS:000944762500001
PM 36773593
ER

PT J
AU Liang, M
   Zhang, ZX
   Zhang, JY
   Ruan, T
   Ye, Q
   He, P
AF Liang, Ming
   Zhang, ZhiXing
   Zhang, JiaYing
   Ruan, Tong
   Ye, Qi
   He, Ping
TI Lab indicators standardization method for the regional healthcare
   platform: a case study on heart failure
SO BMC MEDICAL INFORMATICS AND DECISION MAKING
AB Background: Laboratory indicator test results in electronic health records have been applied to many clinical big data analysis. However, it is quite common that the same laboratory examination item (i.e., lab indicator) is presented using different names in Chinese due to the translation problem and the habit problem of various hospitals, which results in distortion of analysis results.
   Methods: A framework with a recall model and a binary classification model is proposed, which could reduce the alignment scale and improve the accuracy of lab indicator normalization. To reduce alignment scale, tf-idf is used for candidate selection. To assure the accuracy of output, we utilize enhanced sequential inference model for binary classification. And active learning is applied with a selection strategy which is proposed for reducing annotation cost.
   Results: Since our indicator standardization method mainly focuses on Chinese indicator inconsistency, we perform our experiment on Shanghai Hospital Development Center and select clinical data from 8 hospitals. The method achieves a F1-score 92.08% in our final binary classification. As for active learning, the new strategy proposed performs better than random baseline and could outperform the result trained on full data with only 43% training data. A case study on heart failure clinic analysis conducted on the sub-dataset collected from SHDC shows that our proposed method is practical in the application with good performance.
   Conclusion: This work demonstrates that the structure we proposed can be effectively applied to lab indicator normalization. And active learning is also suitable for this task for cost reduction. Such a method is also valuable in data cleaning, data mining, text extracting and entity alignment.
EI 1472-6947
PD DEC 15
PY 2020
VL 20
SU 14
SI SI
AR 331
DI 10.1186/s12911-020-01324-6
UT WOS:000600129600003
PM 33323114
ER

PT C
AU Ren, Y
   Liu, JL
   Tan, X
   Zhao, Z
   Zhao, S
   Liu, TY
AF Ren, Yi
   Liu, Jinglin
   Tan, Xu
   Zhao, Zhou
   Zhao, Sheng
   Liu, Tie-Yan
GP Assoc Computat Linguist
TI A Study of Non-autoregressive Model for Sequence Generation
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB Non-autoregressive (NAR) models generate all the tokens of a sequence in parallel, resulting in faster generation speed compared to their autoregressive (AR) counterparts but at the cost of lower accuracy. Different techniques including knowledge distillation and source-target alignment have been proposed to bridge the gap between AR and NAR models in various tasks such as neural machine translation (NMT), automatic speech recognition (ASR), and text to speech (TTS). With the help of those techniques, NAR models can catch up with the accuracy of AR models in some tasks but not in some others. In this work, we conduct a study to understand the difficulty of NAR sequence generation and try to answer: (1) Why NAR models can catch up with AR models in some tasks but not all? (2) Why techniques like knowledge distillation and source-target alignment can help NAR models. Since the main difference between AR and NAR models is that NAR models do not use dependency among target tokens while AR models do, intuitively the difficulty of NAR sequence generation heavily depends on the strongness of dependency among target tokens. To quantify such dependency, we propose an analysis model called CoMMA to characterize the difficulty of different NAR sequence generation tasks. We have several interesting findings: 1) Among the NMT, ASR and TTS tasks, ASR has the most target-token dependency while TTS has the least. 2) Knowledge distillation reduces the target-token dependency in target sequence and thus improves the accuracy of NAR models. 3) Source-target alignment constraint encourages dependency of a target token on source tokens and thus eases the training of NAR models.
BN 978-1-952148-25-5
PY 2020
BP 149
EP 159
UT WOS:000570978200015
ER

PT J
AU He, LY
   Tang, J
   Andersson, EI
   Timonen, S
   Koschmieder, S
   Wennerberg, K
   Mustjoki, S
   Aittokallio, T
AF He, Liye
   Tang, Jing
   Andersson, Emma I.
   Timonen, Sanna
   Koschmieder, Steffen
   Wennerberg, Krister
   Mustjoki, Satu
   Aittokallio, Tero
TI Patient-Customized Drug Combination Prediction and Testing for T-cell
   Prolymphocytic Leukemia Patients
SO CANCER RESEARCH
AB The molecular pathways that drive cancer progression and treatment resistance are highly redundant and variable between individual patients with the same cancer type. To tackle this complex rewiring of pathway cross-talk, personalized combination treatments targeting multiple cancer growth and survival pathways are required. Here we implemented a computational-experimental drug combination prediction and testing (DCPT) platform for efficient in silico prioritization and ex vivo testing in patient-derived samples to identify customized synergistic combinations for individual cancer patients. DCPT used drug-target interaction networks to traverse the massive combinatorial search spaces among 218 compounds (a total of 23,653 pairwise combinations) and identified cancer-selective synergies by using differential single-compound sensitivity profiles between patient cells and healthy controls, hence reducing the likelihood of toxic combination effects. A polypharmacology-based machine learning modeling and network visualization made use of baseline genomic and molecular profiles to guide patient-specific combination testing and clinical translation phases. Using T-cell prolymphocytic leukemia (T-PLL) as a first case study, we show how the DCPT platform successfully predicted distinct synergistic combinations for each of the three T-PLL patients, each presenting with different resistance patterns and synergy mechanisms. In total, 10 of 24 (42%) of selective combination predictions were experimentally confirmed to show synergy in patient-derived samples ex vivo. The identified selective synergies among approved drugs, including tacrolimus and temsirolimus combined with BCL-2 inhibitor venetoclax, may offer novel drug repurposing opportunities for treating T-PLL.
   Significance: An integrated use of functional drug screening combined with genomic and molecular profiling enables patient-customized prediction and testing of drug combination synergies for T-PLL patients. (C) 2018 AACR.
RI Tang, Jing/W-1764-2019; Mustjoki, Satu/AAD-9974-2020; tang,
   jing/HHR-9815-2022; Wennerberg, Krister/AAH-2919-2022; Tang,
   Jing/H-4084-2012; He, Liye/AAW-5928-2020; Wennerberg,
   Krister/AFM-0539-2022; Aittokallio, Tero/B-6583-2009
OI Tang, Jing/0000-0001-7480-7710; Mustjoki, Satu/0000-0002-0816-8241;
   Wennerberg, Krister/0000-0002-1352-4220; Tang, Jing/0000-0001-7480-7710;
   He, Liye/0000-0002-6632-2112; Wennerberg, Krister/0000-0002-1352-4220;
   Aittokallio, Tero/0000-0002-0886-9769; Koschmieder,
   Steffen/0000-0002-1011-8171; Timonen, Sanna/0000-0002-8139-5950
SN 0008-5472
EI 1538-7445
PD MAY 1
PY 2018
VL 78
IS 9
BP 2407
EP 2418
DI 10.1158/0008-5472.CAN-17-3644
UT WOS:000431374000023
PM 29483097
ER

PT J
AU Bechar, A
   Nof, SY
   Wachs, JP
AF Bechar, A.
   Nof, S. Y.
   Wachs, J. P.
TI A review and framework of laser-based collaboration support
SO ANNUAL REVIEWS IN CONTROL
AB New technologies are emerging to enable and support physical, implicit and explicit collaborations. They are essential for dealing with increasingly complex systems in unstructured, dynamic environments. The purpose of this article is to review the role of laser technology in enabling better, more precise interactions and their control, and to identify opportunities and challenges in this area. While the most common applications of laser technology are found in medical and health care, manufacturing, and communication, other domains such as safety, quality assurance, agriculture, construction, entertainment, defense, transportation, and law enforcement also benefit from it. In spite of the rapid dissemination of this technology, its role in support of collaboration and discovery is still in its infancy. Research activities concerning new ways of using lasers as a collaboration supporting technology that may strengthen new areas have been relatively limited. Nevertheless, the translation to this domain of collaboration support has been recognized as vital for activities that demand increasingly more coordinated effort among interacting agents (e.g., humans, machines, particles) and digital, possibly also photonic agents. Recent advances in laser technology in a number of application domains are reviewed in this article, focusing primarily on lasers' role for supporting different forms of precision interactions and collaboration. In addition, a framework with five collaboration support functions and five collaboration dimensions is defined for this review. The taxonomy framework is useful for enabling better understanding of the existing and emerging opportunities that laser-based technology offers for collaboration support, its advantages and several research gaps. (C) 2015 Elsevier Ltd. All rights reserved.
SN 1367-5788
PY 2015
VL 39
BP 30
EP 45
DI 10.1016/j.arcontrol.2015.03.003
UT WOS:000355372400003
ER

PT J
AU Halbig, K
   Sacharidou, A
   De Nova-Ocampo, M
   Cruz-Reyes, J
AF Halbig, Karl
   Sacharidou, Anastasia
   De Nova-Ocampo, Monica
   Cruz-Reyes, Jorge
TI Preferential interaction of a 25 kDa protein with an A6 pre-mRNA
   substrate for RNA editing in Trypanosoma brucei
SO INTERNATIONAL JOURNAL FOR PARASITOLOGY
AB Mitochondrial gene expression in kinctoplastids is controlled after transcription, potentially at the levels of RNA maturation, stability and translation. Among these processes, RNA editing by U-insertion/deletion catalysed by multi-subunit editing complexes is best characterised at the molecular level. Nevertheless, mitochondrial RNA metabolism overall remains poorly understood, including the potential regulatory factors that may interact with the relevant catalytic molecular machines and/or RNA substrates. Here we report on a similar to 25 kDa polypeptide in mitochondrial extracts that exhibits a preferential "zero-distance" photo-crosslinking interaction with an A6 pre-mRNA model substrate for RNA editing containing a single [P-32] at the first editing site. The similar to 25 kDa polypeptide purified away from editosomes upon ion-exchange chromatography and glycerol gradient sedimentation. Competition assays with homologous and heterologous transcripts suggest that the preferential recognition of the A6 substrate is based on relatively low-specificity RNA-protein contacts. Our mapping and substrate truncation analyses suggest that the crosslinking activity primarily targeted a predicted stem-loop region containing the first editing sites. Consistent with the notion that pre-mRNA folding may be required, pre-annealing with guide RNA abolished crosslinking. Interestingly, this preferential protein interaction with the A6 substrate seemed to require adenosine 5'-triphosphate but not hydrolysis. As in other biological systems, fine regulation in vivo may be brought about by transient networks of relatively low-specificity interactions in which multiple auxiliary factors bind to mRNAs and/or editing complexes in unique higher-order assemblies. (c) 2006 Australian Society for Parasitology Inc. Published by Elsevier Ltd. All rights reserved.
RI Cruz-Reyes, Jorge/GQP-1338-2022
OI De Nova Ocampo, Monica/0000-0002-0750-7977; Cruz-Reyes,
   Jorge/0000-0003-0545-1508
SN 0020-7519
PD OCT
PY 2006
VL 36
IS 12
BP 1295
EP 1304
DI 10.1016/j.ijpara.2006.05.011
UT WOS:000241298800008
PM 16860325
ER

PT J
AU Edmonds, P
   Hirst, G
AF Edmonds, P
   Hirst, G
TI Near-synonymy and lexical choice
SO COMPUTATIONAL LINGUISTICS
AB We develop a new computational model for representing the fine-grained meanings of near-synonyms and the differences between them. We also develop a lexical-choice process that can decide which of several near-synonyms is most appropriate in a particular situation. This research has direct applications in machine translation and text generation.
   We first identify the problems of representing near-synonyms in a computational lexicon and show that no previous model adequately accounts for near-synonymy. We then propose a preliminary theory to account for near-synonymy, relying crucially on the notion of granularity of representation, in which the meaning of a word arises out of a context-dependent combination of a context-independent core meaning and a set of explicit differences to its near-synonyms. That is, near-synonyms cluster together.
   We then develop a clustered model of lexical knowledge, derived from the conventional ontological model. The model cuts off the ontology at a coarse grain, thus avoiding an awkward proliferation of language-dependent concepts in the ontology, yet maintaining the advantages of efficient computation and reasoning. The model groups near-synonyms into subconceptual clusters that are linked to the ontology. A cluster differentiates near-synonyms in terms of fine-grained aspects of denotation, implication, expressed attitude, and style. The model is general enough to account for other types of variation, for instance, in collocational behavior.
   An efficient, robust, and flexible fine-grained lexical-choice process is a consequence of a clustered model of lexical knowledge. To make it work, we formalize criteria for lexical choice as preferences to express certain concepts with varying indirectness, to express attitudes, and to establish certain styles. The lexical-choice process itself works on two tiers: between clusters and between near-synonyns of clusters. We describe our prototype implementation of the system, called I-Saurus.
RI Hirst, Graeme/A-1825-2008
SN 0891-2017
EI 1530-9312
PD JUN
PY 2002
VL 28
IS 2
BP 105
EP 144
DI 10.1162/089120102760173625
UT WOS:000177248700001
ER

PT C
AU Mishra, S
   Gharpure, DC
AF Mishra, S
   Gharpure, DC
BE Hunt, MA
TI Cost effective tactile sensing system for object recognition
SO MACHINE VISION APPLICATIONS IN INDUSTRIAL INSPECTION IX
SE PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)
CT Conference on Machine Vision Applications in Industrial Inspection IX
CY JAN 22-23, 2001
CL SAN JOSE, CA
SP Soc Imaging Sci & Technolo, SPIE
AB Though significant progress has been made in applying computer technology to manufacturing, anticipated benefits from machine vision have not been realized. Despite greatly improved image-processing hardware and analysis algorithms, successful application of the vision technology to manufacturing is still very difficult, partly due to difficulty of integrating various aspects of this technology into cost effective and robust systems.
   The design of a recognition system involves two processes namely learning and recognition based on object representation and similarity measures. Object representation has to provide for translation, rotation and scale invariance together with accuracy and simplicity. The similarity measures which account for resemblance among objects and decision functions used for identification influence overall robustness of the process. Image processing systems used for the purpose have to work with a huge amount of data making the algorithms memory and computer intensive. In this work we have tried to use tactile images for inputting the data. Tactile sensing is related to touch sensing and hence is relatively economical as the system employs simple pressure sensing devices which provide data relatively easy to condition and measure. Touch is not only complimentary to vision but it offers many powerful sensing capabilities to obtain the shape, hardness, surface details etc
   This paper presents the use of simple PC based tactile sensing system for object recognition Software has been developed to acquire, process and analyze the tactile images. The recognition is based on the use of invariant moments and a back propagation neural network. The software also provides information regarding contact area, height, position and orientation of the object. The paper deals with details of the software developed. Various experiments carried out to test the performance of the system have also been described along with the results obtained.
SN 0277-786X
BN 0-8194-3979-7
PY 2001
VL 4301
BP 175
EP 180
DI 10.1117/12.420910
UT WOS:000169322300018
ER

PT J
AU Padmini, P
   Paramasivam, C
   Lal, GJ
   Alharbi, S
   Bhowmick, K
AF Padmini, Palli
   Paramasivam, C.
   Lal, G. Jyothish
   Alharbi, Sadeen
   Bhowmick, Kaustav
TI Age-Based Automatic Voice Conversion Using Blood Relation for Voice
   Impaired
SO CMC-COMPUTERS MATERIALS & CONTINUA
AB The present work presents a statistical method to translate human voices across age groups, based on commonalities in voices of blood relations. The age-translated voices have been naturalized extracting the blood relation features e.g., pitch, duration, energy, using Mel Frequency Cepstrum Coefficients (MFCC), for social compatibility of the voice-impaired. The system has been demonstrated using standard English and an Indian language. The voice samples for resynthesis were derived from 12 families, with member ages ranging from 8-80 years. The voice-age translation, performed using the Pitch synchronous overlap and add (PSOLA) approach, by modulation of extracted voice features, was validated by perception test. The translated and resynthesized voices were correlated using Linde, Buzo, Gray (LBG), and Kekre's Fast Codebook generation (KFCG) algorithms. For translated voice targets, a strong (theta < similar to 93% and theta < similar to 96%) correlation was found with blood relatives, whereas, a weak (theta < similar to 78% and theta < similar to 80%) correlation range was found between different families and different gender from same families. The study further subcategorized the sampling and synthesis of the voices into similar or dissimilar gender groups, using a support vector machine (SVM) choosing between available voice samples. Finally, similar to 96%, similar to 93%, and similar to 94% accuracies were obtained in the identification of the gender of the voice sample, the age group samples, and the correlation between the original and converted voice samples, respectively. The results obtained were close to the natural voice sample features and are envisaged to facilitate a near-natural voice for speech-impaired easily.
RI Alansi, Saleh/AAZ-5022-2021; Alharbi, Sadeen/ABA-1454-2021
OI Bhowmick, Kaustav/0000-0002-0316-0224
SN 1546-2218
EI 1546-2226
PY 2022
VL 70
IS 2
BP 4027
EP 4051
DI 10.32604/cmc.2022.020065
UT WOS:000705947900001
ER

PT C
AU Braun, S
   Starr, K
   Delfani, J
   Tiittula, L
   Laaksonen, J
   Braeckman, K
   Van Rijsselbergen, D
   Lagrilliere, S
   Saarikoski, L
AF Braun, Sabine
   Starr, Kim
   Delfani, Jaleh
   Tiittula, Liisa
   Laaksonen, Jorma
   Braeckman, Karel
   Van Rijsselbergen, Dieter
   Lagrilliere, Sasha
   Saarikoski, Lauri
BE Stephanidis, C
   Harris, D
   Li, WC
   Schmorrow, DD
   Fidopiastis, CM
   Antona, M
   Gao, Q
   Zhou, J
   Zaphiris, P
   Ioannou, A
   Sottilare, RA
   Schwarz, J
   Rauterberg, M
TI When Worlds Collide: AI-Created, Human-Mediated Video Description
   Services and the User Experience
SO HCI INTERNATIONAL 2021 - LATE BREAKING PAPERS: COGNITION, INCLUSION,
   LEARNING, AND CULTURE, HCII 2021
SE Lecture Notes in Computer Science
CT 23rd International Conference on Human-Computer Interaction (HCII)
CY JUL 24-29, 2021
CL ELECTR NETWORK
AB This paper reports on a user-experience study undertaken as part of the H2020 project MeMAD (`Methods for Managing Audiovisual Data: Combining Automatic Efficiency with Human Accuracy'), in which multimedia content describers from the television and archive industries tested Flow, an online platform, designed to assist the post-editing of automatically generated data, in order to enhance the production of archival descriptions of film content. Our study captured the participant experience using screen recordings, the User Experience Questionnaire (UEQ), a benchmarked interactive media questionnaire and focus group discussions, reporting a broadly positive post-editing environment. Users designated the platform's role in the collation of machine-generated content descriptions, transcripts, named-entities (location, persons, organisations) and translated text as helpful and likely to enhance creative outputs in the longer term. Suggestions for improving the platform included the addition of specialist vocabulary functionality, shot-type detection, film-topic labelling, and automatic music recognition. The limitations of the study are, most notably, the current level of accuracy achieved in computer vision outputs (i.e. automated video descriptions of film material) which has been hindered by the lack of reliable and accurate training data, and the need for a more narratively oriented interface which allows describers to develop their storytelling techniques and build descriptions which fit within a platform-hosted storyboarding functionality. While this work has value in its own right, it can also be regarded as paving the way for the future (semi)automation of audio descriptions to assist audiences experiencing sight impairment, cognitive accessibility difficulties or for whom `visionless' multimedia consumption is their preferred option.
OI Tiittula, Liisa/0000-0002-4688-0854; Delfani, Jaleh/0000-0003-2075-3539;
   Braun, Sabine/0000-0002-6187-3812; Starr, Kim/0000-0001-5236-1535
SN 0302-9743
EI 1611-3349
BN 978-3-030-90328-2; 978-3-030-90327-5
PY 2021
VL 13096
BP 147
EP 167
DI 10.1007/978-3-030-90328-2_10
UT WOS:000765928500010
ER

PT J
AU Yu, J
   Li, J
   Yu, Z
   Huang, QM
AF Yu, Jun
   Li, Jing
   Yu, Zhou
   Huang, Qingming
TI Multimodal Transformer With Multi-View Visual Representation for Image
   Captioning
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY
AB Image captioning aims to automatically generate a natural language description of a given image, and most state-of-the-art models have adopted an encoder-decoder framework. The framework consists of a convolution neural network (CNN)-based image encoder that extracts region-based visual features from the input image, and an recurrent neural network (RNN) based caption decoder that generates the output caption words based on the visual features with the attention mechanism. Despite the success of existing studies, current methods only model the co-attention that characterizes the inter-modal interactions while neglecting the self-attention that characterizes the intra-modal interactions. Inspired by the success of the Transformer model in machine translation, here we extend it to a Multimodal Transformer (MT) model for image captioning. Compared to existing image captioning approaches, the MT model simultaneously captures intra- and inter-modal interactions in a unified attention block. Due to the in-depth modular composition of such attention blocks, the MT model can perform complex multimodal reasoning and output accurate captions. Moreover, to further improve the image captioning performance, multi-view visual features are seamlessly introduced into the MT model. We quantitatively and qualitatively evaluate our approach using the benchmark MSCOCO image captioning dataset and conduct extensive ablation studies to investigate the reasons behind its effectiveness. The experimental results show that our method significantly outperforms the previous state-of-the-art methods. With an ensemble of seven models, our solution ranks the 1st place on the real-time leaderboard of the MSCOCO image captioning challenge at the time of the writing of this paper.
OI Yu, Zhou/0000-0001-8407-1137
SN 1051-8215
EI 1558-2205
PD DEC
PY 2020
VL 30
IS 12
BP 4467
EP 4480
DI 10.1109/TCSVT.2019.2947482
UT WOS:000597751000007
ER

PT J
AU Ackermann, J
   Mestriner, AB
   Merkely, G
   Ambra, FML
   Gomoll, AH
AF Ackermann, Jakob
   Mestriner, Alexandre Barbieri
   Merkely, Gergo
   Ambra, Felipe Morlin Luiz
   Gomoll, Andreas H.
TI Femoral interference screw insertion significantly increases graft
   tension in medial patellofemoral ligament reconstruction
SO KNEE SURGERY SPORTS TRAUMATOLOGY ARTHROSCOPY
AB Purpose This study aimed to quantify the effect of interference screw insertion on MPFL graft tension when securing the femoral attachment after patellar fixation. It was hypothesized that interference screw insertion significantly increases graft tension. Methods Ten fresh frozen human cadaveric femurs were utilized to compare graft tension at three different preloading conditions (2 N, 5 N, 10 N) using a tensile testing machine (Admet Inc., Norwood, MA). Each preloading condition was analyzed with varying graft sizes (5-8 mm), tunnel diameters (7-9 mm), and interference screw sizes (7-9 mm). Non-parametric statistical analysis was utilized to compare testing conditions among each other. Results Graft tension significantly increased after interference screw insertion by 100% to 552%, with 2 N preload showing the greatest increase (p < 0.001). Grafts with a larger diameter (7-8 mm) had a significantly greater increase in tension than smaller grafts (5-6 mm), regardless of preloading conditions (p < 0.001). Interference screw size had no influence on graft tension (n.s.). A graft-tunnel interference (tunnel diameter-graft diameter) fit of 0 mm and 1 mm significantly increased graft tension for each preloading condition when compared to a slightly looser fit of >= 2 mm (p < 0.05). Conclusion Femoral interference screw insertion significantly increases graft tension in MPFL reconstruction even in low preloading conditions, with graft size and graft-tunnel interference fit having a considerably effect on graft tension. Surgeons should be aware of the inadvertent increases in graft tension even in low preloading conditions to mitigate the risk of graft overtensioning.
RI Merkely, Gergő/O-1124-2015
OI Merkely, Gergő/0000-0001-6660-6994; Mestriner,
   Alexandre/0000-0002-4220-6360
SN 0942-2056
EI 1433-7347
PD SEP
PY 2021
VL 29
IS 9
BP 2851
EP 2856
DI 10.1007/s00167-020-06186-z
EA JUL 2020
UT WOS:000556546600001
PM 32734332
ER

PT J
AU Gao, N
   Zhu, ZY
   Weng, ZQ
   Chen, GL
   Zhang, M
AF Gao, Nan
   Zhu, Zhenyang
   Weng, Zhengqiu
   Chen, Guolang
   Zhang, Min
TI A Supervised Named Entity Recognition Method Based on Pattern Matching
   and Semantic Verification
SO JOURNAL OF INTERNET TECHNOLOGY
AB Named entity recognition is a basic task in the field of natural language processing and plays a pivotal role in tasks such as information extraction, machine translation, and knowledge graph construction. It has also received widespread attention in financial, biological and pharmaceutical industries. This paper proposes a method of weakly supervised learning to recognize the complex named entities (commonly composed of multiple small entity sequences, hereinafter referred to as CNEs) in the corpus, which makes it difficult to determine the boundaries of such entities. To improve the recognition accuracy, our method Masked-BiLSTM-CRF is proposed to separate the context semantic relationship determination from the entity boundary confirmation. This method is based on two aspects to solve the above problems: (1) Semantic model based on CNEs mask processing. Before training, the CNEs in the corpus will be masked, and then use the masked corpus training the semantic model through BiLSTM-CRF, which can verify whether the context semantics of the corresponding location entities are correct. (2) A weakly supervised CNEs boundary confirmation model based on sequential patterns. In the small sample data set, the target CNE candidate set is found by sliding window combined with sequence pattern matching, and then it is effectively screened and judged by the semantic understanding model obtained in (1). The experimental results show that compared with the named entity recognition method based directly on BiLSTMCRF on the weakly-supervised named entity recognition in financial field, our proposed method improves F1Score in the small data training sample set by nearly 9%, and it has some generalization ability.
RI Zhu, Sivan/AAC-2579-2022
SN 1607-9264
EI 2079-4029
PY 2020
VL 21
IS 7
BP 1917
EP 1928
DI 10.3966/160792642020122107006
UT WOS:000607113300006
ER

PT C
AU Li, Z
   Hu, CY
   Zhang, Y
   Guo, SQ
AF Li, Zheng
   Hu, Chengyu
   Zhang, Yang
   Guo, Shanqing
GP ACM
TI How to Prove Your Model Belongs to You: A Blind-Watermark based
   Framework to Protect Intellectual Property of DNN
SO 35TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSA)
CT 35th Annual Computer Security Applications Conference (ACSA)
CY DEC 09-13, 2019
CL San Juan, PREF_CTRY_STATE
SP Appl Comp Secur Associates, Natl Sci Fdn, Charles Koch Inst
AB Deep learning techniques have made tremendous progress in a variety of challenging tasks, such as image recognition and machine translation, during the past decade. Training deep neural networks is computationally expensive and requires both human and intellectual resources. Therefore, it is necessary to protect the intellectual property of the model and externally verify the ownership of the model. However, previous studies either fail to defend against the evasion attack or have not explicitly dealt with fraudulent claims of ownership by adversaries. Furthermore, they can not establish a clear association between the model and the creator's identity.
   To fill these gaps, in this paper, we propose a novel intellectual property protection (IPP) framework based on blind-watermark for watermarking deep neural networks that meet the requirements of security and feasibility. Our framework accepts ordinary samples and the exclusive logo as inputs, outputting newly generated samples as watermarks, which are almost indistinguishable from the origin, and infuses these watermarks into DNN models by assigning specific labels, leaving the backdoor as the basis for our copyright claim. We evaluated our IPP framework on two benchmark datasets and 15 popular deep learning models. The results show that our framework successfully verifies the ownership of all the models without a noticeable impact on their primary task. Most importantly, we are the first to successfully design and implement a blind-watermark based framework, which can achieve state-of-art performances on undetectability against evasion attack and unforgeability against fraudulent claims of ownership. Further, our framework shows remarkable robustness and establishes a clear association between the model and the author's identity.
OI Li, Zheng/0000-0002-4466-7523
BN 978-1-4503-7628-0
PY 2019
BP 126
EP 137
DI 10.1145/3359789.3359801
UT WOS:000540643900010
ER

PT J
AU Zhang, RH
   Mu, CP
   Xu, M
   Xu, LX
   Shi, QL
   Wang, JB
AF Zhang, Ruiheng
   Mu, Chengpo
   Xu, Min
   Xu, Lixin
   Shi, Qiaolin
   Wang, Junbo
TI Synthetic IR Image Refinement Using Adversarial Learning With
   Bidirectional Mappings
SO IEEE ACCESS
AB Collecting a large dataset of real infrared (IR) images is expensive, time-consuming, and even unavailable in some specific scenarios. With recent progress in machine learning, it has become more feasible to replace real IR images with qualified synthetic IR images in learning-based IR systems. However, this alternative may fail to achieve the desired performance, due to the gap between real and synthetic IR images. Inspired by adversarial learning for image-to-image translation, we propose the Synthetic IR Refinement Generative Adversarial Network (SIR-GAN) to narrow this gap. By learning the bidirectional mappings between two unpaired domains, the realism of the simulated IR images generated from the IR Simulator are significantly improved, where the source domain contains a large number of simulated IR images, where the target domain contains a limited quantity of real IR images. Specifically, driven by the idea of transferring infrared characteristic and protect target semantic information simultaneously, we propose a SIR refinement loss to consider an infrared loss and a structure loss further to the adversarial loss and the consistency loss. To further reduce the gap, stabilize training, and avoid artefacts, we modify the proposed algorithm by developing a training strategy, adding the U-net in the generators, using the dilated convolution in the discriminators and invoking the N-Adam acts as the optimizer. Qualitative, quantitative, and ablation study experiments demonstrate the superiority of the proposed approach compared with the state-of-the-art techniques in terms of realism and fidelity. In addition, our refined IR images are evaluated in the context of a feasibility study, where the accuracy of the trained classifier is significantly improved by adding our refined data into a small real-data training set.
RI xu, li/GNH-3667-2022
OI Xu, Min/0000-0001-9581-8849; Zhang, Ruiheng/0000-0002-5460-7196
SN 2169-3536
PY 2019
VL 7
BP 153734
EP 153750
DI 10.1109/ACCESS.2019.2947657
UT WOS:000510249400003
ER

PT J
AU Xu, JZ
   Li, H
   Li, K
   Harkins, KD
   Jiang, XY
   Xie, JP
   Kang, H
   Dortch, RD
   Anderson, AW
   Does, MD
   Gore, JC
AF Xu, Junzhong
   Li, Hua
   Li, Ke
   Harkins, Kevin D.
   Jiang, Xiaoyu
   Xie, Jingping
   Kang, Hakmook
   Dortch, Richard D.
   Anderson, Adam W.
   Does, Mark D.
   Gore, John C.
TI Fast and simplified mapping of mean axon diameter using temporal
   diffusion spectroscopy
SO NMR IN BIOMEDICINE
AB Mapping axon diameter is of interest for the potential diagnosis and monitoring of various neuronal pathologies. Advanced diffusion-weighted MRI methods have been developed to measure mean axon diameters non-invasively, but suffer major drawbacks that prevent their direct translation into clinical practice, such as complex non-linear data fitting and, more importantly, long scanning times that are usually not tolerable for most human subjects. In the current study, temporal diffusion spectroscopy using oscillating diffusion gradients was used to measure mean axon diameters with high sensitivity to small axons in the central nervous system. Axon diameters have been found to be correlated with a novel metric, DDR perpendicular to (the rate of dispersion of the perpendicular diffusion coefficient with gradient frequency), which is a model-free quantity that does not require complex data analyses and can be obtained from two diffusion coefficient measurements in clinically relevant times with conventional MRI machines. A comprehensive investigation including computer simulations and animal experiments ex vivo showed that measurements of DDR perpendicular to agree closely with histological data. In humans in vivo, DDR perpendicular to was also found to correlate well with reported mean axon diameters in human corpus callosum, and the total scan time was only about 8 min. In conclusion, DDR perpendicular to may have potential to serve as a fast, simple and model-free approach to map the mean axon diameter of white matter in clinics for assessing axon diameter changes. Copyright (c) 2016 John Wiley & Sons, Ltd.
RI Jovicich, Jorge/D-2293-2010; Xu, Junzhong/E-6731-2010
OI jiang, xiaoyu/0000-0002-0369-6301; Xu, Junzhong/0000-0001-7895-4232;
   Dortch, Richard/0000-0002-9978-2203
SN 0952-3480
EI 1099-1492
PD APR
PY 2016
VL 29
IS 4
BP 400
EP 410
DI 10.1002/nbm.3484
UT WOS:000373388800004
PM 27077155
ER

PT J
AU Oliver, CR
   Westrick, W
   Koehler, J
   Brieland-Shoultz, A
   Anagnostopoulos-Politis, I
   Cruz-Gonzalez, T
   Hart, AJ
AF Oliver, C. Ryan
   Westrick, William
   Koehler, Jeremy
   Brieland-Shoultz, Anna
   Anagnostopoulos-Politis, Ilias
   Cruz-Gonzalez, Tizoc
   Hart, A. John
TI Robofurnace: A semi-automated laboratory chemical vapor deposition
   system for high-throughput nanomaterial synthesis and process discovery
SO REVIEW OF SCIENTIFIC INSTRUMENTS
AB Laboratory research and development on new materials, such as nanostructured thin films, often utilizes manual equipment such as tube furnaces due to its relatively low cost and ease of setup. However, these systems can be prone to inconsistent outcomes due to variations in standard operating procedures and limitations in performance such as heating and cooling rates restrict the parameter space that can be explored. Perhaps more importantly, maximization of research throughput and the successful and efficient translation of materials processing knowledge to production-scale systems, relies on the attainment of consistent outcomes. In response to this need, we present a semi-automated lab-scale chemical vapor deposition (CVD) furnace system, called "Robofurnace." Robofurnace is an automated CVD system built around a standard tube furnace, which automates sample insertion and removal and uses motion of the furnace to achieve rapid heating and cooling. The system has a 10-sample magazine and motorized transfer arm, which isolates the samples from the lab atmosphere and enables highly repeatable placement of the sample within the tube. The system is designed to enable continuous operation of the CVD reactor, with asynchronous loading/unloading of samples. To demonstrate its performance, Robofurnace is used to develop a rapid CVD recipe for carbon nanotube (CNT) forest growth, achieving a 10-fold improvement in CNT forest mass density compared to a benchmark recipe using a manual tube furnace. In the long run, multiple systems like Robofurnace may be linked to share data among laboratories by methods such as Twitter. Our hope is Robofurnace and like automation will enable machine learning to optimize and discover relationships in complex material synthesis processes. (c) 2013 AIP Publishing LLC.
RI Hart, A. John/A-9027-2010
OI Hart, A. John/0000-0002-7372-3512
SN 0034-6748
EI 1089-7623
PD NOV
PY 2013
VL 84
IS 11
AR 115105
DI 10.1063/1.4826275
UT WOS:000329982000057
PM 24289435
ER

PT J
AU Bernabei, JM
   Li, A
   Revell, AY
   Smith, RJ
   Gunnarsdottir, KM
   Ong, IZ
   Davis, KA
   Sinha, N
   Sarma, S
   Litt, B
AF Bernabei, John M.
   Li, Adam
   Revell, Andrew Y.
   Smith, Rachel J.
   Gunnarsdottir, Kristin M.
   Ong, Ian Z.
   Davis, Kathryn A.
   Sinha, Nishant
   Sarma, Sridevi
   Litt, Brian
TI Quantitative approaches to guide epilepsy surgery from intracranial EEG
SO BRAIN
AB Over the past 10 years, the drive to improve outcomes from epilepsy surgery has stimulated widespread interest in methods to quantitatively guide epilepsy surgery from intracranial EEG (iEEG). Many patients fail to achieve seizure freedom, in part due to the challenges in subjective iEEG interpretation. To address this clinical need, quantitative iEEG analytics have been developed using a variety of approaches, spanning studies of seizures, interictal periods, and their transitions, and encompass a range of techniques including electrographic signal analysis, dynamical systems modeling, machine learning and graph theory. Unfortunately, many methods fail to generalize to new data and are sensitive to differences in pathology and electrode placement. Here, we critically review selected literature on computational methods of identifying the epileptogenic zone from iEEG. We highlight shared methodological challenges common to many studies in this field and propose ways that they can be addressed. One fundamental common pitfall is a lack of open-source, high-quality data, which we specifically address by sharing a centralized high-quality, well-annotated, multicentre dataset consisting of >100 patients to support larger and more rigorous studies. Ultimately, we provide a road map to help these tools reach clinical trials and hope to improve the lives of future patients.
   Bernabei et al. provide an update on quantitative methods for guiding epilepsy surgery using intracranial EEG. They identify challenges which have prevented successful clinical translation of these methods, and offer potential solutions, including the release of a new dataset with more than 100 patients to support larger and more rigorous studies.
OI Sinha, Nishant/0000-0002-2090-4889; Bernabei, John/0000-0002-3012-1263;
   Silva, Alexander/0000-0003-0838-4136; Smith, Rachel/0000-0001-7142-0684;
   Ong, Ian/0000-0002-9032-9154; Gunnarsdottir,
   Kristin/0000-0002-9278-3844; Li, Adam/0000-0001-8421-365X
SN 0006-8950
EI 1460-2156
DI 10.1093/brain/awad007
EA JAN 2023
UT WOS:000949808800001
PM 36623936
ER

PT J
AU Tam, NT
   Trung, HT
   Yin, HZ
   Vinh, TV
   Sakong, D
   Zheng, BL
   Hung, NQV
AF Nguyen Thanh Tam
   Huynh Thanh Trung
   Yin, Hongzhi
   Tong Van Vinh
   Sakong, Darnbi
   Zheng, Bolong
   Nguyen Quoc Viet Hung
TI Entity Alignment for Knowledge Graphs With Multi-Order Convolutional
   Networks
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
AB Knowledge graphs (KGs) have become popular structures for unifying real-world entities by modelling the relationships between them and their attributes. To support multilingual applications, a significant number of language-specific KGs have been built by different parties using various data sources. As a result, these monolingual KGs are often disconnected, causing semantic heterogeneity and detracting from the original purpose of KGs. Entity alignment - the task of identifying corresponding entities across different KGs - has attracted a great deal of attention in both academia and industry. However, existing alignment techniques often require large amounts of labelled data, are unable to encode multi-modal data simultaneously, and enforce only a few consistency constraints. In this paper, we propose an end-to-end, unsupervised entity alignment framework for cross-lingual KGs that fuses different types of information in order to fully exploit the richness of KG data. The model captures the relation-based correlation between entities by using a multi-order graph convolutional neural (GCN) model that is designed to satisfy the consistency constraints, while incorporating the attribute-based correlation via a translation machine. We adopt a late-fusion mechanism to combine all the information together, which allows these approaches to complement each other and thus enhances the final alignment result, and makes the model more robust to consistency violations. Empirical results for various scenarios on real-world and synthetic KGs show that our model is up to 22.71 percent more accurate and orders of magnitude faster than existing baselines. We also demonstrate its sensitivity to hyper-parameters, effort saving in terms of labelling, and the robustness against adversarial conditions.
RI 비, 단/HDO-7846-2022; Sakong, Darnbi/HDO-7892-2022
OI Nguyen, Thanh Tam/0000-0002-2586-7757; Tong, Vinh/0000-0003-1756-4251;
   Huynh, Thanh Trung/0000-0003-2027-5362; Nguyen, Quoc Viet
   Hung/0000-0002-9687-1315; Sakong, Darnbi/0000-0002-1827-2421
SN 1041-4347
EI 1558-2191
PD SEPT 1
PY 2022
VL 34
IS 9
BP 4201
EP 4214
DI 10.1109/TKDE.2020.3038654
UT WOS:000836626800012
ER

PT J
AU Grasso, V
   Willumeit-Roemer, R
   Jose, J
AF Grasso, Valeria
   Willumeit-Roemer, Regine
   Jose, Jithin
TI Superpixel spectral unmixing framework for the volumetric assessment of
   tissue chromophores: A photoacoustic data-driven approach
SO PHOTOACOUSTICS
AB The assessment of tissue chromophores at a volumetric scale is vital for an improved diagnosis and treatment of a large number of diseases. Spectral photoacoustic imaging (sPAI) co-registered with high-resolution ultrasound (US) is an innovative technology that has a great potential for clinical translation as it can assess the volumetric distribution of the tissue components. Conventionally, to detect and separate the chromophores from sPAI, an input of the expected tissue absorption spectra is required. However, in pathological conditions, the prediction of the absorption spectra is difficult as it can change with respect to the physiological state. Besides, this conventional approach can also be hampered due to spectral coloring, which is a prominent distortion effect that induces spectral changes at depth. Here, we are proposing a novel data-driven framework that can overcome all these limitations and provide an improved assessment of the tissue chromophores. We have developed a superpixel spectral unmixing (SPAX) approach that can detect the most and less prominent absorber spectra and their volumetric distribution without any user interactions. Within the SPAX framework, we have also implemented an advanced spectral coloring compensation approach by utilizing US image segmentation and Monte Carlo simulations, based on a predefined library of optical properties. The framework has been tested on tissue mimicking phantoms and also on healthy animals. The obtained results show enhanced specificity and sensitivity for the detection of tissue chromophores. To our knowledge, this is a unique framework that accounts for the spectral coloring and provides automated detection of tissue spectral signatures at a volumetric scale, which can open many possibilities for translational research.
OI Grasso, Valeria/0000-0001-6912-5053
SN 2213-5979
PD JUN
PY 2022
VL 26
AR 100367
DI 10.1016/j.pacs.2022.100367
EA MAY 2022
UT WOS:000806796900001
PM 35601933
ER

PT J
AU Ji, M
   Bodomo, A
   Xie, WX
   Huang, RL
AF Ji, Meng
   Bodomo, Adams
   Xie, Wenxiu
   Huang, Riliu
TI Assessing Communicative Effectiveness of Public Health Information in
   Chinese: Developing Automatic Decision Aids for International Health
   Professionals
SO INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH
AB Effective multilingual communication of authoritative health information plays an important role in helping to reduce health disparities and inequalities in developed and developing countries. Health information communication from the World Health Organization is governed by key principles including health information relevance, credibility, understandability, actionability, accessibility. Multilingual health information developed under these principles provide valuable benchmarks to assess the quality of health resources developed by local health authorities. In this paper, we developed machine learning classifiers for health professionals with or without Chinese proficiency to assess public-oriented health information in Chinese based on the definition of effective health communication by the WHO. We compared our optimized classifier (SVM_F5) with the state-of-art Chinese readability classifier (Chinese Readability Index Explorer CRIE 3.0), and classifiers adapted from established English readability formula, Gunning Fog Index, Automated Readability Index. Our optimized classifier achieved statistically significant higher area under the receiver operator curve (AUC of ROC), accuracy, sensitivity, and specificity than those of SVM using CRIE 3.0 features and SVM using linguistic features of Gunning Fog Index and Automated Readability Index (ARI). The statistically improved performance of our optimized classifier compared to that of SVM classifiers adapted from popular readability formula suggests that evaluation of health communication effectiveness as defined by the principles of the WHO is more complex than information readability assessment. Our SVM classifier validated on health information covering diverse topics (environmental health, infectious diseases, pregnancy, maternity care, non-communicable diseases, tobacco control) can aid effectively in the automatic assessment of original, translated Chinese public health information of whether they satisfy or not the current international standard of effective health communication as set by the WHO.
RI ; Bodomo, Adams/A-8403-2010
OI Xie, Wenxiu/0000-0002-8528-5193; Bodomo, Adams/0000-0002-3807-3681; Ji,
   Meng/0000-0002-7463-9208
EI 1660-4601
PD OCT
PY 2021
VL 18
IS 19
AR 10329
DI 10.3390/ijerph181910329
UT WOS:000709633800001
PM 34639643
ER

PT J
AU Aoyagi, S
   Fujiwara, Y
   Takano, A
   Vorng, JL
   Gilmore, IS
   Wang, YC
   Tallarek, E
   Hagenhoff, B
   Iida, SI
   Luch, A
   Jungnickel, H
   Lang, YS
   Shon, HK
   Lee, TG
   Li, ZP
   Matsuda, K
   Mihara, I
   Miisho, A
   Murayama, Y
   Nagatomi, T
   Ikeda, R
   Okamoto, M
   Saiga, K
   Tsuchiya, T
   Uemura, S
AF Aoyagi, Satoka
   Fujiwara, Yukio
   Takano, Akio
   Vorng, Jean-Luc
   Gilmore, Ian S.
   Wang, Yung-Chen
   Tallarek, Elke
   Hagenhoff, Birgit
   Iida, Shin-Ichi
   Luch, Andreas
   Jungnickel, Harald
   Lang, Yusheng
   Shon, Hyun Kyong
   Lee, Tae Geol
   Li, Zhanping
   Matsuda, Kazuhiro
   Mihara, Ichiro
   Miisho, Ako
   Murayama, Yohei
   Nagatomi, Takaharu
   Ikeda, Reiko
   Okamoto, Masayuki
   Saiga, Kunio
   Tsuchiya, Toshihiko
   Uemura, Shigeaki
TI Evaluation of Time-of-Flight Secondary Ion Mass Spectrometry Spectra of
   Peptides by Random Forest with Amino Acid Labels: Results from a
   Versailles Project on Advanced Materials and Standards Interlaboratory
   Study
SO ANALYTICAL CHEMISTRY
AB We report the results of a VAMAS (Versailles Project on Advanced Materials and Standards) interlaboratory study on the identification of peptide sample TOF-SIMS spectra by machine learning. More than 1000 time-of-flight secondary ion mass spectrometry (TOF-SIMS) spectra of six peptide model samples (one of them was a test sample) were collected using 27 TOF-SIMS instruments from 25 institutes of six countries, the U. S., the U. K., Germany, China, South Korea, and Japan. Because peptides have systematic and simple chemical structures, they were selected as model samples. The intensity of peaks in every TOF-SIMS spectrum was extracted using the same peak list and normalized to the total ion count. The spectra of the test peptide sample were predicted by Random Forest with 20 amino acid labels. The accuracy of the prediction for the test spectra was 0.88. Although the prediction of an unknown peptide was not perfect, it was shown that all of the amino acids in an unknown peptide can be determined by Random Forest prediction and the TOF-SIMS spectra. Moreover, the prediction of peptides, which are included in the training spectra, was almost perfect. Random Forest also suggests specific fragment ions from an amino acid residue Q, whose fragment ions detected by TOF-SIMS have not been reported, in the important features. This study indicated that the analysis using Random Forest, which enables translation of the mathematical relationships to chemical relationships, and the multi labels representing monomer chemical structures, is useful to predict the TOFSIMS spectra of an unknown peptide.
OI Hagenhoff, Birgit/0000-0002-8380-2257; Matsuda,
   Kazuhiro/0000-0001-5901-6937
SN 0003-2700
EI 1520-6882
PD MAR 9
PY 2021
VL 93
IS 9
BP 4191
EP 4197
DI 10.1021/acs.analchem.0c04577
EA FEB 2021
UT WOS:000627639900008
PM 33635050
ER

PT J
AU Jaiswal, S
   Birelliwar, A
   Chitale, N
   Phansopkar, P
AF Jaiswal, Simran
   Birelliwar, Aachal
   Chitale, Neha
   Phansopkar, Pratik
TI A Report of Physiotherapy Rehabilitation in A Case of Post-Surgical
   Anterior Cruciate Ligament Reconstruction
SO BIOSCIENCE BIOTECHNOLOGY RESEARCH COMMUNICATIONS
AB Anterior Cruciate ligament (ACL) is the most common ligament to get damaged in the knee joint. Knee joint being a dynamic structure requires lot of stabilizing factors to maintain dynamic stability of the joint. ACLhelps to maintain dynamic stability of the knee joint by preventing anterior translation of tibia.ACL and PCLserve as primary rotatory stabilizers for knee joint. This case study reflects on the treatment of a case of ACL reconstruction of the left knee. A 50 years old male who met an accident reported with anterior cruciate ligament tear. Patient had reported with swelling over knee region and he had been treated surgically for anterior cruciate ligament reconstruction. The patient was mesomorphic in nature. Physical therapy rehabilitation protocol mainly focused on strengthening of quadriceps and hamstrings muscle and accordingly provided care in ways including postoperative weight bearing, gait training, improving strength of quadriceps and hamstring muscles. Anterior Cruciate Ligament Tear following accidental trauma. Therapeutic Intervention and Post-operative knee brace was given to the patient after surgery which was locked in slight hyperextension. The patient was made aware of the need to wear the brace even while sleeping. CPM machine was used daily for 3 hours per day. Outpatient physiotherapy was started on post-operative day 10. Basic exercises such as active and passive ROM, strengthening exercise for quadriceps, straight leg raising with brace. After 7th week there was complete recovery in passive range of motion of the knee joint. Early postoperative recovery is ensured withtimely initiation of physiotherapy and the motivation to continue with the physiotherapy.
RI Chitale, Neha/ABF-4242-2021; Phansopkar, Pratik/AAX-5884-2020
OI Phansopkar, Pratik/0000-0003-3635-8840; Chitale,
   Neha/0000-0003-1586-0612
SN 0974-6455
PY 2021
VL 14
IS 6
SI SI
BP 116
EP 119
DI 10.21786/bbrc/14.6.27
UT WOS:000697827700027
ER

PT S
AU Rabbani, N
   Thornalley, PJ
AF Rabbani, Naila
   Thornalley, Paul J.
BE Hooper, N
TI Reading patterns of proteome damage by glycation, oxidation and
   nitration: quantitation by stable isotopic dilution analysis LC-MS/MS
SO PROTEIN OXIDATION
SE Essays in Biochemistry
AB Liquid chromatography-tandem mass spectrometry (LC-MS/MS) provides a high sensitivity, high specificity multiplexed method for concurrent detection of adducts formed by protein glycation, oxidation and nitration, also called AGEomics. Combined with stable isotopic dilution analysis, it provides for robust quantitation of protein glycation, oxidation and nitration adduct analytes. It is the reference method for such measurements. LC-MS/MS has been used to measure glycated, oxidized and nitrated amino acids - also called glycation, oxidation and nitration free adducts, with a concurrent quantitation of the amino acid metabolome in physiological fluids. Similar adduct residues in proteins may be quantitated with prior exhaustive enzymatic hydrolysis. It has also been applied to quantitation of other post-translation modifications, such as citrullination and formation of N-2-(gamma-glutamyl)lysine crosslink by transglutaminases. Application to cellular and extracellular proteins gives estimates of the steady-state levels of protein modification by glycation, oxidation and nitration, and measurement of the accumulation of glycation, oxidation and nitration adducts in cell culture medium and urinary excretion gives an indication of flux of adduct formation. Measurement of glycation, oxidation and nitration free adducts in plasma and urine provides for estimates of renal clearance of free adducts. Diagnostic potential in clinical studies has been enhanced by the combination of estimates of multiple adducts in optimized diagnostic algorithms by machine learning. Recent applications have been in early-stage detection of metabolic, vascular and renal disease, and arthritis, metabolic control and risk of developing vascular complication in diabetes, and a blood test for autism.
OI Rabbani, Naila/0000-0002-5819-2506; Thornalley, Paul/0000-0001-7659-443X
SN 0071-1365
EI 1744-1358
PY 2020
VL 64
IS 1
BP 169
EP 183
DI 10.1042/EBC20190047
UT WOS:000537063700013
PM 32065835
ER

PT J
AU Anterrieu, O
   Giroux, B
   Gloaguen, E
   Carde, C
AF Anterrieu, Olivier
   Giroux, Bernard
   Gloaguen, Erwan
   Carde, Christophe
TI Non-destructive data assimilation as a tool to diagnose corrosion rate
   in reinforced concrete structures
SO JOURNAL OF BUILDING ENGINEERING
AB Reinforcement corrosion is a major problem in the long-term management of reinforced concrete structures. With sustainability in perspective, knowledge of the corrosion rate (V-cor) makes it possible to estimate the kinetics of the corrosion phenomenon and helps in refining the maintenance strategy of such structures. Although in situ V-cor measurements are possible, data acquisition is time-consuming because of the protocol intrinsic to its measurement (reinforcement polarization made point by point). Therefore, in the context of site diagnostics, these methods cannot reasonably be used systematically on site and must be combined with high performance non-destructive testing (NDT) surface methods (GPR, capacimetry, half-cell corrosion). In addition, depending on the case, V-cor (point measurements) and NDT (surface) data are statistically related. However, there is a lack of efficient data assimilation tools permitting accurate translation of NDT data into pseudo V-cor data. In this paper, we present a numerical tool allowing prediction of V-cor values from NDT measurements. The tool permits application of different data assimilation techniques, i.e., cokriging, Bayesian sequential simulation, and a decision tree-driven learning depending on statistical behavior and available data. The efficiency of our numerical tool has been tested on a dataset acquired on a structure located in the French Alps. Results show that, for the case study, our data assimilation tool allows prediction of V-cor with accuracy compared to in situ measurements and also permits one to infer the uncertainty of the prediction. This opens the door for quantitative use of multiple NDT in the management of reinforced concrete structures.
RI Moraes, Edison/C-2443-2015; Giroux, Bernard/AAG-1069-2019
OI Giroux, Bernard/0000-0002-2042-2759
SN 2352-7102
PD MAY
PY 2019
VL 23
BP 193
EP 206
DI 10.1016/j.jobe.2019.01.033
UT WOS:000461445700017
ER

PT J
AU Alquliti, WH
   Ghani, NBA
AF Alquliti, Wajdi Homaid
   Ghani, Norjihan Binti Abdul
TI Convolutional Neural Network based for Automatic Text Summarization
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
AB In recent times, the apps for the processing of a natural language has been formed and generated through the use of intelligent and soft computing methods that allow computer systems to practically mimic practices related to the process of human texts like the detection of plagiarism, determination of the pattern as well as machine translation, Thereafter, Text summarization serves as the procedure of abridging writing within consolidated structures. 'Automatic text summarization' or the ATS is when a computer system is used to create a text summarization. In this study, the researchers have introduced a novel ATS system, i.e., CNN-ATS, which is a convolutional neural network that enables to Automatic text summarization using a text matrix representation. CNN-ATS is a deep learning system that was used to evaluate the improvements resulting from the increase in the depth to determine the better CNN configurations, assess the sentences, and determine the most informative one. Sentences deemed important are extracted for document summarization. The researchers have investigated this novel convolutional network depth for determining its accuracy during the informative sentences selection for each input text document. The experiment findings of the proposed method are based on the Convolutional Neural Network that uses 26 different configurations. It demonstrates that the resulting summaries have the potential to be better compared to other summaries. DUC 2002 served as the data warehouse. Some of the news articles were used as input in this experiment. Through this method, a new matrix representation was utilized for every sentence. The system summaries were examined by using the ROUGE tool kit at 95% confidence intervals, in which results were extracted by employing average recall, F-measure and precision from ROUGE-1, 2, and L.
RI GHANI, NORJIHAN ABDUL/B-9381-2010
OI GHANI, NORJIHAN ABDUL/0000-0002-0804-3916
SN 2158-107X
EI 2156-5570
PD APR
PY 2019
VL 10
IS 4
BP 200
EP 211
UT WOS:000467916400025
ER

PT C
AU Silfa, F
   Dot, G
   Arnau, JM
   Gonzalez, A
AF Silfa, Franyell
   Dot, Gem
   Arnau, Jose-Maria
   Gonzalez, Antonio
GP Assoc Comp Machinery
TI Neuron-Level Fuzzy Memoization in RNNs
SO MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON
   MICROARCHITECTURE
CT 52nd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 12-16, 2019
CL Columbus, OH
SP IEEE, Assoc Comp Machinery, IEEE TCuARCH, Assoc Comp Machinery SIGMICRO, Huawei, Microsoft, AMD, arm, IBM, Intel, Samsung
AB Recurrent Neural Networks (RNNs) are a key technology for applications such as automatic speech recognition or machine translation. Unlike conventional feed-forward DNNs, RNNs remember past information to improve the accuracy of future predictions and, therefore, they are very effective for sequence processing problems.
   For each application run, each recurrent layer is executed many times for processing a potentially large sequence of inputs (words, images, audio frames, etc.). In this paper, we make the observation that the output of a neuron exhibits small changes in consecutive invocations. We exploit this property to build a neuron-level fuzzy memoization scheme, which dynamically caches the output of each neuron and reuses it whenever it is predicted that the current output will be similar to a previously computed result, avoiding in this way the output computations.
   The main challenge in this scheme is determining whether the new neuron's output for the current input in the sequence will be similar to a recently computed result. To this end, we extend the recurrent layer with a much simpler Bitwise Neural Network (BNN), and show that the BNN and RNN outputs are highly correlated: if two BNN outputs are very similar, the corresponding outputs in the original RNN layer are likely to exhibit negligible changes. The BNN provides a low-cost and effective mechanism for deciding when fuzzy memoization can be applied with a small impact on accuracy.
   We evaluate our memoization scheme on top of a state-of-the-art accelerator for RNNs, for a variety of different neural networks from multiple application domains. We show that our technique avoids more than 24.2% of computations, resulting in 18.5% energy savings and 1.35x speedup on average.
BN 978-1-4503-6938-1
PY 2019
BP 782
EP 793
DI 10.1145/3352460.3358309
UT WOS:000519057400058
ER

PT J
AU Hui, XJ
   Hu, YM
   Sun, MA
   Shu, XS
   Han, RF
   Ge, QG
   Wang, YJ
AF Hui, Xinjie
   Hu, Yueming
   Sun, Ming-An
   Shu, Xingsheng
   Han, Rongfei
   Ge, Qinggang
   Wang, Yejun
TI EBT: a statistic test identifying moderate size of significant features
   with balanced power and precision for genome-wide rate comparisons
SO BIOINFORMATICS
AB Motivation: In genome-wide rate comparison studies, there is a big challenge for effective identification of an appropriate number of significant features objectively, since traditional statistical comparisons without multi-testing correction can generate a large number of false positives while multi-testing correction tremendously decreases the statistic power.
   Results: In this study, we proposed a new exact test based on the translation of rate comparison to two binomial distributions. With modeling and real datasets, the exact binomial test (EBT) showed an advantage in balancing the statistical precision and power, by providing an appropriate size of significant features for further studies. Both correlation analysis and bootstrapping tests demonstrated that EBT is as robust as the typical rate-comparison methods, e.g. chi(2) test, Fisher's exact test and Binomial test. Performance comparison among machine learning models with features identified by different statistical tests further demonstrated the advantage of EBT. The new test was also applied to analyze the genome-wide somatic gene mutation rate difference between lung adenocarcinoma (LUAD) and lung squamous cell carcinoma (LUSC), two main lung cancer subtypes and a list of new markers were identified that could be lineage-specifically associated with carcinogenesis of LUAD and LUSC, respectively. Interestingly, three cilia genes were found selectively with high mutation rates in LUSC, possibly implying the importance of cilia dysfunction in the carcinogenesis.
   Availability and implementation: An R package implementing EBT could be downloaded from the website freely: http://www.szu-bioinf.org/EBT.
   Contact: wangyj@szu.edu.cn
   Supplementary information: Supplementary data are available at Bioinformatics online.
RI Sun, Mingan/D-7141-2019; Ge, Qing/HJG-9192-2022
OI Sun, Mingan/0000-0002-4661-3027; Hu, Yueming/0000-0003-2174-5987
SN 1367-4803
EI 1460-2059
PD SEP 1
PY 2017
VL 33
IS 17
BP 2631
EP 2641
DI 10.1093/bioinformatics/btx294
UT WOS:000408772700004
PM 28472273
ER

PT J
AU Kristol, DM
   Lee, D
   Netravali, AN
   Sabnani, K
AF Kristol, David M.
   Lee, David
   Netravali, Arun N.
   Sabnani, Krishan
TI A Polynomial Algorithm for Gateway Generation from Formal Specifications
SO IEEE-ACM TRANSACTIONS ON NETWORKING
AB Heterogeneity is a fact of life in computer networks. Increasing attention is being given to provide "global" connectivity by building gateways to accommodate heterogeneous elements in a network. One of the key problems in synthesizing gateways is protocol conversion. Protocol converters "translate" messages from one set of protocols to another so as to overcome mismatches in the interconnection. Despite the importance of this problem, most protocol converters have been built in an ad hoc manner.
   We present a systematic procedure to synthesize protocol converters from formal specifications. Compared to the other procedures reported in the literature, which take exponential time, our procedure takes only polynomial time in the size of protocols. Our algorithm proceeds in two steps: a) compute the largest common subset of services provided by the two mismatched protocols; and b) reduce the converter, retaining common services, without traversing the entire machine that represents the composition of the two mismatched protocols. In a number of cases, the converter can be constructed by a "memoryless" translation of messages from one protocol to another. We give conditions under which such stateless conversion is possible.
   We present two examples to illustrate our techniques. In the first example, we compute a converter that interconnects a half-duplex protocol with a full-duplex protocol from their formal specifications. A trivially constructed protocol converter for these protocols has 33 936 states, while the number of states in the converter generated by our procedure is only 336. Our second example, illustrates the polynomial procedure applied to computation of a converter for interconnecting the SNR and TCP protocols. A brute force computation would be exponential and therefore infeasible, whereas our algorithm computes the converter in about 10 seconds on a Sun SparcStation 1+.
SN 1063-6692
EI 1558-2566
PD APR
PY 1993
VL 1
IS 2
BP 217
EP 229
DI 10.1109/90.222928
UT WOS:000208155200006
ER

PT J
AU Chen, HW
   Jing, XY
   Zhou, YM
   Li, B
   Xu, BW
AF Chen, Haowen
   Jing, Xiao-Yuan
   Zhou, Yuming
   Li, Bing
   Xu, Baowen
TI Aligned metric representation based balanced multiset ensemble learning
   for heterogeneous defect prediction
SO INFORMATION AND SOFTWARE TECHNOLOGY
AB Context: Heterogeneous defect prediction (HDP) refers to the defect prediction across projects with different metrics. Most existing HDP methods map source and target data into a common metric space where each dimension has no actual meaning, which weakens their interpretability. Besides, HDP always suffers from the class imbalance problem.
   Objective: For deficiencies of current HDP methods, we intend to propose a novel HDP approach that can reduce the heterogeneity of source and target data and deal with imbalanced data while retaining the actual meaning for each dimension of constructed common metric space.
   Method: We propose an Aligned Metric Representation based Balanced Multiset Ensemble learning (BMEL+ AMR) approach for HDP. AMR consists of shared, source-specific, and target-specific metrics. It is built by learning the translation from shared to specific metrics and reducing the distribution difference. To deal with imbalanced data, we design BMEL that constructs multiple balanced subsets for source data and produces an aggregated classifier for predicting labels of target data.
   Result: Experimental results on 22 public projects indicate that (1) among all competing methods, BMEL+AMR achieves the best performance on all indicators except Popt, followed by AMR; (2) compared with AMR, the introduction of BMEL improves the performance on non-effort-aware indicators statistically significantly except F1-score; compared with BMEL, the introduction of AMR improves the performance throughout all indicators statistically significantly.
   Conclusion: BMEL+AMR can effectively improve HDP performance by eliminating heterogeneity and dealing with imbalanced data, and AMR is helpful to explain the prediction model.
RI li, bing/GWQ-9617-2022
SN 0950-5849
EI 1873-6025
PD JUL
PY 2022
VL 147
AR 106892
DI 10.1016/j.infsof.2022.106892
EA MAR 2022
UT WOS:000852891700007
ER

PT C
AU Brkljac, B
   Antic, B
   Mitrovic, Z
AF Brkljac, Branko
   Antic, Boris
   Mitrovic, Zoran
GP IEEE
TI Potential of embedded vision platforms in development of spatial AI
   enabled CPS
SO 2022 11TH MEDITERRANEAN CONFERENCE ON EMBEDDED COMPUTING (MECO)
SE Mediterranean Conference on Embedded Computing
CT 11th Mediterranean Conference on Embedded Computing (MECO) / 3rd Summer
   School on Cyber-Physical + Systems and Internet of Things (CPS and IoT)
CY JUN 07-10, 2022
CL Budva, MONTENEGRO
SP EUROMICRO, MANT, MECOnet, Univ Montenegro, Eindhoven Tech Univ, Univ Zagreb, Univ Belgrade, Ind Syst Inst, Minist Montenegro, Cikom, Elkon, SMART4ALL
AB Motivated by the recent trends in the field of embedded vision platforms, we discuss potential of such solutions in providing foundations for the next generation of Cyber-Physical Systems (CPS). Improved capabilities and reduced price of these platforms will have profound effect on their everyday usage and applications. In comparison to speech and natural language processing, which have established speech recognition and machine translation applications as indispensable in many contemporary CPSs, the vision community is still searching for an application that would be so necessary and desirable to make most of the consumers buy specific vision hardware just to run it. That would be the ultimate proof of the core value of the technology in the market. Thus, also vision problems come with a longstanding tradition and history of numerous solutions, it is still hard to point out a single application that would incorporate many specific vision tasks into one device, and which would be ubiquitously useful and affordable to all (e.g. like smartphone has done in the fields of communication and personal computing). However, with development of new miniaturization technologies and spatial AI it is reasonable to expect that there will be more possibilities for designing CPS with capabilities of visual understanding of outdoor, dynamic and uncontrolled environments. One step in such direction are embedded vision platforms that besides powerful computing capabilities also provide multimodal perception, and thus improve the algorithm performance. As an example, we will discuss stereo depth perception in the context of new spatial AI platforms like OAK-D lite, and point out some possibilities for its improvement and integration into future CPS.
SN 2377-5475
BN 978-1-6654-6828-2
PY 2022
BP 84
EP 87
DI 10.1109/MECO55406.2022.9797078
UT WOS:000855969800019
ER

PT J
AU Totaro, S
   Hussain, A
   Scardapane, S
AF Totaro, Simone
   Hussain, Amir
   Scardapane, Simone
TI A non-parametric softmax for improving neural attention in time-series
   forecasting
SO NEUROCOMPUTING
AB Neural attention has become a key component in many deep learning applications, ranging from machine translation to time series forecasting. While many variations of attention have been developed over recent years, all share a common component in the application of a softmax function to normalize the attention weights, in order to transform them into valid mixing coefficients. In this paper, we aim to improve the modeling flexibility of a generic attention module by innovatively replacing this softmax operation with a learnable softmax, in which the normalizing functions are also adapted from the data. Specifically, our generalized softmax builds upon recent work in learning activation functions for deep networks, in particular the kernel activation function and its extensions. We describe the application of the proposed technique for the challenging case of time series forecasting with the dual-stage attention-based recurrent neural network (DA-RNN), an innovative model for predicting time series that employs two different attention modules for handling exogenous factors and long-term dependencies. A series of real-world benchmarks are used to show that simply plugging-in our generalized attention model can improve results on all datasets, even when keeping the number of trainable parameters in the model constant. To further evaluate the algorithm, we collect a novel dataset for predicting the Bitcoin closing exchange rate, a problem of high practical significance lately. Finally, to foster research in the topic, we also release both the dataset and our model as an open source extensible library. Over a baseline DA-RNN, our proposed model delivers an improvement of MAR ranging from 6% to 15% using our newly-released dataset. (C) 2019 Elsevier B.V. All rights reserved.
RI Hussain, Amir/AAG-6299-2020; Scardapane, Simone/AAA-2267-2020
OI Hussain, Amir/0000-0002-8080-082X; Scardapane,
   Simone/0000-0003-0881-8344
SN 0925-2312
EI 1872-8286
PD MAR 14
PY 2020
VL 381
BP 177
EP 185
DI 10.1016/j.neucom.2019.10.084
UT WOS:000509741100015
ER

PT C
AU Higaki, S
   Nishida, H
   Koike, Y
   Sasada, M
   Tanaka, T
AF Higaki, Satoshi
   Nishida, Hibiki
   Koike, Yuta
   Sasada, Masahiro
   Tanaka, Tatsuya
BE Szeliga, D
   Muszka, K
TI Effect of transverse ribs on axial displacement of rebars in bending
SO 18TH INTERNATIONAL CONFERENCE ON METAL FORMING 2020
SE Procedia Manufacturing
CT 18th International Conference on Metal Forming
CY SEP 13-16, 2020
CL Krakow, POLAND
SP AGH Univ Sci & Technol, Univ Palermo, Toyohashi Univ Technol, Yokohama Natl Univ, Minist Sci & Higher Educ
AB The strength of buildings is increased by using rebars; these are curved bars obtained with a bending machine and are primarily used with concrete. It is a known issue that a rebar tends to be displaced during bending so that it is no longer touches the fulcrum roller due to deformation and translation inherent to the process. Therefore, the processing conditions are determined based on the shapes of test products and experience of technicians. A reduction in the displacement of the rebar is desired to improve the dimensional accuracy of products. The ultimate aim of this study is to better understand the effect of bending on the axial displacement of rebars. Because deformation of the rebar may occur in one or more directions, many displacement sensors are required to determine the details of the deformation. In this study, the deformation of rebars during bending was photographed with a high-speed camera, and the displacement of the rebars was determined using image analysis based on the captured moving images. A small increase in the axial displacement due to bending was observed in the first half of round bar processing. In contrast, the displacement increased significantly in the second half of processing. It was found that the amount of axial displacement increases with the rotation angle of the circular roller during bending. The bending tendency of D22 rebars under the same conditions as D25 rebars showed different trends in axial displacement growth. In the case of D22 rebars, it was found that the displacement barely increased in the first half of processing but increased significantly in the second half of processing, as with the case of the round bars (phi 23). (C) 2020 The Authors. Published by Elsevier B.V.
SN 2351-9789
PY 2020
VL 50
BP 253
EP 256
DI 10.1016/j.promfg.2020.08.047
UT WOS:000865803400046
ER

PT J
AU Lee, D
   Min, C
   Eom, YI
AF Lee, Dongwoo
   Min, Changwoo
   Eom, Young Ik
TI Effective Flash-based SSD Caching for High Performance Home Cloud Server
SO IEEE TRANSACTIONS ON CONSUMER ELECTRONICS
AB In the home cloud environment, the storage performance of home cloud servers, which govern connected devices and provide resources with virtualization features, is critical to improve the end-user experience. To improve the storage performance of virtualized home cloud servers in a cost-effective manner, caching schemes using flash-based solid state drives (SSD) have been widely studied. Although previous studies successfully narrow the speed gap between memory and hard disk drives, they only focused on how to manage the cache space, but were less interested in how to use the cache space efficiently taking into account the characteristics of flash-based SSD. Moreover, SSD caching is used as a read-only cache due to two well-known limitations of SSD: slow write and limited lifespan. Since storage access in virtual machines is performed in a more complex and costly manner, the limitations of SSD affect more significantly the storage performance. This paper proposes a novel SSD caching scheme and virtual disk image format, named sequential virtual disk (SVD), for achieving high-performance home cloud environments. The proposed techniques are based on the workload characteristics, in which synchronous random writes dominate, while taking into consideration the characteristics of flash memory and storage stack of the virtualized systems. Unlike previous studies, SSD is used as a read-write cache in the proposed caching scheme to effectively mitigate the performance degradation of synchronous random writes. The prototype was evaluated with some realistic workloads, through which the developed scheme was shown to allow improvement of the storage access performance by 21% to 112%, with reduction in the number of erasures on SSD by about 56% on average.(1)
SN 0098-3063
EI 1558-4127
PD MAY
PY 2015
VL 61
IS 2
BP 215
EP 221
DI 10.1109/TCE.2015.7150596
UT WOS:000357803600011
ER

PT J
AU Fukasawa, Y
   Tsuji, J
   Fu, SC
   Tomii, K
   Horton, P
   Imai, K
AF Fukasawa, Yoshinori
   Tsuji, Junko
   Fu, Szu-Chin
   Tomii, Kentaro
   Horton, Paul
   Imai, Kenichiro
TI MitoFates: Improved Prediction of Mitochondrial Targeting Sequences and
   Their Cleavage Sites
SO MOLECULAR & CELLULAR PROTEOMICS
AB Mitochondria provide numerous essential functions for cells and their dysfunction leads to a variety of diseases. Thus, obtaining a complete mitochondrial proteome should be a crucial step toward understanding the roles of mitochondria. Many mitochondrial proteins have been identified experimentally but a complete list is not yet available. To fill this gap, methods to computationally predict mitochondrial proteins from amino acid sequence have been developed and are widely used, but unfortunately, their accuracy is far from perfect. Here we describe MitoFates, an improved prediction method for cleavable N-terminal mitochondrial targeting signals (presequences) and their cleavage sites. MitoFates introduces novel sequence features including positively charged amphiphilicity, presequence motifs, and position weight matrices modeling the presequence cleavage sites. These features are combined with classical ones such as amino acid composition and physico-chemical properties as input to a standard support vector machine classifier. On independent test data, MitoFates attains better performance than existing predictors in both detection of presequences and in predicting their cleavage sites. We used MitoFates to look for undiscovered mitochondrial proteins from 42,217 human proteins (including isoforms such as alternative splicing or translation initiation variants). MitoFates predicts 1167 genes to have at least one isoform with a presequence. Five-hundred and eighty of these genes were not annotated as mitochondrial in either UniProt or Gene Ontology. Interestingly, these include candidate regulators of parkin translocation to damaged mitochondria, and also many genes with known disease mutations, suggesting that careful investigation of MitoFates predictions may be helpful in elucidating the role of mitochondria in health and disease. MitoFates is open source with a convenient web server publicly available.
RI Tomii, Kentaro/B-1135-2017; Fukasawa, Yoshinori/A-5582-2017; Tomii,
   Kentaro/AAK-6940-2021; Fukasawa, Yoshinori/HKF-8479-2023; Imai,
   Kenichiro/A-5694-2017
OI Tomii, Kentaro/0000-0002-4567-4768; Fukasawa,
   Yoshinori/0000-0002-0882-4392; Tomii, Kentaro/0000-0002-4567-4768;
   Fukasawa, Yoshinori/0000-0002-0882-4392; Imai,
   Kenichiro/0000-0001-5664-0566; Tsuji, Junko/0000-0003-0139-3750
EI 1535-9484
PD APR
PY 2015
VL 14
IS 4
BP 1113
EP 1126
DI 10.1074/mcp.M114.043083
UT WOS:000352194400024
PM 25670805
ER

PT J
AU Nicolas-Alonso, LF
   Gomez-Gil, J
AF Fernando Nicolas-Alonso, Luis
   Gomez-Gil, Jaime
TI Brain Computer Interfaces, a Review
SO SENSORS
AB A brain-computer interface (BCI) is a hardware and software communications system that permits cerebral activity alone to control computers or external devices. The immediate goal of BCI research is to provide communications capabilities to severely disabled people who are totally paralyzed or 'locked in' by neurological neuromuscular disorders, such as amyotrophic lateral sclerosis, brain stem stroke, or spinal cord injury. Here, we review the state-of-the-art of BCIs, looking at the different steps that form a standard BCI: signal acquisition, preprocessing or signal enhancement, feature extraction, classification and the control interface. We discuss their advantages, drawbacks, and latest advances, and we survey the numerous technologies reported in the scientific literature to design each step of a BCI. First, the review examines the neuroimaging modalities used in the signal acquisition step, each of which monitors a different functional brain activity such as electrical, magnetic or metabolic activity. Second, the review discusses different electrophysiological control signals that determine user intentions, which can be detected in brain activity. Third, the review includes some techniques used in the signal enhancement step to deal with the artifacts in the control signals and improve the performance. Fourth, the review studies some mathematic algorithms used in the feature extraction and classification steps which translate the information in the control signals into commands that operate a computer or other device. Finally, the review provides an overview of various BCI applications that control a range of devices.
RI Gomez-Gil, Jaime/L-7620-2014
OI Gomez-Gil, Jaime/0000-0003-3333-0148
SN 1424-8220
PD FEB
PY 2012
VL 12
IS 2
BP 1211
EP 1279
DI 10.3390/s120201211
UT WOS:000300720300006
PM 22438708
ER

PT J
AU Kachhoria, R
   Jaiswal, S
   Khairnar, S
   Rajeswari, K
   Pede, S
   Kharat, R
   Galande, S
   Khadse, C
AF Kachhoria, Renu
   Jaiswal, Swati
   Khairnar, Smita
   Rajeswari, Kanan
   Pede, Shailaja
   Kharat, Reena
   Galande, Shailesh
   Khadse, Chetan
TI Lie group dee learning technique to identify the precision errors by map
   geometry functions in smart manufacturing
SO INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY
AB Numerous technical disciplines examine the information with a non-Euclidean dimension as its fundamental structural basis. This geometrical information is common in several industries, generally huge and complicated (in virtual groups, also on order to billions). Therefore, they are prime candidates for using artificial intelligence methods. We will employ deeper neuro systems since they are effective solutions for various issues in manufacturing industries, including accurate measurements, precision enabling, and predictive maintenance. Furthermore, the datasets having an inherent Euclidean but a rather grid-like pattern, as well as situations at which invariances of such patterns get integrated into systems employed for simulating those, demonstrate the greatest performance for these methods. The application of AI for smart manufacturing is evolving as algorithms are matured. Modern techniques often superficially discover advantageous Lie grouping characteristics before first representing every action series mostly as a high-dimensional path upon the Lie grouping, including an added crucial moment distortion that causes low accuracy. In this article, we acquire highly suitable Lie grouping characteristics that enable 3D motion identification by integrating the Lie grouping topology into a deeper networking design. We create rotational translating levels inside this networking topology that change the undesirable inputs of the manufacturing parameters with Lie grouping characteristics into those that seem closely correlated as in the timing realm. The group structure has rotating dumping levels for such components, upon which the Lie subgroup helps lower the excessive characteristic dimensions. Therefore, to effectively use normal output levels for such eventual categorization of precision errors, we also suggest a log translation level that transfers the generated multi-dimensional information into contour lines.
RI Rajeshwari, Kannan/AAG-7573-2019; Khairnar, Smita/ABD-4796-2021;
   Jaiswal, Swati/AAA-2098-2022
OI Khairnar, Smita/0000-0003-3194-4859; Jaiswal, Swati/0000-0001-9671-534X;
   Kharat, Reena/0000-0002-7937-5221
SN 0268-3768
EI 1433-3015
DI 10.1007/s00170-023-10834-2
EA JAN 2023
UT WOS:000920820800003
ER

PT J
AU Sharma, N
   Sharma, R
   Jindal, N
AF Sharma, Neha
   Sharma, Reecha
   Jindal, Neeru
TI Comparative analysis of CycleGAN and AttentionGAN on face aging
   application
SO SADHANA-ACADEMY PROCEEDINGS IN ENGINEERING SCIENCES
AB Recently, there is incredible progress in the arena of machine learning with generative adversarial network (GAN) methods. These methods tend to synthesize new data from input images that are highly realistic at the output. One of its applications in the image-to-image transformation way is the face aging task. In the face aging process, new face images are synthesized with the help of the input images and desired target images. Face aging can be beneficial in several domains such as in biometric systems for face recognition with age progression, in forensics for helping to find the missing children, in entertainment, and many more. Nowadays, several GANs are available for face aging applications and this paper focuses on the insight comparison among the frequently used image-to-image translation GANs which are CycleGAN (Cycle-Consistent Adversarial Network) and AttentionGAN (Attention-Guided Generative Adversarial Network). The first model (CycleGAN) comprises two generators, two discriminators, and converting an image from one domain to another without the need for paired images dataset. The second is AttentionGAN, which consists of attention masks and content masks multiplied with the generated output in one domain to generate a highly realistic image in another domain. For comparison, these two are trained on two dataset which is CelebA-HQ (CelebFaces Attributes high-quality dataset) and FFHQ (Flickr Faces HQ). Efficacy is evaluated quantitatively with identity preservation, five image quality assessment metrics, and qualitatively with a perceptual study on synthesized images, face aging signs, and robustness. It has been concluded that overall CycleGAN has better performance than AttentionGAN. In the future, a more critical comparison can be performed on the number of GANs for face aging applications.
RI Sharma, Neha/AAE-6287-2022
SN 0256-2499
EI 0973-7677
PD MAR
PY 2022
VL 47
IS 1
AR 33
DI 10.1007/s12046-022-01807-4
UT WOS:000753866400002
ER

PT J
AU Su, B
   Wen, YT
   Liu, YY
   Liao, S
   Fu, JW
   Quan, GT
   Li, ZL
AF Su, Bin
   Wen, Yuting
   Liu, Yanyan
   Liao, Shu
   Fu, Jianwei
   Quan, Guotao
   Li, Zhenlin
TI A deep learning method for eliminating head motion artifacts in computed
   tomography
SO MEDICAL PHYSICS
AB Purpose Involuntary patient movement results in data discontinuities during computed tomography (CT) scans which lead to a serious degradation in the image quality. In this paper, we specifically address artifacts induced by patient motion during a head scan. Method Instead of trying to solve an inverse problem, we developed a motion simulation algorithm to synthesize images with motion-induced artifacts. The artifacts induced by rotation, translation, oscillation and any possible combination are considered. Taking advantage of the powerful learning ability of neural networks, we designed a novel 3D network structure with both a large reception field and a high image resolution to map the artifact-free images from artifact-contaminated images. Quantitative results of the proposed method were evaluated against the results of U-Net and proposed networks without dilation structure. Thirty sets of motion contaminated images from two hospitals were selected to do a clinical evaluation. Result Facilitating the training dataset with artifacts induced by variable motion patterns and the neural network, the artifact can be removed with good performance. Validation dataset with simulated random motion pattern showed outperformed image correction, and quantitative results showed the proposed network had the lowest normalized root-mean-square error, highest peak signal-to-noise ratio and structure similarity, indicating our network gave the best approximation of gold standard. Clinical image processing results further confirmed the effectiveness of our method. Conclusion We proposed a novel deep learning-based algorithm to eliminate motion artifacts. The convolutional neural networks trained with synthesized image pairs achieved promising results in artifacts reduction. The corrected images increased the diagnostic confidence compared with artifacts contaminated images. We believe that the correction method can restore the ability to successfully diagnose and avoid repeated CT scans in certain clinical circumstances.
RI liu, yan/HGV-1365-2022; liu, yan/HCI-5542-2022
SN 0094-2405
EI 2473-4209
PD JAN
PY 2022
VL 49
IS 1
BP 411
EP 419
DI 10.1002/mp.15354
EA DEC 2021
UT WOS:000728588500001
PM 34786714
ER

PT J
AU Juriasingani, S
   Jackson, A
   Zhang, MY
   Ruthirakanthan, A
   Dugbartey, GJ
   Sogutdelen, E
   Levine, M
   Mandurah, M
   Whiteman, M
   Luke, P
   Sener, A
AF Juriasingani, Smriti
   Jackson, Ashley
   Zhang, Max Yulin
   Ruthirakanthan, Aushanth
   Dugbartey, George J.
   Sogutdelen, Emrullah
   Levine, Max
   Mandurah, Moaath
   Whiteman, Matthew
   Luke, Patrick
   Sener, Alp
TI Evaluating the Effects of Subnormothermic Perfusion with AP39 in a Novel
   Blood-Free Model of Ex Vivo Kidney Preservation and Reperfusion
SO INTERNATIONAL JOURNAL OF MOLECULAR SCIENCES
AB The use of blood for normothermic and subnormothermic kidney preservation hinders the translation of these approaches and promising therapeutics. This study evaluates whether adding hydrogen sulfide donor AP39 to Hemopure, a blood substitute, during subnormothermic perfusion improves kidney outcomes. After 30 min of renal pedicle clamping, porcine kidneys were treated to 4 h of static cold storage (SCS-4 degrees C) or subnormothermic perfusion at 21 degrees C with Hemopure (H-21 degrees C), Hemopure + 200 nM AP39 (H200nM-21 degrees C) or Hemopure + 1 mu M AP39 (H1 mu M-21 degrees C). Then, kidneys were reperfused with Hemopure at 37 degrees C for 4 h with metabolic support. Perfusate composition, tissue oxygenation, urinalysis and histopathology were analyzed. During preservation, the H200nM-21 degrees C group exhibited significantly higher urine output than the other groups and significantly higher tissue oxygenation than the H1 mu M-21 degrees C group at 1 h and 2h. During reperfusion, the H200nM-21 degrees C group exhibited significantly higher urine output and lower urine protein than the other groups. Additionally, the H200nM-21 degrees C group exhibited higher perfusate pO(2) levels than the other groups and significantly lower apoptotic injury than the H-21 degrees C and the H1 mu M-21 degrees C groups. Thus, subnormothermic perfusion at 21 degrees C with Hemopure + 200 nM AP39 improves renal outcomes. Additionally, our novel blood-free model of ex vivo kidney preservation and reperfusion could be useful for studying other therapeutics.
RI Whiteman, Matthew/C-6079-2009
OI Whiteman, Matthew/0000-0002-6583-6779; Sogutdelen,
   Emrullah/0000-0002-1454-5672; Dugbartey, George/0000-0001-8161-7202
EI 1422-0067
PD JUL
PY 2021
VL 22
IS 13
AR 7180
DI 10.3390/ijms22137180
UT WOS:000670999000001
PM 34281230
ER

PT J
AU Demarest, B
   Sugimoto, CR
AF Demarest, Bradford
   Sugimoto, Cassidy R.
TI Argue, observe, assess: Measuring disciplinary identities and
   differences through socio-epistemic discourse
SO JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY
AB Calls for interdisciplinary collaboration have become increasingly common in the face of large-scale complex problems (including climate change, economic inequality, and education, among others); however, outcomes of such collaborations have been mixed, due, among other things, to the so-called translation problem in interdisciplinary research. This article presents a potential solution: an empirical approach to quantitatively measure both the degree and nature of differences among disciplinary tongues through the social and epistemic terms used (a research area we refer to as discourse epistemetrics), in a case study comparing dissertations in philosophy, psychology, and physics. Using a support-vector model of machine learning to classify disciplines based on relative frequencies of social and epistemic terms, we were able to markedly improve accuracy over a random selection baseline (distinguishing between disciplines with as high as 90% accuracy) as well as acquire sets of most indicative terms for each discipline by their relative presence or absence. These lists were then considered in light of findings of sociological and epistemological studies of disciplines and found to validate the approach's measure of social and epistemic disciplinary identities and contrasts. Based on the findings of our study, we conclude by considering the beneficiaries of research in this area, including bibliometricians, students, and science policy makers, among others, as well as laying out a research program that expands the number of disciplines, considers shifts in socio-epistemic identities over time and applies these methods to nonacademic epistemological communities (e.g., political groups).
RI Sugimoto, Cassidy R/AAV-2705-2021
OI Sugimoto, Cassidy R/0000-0001-8608-3203; Demarest,
   Bradford/0000-0002-9349-5676
SN 2330-1635
EI 2330-1643
PD JUL
PY 2015
VL 66
IS 7
BP 1374
EP 1387
DI 10.1002/asi.23271
UT WOS:000355858200006
ER

PT J
AU Soler-Bistue, A
   Mondotte, JA
   Bland, MJ
   Val, ME
   Saleh, MC
   Mazel, D
AF Soler-Bistue, Alfonso
   Mondotte, Juan A.
   Bland, Michael Jason
   Val, Marie-Eve
   Saleh, Mara-Carla
   Mazel, Didier
TI Genomic Location of the Major Ribosomal Protein Gene Locus Determines
   Vibrio cholerae Global Growth and Infectivity
SO PLOS GENETICS
AB The effects on cell physiology of gene order within the bacterial chromosome are poorly understood. In silico approaches have shown that genes involved in transcription and translation processes, in particular ribosomal protein (RP) genes, localize near the replication origin (oriC) in fast-growing bacteria suggesting that such a positional bias is an evolutionarily conserved growth-optimization strategy. Such genomic localization could either provide a higher dosage of these genes during fast growth or facilitate the assembly of ribosomes and transcription foci by keeping physically close the many components of these macromolecular machines. To explore this, we used novel recombineering tools to create a set of Vibrio cholerae strains in which S10-spec-alpha (S10), a locus bearing half of the ribosomal protein genes, was systematically relocated to alternative genomic positions. We show that the relative distance of S10 to the origin of replication tightly correlated with a reduction of S10 dosage, mRNA abundance and growth rate within these otherwise isogenic strains. Furthermore, this was accompanied by a significant reduction in the host-invasion capacity in Drosophila melanogaster. Both phenotypes were rescued in strains bearing two S10 copies highly distal to oriC, demonstrating that replication-dependent gene dosage reduction is the main mechanism behind these alterations. Hence, S10 positioning connects genome structure to cell physiology in Vibrio cholerae. Our results show experimentally for the first time that genomic positioning of genes involved in the flux of genetic information conditions global growth control and hence bacterial physiology and potentially its evolution.
RI Mazel, Didier/F-9200-2013; Val, Marie-Eve/I-4279-2016; Soler-Bistué,
   Alfonso/AAV-3123-2021; Saleh, Maria-Carla/ABC-2527-2021
OI Mazel, Didier/0000-0001-6482-6002; Val, Marie-Eve/0000-0001-7097-9072;
   Soler-Bistué, Alfonso/0000-0002-3917-0002; Saleh,
   Maria-Carla/0000-0001-8593-4117
SN 1553-7404
PD APR
PY 2015
VL 11
IS 4
AR e1005156
DI 10.1371/journal.pgen.1005156
UT WOS:000354524200043
PM 25875621
ER

PT J
AU Arno, S
   Chaudhary, M
   Walker, PS
   Forman, R
   Glassner, P
   Regatte, R
   Oh, C
AF Arno, Sally
   Chaudhary, Miriam
   Walker, Peter S.
   Forman, Rachel
   Glassner, Philip
   Regatte, Ravinder
   Oh, Cheongeun
TI Anterior-posterior stability of the knee by an MR image subtraction
   method
SO KNEE
AB The purpose of our study was to test the hypothesis that when a shear force was applied posteriorly to the loaded knee in vivo, there would be no relative motion between the tibia and the medial femoral condyle. Siemens 7 Tesla high-resolution MRI machine was used to scan eight healthy male volunteers with the knee at 15 degrees of flexion. Two scans were obtained: the first with a compressive force of 660 N along the tibial long axis and a second with the compressive force and a posterior shear force of 36 N applied to the tibia. Solid models were created of the femur, tibia, and menisci for both loading conditions. The tibial models were superimposed enabling the displacements of the femur and menisci to be determined, relative to a fixed tibia. On average, the lateral femoral condyle displaced anteriorly by 0.66 mm but the medial femoral condyle displaced posteriorly by 0.36 mm. This indicated an axial rotation with a center between the lateral and medial condyles, but closer to the medial. The menisci displaced with the femoral condyles, but there was no indication that the medial meniscus was contributing to the pivoting action. This study supported the concept of medial anterior-posterior stability under weight-bearing conditions, but with structures other than the medial meniscus providing the stability. This study has application to the treatment of knee injuries and to knee arthroplasty design. (C) 2011 Elsevier B.V. All rights reserved.
RI Regatte, Ravinder/K-2364-2014
OI Regatte, Ravinder/0000-0002-4607-7682
SN 0968-0160
PD AUG
PY 2012
VL 19
IS 4
BP 445
EP 449
DI 10.1016/j.knee.2011.05.007
UT WOS:000305852300040
PM 21665481
ER

PT J
AU Billuart, F
   Devun, L
   Skalli, W
   Mitton, D
   Gagey, O
AF Billuart, F.
   Devun, L.
   Skalli, W.
   Mitton, D.
   Gagey, O.
TI Role of deltoid and passives elements in stabilization during abduction
   motion (0 degrees-40 degrees): an ex vivo study
SO SURGICAL AND RADIOLOGIC ANATOMY
AB The deltoid and the passive elements of the glenohumeral joint play a role during abduction of the upper limb. However, there is a lack of quantification of their respective role. The aim of the present study was to describe the influence of the deltoid and the passive elements during kinematics experiments in abduction (0 degrees-40 degrees) of unconstrained humerus. Six fresh-frozen anatomical specimens were considered. Bi-planar X-rays were obtained using the EOS (R) stop imaging system (Biospace Med, Paris, France). Then a horizontal traction at constant speed was applied to the "acromion and clavicle block", using an universal testing machine and specific device, and the humerus kinematics was recorded using an optoelectronic system (Polaris (R), NDI, Canada). For each anatomical specimen the protocol included two types of tests: intact capsule and perforated capsule. For a displacement of 28 mm of the acromio-clavicular set, the amplitudes of "abduction" rotation vary between 26 degrees and 41 degrees for the "intact capsule" configuration and between 27 degrees and 40.5 degrees for injured capsule configuration. For the same displacement the translation according to Y of the humeral head changes between 1 and 5.5 mm for intact capsule configuration and between -0.5 and 5.5 mm for injured capsule configuration. During the abduction (0 degrees-40 degrees) motion this study suggests that the humeral head is stabilized by the deltoid, the labrum, tendons of the rotators cuff and to a lesser level by the glenoid.
RI Mitton, David/H-5695-2018
OI Mitton, David/0000-0001-9260-0916
SN 0930-1038
PD OCT
PY 2008
VL 30
IS 7
BP 563
EP 568
DI 10.1007/s00276-008-0374-x
UT WOS:000259444000005
PM 18612583
ER

PT J
AU Matsui, K
   Shimada, K
   Andrew, PD
AF Matsui, K
   Shimada, K
   Andrew, PD
TI Deviation of skin marker from bone target during movement of the scapula
SO JOURNAL OF ORTHOPAEDIC SCIENCE
AB Background. Recording movement of the scapula by non-invasive techniques is fraught with technical difficulty. One convenient method involves placing a single marker on the skin overlying the acromion. The purpose of this study was to compare translatory discrepancies between marker and underlying bone for seven markers affixed to the skin overlying different parts of the scapula.
   Methods. The markers were small plastic spheres filled with machine oil, clearly visible on magnetic resonance imaging (MRI), placed over seven loci of the scapula, including the acromion, spine, medial border, lateral border, and inferior angle. Nine healthy men participated, assuming three positions in the MRI apparatus: (1) arm at the side of the trunk (starting position); (2) arm in full elevation over the head; and (3) hand placed behind the back at the thoracolumbar area. Visible markers and three loci of the scapula itself were digitized on each MRI scan, enabling calculation of changes in location of each marker relative to the scapula between the starting position and either of the other two positions.
   Results. Among the seven loci examined, the marker placed atop the acromion deviated least from its target, 39 +/- 1mm (mean +/- standard deviation) for full elevation and 15 +/- 1mm for moving the hand behind the back. Markers along the medial border and at the inferior angle exhibited relatively large deviations, on the order of 8mm for full elevation and 3mm for moving the hand behind the back.
   Conclusions. For the two movements studied, involving full range of motion in the shoulder complex, translation of the scapula is most accurately recorded if the marker is placed over the acromion, but the systematic error is too large for such tracking to be deemed precise.
OI Matsui, Kazuhisa/0000-0002-0874-857X
SN 0949-2658
PD MAR
PY 2006
VL 11
IS 2
BP 180
EP 184
DI 10.1007/s00776-005-1000-y
UT WOS:000236382100011
PM 16568391
ER

PT J
AU Ma, BY
   Nussinov, R
AF Ma, BY
   Nussinov, R
TI Release factors eRF1 and RF2 - A universal mechanism controls the large
   conformational changes
SO JOURNAL OF BIOLOGICAL CHEMISTRY
AB Class I release factors 1 and 2 (RF1 and RF2) terminate protein synthesis by recognizing stop codons on the mRNA via their conserved amino acid motifs (NIKS in eRF1 and SPF in RF2) and by the conserved tripeptide (GGQ) interactions with the ribosomal peptidyltransferase center. Crystal structures of eRF1 and RF2 do not fit their ribosomal binding pocket (similar to73 Angstrom). Cryoelectron microscopy indicates large conformational changes in the ribosome-bound RF2. Here, we investigate the conformational dynamics of the eRF1 and RF2 using molecular dynamics simulation, structural alignment, and electrostatic analysis of domain interactions. We show that relaxed eRF1 has a shape remarkably similar to the ribosome-bound RF2 observed by cryoelectron microscopy. The similarity between the two release factors is as good as between elongation factor G and elongation factor Tuguanosine-5'(beta,gamma-imido)triphosphate-tRNA. Further, the conformational transitions and dynamics of eRF1 and RF2 between the free and ribosome-bound states are most likely controlled by protonation of conserved histidines. For eRF1, the distance between the NIKS and GGQ motifs shrinks from 97.5 Angstromin the crystal to 70-80 Angstrom. For RF2, the separation between SPF and GGQ elongates from 32 Angstrom in the crystal to 50 Angstrom. Coulombic interaction strongly favors the open conformation of eRF1; however, solvation and histidine protonation modulate the domain interactions, making the closed conformation of eRF1 more accessible. Thus, RF1 and RF2 function like molecular machines, most likely fueled by histidine protonation. The unified conformational control and the shapes of eRF1 and RF2 support the proposition that the termination of protein synthesis involves similar mechanisms across species.
RI Ma, Buyong/F-9491-2011
OI Ma, Buyong/0000-0002-7383-719X; Nussinov, Ruth/0000-0002-8115-6415
SN 0021-9258
EI 1083-351X
PD DEC 17
PY 2004
VL 279
IS 51
BP 53875
EP 53885
DI 10.1074/jbc.M407412200
UT WOS:000225680600126
PM 15475364
ER

PT J
AU Yu, J
   Lee, S
   Song, J
   Lee, SR
   Kim, S
   Choi, H
   Kang, HB
   Hwang, YC
   Hong, YK
   Jeon, NL
AF Yu, James
   Lee, Somin
   Song, Jiyoung
   Lee, Seung-Ryeol
   Kim, Suryong
   Choi, Hyeri
   Kang, Habin
   Hwang, Yunchan
   Hong, Young-Kwon
   Jeon, Noo Li
TI Perfusable micro-vascularized 3D tissue array for high-throughput
   vascular phenotypic screening
SO NANO CONVERGENCE
AB Microfluidic organ-on-a-chip technologies have enabled construction of biomimetic physiologically and pathologically relevant models. This paper describes an injection molded microfluidic platform that utilizes a novel sequential edge-guided patterning method based on spontaneous capillary flow to realize three-dimensional co-culture models and form an array of micro-vascularized tissues (28 per 1 x 2-inch slide format). The MicroVascular Injection-Molded Plastic Array 3D Culture (MV-IMPACT) platform is fabricated by injection molding, resulting in devices that are reliable and easy to use. By patterning hydrogels containing human umbilical endothelial cells and fibroblasts in close proximity and allowing them to form vasculogenic networks, an array of perfusable vascularized micro-tissues can be formed in a highly efficient manner. The high-throughput generation of angiogenic sprouts was quantified and their uniformity was characterized. Due to its compact design (half the size of a 96-well microtiter plate), it requires small amount of reagents and cells per device. In addition, the device design is compatible with a high content imaging machine such as Yokogawa CQ-1. Furthermore, we demonstrated the potential of our platform for high-throughput phenotypic screening by testing the effect of DAPT, a chemical known to affect angiogenesis. The MV-IMPACT represent a significant improvement over our previous PDMS-based devices in terms of molding 3D co-culture conditions at much higher throughput with added reliability and robustness in obtaining vascular micro-tissues and will provide a platform for developing applications in drug screening and development.
OI Jeon, Noo Li/0000-0003-0490-3592
SN 2196-5404
PD APR 8
PY 2022
VL 9
IS 1
AR 16
DI 10.1186/s40580-022-00306-w
UT WOS:000779597100001
PM 35394224
ER

PT J
AU Sakamoto, Y
   Tsukada, H
   Sasaki, S
   Kimura, Y
   Yamamoto, Y
   Tsuda, E
   Ishibashi, Y
AF Sakamoto, Yukiko
   Tsukada, Harehiko
   Sasaki, Shizuka
   Kimura, Yuka
   Yamamoto, Yuji
   Tsuda, Eiichi
   Ishibashi, Yasuyuki
TI Effects of the tibial tunnel position on knee joint stability and
   meniscal contact pressure after double-bundle anterior cruciate ligament
   reconstruction
SO JOURNAL OF ORTHOPAEDIC SCIENCE
AB Background: To investigate the effect of the tibial tunnel position on knee stability and the maximum contact area and peak contact pressure on the menisci after double-bundle anterior cruciate ligament (ACL) reconstruction.
   Methods: Ten human knee specimens (mean age: 74.1 +/- 15.8 years) were used in this study. The anterior tibial loading test was conducted using a material testing machine at 30 degrees, 60 degrees, and 90 degrees of knee flexion, with the anterior tibial translation (ATT) and the maximum contact area and peak contact pressure on the menisci measured. Outcome measures were compared between the following groups: 1) intact ACL (intact group); 2) anatomical tibial tunnel position (anatomical group) and 3) posterior tibial tunnel position (posterior group) with double-bundle reconstruction, and 4) ACL-deficient (deficient group).
   Results: In response to a 100 N anterior tibial load, the ATT was greater for the posterior and ACL-deficient groups compared to that in the intact group. The normalized maximum contact area of the medial meniscus significantly decreased for the posterior group compared to that in the intact group. The normalized peak contact pressure on the medial meniscus increased in all groups compared to that in the intact group, but with no between-group differences in pressure applied to the lateral meniscus.
   Conclusions: ATT and contact pressure on the medial meniscus increased, concomitant with a decrease in contact area of the medial meniscus, as the position of the tibial tunnel position moved towards a posterior position. (C) 2020 The Japanese Orthopaedic Association. Published by Elsevier B.V. All rights reserved.
RI Kimura, Yuka/AAC-2684-2022; Kimura, Yuka/AGY-9521-2022
OI Kimura, Yuka/0000-0001-6902-4850; Yamamoto, Yuji/0000-0001-7472-363X
SN 0949-2658
EI 1436-2023
PD NOV
PY 2020
VL 25
IS 6
BP 1040
EP 1046
DI 10.1016/j.jos.2019.12.006
UT WOS:000594792300018
PM 31937484
ER

PT J
AU Keneshloo, Y
   Shi, T
   Ramakrishnan, N
   Reddy, CK
AF Keneshloo, Yaser
   Shi, Tian
   Ramakrishnan, Naren
   Reddy, Chandan K.
TI Deep Reinforcement Learning for Sequence-to-Sequence Models
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
AB In recent times, sequence-to-sequence (seq2seq) models have gained a lot of popularity and provide state-of-the-art performance in a wide variety of tasks, such as machine translation, headline generation, text summarization, speech-to-text conversion, and image caption generation. The underlying framework for all these models is usually a deep neural network comprising an encoder and a decoder. Although simple encoder-decoder models produce competitive results, many researchers have proposed additional improvements over these seq2seq models, e.g., using an attention-based model over the input, pointer-generation models, and self-attention models. However, such seq2seq models suffer from two common problems: 1) exposure bias and 2) inconsistency between train/test measurement. Recently, a completely novel point of view has emerged in addressing these two problems in seq2seq models, leveraging methods from reinforcement learning (RL). In this survey, we consider seq2seq problems from the RL point of view and provide a formulation combining the power of RL methods in decision-making with seq2seq models that enable remembering long-term memories. We present some of the most recent frameworks that combine the concepts from RL and deep neural networks. Our work aims to provide insights into some of the problems that inherently arise with current approaches and how we can address them with better RL models. We also provide the source code for implementing most of the RL models discussed in this paper to support the complex task of abstractive text summarization and provide some targeted experiments for these RL models, both in terms of performance and training time.
OI Shi, Tian/0000-0002-7604-5665; KENESHLOO, Yaser/0000-0002-1962-2542;
   Reddy, Chandan/0000-0003-2839-3662
SN 2162-237X
EI 2162-2388
PD JUL
PY 2020
VL 31
IS 7
BP 2469
EP 2489
DI 10.1109/TNNLS.2019.2929141
UT WOS:000546986600020
PM 31425057
ER

PT J
AU Paidi, SK
   Diaz, PM
   Dadgar, S
   Jenkins, SV
   Quick, CM
   Griffin, RJ
   Dings, RPM
   Rajaram, N
   Barman, I
AF Paidi, Santosh K.
   Diaz, Paola Monterroso
   Dadgar, Sina
   Jenkins, Samir, V
   Quick, Charles M.
   Griffin, Robert J.
   Dings, Ruud P. M.
   Rajaram, Narasimhan
   Barman, Ishan
TI Label-Free Raman Spectroscopy Reveals Signatures of Radiation Resistance
   in the Tumor Microenvironment
SO CANCER RESEARCH
AB Delay in the assessment of tumor response to radiotherapy continues to pose a major challenge to quality of life for patients with nonresponsive tumors. Here, we exploited label-free Raman spectroscopic mapping to elucidate radiation-induced biomolecular changes in tumors and uncovered latent microenvironmental differences between treatment-resistant and -sensitive tumors. We used isogenic radiation-resistant and -sensitive A549 human lung cancer cells and human head and neck squamous cell carcinoma (HNSCC) cell lines (UM-SCC-47 and UM-SCC-22B, respectively) to grow tumor xenografts in athymic nude mice and demonstrated the molecular specificity and quantitative nature of Raman spectroscopic tissue assessments. Raman spectra obtained from untreated and treated tumors were subjected to chemometric analysis using multivariate curve resolution-alternating least squares (MCR-ALS) and support vector machine (SVM) to quantify biomolecular differences in the tumor microenvironment. The Raman measurements revealed significant and reliable differences in lipid and collagen content postradiation in the tumor microenvironment, with consistently greater changes observed in the radiationsensitive tumors. In addition to accurately evaluating tumor response to therapy, the combination of Raman spectral markers potentially offers a route to predicting response in untreated tumors prior to commencing treatment. Combined with its noninvasive nature, our findings provide a rationale for in vivo studies using Raman spectroscopy, with the ultimate goal of clinical translation for patient stratification and guiding adaptation of radiotherapy during the course of treatment.
   Significance: These findings highlight the sensitivity of label-free Raman spectroscopy to changes induced by radiotherapy and indicate the potential to predict radiation resistance prior to commencing therapy.
RI Rajaram, Narasimhan/A-2249-2010; Diaz, Paola/HTM-8161-2023; Dings,
   Ruud/R-3772-2019
OI Rajaram, Narasimhan/0000-0003-1224-8567; Dings,
   Ruud/0000-0001-7686-1331; Dadgar, Sina/0000-0002-5983-3512; Griffin,
   Robert/0000-0002-3574-2958; Paidi, Santosh/0000-0002-7034-586X
SN 0008-5472
EI 1538-7445
PD APR 15
PY 2019
VL 79
IS 8
BP 2054
EP 2064
DI 10.1158/0008-5472.CAN-18-2732
UT WOS:000464651500031
PM 30819665
ER

PT J
AU Chen, L
   He, YH
   Fan, L
AF Chen, Long
   He, Yuhang
   Fan, Lei
TI Let the robot tell: Describe car image with natural language via LSTM
SO PATTERN RECOGNITION LETTERS
AB Image-based car detection and classification has remained as a research hub in self-driving for decades. However, natural language description of car images is still a virgin territory even though it is a simple task for human to describe it by sentences within a glimpse at the image. In this paper, we present an end-to-end trainable and spatial-temporal deep recurrent neural network: LSTM (Long-Short Term Memory) to automatically convert car images to human understandable natural language descriptions. Our model builds on state of the art progress in computer vision and machine translation: we extract car region proposals with Region Convolutional Neural Networks(R-CNN) and embed them into fixed-sized vectors. Each word in a sentence is also embedded into real-valued vectors of the same size of images through a local global context aware neural network. The LSTM, feeding by image-sentence pairs sequentially in the training stage, is trained to maximize the joint probability of target word in each time step. In the test stage, the pre-trained LSTM receives a car image and predicts natural language description word by word. Finally, we evaluate our model regarding car's static/dynamic attribute description on both 30,000 CompCar dataset [21] and 1000 video dataset collected on street scenario by our self-driving car, with quantitative BLEU score and subjective human-rating system evaluation metrics. We test our model's generalization ability, its transfer ability to address car property classification issue and various image feature extractors' impact on our model. Experiment results show the superiority and robustness of our model (refer to www. carlib. net/carimg2text. html formoreexperimentresults). (C) 2017 Elsevier B.V. Allrightsreserved.
RI he, yh/HJA-5454-2022
SN 0167-8655
EI 1872-7344
PD OCT
PY 2017
VL 98
BP 75
EP 82
DI 10.1016/j.patrec.2017.09.007
UT WOS:000411766300011
ER

PT J
AU Pratihar, DK
   Deb, K
   Ghosh, A
AF Pratihar, DK
   Deb, K
   Ghosh, A
TI Optimal turning gait of a six-legged robot using a GA-fuzzy approach
SO AI EDAM-ARTIFICIAL INTELLIGENCE FOR ENGINEERING DESIGN ANALYSIS AND
   MANUFACTURING
AB This paper describes a new method for generating the turning-gait of a six-legged robot using a combined genetic algorithm (GA)-Fuzzy approach. The main drawback of the traditional methods of gait generation is their high computational load. Thus, there is still a need for the development of a computationally tractable algorithm that can be implemented online to generate stable gait of a multilegged robot. In the proposed genetic-fuzzy system, the fuzzy logic controllers (FLCs) are used to generate the stable gait of a hexapod and a GA is used to improve the performance of the FLCs. The effectiveness of the proposed algorithm is tested on a number of turning-gait generation problems of a hexapod that involve translation as well as rotation of the vehicle. The hexapod will have to take a sharp circular turn (either clockwise or counter-clockwise) with minimum number of ground legs having the maximum average kinematic margin. Moreover: the stability margin should lie within a certain range to ensure Static stability of the vehicle. Each leg of a six-legged robot is controlled by a separate FLC and the performance of the controllers is improved by using a GA. it is to be noted that the actual optimization is done off-line and the hexapod can use these optimized FLCs to navigate in real-world scenarios. As an FLC is computationally less expensive, the proposed algorithm will be faster compared with the traditional methods of gait-generation, which include both graphical as well as analytical methods. The GA-tuned FLCs are found to perform better than the author-defined FLCs.
RI Deb, Kalyanmoy/B-1563-2009
OI Pratihar, Dilip/0000-0001-8585-5910
SN 0890-0604
EI 1469-1760
PD JUN
PY 2000
VL 14
IS 3
BP 207
EP 219
DI 10.1017/S0890060400143033
UT WOS:000090115400003
ER

PT J
AU Wu, AN
   Biljecki, F
AF Wu, Abraham Noah
   Biljecki, Filip
TI InstantCITY: Synthesising morphologically accurate geospatial data for
   urban form analysis, transfer, and quality control
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
AB Generative Adversarial Network (GAN) is widely used in many generative problems, including in spatial information sciences and urban systems. The data generated by GANs can achieve high quality to augment downstream training or to complete missing entries in a dataset. GANs can also be used to learn the relationship between two datasets and translate one into another, e.g. road network data into building footprint data. However, such approach has not been developed in the geospatial and urban data science context, its usability remains unknown, and the methods are not fully developed. We develop a new Geographical Data Translation algorithm based on GAN to generate high-resolution vector building data solely from street networks, which may be used to predict the urban morphology in absence of building data, also enabling studies in unmapped or undermapped urban geographies, among other advantages. Experiments on 16 cities around the world demonstrate that the generated datasets are largely successful in resembling ground truth morphologies. Thus, the approach may be used in lieu of traditional data for tasks that are often hampered by lack of data, e.g. urban form studies, simulation of urban morphologies in new contexts, and spatial data quality assessment. Our work proposes a novel rapid approach to generate building footprints in replacement of procedural methods and it introduces a new intrinsic method for large-scale spatial data quality control, which we test on OpenStreetMap by predicting missing buildings and suggesting the completeness of data without the usually required authoritative counterparts. The code, sample model, and dataset are available openly.
OI Wu, Abraham Noah/0000-0001-9586-3201
SN 0924-2716
EI 1872-8235
PD JAN
PY 2023
VL 195
BP 90
EP 104
DI 10.1016/j.isprsjprs.2022.11.005
UT WOS:000898868700002
ER

PT J
AU Qian, FL
   Huang, YF
   Li, JH
   Wang, CJ
   Zhao, S
   Zhang, YP
AF Qian, Fulan
   Huang, Yafan
   Li, Jianhong
   Wang, Chengjun
   Zhao, Shu
   Zhang, Yanping
TI DLSA: dual-learning based on self-attention for rating prediction
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
AB Latent factor models (LFMs) have been widely applied in many rating recommendation systems because of their prediction rating capability. Nevertheless, LFMs may not fully leverage rating information and lack good recommendation performance. Furthermore, many subsequent works have often used auxiliary text information, such as user attributes, to improve the prediction effect. However, they did not fully utilize implicit information (i.e., users' preferences, items' common features), and additional information is sometimes difficult to acquire. In this paper, we propose a new framework, named dual-learning based on self-attention for rating prediction (DLSA), to solve these problems. Self-attention has a proven ability to learn implicit information about sentences in machine translation, which can be used to mine implicit information in recommendation systems. Additionally, dual learning has shown that the model can generate feedback information when it learns from unlabeled data; therefore, we were inspired to use it in recommendation and obtain implicit information feedback. From the user's perspective, we design a user self-attention model to learn user-user implicit information and create an interactive user-item self-attention mechanism to learn user-item information. We can also obtain item self-attention to utilize item-item information and an item-user self-attention model to acquire item-user information from an item's perspective. The interactive structure of the user-item and item-user can adopt the dual learning mechanism to learn implicit information feedback. Moreover, no auxiliary text information was used in the process. The proposed model combines the power of self-attention for implicit information and dual learning for information feedback in a new neural network architecture. Experiments on several real-world datasets demonstrate the effectiveness of DLSA over competitive algorithms on rating recommendation.
SN 1868-8071
EI 1868-808X
PD JUL
PY 2021
VL 12
IS 7
BP 1993
EP 2005
DI 10.1007/s13042-021-01288-7
EA MAY 2021
UT WOS:000651718900001
ER

PT J
AU Zormpas-Petridis, K
   Noguera, R
   Ivankovic, DK
   Roxanis, I
   Jamin, Y
   Yuan, YY
AF Zormpas-Petridis, Konstantinos
   Noguera, Rosa
   Ivankovic, Daniela Kolarevic
   Roxanis, Ioannis
   Jamin, Yann
   Yuan, Yinyin
TI SuperHistopath: A Deep Learning Pipeline for Mapping Tumor Heterogeneity
   on Low-Resolution Whole-Slide Digital Histopathology Images
SO FRONTIERS IN ONCOLOGY
AB High computational cost associated with digital pathology image analysis approaches is a challenge towards their translation in routine pathology clinic. Here, we propose a computationally efficient framework (SuperHistopath), designed to map global context features reflecting the rich tumor morphological heterogeneity. SuperHistopath efficiently combines i) a segmentation approach using the linear iterative clustering (SLIC) superpixels algorithm applied directly on the whole-slide images at low resolution (5x magnification) to adhere to region boundaries and form homogeneous spatial units at tissue-level, followed by ii) classification of superpixels using a convolution neural network (CNN). To demonstrate how versatile SuperHistopath was in accomplishing histopathology tasks, we classified tumor tissue, stroma, necrosis, lymphocytes clusters, differentiating regions, fat, hemorrhage and normal tissue, in 127 melanomas, 23 triple-negative breast cancers, and 73 samples from transgenic mouse models of high-risk childhood neuroblastoma with high accuracy (98.8%, 93.1% and 98.3% respectively). Furthermore, SuperHistopath enabled discovery of significant differences in tumor phenotype of neuroblastoma mouse models emulating genomic variants of high-risk disease, and stratification of melanoma patients (high ratio of lymphocyte-to-tumor superpixels (p = 0.015) and low stroma-to-tumor ratio (p = 0.028) were associated with a favorable prognosis). Finally, SuperHistopath is efficient for annotation of ground-truth datasets (as there is no need of boundary delineation), training and application (similar to 5 min for classifying a whole-slide image and as low as similar to 30 min for network training). These attributes make SuperHistopath particularly attractive for research in rich datasets and could also facilitate its adoption in the clinic to accelerate pathologist workflow with the quantification of phenotypes, predictive/prognosis markers.
OI Yuan, Yinyin/0000-0002-8556-4707
SN 2234-943X
PD JAN 20
PY 2021
VL 10
AR 586292
DI 10.3389/fonc.2020.586292
UT WOS:000614087200001
PM 33552964
ER

PT C
AU Malte, A
   Ratadiya, P
AF Malte, Aditya
   Ratadiya, Pratik
GP IEEE
TI Multilingual Cyber Abuse Detection using Advanced Transformer
   Architecture
SO PROCEEDINGS OF THE 2019 IEEE REGION 10 CONFERENCE (TENCON 2019):
   TECHNOLOGY, KNOWLEDGE, AND SOCIETY
SE TENCON IEEE Region 10 Conference Proceedings
CT IEEE Region 10 Conference on Technology, Knowledge, and Society (TENCON)
CY OCT 17-20, 2019
CL Kochi, INDIA
SP IEEE Kerala Sect, IEEE Humanitarian Activities Comm, Nissan Digital, Nest, Kerala State IT Miss, Cochin Shipyard Ltd, Terumo Penpol, Oracle Acad, InApp, Natl Instruments, Mentor, UST Global, I3, ICFOSS, Kerala Startup Miss, IEEE Reg 10
AB The rise in the number of active online users has subsequently increased the number of cyber abuse incidents being reported as well. Such events pose a harm to the privacy and liberty of users in the digital space. Conventionally, manual moderation and reporting mechanisms have been used to ensure that no such text is present online. However, there have been some flaws in this method including dependency on humans, increased delays and reduced data privacy. Previous approaches to automate this process have involved using supervised machine learning and traditional recurrent sequence models which tend to perform poorly on non-English text. Given the rising diversity of users being a part of the cyberspace, a flexible solution able to accommodate multilingual text is the need of the hour. Furthermore, text in colloquial languages often hold pertinent context and emotion that is lost after translation. In this paper, we propose a generative deep-learning based approach which involves the use of bidirectional transformer-based BERT architecture for cyber abuse detection across English, Hindi and code-mixed Hindi English(Hinglish) text. The proposed architecture can achieve state-of-the-art results on the code-mixed Hindi dataset in the TRAC-1 standard aggression identification task while being able to achieve very good results on the English task leaderboard as well. The results achieved are without using any ensemble-based methods or multiple models and thus prove to be a better alternative to the existing approaches. Deep learning based models which perform well on multilingual text will be able to handle a broader range of inputs and thus can prove to be crucial in cracking down on such social evils.
SN 2159-3442
BN 978-1-7281-1895-6
PY 2019
BP 784
EP 789
UT WOS:000528677800145
ER

PT J
AU Benedikt, MA
   Lenhardt, R
   Worrell, J
AF Benedikt, Michael A.
   Lenhardt, Rastislav
   Worrell, James
TI TWO VARIABLE VS. LINEAR TEMPORAL LOGIC IN MODEL CHECKING AND GAMES
SO LOGICAL METHODS IN COMPUTER SCIENCE
AB Model checking linear-time properties expressed in first-order logic has non-elementary complexity, and thus various restricted logical languages are employed. In this paper we consider two such restricted specification logics, linear temporal logic (LTL) and two-variable first-order logic (FO2). LTL is more expressive but FO2 can be more succinct, and hence it is not clear which should be easier to verify. We take a comprehensive look at the issue, giving a comparison of verification problems for FO2, LTL, and various sub-logics thereof across a wide range of models. In particular, we look at unary temporal logic (UTL), a subset of LTL that is expressively equivalent to FO2; we also consider the stutter-free fragment of FO2, obtained by omitting the successor relation, and the expressively equivalent fragment of UTL, obtained by omitting the next and previous connectives.
   We give three logic-to-automata translations which can be used to give upper bounds for FO2 and UTL and various sub-logics. We apply these to get new bounds for both non-deterministic systems (hierarchical and recursive state machines, games) and for probabilistic systems (Markov chains, recursive Markov chains, and Markov decision processes). We couple these with matching lower-bound arguments.
   Next, we look at combining FO2 verification techniques with those for LTL. We present here a language that subsumes both FO2 and LTL, and inherits the model checking properties of both languages. Our results give both a unified approach to understanding the behaviour of FO2 and LTL, along with a nearly comprehensive picture of the complexity of verification for these logics and their sublogics.
OI Worrell, James/0000-0001-8151-2443; benedikt,
   michael/0000-0003-2964-0880
SN 1860-5974
PY 2013
VL 9
IS 2
AR 04
DI 10.2168/LMCS-9(2:04)2013
UT WOS:000322537700008
ER

PT J
AU Collins, M
   Koo, T
AF Collins, M
   Koo, T
TI Discriminative reranking for natural language parsing
SO COMPUTATIONAL LINGUISTICS
AB This article considers approaches which rerank the output of an existing probabilistic parser. The base parser produces a set of candidate parses for each input sentence, with associated probabilities that define an initial ranking of these parses. A second model then attempts to improve upon this initial ranking, using additional features of the tree as evidence. The strength of our approach is that it allows a tree to be represented as an arbitrary set of features, without concerns about how these features interact or overlap and without the need to define a derivation or a generative model which takes these features into account. We introduce a new method for the reranking task, based on the boosting approach to ranking problems described in Freund et al. (1998). We apply the boosting method to parsing the Wall Street journal treebank. The method combined the log-likelihood under a baseline model (that of Collins [19991) with evidence from an additional 500,000 features over parse trees that were not included in the original model. The new model achieved 89.75% F-measure, a 13% relative decrease in F-measure error over the baseline model's score of 88.2%. The article also introduces a new algorithm for the boosting approach which takes advantage of the sparsity of the feature space in the parsing data. Experiments show significant efficiency gains for the new algorithm over the obvious implementation of the boosting approach. We argue that the method is an appealing alternative-in terms of both simplicity and efficiency-to work on feature selection methods within log-linear (maximum-entropy) models. Although the experiments in this article are on natural language parsing (NLP), the approach should be applicable to many other NLP problems which are naturally framed as ranking tasks, for example, speech recognition, machine translation, or natural language generation.
SN 0891-2017
EI 1530-9312
PD MAR
PY 2005
VL 31
IS 1
BP 25
EP 69
DI 10.1162/0891201053630273
UT WOS:000228836600003
ER

PT J
AU Brooks, KW
   Trueblood, JH
   Kearfott, KJ
   Lawton, DT
AF Brooks, KW
   Trueblood, JH
   Kearfott, KJ
   Lawton, DT
TI Automated analysis of the American College of Radiology mammographic
   accreditation phantom images
SO MEDICAL PHYSICS
AB A significant metric in federal mammography quality standards is the phantom image quality assessment. The present work seeks to demonstrate that automated image analyses for American College of Radiology (ACR) mammographic accreditation phantom (MAP) images may be performed by a computer with objectivity, once a human acceptance level has been established. Twelve MAP images were generated with different x-ray techniques and digitized. Nineteen medical physicists in diagnostic roles (five of which were specially trained in mammography) viewed the original film images under similar conditions and provided individual scores for each test object (fibrils, microcalcifications, and nodules). Fourier domain template matching, used for tow-level processing, combined with derivative filters, for intermediate-level processing, provided translation and rotation-independent localization of the test objects in the MAP images. The visibility classification decision was modeled by a Bayesian classifer using threshold contrast. The 50% visibility contrast thresholds established by the trained observers' responses were: fibrils 1.010, microcalcifications 1.156, and nodules 1.016. Using these values as an estimate of human observer performance and given the automated localization of test objects, six images were graded with the computer algorithm. In all but one instance, the algorithm scored the images the same as the diagnostic physicists. Ln the case where it did not, the margin of disagreement was 10% due to the fact that the human scoring did not allow for half-visible fibrils (agreement occurred for the other test objects). The implication from this is that an operator-independent, machine-based scoring of MAP images is feasible and could be used as a tool to help eliminate the effect of observer variability within the current system, given proper, consistent digitization is performed. (C) 1997 American Association of Physicists in Medicine.
RI Kearfott, Kimberlee J/G-2467-2014
OI Kearfott, Kimberlee J/0000-0002-8698-0913
SN 0094-2405
PD MAY
PY 1997
VL 24
IS 5
BP 709
EP 723
DI 10.1118/1.597992
UT WOS:A1997WZ85500010
PM 9167162
ER

PT J
AU Hou, TH
   Bryant, RG
AF Hou, TH
   Bryant, RG
TI Processing and properties of IM7/LARC(TM)-SCI composite
SO HIGH PERFORMANCE POLYMERS
AB LARC(TM)-SCI (Langley Research Center - Semi-Crystaline polyImide) is an aromatic polyimide based on 3,4'-oxydianiline and 3,3',4,4'-biphenyl tetracarboxylic dianhydride. This polyimide was synthesized and evaluated for use as a neat resin and a matrix resin for advanced composites. Three 30% w/w solids polyamic acid/N-methypyrrolidone solutions were prepared using 2, 3 and 4% stoichiometric imbalances end-capped with phthalic anhydride to provide polyimides with theoretical number average molecular weights of approximately 22 800, 15 100 and 11 400 g mol(-1) respectively. Unidirectional IM7 carbon fibre prepreg was prepared from these three resins using the Langley multipurpose tape machine. Thermal and rheological properties and the solvent/volatile depletion rates along with crystallization kinetics were characterized for the resin scraps taken from the prepreg tapes. Processing characteristics of the LARC(TM)-SCI resin were thoroughly understood from these results, and a workable moulding cycle was designed for this composite. Composite laminates were moulded at 410 degrees C at either 200 or 300 psi, which consistently yielded good consolidation and high-quality panels as measured by C-scan, acid digestion and optical photomicrography. The composite mechanical properties were also obtained. Short beam shear strength was 15 ksi at RT. Longitudinal flexural strength was 295 ksi at RT and 200 ksi at 177 degrees C. Excellent fracture toughness of 6.9 in-lb/in(2) was obtained. Excellent values of transverse flexural strength and longitudinal tensile strength indicated a good translation of fibre properties int the composite. Un-notched longitudinal compression strength of 163 ksi was comparable to typical thermoplastic composites. An open hole compression strength of 55 ksi suggested good damage tolerance for this composite.
SN 0954-0083
PD JUN
PY 1996
VL 8
IS 2
BP 169
EP 184
DI 10.1088/0954-0083/8/2/002
UT WOS:A1996UV18800002
ER

PT J
AU Pawar, S
   San, OM
   Rasheed, A
   Vedula, P
AF Pawar, Suraj
   San, Omer
   Rasheed, Adil
   Vedula, Prakash
TI Frame invariant neural network closures for Kraichnan turbulence
SO PHYSICA A-STATISTICAL MECHANICS AND ITS APPLICATIONS
AB Numerical simulations of geophysical and atmospheric flows have to rely on param-eterizations of subgrid scale processes due to their limited spatial resolution. Despite substantial progress in developing parameterization (or closure) models for subgrid scale (SGS) processes using physical insights and mathematical approximations, they remain imperfect and can lead to inaccurate predictions. In recent years, machine learning has been successful in extracting complex patterns from high-resolution spatio-temporal data, leading to improved parameterization models, and ultimately better coarse grid prediction. However, the inability to satisfy known physics and poor generalization hinders the application of these models for real-world problems. In this work, we put forth a frame invariant closure approach to improve the accuracy and generalizability of deep learning-based subgrid scale closure models by embedding physical symmetries directly into the structure of the neural network. Specifically, we utilized specialized layers within the convolutional neural network in such a way that desired constraints are theoretically guaranteed without the need for any regularization terms. We demonstrate our framework for a two-dimensional decaying turbulence test case mostly characterized by the forward enstrophy cascade. We show that our frame invariant SGS model (i) accurately predicts the subgrid scale source term, (ii) respects the physical symmetries such as translation, Galilean, and rotation invariance, and (iii) is numerically stable when implemented in coarse-grid simulation with generalization to different initial conditions and Reynolds number. This work opens up a possibility of connecting physics -based theories and data-driven modeling paradigms, and thus represents a promising step towards the development of physically consistent data-driven turbulence closure models.(c) 2022 Elsevier B.V. All rights reserved.
RI Pawar, Suraj/AIF-1672-2022
OI Pawar, Suraj/0000-0001-7562-799X
SN 0378-4371
EI 1873-2119
PD JAN 1
PY 2023
VL 609
AR 128327
DI 10.1016/j.physa.2022.128327
UT WOS:000895783100003
ER

PT J
AU Kang, J
AF Kang, Jaesik
TI Comprehensive Analysis of Transient Overvoltage Phenomena for
   Metal-Oxide Varistor Surge Arrester in LCC-HVDC Transmission System with
   Special Protection Scheme
SO ENERGIES
AB This paper proposes a systematic and deterministic method for metal-oxide varistor (MOV) surge arrester selection based on the comprehensive analysis in line-commutated converter (LCC)-based high-voltage direct current (HVDC) transmission systems. For the MOV surge arrester, this paper investigates several significant impacts on the transient overvoltage (TOV) phenomena, which is affected by practical factors such as an operating point of the LCC-HVDC system, synchronous machine operating status of the power system, AC passive filter trip, and communication delay in a special protection system (SPS). In order to determine an appropriate rating of surge arrester, especially for TOV, this paper considers a pattern, magnitude, and duration of TOV based on various fault scenarios in an electrical power system with an LCC-HVDC system. A screening study method with 60 Hz and RMS-based balance system is conducted for examining a wide range of fault scenarios, and then for the specific test cases that need a detailed analysis, electro-magnetic transient (EMT)-based analysis models are developed with an approvable boundary setting method through the equivalent network translation tool. A detailed EMT study is subsequent based on the distinguished cases; as a result, the exact number of metal-oxide resistor stacks could be obtained through the detailed TOV study according to this procedure. The efficacy of the selection method from the proposed procedure based on the comprehensive analysis are verified on a specific power system with a 1.5 GW DC +/- 500 kV symmetric monopole LCC-HVDC transmission system.
OI Kang, Jaesik/0000-0001-6192-6577
EI 1996-1073
PD OCT
PY 2022
VL 15
IS 19
AR 7034
DI 10.3390/en15197034
UT WOS:000866780400001
ER

PT J
AU Allen, B
   Seltzer, SE
   Langlotz, CP
   Dreyer, KP
   Summers, RM
   Petrick, N
   Marinac-Dabic, D
   Cruz, M
   Alkasab, TK
   Hanisch, RJ
   Nilsen, WJ
   Burleson, J
   Lyman, K
   Kandarpa, K
AF Allen, Bibb, Jr.
   Seltzer, Steven E.
   Langlotz, Curtis P.
   Dreyer, Keith P.
   Summers, Ronald M.
   Petrick, Nicholas
   Marinac-Dabic, Danica
   Cruz, Marisa
   Alkasab, Tarik K.
   Hanisch, Robert J.
   Nilsen, Wendy J.
   Burleson, Judy
   Lyman, Kevin
   Kandarpa, Krishna
TI A Road Map for Translational Research on Artificial Intelligence in
   Medical Imaging: From the 2018 National Institutes of
   Health/RSNA/ACR/The Academy Workshop
SO JOURNAL OF THE AMERICAN COLLEGE OF RADIOLOGY
AB Advances in machine learning in medical imaging are occurring at a rapid pace in research laboratories both at academic institutions and in industry. Important artificial intelligence (AI) tools for diagnostic imaging include algorithms for disease detection and classification, image optimization, radiation reduction, and workflow enhancement. Although advances in foundational research are occurring rapidly, translation to routine clinical practice has been slower. In August 2018, the National Institutes of Health assembled multiple relevant stakeholders at a public meeting to discuss the current state of knowledge, infrastructure gaps, and challenges to wider implementation. The conclusions of that meeting are summarized in two publications that identify and prioritize initiatives to accelerate foundational and translational research in AI for medical imaging. This publication summarizes key priorities for translational research developed at the workshop including: (1) creating structured AI use cases, defining and highlighting clinical challenges potentially solvable by AI; (2) establishing methods to encourage data sharing for training and testing AI algorithms to promote generalizability to widespread clinical practice and mitigate unintended bias; (3) establishing tools for validation and performance monitoring of AI algorithms to facilitate regulatory approval; and (4) developing standards and common data elements for seamless integration of AI tools into existing clinical workflows. An important goal of the resulting road map is to grow an ecosystem, facilitated by professional societies, industry, and government agencies, that will allow robust collaborations between practicing clinicians and AI researchers to advance foundational and translational research relevant to medical imaging. (C) 2019 Published by Elsevier on behalf of American College of Radiology
RI Summers, Ronald/AAX-6290-2021
OI Marinac-Dabic, Danica/0000-0002-1824-0104; Hanisch,
   Robert/0000-0002-6853-4602
SN 1546-1440
PD SEP
PY 2019
VL 16
IS 9
BP 1179
EP 1189
DI 10.1016/j.jacr.2019.04.014
PN A
UT WOS:000486132000016
PM 31151893
ER

PT J
AU Paraskevaidi, M
   Ashton, KM
   Stringfellow, HF
   Wood, NJ
   Keating, PJ
   Rowbottom, AW
   Martin-Hirsch, PL
   Martin, FL
AF Paraskevaidi, Maria
   Ashton, Katherine M.
   Stringfellow, Helen F.
   Wood, Nicholas J.
   Keating, Patrick J.
   Rowbottom, Anthony W.
   Martin-Hirsch, Pierre L.
   Martin, Francis L.
TI Raman spectroscopic techniques to detect ovarian cancer biomarkers in
   blood plasma
SO TALANTA
AB Robust diagnosis of ovarian cancer is crucial to improve patient outcomes. The lack of a single and accurate diagnostic approach necessitates the advent of novel methods in the field. In the present study, two spectroscopic techniques, Raman and surface-enhanced Raman spectroscopy (SERS) using silver nanoparticles, have been employed to identify signatures linked to cancer in blood. Blood plasma samples were collected from 27 patients with ovarian cancer and 28 with benign gynecological conditions, the majority of which had a prolapse. Early ovarian cancer cases were also included in the cohort (n = 17). The derived information was processed to account for differences between cancerous and healthy individuals and a support vector machine (SVM) algorithm was applied for classification. A subgroup analysis using CA-125 levels was also conducted to rule out that the observed segregation was due to CA-125 differences between patients and controls. Both techniques provided satisfactory diagnostic accuracy for the detection of ovarian cancer, with spontaneous Raman achieving 94% sensitivity and 96% specificity and SERS 87% sensitivity and 89% specificity. For early ovarian cancer, Raman achieved sensitivity and specificity of 93% and 97%, respectively, while SERS had 80% sensitivity and 94% specificity. Five spectral biomarkers were detected by both techniques and could be utilised as a panel of markers indicating carcinogenesis. CA-125 levels did not seem to undermine the high classification accuracies. This minimally invasive test may provide an alternative diagnostic and screening tool for ovarian cancer that is superior to other established blood-based biomarkers.
RI Wood, Nicholas/E-7124-2018
OI Wood, Nicholas/0000-0002-5909-7885
SN 0039-9140
EI 1873-3573
PD NOV 1
PY 2018
VL 189
BP 281
EP 288
DI 10.1016/j.talanta.2018.06.084
UT WOS:000442063900039
PM 30086919
ER

PT J
AU Plappert, M
   Mandery, C
   Asfour, T
AF Plappert, Matthias
   Mandery, Christian
   Asfour, Tamim
TI Learning a bidirectional mapping between human whole-body motion and
   natural language using deep recurrent neural networks
SO ROBOTICS AND AUTONOMOUS SYSTEMS
AB Linking human whole-body motion and natural language is of great interest for the generation of semantic representations of observed human behaviors as well as for the generation of robot behaviors based on natural language input. While there has been a large body of research in this area, most approaches that exist today require a symbolic representation of motions (e.g. in the form of motion primitives), which have to be defined a-priori or require complex segmentation algorithms. In contrast, recent advances in the field of neural networks and especially deep learning have demonstrated that sub-symbolic representations that can be learfied end-to-end usually outperform more traditional approaches, for applications such as machine translation. In this paper we propose a generative model that learns a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks (RNNs) and sequence-to-sequence learning. Our approach does not require any segmentation or manual feature engineering and learns a distributed representation, which is shared for all motions and descriptions. We evaluate our approach on 2 846 human whole-body motions and 6 187 natural language descriptions thereof from the KIT Motion-Language Dataset. Our results clearly demonstrate the effectiveness of the proposed model: We show that our model generates a wide variety of realistic motions only from descriptions thereof in form of a single sentence. Conversely, our model is also capable of generating correct and detailed natural language descriptions from human motions. (C) 2018 Elsevier B.V. All rights reserved.
OI Asfour, Tamim/0000-0003-4879-7680
SN 0921-8890
EI 1872-793X
PD NOV
PY 2018
VL 109
BP 13
EP 26
DI 10.1016/j.robot.2018.07.006
UT WOS:000447547300002
ER

PT J
AU Hnat, SK
   van Basten, BJH
   van den Bogert, AJ
AF Hnat, Sandra K.
   van Basten, Ben J. H.
   van den Bogert, Antonie J.
TI Compensation for inertial and gravity effects in a moving force platform
SO JOURNAL OF BIOMECHANICS
AB Force plates for human movement analysis provide accurate measurements when mounted rigidly on an inertial reference frame. Large measurement errors occur, however, when the force plate is accelerated, or tilted relative to gravity. This prohibits the use of force plates in human perturbation studies with controlled surface movements, or in conditions where the foundation is moving or not sufficiently rigid. Here we present a linear model to predict the inertial and gravitational artifacts using accelerometer signals. The model is first calibrated with data collected from random movements of the unloaded system and then used to compensate for the errors in another trial. The method was tested experimentally on an instrumented force treadmill capable of dynamic mediolateral translation and sagittal pitch. The compensation was evaluated in five experimental conditions, including platform motions induced by actuators, by motor vibration, and by human ground reaction forces. In the test that included all sources of platform motion, the root-mean-square (RMS) errors were 39.0 N and 15.3 N m in force and moment, before compensation, and 1.6 N and 1.1 N m, after compensation. A sensitivity analysis was performed to determine the effect on estimating joint moments during human gait. Joint moment errors in hip, knee, and ankle were initially 53.80 N m, 32.69 N m, and 19.10 N m, and reduced to 1.67 N m, 1.37 N m, and 1.13 N m with our method. It was concluded that the compensation method can reduce the inertial and gravitational artifacts to an acceptable level for human gait analysis. (C) 2018 Elsevier Ltd. All rights reserved.
RI van den Bogert, Antonie J/A-7809-2009
OI van den Bogert, Antonie J/0000-0002-3791-3749
SN 0021-9290
EI 1873-2380
PD JUN 25
PY 2018
VL 75
BP 96
EP 101
DI 10.1016/j.jbiomech.2018.05.009
UT WOS:000437991500011
PM 29789150
ER

PT J
AU Jin, XW
   Cheng, P
   Chen, WL
   Li, H
AF Jin, Xiaowei
   Cheng, Peng
   Chen, Wen-Li
   Li, Hui
TI Prediction model of velocity field around circular cylinder over various
   Reynolds numbers by fusion convolutional neural networks based on
   pressure on the cylinder
SO PHYSICS OF FLUIDS
AB A data-driven model is proposed for the prediction of the velocity field around a cylinder by fusion convolutional neural networks (CNNs) using measurements of the pressure field on the cylinder. The model is based on the close relationship between the Reynolds stresses in the wake, the wake formation length, and the base pressure. Numerical simulations of flow around a cylinder at various Reynolds numbers are carried out to establish a dataset capturing the effect of the Reynolds number on various flow properties. The time series of pressure fluctuations on the cylinder is converted into a grid-like spatial-temporal topology to be handled as the input of a CNN. A CNN architecture composed of a fusion of paths with and without a pooling layer is designed. This architecture can capture both accurate spatial-temporal information and the features that are invariant of small translations in the temporal dimension of pressure fluctuations on the cylinder. The CNN is trained using the computational fluid dynamics (CFD) dataset to establish the mapping relationship between the pressure fluctuations on the cylinder and the velocity field around the cylinder. Adam (adaptive moment estimation), an efficient method for processing large-scale and high-dimensional machine learning problems, is employed to implement the optimization algorithm. The trained model is then tested over various Reynolds numbers. The predictions of this model are found to agree well with the CFD results, and the data-driven model successfully learns the underlying flow regimes, i.e., the relationship between wake structure and pressure experienced on the surface of a cylinder is well established. Published by AIP Publishing.
OI Chen, Wen-Li/0000-0002-7471-815X; Jin, Xiaowei/0000-0002-3075-1601; Hui,
   Li/0000-0001-9198-3951
SN 1070-6631
EI 1089-7666
PD APR
PY 2018
VL 30
IS 4
AR 047105
DI 10.1063/1.5024595
UT WOS:000431138700017
ER

PT J
AU Dooba, IM
   Downe, AG
AF Dooba, Ibraheem M.
   Downe, Alan G.
TI Extraction and translation of safety knowledge in organizations using
   incident reports
SO AFRICAN JOURNAL OF BUSINESS MANAGEMENT
AB The Incident Report-Based Safety Knowledge Transfer (IRSKT) model found in this paper identifies the elements necessary for social systems in workplaces to extract, disseminate and use new safety knowledge emanating from incident reports. The purpose of this paper is twofold: to understand how recent developments in systems thinking and materiality of knowledge can influence understanding of safety knowledge transfer (SKT); and to propose a new systems-based safety knowledge transfer model founded on incident reports. The paper is a review of the literature on safety knowledge transfer, materiality of knowledge and systems thinking; leading to the proposal of a new SKT paradigm. This paper shows that the IRSKT model is well suited to analyzing safety knowledge transfer in both complex and small-scale systems. Empirical studies in various systems (of complexity) environments will help affirm and enrich the model. The paper sees that in organizations where safety of employees is important, the ability to extract knowledge from incidents reports - which is an accessible and ready estimate of safety situations in organizations - is vital for establishing safe workplaces. The capacity for effective exchange and utilization of safety information inherent in incident reports by employees, equipment manufacturers, professional bodies and government agencies as reflected in IRSKT will inform the decisions to build in safety in machinery, better safety rules, effective safety campaigns and enhance safety conscious behaviours in organizations. The paper offers a new safety knowledge transfer paradigm that views safety knowledge as a systemic, emergent, embedded and materially entangled representation of reality. The proposed knowledge transfer model is different from earlier attempts, concentrating movement of safety information in incident reports and the significance stakeholders must attach to them to minimize both human and machine error.
SN 1993-8233
PD OCT 7
PY 2011
VL 5
IS 23
BP 9794
EP 9799
UT WOS:000296239700004
ER

PT J
AU Chelba, C
   Acero, A
AF Chelba, Ciprian
   Acero, Alex
TI Adaptation of maximum entropy capitalizer: Little data can help a lot
SO COMPUTER SPEECH AND LANGUAGE
AB A novel technique for maximum "a posteriori" (MAP) adaptation of maximum entropy (MaxEnt) and maximum entropy Markov models (MEMM) is presented.
   The technique is applied to the problem of automatically capitalizing uniformly cased text. Automatic capitalization is a practically relevant problem: speech recognition output needs to be capitalized; also, modern word processors perform capitalization among other text proofing algorithms such as spelling correction and grammar checking. Capitalization can be also used as a preprocessing step in named entity extraction or machine translation.
   A "background" capitalizer trained on 20 M words of Wall Street Journal (WSJ) text from 1987 is adapted to two Broadcast News (BN) test sets - one containing ABC Primetime Live text and the other NPR Morning News/CNN Morning Edition text - from 1996.
   The "in-domain" performance of the WSJ capitalizer is 45% better relative to the 1-gram baseline, when evaluated on a test set drawn from WSJ 1994. When evaluating on the mismatched "out-of-domain" test data, the 1-gram baseline is outperformed by 60% relative; the improvement brought by the adaptation technique using a very small amount of matched BN data - 25-70k words - is about 20-25% relative. Overall, automatic capitalization error rate of 1.4% is achieved on BN data.
   The performance gain obtained by employing our adaptation technique using a tiny amount of out-of-domain training data on top of the background data is striking: as little as 0.14 M words of in-domain data brings more improvement than using 10 times more background training data (from 2 M words to 20 M words). (c) 2005 Elsevier Ltd. All rights reserved.
SN 0885-2308
EI 1095-8363
PD OCT
PY 2006
VL 20
IS 4
BP 382
EP 399
DI 10.1016/j.csl.2005.05.005
UT WOS:000240727800002
ER

PT C
AU Ghiglio, P
   Dolinsky, U
   Goli, M
   Narasimhan, K
AF Ghiglio, Pietro
   Dolinsky, Uwe
   Goli, Mehdi
   Narasimhan, Kumudha
GP ACM
TI Improving performance of SYCL applications on CPU architectures using
   LLVM-directed compilation flow
SO PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL WORKSHOP ON PROGRAMMING
   MODELS AND APPLICATIONS FOR MULTICORES AND MANYCORES (PMAM '22)
CT 13th International Workshop on Programming Models and Applications for
   Multicores and Manycores (PMAM) part of PPoPP Conference
CY APR 02-06, 2022
CL Seoul, SOUTH KOREA
SP Assoc Comp Machinery, ACM SIGPLAN, ACM SIGHPC
AB The wide adoption of SYCL as an open-standard API for accelerating C++ software in domains such as HPC, Automotive, Artificial Intelligence, Machine Learning, and other areas necessitates efficient compiler and runtime support for a growing number of different platforms. Existing SYCL implementations provide support for various devices like CPUs, GPUs, DSPs, FPGAs, etc, typically via OpenCL or CUDA backends. While accelerators have increased the performance of user applications significantly, employing CPU devices for further performance improvement is beneficial due to the significant presence of CPUs in existing datacenters.
   SYCL applications on CPUs, currently go through an OpenCL backend. Though an OpenCL backend is valuable in supporting accelerators, it may introduce additional overhead for CPUs since the host and device are the same. Overheads like a run-time compilation of the kernel, transferring of input/output memory to/from the OpenCL device, invoking the OpenCL kernel, may not be necessary when running on the CPU. While some of these overheads (such as data transfer) can be avoided by modifying the application, it can introduce disparity in the SYCL application's ability to achieve performance portability on other devices.
   In this paper, we propose an alternate approach to running SYCL applications on CPUs. We bypass OpenCL and use a CPU-directed compilation flow, along with the integration of Whole Function Vectorization to generate optimized host and device code together in the same translation unit. We compare the performance of our approach - the CPU-directed compilation flow, with an OpenCL backend for existing SYCL-based applications, with no code modification. We run experiments across various CPU architectures to attest to the efficacy of our proposed approach.
OI Narasimhan, Kumudha/0000-0002-1142-3039
BN 978-1-4503-9339-3
PY 2022
BP 1
EP 10
DI 10.1145/3528425.3529099
UT WOS:000883489400001
ER

PT J
AU Lieslehto, J
   Jaaskelainen, E
   Kiviniemi, V
   Haapea, M
   Jones, PB
   Murray, GK
   Veijola, J
   Dannlowski, U
   Grotegerd, D
   Meinert, S
   Hahn, T
   Ruef, A
   Isohanni, M
   Falkai, P
   Miettunen, J
   Dwyer, DB
   Koutsouleris, N
AF Lieslehto, Johannes
   Jaaskelainen, Erika
   Kiviniemi, Vesa
   Haapea, Marianne
   Jones, Peter B.
   Murray, Graham K.
   Veijola, Juha
   Dannlowski, Udo
   Grotegerd, Dominik
   Meinert, Susanne
   Hahn, Tim
   Ruef, Anne
   Isohanni, Matti
   Falkai, Peter
   Miettunen, Jouko
   Dwyer, Dominic B.
   Koutsouleris, Nikolaos
TI The progression of disorder-specific brain pattern expression in
   schizophrenia over 9 years
SO NPJ SCHIZOPHRENIA
AB Age plays a crucial role in the performance of schizophrenia vs. controls (SZ-HC) neuroimaging-based machine learning (ML) models as the accuracy of identifying first-episode psychosis from controls is poor compared to chronic patients. Resolving whether this finding reflects longitudinal progression in a disorder-specific brain pattern or a systematic but non-disorder-specific deviation from a normal brain aging (BA) trajectory in schizophrenia would help the clinical translation of diagnostic ML models. We trained two ML models on structural MRI data: an SZ-HC model based on 70 schizophrenia patients and 74 controls and a BA model (based on 561 healthy individuals, age range = 66 years). We then investigated the two models' predictions in the naturalistic longitudinal Northern Finland Birth Cohort 1966 (NFBC1966) following 29 schizophrenia and 61 controls for nine years. The SZ-HC model's schizophrenia-specificity was further assessed by utilizing independent validation (62 schizophrenia, 95 controls) and depression samples (203 depression, 203 controls). We found better performance at the NFBC1966 follow-up (sensitivity = 75.9%, specificity = 83.6%) compared to the baseline (sensitivity = 58.6%, specificity = 86.9%). This finding resulted from progression in disorder-specific pattern expression in schizophrenia and was not explained by concomitant acceleration of brain aging. The disorder-specific pattern's progression reflected longitudinal changes in cognition, outcomes, and local brain changes, while BA captured treatment-related and global brain alterations. The SZ-HC model was also generalizable to independent schizophrenia validation samples but classified depression as control subjects. Our research underlines the importance of taking account of longitudinal progression in a disorder-specific pattern in schizophrenia when developing ML classifiers for different age groups.
RI Haapea, Marianne/I-3291-2016; Miettunen, Jouko/AAC-4334-2019; Dwyer,
   Dominic/Z-1225-2018
OI Haapea, Marianne/0000-0002-3989-9354; Miettunen,
   Jouko/0000-0003-0575-2669; Murray, Graham/0000-0001-8296-1742; Meinert,
   Susanne/0000-0003-2177-7161; Dwyer, Dominic/0000-0003-3949-5867; Jones,
   Peter Brian/0000-0002-0387-880X
EI 2334-265X
PD JUN 14
PY 2021
VL 7
IS 1
AR 32
DI 10.1038/s41537-021-00157-0
UT WOS:000661475900001
PM 34127678
ER

PT C
AU Dandekar, A
   Zen, RAM
   Bressan, S
AF Dandekar, Ashish
   Zen, Remmy A. M.
   Bressan, Stephane
BE Benslimane, D
   Damiani, E
   Grosky, WI
   Hameurlain, A
   Sheth, A
   Wagner, RR
TI Generating Fake but Realistic Headlines Using Deep Neural Networks
SO DATABASE AND EXPERT SYSTEMS APPLICATIONS, DEXA 2017, PT II
SE Lecture Notes in Computer Science
CT 28th International Conference on Database and Expert Systems
   Applications (DEXA)
CY AUG 28-31, 2017
CL Lyon, FRANCE
SP Jean Moulin Lyon 3 Univ, FAW Co, LIRIS Lab, Federat Informatique Lyon, Natl Ctr Sci Res, Agence Mathematiques Interact Avec Entreprise Soc, Claude Bernard Univ Lyon 1, Natl Inst Appl Sci Lyon, ERIC Lab, Univ Lyon, Univ Lumiere Lyon 2
AB Social media platforms such as Twitter and Facebook implement filters to detect fake news as they foresee their transition from social media platform to primary sources of news. The robustness of such filters lies in the variety and the quality of the data used to train them. There is, therefore, a need for a tool that automatically generates fake but realistic news.
   In this paper, we propose a deep learning model that automatically generates news headlines. The model is trained with a corpus of existing headlines from different topics. Once trained, the model generates a fake but realistic headline given a seed and a topic. For example, given the seed "Kim Jong Un" and the topic "Business", the model generates the headline "kim jong un says climate change is already making money".
   In order to better capture and leverage the syntactic structure of the headlines for the task of synthetic headline generation, we extend the architecture - Contextual Long Short Term Memory, proposed by Ghosh et al. - to also learn a part-of-speech model. We empirically and comparatively evaluate the performance of the proposed model on a real corpora of headlines. We compare our proposed approach and its variants using Long Short Term Memory and Gated Recurrent Units as the building blocks. We evaluate and compare the topical coherence of the generated headlines using a state-of-the-art classifier. We, also, evaluate the quality of the generated headline using a machine translation quality metric and its novelty using a metric we propose for this purpose. We show that the proposed model is practical and competitively efficient and effective.
SN 0302-9743
EI 1611-3349
BN 978-3-319-64471-4
PY 2017
VL 10439
BP 427
EP 440
DI 10.1007/978-3-319-64471-4_34
UT WOS:000452448100034
ER

PT J
AU Vij, R
   Arora, S
AF Vij, Richa
   Arora, Sakshi
TI A systematic survey of advances in retinal imaging modalities for
   Alzheimer's disease diagnosis
SO METABOLIC BRAIN DISEASE
AB Recent advances in retinal imaging pathophysiology have shown a new function for biomarkers in Alzheimer's disease diagnosis and prognosis. The significant improvements in Optical coherence tomography (OCT) retinal imaging have led to significant clinical translation, particularly in Alzheimer's disease detection. This systematic review will provide a comprehensive overview of retinal imaging in clinical applications, with a special focus on biomarker analysis for use in Alzheimer's disease detection. Articles on OCT retinal imaging in Alzheimer's disease diagnosis were identified in PubMed, Google Scholar, IEEE Xplore, and Research Gate databases until March 2021. Those studies using simultaneous retinal imaging acquisition were chosen, while those using sequential techniques were rejected. "Alzheimer's disease" and "Dementia" were searched alone and in combination with "OCT" and "retinal imaging". Approximately 1000 publications were searched, and after deleting duplicate articles, 145 relevant studies focused on the diagnosis of Alzheimer's disease utilizing retinal imaging were chosen for study. OCT has recently been demonstrated to be a valuable technique in clinical practice as according to this survey, 57% of the researchers employed optical coherence tomography, 19% used ocular fundus imaging, 13% used scanning laser ophthalmoscopy, and 11% have used multimodal imaging to diagnose Alzheimer disease. Retinal imaging has become an important diagnostic technique for Alzheimer's disease. Given the scarcity of available literature, it is clear that future prospective trials involving larger and more homogeneous groups are necessary, and the work can be expanded by evaluating its significance utilizing a machine-learning platform rather than simply using statistical methodologies.
SN 0885-7490
EI 1573-7365
PD OCT
PY 2022
VL 37
IS 7
BP 2213
EP 2243
DI 10.1007/s11011-022-00927-4
EA MAR 2022
UT WOS:000769329400001
PM 35290546
ER

PT J
AU Wang, RL
   Wang, Z
   Li, ZY
   Lee, TY
AF Wang, Rulan
   Wang, Zhuo
   Li, Zhongyan
   Lee, Tzong-Yi
TI Residue-Residue Contact Can Be a Potential Feature for the Prediction of
   Lysine Crotonylation Sites
SO FRONTIERS IN GENETICS
AB Lysine crotonylation (Kcr) is involved in plenty of activities in the human body. Various technologies have been developed for Kcr prediction. Sequence-based features are typically adopted in existing methods, in which only linearly neighboring amino acid composition was considered. However, modified Kcr sites are neighbored by not only the linear-neighboring amino acid but also those spatially surrounding residues around the target site. In this paper, we have used residue-residue contact as a new feature for Kcr prediction, in which features encoded with not only linearly surrounding residues but also those spatially nearby the target site. Then, the spatial-surrounding residue was used as a new scheme for feature encoding for the first time, named residue-residue composition (RRC) and residue-residue pair composition (RRPC), which were used in supervised learning classification for Kcr prediction. As the result suggests, RRC and RRPC have achieved the best performance of RRC at an accuracy of 0.77 and an area under curve (AUC) value of 0.78, RRPC at an accuracy of 0.74, and an AUC value of 0.80. In order to show that the spatial feature is of a competitively high significance as other sequence-based features, feature selection was carried on those sequence-based features together with feature RRPC. In addition, different ranges of the surrounding amino acid compositions' radii were used for comparison of the performance. After result assessment, RRC and RRPC features have shown competitively outstanding performance as others or in some cases even around 0.20 higher in accuracy or 0.3 higher in AUC values compared with sequence-based features.
EI 1664-8021
PD JAN 4
PY 2022
VL 12
AR 788467
DI 10.3389/fgene.2021.788467
UT WOS:000745711900001
PM 35058968
ER

PT J
AU Siontis, GCM
   Sweda, R
   Noseworthy, PA
   Friedman, PA
   Siontis, KC
   Patel, CJ
AF Siontis, George C. M.
   Sweda, Romy
   Noseworthy, Peter A.
   Friedman, Paul A.
   Siontis, Konstantinos C.
   Patel, Chirag J.
TI Development and validation pathways of artificial intelligence tools
   evaluated in randomised clinical trials
SO BMJ HEALTH & CARE INFORMATICS
AB Objective Given the complexities of testing the translational capability of new artificial intelligence (AI) tools, we aimed to map the pathways of training/validation/testing in development process and external validation of AI tools evaluated in dedicated randomised controlled trials (AI-RCTs). Methods We searched for peer-reviewed protocols and completed AI-RCTs evaluating the clinical effectiveness of AI tools and identified development and validation studies of AI tools. We collected detailed information, and evaluated patterns of development and external validation of AI tools. Results We found 23 AI-RCTs evaluating the clinical impact of 18 unique AI tools (2009-2021). Standard-of-care interventions were used in the control arms in all but one AI-RCT. Investigators did not provide access to the software code of the AI tool in any of the studies. Considering the primary outcome, the results were in favour of the AI intervention in 82% of the completed AI-RCTs (14 out of 17). We identified significant variation in the patterns of development, external validation and clinical evaluation approaches among different AI tools. A published development study was found only for 10 of the 18 AI tools. Median time from the publication of a development study to the respective AI-RCT was 1.4 years (IQR 0.2-2.2). Conclusions We found significant variation in the patterns of development and validation for AI tools before their evaluation in dedicated AI-RCTs. Published peer-reviewed protocols and completed AI-RCTs were also heterogeneous in design and reporting. Upcoming guidelines providing guidance for the development and clinical translation process aim to improve these aspects.
OI Siontis, George/0000-0003-2128-9205
EI 2632-1009
PD DEC
PY 2021
VL 28
IS 1
AR e100466
DI 10.1136/bmjhci-2021-100466
UT WOS:000736695500001
PM 34969668
ER

PT J
AU Philipsen, MP
   Moeslund, TB
AF Philipsen, Mark P.
   Moeslund, Thomas B.
TI Cutting Pose Prediction from Point Clouds
SO SENSORS
AB The challenge of getting machines to understand and interact with natural objects is encountered in important areas such as medicine, agriculture, and, in our case, slaughterhouse automation. Recent breakthroughs have enabled the application of Deep Neural Networks (DNN) directly to point clouds, an efficient and natural representation of 3D objects. The potential of these methods has mostly been demonstrated for classification and segmentation tasks involving rigid man-made objects. We present a method, based on the successful PointNet architecture, for learning to regress correct tool placement from human demonstrations, using virtual reality. Our method is applied to a challenging slaughterhouse cutting task, which requires an understanding of the local geometry including the shape, size, and orientation. We propose an intermediate five-Degree of Freedom (DoF) cutting plane representation, a point and a normal vector, which eases the demonstration and learning process. A live experiment is conducted in order to unveil issues and begin to understand the required accuracy. Eleven cuts are rated by an expert, with 8/11 being rated as acceptable. The error on the test set is subsequently reduced through the addition of more training data and improvements to the DNN. The result is a reduction in the average translation from 1.5 cm to 0.8 cm and the orientation error from 4.59 degrees to 4.48 degrees. The method's generalization capacity is assessed on a similar task from the slaughterhouse and on the very different public LINEMOD dataset for object pose estimation across view points. In both cases, the method shows promising results. Code, datasets, and other materials are available in Supplementary Materials.
OI Moeslund, Thomas B./0000-0001-7584-5209
EI 1424-8220
PD MAR
PY 2020
VL 20
IS 6
AR 1563
DI 10.3390/s20061563
UT WOS:000529139700022
PM 32168888
ER

PT J
AU Lin, YC
   Mhuircheartaigh, JN
   Cheung, YC
   Juan, YH
   Chiu, CH
   Yeh, WL
   Wu, JS
AF Lin, Y. -C.
   Mhuircheartaigh, J. N.
   Cheung, Y. -C.
   Juan, Y. -H.
   Chiu, C. -H.
   Yeh, W. -L.
   Wu, J. S.
TI Pain following double-bundle anterior cruciate ligament reconstruction:
   Correlation with morphological graft findings and dynamic
   contrast-enhanced MRI
SO CLINICAL RADIOLOGY
AB AIM: To determine the relationship between knee pain following anterior cruciate ligament (ACL) graft placement with morphological graft findings and dynamic contrast enhancement as assessed at MRI.
   MATERIAL AND METHODS: Following institutional review board approval, 37 consecutive patients with double-bundle ACL reconstruction were enrolled. Thirteen patients had pain and 24 were asymptomatic. Imaging was performed using a 1.5 T MRI machine an average of 7.6 months after surgery. Graft-related (increase signal intensity, abnormal orientation, discontinuity, cystic degeneration, anterior translation of lateral tibia, arthrofibrosis), and non-graft related causes of knee pain (meniscal tear, cartilage injury, loose bodies, and synovitis) were evaluated. During dynamic contrast enhancement analysis, peak enhancement (ePeak) was calculated by placing a region of interest at the osteoligamentous interface of each bundle. Student's t-test was used for continuous variables analysis and chi-square or Fisher's exact test was used for categorical variables analysis.
   RESULTS: There was no difference between symptomatic and asymptomatic patients regarding morphological graft-related or non-graft-related causes of knee pain. For dynamic contrast enhancement analysis, symptomatic patients had significantly lower ePeak values than asymptomatic patients in the anteromedial (p = 0.008) and posterolateral (p = 0.001) bundles or when using the higher ePeak value in either bundle (p = 0.003).
   CONCLUSION: Morphological ACL graft findings as assessed at MRI could not be used to distinguish between symptomatic and asymptomatic patients. However, lower ePeak values had a significant association with knee pain. This may indicate poor neovascularization of the graft, potentially leading to graft failure. (C) 2014 The Royal College of Radiologists. Published by Elsevier Ltd. All rights reserved.
RI Wu, JIm S/AAQ-3416-2021; Ni Mhuircheartaigh, Jennifer/ABA-9473-2021; Ni
   Mhuircheartaigh, Jennifer/ABA-9477-2021
OI Ni Mhuircheartaigh, Jennifer/0000-0001-7300-6575
SN 0009-9260
EI 1365-229X
PD NOV
PY 2014
VL 69
IS 11
BP 1142
EP 1148
DI 10.1016/j.crad.2014.06.018
UT WOS:000345881900008
PM 25060934
ER

PT J
AU Cosme, RSC
   Yamamura, Y
   Tang, QY
AF Cosme, Ruth S. Cruz
   Yamamura, Yasuhiro
   Tang, Qiyi
TI Roles of Polypyrimidine Tract Binding Proteins in Major Immediate-Early
   Gene Expression and Viral Replication of Human Cytomegalovirus
SO JOURNAL OF VIROLOGY
AB Human cytomegalovirus (HCMV), a member of the beta subgroup of the family Herpesviridae, causes serious health problems worldwide. HCMV gene expression in host cells is a well-defined sequential process: immediate-early (IE) gene expression, early-gene expression, DNA replication, and late-gene expression. The most abundant IE gene, major IE (MIE) gene pre-mRNA, needs to be spliced before being exported to the cytoplasm for translation. In this study, the regulation of MIE gene splicing was investigated; in so doing, we found that polypyrimidine tract binding proteins (PTBs) strongly repressed MIE gene production in cotransfection assays. In addition, we discovered that the repressive effects of PTB could be rescued by splicing factor U2AF. Taken together, the results suggest that PTBs inhibit MIE gene splicing by competing with U2AF65 for binding to the polypyrimidine tract in pre-mRNA. In intron deletion mutation assays and RNA detection experiments (reverse transcription [RT]-PCR and real-time RT-PCR), we further observed that PTBs target all the introns of the MIE gene, especially intron 2, and affect gene splicing, which was reflected in the variation in the ratio of pre-mRNA to mRNA. Using transfection assays, we demonstrated that PTB knockdown cells induce a higher degree of MIE gene splicing/expression. Consistently, HCMV can produce more viral proteins and viral particles in PTB knockdown cells after infection. We conclude that PTB inhibits HCMV replication by interfering with MIE gene splicing through competition with U2AF for binding to the polypyrimidine tract in MIE gene introns.
RI Kim, Seongman/N-6910-2014
SN 0022-538X
EI 1098-5514
PD APR
PY 2009
VL 83
IS 7
BP 2839
EP 2850
DI 10.1128/JVI.02407-08
UT WOS:000264046000005
PM 19144709
ER

PT J
AU Mohamood, F
   Ghosh, M
   Lee, HHS
AF Mohamood, Fayez
   Ghosh, Mrinmoy
   Lee, Hsien-Hsin S.
TI DLL-conscious instruction fetch optimization for SMT processors
SO JOURNAL OF SYSTEMS ARCHITECTURE
AB Simultaneous multithreading (SMT) processors can issue Multiple instructions from distinct processes or threads in the same cycle. This technique effectively increases the overall throughput by keeping the pipeline resources more Occupied at the potential expense of reducing single thread performance due to resource sharing. In the software domain, in increasing number of dynamically linked libraries (DLL) are used by applications and operating systems, providing better flexibility and modularity, and enabling code sharing. It is observed that a Significant amount Of execution time in software today is spent in executing standard DLL instructions, that are shared among Multiple threads or processes. However, for an SMT processor with a virtually-indexed cache implementation, existing instruction fetching mechanisms can induce unnecessary false I-TLB and I-Cache misses caused by the DLL-based instructions that are intended to be shared. This problem is more prominent when multiple independent threads are executing Concurrently oil an SMT processor.
   In this work, we investigate a neglected form of contention between running threads in the I-TLB and Cache (including both VIVT and VIPT) due to DLLs. To address these shortcomings, we propose a system level technique involving a light-weight modification in the microarchitecture and the OS. By exploiting the nature of the DLLs in Our optimized system, we can reinstate the intended sharing of the DLLs in an SMT machine. Using Microsoft Windows based applications, our simulation results show that the optimized instruction fetching mechanism can reduce the number of DLL misses up to 5.5 times and improve the instruction cache hit rates by up to 62%, resulting in up to 30% DLL IPC improvements and up to 15% overall IPC improvements. (c) 2008 Elsevier B.V. All Lights reserved.
RI Lee, Hsien-Hsin S./AAI-4932-2020
SN 1383-7621
EI 1873-6165
PD NOV
PY 2008
VL 54
IS 12
BP 1089
EP 1100
DI 10.1016/j.sysarc.2008.04.014
UT WOS:000261307000002
ER

PT J
AU Fontanesi, F
   Soto, IC
   Horn, D
   Barrientos, A
AF Fontanesi, Flavia
   Soto, Ileana C.
   Horn, Darryl
   Barrientos, Antoni
TI Assembly of mitochondrial cytochrome c-oxidase, a complicated and highly
   regulated cellular process
SO AMERICAN JOURNAL OF PHYSIOLOGY-CELL PHYSIOLOGY
AB Cytochrome c-oxidase (COX), the terminal enzyme of the mitochondrial respiratory chain, plays a key role in the regulation of aerobic production of energy. Biogenesis of eukaryotic COX involves the coordinated action of two genomes. Three mitochondrial DNA-encoded subunits form the catalytic core of the enzyme, which contains metal prosthetic groups. Another 10 subunits encoded in the nuclear DNA act as a protective shield surrounding the core. COX biogenesis requires the assistance of > 20 additional nuclear-encoded factors acting at all levels of the process. Expression of the mitochondrial-encoded subunits, expression and import of the nuclear-encoded subunits, insertion of the structural subunits into the mitochondrial inner membrane, addition of prosthetic groups, assembly of the holoenzyme, further maturation to form a dimer, and additional assembly into supercomplexes are all tightly regulated processes in a nuclear-mitochondrial-coordinated fashion. Such regulation ensures the building of a highly efficient machine able to catalyze the safe transfer of electrons from cytochrome c to molecular oxygen and ultimately facilitate the aerobic production of ATP. In this review, we will focus on describing and analyzing the present knowledge about the different regulatory checkpoints in COX assembly and the dynamic relationships between the different factors involved in the process. We have used information mostly obtained from the suitable yeast model, but also from bacterial and animal systems, by means of large-scale genetic, molecular biology, and physiological approaches and by integrating information concerning individual elements into a cellular system network.
OI Fontanesi, Flavia/0000-0003-0509-3835; Soto, Iliana/0000-0002-8499-6081
SN 0363-6143
EI 1522-1563
PD DEC
PY 2006
VL 291
IS 6
BP C1129
EP C1147
DI 10.1152/ajpcell.00233.2006
UT WOS:000241992000006
PM 16760263
ER

PT C
AU Iftekharuddin, KM
   Shaik, JS
AF Iftekharuddin, KM
   Shaik, JS
BE Iftekharuddin, KM
   Awwal, AAS
TI Distorted IR target detection and tracking using composite filters
SO PHOTONIC DEVICES AND ALGORITHMS FOR COMPUTING V
SE PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)
CT Conference on Photonic Devices and Algorithms for Computing V
CY AUG 06-07, 2003
CL SAN DIEGO, CA
SP SPIE
AB The automatic target recognition (ATR), often time, is limited by the presence of background clutter and distortions such as scale, translation and rotation (both in-plane and out-of-plane) in both single and multi object cases. Such distortion invariant ATR and image understanding have been the subject of intense research in machine vision. In a previous work, we have demonstrated the usefulness of an amplitude-coupled minimum-average correlation energy (AC-MACE) filter in in-plane rotated SAR image ATR. The AC-MACE filter outperforms the regular MACE filter in rotation-related cases. Motion tracking is also an important task in computer vision, especially, when objects are subjected to certain viewing transformation. There are many problems in which very small objects undergoing motion must be detected and then tracked. For example, one of the most difficult goals of ATR is to spot incoming objects at long range, wherein the motion appears small and the signal to noise ratio (SNR) is poor. The system must be able to track such targets long enough to identify whether the object is a friend or foe. In this work, we are interested in locating both long-range and short-range moving objects in IR images wherein the object may vary from a few pixels in size to a large number of pixels in a sequence of IR images. The targets are submerged in background noise and clutter. Additionally, the tracking problem also involves out-of-plane rotation of the target. Thus, we investigate both MACE and AC-MACE filter for rotation and size invariant target detection and tracking using realistic IR images.
RI Iftekharuddin, Khan/AAT-5217-2020
OI Iftekharuddin, Khan/0000-0001-8316-4163
SN 0277-786X
BN 0-8194-5074-X
PY 2003
VL 5201
BP 73
EP 84
DI 10.1117/12.503885
UT WOS:000188420500009
ER

PT J
AU Miriami, E
   Motro, U
   Sperling, J
   Sperling, R
AF Miriami, E
   Motro, U
   Sperling, J
   Sperling, R
TI Conservation of an open-reading frame as an element affecting 5 ' splice
   site selection
SO JOURNAL OF STRUCTURAL BIOLOGY
CT EMBO Workshop on Functional Organization of the Cell Nucleus
CY APR 18-21, 2002
CL PRAGUE, CZECH REPUBLIC
SP EMBO
AB Splice site selection is a key element of pre-mRNA splicing and involves specific recognition of consensus sequences at the 5' and 3' splice sites. Evidently, the compliance of a given sequence with the consensus 5' splice site sequence is not sufficient to define it as a functional 5' splice site, because not all sequences that conform with the consensus are used for splicing. We have previously hypothesized that the necessity to avoid the inclusion of premature termination codons within mature mRNAs may serve as a criterion that differentiates normal 5' splice sites from unused (latent) ones. We further provided experimental support to this idea, by analyzing the splicing of pre-mRNAs in which in-frame stop codons upstream of a latent 5' splice site were mutated, and showing that splicing using the latent site is indeed activated by such mutations. Here we evaluate this hypothesis by a computerized survey for latent 5' splice sites in 446 protein-coding human genes. This data set contains 2311 introns, in which we found 10 490 latent 5' splice sites. The utilization of 10 045 (95.8%) of these sites for splicing would have led to the inclusion of an in-frame stop codon within the resultant mRNA. The validity of this finding is confirmed here by statistical analyses. This finding, together with our previous experimental results, invokes a nuclear scanning mechanism, as part of the splicing machine, which identifies in-frame stop codons within the pre-mRNA and prevents splicing that could lead to the formation of a prematurely terminated protein. (C) 2002 Elsevier Science (USA). All rights reserved.
SN 1047-8477
EI 1095-8657
PD OCT-DEC
PY 2002
VL 140
IS 1-3
BP 116
EP 122
AR PII S1047-8477(02)00539-7
DI 10.1016/S1047-8477(02)00539-7
UT WOS:000179957700013
PM 12490159
ER

PT J
AU Pais, S
   Cordeiro, J
   Jamil, ML
AF Pais, Sebastiao
   Cordeiro, Joao
   Jamil, M. Luqman
TI NLP-based platform as a service: a brief review
SO JOURNAL OF BIG DATA
AB Natural language processing (NLP) refers to the field of study that focuses on the interactions between human language and computers. It has recently gained much attention for analyzing human language computationally and has spread its applications for various tasks such as machine translation, information extraction, summarization, question answering, and others. With the rapid growth of cloud computing services, merging NLP in the cloud is a significant benefit. It allows researchers to conduct NLP-related experiments on large amounts of data handled by big data techniques while harnessing the cloud's vast, on-demand computing power. However, it has not sufficiently spread its tools and applications as a service in the cloud and there is little literature available that discusses the scope of interdisciplinary work. NLP, cloud Computing, and big data are vast domains and contain their challenges and potentials. By overcoming those challenges and integrating these fields, great potential for NLP and its applications can be unleashed. This paper presents a survey of NLP in cloud computing with a key focus on the comparison of cloud-based NLP services, challenges of NLP and big data while emphasizing the necessity of viable cloud-based NLP services. In the first part of this paper, an overview of NLP is presented by discussing different levels of NLP and components of natural language generation (NLG), followed by the applications of NLP. In the second part, the concept of cloud computing is discussed that highlights the architectural layers and deployment models of cloud computing and cloud-hosted NLP services. In the third part, the field of big data in the cloud is discussed with an emphasis on NLP. Furthermore, information extraction via NLP techniques within big data is introduced.
RI Pais, Sebastião/J-4766-2017
OI Pais, Sebastião/0000-0003-2337-0779; Cordeiro, Joao
   Paulo/0000-0003-0466-1618; Jamil, Muhammad Luqman/0000-0003-3786-0744
EI 2196-1115
PD APR 28
PY 2022
VL 9
IS 1
AR 54
DI 10.1186/s40537-022-00603-5
UT WOS:000788586500008
ER

PT J
AU Vaezi, M
   Pishkenari, HN
   Nemati, A
AF Vaezi, Mehran
   Pishkenari, Hossein Nejat
   Nemati, Alireza
TI Mechanism of the motion of nanovehicles on hexagonal boron-nitride: A
   molecular dynamics study
SO COMPUTATIONAL MATERIALS SCIENCE
AB Nanocars have been proposed to transport nanomaterials on the surface. Study of the mechanism of the motion of nanocars has attracted a lot of interests due to the potential ability of these nano-vehicles in the construction of nanostructures with bottom-up approach. Using molecular dynamics simulations, we study the motion of two nano-vehicles named "Nanocar" and "Nanotruck" on hexagonal boron-nitride monolayer. The obtained results reveals that, boron-nitride is an appropriate option to obtain higher mobility of nanocars compared with metal substrates. Considering different temperatures reveals that nanocars start to move on the BN at 200 K, while long range motions are observed at 400 K and higher temperatures. The flexibility of Nanocar chassis wastes a portion of its energy and reduces its displacement range. The anomaly parameters show that C60, Nanocar and Nano truck experience super-diffusive regime at 100 K and higher temperatures. Using diffusion coefficient and activation energy, rotational motion of the nanocars is evaluated. To accurately investigate the mechanism of nanocars motion, we find rotation of the wheels around their axles and the speed of Nanotruck in directions parallel and perpendicular to the chassis. The mentioned parameters indicate that wheel rolling mechanism is the minority mode of the nanocars motion and the translations commonly occur through sliding. At low temperatures, two stable configurations are found for the Nanocar, and reconfiguration is energetically possible at 200 K and higher temperatures. The results presented in this work are expected to facilitate the fabrication of nano structures using molecular machines.
OI Vaezi, Mehran/0000-0002-7422-3026; Nejat Pishkenari,
   Hossein/0000-0002-3487-3198
SN 0927-0256
EI 1879-0801
PD MAY
PY 2022
VL 207
AR 111317
DI 10.1016/j.commatsci.2022.111317
EA MAR 2022
UT WOS:000789987900001
ER

PT J
AU Hu, X
   Jiang, SY
   Xu, FF
   Zeng, C
   Wang, XX
   Liu, W
   Cheng, AM
   Ma, CY
   Gao, N
   Zhao, YY
   Dai, JB
   Zhao, GH
AF Hu, Xin
   Jiang, Shuangying
   Xu, Feifei
   Zeng, Cheng
   Wang, Xiangxiang
   Liu, Wei
   Cheng, Aimin
   Ma, Chengying
   Gao, Ning
   Zhao, Yuyu
   Dai, Junbiao
   Zhao, Guanghou
TI Engineering and functional analysis of yeast with a monotypic 40S
   ribosome subunit
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
AB Emerging evidence reveals that ribosomes are not monolithic but dynamic machines with heterogeneous protein compositions that can reshape ribosomal translational abilities and cellular adaptation to environmental changes. Duplications of ribosomal protein (RP) genes are ubiquitous among organisms and are believed to affect cell function through paralog-specific regulation (e.g., by generating heterogeneous ribosomes) and/or gene dose amplification. However, direct evaluations of their impacts on cell function remain elusive due to the highly heterogeneous cellular RP pool. Here, we engineered a yeast with homogeneous 40S RP paralog compositions, designated homo-40S, by deleting the entire set of alternative duplicated genes encoding yeast 40S RP paralogs. Homo-40S displayed mild growth defects along with high sensitivity to the translation inhibitor paromomycin and a significantly increased stop codon readthrough. Moreover, doubling of the remaining RP paralogous genes in homo-40S rescued these phenotypes markedly, although not fully, compared to the wild-type phenotype, indicating that the dose of 40S RP genes together with the heterogeneity of the contents was vital for maintaining normal translational functionalities and growth robustness. Additional experiments revealed that homo-40S improved paromomycin tolerance via acquisition of bypass mutations or evolved to be diploid to generate fast-growing derivatives, highlighting the mutational robustness of engineered yeast to accommodate environmental and genetic changes. In summary, our work demonstrated that duplicated RP paralogs impart robustness and phenotypic plasticity through both gene dose amplification and paralog-specific regulation, paving the way for the direct study of ribosome biology through monotypic ribosomes with a homogeneous composition of specific RP paralogs.
RI Zhao, Guanghou/GPF-3341-2022; Gao, Ning/J-9623-2012
OI Gao, Ning/0000-0003-3067-9993; Jiang, Shuangying/0000-0002-6786-6533;
   Zeng, Cheng/0000-0002-4499-5076
SN 0027-8424
EI 1091-6490
PD FEB 8
PY 2022
VL 119
IS 6
AR e2114445119
DI 10.1073/pnas.2114445119
UT WOS:000758482900009
PM 35105807
ER

PT C
AU Lustig, D
   Cooksey, S
   Giroux, O
AF Lustig, Daniel
   Cooksey, Simon
   Giroux, Olivier
GP ACM
TI Mixed-Proxy Extensions for the NVIDIA PTX Memory Consistency Model
SO PROCEEDINGS OF THE 2022 THE 49TH ANNUAL INTERNATIONAL SYMPOSIUM ON
   COMPUTER ARCHITECTURE (ISCA '22)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
CT 49th IEEE/ACM Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 18-22, 2022
CL New York, NY
SP Assoc Comp Machinery, ACM SIGARCH, IEEE, Meta, FutureWei Technologies, AMD, Google, Microsoft, SK Hynix, Intel, ARM, IBM, Samsung, Vmware, Hewlett Packard Enterprise, IEEE Comp Soc Tech Comm Comp Architecture
AB In recent years, there has been a trend towards the use of accelerators and architectural specialization to continue scaling performance in spite of a slowing of Moore's Law. GPUs have always relied on dedicated hardware for graphics workloads, but modern GPUs now also incorporate compute-domain accelerators such as NVIDIA's Tensor Cores for machine learning. For these accelerators to be successfully integrated into a general-purpose programming language such as C++ or CUDA, there must be a forward- and backward-compatible API for the functionality they provide. To the extent that all of these accelerators interact with program threads through memory, they should be incorporated into the GPU's memory consistency model. Unfortunately, the use of accelerators and/or special non-coherent paths into memory produces non-standard memory behavior that existing GPU memory models cannot capture.
   In this work, we describe the "proxy" extensions added to version 7.5 of NVIDIA's PTX ISA for GPUs. A proxy is an extra tag abstractly applied to every memory or fence operation. Proxies generalize the notion of address translation and specialized non-coherent cache hierarchies into an abstraction that cleanly describes the resulting non-standard behavior. The goal of proxies is to facilitate integration of these specialized memory accesses into the general-purpose PTX programming model in a fully composable manner. This paper characterizes the behaviors that proxies can capture, the microarchitectural intuition behind them, the necessary updates to the formal memory model, and the tooling that we built in order to ensure that the resulting model both is sound and meets the needs of business-critical workloads that they are designed to support.
SN 1063-6897
BN 978-1-4503-8610-4
PY 2022
BP 1058
EP 1070
DI 10.1145/3470496.3533045
UT WOS:000852702500073
ER

PT J
AU Rakhra, M
   Singh, R
   Lohani, TK
   Shabaz, M
AF Rakhra, Manik
   Singh, Ramandeep
   Lohani, Tarun Kumar
   Shabaz, Mohammad
TI Metaheuristic and Machine Learning-Based Smart Engine for Renting and
   Sharing of Agriculture Equipment
SO MATHEMATICAL PROBLEMS IN ENGINEERING
AB Recently, many companies have substituted human labor with robotics. Some farmers are sharing different perspectives on the incorporation of technology into farming techniques. Some are willing to accept the technology, some are hesitant and bemused to adapt modern technology, and others are uncertain and are worried about the potential of technology to cause havoc and decrease yields. The third group prevails the most in the developed world, for lack of know-how, including translation of utility and, most significantly, the expense involved. A special Smart Tillage platform is established to solve the above issues. A smart-engine-based decision has been developed, which further uses classification and regression trees to shift towards decision-making. The decision is focused entirely on different input factors, such as type of crop, time/month of harvest, type of plant required for the crop, type of harvest, and authorised rental budget. Sitting on top of this would be a recommendation engine that is powered by deep learning network to suggest the escalation of a farmer from lower to higher category, namely, small to medium to large. A metaheuristic is one of the best computing techniques that help for solving a problem without the exhaustive application of a procedure. Recommendations will be cost-effective and suitable for an escalating update depending on the use of sufficient amends, practices, and services. We carried out a study of 562 agriculturists. Owing to the failure to buy modern equipment, growers are flooded by debt. We question if customers will be able to rent and exchange appliances. The farmers would be able to use e-marketplace to develop their activities.
RI LOHANI, TARUN KUMAR/AAK-1392-2021; Shabaz, Mohammad/ABD-1068-2020;
   Shabaz, Mohammad/AAB-3168-2020
OI LOHANI, TARUN KUMAR/0000-0003-4804-9711; Shabaz,
   Mohammad/0000-0001-5106-7609; rakhra, manik/0000-0003-1680-6992; Singh,
   Ramandeep/0000-0001-5775-7993
SN 1024-123X
EI 1563-5147
PD FEB 28
PY 2021
VL 2021
AR 5561065
DI 10.1155/2021/5561065
UT WOS:000627389000011
ER

PT J
AU Qin, N
   Liang, KW
   Huang, DQ
   Ma, L
   Kemp, AH
AF Qin, Na
   Liang, Kaiwei
   Huang, Deqing
   Ma, Lei
   Kemp, Andrew H.
TI Multiple Convolutional Recurrent Neural Networks for Fault
   Identification and Performance Degradation Evaluation of High-Speed
   Train Bogie
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
AB As an important part of high-speed train (HST), the mechanical performance of bogies imposes a direct impact on the safety and reliability of HST. It is a fact that, regardless of the potential mechanical performance degradation status, most existing fault diagnosis methods focus only on the identification of bogie fault types. However, for application scenarios such as auxiliary maintenance, identifying the performance degradation of bogie is critical in determining a particular maintenance strategy. In this article, by considering the intrinsic link between fault type and performance degradation of bogie, a novel multiple convolutional recurrent neural network (M-CRNN) that consists of two CRNN frameworks is proposed for simultaneous diagnosis of fault type and performance degradation state. Specifically, the CRNN framework 1 is designed to detect the fault types of the bogie. Meanwhile, CRNN framework 2, which is formed by CRNN Framework 1 and an RNN module, is adopted to further extract the features of fault performance degradation. It is worth highlighting that M-CRNN extends the structure of traditional neural networks and makes full use of the temporal correlation of performance degradation and model fault types. The effectiveness of the proposed M-CRNN algorithm is tested via the HST model CRH380A at different running speeds, including 160, 200, and 220 km/h. The overall accuracy of M-CRNN, i.e., the product of the accuracies for identifying the fault types and evaluating the fault performance degradation, is beyond 94.6% in all cases. This clearly demonstrates the potential applicability of the proposed method for multiple fault diagnosis tasks of HST bogie system.
OI ma, lei/0000-0002-0906-3978
SN 2162-237X
EI 2162-2388
PD DEC
PY 2020
VL 31
IS 12
BP 5363
EP 5376
DI 10.1109/TNNLS.2020.2966744
UT WOS:000595533300026
PM 32054588
ER

PT J
AU Shuang, K
   Li, R
   Gu, MY
   Loo, J
   Su, S
AF Shuang, Kai
   Li, Rui
   Gu, Mengyu
   Loo, Jonathan
   Su, Sen
TI Major-Minor Long Short-Term Memory for Word-Level Language Model
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
AB Language model (LM) plays an important role in natural language processing (NLP) systems, such as machine translation, speech recognition, learning token embeddings, natural language generation, and text classification. Recently, the multilayer long short-term memory (LSTM) models have been demonstrated to achieve promising performance on word-level language modeling. For each LSTM layer, larger hidden size usually means more diverse semantic features, which enables the LM to perform better. However, we have observed that when a certain LSTM layer reaches a sufficiently large scale, the promotion of overall effect will slow down, as its hidden size increases. In this article, we analyze that an important factor leading to this phenomenon is the high correlation between the newly extended hidden states and the original hidden states, which hinders diverse feature expression of the LSTM. As a result, when the scale is large enough, simply lengthening the LSTM hidden states will cost tremendous extra parameters but has little effect. We propose a simple yet effective improvement on each LSTM layer consisting of a large-scale Major LSTM and a small-scale Minor LSTM to break the high correlation between the two parts of hidden states, which we call Major-Minor LSTMs (MMLSTMs). In experiments, we demonstrate the LM with MMLSTMs surpasses the existing state-of-the-art model on Penn Treebank (PTB) and WikiText-2 (WT2) data sets and outperforms the baseline by 3.3 points in perplexity on WikiText-103 data set without increasing model parameter counts.
RI Loo, Jonathan/E-6075-2019
OI Loo, Jonathan/0000-0002-2197-8126; shuang, kai/0000-0003-0917-3541; Li,
   Rui/0000-0002-4595-0881
SN 2162-237X
EI 2162-2388
PD OCT
PY 2020
VL 31
IS 10
BP 3932
EP 3946
DI 10.1109/TNNLS.2019.2947563
UT WOS:000576436600013
PM 31825875
ER

PT J
AU Ursprung, S
   Beer, L
   Bruining, A
   Woitek, R
   Stewart, GD
   Gallagher, FA
   Sala, E
AF Ursprung, Stephan
   Beer, Lucian
   Bruining, Annemarie
   Woitek, Ramona
   Stewart, Grant D.
   Gallagher, Ferdia A.
   Sala, Evis
TI Radiomics of computed tomography and magnetic resonance imaging in renal
   cell carcinoma-a systematic review and meta-analysis
SO EUROPEAN RADIOLOGY
AB Objectives (1) To assess the methodological quality of radiomics studies investigating histological subtypes, therapy response, and survival in patients with renal cell carcinoma (RCC) and (2) to determine the risk of bias in these radiomics studies. Methods In this systematic review, literature published since 2000 on radiomics in RCC was included and assessed for methodological quality using the Radiomics Quality Score. The risk of bias was assessed using the Quality Assessment of Diagnostic Accuracy Studies tool and a meta-analysis of radiomics studies focusing on differentiating between angiomyolipoma without visible fat and RCC was performed. Results Fifty-seven studies investigating the use of radiomics in renal cancer were identified, including 4590 patients in total. The average Radiomics Quality Score was 3.41 (9.4% of total) with good inter-rater agreement (ICC 0.96, 95% CI 0.93-0.98). Three studies validated results with an independent dataset, one used a publically available validation dataset. None of the studies shared the code, images, or regions of interest. The meta-analysis showed moderate heterogeneity among the included studies and an odds ratio of 6.24 (95% CI 4.27-9.12; p < 0.001) for the differentiation of angiomyolipoma without visible fat from RCC. Conclusions Radiomics algorithms show promise for answering clinical questions where subjective interpretation is challenging or not established. However, the generalizability of findings to prospective cohorts needs to be demonstrated in future trials for progression towards clinical translation. Improved sharing of methods including code and images could facilitate independent validation of radiomics signatures.
OI Ursprung, Stephan/0000-0003-2476-178X; Beer, Lucian/0000-0003-4388-7580;
   Sala, Evis/0000-0002-5518-9360
SN 0938-7994
EI 1432-1084
PD JUN
PY 2020
VL 30
IS 6
BP 3558
EP 3566
DI 10.1007/s00330-020-06666-3
UT WOS:000535922400055
PM 32060715
ER

PT J
AU Xu, XZ
   Zheng, CL
   Xu, FQ
AF Xu, Xianze
   Zheng, Chenglin
   Xu, Fengqiu
TI A Real-Time Numerical Decoupling Method for Multi-DoF Magnetic
   Levitation Rotary Table
SO APPLIED SCIENCES-BASEL
AB Magnetic levitation technology shows promise for realizing multiple degrees of free precision motion for modern manufacturing, as the bearing and guiding parts are not used. However, motion decoupling in a magnetically levitated (maglev) system is difficult because it is hard to derive accurate magnetic force and a torque model considering the translation and rotation in all axes. In this work, a magnetic levitation rotary table that has the potential to realize unlimited rotation around the vertical axis and a relatively long stroke in the horizontal plane is proposed and analyzed, and the corresponding real-time numerical decoupling method is presented. The numerical magnetic force and torque model solves the current to magnetic force and torque transformation matrix, and the matrix is used to allocate the exact current in each coil phase to produce the required motion in the magnetically levitated (maglev) system. Next, utilizing a high-level synthesis tool and hardware description language, the proposed motion-decoupling module is implemented on a field programmable gate array (FPGA). To realize real-time computation, a pipelined program architecture and finite-state machine with a strict timing sequence are employed for maximum data throughput. In the last decoupling module of the maglev system, the delay for each sampling point is less than 200 mu s. To illustrate and evaluate real-time solutions, they are presented via the DAC adapter on the oscilloscope and stored in the SD card. The error ratios of the force and torque results solved by the numerical wrench model were less than 5% and 10% using the solutions from the boundary element method (BEM) program package Radia(TM) as a benchmark.
OI Xu, Xianze/0000-0003-4604-6445
EI 2076-3417
PD AUG
PY 2019
VL 9
IS 16
AR 3263
DI 10.3390/app9163263
UT WOS:000484444100057
ER

PT J
AU Hogarth, L
   Payton, C
   Van de Vliet, P
   Connick, M
   Burkett, B
AF Hogarth, L.
   Payton, C.
   Van de Vliet, P.
   Connick, M.
   Burkett, B.
TI A novel method to guide classification of para swimmers with limb
   deficiency
SO SCANDINAVIAN JOURNAL OF MEDICINE & SCIENCE IN SPORTS
AB The International Paralympic Committee has directed International Federations that govern Para sports to develop evidence-based classification systems. This study defined the impact of limb deficiency impairment on 100 m freestyle performance to guide an evidence-based classification system in Para Swimming, which will be implemented following the 2020 Tokyo Paralympic games. Impairment data and competitive race performances of 90 international swimmers with limb deficiency were collected. Ensemble partial least squares regression established the relationship between relative limb length measures and competitive 100 m freestyle performance. The model explained 80% of the variance in 100 m freestyle performance and found hand length and forearm length to be the most important predictors of performance. Based on the results of this model, Para swimmers were clustered into four-, five-, six-, and seven-class structures using nonparametric kernel density estimations. The validity of these classification structures, and effectiveness against the current classification system, were examined by establishing within-class variations in 100 m freestyle performance and differences between adjacent classes. The derived classification structures were found to be more effective than current classification based on these criteria. This study provides a novel method that can be used to improve the objectivity and transparency of decision-making in Para sport classification. Expert consensus from experienced coaches, Para swimmers, classifiers, and sport science and medicine personnel will benefit the translation of these findings into a revised classification system that is accepted by the Para swimming community.
RI Hogarth, Luke/L-4975-2016
OI Hogarth, Luke/0000-0001-7085-4501; Payton, Carl/0000-0001-8896-9753
SN 0905-7188
EI 1600-0838
PD NOV
PY 2018
VL 28
IS 11
BP 2397
EP 2406
DI 10.1111/sms.13229
UT WOS:000446997500016
PM 29846980
ER

PT J
AU Fair, DA
   Bathula, D
   Nikolas, MA
   Nigg, JT
AF Fair, Damien A.
   Bathula, Deepti
   Nikolas, Molly A.
   Nigg, Joel T.
TI Distinct neuropsychological subgroups in typically developing youth
   inform heterogeneity in children with ADHD
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
AB Research and clinical investigations in psychiatry largely rely on the de facto assumption that the diagnostic categories identified in the Diagnostic and Statistical Manual (DSM) represent homogeneous syndromes. However, the mechanistic heterogeneity that potentially underlies the existing classification scheme might limit discovery of etiology for most developmental psychiatric disorders. Another, perhaps less palpable, reality may also be interfering with progress-heterogeneity in typically developing populations. In this report we attempt to clarify neuropsychological heterogeneity in a large dataset of typically developing youth and youth with attention deficit/hyperactivity disorder (ADHD), using graph theory and community detection. We sought to determine whether data-driven neuropsychological subtypes could be discerned in children with and without the disorder. Because individual classification is the sine qua non for eventual clinical translation, we also apply support vector machine-based multivariate pattern analysis to identify how well ADHD status in individual children can be identified as defined by the community detection delineated subtypes. The analysis yielded several unique, but similar subtypes across both populations. Just as importantly, comparing typically developing children with ADHD children within each of these distinct subgroups increased diagnostic accuracy. Two important principles were identified that have the potential to advance our understanding of typical development and developmental neuropsychiatric disorders. The first tenet suggests that typically developing children can be classified into distinct neuropsychological subgroups with high precision. The second tenet proposes that some of the heterogeneity in individuals with ADHD might be "nested" in this normal variation.
RI Nikolas, Molly/AAE-9359-2019
OI Nikolas, Molly/0000-0002-0952-7971
SN 0027-8424
EI 1091-6490
PD APR 24
PY 2012
VL 109
IS 17
BP 6769
EP 6774
DI 10.1073/pnas.1115365109
UT WOS:000303249100083
PM 22474392
ER

PT J
AU AGARWAL, KK
   GELERNTER, HL
AF AGARWAL, KK
   GELERNTER, HL
TI A COMPUTER-ORIENTED LINEAR CANONICAL NOTATIONAL SYSTEM FOR THE
   REPRESENTATION OF ORGANIC STRUCTURES WITH STEREOCHEMISTRY
SO JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES
AB Computer algorithms and programs have been developed for a simple and effective notational system for organic molecules. The main features of the system are as follows: (1) The name produced is canonical and linear and consists of two parts. The first part represents the constitution of the molecule, the second its stereochemistry. Two molecules that are constitutionally alike but stereochemically distinct (diastereomers) have identical constitutional representations but different stereochemical descriptors. (2) Atoms which are constitutionally equivalent are identified, as are those that are stereochemically equivalent. (3) Generalized Huckel-resonant substructures of the molecule are identified by the system, allowing different resonant forms of the same molecule to be given identical names. (4) The program accepts as input an easy to write stereochemical descriptor of the molecule which is in fact a noncanonical form of the canonical name. (5) Molecules which are mirror images of one another (enantiomers) are identifiable from their canonical names. (6) The smallest number of asymmetric carbons at which two diastereomers differ can readily be computed from their names. Few systems offer the depth, breadth, and algorithmic correctness in addition to easy bidirectional human-machine communication of organic molecules including their stereochemistry. Although the notational system described here was developed to provide a complete and independent canonical stereochemical descriptor of a molecular structure for the SYNCHEM2 organic synthesis discovery program and has been successfully used for several years, the stereochemical descriptors may be used in conjunction with other standard nomenclature systems to extend their range to include stereochemistry.
SN 0095-2338
PD MAY-JUN
PY 1994
VL 34
IS 3
BP 463
EP 479
DI 10.1021/ci00019a001
UT WOS:A1994NN74500001
ER

PT J
AU Al-Zaiti, S
   Macleod, R
   Van Dam, P
   Smith, SW
   Birnbaum, Y
AF Al-Zaiti, Salah
   Macleod, Robert
   Van Dam, Peter
   Smith, Stephen W.
   Birnbaum, Yochai
TI Emerging ECG methods for acute coronary syndrome detection:
   Recommendations & future opportunities
SO JOURNAL OF ELECTROCARDIOLOGY
AB Despite being the mainstay for the initial noninvasive assessment of patients with symptomatic coronary artery disease, the 12-lead ECG remains a suboptimal diagnostic tool for myocardial ischemia detection with only acceptable sensitivity and specificity scores. Although myocardial ischemia affects the configuration of the QRS complex and the STT waveform, current guidelines primarily focus on ST segment amplitude, which constitutes a missed opportunity and may explain the suboptimal diagnostic performance of the ECG. This possible opportunity and the low cost and ease of use of the ECG provide compelling motivation to enhance the diagnostic accuracy of the ECG to ischemia detection. This paper describes numerous computational ECG methods and approaches that have been shown to dramatically increase ECG sensitivity to ischemia detection. Briefly, these emerging approaches can be conceptually grouped into one of the following four approaches: (1) leveraging novel ECG waveform features and signatures indicative of ischemic injury other than the classical ST-T amplitude measures; (2) applying body surface potentials mapping (BSPM)-based approaches to enhance the spatial coverage of the surface ECG to detecting ischemia; (3) developing an inverse ECG solution to reconstruct anatomical models of activation and recovery pathways to detect and localize injury currents; and (4) exploring artificial intelligence (AI)-based techniques to harvest ECG waveform signatures of ischemia. We present recent advances, shortcomings, and future opportunities for each of these emerging ECG methods. Future research should focus on the prospective clinical testing of these approaches to establish clinical utility and to expedite potential translation into clinical practice.
RI van Dam, Peter M/J-6452-2012
OI van Dam, Peter M/0000-0002-7962-1760
SN 0022-0736
EI 1532-8430
PD SEP-OCT
PY 2022
VL 74
BP 65
EP 72
DI 10.1016/j.jelectrocard.2022.08.003
EA AUG 2022
UT WOS:000848113500003
PM 36027675
ER

PT J
AU Vijayaprabakaran, K
   Sathiyamurthy, K
AF Vijayaprabakaran, K.
   Sathiyamurthy, K.
TI Towards activation function search for long short-term model network: A
   differential evolution based approach
SO JOURNAL OF KING SAUD UNIVERSITY-COMPUTER AND INFORMATION SCIENCES
AB In Deep Neural Networks (DNNs), several architectures had been proposed for the various complex tasks such as Machine Translation, Natural Language processing and time series forecasting. Long-Short Term Model (LSTM), a deep neural network became the popular architecture for solving sequential and time series problems and achieved markable results. On building the LSTM model, many hyper-parameters like activation function, loss function, and optimizer need to be set in advance. These hyperparameters play a significant role in the performance of the DNNs. This work concentrates on finding a novel activation function that can replace the existing activation function such as sigmoid and tanh in the LSTM. The Differential Evolution Algorithm (DEA) based search methodology is proposed in our work to discover the novel activation function for the LSTM network. Our proposed methodology finds an optimal activation function that outperforms than the traditional activation functions like sigmoid (r), hyperbolic tangent (tanh) and Rectified Linear Unit (ReLU). In this work, the newly explored activation function based on DEA methodology is sinh (x) + sinh-1(x) named as Combined Hyperbolic Sine (comb-H-sine) function. The proposed comb-H-sine activation function outperforms the traditional functions in LSTM with accuracy of 98.83%,93.49% and 78.38% with MNIST, IMDB and UCI HAR datasets respectively. (c) 2020 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
SN 1319-1578
EI 2213-1248
PD JUN
PY 2022
VL 34
IS 6
BP 2637
EP 2650
DI 10.1016/j.jksuci.2020.04.015
PN A
UT WOS:000835043700006
ER

PT J
AU Fuhrman, JD
   Gorre, N
   Hu, QY
   Li, H
   El Naqa, I
   Giger, ML
AF Fuhrman, Jordan D.
   Gorre, Naveena
   Hu, Qiyuan
   Li, Hui
   El Naqa, Issam
   Giger, Maryellen L.
TI A review of explainable and interpretable AI with applications in
   COVID-19 imaging
SO MEDICAL PHYSICS
AB The development of medical imaging artificial intelligence (AI) systems for evaluating COVID-19 patients has demonstrated potential for improving clinical decision making and assessing patient outcomes during the recent COVID-19 pandemic. These have been applied to many medical imaging tasks, including disease diagnosis and patient prognosis, as well as augmented other clinical measurements to better inform treatment decisions. Because these systems are used in life-or-death decisions, clinical implementation relies on user trust in the AI output. This has caused many developers to utilize explainability techniques in an attempt to help a user understand when an AI algorithm is likely to succeed as well as which cases may be problematic for automatic assessment, thus increasing the potential for rapid clinical translation. AI application to COVID-19 has been marred with controversy recently. This review discusses several aspects of explainable and interpretable AI as it pertains to the evaluation of COVID-19 disease and it can restore trust in AI application to this disease. This includes the identification of common tasks that are relevant to explainable medical imaging AI, an overview of several modern approaches for producing explainable output as appropriate for a given imaging scenario, a discussion of how to evaluate explainable AI, and recommendations for best practices in explainable/interpretable AI implementation. This review will allow developers of AI systems for COVID-19 to quickly understand the basics of several explainable AI techniques and assist in the selection of an approach that is both appropriate and effective for a given scenario.
RI Hu, Qiyuan/HDM-5763-2022; Gorre, Naveena/GWR-0473-2022; Hu,
   Qiyuan/ABR-5306-2022
OI Hu, Qiyuan/0000-0002-3326-6441; Li, Hui/0000-0003-3139-2898
SN 0094-2405
EI 2473-4209
PD JAN
PY 2022
VL 49
IS 1
BP 1
EP 14
DI 10.1002/mp.15359
EA DEC 2021
UT WOS:000727548800001
PM 34796530
ER

PT J
AU Behera, SP
   Dubey, A
   Chen, WN
   De Paula, VS
   Zhang, M
   Sgourakis, NG
   Bermel, W
   Wagner, G
   Coote, PW
   Arthanari, H
AF Behera, Soumya P.
   Dubey, Abhinav
   Chen, Wan-Na
   De Paula, Viviane S.
   Zhang, Meng
   Sgourakis, Nikolaos G.
   Bermel, Wolfgang
   Wagner, Gerhard
   Coote, Paul W.
   Arthanari, Haribabu
TI Nearest-neighbor NMR spectroscopy: categorizing spectral peaks by their
   adjacent nuclei
SO NATURE COMMUNICATIONS
AB Methyl-NMR enables atomic-resolution studies of structure and dynamics of large proteins in solution. However, resonance assignment remains challenging. The problem is to combine existing structural informational with sparse distance restraints and search for the most compatible assignment among the permutations. Prior classification of peaks as either from isoleucine, leucine, or valine reduces the search space by many orders of magnitude. However, this is hindered by overlapped leucine and valine frequencies. In contrast, the nearest-neighbor nuclei, coupled to the methyl carbons, resonate in distinct frequency bands. Here, we develop a framework to imprint additional information about passively coupled resonances onto the observed peaks. This depends on simultaneously orchestrating closely spaced bands of resonances along different magnetization trajectories, using principles from control theory. For methyl-NMR, the method is implemented as a modification to the standard fingerprint spectrum (the 2D-HMQC). The amino acid type is immediately apparent in the fingerprint spectrum. There is no additional relaxation loss or an increase in experimental time. The method is validated on biologically relevant proteins. The idea of generating new spectral information using passive, adjacent resonances is applicable to other contexts in NMR spectroscopy. The structure and dynamics of large proteins and complexes can be studied by methyl-NMR but resonance assignment is still challenging. Here, the authors present a NMR method that leverages optimal control pulse design to unambiguously distinguish between Leu and Val using a simple 2D HMQC experiment and they apply it to several proteins including Cas9, interleukin, and human translation initiation factor eIF4a.
RI Wagner, Gerhard/HMV-6709-2023; Behera, Soumya Prakash/AAY-6461-2021; De
   Paula, Viviane/L-1947-2013; Zhang, Meng/P-6278-2017
OI De Paula, Viviane/0000-0003-3171-6477; Zhang, Meng/0000-0003-4497-3253;
   Wagner, Gerhard/0000-0002-2063-4401; Arthanari,
   Haribabu/0000-0002-7281-1289; Sgourakis, Nikolaos/0000-0003-3655-3902;
   Dubey, Abhinav/0000-0002-2392-8050; Coote, Paul/0000-0003-3030-2520
SN 2041-1723
PD NOV 3
PY 2020
VL 11
IS 1
AR 5547
DI 10.1038/s41467-020-19325-4
UT WOS:000591843300002
PM 33144564
ER

PT C
AU Miceli, R
   McGuigan, M
AF Miceli, Raffaele
   McGuigan, Michael
GP IEEE
TI Quantum Computation and Visualization of Hamiltonians Using Discrete
   Quantum Mechanics and IBM QISKit
SO 2018 NEW YORK SCIENTIFIC DATA SUMMIT (NYSDS)
CT New York Scientific Data Summit (NYSDS)
CY AUG 06-08, 2018
CL Upton, NY
SP IEEE
AB Quantum computers have the potential to transform the ways in which we tackle some important problems. The efforts by companies like Google, IBM and Microsoft to construct quantum computers have been making headlines for years. Equally important is the challenge of translating problems into a state that can be fed to these machines. Because quantum computers are in essence controllable quantum systems, the problems that most naturally map to them are those of quantum mechanics. Quantum chemistry has seen particular success in the form of the variational quantum eigensolver (VQE) algorithm, which is used to determine the ground state energy of molecular systems. The goal of our work has been to use the matrix formulation of quantum mechanics to translate other systems so that they can be run through this same algorithm. We describe two ways of accomplishing this using a position basis approach and a Gaussian basis approach. We use this translation to compute finite temperature quantities such as the average energy as a function of temperature. We do this by constructing a 0+1-dimensional thermal field theory, constructing a thermal double of the system and using tensor products to construct operators in the system coupled to a heat bath. We also discuss how to include a chemical potential in the quantum computations. We then connect the 0+1 formalism to gauge theory by using an effective matrix model description used in nuclear theory. We study effective potentials for components of the gauge field and use the VQE algorithm to calculate the ground state energies. We also visualize the wave functions from the eigensolver and make comparisons to theoretical results obtained with continuous operators.
BN 978-1-5386-7933-3
PY 2018
UT WOS:000519951900017
ER

PT J
AU Pino, CJ
   Westover, AJ
   Buffington, DA
   Humes, HD
AF Pino, Christopher J.
   Westover, Angela J.
   Buffington, Deborah A.
   Humes, H. David
TI Bioengineered Renal Cell Therapy Device for Clinical Translation
SO ASAIO JOURNAL
AB The bioartificial renal epithelial cell system (BRECS) is a cell-based device to treat acute kidney injury through renal cell therapy from an extracorporeal circuit. To enable widespread implementation of cell therapy, the BRECS was designed to be cryopreserved as a complete device, cryostored, cryoshipped to an end-use site, thawed as a complete device, and employed in a therapeutic extracorporeal hemofiltration circuit. This strategy overcomes storage and distribution issues that have been previous barriers to cell therapy. Previous BRECS housings produced by computer numerical control (CNC) machining, a slow process taking hours to produce one bioreactor, was also prohibitively expensive (>$600/CNC-BRECS); major obstacles to mass production. The goal of this study was to produce a BRECS to be mass produced by injection-molded BRECS (IM-BRECS), decreasing cost (<$20/unit), and improving manufacturing speed (hundreds of units/h), while maintaining the same cell therapy function as the previous CNC-BRECS, first evaluated through prototypes produced by stereolithography BRECS (SLA-BRECS). The finalized IM-BRECS design had a significantly lower fill volume (10 ml), mass (49 g), and footprint (8.5 cm x 8.5 cm x 1.5 cm), and was demonstrated to outperform the previous BRECS designs with respect to heat transfer, significantly improving control of cooling during cryopreservation and reducing thaw times during warming. During in vitro culture, IM-BRECS performed similarly to previous CNC-BRECS with respect to cell metabolic activity (lactate production, oxygen consumption, and glutathione metabolism) and amount of cells supported.
OI Pino, Christopher/0000-0003-4063-9215
SN 1058-2916
EI 1538-943X
PD MAY-JUN
PY 2017
VL 63
IS 3
BP 305
EP 315
DI 10.1097/MAT.0000000000000485
UT WOS:000404043600016
PM 27922886
ER

PT J
AU Sarabian, C
   Wilkinson, A
   Sigaud, M
   Kano, F
   Tobajas, J
   Darmaillacq, AS
   Kalema-Zikusoka, G
   Plotnik, JM
   MacIntosh, AJJ
AF Sarabian, Cecile
   Wilkinson, Anna
   Sigaud, Marie
   Kano, Fumihiro
   Tobajas, Jorge
   Darmaillacq, Anne-Sophie
   Kalema-Zikusoka, Gladys
   Plotnik, Joshua M.
   MacIntosh, Andrew J. J.
TI Disgust in animals and the application of disease avoidance to wildlife
   management and conservation
SO JOURNAL OF ANIMAL ECOLOGY
AB Disgust is an adaptive system hypothesized to have evolved to reduce the risk of becoming sick. It is associated with behavioural, cognitive and physiological responses tuned to allow animals to avoid and/or get rid of parasites, pathogens and toxins. Little is known about the mechanisms and outcomes of disease avoidance in wild animals. Furthermore, given the escalation of negative human-wildlife interactions, the translation of such knowledge into the design of evolutionarily relevant conservation and wildlife management strategies is becoming urgent. Contemporary methods in animal ecology and related fields, using direct (sensory cues) or indirect (remote sensing technologies and machine learning) means, provide a flexible toolbox for testing and applying disgust at individual and collective levels. In this review/perspective paper, we provide an empirical framework for testing the adaptive function of disgust and its associated disease avoidance behaviours across species, from the least to the most social, in different habitats. We predict various trade-offs to be at play depending on the social system and ecology of the species. We propose five contexts in which disgust-related avoidance behaviours could be applied, including endangered species rehabilitation, invasive species, crop-raiding, urban pests and animal tourism. We highlight some of the perspectives and current challenges of testing disgust in the wild. In particular, we recommend future studies to consider together disease, predation and competition risks. We discuss the ethics associated with disgust experiments in the above contexts. Finally, we promote the creation of a database gathering disease avoidance evidence in animals and its applications.
RI ; MacIntosh, Andrew/B-2242-2013
OI Tobajas, Jorge/0000-0002-8329-8265; MacIntosh,
   Andrew/0000-0002-9136-7099; Sigaud, Marie/0000-0002-6958-7239
SN 0021-8790
EI 1365-2656
DI 10.1111/1365-2656.13903
EA MAR 2023
UT WOS:000947891800001
PM 36914973
ER

PT J
AU Zaman, KS
   Reaz, MB
   Ali, SHM
   Bakar, AAA
   Chowdhury, MEH
AF Zaman, Kh Shahriya
   Reaz, Mamun Bin Ibne
   Ali, Sawal Hamid Md
   Bakar, Ahmad Ashrif A.
   Chowdhury, Muhammad Enamul Hoque
TI Custom Hardware Architectures for Deep Learning on Portable Devices: A
   Review
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
AB The staggering innovations and emergence of numerous deep learning (DL) applications have forced researchers to reconsider hardware architecture to accommodate fast and efficient application-specific computations. Applications, such as object detection, image recognition, speech translation, as well as music synthesis and image generation, can be performed with high accuracy at the expense of substantial computational resources using DL. Furthermore, the desire to adopt Industry 4.0 and smart technologies within the Internet of Things infrastructure has initiated several studies to enable on-chip DL capabilities for resource-constrained devices. Specialized DL processors reduce dependence on cloud servers, improve privacy, lessen latency, and mitigate bandwidth congestion. As we reach the limits of shrinking transistors, researchers are exploring various application-specific hardware architectures to meet the performance and efficiency requirements for DL tasks. Over the past few years, several software optimizations and hardware innovations have been proposed to efficiently perform these computations. In this article, we review several DL accelerators, as well as technologies with emerging devices, to highlight their architectural features in application-specific integrated circuit (IC) and field-programmable gate array (FPGA) platforms. Finally, the design considerations for DL hardware in portable applications have been discussed, along with some deductions about the future trends and potential research directions to innovate DL accelerator architectures further. By compiling this review, we expect to help aspiring researchers widen their knowledge in custom hardware architectures for DL.
RI BAKAR, AHMAD ASHRIF A/AAC-9456-2019; Chowdhury, Muhammad
   E.H./J-6916-2019; Zaman, Kh Shahriya/F-3933-2019; Ali, Sawal Hamid
   Md/M-3781-2016; Reaz, Md. Mamun Bin Ibne/E-7221-2010
OI BAKAR, AHMAD ASHRIF A/0000-0002-9060-0346; Chowdhury, Muhammad
   E.H./0000-0003-0744-8206; Zaman, Kh Shahriya/0000-0002-0636-920X; Ali,
   Sawal Hamid Md/0000-0002-4819-863X; Reaz, Md. Mamun Bin
   Ibne/0000-0002-0459-0365
SN 2162-237X
EI 2162-2388
PD NOV
PY 2022
VL 33
IS 11
BP 6068
EP 6088
DI 10.1109/TNNLS.2021.3082304
EA JUN 2021
UT WOS:000732201500001
PM 34086580
ER

PT J
AU Huang, Y
   Huang, SH
   Chen, HC
   Chen, XP
   Zheng, ZB
   Luo, XP
   Jia, N
   Hu, XY
   Zhou, XC
AF Huang, Yuan
   Huang, Shaohao
   Chen, Huanchao
   Chen, Xiangping
   Zheng, Zibin
   Luo, Xiapu
   Jia, Nan
   Hu, Xinyu
   Zhou, Xiaocong
TI Towards automatically generating block comments for code snippets
SO INFORMATION AND SOFTWARE TECHNOLOGY
AB Code commenting is a common programming practice of practical importance to help developers review and comprehend source code. There are two main types of code comments for a method: header comments that summarize the method functionality located before a method, and block comments that describe the functionality of the code snippets within a method. Inspired by the effectiveness of deep learning techniques in the NLP field, many studies focus on using the machine translation model to automatically generate comment for the source code. Because the data set of block comments is difficult to collect, current studies focus more on the automatic generation of header comments than that of block comments. However, block comments are important for program comprehension due to their explanation role for the code snippets in a method. To fill the gap, we have proposed an approach that combines heuristic rules and learning-based method to collect a large number of comment-code pairs from 1,032 open source projects in our previous study. In this paper, we propose a reinforcement learning-based method, RL-BlockCom, to automatically generate block comments for code snippets based on the collected comment-code pairs. Specifically, we utilize the abstract syntax tree (i.e., AST) of a code snippet to generate a token sequence with a statement-based traversal way. Then we propose a composite learning model, which combines the actor-critic algorithm of reinforcement learning with the encoder-decoder algorithm, to generate block comments. On the data set of the comment-code pairs, the BLEU-4 score of our method is 24.28, which outperforms the baselines and state-of-the-art in comment generation.
RI Zheng, Zibin/HCH-2408-2022; Zheng, Zibin/E-3024-2014
OI Zheng, Zibin/0000-0002-7878-4330; Zheng, Zibin/0000-0002-7878-4330
SN 0950-5849
EI 1873-6025
PD NOV
PY 2020
VL 127
AR 106373
DI 10.1016/j.infsof.2020.106373
UT WOS:000571236700006
ER

PT J
AU Dai, XL
   Yin, HX
   Jha, NK
AF Dai, Xiaoliang
   Yin, Hongxu
   Jha, Niraj K.
TI Grow and Prune Compact, Fast, and Accurate LSTMs
SO IEEE TRANSACTIONS ON COMPUTERS
AB Long short-term memory (LSTM) has been widely used for sequential data modeling. Researchers have increased LSTM depth by stacking LSTM cells to improve performance. This incurs model redundancy, increases run-time delay, and makes the LSTMs more prone to overfitting. To address these problems, we propose a hidden-layer LSTM (H-LSTM) that adds hidden layers to LSTM's original one-level nonlinear control gates. H-LSTM increases accuracy while employing fewer external stacked layers, thus reducing the number of parameters and run-time latency significantly. We employ grow-and-prune (GP) training to iteratively adjust the hidden layers through gradient-based growth and magnitude-based pruning of connections. This learns both the weights and the compact architecture of H-LSTM control gates. We have GP-trained H-LSTMs for image captioning, speech recognition, and neural machine translation applications. For the NeuralTalk architecture on the MSCOCO dataset, our three models reduce the number of parameters by 38.7x [floating-point operations (FLOPs) by 45.5x], run-time latency by 4.5x, and improve the CIDEr-D score by 2.8 percent, respectively. For the DeepSpeech2 architecture on the AN4 dataset, the first model we generated reduces the number of parameters by 19.4x and run-time latency by 37.4 percent. The second model reduces the word error rate (WER) from 12.9 to 8.7 percent. For the encoder-decoder sequence-to-sequence network on the IWSLT 2014 German-English dataset, the first model we generated reduces the number of parameters by 10.8x and run-time latency by 14.2 percent. The second model increases the BLEU score from 30.02 to 30.98. Thus, GP-trained H-LSTMs can be seen to be compact, fast, and accurate.
RI Yin, Hongxu/AAZ-3328-2020
OI Yin, Hongxu/0000-0002-6481-6389
SN 0018-9340
EI 1557-9956
PD MAR 1
PY 2020
VL 69
IS 3
BP 441
EP 452
DI 10.1109/TC.2019.2954495
UT WOS:000515763100011
ER

PT J
AU Ofman, G
   Caballero, MT
   Paggi, DA
   Marzec, J
   Nowogrodzki, F
   Cho, HY
   Sorgetti, M
   Colantonio, G
   Bianchi, A
   Prudent, LM
   Vain, N
   Mariani, G
   Digregorio, J
   Turconi, EL
   Osio, C
   Galletti, F
   Quiros, M
   Brum, A
   Garcia, SL
   Garcia, S
   Bell, D
   Jones, MH
   Tipple, TE
   Kleeberger, SR
   Polack, FP
AF Ofman, Gaston
   Caballero, Mauricio T.
   Alvarez Paggi, Damian
   Marzec, Jacqui
   Nowogrodzki, Florencia
   Cho, Hye-Youn
   Sorgetti, Mariana
   Colantonio, Guillermo
   Bianchi, Alejandra
   Prudent, Luis M.
   Vain, Nestor
   Mariani, Gonzalo
   Digregorio, Jorge
   Lopez Turconi, Elba
   Osio, Cristina
   Galletti, Fernanda
   Quiros, Mariangeles
   Brum, Andrea
   Lopez Garcia, Santiago
   Garcia, Silvia
   Bell, Douglas
   Jones, Marcus H.
   Tipple, Trent E.
   Kleeberger, Steven R.
   Polack, Fernando P.
TI The discovery BPD (D-BPD) program: study protocol of a prospective
   translational multicenter collaborative study to investigate
   determinants of chronic lung disease in very low birth weight infants
SO BMC PEDIATRICS
AB BackgroundPremature birth is a growing and serious public health problem affecting more than one of every ten infants worldwide. Bronchopulmonary dysplasia (BPD) is the most common neonatal morbidity associated with prematurity and infants with BPD suffer from increased incidence of respiratory infections, asthma, other forms of chronic lung illness, and death (Day and Ryan, Pediatr Res 81: 210-213, 2017; Isayama et la., JAMA Pediatr 171:271-279, 2017). BPD is now understood as a longitudinal disease process influenced by the intrauterine environment during gestation and modulated by gene-environment interactions throughout the neonatal and early childhood periods. Despite of this concept, there remains a paucity of multidisciplinary team-based approaches dedicated to the comprehensive study of this complex disease.MethodsThe Discovery BPD (D-BPD) Program involves a cohort of infants <1,250g at birth prospectively followed until 6years of age. The program integrates analysis of detailed clinical data by machine learning, genetic susceptibility and molecular translation studies.DiscussionThe current gap in understanding BPD as a complex multi-trait spectrum of different disease endotypes will be addressed by a bedside-to-bench and bench-to-bedside approach in the D-BPD program. The D-BPD will provide enhanced understanding of mechanisms, evolution and consequences of lung diseases in preterm infants. The D-BPD program represents a unique opportunity to combine the expertise of biologists, neonatologists, pulmonologists, geneticists and biostatisticians to examine the disease process from multiple perspectives with a singular goal of improving outcomes of premature infants.Trial registrationDoes not apply for this study.
RI Jones, Marcus Herbert/A-3580-2011; Kleeberger, Steven R/F-1807-2019;
   Tipple, Trent/AAG-4195-2021; Bell, Douglas/HGE-6048-2022; Alvarez Paggi,
   Damian/N-7549-2018
OI Jones, Marcus Herbert/0000-0002-8263-1265; Kleeberger, Steven
   R/0000-0003-2948-8452; Tipple, Trent/0000-0002-5156-4282; Alvarez Paggi,
   Damian/0000-0002-1507-9685
SN 1471-2431
PD JUL 6
PY 2019
VL 19
AR 227
DI 10.1186/s12887-019-1610-8
UT WOS:000474369400001
PM 31279333
ER

PT J
AU Giannella, CR
   Winder, RK
   Jubinski, JP
AF Giannella, Chris R.
   Winder, Ransom K.
   Jubinski, Joseph P.
TI Annotation projection for temporal information extraction
SO NATURAL LANGUAGE ENGINEERING
AB Approaches to building temporal information extraction systems typically rely on large, manually annotated corpora. Thus, porting these systems to new languages requires acquiring large corpora of manually annotated documents in the new languages. Acquiring such corpora is difficult owing to the complexity of temporal information extraction annotation. One strategy for addressing this difficulty is to reduce or eliminate the need for manually annotated corpora through annotation projection. This technique utilizes a temporal information extraction system for a source language (typically English) to automatically annotate the source language side of a parallel corpus. It then uses automatically generated word alignments to project the annotations, thereby creating noisily annotated target language training data. We developed an annotation projection technique for producing target language temporal information extraction systems. We carried out an English (source) to French (target) case study wherein we compared a French temporal information extraction system built using annotation projection with one built using a manually annotated French corpus. While annotation projection has been applied to building other kinds of Natural Language Processing tools (e.g., Named Entity Recognizers), to our knowledge, this is the first paper examining annotation projection as applied to temporal information extraction where no manual corrections of the target language annotations were made. We found that, even using manually annotated data to build a temporal information extraction system, F-scores were relatively low (<0.35), which suggests that the problem is challenging even with manually annotated data. Our annotation projection approach performed well (relative to the system built from manually annotated data) on some aspects of temporal information extraction (e.g., event-document creation time temporal relation prediction), but it performed poorly on the other kinds of temporal relation prediction (e.g., event-event and event-time).
SN 1351-3249
EI 1469-8110
PD MAY
PY 2019
VL 25
IS 3
BP 385
EP 403
DI 10.1017/S1351324919000044
UT WOS:000471328200003
ER

PT J
AU Chang, CM
   Wang, PH
   Horng, HC
AF Chang, Chia-Ming
   Wang, Peng-Hui
   Horng, Huann-Cheng
TI Gene set-based analysis of mucinous ovarian carcinoma
SO TAIWANESE JOURNAL OF OBSTETRICS & GYNECOLOGY
AB Objective: Mutinous ovarian carcinoma (MOC) is an uncommon subtype of epithelial ovarian cancers, and the pathogenesis is still poorly understood because of its rarity. We conducted a gene set-based analysis to investigate the pathogenesis of MOC by integrating microarray gene expression datasets based on the regularity of functions defined by gene ontology or canonical pathway databases.
   Materials and methods: Forty-five pairs of MOC and normal ovarian tissue sample gene expression profiles were downloaded from the National Center for Biotechnology Information Gene Expression Omnibus database. The gene expression profiles were converted to the gene set regularity indexes by measuring the change of gene expression ordering in a gene set. Then the pathogenesis of MOC was investigated with the differences of function regularity with the gene set regularity indexes between the MOC and normal control samples.
   Results: The informativeness of the gene set regularity indexes was sufficient for machine learning to accurately recognize and classify the functional regulation patterns with an accuracy of 99.44%. The statistical analysis revealed that the GTPase regulators and receptor tyrosine kinase erbB-2 (ERBB2) were the most important aberrations; the exploratory factor analysis revealed phosphoinositide 3-kinase-activating kinase, G-protein coupled receptor pathway, oxidoreductase activity, immune response, peptidase activity, regulation of translation, and transport and channel activity were also involved in the pathogenesis of MOC.
   Conclusion: Investigating the pathogenesis of MOC with the functionome provided a comprehensive view of the deregulated functions of this disease. In addition to GTPase regulators and ERBB2, a plenty of deregulated functions such as phosphoinositide 3-kinase, G-protein coupled receptor pathway, and immune response also participated in the interaction network of MOC pathogenesis. (C) 2017 Taiwan Association of Obstetrics & Gynecology. Publishing services by Elsevier B.V.
SN 1028-4559
PD APR
PY 2017
VL 56
IS 2
BP 210
EP 216
DI 10.1016/j.tjog.2016.12.016
UT WOS:000418316000017
PM 28420510
ER

PT C
AU Hussein, M
   Renner, M
   Iagnemma, K
AF Hussein, Marwan
   Renner, Matthew
   Iagnemma, Karl
BE Karlsen, RE
   Gage, DW
   Shoemaker, CM
   Gerhart, GR
TI Absolute Localization of Ground Robots By Matching LiDAR and Image Data
   in Dense Forested Environments
SO UNMANNED SYSTEMS TECHNOLOGY XVI
SE Proceedings of SPIE
CT Conference on Unmanned Systems Technology XVI
CY MAY 06-08, 2014
CL Baltimore, MD
SP SPIE
AB A method for the autonomous geolocation of ground vehicles in forest environments is discussed. The method provides an estimate of the global horizontal position of a vehicle strictly based on finding a geometric match between a map of observed tree stems, scanned in 3D by Light Detection and Ranging (LiDAR) sensors onboard the vehicle, to another stem map generated from the structure of tree crowns analyzed from high resolution aerial orthoimagery of the forest canopy. Extraction of stems from 3D data is achieved by using Support Vector Machine (SVM) classifiers and height above ground filters that separate ground points from vertical stem features. Identification of stems from overhead imagery is achieved by finding the centroids of tree crowns extracted using a watershed segmentation algorithm. Matching of the two maps is achieved by using a robust Iterative Closest Point (ICP) algorithm that determines the rotation and translation vectors to align the datasets. The alignment is used to calculate the absolute horizontal location of the vehicle. The method has been tested with real-world data and has been able to estimate vehicle geoposition with an average error of less than 2 m. It is noted that the algorithm's accuracy performance is currently limited by the accuracy and resolution of aerial orthoimagery used.
   The method can be used in real-time as a complement to the Global Positioning System (GPS) in areas where signal coverage is inadequate due to attenuation by the forest canopy, or due to intentional denied access. The method has two key properties that are significant: i) It does not require a priori knowledge of the area surrounding the robot. ii) Uses the geometry of detected tree stems as the only input to determine horizontal geoposition.
SN 0277-786X
EI 1996-756X
BN 978-1-62841-021-1
PY 2014
VL 9084
AR 90840V
DI 10.1117/12.2053129
UT WOS:000342427200028
ER

PT C
AU Wang, GM
   Sevick, EM
AF Wang, G. M.
   Sevick, E. M.
BE Dholakia, K
   Spalding, GC
TI Optical Tweezers manipulation of colloids and biopolymers:
   non-equilibrium processes
SO OPTICAL TRAPPING AND OPTICAL MICROMANIPULATION V
SE Proceedings of SPIE
CT Conference on Optical Trapped and Optical Micromanipulation V
CY AUG 10-13, 2008
CL San Diego, CA
SP SPIE
AB The Fluctuation Theorems (FTs) of Evans & Searles and of Crooks are fundamental theorems of modern thermodynamics that have been suggested to be of practical use to scientists and engineers. Non-equilibrium processes with energy fluctuations on the order of thermal energy, k(B)T, are described by the FTs, examples include the stretching of a DNA molecule, the localisation of a colloidal particle in an optical trap of changing strength, and translation of an optically trapped colloidal particle. If the path or process is traversed over long times or the system is sufficiently large that it can be considered in the classical, thermodynamic limit, then, in principle, there is only one value of the energy characterising the path. However, for small systems, there exists a distribution of energy values and this distribution is associated with non-equilibrium fluctuations of the system that do not average out over short time. The FT of Evans & Searles, as well as the FT of Crooks (from which the Jarzynski relation is derived), describe the symmetry of this energy distribution about zero. This distribution is inherent to the dynamics of small systems, such as nano-machines and single molecular motors.
   In this paper we present the FTs in a single unified language, considering that the work done on the system is either purely dissipative, achieves a, change in thermodynamic state of the system, or a, combination of these. We demonstrate this with a single colloidal particle in an optical trap and a single DNA molecule stretched in an OT experiment.
RI Sevick, Edith M/I-8029-2014
OI Sevick, Edith M/0000-0003-4857-0523
SN 0277-786X
EI 1996-756X
BN 978-0-8194-7258-8
PY 2008
VL 7038
AR 70380L
DI 10.1117/12.797399
UT WOS:000262711000009
ER

PT J
AU Pappenberger, G
   McCormack, EA
   Willison, KR
AF Pappenberger, Gunter
   McCormack, Elizabeth A.
   Willison, Keith R.
TI Quantitative actin folding reactions using yeast CCT purified via an
   internal tag in the CCT3/gamma subunit
SO JOURNAL OF MOLECULAR BIOLOGY
AB The eukaryotic cytosolic chaperonin CCT is an essential ATP-dependent protein folding machine whose action is required for folding the cytoskeletal proteins actin and tubulin, and a small number of other substrates, including members of the WD40-propellor repeat-containing protein family. An efficient purification protocol for CCT from Saccharomyces cerevisiae has been developed. It uses the calmodulin binding peptide as an affinity tag in an internal loop in the apical domain of the CCT3 subunit, which is predicted to be located on the outside of the double-ring assembly. This purified yeast CCT was used for a novel quantitative actin-folding assay with human beta-actin or yeast ACT1p protein folding intermediates, Ac-I, pre-synthesised in an Escherichia coli translation system. The formation of native actin follows approximately a first-order reaction with a rate constant of about 0.03 min(-1). Yeast CCT catalyses the folding of yeast ACT1p and human beta-actin with nearly identical rate constants and yields. The results from this controlled CCT-actin folding assay are consistent with a model where CCT and Ac-I are in a binding pre-equilibrium with a rate-limiting binding step, followed by a faster ATP-driven processing to native actin. In this pure in vitro system, the human beta-actin mutants, D244S and G150P, show impaired folding behaviour in the manner predicted by our sequence-specific recognition model for CCT-actin interaction. (c) 2006 Elsevier Ltd. All rights reserved.
SN 0022-2836
EI 1089-8638
PD JUL 7
PY 2006
VL 360
IS 2
BP 484
EP 496
DI 10.1016/j.jmb.2006.05.003
UT WOS:000238844600019
PM 16762366
ER

PT J
AU Manoj, KM
   Jacob, VD
   Kavdia, M
   Tamagawa, H
   Jaeken, L
   Soman, V
AF Manoj, Kelath Murali
   Jacob, Vivian David
   Kavdia, Mahendra
   Tamagawa, Hirohisa
   Jaeken, Laurent
   Soman, Vidhu
TI Questioning rotary functionality in the bacterial flagellar system and
   proposing a murburn model for motility
SO JOURNAL OF BIOMOLECULAR STRUCTURE & DYNAMICS
AB Bacterial flagellar system (BFS) was the primary example of a purported 'rotary-motor' functionality in a natural assembly. This mandates the translation of a circular motion of components inside into a linear displacement of the cell body outside, which is supposedly orchestrated with the following features of the BFS: (i) A chemical/electrical differential generates proton motive force (pmf, including a trans-membrane potential, TMP), which is electro-mechanically transduced by inward movement of protons via BFS. (ii) Membrane-bound proteins of BFS serve as stators and the slender filament acts as an external propeller, culminating into a hook-rod that pierces the membrane to connect to a 'broader assembly of deterministically movable rotor'. We had disclaimed the purported pmf/TMP-based respiratory/photosynthetic physiology involving Complex V, which was also perceived as a 'rotary machine' earlier. We pointed out that the murburn redox logic was operative therein. We pursue the following similar perspectives in BFS-context: (i) Low probability for the evolutionary attainment of an ordered/synchronized teaming of about two dozen types of proteins (assembled across five-seven distinct phases) towards the singular agendum of rotary motility. (ii) Vital redox activity (not the gambit of pmf/TMP!) powers the molecular and macroscopic activities of cells, including flagella. (iii) Flagellar movement is noted even in ambiances lacking/countering the directionality mandates sought by pmf/TMP. (iv) Structural features of BFS lack component(s) capable of harnessing/achieving pmf/TMP and functional rotation. A viable murburn model for conversion of molecular/biochemical activity into macroscopic/mechanical outcomes is proposed herein for understanding BFS-assisted motility.
SN 0739-1102
EI 1538-0254
DI 10.1080/07391102.2023.2191146
EA MAR 2023
UT WOS:000954790100001
PM 36970840
ER

PT J
AU Choi, WJ
   Lee, SH
   Park, BC
   Kotov, NA
AF Choi, Won Jin
   Lee, Sang Hyun
   Park, Bum Chul
   Kotov, Nicholas A.
TI Terahertz Circular Dichroism Spectroscopy of Molecular Assemblies and
   Nanostructures
SO JOURNAL OF THE AMERICAN CHEMICAL SOCIETY
AB Chemical, physical, biological and materials engineering disciplines use a variety of chiroptical spectroscopies to probe geometrical and optical asymmetry in molecules and particles. Electronic (ECD) and vibrational (VCD) circular dichroism are the most common of these techniques and collectively enable the studies of electronic and vibronic transitions with energies between 0.1 and 5.0 eV. The vibrational states with characteristic energies in the range of 0.001-0.01 eV carry valuable information about concerted intermolecular motions in molecules and crystals involving multiple atoms. These vibronic transitions located in the terahertz (THz) part of the spectrum become increasingly more important for the chemistry, physics, and biology of complex molecules and materials However, the methodology and hardware of THz circular dichroism (TCD) are much less developed than the chiroptical spectroscopies for ultraviolet, visible, near-and mid infrared photons. Here we provide theoretical foundations, practical implementations, comparative assessments, and exemplary applications of TCD spectroscopy. We show that the sign, intensity, and position of TCD peaks are highly sensitive to the three-dimensional structure and long-range organization of molecular crystals, which offer unique capabilities to study (bio) molecules, their crystals, and nanoscale assemblies and apply the novel data processing methodologies. TCD also offers a convenient toolbox to identify new physical phenomena, such as chiral phonons and their propagation in nanostructured matter. We also discuss the major challenges, emerging opportunities and promising research directions, including broad investigation of chiral phonons observed in chiral (nano) crystals and emerging machine learning methodologies for TCD in biological and nanoscale structures. Ubiquity of low-frequency vibrations with rotational components in biomolecular structures, combined with sharpness of peaks in TCD spectra, enables a variety of technological translations.
OI Kotov, Nicholas A./0000-0002-6864-5804; CHOI, WON
   JIN/0000-0001-6303-8899
SN 0002-7863
EI 1520-5126
PD DEC 21
PY 2022
VL 144
IS 50
BP 22789
EP 22804
DI 10.1021/jacs.2c04817
EA DEC 2022
UT WOS:000895802900001
PM 36490376
ER

PT J
AU Knevel, R
   Liao, KP
AF Knevel, Rachel
   Liao, Katherine P.
TI From real-world electronic health record data to real-world results
   using artificial intelligence
SO ANNALS OF THE RHEUMATIC DISEASES
AB With the worldwide digitalisation of medical records, electronic health records (EHRs) have become an increasingly important source of real-world data (RWD). RWD can complement traditional study designs because it captures almost the complete variety of patients, leading to more generalisable results. For rheumatology, these data are particularly interesting as our diseases are uncommon and often take years to develop. In this review, we discuss the following concepts related to the use of EHR for research and considerations for translation into clinical care: EHR data contain a broad collection of healthcare data covering the multitude of real-life patients and the healthcare processes related to their care. Machine learning (ML) is a powerful method that allows us to leverage a large amount of heterogeneous clinical data for clinical algorithms, but requires extensive training, testing, and validation. Patterns discovered in EHR data using ML are applicable to real life settings, however, are also prone to capturing the local EHR structure and limiting generalisability outside the EHR(s) from which they were developed. Population studies on EHR necessitates knowledge on the factors influencing the data available in the EHR to circumvent biases, for example, access to medical care, insurance status. In summary, EHR data represent a rapidly growing and key resource for real-world studies. However, transforming RWD EHR data for research and for real-world evidence using ML requires knowledge of the EHR system and their differences from existing observational data to ensure that studies incorporate rigorous methods that acknowledge or address factors such as access to care, noise in the data, missingness and indication bias.
OI Knevel, Rachel/0000-0002-7494-3023
SN 0003-4967
EI 1468-2060
PD MAR
PY 2023
VL 82
IS 3
BP 306
EP 311
DI 10.1136/ard-2022-222626
EA SEP 2022
UT WOS:000859819300001
PM 36150748
ER

PT J
AU Yang, L
   Song, YH
   Jia, XY
   Ma, K
   Xie, LH
AF Yang, Lie
   Song, Yonghao
   Jia, Xueyu
   Ma, Ke
   Xie, Longhan
TI Two-branch 3D convolutional neural network for motor imagery EEG
   decoding
SO JOURNAL OF NEURAL ENGINEERING
AB Objective. The original motor imagery electroencephalography (MI-EEG) data contains not only temporal features but also a large number of spatial features related to the distribution of electrodes on the brain. However, in the process of MI-EEG decoding, most of the current convolutional neural network (CNN) based methods do not make the utmost of the spatial features related to electrode distribution. Approach. In this study, we adopt a concise 3D representation for the MI-EEG data to take full advantage of the spatial features and propose a two-branch 3D CNN (TB-3D CNN) for the 3D representation of MI-EEG data. First, the spatial and temporal features of the input 3D samples are extracted by the spatial and temporal feature learning branches, respectively, to avoid the mutual interference between the temporal and spatial features. Then, the central loss is introduced into the TB-3D CNN framework to further improve the MI-EEG decoding accuracy. And a 3D data augmentation method based on the cyclic translation of time dimension is proposed for the 3D representation method to alleviate the overfitting problem. Main results. Some experiments are conducted on the famous BCI competition IV 2a dataset to evaluate the effectiveness of the proposed MI-EEG decoding method. The experimental results comparison with some state-of-the-art methods demonstrates that the average accuracy of our method is 4.42% higher than that of the best of the comparative methods. Significance. The proposed MI-EEG decoding method has great promise to improve the performance of motor imagery brain-computer interface system.
OI Yang, Lie/0000-0002-6054-9818
SN 1741-2560
EI 1741-2552
PD AUG
PY 2021
VL 18
IS 4
AR 0460c7
DI 10.1088/1741-2552/ac17d6
UT WOS:000684705600001
PM 34311452
ER

PT J
AU Hu, X
   Zhao, Y
   Deng, L
   Liang, L
   Zuo, PF
   Ye, J
   Lin, YY
   Xie, Y
AF Hu, Xing
   Zhao, Yang
   Deng, Lei
   Liang, Ling
   Zuo, Pengfei
   Ye, Jing
   Lin, Yingyan
   Xie, Yuan
TI Practical Attacks on Deep Neural Networks by Memory Trojaning
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
AB Deep neural network (DNN) accelerators are widely deployed in computer vision, speech recognition, and machine translation applications, in which attacks on DNNs have become a growing concern. This article focuses on exploring the implications of hardware Trojan attacks on DNNs. Trojans are one of the most challenging threat models in hardware security where adversaries insert malicious modifications to the original integrated circuits (ICs), leading to malfunction once being triggered. Such attacks can be conducted by adversaries because modern ICs commonly include third-party intellectual property (IP) blocks. Previous studies design hardware Trojans to attack DNNs with the assumption that adversaries have full knowledge or manipulation of the DNN systems' victim model and toolchain in addition to the hardware platforms, yet such a threat model is strict, limiting their practical adoption. In this article, we propose a memory Trojan methodology that implants the malicious logics merely into the memory controllers of DNN systems without the necessity of toolchain manipulation or accessing to the victim model and thus is feasible for practical uses. Specifically, we locate the input image data among the massive volume of memory traffics based on memory access patterns and propose a Trojan trigger mechanism based on detecting the geometric feature in input images. Extensive experiments show that the proposed trigger mechanism is effective even in the presence of environmental noises and preprocessing operations. Furthermore, we design and implement the payload and verify that the proposed Trojan technique can effectively conduct both untargeted and targeted attacks on DNNs.
OI Zuo, Pengfei/0000-0001-9982-5130; Zhao, Yang (Katie)/0000-0001-8023-1551
SN 0278-0070
EI 1937-4151
PD JUN
PY 2021
VL 40
IS 6
BP 1230
EP 1243
DI 10.1109/TCAD.2020.2995347
UT WOS:000652792400018
ER

PT J
AU Chaddad, A
   Kucharczyk, MJ
   Cheddad, A
   Clarke, SE
   Hassan, L
   Ding, SX
   Rathore, S
   Zhang, ML
   Katib, Y
   Bahoric, B
   Abikhzer, G
   Probst, S
   Niazi, T
AF Chaddad, Ahmad
   Kucharczyk, Michael J.
   Cheddad, Abbas
   Clarke, Sharon E.
   Hassan, Lama
   Ding, Shuxue
   Rathore, Saima
   Zhang, Mingli
   Katib, Yousef
   Bahoric, Boris
   Abikhzer, Gad
   Probst, Stephan
   Niazi, Tamim
TI Magnetic Resonance Imaging Based Radiomic Models of Prostate Cancer: A
   Narrative Review
SO CANCERS
AB Simple Summary
   The increasing interest in implementing artificial intelligence in radiomic models has occurred alongside advancement in the tools used for computer-aided diagnosis. Such tools typically apply both statistical and machine learning methodologies to assess the various modalities used in medical image analysis. Specific to prostate cancer, the radiomics pipeline has multiple facets that are amenable to improvement. This review discusses the steps of a magnetic resonance imaging based radiomics pipeline. Present successes, existing opportunities for refinement, and the most pertinent pending steps leading to clinical validation are highlighted.
   The management of prostate cancer (PCa) is dependent on biomarkers of biological aggression. This includes an invasive biopsy to facilitate a histopathological assessment of the tumor's grade. This review explores the technical processes of applying magnetic resonance imaging based radiomic models to the evaluation of PCa. By exploring how a deep radiomics approach further optimizes the prediction of a PCa's grade group, it will be clear how this integration of artificial intelligence mitigates existing major technological challenges faced by a traditional radiomic model: image acquisition, small data sets, image processing, labeling/segmentation, informative features, predicting molecular features and incorporating predictive models. Other potential impacts of artificial intelligence on the personalized treatment of PCa will also be discussed. The role of deep radiomics analysis-a deep texture analysis, which extracts features from convolutional neural networks layers, will be highlighted. Existing clinical work and upcoming clinical trials will be reviewed, directing investigators to pertinent future directions in the field. For future progress to result in clinical translation, the field will likely require multi-institutional collaboration in producing prospectively populated and expertly labeled imaging libraries.
RI Chaddad, Ahmad/AAG-3730-2020; Kucharczyk, Michael/ABB-4376-2021;
   Cheddad, Abbas/R-7061-2018
OI Chaddad, Ahmad/0000-0003-3402-9576; Kucharczyk,
   Michael/0000-0002-2857-6840; Hassan, Lama/0000-0002-2368-0366; Clarke,
   Sharon Elizabeth/0000-0001-5759-5808; Cheddad, Abbas/0000-0002-4390-411X
EI 2072-6694
PD FEB
PY 2021
VL 13
IS 3
AR 552
DI 10.3390/cancers13030552
UT WOS:000614966800001
PM 33535569
ER

PT J
AU Le, MT
   Tu, CT
   Guo, SM
   Lien, JJJ
AF Le, Minh-Tri
   Tu, Ching-Ting
   Guo, Shu-Mei
   Lien, Jenn-Jier James
TI A PCB Alignment System Using RST Template Matching with CUDA on Embedded
   GPU Board
SO SENSORS
CT 16th International Conference on Automation Technology (Automation)
CY NOV 22-24, 2019
CL Natl Taiwan Univ Sci & Technol, Taipei, TAIWAN
SP Chinese Inst Automat Engineers
HO Natl Taiwan Univ Sci & Technol
AB The fiducial-marks-based alignment process is one of the most critical steps in printed circuit board (PCB) manufacturing. In the alignment process, a machine vision technique is used to detect the fiducial marks and then adjust the position of the vision system in such a way that it is aligned with the PCB. The present study proposed an embedded PCB alignment system, in which a rotation, scale and translation (RST) template-matching algorithm was employed to locate the marks on the PCB surface. The coordinates and angles of the detected marks were then compared with the reference values which were set by users, and the difference between them was used to adjust the position of the vision system accordingly. To improve the positioning accuracy, the angle and location matching process was performed in refinement processes. To overcome the matching time, in the present study we accelerated the rotation matching by eliminating the weak features in the scanning process and converting the normalized cross correlation (NCC) formula to a sum of products. Moreover, the scanning time was reduced by implementing the entire RST process in parallel on threads of a graphics processing unit (GPU) by applying hash functions to find refined positions in the refinement matching process. The experimental results showed that the resulting matching time was around 32x faster than that achieved on a conventional central processing unit (CPU) for a test image size of 1280 x 960 pixels. Furthermore, the precision of the alignment process achieved a considerable result with a tolerance of 36.4 mu m.
RI Hộp, Thế Giới/HNQ-4216-2023
EI 1424-8220
PD MAY
PY 2020
VL 20
IS 9
AR 2736
DI 10.3390/s20092736
UT WOS:000537106200300
PM 32403333
ER

PT J
AU Waltz, F
   Soufari, H
   Bochler, A
   Giege, P
   Hashem, Y
AF Waltz, Florent
   Soufari, Heddy
   Bochler, Anthony
   Giege, Philippe
   Hashem, Yaser
TI Cryo-EM structure of the RNA-rich plant mitochondrial ribosome
SO NATURE PLANTS
AB The vast majority of eukaryotic cells contain mitochondria, essential powerhouses and metabolic hubs(1). These organelles have a bacterial origin and were acquired during an early endosymbiosis event(2). Mitochondria possess specialized gene expression systems composed of various molecular machines, including the mitochondrial ribosomes (mitoribosomes). Mitoribosomes are in charge of translating the few essential mRNAs still encoded by mitochondrial genomes(3). While chloroplast ribosomes strongly resemble those of bacteria(4,5), mitoribosomes have diverged significantly during evolution and present strikingly different structures across eukaryotic species(6-10). In contrast to animals and trypanosomatids, plant mitoribosomes have unusually expanded ribosomal RNAs and have conserved the short 5S rRNA, which is usually missing in mitoribosomes(11). We have previously characterized the composition of the plant mitoribosome(6), revealing a dozen plant-specific proteins in addition to the common conserved mitoribosomal proteins. In spite of the tremendous recent advances in the field, plant mitoribosomes remained elusive to high-resolution structural investigations and the plant-specific ribosomal features of unknown structures. Here, we present a cryo-electron microscopy study of the plant 78S mitoribosome from cauliflower at near-atomic resolution. We show that most of the plant-specific ribosomal proteins are pentatricopeptide repeat proteins (PPRs) that deeply interact with the plant-specific rRNA expansion segments. These additional rRNA segments and proteins reshape the overall structure of the plant mitochondrial ribosome, and we discuss their involvement in the membrane association and mRNA recruitment prior to translation initiation. Finally, our structure unveils an rRNA-constructive phase of mitoribosome evolution across eukaryotes.
   Mitochondria ribosomes translate essential mRNAs encoded by mitochondrial genomes. The cryo-EM structure of the 78S mitoribosome from cauliflower shows plant-specific pentatricopeptide repeat proteins binding rRNAs expanded over those of animals.
OI WALTZ, Florent/0000-0002-2251-3363
SN 2055-026X
EI 2055-0278
PD APR
PY 2020
VL 6
IS 4
BP 377
EP +
DI 10.1038/s41477-020-0631-5
EA APR 2020
UT WOS:000523952800001
PM 32251374
ER

PT J
AU Lajevardi, SM
   Arakala, A
   Davis, SA
   Horadam, KJ
AF Lajevardi, Seyed Mehdi
   Arakala, Arathi
   Davis, Stephen A.
   Horadam, Kathy J.
TI Retina Verification System Based on Biometric Graph Matching
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
AB This paper presents an automatic retina verification framework based on the biometric graph matching (BGM) algorithm. The retinal vasculature is extracted using a family of matched filters in the frequency domain and morphological operators. Then, retinal templates are defined as formal spatial graphs derived from the retinal vasculature. The BGM algorithm, a noisy graph matching algorithm, robust to translation, non-linear distortion, and small rotations, is used to compare retinal templates. The BGM algorithm uses graph topology to define three distance measures between a pair of graphs, two of which are new. A support vector machine (SVM) classifier is used to distinguish between genuine and imposter comparisons. Using single as well as multiple graph measures, the classifier achieves complete separation on a training set of images from the VARIA database (60% of the data), equaling the state-of-the-art for retina verification. Because the available data set is small, kernel density estimation (KDE) of the genuine and imposter score distributions of the training set are used to measure performance of the BGM algorithm. In the one dimensional case, the KDE model is validated with the testing set. A 0 EER on testing shows that the KDE model is a good fit for the empirical distribution. For the multiple graph measures, a novel combination of the SVM boundary and the KDE model is used to obtain a fair comparison with the KDE model for the single measure. A clear benefit in using multiple graph measures over a single measure to distinguish genuine and imposter comparisons is demonstrated by a drop in theoretical error of between 60% and more than two orders of magnitude.
SN 1057-7149
EI 1941-0042
PD SEP
PY 2013
VL 22
IS 9
BP 3625
EP 3635
DI 10.1109/TIP.2013.2266257
UT WOS:000324382700016
PM 23744685
ER

PT J
AU Kumar, P
   Sharma, RK
AF Kumar, Parteek
   Sharma, Rajendra Kumar
TI Punjabi DeConverter for generating Punjabi from Universal Networking
   Language
SO JOURNAL OF ZHEJIANG UNIVERSITY-SCIENCE C-COMPUTERS & ELECTRONICS
AB DeConverter is core software in a Universal Networking Language (UNL) system. A UNL system has EnConverter and DeConverter as its two major components. EnConverter is used to convert a natural language sentence into an equivalent UNL expression, and DeConverter is used to generate a natural language sentence from an input UNL expression. This paper presents design and development of a Punjabi DeConverter. It describes five phases of the proposed Punjabi DeConverter, i.e., UNL parser, lexeme selection, morphology generation, function word insertion, and syntactic linearization. This paper also illustrates all these phases of the Punjabi DeConverter with a special focus on syntactic linearization issues of the Punjabi DeConverter. Syntactic linearization is the process of defining arrangements of words in generated output. The algorithms and pseudocodes for implementation of syntactic linearization of a simple UNL graph, a UNL graph with scope nodes and a node having un-traversed parents or multiple parents in a UNL graph have been discussed in this paper. Special cases of syntactic linearization with respect to Punjabi language for UNL relations like 'and', 'or', 'fmt', 'cnt', and 'seq' have also been presented in this paper. This paper also provides implementation results of the proposed Punjabi DeConverter. The DeConverter has been tested on 1000 UNL expressions by considering a Spanish UNL language server and agricultural domain threads developed by Indian Institute of Technology (IIT), Bombay, India, as gold-standards. The proposed system generates 89.0% grammatically correct sentences, 92.0% faithful sentences to the original sentences, and has a fluency score of 3.61 and an adequacy score of 3.70 on a 4-point scale. The system is also able to achieve a bilingual evaluation understudy (BLEU) score of 0.72.
RI Kumar, Parteek/AAW-1551-2020
SN 1869-1951
EI 1869-196X
PD MAR
PY 2013
VL 14
IS 3
BP 179
EP 196
DI 10.1631/jzus.C1200061
UT WOS:000316087700003
ER

PT J
AU Jain, AK
   Mustafa, T
   Zhou, Y
   Burdette, C
   Chirikjian, GS
   Fichtinger, G
AF Jain, AK
   Mustafa, T
   Zhou, Y
   Burdette, C
   Chirikjian, GS
   Fichtinger, G
TI FTRAC - A robust fluoroscope tracking fiducial
SO MEDICAL PHYSICS
AB C-arm fluoroscopy is ubiquitous in contemporary surgery, but it lacks the ability to accurately reconstruct three-dimensional (3D) information. A major obstacle in fluoroscopic reconstruction is discerning the pose of the x-ray image, in 3D space. Optical/magnetic trackers tend to be prohibitively expensive, intrusive and cumbersome in many applications. We present single-image-based fluoroscope tracking (FTRAC) with the use of an external radiographic fiducial consisting of a mathematically optimized set of ellipses, lines, and points. This is an improvement over contemporary fiducials, which use only points. The fiducial encodes six degrees of freedom in a single image by creating a unique view from any direction. A nonlinear optimizer can rapidly compute the pose of the fiducial using this image. The current embodiment has salient attributes: small dimensions (3 X 3 X 5 cm); need not be close to the anatomy of interest; and accurately segmentable. We tested the fiducial and the pose recovery method on synthetic data and also experimentally on a precisely machined mechanical phantom. Pose recovery in phantom experiments had an accuracy of 0.56 mm in translation and 0.33 degrees in orientation. Object reconstruction had a mean error of 0.53 mm with 0.16 mm STD. The method offers accuracies similar to commercial tracking systems, and appears to be sufficiently robust for intraoperative quantitative C-arm fluoroscopy. Simulation experiments indicate that the size can be further reduced to 1 X 1 X 2 cm, with only a marginal drop in accuracy. (c) 2005 American Association of Physicists in Medicine.
RI Chirikjian, Gregory/A-3314-2010
SN 0094-2405
EI 2473-4209
PD OCT
PY 2005
VL 32
IS 10
BP 3185
EP 3198
DI 10.1118/1.2047782
UT WOS:000232755900015
PM 16279072
ER

PT J
AU DYADKIN, LJ
AF DYADKIN, LJ
TI MULTIBOX PARSERS
SO SIGPLAN NOTICES
AB Traditional compiler front end generating tools such as Lex/Yacc assume a front end consisting of two boxes: a lexical box and a syntax box. Lex produces a lexical analyzer using regular expressions as a token description. Yacc generates a syntax analyzer from the LALR grammar for the parsed language. This approach has big problems with such lexically and syntactically complex languages as Fortran. The main reason for these problems is that regular expressions, being equivalent to a right linear grammar, do not have the capability to describe the incredibly complex lexical structure of Fortran. As a result, compiler writers abandon Lex and produce handwritten lexers for Fortran, thus defeating the main purpose of the parser generator, automation.
   This work solves these problems by introducing a multibox parser, where each lower box modifies its input language to produce a more ''straightened'' output language for the higher box. The number of boxes reflects the complexity of the parsed language.
   For example, Fortran requires more boxes than does C. Each box is represented by an L-attributed translation grammar in simple assignment form with an LL(1) input grammar. LL(1) grammars were chosen for higher speed, smaller size, and because, unlike regular expressions, they can express constructs such as nested parentheses, a capability which is required for parsing Fortran on the lexical level.         New operations for the LL(1) machine are added to ensure it is strictly forward moving, without backtracking in the parsed source code. We have ''tended the LL(1) grammars to ''indexed LL(1) grammars.'' This enhancement allows more of the resulting code to be automatically generated, rather than handwritten. New parser generating tools have been developed by us to support this technology. The multibox approach has been implemented in the Lahey Fortran 90 compiler.
SN 0362-1340
PD JUL
PY 1994
VL 29
IS 7
BP 54
EP 60
UT WOS:A1994NU15200011
ER

PT J
AU Suebsamarn, O
   Kamimura, Y
   Suzuki, A
   Kodama, Y
   Mizuno, R
   Osawa, Y
   Komatsu, T
   Sato, T
   Haga, K
   Kobayashi, R
   Naito, E
   Kida, M
   Kishimoto, K
   Mizuno, J
   Hayasaki, H
   Izumi, K
AF Suebsamarn, O.
   Kamimura, Y.
   Suzuki, A.
   Kodama, Y.
   Mizuno, R.
   Osawa, Y.
   Komatsu, T.
   Sato, T.
   Haga, K.
   Kobayashi, R.
   Naito, E.
   Kida, M.
   Kishimoto, K.
   Mizuno, J.
   Hayasaki, H.
   Izumi, K.
TI In-process monitoring of a tissue-engineered oral mucosa fabricated on a
   micropatterned collagen scaffold: use of optical coherence tomography
   for quality control
SO HELIYON
AB Background: We previously reported a novel technique for fabricating dermo-epidermal junction (DEJ)-like micropatterned collagen scaffolds to manufacture an ex vivo produced oral mucosa equivalent (EVPOME) for clinical translation; however, more biomimetic micropatterns are required to promote oral keratinocyte-based tissue engineering/regenerative medicine. In addition, in-process monitoring for quality control of tissueengineered products is key to successful clinical outcomes. However, evaluating three-dimensional tissue-engineered constructs such as EVPOME is challenging. This study aimed to update our technique to fabricate a more biomimetic DEJ structure of oral mucosa and to investigate the efficacy of optical coherence tomography (OCT) in combination with deep learning for non-invasive EVPOME monitoring.Methods: A picosecond laser-textured microstructure mimicking DEJ on stainless steel was used as a negative mould to fabricate the micropatterned collagen scaffold. During EVPOME manufacturing, OCT was applied twice to monitor the EVPOME and evaluate its epithelial thickness.Findings: Our moulding system resulted in successful micropattern replication on the curved collagen scaffold. OCT imaging visualised the epithelial layer and the underlying micropatterned scaffold in EVPOME, enabling to non-invasively detect specific defects not found before the histological examination. Additionally, a gradual increase in epithelial thickness was observed over time.Conclusion: These findings demonstrate the feasibility of using a stainless-steel negative mould to create a more biomimetic micropattern on collagen scaffolds and the potential of OCT imaging for quality control in oral keratinocyte-based tissue engineering/regenerative medicine.
EI 2405-8440
PD NOV
PY 2022
VL 8
IS 11
AR e11468
DI 10.1016/j.heliyon.2022.e11468
UT WOS:000911731100021
PM 36406717
ER

PT J
AU Uddin, KMS
   Zhang, MH
   Anastasio, M
   Zhu, Q
AF Uddin, K. M. Shihab
   Zhang, Menghao
   Anastasio, Mark
   Zhu, Quing
TI Optimal breast cancer diagnostic strategy using combined ultrasound and
   diffuse optical tomography
SO BIOMEDICAL OPTICS EXPRESS
AB Ultrasound (US)-guided near-infrared diffuse optical tomography (DOT) has demonstrated great potential as an adjunct breast cancer diagnosis tool to US imaging alone, especially in reducing unnecessary benign biopsies. However, DOT data processing and image reconstruction speeds remain slow compared to the real-time speed of US. Real-time or near real-time diagnosis with DOT is an important step toward the clinical translation of US-guided DOT. Here, to address this important need, we present a two-stage diagnostic strategy that is both computationally efficient and accurate. In the first stage, benign lesions are identified in near real-time by use of a random forest classifier acting on the DOT measurements and the radiologists' US diagnostic scores. Any lesions that cannot be reliably classified by the random forest classifier will be passed on to the second stage which begins with image reconstruction. Functional information from the reconstructed hemoglobin concentrations is employed by a Support Vector Machine (SVM) classifier for diagnosis at the end of the second stage. This two-step classification approach which combines both perturbation data and functional features, results in improved classification, as denoted by the receiver operating characteristic (ROC) curve. Using this two-step approach, the area under the ROC curve (AUC) is 0.937 +/- 0.009, with a sensitivity of 91.4% and specificity of 85.7%. In comparison, using functional features and US score yields an AUC of 0.892 +/- 0.027, with a sensitivity of 90.2% and specificity of 74.5%. Most notably, the specificity is increased by more than 10% due to the implementation of the random forest classifier. (C) 2020 Optical Society of America under the terms of the OSA Open Access Publishing Agreement
OI Zhu, Quing/0000-0002-1837-2588
SN 2156-7085
PD MAY 1
PY 2020
VL 11
IS 5
BP 2722
EP 2737
DI 10.1364/BOE.389275
UT WOS:000532568000031
PM 32499955
ER

PT J
AU Jang, M
   Seo, S
   Kang, P
AF Jang, Myeongjun
   Seo, Seungwan
   Kang, Pilsung
TI Recurrent neural network-based semantic variational autoencoder for
   Sequence-to-sequence learning
SO INFORMATION SCIENCES
AB Sequence-to-sequence (Seq2seq) models have played an important role in the recent success of various natural language processing methods, such as machine translation, text summarization, and speech recognition. However, current Seq2seq models have trouble preserving global latent information from a long sequence of words. Variational autoencoder (VAE) alleviates this problem by learning a continuous semantic space of the input sentence. However, it does not solve the problem completely. In this paper, we propose a new recurrent neural network (RNN)-based Seq2seq model, RNN semantic variational autoencoder (RNN-SVAE), to better capture the global latent information of a sequence of words. To suitably reflect the meanings of words in a sentence regardless of their position within the sentence, we utilized two approaches: (1) constructing a document information vector based on the attention information between the final state of the encoder and every prior hidden state, and (2) extracting the semantic vector based on the self-attention mechanism. Then, the mean and standard deviation of the continuous semantic space are learned by using this vector to take advantage of the variational method. By using the document information vector and the self-attention mechanism to find the semantic space of the sentence, it becomes possible to better capture the global latent feature of the sentence. Experimental results of three natural language tasks (i.e., language modeling, missing word imputation, paraphrase identification) confirm that the proposed RNN-SVAE yields higher performance than two benchmark models. (C) 2019 Elsevier Inc. All rights reserved.
RI Seo, Seungwan/AAC-8687-2021
OI Kang, Pilsung/0000-0001-7663-3937
SN 0020-0255
EI 1872-6291
PD JUL
PY 2019
VL 490
BP 59
EP 73
DI 10.1016/j.ins.2019.03.066
UT WOS:000468011900004
ER

PT J
AU Ezeani, M
   Prabhu, S
AF Ezeani, Martin
   Prabhu, Sandeep
TI PI3K signalling at the intersection of cardio-oncology networks: cardiac
   safety in the era of AI
SO CELLULAR AND MOLECULAR LIFE SCIENCES
AB Class I phosphoinositide 3-kinases (PI3Ks) are a family of lipid kinases. They are super elevated in many human cancer types and exert their main cellular functions by activating Akt to trigger an array of distinct responses, affecting metabolism and cell polarity. The signal equally plays important roles in cardiovascular pathophysiology. PI3K is required for cardiogenesis and regulation of cardiac structure and function. Overexpression of PI3K governs the development of cardiac pressure overload adaptation and compensatory hypertrophy. Therefore, inhibition of PI3K shortens life span, enhances cardiac dysfunction and pathological hypertrophy. The inverse inhibition effect, however, desirably destroys many cancer cells by blocking several aspects of the tumorigenesis phenotype. Given the contrasting effects in cardio-oncology; the best therapeutic strategy to target PI3K in cancer, while maintaining or rather increasing cardiac safety is under intense investigational scrutiny. To improve our molecular understanding towards identifying cardiac safety signalling of PI3K and/or better therapeutic strategy for cancer treatment, this article reviews PI3K signalling in cardio-oncology. PI3K signalling at the interface of metabolism, inflammation and immunity, and autonomic innervation networks were examined. Examples were then given of cardiovascular drugs that target the networks, being repurposed for cancer treatment. This was followed by an intersection scheme of the networks that can be functionalised with machine learning for safety and risk prediction, diagnoses, and defining new novel encouraging leads and targets for clinical translation. This will hopefully overcome the challenges of the one-signalling-one-health-outcome alliance, and expand our knowledge of the totality of PI3K signalling in cardio-oncology.
OI Ezeani, Martin/0000-0002-1270-9469
SN 1420-682X
EI 1420-9071
PD DEC
PY 2022
VL 79
IS 12
AR 594
DI 10.1007/s00018-022-04627-1
UT WOS:000884292800002
PM 36380172
ER

PT J
AU Sugano, N
   Hamada, H
   Uemura, K
   Takashima, K
   Nakahara, I
AF Sugano, Nobuhiko
   Hamada, Hidetoshi
   Uemura, Keisuke
   Takashima, Kazuma
   Nakahara, Ichiro
TI Numerical analysis evaluation of artificial joints
SO JOURNAL OF ARTIFICIAL ORGANS
AB Artificial joints are exposed to loads on a daily basis. Loads on the bone through the artificial joint and the joint's sliding surface shear force may cause implant fixation failure, fatigue fractures, wear of the bearing and foreign body reactions. Artificial joints can experience sudden internal damage, which can be fatal if it occurs during activities performed at high altitudes or in water. The standard design hip prosthesis has a metal femoral stem. Most stem fractures are caused at the proximal one third of the stem by fatigue due to repetitive loading. Femoral stem neck fractures can also occur. To eliminate in vivo prosthesis failures, safety performance preclinical studies evaluate stem body and neck breakage. However, the development of new femoral stems via prototyping and fatigue test verification would require excessive time and money. Therefore, evaluation methods based on numerical analyses, such as finite element analysis (FEA), have been introduced to simulate tests on actual machines. Fatigue strength design verification using FEA can efficiently identify a design that can pass International Organization for Standardization fatigue tests. FEA may also aid with composite implant development by enabling efficient preclinical testing to prove safety using minimal actual fatigue testing. Once a biological safety study of a composite material is performed, a clinical trial can prove its clinical efficacy and safety and device regulatory approval can be requested. This review was created based on a translation of the Japanese review written in the Japanese Journal of Artificial Organs in 2020 (Vol. 49, No. 3, pp. 195-198), with adding some additional contents and references.
RI Uemura, Keisuke/ABC-5817-2020
OI Uemura, Keisuke/0000-0002-9245-1743; Sugano,
   Nobuhiko/0000-0002-5305-3179
SN 1434-7229
EI 1619-0904
PD SEP
PY 2022
VL 25
IS 3
BP 185
EP 190
DI 10.1007/s10047-022-01345-0
EA JUL 2022
UT WOS:000827469600001
PM 35842848
ER

PT J
AU Oliver, LD
   Hawco, C
   Viviano, JD
   Voineskos, AN
AF Oliver, Lindsay D.
   Hawco, Colin
   Viviano, Joseph D.
   Voineskos, Aristotle N.
TI From the Group to the Individual in Schizophrenia Spectrum Disorders:
   Biomarkers of Social Cognitive Impairments and Therapeutic Translation
SO BIOLOGICAL PSYCHIATRY
AB People with schizophrenia spectrum disorders (SSDs) often experience persistent social cognitive impairments, associated with poor functional outcome. There are currently no approved treatment options for these debilitating symptoms, highlighting the need for novel therapeutic strategies. Work to date has elucidated differential social processes and underlying neural circuitry affected in SSDs, which may be amenable to modulation using neurostimulation. Further, advances in functional connectivity mapping and electric field modeling may be used to identify individualized treatment targets to maximize the impact of brain stimulation on social cognitive networks. Here, we review literature supporting a roadmap for translating functional connectivity biomarker discovery to individualized treatment development for social cognitive impairments in SSDs. First, we outline the relevance of social cognitive impairments in SSDs. We review machine learning approaches for dimensional brain-behavior biomarker discovery, emphasizing the importance of individual differences. We synthesize research showing that brain stimulation techniques, such as repetitive transcranial magnetic stimulation, can be used to target relevant networks. Further, functional connectivity-based individualized targeting may enhance treatment response. We then outline recent approaches to account for neuroanatomical variability and optimize coil positioning to individually maximize target engagement. Overall, the synthesized literature provides support for the utility and feasibility of this translational approach to precision treatment. The proposed roadmap to translate biomarkers of social cognitive impairments to individualized treatment is currently under evaluation in precision-guided trials. Such a translational approach may also be applicable across conditions and generalizable for the development of individualized neurostimulation targeting other behavioral deficits.
RI Oliver, Lindsay/ACZ-4360-2022
OI Oliver, Lindsay/0000-0003-2163-7257; Viviano,
   Joseph/0000-0001-7016-5212; Voineskos, Aristotle/0000-0003-0156-0395
SN 0006-3223
EI 1873-2402
PD APR 15
PY 2022
VL 91
IS 8
BP 699
EP 708
DI 10.1016/j.biopsych.2021.09.007
EA MAR 2022
UT WOS:000820422800008
PM 34799097
ER

PT J
AU Ali, K
   Lai, XN
   Luo, ZY
   Lhotak, O
   Dolby, J
   Tip, F
AF Ali, Karim
   Lai, Xiaoni
   Luo, Zhaoyi
   Lhotak, Ondrej
   Dolby, Julian
   Tip, Frank
TI A Study of Call Graph Construction for JVM-Hosted Languages
SO IEEE TRANSACTIONS ON SOFTWARE ENGINEERING
AB Call graphs have many applications in software engineering, including bug-finding, security analysis, and code navigation in IDEs. However, the construction of call graphs requires significant investment in program analysis infrastructure. An increasing number of programming languages compile to the Java Virtual Machine (JVM), and program analysis frameworks such as WALA and SOOT support a broad range of program analysis algorithms by analyzing JVM bytecode. This approach has been shown to work well when applied to bytecode produced from Java code. In this paper, we show that it also works well for diverse other JVM-hosted languages: dynamically-typed functional Scheme, statically-typed object-oriented Scala, and polymorphic functional OCaml. Effectively, we get call graph construction for these languages for free, using existing analysis infrastructure for Java, with only minor challenges to soundness. This, in turn, suggests that bytecode-based analysis could serve as an implementation vehicle for bug-finding, security analysis, and IDE features for these languages. We present qualitative and quantitative analyses of the soundness and precision of call graphs constructed from JVM bytecodes for these languages, and also for Groovy, Clojure, Python, and Ruby. However, we also show that implementation details matter greatly. In particular, the JVM-hosted implementations of Groovy, Clojure, Python, and Ruby produce very unsound call graphs, due to the pervasive use of reflection, invokedynamic instructions, and run-time code generation. Interestingly, the dynamic translation schemes employed by these languages, which result in unsound static call graphs, tend to be correlated with poor performance at run time.
OI Tip, Frank/0000-0002-1862-3498
SN 0098-5589
EI 1939-3520
PD DEC 1
PY 2021
VL 47
IS 12
BP 2644
EP 2666
DI 10.1109/TSE.2019.2956925
UT WOS:000728924600001
ER

PT J
AU Nan, GC
   Wang, ZK
   Wang, CH
   Wu, B
   Wang, ZC
   Liu, WQ
   Lombardi, F
AF Nan, Guocai
   Wang, Zhengkuan
   Wang, Chenghua
   Wu, Bi
   Wang, Zhican
   Liu, Weiqiang
   Lombardi, Fabrizio
TI An Energy Efficient Accelerator for Bidirectional Recurrent Neural
   Networks (BiRNNs) Using Hybrid-Iterative Compression With Error
   Sensitivity
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
AB Recurrent Neural Networks (RNNs) have been widely used in many sequential applications, such as machine translation, speech recognition and sentiment analysis. Long Term Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) are widely used variants of RNN due to their effectiveness in overcoming gradient vanishing and exploding problems; however, compared to conventional RNN, their massive storage and computation requirements hinder their application. In addition, the recurrent structure of RNNs makes them prone to accumulate errors, resulting in a severe loss of accuracy. In this work, we propose a hybrid-iterative compression (HIC) algorithm for LSTM/GRU. By exploiting the error sensitivity of RNN, the gating units are divided into error-sensitive and error-insensitive groups, that are compressed using different algorithms. By using this approach, a 37.1x/32.3x compression ratio is achieved with negligible accuracy loss for LSTM/GRU. Further, an energy efficient accelerator for bidirectional RNNs is proposed. In this accelerator, the data flow of the matrix operation unit based on the block structure matrix (MOU-S) is improved through rearranging weights; the utilization of BRAM is improved through a fine-grained parallelism configuration of matrix-vector multiplications (MVMs). Meanwhile, the timing matching strategy alleviates the load-imbalance problem between MOU-S and the matrix operation unit based on top-k pruning (MOU-P). When running at 200MHz on Xilinx ADM-PCIE-7V3 FPCA, the proposed design achieves an improvement in energy efficiency in a range of 5%-237% for LSTM networks, and an improvement of 58% for GRU networks compared with state-of-the-art designs.
OI Liu, Weiqiang/0000-0001-8398-8648; Lombardi,
   Fabrizio/0000-0003-3152-3245; Wu, Bi/0000-0001-9972-0478; Wang,
   Zhengkuan/0000-0002-1999-1065
SN 1549-8328
EI 1558-0806
PD SEP
PY 2021
VL 68
IS 9
BP 3707
EP 3718
DI 10.1109/TCSI.2021.3091318
UT WOS:000684001600018
ER

PT J
AU Ayoub, J
   Yang, XJ
   Zhou, F
AF Ayoub, Jackie
   Yang, X. Jessie
   Zhou, Feng
TI Combat COVID-19 infodemic using explainable natural language processing
   models
SO INFORMATION PROCESSING & MANAGEMENT
AB Misinformation of COVID-19 is prevalent on social media as the pandemic unfolds, and the associated risks are extremely high. Thus, it is critical to detect and combat such misinformation. Recently, deep learning models using natural language processing techniques, such as BERT (Bidirectional Encoder Representations from Transformers), have achieved great successes in detecting misinformation. In this paper, we proposed an explainable natural language processing model based on DistilBERT and SHAP (Shapley Additive exPlanations) to combat misinformation about COVID-19 due to their efficiency and effectiveness. First, we collected a dataset of 984 claims about COVID-19 with fact-checking. By augmenting the data using back-translation, we doubled the sample size of the dataset and the DistilBERT model was able to obtain good performance (accuracy: 0.972; areas under the curve: 0.993) in detecting misinformation about COVID-19. Our model was also tested on a larger dataset for AAAI2021 COVID-19 Fake News Detection Shared Task and obtained good performance (accuracy: 0.938; areas under the curve: 0.985). The performance on both datasets was better than traditional machine learning models. Second, in order to boost public trust in model prediction, we employed SHAP to improve model explainability, which was further evaluated using a between-subjects experiment with three conditions, i.e., text (T), text+SHAP explanation (TSE), and text+SHAP explanation+source and evidence (TSESE). The participants were significantly more likely to trust and share information related to COVID-19 in the TSE and TSESE conditions than in the T condition. Our results provided good implications for detecting misinformation about COVID-19 and improving public trust.
RI Gui, Yuliang/AAP-5071-2021
OI Zhou, Feng/0000-0001-6123-073X
SN 0306-4573
EI 1873-5371
PD JUL
PY 2021
VL 58
IS 4
AR 102569
DI 10.1016/j.ipm.2021.102569
EA MAR 2021
UT WOS:000658372100021
PM 33776192
ER

PT J
AU Huie, JR
   Ferguson, AR
   Kyritsis, N
   Pan, JZ
   Irvine, KA
   Nielson, JL
   Schupp, PG
   Oldham, MC
   Gensel, JC
   Lin, A
   Segal, MR
   Ratan, RR
   Bresnahan, JC
   Beattie, MS
AF Huie, J. R.
   Ferguson, A. R.
   Kyritsis, N.
   Pan, J. Z.
   Irvine, K. -A.
   Nielson, J. L.
   Schupp, P. G.
   Oldham, M. C.
   Gensel, J. C.
   Lin, A.
   Segal, M. R.
   Ratan, R. R.
   Bresnahan, J. C.
   Beattie, M. S.
TI Machine intelligence identifies soluble TNFa as a therapeutic target for
   spinal cord injury
SO SCIENTIFIC REPORTS
AB Traumatic spinal cord injury (SCI) produces a complex syndrome that is expressed across multiple endpoints ranging from molecular and cellular changes to functional behavioral deficits. Effective therapeutic strategies for CNS injury are therefore likely to manifest multi-factorial effects across a broad range of biological and functional outcome measures. Thus, multivariate analytic approaches are needed to capture the linkage between biological and neurobehavioral outcomes. Injury-induced neuroinflammation (NI) presents a particularly challenging therapeutic target, since NI is involved in both degeneration and repair. Here, we used big-data integration and large-scale analytics to examine a large dataset of preclinical efficacy tests combining five different blinded, fully counter-balanced treatment trials for different acute anti-inflammatory treatments for cervical spinal cord injury in rats. Multi-dimensional discovery, using topological data analysis (TDA) and principal components analysis (PCA) revealed that only one showed consistent multidimensional syndromic benefit: intrathecal application of recombinant soluble TNF alpha receptor 1 (sTNFR1), which showed an inverse-U dose response efficacy. Using the optimal acute dose, we showed that clinically-relevant 90 min delayed treatment profoundly affected multiple biological indices of NI in the first 48 h after injury, including reduction in pro-inflammatory cytokines and gene expression of a coherent complex of acute inflammatory mediators and receptors. Further, a 90 min delayed bolus dose of sTNFR1 reduced the expression of NI markers in the chronic perilesional spinal cord, and consistently improved neurological function over 6 weeks post SCI. These results provide validation of a novel strategy for precision preclinical drug discovery that is likely to improve translation in the difficult landscape of CNS trauma, and confirm the importance of TNF alpha signaling as a therapeutic target.
RI Irvine, Karen-amanda/AAF-1717-2022; Irvine, Karen-amanda/AFG-7716-2022
OI Irvine, Karen-amanda/0000-0001-5259-1824; Irvine,
   Karen-amanda/0000-0001-5259-1824; Ferguson, Adam/0000-0001-7102-1608;
   Kyritsis, Nikos/0000-0001-7801-5796
SN 2045-2322
PD FEB 9
PY 2021
VL 11
IS 1
AR 3442
DI 10.1038/s41598-021-82951-5
UT WOS:000684872200005
PM 33564058
ER

PT J
AU Zhong, JY
   Hu, YF
   Si, LP
   Jia, G
   Xing, Y
   Zhang, H
   Yao, WW
AF Zhong, Jingyu
   Hu, Yangfan
   Si, Liping
   Jia, Geng
   Xing, Yue
   Zhang, Huan
   Yao, Weiwu
TI A systematic review of radiomics in osteosarcoma: utilizing radiomics
   quality score as a tool promoting clinical translation
SO EUROPEAN RADIOLOGY
AB Objectives To assess the methodological quality and risk of bias in radiomics studies investigating diagnosis, therapy response, and survival of patients with osteosarcoma. Methods In this systematic review, literatures on radiomics in osteosarcoma were included and assessed for methodological quality through the radiomics quality score (RQS). The risk of bias and concern of application was assessed using the Quality Assessment of Diagnostic Accuracy Studies tool. A meta-analysis of studies focusing on predicting osteosarcoma response to neoadjuvant chemotherapy was performed. Results Twelve radiomics studies exploring osteosarcoma were identified, and five were included in meta-analysis. The RQS reached an average of 20.4% (6.92 of 36) with good inter-rater agreement (ICC 0.95, 95% CI 0.85-0.99). Four studies validated results with an internal dataset, none of which used external dataset; one study was prospectively designed, and another one shared part of the dataset. The risk of bias and concern of application were mainly related to index test aspect. The meta-analysis showed a diagnostic odds ratio of 43.68 (95%CI 13.5-141.31) for predicting response to neoadjuvant chemotherapy with high heterogeneity and low methodological quality. Conclusions The overall scientific quality of included studies is insufficient; however, radiomics remains a promising technology for predicting treatment response, which might guide therapeutic decision-making and related to prognosis. Improvements in study design, validation, and open science needs to be made to demonstrate the generalizability of findings and to achieve clinical applications. Widespread application of RQS, pre-trained RQS scoring procedure, and modification of RQS in response to clinical needs are necessary.
RI Zhong, Jingyu/GPW-8726-2022; Zhong, Jingyu/ABG-3078-2021
OI Zhong, Jingyu/0000-0002-9817-2294; Zhong, Jingyu/0000-0002-9817-2294;
   Reis, AlessanRSS/0000-0001-8486-7469
SN 0938-7994
EI 1432-1084
PD MAR
PY 2021
VL 31
IS 3
BP 1526
EP 1535
DI 10.1007/s00330-020-07221-w
EA SEP 2020
UT WOS:000565480500002
PM 32876837
ER

PT J
AU Zhang, TY
   Cheng, J
   Fu, HZ
   Gu, ZW
   Xiao, YT
   Zhou, K
   Gao, SH
   Zheng, R
   Liu, J
AF Zhang, Tianyang
   Cheng, Jun
   Fu, Huazhu
   Gu, Zaiwang
   Xiao, Yuting
   Zhou, Kang
   Gao, Shenghua
   Zheng, Rui
   Liu, Jiang
TI Noise Adaptation Generative Adversarial Network for Medical Image
   Analysis
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
AB Machine learning has been widely used in medical image analysis under an assumption that the training and test data are under the same feature distributions. However, medical images from difference devices or the same device with different parameter settings are often contaminated with different amount and types of noises, which violate the above assumption. Therefore, the models trained using data from one device or setting often fail to work for that from another. Moreover, it is very expensive and tedious to label data and re-train models for all different devices or settings. To overcome this noise adaptation issue, it is necessary to leverage on the models trained with data from one device or setting for new data. In this paper, we reformulate this noise adaptation task as an image-to-image translation task such that the noise patterns from the test data are modified to be similar to those from the training data while the contents of the data are unchanged. In this paper, we propose a novel Noise Adaptation Generative Adversarial Network (NAGAN), which contains a generator and two discriminators. The generator aims to map the data from source domain to target domain. Among the two discriminators, one discriminator enforces the generated images to have the same noise patterns as those from the target domain, and the second discriminator enforces the content to be preserved in the generated images. We apply the proposed NAGAN on both optical coherence tomography (OCT) images and ultrasound images. Results show that the method is able to translate the noise style. In addition, we also evaluate our proposed method with segmentation task in OCT and classification task in ultrasound. The experimental results show that the proposed NAGAN improves the analysis outcome.
RI Cheng, Jun/E-7778-2016; LIU, JIANG Jimmy/AHB-8921-2022; Fu,
   Huazhu/A-1411-2014
OI Cheng, Jun/0000-0003-1786-6188; LIU, JIANG Jimmy/0000-0001-6281-6505;
   Fu, Huazhu/0000-0002-9702-5524; Zhang, Tianyang/0000-0002-5833-7840;
   Zhou, Kang/0000-0001-8789-4243; Gu, Zaiwang/0000-0001-8764-0622
SN 0278-0062
EI 1558-254X
PD APR
PY 2020
VL 39
IS 4
BP 1149
EP 1159
DI 10.1109/TMI.2019.2944488
UT WOS:000525265800031
PM 31567075
ER

PT J
AU Al-Thubaity, A
   Alkhalifa, A
   Almuhareb, A
   Alsanie, W
AF Al-Thubaity, Abdulmohsen
   Alkhalifa, Atheer
   Almuhareb, Abdulrahman
   Alsanie, Waleed
TI Arabic Diacritization Using Bidirectional Long Short-Term Memory Neural
   Networks With Conditional Random Fields
SO IEEE ACCESS
AB Arabic diacritics play a significant role in distinguishing words with the same orthography but different meanings, pronunciations, and syntactic functions. The presence of Arabic diacritics can be useful in many natural language processing applications, such as text-to-speech tasks, machine translation, and part-of-speech tagging. This article discusses the use of bidirectional long short-term memory neural networks with conditional random fields for Arabic diacritization. This approach requires no morphological analyzers, dictionary, or feature engineering, but rather uses a sequence-to-sequence schema. The input is a sequence of characters that constitute the sentence, and the output consists of the corresponding diacritic(s) for each character in that sentence. The performance of the proposed approach was examined using four datasets with different sizes and genres, namely, the King Abdulaziz City for Science and Technology text-to-speech (KACST TTS) dataset, the Holy Quran, Sahih Al-Bukhary, and the Penn Arabic Treebank (ATB). For training, 60% of the sentences were randomly selected from each dataset, 20% were selected for validation, and 20% were selected for testing. The trained models achieved diacritic error rates of 3.41%, 1.34%, 1.57%, and 2.13% and word error rates of 14.46%, 4.92%, 5.65%, and 8.43% on the KACST TTS, Holy Quran, Sahih Al-Bukhary, and ATB datasets, respectively. Comparison of the proposed method with those used in other studies and existing systems revealed that its results are comparable to or better than those of the state-of-the-art methods.
RI Al-Thubaity, AbdulMohsen/AAW-3824-2020
OI Al-Thubaity, AbdulMohsen/0000-0003-2376-0849; Alkhalifa,
   Atheer/0000-0002-6576-0735
SN 2169-3536
PY 2020
VL 8
BP 154984
EP 154996
DI 10.1109/ACCESS.2020.3018885
UT WOS:000566116800001
ER

PT J
AU Krezdorn, N
   Macleod, F
   Tasigiorgos, S
   Turk, M
   Wo, L
   Kiwanuka, H
   Lopdrup, R
   Kollar, B
   Edelman, ER
   Pomahac, B
AF Krezdorn, Nicco
   Macleod, Fiona
   Tasigiorgos, Sotirios
   Turk, Marvee
   Wo, Luccie
   Kiwanuka, Harriet
   Lopdrup, Rachel
   Kollar, Branislav
   Edelman, Elazer R.
   Pomahac, Bohdan
TI Twenty-Four-Hour Ex Vivo Perfusion with Acellular Solution Enables
   Successful Replantation of Porcine Forelimbs
SO PLASTIC AND RECONSTRUCTIVE SURGERY
CT 6th Harvard Surgery Research Day Symposium of the Harvard-Medical-School
CY MAY 13, 2017
CL Boston, MA
SP Harvard Med Sch
AB Background: A critical barrier to successful limb replantation and allotransplantation is the maximum allowable limb ischemia time of 4 to 6 hours. The current gold standard is to preserve amputated limbs on an ice slurry. Experimental machine perfusion has yielded promising results as an alternative. In particular, hypothermic acellular perfusion has enabled preservation of amputated limbs for up to 12 hours thus far. Methods: Amputated forelimbs of Yorkshire pigs were preserved on static cold storage at 4 degrees C for 4 hours (static cold storage group) or perfused at 8 degrees C for 24 hours (perfusion group) with oxygenated modified STEEN Solution perfusate before replantation. Animals were followed up for 7 days after replantation. Results: Eight animals underwent replantation (cold storage group, n = 4; perfusion group, n = 4). Seventy-five and 100 percent of animals in the static cold storage and perfusion groups survived for 7 days, respectively. Glycogen and adenosine triphosphate remained stable throughout perfusion. Heart and respiratory rate after replantation were increased in the static cold storage group. There was increased damage in muscle biopsy specimens obtained from animals in the static cold storage group after 7 days when compared with those from animals in the perfusion group. Conclusions: Hypothermic acellular ex vivo perfusion of limbs for up to 24 hours enables tissue preservation comparable to that obtained with conventional static cold storage for 4 hours and may reduce muscle damage and systemic reactions on limb replantation. Translation to human limbs may help improve limb replantation and allotransplantation outcomes.
RI Krezdorn, Nicco/AAP-6266-2021; Pomahac, Bohdan/AAH-1792-2019; Kollar,
   Branislav/W-5203-2019
OI Krezdorn, Nicco/0000-0003-2662-6290; Pomahac,
   Bohdan/0000-0003-3703-8240; Kollar, Branislav/0000-0001-6668-7798;
   Edelman, Elazer/0000-0002-7832-7156
SN 0032-1052
EI 1529-4242
PD OCT
PY 2019
VL 144
IS 4
BP 608E
EP 618E
DI 10.1097/PRS.0000000000006084
UT WOS:000487668000010
PM 31568296
ER

PT J
AU Fleming, A
   Winship, B
   Macfarlane, G
AF Fleming, Alan
   Winship, Brian
   Macfarlane, Gregor
TI Application of photogrammetry for spatial free surface elevation and
   velocity measurement in wave flumes
SO PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART M-JOURNAL OF
   ENGINEERING FOR THE MARITIME ENVIRONMENT
AB This article presents a method for obtaining the spatial free surface elevation and velocity field for the water surface in a wave flume over a relatively large measurement area for this type of application (approximately 1.5 m x 1.5 m). The technique employs proprietary videogrammetry software to post-process stereo images captured by multiple synchronised machine vision cameras. Dimensional resolution and other limitations are similar to that experienced for particle imaging velocimetry systems (x, y resolution of 2 mm). Imaging of the free surface was enabled by the use of millions of bespoke slightly positively buoyant fluorescent flakes. Ultraviolet light was used as the primary light source to excite the fluorescent flakes. Reflected ultraviolet light was attenuated by a high-pass filter fitted to the cameras so that only the emitted light from the fluorescent flakes was visible. The software was validated using a simple linear translation experiment. An application is demonstrated for the radiated wave field generated from a submerged sinusoidal heaving sphere for two cases: one single and five consecutive oscillations. Results agree with linear wave theory which indicates that the floating flakes had minimal impact on the water surface particle motion at the scale tested. It is, therefore, concluded that spatial measurement of the free surface elevation and velocity using the method presented has good resolution over a large measurement field. The flakes were found to follow the free surface well, but the measurement area is constrained to where the pattern of flakes exists in the image. Hence, application of floating markers is not suitable for experiments with significant outflow/upwelling which would wash away the floating markers from the intended measurement area.
RI Winship, Brian/K-2628-2019; Fleming, Alan/J-7779-2014
OI Winship, Brian/0000-0001-7400-9137; Macfarlane,
   Gregor/0000-0002-0518-430X; Fleming, Alan/0000-0002-2738-4521
SN 1475-0902
EI 2041-3084
PD AUG
PY 2019
VL 233
IS 3
BP 905
EP 917
DI 10.1177/1475090218797785
UT WOS:000482107100017
ER

PT C
AU Alani, AA
   Cosma, G
   Taherkhani, A
   McGinnity, TM
AF Alani, Ali A.
   Cosma, Georgina
   Taherkhani, Aboozar
   McGinnity, T. M.
GP IEEE
TI Hand Gesture Recognition Using an Adapted Convolutional Neural Network
   with Data Augmentation
SO 2018 4TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM2018)
CT 4th International Conference on Information Management (ICIM)
CY MAY 25-27, 2018
CL Univ Oxford, St Antonys Coll, Oxford, ENGLAND
SP IEEE, Univ Westminster
HO Univ Oxford, St Antonys Coll
AB Hand gestures provide a natural way for humans to interact with computers to perform a variety of different applications. However, factors such as the complexity of hand gesture structures, differences in hand size, hand posture, and environmental illumination can influence the performance of hand gesture recognition algorithms. Recent advances in Deep Learning have significantly advanced the performance of image recognition systems. In particular, the Deep Convolutional Neural Network has demonstrated superior performance in image representation and classification, compared to conventional machine learning approaches. This paper proposes an Adapted Deep Convolutional Neural Network (ADCNN) suitable for hand gesture recognition tasks. Data augmentation is initially applied which shifts images both horizontally and vertically to an extent of 20% of the original dimensions randomly, in order to numerically increase the size of the dataset and to add the robustness needed for a deep learning approach. These images are input into the proposed ADCNN model which is empowered by the presence of network initialization (ReLU and Softmax) and L2 Regularization to eliminate the problem of data overfitting. With these modifications, the experimental results using the ADCNN model demonstrate that it is an effective method of increasing the performance of CNN for hand gesture recognition. The model was trained and tested using 3750 static hand gesture images, which incorporate variations in features such as scale, rotation, translation, illumination and noise. The proposed ADCNN was compared to a baseline Convolutional Neural Network and the results show that the proposed ADCNN achieved a classification recognition accuracy of 99.73%, and a 4% improvement over the baseline Convolutional Neural Network model (95.73%).
RI Cosma, Georgina/G-3508-2019; Taherkhani, Aboozar/U-5374-2018
OI Cosma, Georgina/0000-0002-4663-6907; Alani, Ali/0000-0003-4765-5779;
   Taherkhani, Aboozar/0000-0002-3627-6362
BN 978-1-5386-6147-5
PY 2018
BP 5
EP 12
UT WOS:000467073600002
ER

PT C
AU Drukker, K
   Anderson, R
   Edwards, A
   Papaioannou, J
   Pineda, F
   Abe, H
   Karzcmar, G
   Giger, ML
AF Drukker, Karen
   Anderson, Rachel
   Edwards, Alexandra
   Papaioannou, John
   Pineda, Fred
   Abe, Hiroyuki
   Karzcmar, Gregory
   Giger, Maryellen L.
BE Petrick, N
   Mori, K
TI Radiomics for ultrafast dynamic contrast-enhanced breast MRI in the
   diagnosis of breast cancer: a pilot study
SO MEDICAL IMAGING 2018: COMPUTER-AIDED DIAGNOSIS
SE Proceedings of SPIE
CT Conference on Medical Imaging - Computer-Aided Diagnosis
CY FEB 12-15, 2018
CL Houston, TX
SP SPIE, DECTRIS Ltd
AB Radiomics for dynamic contrast-enhanced (DCE) breast MRI have shown promise in the diagnosis of breast cancer as applied to conventional DCE-MRI protocols. Here, we investigate the potential of using such radiomic features in the diagnosis of breast cancer applied on ultrafast breast MRI in which images are acquired every few seconds. The dataset consisted of 64 lesions (33 malignant and 31 benign) imaged with both 'conventional' and ultrafast DCE-MRI. After automated lesion segmentation in each image sequence, we calculated 38 radiomic features categorized as describing size, shape, margin, enhancement-texture, kinetics, and enhancement variance kinetics. For each feature, we calculated the 95% confidence interval of the area under the ROC curve (AUC) to determine whether the performance of each feature in the task of distinguishing between malignant and benign lesions was better than random guessing. Subsequently, we assessed performance of radiomic signatures in 10-fold cross-validation repeated 10 times using a support vector machine with as input all the features as well as features by category. We found that many of the features remained useful (AUC > 0.5) for the ultrafast protocol, with the exception of some features, e.g., those designed for late phase kinetics such as the washout rate. For ultrafast MRI, the radiomics enhancement-texture signature achieved the best performance, which was comparable to that of the kinetics signature for 'conventional' DCE-MRI, both achieving AUC values of 0.71. Radiomic developed for 'conventional' DCE-MRI shows promise for translation to the ultrafast protocol, where enhancement texture appears to play a dominant role.
RI Giger, Maryellen/AAH-1908-2021; Drukker, Karen/ABA-4844-2020
SN 0277-786X
EI 1996-756X
BN 978-1-5106-1640-0
PY 2018
VL 10575
AR UNSP 105753U
DI 10.1117/12.2293644
UT WOS:000432546900134
ER

PT J
AU Lott, G
   Falletto, N
   Devilder, PJ
   Kling, R
AF Lott, Geoffrey
   Falletto, Nicolas
   Devilder, Pierre-Jean
   Kling, Rainer
TI Optimizing the processing of sapphire with ultrashort laser pulses
SO JOURNAL OF LASER APPLICATIONS
CT 34th International Congress on Applications of Lasers and Electro-Optics
   (ICALEO)
CY OCT 18-22, 2015
CL Atlanta, GA
SP Laser Inst Amer
AB The ability to rapidly and precisely generate high-quality features with small dimensions in sapphire is paramount for broadening its appeal and expanding its utilization for consumer electronics applications. Intrinsic properties of sapphire, including high scratch resistance, make it an attractive option for these purposes, but the ability to machine fine features in sapphire substrates with common mechanical and laser-based methods has proved elusive to this point. In this study, we present results from a series of systematic trials to determine the optimum laser processing parameters for drilling 400 mu m diameter holes with no cracks or chips and <5 degrees taper in 430 mu m thick sapphire wafers with a 0.8 ps 1030 nm source. Holes are drilled at repetition rates from 21 to 1042 kHz, overlaps from 70% to 98%, and translation of the beam waist through the sample at rates from 10 to 200 mu m/s. We present qualitative and quantitative results generated from laser scanning microscopy demonstrating that holes with <5 degrees taper and no cracks or chips can be drilled at repetition rates of 260 kHz with 90% and 95% overlap and 521 kHz with 95% overlap. We find that the optimum processing parameters for drilling holes with <5 degrees taper correlates well with the conditions necessary for avoiding chipping, cracking, and back-side damage rings. Holes with <5 degrees taper can be drilled in as short as 4-6 s per holes, and holes with <2 degrees taper can be drilled in 10-12 s per hole. (C) 2016 Laser Institute of America.
OI KLING, Rainer/0000-0001-6831-4274
SN 1042-346X
EI 1938-1387
PD MAY
PY 2016
VL 28
IS 2
AR 022206
DI 10.2351/1.4944509
UT WOS:000374165400018
ER

PT J
AU Batista, FAH
   Almeida, GS
   Seraphim, TV
   Silva, KP
   Murta, SMF
   Barbosa, LRS
   Borges, JUC
AF Batista, Fernanda A. H.
   Almeida, Glessler S.
   Seraphim, Thiago V.
   Silva, Kelly P.
   Murta, Silvane M. F.
   Barbosa, Leandro R. S.
   Borges, J. Ulio C.
TI Identification of two p23 co-chaperone isoforms in Leishmania
   braziliensis exhibiting similar structures and Hsp90 interaction
   properties despite divergent stabilities
SO FEBS Journal
AB The small acidic protein called p23 acts as a co-chaperone for heat-shock protein of 90 kDa (Hsp90) during its ATPase cycle. p23 proteins inhibit Hsp90 ATPase activity and show intrinsic chaperone activity. A search for p23 in protozoa, especially trypanosomatids, led us to identify two putative proteins in the Leishmania braziliensis genome that share approximately 30% identity with each other and with the human p23. To understand the presence of two p23 isoforms in trypanosomatids, we obtained the recombinant p23 proteins of L. braziliensis (named Lbp23A and Lbp23B) and performed structural and functional studies. The recombinant proteins share similar solution structures; however, temperature-and chemicalinduced unfolding experiments showed that Lbp23A is more stable than Lbp23B, suggesting that they may have different functions. Lbp23B prevented the temperature-induced aggregation of malic dehydrogenase more efficiently than did Lbp23A, whereas the two proteins had equivalent efficiencies with respect to preventing the temperature-induced aggregation of luciferase. Both proteins interacted with L. braziliensis Hsp90 (LbHsp90) and inhibited its ATPase activity, although their efficiencies differed. In vivo identification studies suggested that both proteins are present in L. braziliensis cells grown under different conditions, although Lbp23B may undergo post-translation modifications. Interaction studies indicated that both Lbp23 proteins interact with LbHsp90. Taken together, our data suggest that the two protozoa p23 isoforms act similarly when regulating Hsp90 function. However, they also have some differences, indicating that the L. braziliensis Hsp90 machine has features providing an opportunity for novel forms of selective inhibition of protozoan Hsp90.
RI Barbosa, Leandro Ramos Souza/E-6577-2012; Barbosa, L. R.
   S./AAN-7787-2020; Seraphim, Thiago V/J-9949-2013; Barbosa, Leandro Ramos
   Souza/GRJ-9680-2022; Batista, Fernanda A.H./E-1633-2013; Borges, Julio
   C/C-6160-2008; Murta, Silvane Fonseca Murta/ABE-9410-2021
OI Barbosa, Leandro Ramos Souza/0000-0001-5997-2160; Barbosa, Leandro Ramos
   Souza/0000-0001-5997-2160; Borges, Julio C/0000-0003-4856-748X; Murta,
   Silvane Fonseca Murta/0000-0002-8523-2155; Vargas Seraphim,
   Thiago/0000-0002-8682-8962
SN 1742-464X
EI 1742-4658
PD JAN
PY 2015
VL 282
IS 2
BP 388
EP 406
DI 10.1111/febs.13141
UT WOS:000348517400013
PM 25369258
ER

PT J
AU Bergman, A
   Condeelis, JS
   Gligorijevic, B
AF Bergman, Aviv
   Condeelis, John S.
   Gligorijevic, Bojana
TI Invadopodia in context
SO CELL ADHESION & MIGRATION
AB Invadopodia are dynamic protrusions in motile tumor cells whose function is to degrade extracellular matrix so that cells can enter into new environments. Invadopodia are specifically identified by microscopy as proteolytic invasive protrusions containing TKS5 and cortactin. The increasing complexity in models for the study of invadopodia, including engineered 3D environments, explants, or animal models in vivo, entails a higher level of microenvironment complexity as well as cancer cell heterogeneity. Such experimental setups are rich in information and offer the possibility of contextualizing invadopodia and other motility-related structures. That is, they hold the promise of revealing more realistic microenvironmental conditions under which the invadopodium assembles and functions or in which tumor cells switch to a different cellular phenotype (focal adhesion, lamellipodia, proliferation, and apoptosis). For such an effort, we need a systemic approach to microscopy, which will integrate information from multiple modalities. While the individual technologies needed to achieve this are mostly available, data integration and standardization is not a trivial process. In a systems microscopy approach, microscopy is used to extract information on cell phenotypes and the microenvironment while -omics technologies assess profiles of cancer cell and microenvironment genetic, transcription, translation, and protein makeups. Data are classified and linked via in silico modeling (including statistical and mathematical models and bioinformatics). Computational considerations create predictions to be validated experimentally by perturbing the system through use of genetic manipulations and molecular biology. With such a holistic approach, a deeper understanding of function of invadopodia in vivo will be reached, opening the potential for personalized diagnostics and therapies.
RI gligorijevic, bojana/AAV-9687-2020
OI gligorijevic, bojana/0000-0001-9071-7467
SN 1933-6918
EI 1933-6926
PY 2014
VL 8
IS 3
BP 273
EP 279
DI 10.4161/cam.28349
UT WOS:000348322200012
PM 24713806
ER

PT J
AU Olson, MA
   Braunschweig, AB
   Ikeda, T
   Fang, L
   Trabolsi, A
   Slawin, AMZ
   Khan, SI
   Stoddart, JF
AF Olson, Mark A.
   Braunschweig, Adam B.
   Ikeda, Taichi
   Fang, Lei
   Trabolsi, Ali
   Slawin, Alexandra M. Z.
   Khan, Saeed I.
   Stoddart, J. Fraser
TI Thermodynamic forecasting of mechanically interlocked switches
SO ORGANIC & BIOMOLECULAR CHEMISTRY
AB Mechanically interlocked molecular (MIM) switches in the form of bistable [2]rotaxanes and [2]catenanes have proven to be-when incorporated in molecular electronic devices (MEDs) and in nanoelectromechanical systems (NEMS)-a realistic and viable alternative to the silicon chip density challenge. Structural modifications and chemical environment can have a large impact on the relaxation thermodynamics of the molecular motions, such as translation and circumrotation in bistable rotaxanes and catenanes responsible for the operation of devices based on MIMs. The effects of structural modifications on the difference in free energy (Delta G degrees) for the equilibrium processes in switchable MIMs can be predicted by considering, firstly, the interactions present in their precursor pseudorotaxanes. By employing isothermal titration microcalorimetry (ITC) to investigate the thermodynamic parameters governing pseudorotaxane formation for a series of monosubstituted, acceptor host cyclophanes with various donor guests, in conjunction with X-ray crystallographic data, an obvious link between the noncovalent bonding interactions in pseudorotaxanes and MIMs that survive following the formation of the mechanical bond can be identified. It follows that the changes (Delta Delta G degrees values) in the difference of free energy during the formation of different pseudorotaxanes can subsequently be extrapolated to predict Delta G degrees values for the thermodynamics associated with switching in analogous MIM switches, employing the same donor-acceptor recognition components. In this manner, a systematic and predictive thermodynamic approach to designing and tuning switchable MIMs and MIM-based materials has been established. Additionally, these thermodynamic relationships are reminiscent of the long forgotten concept of the 'parachor' as a molecular descriptor with respect to the additivity of physical properties in chemical systems dealing specifically with quantitative structure property-activity relationships (QSPR/QSAR).
RI Slawin, Alexandra M Z/I-9878-2014; Fang, Lei/C-1084-2008; Ikeda,
   Taichi/U-2356-2019; Olson, Mark Anthony/C-1083-2008; Fang,
   Lei/Q-4913-2019; Stoddart, James Fraser/H-1518-2011
OI Slawin, Alexandra M Z/0000-0002-9527-6418; Fang,
   Lei/0000-0003-4757-5664; Ikeda, Taichi/0000-0001-6650-5798; Olson, Mark
   Anthony/0000-0003-0398-5063; Fang, Lei/0000-0003-4757-5664; Stoddart,
   James Fraser/0000-0003-3161-3697
SN 1477-0520
EI 1477-0539
PY 2009
VL 7
IS 21
BP 4391
EP 4405
DI 10.1039/b911874h
UT WOS:000270795700010
PM 19830288
ER

PT J
AU Guevorguian, P
   Chinnery, T
   Lang, PCL
   Nichols, A
   Mattonen, SA
AF Guevorguian, Philipp
   Chinnery, Tricia
   Lang, Pencilla
   Nichols, Anthony
   Mattonen, Sarah A.
TI External validation of a CT-based radiomics signature in oropharyngeal
   cancer: Assessing sources of variation
SO RADIOTHERAPY AND ONCOLOGY
AB Background and purpose: Radiomics is a high-throughput approach that allows for quantitative analysis of imaging data for prognostic applications. Medical images are used in oropharyngeal cancer (OPC) diag-nosis and treatment planning and these images may contain prognostic information allowing for treat-ment personalization. However, the lack of validated models has been a barrier to the translation of radiomic research to the clinic. We hypothesize that a previously developed radiomics model for risk stratification in OPC can be validated in a local dataset.Materials and methods: The radiomics signature predicting overall survival incorporates features derived from the primary gross tumor volume of OPC patients treated with radiation +/-chemotherapy at a single institution (n = 343). Model fit, calibration, discrimination, and utility were evaluated. The signature was compared with a clinical model using overall stage and a model incorporating both radiomics and clinical data. A model detecting dental artifacts on computed tomography images was also validated.Results: The radiomics signature had a Concordance index (C-index) of 0.66 comparable to the clinical model's C-index of 0.65. The combined model significantly outperformed (C-index of 0.69, p = 0.024) the clinical model, suggesting that radiomics provides added value. The dental artifact model demon-strated strong ability in detecting dental artifacts with an area under the curve of 0.87.Conclusion: This work demonstrates model performance comparable to previous validation work and provides a framework for future independent and multi-center validation efforts. With sufficient valida-tion, radiomic models have the potential to improve traditional systems of risk stratification, treatment personalization and patient outcomes.(c) 2022 Elsevier B.V. All rights reserved. Radiotherapy and Oncology 178 (2023) 109434
OI Nichols, Anthony/0000-0002-0760-980X
SN 0167-8140
EI 1879-0887
PD JAN
PY 2023
VL 178
AR 109434
DI 10.1016/j.radonc.2022.11.023
EA DEC 2022
UT WOS:000911028200001
PM 36464179
ER

PT J
AU Gao, QM
   DeLaura, IF
   Anwar, IJ
   Kesseli, SJ
   Kahan, R
   Abraham, N
   Asokan, A
   Barbas, AS
   Hartwig, MG
AF Gao, Qimeng
   DeLaura, Isabel F.
   Anwar, Imran J.
   Kesseli, Samuel J.
   Kahan, Riley
   Abraham, Nader
   Asokan, Aravind
   Barbas, Andrew S.
   Hartwig, Matthew G.
TI Gene Therapy: Will the Promise of Optimizing Lung Allografts Become
   Reality?
SO FRONTIERS IN IMMUNOLOGY
AB Lung transplantation is the definitive therapy for patients living with end-stage lung disease. Despite significant progress made in the field, graft survival remains the lowest of all solid organ transplants. Additionally, the lung has among the lowest of organ utilization rates-among eligible donors, only 22% of lungs from multi-organ donors were transplanted in 2019. Novel strategies are needed to rehabilitate marginal organs and improve graft survival. Gene therapy is one promising strategy in optimizing donor allografts. Over-expression or inhibition of specific genes can be achieved to target various pathways of graft injury, including ischemic-reperfusion injuries, humoral or cellular rejection, and chronic lung allograft dysfunction. Experiments in animal models have historically utilized adenovirus-based vectors and the majority of literature in lung transplantation has focused on overexpression of IL-10. Although several strategies were shown to prevent rejection and prolong graft survival in preclinical models, none have led to clinical translation. The past decade has seen a renaissance in the field of gene therapy and two AAV-based in vivo gene therapies are now FDA-approved for clinical use. Concurrently, normothermic ex vivo machine perfusion technology has emerged as an alternative to traditional static cold storage. This preservation method keeps organs physiologically active during storage and thus potentially offers a platform for gene therapy. This review will explore the advantages and disadvantages of various gene therapy modalities, review various candidate genes implicated in various stages of allograft injury and summarize the recent efforts in optimizing donor lungs using gene therapy.
RI Anwar, Imran/GZM-7933-2022
OI Anwar, Imran/0000-0002-5075-4148; DeLaura, Isabel/0000-0002-2340-0918
SN 1664-3224
PD JUL 1
PY 2022
VL 13
AR 931524
DI 10.3389/fimmu.2022.931524
UT WOS:000827988300001
PM 35844566
ER

PT J
AU Alarabi, AB
   Mohsen, A
   Mizuguchi, K
   Alshbool, FZ
   Khasawneh, FT
AF Alarabi, Ahmed B.
   Mohsen, Attayeb
   Mizuguchi, Kenji
   Alshbool, Fatima Z.
   Khasawneh, Fadi T.
TI Co-expression analysis to identify key modules and hub genes associated
   with COVID-19 in platelets
SO BMC MEDICAL GENOMICS
AB Corona virus disease 2019 (COVID-19) increases the risk of cardiovascular occlusive/thrombotic events and is linked to poor outcomes. The underlying pathophysiological processes are complex, and remain poorly understood. To this end, platelets play important roles in regulating the cardiovascular system, including via contributions to coagulation and inflammation. There is ample evidence that circulating platelets are activated in COVID-19 patients, which is a primary driver of the observed thrombotic outcome. However, the comprehensive molecular basis of platelet activation in COVID-19 disease remains elusive, which warrants more investigation. Hence, we employed gene co-expression network analysis combined with pathways enrichment analysis to further investigate the aforementioned issues. Our study revealed three important gene clusters/modules that were closely related to COVID-19. These cluster of genes successfully identify COVID-19 cases, relative to healthy in a separate validation data set using machine learning, thereby validating our findings. Furthermore, enrichment analysis showed that these three modules were mostly related to platelet metabolism, protein translation, mitochondrial activity, and oxidative phosphorylation, as well as regulation of megakaryocyte differentiation, and apoptosis, suggesting a hyperactivation status of platelets in COVID-19. We identified the three hub genes from each of three key modules according to their intramodular connectivity value ranking, namely: COPE, CDC37, CAPNS1, AURKAIP1, LAMTOR2, GABARAP MT-ND1, MT-ND5, and MTRNR2L12. Collectively, our results offer a new and interesting insight into platelet involvement in COVID-19 disease at the molecular level, which might aid in defining new targets for treatment of COVID-19-induced thrombosis.
RI Mizuguchi, Kenji/GVS-5857-2022; Mohsen, Attayeb/I-6728-2018
OI Mizuguchi, Kenji/0000-0003-3021-7078; Alarabi,
   Ahmed/0000-0002-4278-5067; Mohsen, Attayeb/0000-0003-0690-8012;
   Khasawneh, Fadi/0000-0002-4027-2997
EI 1755-8794
PD APR 14
PY 2022
VL 15
IS 1
AR 83
DI 10.1186/s12920-022-01222-y
UT WOS:000782605900002
PM 35421970
ER

PT J
AU Ismail, H
   Roy, R
   Sheu, LJ
   Chieng, WH
   Tang, LC
AF Ismail, Hasan
   Roy, Rohit
   Sheu, Long-Jye
   Chieng, Wei-Hua
   Tang, Li-Chuan
TI Exploration-Based SLAM (e-SLAM) for the Indoor Mobile Robot Using Lidar
SO SENSORS
AB This paper attempts to uncover one possible method for the IMR (indoor mobile robot) to perform indoor exploration associated with SLAM (simultaneous localization and mapping) using LiDAR. Specifically, the IMR is required to construct a map when it has landed on an unexplored floor of a building. We had implemented the e-SLAM (exploration-based SLAM) using the coordinate transformation and the navigation prediction techniques to achieve that purpose in the engineering school building which consists of many 100-m(2) labs, corridors, elevator waiting space and the lobby. We first derive the LiDAR mesh for the orthogonal walls and filter out the static furniture and dynamic humans in the same space as the IMR. Then, we define the LiDAR pose frame including the translation and rotation from the orthogonal walls. According to the MSC (most significant corner) obtained from the intersection of the orthogonal walls, we calculate the displacement of the IMR. The orientation of the IMR is calculated from the alignment of orthogonal walls in the consecutive LiDAR pose frames, which is also assisted by the LQE (linear quadratic estimation) method. All the computation can be done in a single processor machine in real-time. The e-SLAM technique leads to a potential for the in-house service robot to start operation without having pre-scan LiDAR maps, which can save the installation time of the service robot. In this study, we use only the LiDAR and compared our result with the IMU to verify the consistency between the two navigation sensors in the experiments. The scenario of the experiment consists of rooms, corridors, elevators, and the lobby, which is common to most office buildings.
RI Ismail, Hasan/GWC-9938-2022
OI Roy, Rohit/0000-0001-7844-1488; ISMAIL, HASAN/0000-0003-1850-6651; Tang,
   Li-Chuan/0000-0002-7662-5387
EI 1424-8220
PD FEB
PY 2022
VL 22
IS 4
AR 1689
DI 10.3390/s22041689
UT WOS:000767984600001
PM 35214588
ER

PT J
AU Poon, DJJ
   Tay, L
   Ho, D
   Chua, MLK
   Chow, EKH
   Yeo, ELL
AF Poon, Dennis Jun Jie
   Tay, Li Min
   Ho, Dean
   Chua, Melvin Lee Kiang
   Chow, Edward Kai-Hua
   Yeo, Eugenia Li Ling
TI Improving the therapeutic ratio of radiotherapy against radioresistant
   cancers: Leveraging on novel artificial intelligence-based approaches
   for drug combination discovery
SO CANCER LETTERS
AB Despite numerous advances in cancer radiotherapy, tumor radioresistance remain one of the major challenges limiting treatment efficacy of radiotherapy. Conventional strategies to overcome radioresistance involve understanding the underpinning molecular mechanisms, and subsequently using combinatorial treatment strategies involving radiation and targeted drug combinations against these radioresistant tumors. These strategies exploit and target the molecular fingerprint and vulnerability of the radioresistant clones to achieve improved efficacy in tumor eradication. However, conventional drug-screening approaches for the discovery of new drug combinations have been proven to be inefficient, limited and laborious. With the increasing availability of computational resources in recent years, novel approaches such as Quadratic Phenotypic Optimization Platform (QPOP), CURATE.AI and Drug Combination and Prediction and Testing (DCPT) platform have emerged to aid in drug combination discovery and the longitudinally optimized modulation of combination therapy dosing. These platforms could overcome the limitations of conventional screening approaches, thereby facilitating the discovery of more optimal drug combinations to improve the therapeutic ratio of combinatorial treatment. The use of better and more accurate models and methods with rapid turnover can thus facilitate a rapid translation in the clinic, hence, resulting in a better patient outcome. Here, we reviewed the clinical observations, molecular mechanisms and proposed treatment strategies for tumor radioresistance and discussed how novel approaches may be applied to enhance drug combination discovery, with the aim to further improve the therapeutic ratio and treatment efficacy of radiotherapy against radioresistant cancers.
RI Chua, Melvin LK/ABG-6045-2020
OI Chua, Melvin LK/0000-0002-1648-1473; Ho, Dean/0000-0002-7337-296X
SN 0304-3835
EI 1872-7980
PD JUL 28
PY 2021
VL 511
BP 56
EP 67
DI 10.1016/j.canlet.2021.04.019
EA MAY 2021
UT WOS:000651748700001
PM 33933554
ER

PT J
AU Deng, L
   Liu, YZ
   Shi, YC
   Zhang, WH
   Yang, C
   Liu, H
AF Deng, Lei
   Liu, Youzhi
   Shi, Yechuan
   Zhang, Wenhao
   Yang, Chun
   Liu, Hui
TI Deep neural networks for inferring binding sites of RNA-binding proteins
   by using distributed representations of RNA primary sequence and
   secondary structure
SO BMC GENOMICS
CT IEEE International Conference on Bioinformatics and Biomedicine (BIBM) -
   Genomics
CY NOV 18-21, 2019
CL San Diego, CA
SP IEEE
AB BackgroundRNA binding proteins (RBPs) play a vital role in post-transcriptional processes in all eukaryotes, such as splicing regulation, mRNA transport, and modulation of mRNA translation and decay. The identification of RBP binding sites is a crucial step in understanding the biological mechanism of post-transcriptional gene regulation. However, the determination of RBP binding sites on a large scale is a challenging task due to high cost of biochemical assays. Quite a number of studies have exploited machine learning methods to predict binding sites. Especially, deep learning is increasingly used in the bioinformatics field by virtue of its ability to learn generalized representations from DNA and protein sequences.ResultsIn this paper, we implemented a novel deep neural network model, DeepRKE, which combines primary RNA sequence and secondary structure information to effectively predict RBP binding sites. Specifically, we used word embedding algorithm to extract features of RNA sequences and secondary structures, i.e., distributed representation of k-mers sequence rather than traditional one-hot encoding. The distributed representations are taken as input of convolutional neural networks (CNN) and bidirectional long-term short-term memory networks (BiLSTM) to identify RBP binding sites. Our results show that deepRKE outperforms existing counterpart methods on two large-scale benchmark datasets.ConclusionsOur extensive experimental results show that DeepRKE is an efficacious tool for predicting RBP binding sites. The distributed representations of RNA sequences and secondary structures can effectively detect the latent relationship and similarity between k-mers, and thus improve the predictive performance. The source code of DeepRKE is available at https://github.com/youzhiliu/DeepRKE/.
SN 1471-2164
PD DEC 17
PY 2020
VL 21
SU 13
SI SI
AR 866
DI 10.1186/s12864-020-07239-w
UT WOS:000601306200002
PM 33334313
ER

PT J
AU Gu, M
   Park, Y
   Kim, Y
   Park, S
AF Gu, Minwoo
   Park, Younghun
   Kim, Youngjae
   Park, Sungyong
TI Low-overhead dynamic sharing of graphics memory space in GPU
   virtualization environments
SO CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND
   APPLICATIONS
AB The proliferation of GPU intensive workloads has created a new challenge for low-overhead and efficient GPU virtualization solutions over GPU clouds. gVirt is a full GPU virtualization solution for Intel's integrated GPUs that share system's on-board memory for graphics memory. In order to solve the inherent scalability limitation on the number of simultaneous virtual machines (VM) in gVirt, gScale proposed a dynamic sharing scheme for global graphics memory among VMs by copying the entries in a private graphics translation table (GTT) to a physical GTT along with a GPU context switch. However, copying entries between private GTT and physical GTT often causes significant overhead, which becomes worse when the global graphics memory space shared by each VM is overlapped. This paper identifies that the copy overhead caused by GPU context switch is one of the major bottlenecks in performance improvement and proposes a low-overhead dynamic memory management scheme called DymGPU. DymGPU provides two memory allocation algorithms such as size-based and utilization-based algorithms. While the size-based algorithm allocates memory space based on the memory size required by each VM, the utilization-based algorithm considers GPU utilization of each VM to allocate memory space. DymGPU is also dynamic in the sense that the global graphics memory space used by each VM is rearranged at runtime by periodically checking idle VMs and GPU utilization of each runnable VM. We have implemented our proposed approach in gVirt and confirmed that the proposed scheme reduces GPU context switch time by up to 53% and improved the overall performance of various GPU applications by up to 39%.
OI Park, Sungyong/0000-0002-0309-1820
SN 1386-7857
EI 1573-7543
PD SEP
PY 2020
VL 23
IS 3
BP 2167
EP 2178
DI 10.1007/s10586-019-02967-5
UT WOS:000606424800045
ER

PT J
AU Kitsios, GD
   Fitch, A
   Manatakis, DV
   Rapport, SF
   Li, K
   Qin, SL
   Huwe, J
   Zhang, YZ
   Doi, Y
   Evankovich, J
   Bain, W
   Lee, JS
   Methe, B
   Benos, PV
   Morris, A
   McVerry, BJ
AF Kitsios, Georgios D.
   Fitch, Adam
   Manatakis, Dimitris V.
   Rapport, Sarah F.
   Li, Kelvin
   Qin, Shulin
   Huwe, Joseph
   Zhang, Yingze
   Doi, Yohei
   Evankovich, John
   Bain, William
   Lee, Janet S.
   Methe, Barbara
   Benos, Panayiotis V.
   Morris, Alison
   McVerry, Bryan J.
TI Respiratory Microbiome Profiling for Etiologic Diagnosis of Pneumonia in
   Mechanically Ventilated Patients
SO FRONTIERS IN MICROBIOLOGY
AB Etiologic diagnosis of bacterial pneumonia relies on identification of causative pathogens by cultures, which require extended incubation periods and have limited sensitivity. Next-generation sequencing of microbial DNA directly from patient samples may improve diagnostic accuracy for guiding antibiotic prescriptions. In this study, we hypothesized that enhanced pathogen detection using sequencing can improve upon culture-based diagnosis and that certain sequencing profiles correlate with host response. We prospectively collected endotracheal aspirates and plasma within 72 h of intubation from patients with acute respiratory failure. We performed 16S rRNA gene sequencing to determine pathogen abundance in lung samples and measured plasma biomarkers to assess host responses to detected pathogens. Among 56 patients, 12 patients (21%) had positive respiratory cultures. Sequencing revealed lung communities with low diversity (p < 0.02) dominated by taxa (>50% relative abundance) corresponding to clinically isolated pathogens (concordance p = 0.009). Importantly, sequencing detected dominant pathogens in 20% of the culture-negative patients exposed to broad-spectrum empiric antibiotics. Regardless of culture results, pathogen dominance correlated with increased plasma markers of host injury (receptor of advanced glycation end-products-RAGE) and inflammation (interleukin-6, tumor necrosis factor receptor 1-TNFR1) (p < 0.05), compared to subjects without dominant pathogens in their lung communities. Machine-learning algorithms identified pathogen abundance by sequencing as the most informative predictor of culture positivity. Thus, enhanced detection of pathogenic bacteria by sequencing improves etiologic diagnosis of pneumonia, correlates with host responses, and offers substantial opportunity for individualized therapeutic targeting and antimicrobial stewardship. Clinical translation will require validation with rapid whole meta-genome sequencing approaches to guide real-time antibiotic prescriptions.
RI McVerry, Bryan/AAS-7790-2021; Qin, Shulin/ABA-3986-2020
OI McVerry, Bryan/0000-0002-1175-4874; Qin, Shulin/0000-0003-2496-3007;
   Doi, Yohei/0000-0002-9620-2525; Zhang, YIngze/0000-0001-8042-6105;
   Kitsios, Georgios/0000-0002-1018-948X; Benos,
   Panayiotis/0000-0003-3172-3132; Bain, William/0000-0001-8506-0552; Lee,
   Janet/0000-0002-6812-6043
EI 1664-302X
PD JUL 10
PY 2018
VL 9
AR 1413
DI 10.3389/fmicb.2018.01413
UT WOS:000438061400001
PM 30042738
ER

PT J
AU Bhuiyan, P
   Chuwdhury, GS
   Sun, ZC
   Chen, YA
   Dong, HQ
   Ahmed, FF
   Li, NN
   Rahman, MH
   Qian, YN
AF Bhuiyan, Piplu
   Chuwdhury, G. S.
   Sun, Zhaochu
   Chen, Yinan
   Dong, Hongquan
   Ahmed, Fee Faysal
   Li Nana
   Rahman, Md Habibur
   Qian, Yanning
TI Network Biology Approaches to Uncover Therapeutic Targets Associated
   with Molecular Signaling Pathways from circRNA in Postoperative
   Cognitive Dysfunction Pathogenesis
SO JOURNAL OF MOLECULAR NEUROSCIENCE
AB Postoperative cognitive dysfunction (POCD) is a cognitive deterioration and dementia that arise after a surgical procedure, affecting up to 40% of surgery patients over the age of 60. The precise etiology and molecular mechanisms underlying POCD remain uncovered. These reasons led us to employ integrative bioinformatics and machine learning methodologies to identify several biological signaling pathways involved and molecular signatures to better understand the pathophysiology of POCD. A total of 223 differentially expressed genes (DEGs) comprising 156 upregulated and 67 downregulated genes were identified from the circRNA microarray dataset by comparing POCD and non-POCD samples. Gene ontology (GO) analyses of DEGs were significantly involved in neurogenesis, autophagy regulation, translation in the postsynapse, modulating synaptic transmission, regulation of the cellular catabolic process, macromolecule modification, and chromatin remodeling. Pathway enrichment analysis indicated some key molecular pathways, including mTOR signaling pathway, AKT phosphorylation of cytosolic targets, MAPK and NF-kappa B signaling pathway, PI3K/AKT signaling pathway, nitric oxide signaling pathway, chaperones that modulate interferon signaling pathway, apoptosis signaling pathway, VEGF signaling pathway, cellular senescence, RANKL/RARK signaling pathway, and AGE/RAGE pathway. Furthermore, seven hub genes were identified from the PPI network and also determined transcription factors and protein kinases. Finally, we identified a new predictive drug for the treatment of SCZ using the LINCS L1000, GCP, and P100 databases. Together, our results bring a new era of the pathogenesis of a deeper understanding of POCD, identified novel therapeutic targets, and predicted drug inhibitors in POCD.
RI Rahman, Habibur/AAF-3094-2021
OI Rahman, Habibur/0000-0002-5068-2690; Bhuiyan, Piplu/0000-0001-6180-019X
SN 0895-8696
EI 1559-1166
PD SEP
PY 2022
VL 72
IS 9
BP 1875
EP 1901
DI 10.1007/s12031-022-02042-6
EA JUL 2022
UT WOS:000821367600001
PM 35792980
ER

PT C
AU Sehwani, NS
AF Sehwani, Nitesh Suresh
GP ACM
TI No Features Needed: Using BPE Sequence Embeddings forWeb Log Anomaly
   Detection
SO PROCEEDINGS OF THE 2022 ACM INTERNATIONAL WORKSHOP ON SECURITY AND
   PRIVACY ANALYTICS (IWSPA '22)
CT ACM International Workshop on Security and Privacy Analytics (IWSPA) /
   12th ACM Annual Conference on Data and Applications Security and Privacy
   (CODASPY)
CY APR 27, 2022
CL Baltimore, MD
SP Assoc Comp Machinery, ACM SIGSAC
AB Problem: Manual data analysis for extracting useful features in web log anomaly detection can be costly and time-consuming. Automated techniques on the other hand (e.g. Auto-Encoders and CNNs based) usually require supplemental network trainings for feature extractions. Often the systems trained on these features suffer from high False Positive Rates (FPRs) and rectifying them can negatively impact accuracies and add training/tuning delays. Thus manual analysis delays, mandatory supplementary trainings and inferior detection outcomes are the limitations in contemporary web log anomaly detection systems. Proposal: Byte Pair Encoding (BPE) is an automated data representation scheme which requires no training, and only needs a single parsing run for tokenizing available data. Models trained using BPE-based vectors have shown to outperform models trained on similar representations, in tasks such as machine translation (NMT) and language generation (NLG). We therefore propose to use BPE tokens obtained from web log data and consequently vectorized by a pre-trained sequence embedding model for performing web log anomaly detection. Our experiments using two public data sets show that ML models trained on BPE sequence vectors, achieve better results compared to training on both manually and automatically extracted features. Moreover our technique of obtaining log representations is fully automated (requiring only a single hyperparameter), needs no additional network training and provides representations that give consistent performance across different ML algorithms (a facet absent from feature-based techniques). The only trade-off with our method is an increased upper limit in system memory consumption, as compared to using manual features. This is due to the higher dimensions of the utilized pre-trained embeddings, and reducing it, is our motivation for future work.
BN 978-1-4503-9230-3
PY 2022
BP 78
EP 85
DI 10.1145/3510548.3519375
UT WOS:000927868000010
ER

PT J
AU Alsaaran, N
   Alrabiah, M
AF Alsaaran, Norah
   Alrabiah, Maha
TI Classical Arabic Named Entity Recognition Using Variant Deep Neural
   Network Architectures and BERT
SO IEEE ACCESS
AB Recurrent Neural Networks (RNNs) and transformers are deep learning models that have achieved remarkable success in several Natural Language Processing (NLP) tasks since they do not rely on handcrafted features nor enormous knowledge resources. Named Entity Recognition (NER) is an essential NLP task that is used in many applications such as information retrieval, question answering, and machine translation. NER aims to locate, extract, and classify named entities into predefined categories such as person, organization and location. Arabic NER is considered a challenging task because of the complexity and the unique characteristics of Arabic. Most of the previous research on deep learning based-Arabic NER focused on Modern Standard Arabic and Dialectal Arabic, which are different variations from Classical Arabic. In this paper, we investigate deep learning-based Classical Arabic NER using different deep neural network architectures and a BERT based contextual language model that is trained on general domain Arabic text. We propose two RNN-based models by fine-tunning the pretrained BERT language model to recognize and classify named entities from Classical Arabic. The pre-trained BERT contextual language model representations were used as input features to a BGRU/BLSTM model and were fine-tuned using a Classical Arabic NER dataset. In addition, we explore variant architectures of the proposed BERT-BGRU/BLSTM-CRF models. Experimentations showed that the BERT-BGRU-CRF model outperformed the other models by achieving an F-measure of 94.76% on the CANERCorpus. To the best of our knowledge, this is the first work that aims to recognize named entities in Classical Arabic using deep learning.
RI Alrabiah, Maha/AAV-9338-2020
OI Alrabiah, Maha/0000-0002-5349-6121
SN 2169-3536
PY 2021
VL 9
BP 91537
EP 91547
DI 10.1109/ACCESS.2021.3092261
UT WOS:000673647400001
ER

PT C
AU Pashamokhtari, A
   Okui, N
   Miyake, Y
   Nakahara, M
   Gharakheili, HH
AF Pashamokhtari, Arman
   Okui, Norihiro
   Miyake, Yutaka
   Nakahara, Masataka
   Gharakheili, Hassan Habibi
BE Khoukhi, L
   Oteafy, S
   Bulut, E
TI Inferring Connected IoT Devices from IPFIX Records in Residential ISP
   Networks
SO PROCEEDINGS OF THE IEEE 46TH CONFERENCE ON LOCAL COMPUTER NETWORKS (LCN
   2021)
SE Conference on Local Computer Networks
CT IEEE 46th Conference on Local Computer Networks (LCN)
CY OCT 04-07, 2021
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, IEEE Comp Soc Tech Comm Comp Commun, TELUS, Kings Distributed Syst
AB Residential ISPs today have limited device-level visibility into subscriber houses, primarily due to network address translation (NAT) technology. The continuous growth of "unmanaged" consumer IoT devices combined with the rise of work-from-home makes home networks attractive targets for cyber attacks. Volumetric attacks sourced from a distributed set of vulnerable IoT devices can impact ISPs by deteriorating the performance of their network, or even making them liable for being a carrier of malicious traffic. This paper explains how ISPs can employ IPFIX (IP Flow Information eXport), a flow-level telemetry protocol available on their network, to infer connected IoT devices and ensure their cyber health without making changes to home networks. Our contributions are three-fold: (1) We analyze near three million IPFIX records of 26 IoT devices collected from a residential testbed over three months and identify 28 features, pertinent to their network activity and services, that characterize the network behavior of IoT devices - we release our IPFIX records as open data to the public; (2) We develop a multi-class classifier to infer the presence of certain IoT device types in a home network from NATed IPFIX records. We also develop a Trust metric to track network activity of detected devices over time; and, (3) We evaluate the efficacy of our inferencing method by applying the trained classifier to IPFIX traces which yields an average accuracy of 96% in detecting device types. By computing a temporal measure of trust per each device, we highlight (on our testbed) a permanent behavioral change in third of devices as well as some intermittent behavioral changes in others.
OI Habibi Gharakheili, Hassan/0000-0002-9333-7635
SN 0742-1303
BN 978-0-7381-2476-6
PY 2021
BP 57
EP 64
DI 10.1109/LCN52139.2021.9524954
UT WOS:000766931400008
ER

PT J
AU Manchia, M
   Vieta, E
   Smeland, OB
   Altimus, C
   Bechdolf, A
   Bellivier, F
   Bergink, V
   Fagiolini, A
   Geddes, JR
   Hajek, T
   Henry, C
   Kupka, R
   Lagerberg, TV
   Licht, RW
   Martinez-Cengotitabengoa, M
   Morken, G
   Nielsen, RE
   Pinto, AG
   Reif, A
   Rietschel, M
   Ritter, P
   Schulze, TG
   Scott, J
   Severus, E
   Yildiz, A
   Kessing, LV
   Bauer, M
   Goodwin, GM
   Andreassen, OA
AF Manchia, Mirko
   Vieta, Eduard
   Smeland, Olav B.
   Altimus, Cara
   Bechdolf, Andreas
   Bellivier, Frank
   Bergink, Veerle
   Fagiolini, Andrea
   Geddes, John R.
   Hajek, Tomas
   Henry, Chantal
   Kupka, Ralph
   Lagerberg, Trine, V
   Licht, Rasmus W.
   Martinez-Cengotitabengoa, Monica
   Morken, Gunnar
   Nielsen, Rene E.
   Gonzalez Pinto, Ana
   Reif, Andreas
   Rietschel, Marcella
   Ritter, Phillip
   Schulze, Thomas G.
   Scott, Jan
   Severus, Emanuel
   Yildiz, Aysegul
   Kessing, Lars Vedel
   Bauer, Michael
   Goodwin, Guy M.
   Andreassen, Ole A.
CA European Coll Neuropsychopharmacol
TI Translating big data to better treatment in bipolar disorder - a
   manifesto for coordinated action
SO EUROPEAN NEUROPSYCHOPHARMACOLOGY
AB Bipolar disorder (BD) is a major healthcare and socio-economic challenge. Despite its substantial burden on society, the research activity in BD is much smaller than its economic impact appears to demand. There is a consensus that the accurate identification of the underlying pathophysiology for BD is fundamental to realize major health benefits through better treatment and preventive regimens. However, to achieve these goals requires coordinated action and innovative approaches to boost the discovery of the neurobiological underpinnings of BD, and rapid translation of research findings into development and testing of better and more specific treatments. To this end, we here propose that only a large-scale coordinated action can be successful in integrating international big-data approaches with real-world clinical interventions. This could be achieved through the creation of a Global Bipolar Disorder Foundation, which could bring government, industry and philanthropy together in common cause. A global initiative for BD research would come at a highly opportune time given the seminal advances promised for our understanding of the genetic and brain basis of the disease and the obvious areas of unmet clinical need. Such an endeavour would embrace the principles of open science and see the strong involvement of user groups and integration of dissemination and public involvement with the research programs. We believe the time is right for a step change in our approach to understanding, treating and even preventing BD effectively. (c) 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license. (http://creativecommons.org/licenses/by/4.0/)
RI Goodwin, Guy/ABE-6084-2020; Andreassen, Ole A./AAY-7531-2020; Kupka,
   Ralph/HDM-4184-2022; Hajek, Tomas/U-9185-2018; Geddes, John/B-8240-2011;
   Morken, Gunnar/AAX-3373-2020; Nielsen, René Ernst/I-2107-2019;
   Lagerberg, Trine Vik/L-1766-2017; Smeland, Olav/ADE-5677-2022; Vieta,
   Eduard/I-6330-2013
OI Hajek, Tomas/0000-0003-0281-8458; Geddes, John/0000-0002-5281-5960;
   Morken, Gunnar/0000-0003-1972-5901; Nielsen, René
   Ernst/0000-0002-7982-6352; ritter, philipp/0000-0003-4286-5830; Kupka,
   Ralph/0000-0002-1662-7436; Vieta, Eduard/0000-0002-0548-0053; Kessing,
   Lars/0000-0001-9377-9436; Licht, Rasmus W./0000-0001-8095-3490
SN 0924-977X
EI 1873-7862
PD JUL
PY 2020
VL 36
BP 121
EP 136
DI 10.1016/j.euroneuro.2020.05.006
UT WOS:000545420000013
PM 32536571
ER

PT J
AU Zhao, LC
   Wang, Q
   Zou, Q
   Zhang, Y
   Chen, YJ
AF Zhao, Lingchen
   Wang, Qian
   Zou, Qin
   Zhang, Yan
   Chen, Yanjiao
TI Privacy-Preserving Collaborative Deep Learning With Unreliable
   Participants
SO IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY
AB With powerful parallel computing GPUs and massive user data, neural-network-based deep learning can well exert its strong power in problem modeling and solving, and has archived great success in many applications such as image classification, speech recognition and machine translation etc. While deep learning has been increasingly popular, the problem of privacy leakage becomes more and more urgent. Given the fact that the training data may contain highly sensitive information, e.g., personal medical records, directly sharing them among the users (i.e., participants) or centrally storing them in one single location may pose a considerable threat to user privacy. In this paper, we present a practical privacy-preserving collaborative deep learning system that allows users to cooperatively build a collective deep learning model with data of all participants, without direct data sharing and central data storage. In our system, each participant trains a local model with their own data and only shares model parameters with the others. To further avoid potential privacy leakage from sharing model parameters, we use functional mechanism to perturb the objective function of the neural network in the training process to achieve epsilon-differential privacy. In particular, for the first time, we consider the existence of unreliable participants, i.e., the participants with low-quality data, and propose a solution to reduce the impact of these participants while protecting their privacy. We evaluate the performance of our system on two well-known real-world datasets for regression and classification tasks. The results demonstrate that the proposed system is robust against unreliable participants, and achieves high accuracy close to the model trained in a traditional centralized manner while ensuring rigorous privacy protection.
RI Zou, Qin/AFM-0040-2022; Zhao, Lingchen/HCI-8806-2022; Zou,
   Qin/GVU-2237-2022
OI Zhao, Lingchen/0000-0002-1700-3836; Zou, Qin/0000-0001-7955-0782; Chen,
   Yanjiao/0000-0002-1382-0679; Wang, Qian/0000-0002-8967-8525
SN 1556-6013
EI 1556-6021
PY 2020
VL 15
BP 1486
EP 1500
DI 10.1109/TIFS.2019.2939713
UT WOS:000505523100003
ER

PT C
AU Lacey, I
   Adam, J
   Centers, GP
   Gevorkyan, GS
   Nikitin, SM
   Smith, BV
   Yashchuk, VV
AF Lacey, Ian
   Adam, Jerome
   Centers, Gary P.
   Gevorkyan, Gevork S.
   Nikitin, Sergey M.
   Smith, Brian V.
   Yashchuk, Valeriy V.
BE Assoufid, L
   Ohashi, H
   Asundi, AK
TI Development of a high performance surface slope measuring system for
   two-dimensional mapping of x-ray optics
SO ADVANCES IN METROLOGY FOR X-RAY AND EUV OPTICS VII
SE Proceedings of SPIE
CT Conference on Advances in Metrology for X-Ray and EUV Optics VII
CY AUG 06-07, 2017
CL San Diego, CA
SP SPIE
AB The research and development work on the Advanced Light Source (ALS) upgrade to a diffraction limited storage ring light source, ALS-U, has brought to focus the need for near-perfect x-ray optics, capable of delivering light to experiments without significant degradation of brightness and coherence. The desired surface quality is characterized with residual (after subtraction of an ideal shape) surface slope and height errors of <50-100 nrad (rms) and <1-2 nm (rms), respectively. The ex-situ metrology that supports the optimal usage of the optics at the beamlines has to offer even higher measurement accuracy. At the ALS X-Ray Optics Laboratory, we are developing a new surface slope profiler, the Optical Surface Measuring System (OSMS), capable of two-dimensional (2D) surface-slope metrology at an absolute accuracy below the above optical specification. In this article we provide the results of comprehensive characterization of the key elements of the OSMS, a NOM-like high-precision granite gantry system with air-bearing translation and a custom-made precision air-bearing stage for tilting and flipping the surface under test. We show that the high performance of the gantry system allows implementing an original scanning mode for 2D mapping. We demonstrate the efficiency of the developed 2D mapping via comparison with 1D slope measurements performed with the same hyperbolic test mirror using the ALS developmental long trace profiler. The details of the OSMS design and the developed measuring techniques are also provided.
SN 0277-786X
EI 1996-756X
BN 978-1-5106-1228-0; 978-1-5106-1227-3
PY 2017
VL 10385
AR UNSP 103850G
DI 10.1117/12.2273029
UT WOS:000424395400011
ER

PT J
AU Maco, B
   Ross, IL
   Landsberg, MJ
   Mouradov, D
   Saunders, NFW
   Hankamer, B
   Kobe, B
AF Maco, Bohumil
   Ross, Ian L.
   Landsberg, Michael J.
   Mouradov, Dmitri
   Saunders, Neil F. W.
   Hankamer, Ben
   Kobe, Bostjan
TI Proteomic and Electron Microscopy Survey of Large Assemblies in
   Macrophage Cytoplasm
SO MOLECULAR & CELLULAR PROTEOMICS
AB Many cellular processes are carried out by large macromolecular assemblies. We systematically analyzed large macromolecular assemblies in the cytoplasm of mouse macrophages (RAW264.7 cell line), cells with crucial roles in immunity and inflammation. Fractionation of the cytoplasmic fraction was performed using sucrose density gradient centrifugation, and individual fractions were subjected in parallel to (i) identification of constituent proteins by mass spectrometry and (ii) structural visualization by electron microscopy. Macromolecular assemblies present in the fractions were analyzed by integrating available data using bioinformatic approaches. We identified 368 unique proteins in our sample. Among these are components of some well-characterized assemblies involved in diverse cellular processes and structures including translation, proteolysis, protein folding, metabolism, and the cytoskeleton, as well as less characterized proteins that may correspond to additional components of known assemblies or other homo-or hetero-oligomeric structures. Single-particle analysis of electron micrographs of negatively stained samples allowed the identification of clearly distinguishable two-dimensional projections of discrete protein assemblies. Among these, we can identify small ribosomal subunits and preribosomal particles, the 26S proteasome complex and small ringlike structures resembling the molecular chaperone complexes. In addition, a broad range of discrete and different complexes were seen at size ranges between 11 to 38 nm in diameter. Our procedure selects the assemblies on the basis of abundance and ease of isolation, and therefore provides an immediately useful starting point for further study of structure and function of large assemblies. Our results will also contribute toward building a molecular cell atlas. Molecular & Cellular Proteomics 10: 10.1074/mcp.M111.008763, 1-9, 2011.
RI Saunders, Neil/B-5325-2010; Hankamer, Ben D/C-9688-2015; Landsberg,
   Michael/A-3363-2011; Kobe, Bostjan/D-1292-2009; Ross, Ian/A-8622-2011
OI Saunders, Neil/0000-0003-2139-6107; Hankamer, Ben D/0000-0001-9284-4929;
   Landsberg, Michael/0000-0002-2464-990X; Kobe,
   Bostjan/0000-0001-9413-9166; Ross, Ian/0000-0002-2389-4292; Maco,
   Bohumil/0000-0001-8444-313X; Mouradov, Dmitri/0000-0001-8149-816X
SN 1535-9476
EI 1535-9484
PD JUN
PY 2011
VL 10
IS 6
DI 10.1074/mcp.M111.008763
UT WOS:000291204700017
PM 21406389
ER

PT J
AU Zhu, GY
   Zheng, YF
   Doermann, D
   Jaeger, S
AF Zhu, Guangyu
   Zheng, Yefeng
   Doermann, David
   Jaeger, Stefan
TI Signature Detection and Matching for Document Image Retrieval
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB As one of the most pervasive methods of individual identification and document authentication, signatures present convincing evidence and provide an important form of indexing for effective document image processing and retrieval in a broad range of applications. However, detection and segmentation of free-form objects such as signatures from clustered background is currently an open document analysis problem. In this paper, we focus on two fundamental problems in signature-based document image retrieval. First, we propose a novel multiscale approach to jointly detecting and segmenting signatures from document images. Rather than focusing on local features that typically have large variations, our approach captures the structural saliency using a signature production model and computes the dynamic curvature of 2D contour fragments over multiple scales. This detection framework is general and computationally tractable. Second, we treat the problem of signature retrieval in the unconstrained setting of translation, scale, and rotation invariant nonrigid shape matching. We propose two novel measures of shape dissimilarity based on anisotropic scaling and registration residual error and present a supervised learning framework for combining complementary shape information from different dissimilarity metrics using LDA. We quantitatively study state-of-the-art shape representations, shape matching algorithms, measures of dissimilarity, and the use of multiple instances as query in document image retrieval. We further demonstrate our matching techniques in offline signature verification. Extensive experiments using large real-world collections of English and Arabic machine-printed and handwritten documents demonstrate the excellent performance of our approaches.
RI Zheng, Yefeng/ABG-7053-2020
OI Zheng, Yefeng/0000-0003-2195-2847
SN 0162-8828
EI 1939-3539
PD NOV
PY 2009
VL 31
IS 11
BP 2015
EP 2031
DI 10.1109/TPAMI.2008.237
UT WOS:000269767600007
PM 19762928
ER

PT J
AU Sahu, P
   Chug, A
   Singh, AP
   Singh, D
AF Sahu, Priyanka
   Chug, Anuradha
   Singh, Amit Prakash
   Singh, Dinesh
TI Classification of crop leaf diseases using image to image translation
   with deep-dream
SO MULTIMEDIA TOOLS AND APPLICATIONS
AB Crop diseases are one of the primary triggers of yield devastation. As a result, early detection of crop diseases is critical to avert crop losses. In this study, a Deep-Dream (DD) based crop leaf disease detection (CLDD) architecture is proposed using a combination of Deep Learning (DL) along with Machine Learning (ML) techniques. DD is used to pre-process and segment the lesions present in leaves. The proposed novel framework involves 24 different Hybrid Deep Neural (HDN) Models that comprise the integration of eight distinct variations of the pre-trained DL model, namely EfficientNet (EffiNet) ranges from EffiNet B0-B7 in form of a feature extractor. Subsequently, three ML algorithms, namely Random Forest (RF), AdaBoost (ADB), and Stochastic Gradient Boosting (SGB) are employed as classifiers. In this study, the Optuna framework was also applied to tune the hyperparameters of these classifiers. For this implementation, the tomato crop dataset (a subset of the PlantVillage dataset) was used. It has been observed that the proposed model achieved the highest accuracy with the DD-EffiNet-B4-ADB model. The accuracy results of all the models have ranged from 84% to 96%. Moreover, DD shows a better interpretation of the disease lesions, and hence classification accuracy is also enhanced by 3% (93% to 96%) after applying DD segmentation. The proposed model was also validated with an actual-field tomato crop leaf image database gathered from the Indian Agricultural Research Institute with a high-level accuracy of 100%. This technique could help farmers to predict the pathogenic diseases at an early stage of disease visibility.
SN 1380-7501
EI 1573-7721
DI 10.1007/s11042-023-14994-x
EA MAR 2023
UT WOS:000945792800009
ER

PT J
AU Wang, ZM
   Xu, XR
   Li, XZ
   Li, HC
   Zhu, L
   Wei, XP
AF Wang, Ziming
   Xu, Xirong
   Li, Xinzi
   Li, Haochen
   Zhu, Li
   Wei, Xiaopeng
TI A More Robust Model to Answer Noisy Questions in KBQA
SO IEEE ACCESS
AB In practical applications, the raw input to a Knowledge Based Question Answering (KBQA) system may vary in forms, expressions, sources, etc. As a result, the actual input to the system may contain various errors caused by various noise in raw data and processes of transmission, transformation, translation, etc. As a result, it is significant to evaluate and enhance the robustness of a KBQA model to various noisy questions. In this paper, we generate 29 datasets of various noisy questions based on the original SimpleQuestions dataset to evaluate and enhance the robustness of a KBQA model, and propose a model which is more robust to various noisy questions. Compared with traditional methods, the main contribution in this paper is that we propose a method of generating datasets of different noisy questions to evaluate the robustness of a KBQA model, and propose a KBQA model which contains incremental learning and Mask Language Model (MLM) in the question answering process, so that our model is less affected by different kinds of noise in questions and achieves higher accuracies on datasets of different noisy questions, which shows its robustness. Experimental results show that our model achieves an average accuracy of 78.1% on these datasets and outperforms the baseline BERT-based model by an average margin of 5.0% with the similar training cost. In addition, further experiments show that our model is compatible with other pre-trained models such as ALBERT and ELECTRA.
SN 2169-3536
PY 2023
VL 11
BP 22756
EP 22766
DI 10.1109/ACCESS.2023.3252608
UT WOS:000947545400001
ER

PT J
AU Ma, JX
AF Ma, Jingxia
TI Research on Keyword Extraction Algorithm in English Text Based on
   Cluster Analysis
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
AB How to facilitate users to quickly and accurately search for the text information they need is a current research hotspot. Text clustering can improve the efficiency of information search and is an effective text retrieval method. Keyword extraction and cluster center point selection are key issues in text clustering research. Common keyword extraction algorithms can be divided into three categories: semantic-based algorithms, machine learning-based algorithms, and statistical model-based algorithms. There are three common methods for selecting cluster centers: randomly selecting the initial cluster center point, manually specifying the cluster center point, and selecting the cluster center point according to the similarity between the points to be clustered. The randomly selected initial cluster center points may contain "outliers," and the clustering results are locally optimal. Manually specifying the cluster center points will be very subjective because each person's understanding of the text set is different, and it is not suitable for the case of a large number of text sets. Selecting the cluster center points according to the similarity between the points to be clustered can make the selected cluster center points distributed in each class and be as close as possible to the class center points, but it takes a long time to calculate the cluster centers. Aiming at this problem, this paper proposes a keyword extraction algorithm based on cluster analysis. The results show that the algorithm does not rely on background knowledge bases, dictionaries, etc., and obtains statistical parameters and builds models through training. Experiments show that the keyword extraction algorithm has high accuracy and can quickly extract the subject content of an English translation.
OI ma, jingxia/0000-0002-7357-3251
SN 1687-5265
EI 1687-5273
PD MAR 28
PY 2022
VL 2022
AR 4293102
DI 10.1155/2022/4293102
UT WOS:000793525800004
PM 35387240
ER

PT J
AU Erbin, H
   Lahoche, V
   Samary, DO
AF Erbin, H.
   Lahoche, V
   Samary, D. Ousmane
TI Non-perturbative renormalization for the neural network-QFT
   correspondence
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
AB In a recent work (Halverson et al 2021 Mach. Learn.: Sci. Technol. 2 035002), Halverson, Maiti and Stoner proposed a description of neural networks (NNs) in terms of a Wilsonian effective field theory. The infinite-width limit is mapped to a free field theory while finite N corrections are taken into account by interactions (non-Gaussian terms in the action). In this paper, we study two related aspects of this correspondence. First, we comment on the concepts of locality and power-counting in this context. Indeed, these usual space-time notions may not hold for NNs (since inputs can be arbitrary), however, the renormalization group (RG) provides natural notions of locality and scaling. Moreover, we comment on several subtleties, for example, that data components may not have a permutation symmetry: in that case, we argue that random tensor field theories could provide a natural generalization. Second, we improve the perturbative Wilsonian renormalization from Halverson et al (2021 Mach. Learn.: Sci. Technol. 2 035002) by providing an analysis in terms of the non-perturbative RG using the Wetterich-Morris equation. An important difference with usual non-perturbative RG analysis is that only the effective infrared 2-point function is known, which requires setting the problem with care. Our aim is to provide a useful formalism to investigate NNs behavior beyond the large-width limit (i.e. far from Gaussian limit) in a non-perturbative fashion. A major result of our analysis is that changing the standard deviation of the NN weight distribution can be interpreted as a renormalization flow in the space of networks. We focus on translations invariant kernels and provide preliminary numerical results.
OI Ousmane Samary, Dine/0000-0001-8666-5481
EI 2632-2153
PD MAR 1
PY 2022
VL 3
IS 1
AR 015027
DI 10.1088/2632-2153/ac4f69
UT WOS:000758416600001
ER

PT J
AU Tu, YB
   Li, L
   Su, L
   Gao, SX
   Yan, CG
   Zha, ZJ
   Yu, ZT
   Huang, QM
AF Tu, Yunbin
   Li, Liang
   Su, Li
   Gao, Shengxiang
   Yan, Chenggang
   Zha, Zheng-Jun
   Yu, Zhengtao
   Huang, Qingming
TI I(2)Transformer: Intra- and Inter-Relation Embedding Transformer for TV
   Show Captioning
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
AB TV show captioning aims to generate a linguistic sentence based on the video and its associated subtitle. Compared to purely video-based captioning, the subtitle can provide the captioning model with useful semantic clues such as actors' sentiments and intentions. However, the effective use of subtitle is also very challenging, because it is the pieces of scrappy information and has semantic gap with visual modality. To organize the scrappy information together and yield a powerful omni-representation for all the modalities, an efficient captioning model requires understanding video contents, subtitle semantics, and the relations in between. In this paper, we propose an Intra- and Inter-relation Embedding Transformer (I(2)Transformer), consisting of an Intra-relation Embedding Block (IAE) and an Inter-relation Embedding Block (IEE) under the framework of a Transformer. First, the IAE captures the intra-relation in each modality via constructing the learnable graphs. Then, IEE learns the cross attention gates, and selects useful information from each modality based on their inter-relations, so as to derive the omni-representation as the input to the Transformer. Experimental results on the public dataset show that the I(2)Transformer achieves the state-of-the-art performance. We also evaluate the effectiveness of the IAE and IEE on two other relevant tasks of video with text inputs, i.e., TV show retrieval and video-guided machine translation. The encouraging performance further validates that the IAE and IEE blocks have a good generalization ability. The code is available at https://github.com/tuyunbin/I2Transformer.
OI Li, Liang/0000-0002-1943-8219; Tu, Yunbin/0000-0002-9525-9060
SN 1057-7149
EI 1941-0042
PY 2022
VL 31
BP 3565
EP 3577
DI 10.1109/TIP.2022.3159472
UT WOS:000803395500001
PM 35312620
ER

PT J
AU Sarhan, AM
   Elshennawy, NM
   Ibrahim, DM
AF Sarhan, Amany M.
   Elshennawy, Nada M.
   Ibrahim, Dina M.
TI HLR-Net: A Hybrid Lip-Reading Model Based on Deep Convolutional Neural
   Networks
SO CMC-COMPUTERS MATERIALS & CONTINUA
AB Lip reading is typically regarded as visually interpreting the speaker?s lip movements during the speaking. This is a task of decoding the text from the speaker?s mouth movement. This paper proposes a lip-reading model that helps deaf people and persons with hearing problems to understand a speaker by capturing a video of the speaker and inputting it into the proposed model to obtain the corresponding subtitles. Using deep learning technologies makes it easier for users to extract a large number of different features, which can then be converted to probabilities of letters to obtain accurate results. Recently proposed methods for lip reading are based on sequence-to-sequence architectures that are designed for natural machine translation and audio speech recognition. However, in this paper, a deep convolutional neural network model called the hybrid lip-reading (HLR-Net) model is developed for lip reading from a video. The proposed model includes three stages, namely, preprocessing, encoder, and decoder stages, which produce the output subtitle. The inception, gradient, and bidirectional GRU layers are used to build the encoder, and the attention, fully-connected, activation function layers are used to build the decoder, which performs the connectionist temporal classification (CTC). In comparison with the three recent models, namely, the LipNet model, the lip-reading model with cascaded attention (LCANet), and attention-CTC (A-ACA) model, on the GRID corpus dataset, the proposed HLR-Net model can achieve significant improvements, achieving the CER of 4.9%, WER of 9.7%, and Bleu score of 92% in the case of unseen speakers, and the CER of 1.4%, WER of 3.3%, and Bleu score of 99% in the case of overlapped speakers.
RI Ibrahim, Dina/AAR-9868-2020; M., Dina/AAT-1056-2020; Sarhan,
   ِAmany/U-6091-2019
OI Ibrahim, Dina/0000-0002-7775-0577; M., Dina/0000-0002-7805-6798; Sarhan,
   ِAmany/0000-0002-0151-9619
SN 1546-2218
EI 1546-2226
PY 2021
VL 68
IS 2
BP 1531
EP 1549
DI 10.32604/cmc.2021.016509
UT WOS:000640237000006
ER

PT J
AU Merone, M
   Sansone, C
   Soda, P
AF Merone, Mario
   Sansone, Carlo
   Soda, Paolo
TI A computer-aided diagnosis system for HEp-2 fluorescence intensity
   classification
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
AB Background and objective: The indirect immunofluorescence (IIF) on HEp-2 cells is the recommended technique for the detection of antinuclear antibodies. However, it is burdened by some limitations, as it is time consuming and subjective, and it requires trained personnel. In other fields the adoption of deep neural networks has provided an effective high-level abstraction of the raw data, resulting in the ability to automatically generate optimized high-level features.
   Methods: To alleviate IIF limitations, this paper presents a computer-aided diagnosis (CAD) system classifying HEp-2 fluorescence intensity: it represents each image using an Invariant Scattering Convolutional Network (Scatnet), which is locally translation invariant and stable to deformations, a characteristic useful in case of HEp-2 samples. To cope with the inter-observer discrepancies found in the dataset, we also introduce a method for gold standard computation that assigns a label and a reliability score to each HEp-2 sample on the basis of annotations provided by expert physicians. Features by Scatnet and gold standard information are then used to train a Support Vector Machine.
   Results: The proposed CAD is tested on a new dataset of 1771 images annotated by three independent medical centers. The performances achieved by our CAD in recognizing positive, weak positive and negative samples are also compared against those obtained by other two approaches presented so far in the literature. The same system trained on this new dataset is then tested on two public datasets, namely MIVIA and I3Asel.
   Conclusions: The results confirm the effectiveness of our proposal, also revealing that it achieves the same performance as medical experts.
RI Sansone, Carlo/AGZ-8858-2022; Merone, Mario/AAA-8945-2019; Soda,
   Paolo/K-8126-2016
OI Merone, Mario/0000-0002-9406-2397; Soda, Paolo/0000-0003-2621-072X
SN 0933-3657
EI 1873-2860
PD JUN
PY 2019
VL 97
BP 71
EP 78
DI 10.1016/j.artmed.2018.11.002
UT WOS:000474326600008
PM 30503016
ER

PT C
AU Granik, Y
AF Granik, Yuri
BE Rankin, JH
   Preil, ME
TI Theory of transformation-invariant compact process modeling
SO PHOTOMASK TECHNOLOGY 2019
SE Proceedings of SPIE
CT Photomask Technology Conference
CY SEP 16-18, 2018
CL Monterey, CA
SP BACUS, SPIE
AB Modern one-digit technological nodes demand strict reproduction of the optical proximity corrections (OPC) for repeatable congruent patterns. To ensure this property the optical and process simulations must be invariant to the geometrical transformations of the translation, rotation, and reflection. Simulators must support invariance both in theory, mathematically, and in practice, numerically.
   In the first part of this study we aim to examine manner and conditions under which optical approximations, such as Sum of Coherent Systems (SOCS) and Abbe decomposition, preserve or violate intrinsic invariances of exact imaging. In this age of asymmetrical pixelated sources, complex Jones pupils, and tilted chief rays, the full rotational invariance is observed only in some cases of annular illuminations; otherwise, it is rare in contemporary optics.
   In the second part we consider more important topic: invariances of compact process modeling (CPM) operators. Translational, rotational, and reflectional invariances are obligatory in CPM, because photoresist processing effects do not have preferential lateral direction, origin, or reflectional axis. The invariance of CPM operators has never been scrutinized before. We fill this gap by expanding generic translationally-invariant CPM operator into Volterra series, and then examine linear, quadratic, and high-order terms. Contrary to the straightforward invariance conditions for linear operators, the morphology of invariance for the second and high order operators is non-trivial. We found necessary and sufficient conditions for the invariance to take place, and provide examples of non-linear Volterra operators that can be used as atomic construction blocks in neural networks for CPM.
SN 0277-786X
EI 1996-756X
BN 978-1-5106-3000-0
PY 2019
VL 11148
AR UNSP 111481P
DI 10.1117/12.2537887
UT WOS:000511111700042
ER

PT J
AU Cheng, HD
   Grimm, SK
   Gilman, MSA
   Gwom, LC
   Sok, D
   Sundling, C
   Donofrio, G
   Hedestam, GBK
   Bonsignori, M
   Haynes, BF
   Lahey, TP
   Maro, I
   von Reyn, CF
   Gorny, MK
   Zolla-Pazner, S
   Walker, BD
   Alter, G
   Burton, DR
   Robb, ML
   Krebs, SJ
   Seaman, MS
   Bailey-Kellogg, C
   Ackerman, ME
AF Cheng, Hao D.
   Grimm, Sebastian K.
   Gilman, Morgan S. A.
   Gwom, Luc Christian
   Sok, Devin
   Sundling, Christopher
   Donofrio, Gina
   Hedestam, Gunilla B. Karlsson
   Bonsignori, Mattia
   Haynes, Barton F.
   Lahey, Timothy P.
   Maro, Isaac
   von Reyn, C. Fordham
   Gorny, Miroslaw K.
   Zolla-Pazner, Susan
   Walker, Bruce D.
   Alter, Galit
   Burton, Dennis R.
   Robb, Merlin L.
   Krebs, Shelly J.
   Seaman, Michael S.
   Bailey-Kellogg, Chris
   Ackerman, Margaret E.
TI Fine epitope signature of antibody neutralization breadth at the HIV-1
   envelope CD4-binding site
SO JCI INSIGHT
AB Major advances in donor identification, antigen probe design, and experimental methods to clone pathogen-specific antibodies have led to an exponential growth in the number of newly characterized broadly neutralizing antibodies (bnAbs) that recognize the HIV-1 envelope glycoprotein. Characterization of these bnAbs has defined new epitopes and novel modes of recognition that can result in potent neutralization of HIV-1. However, the translation of envelope recognition profiles in biophysical assays into an understanding of in vivo activity has lagged behind, and identification of subjects and mAbs with potent antiviral activity has remained reliant on empirical evaluation of neutralization potency and breadth. To begin to address this discrepancy between recombinant protein recognition and virus neutralization, we studied the fine epitope specificity of a panel of CD4-binding site (CD4bs) antibodies to define the molecular recognition features of functionally potent humoral responses targeting the HIV-1 envelope site bound by CD4. Whereas previous studies have used neutralization data and machine-learning methods to provide epitope maps, here, this approach was reversed, demonstrating that simple binding assays of fine epitope specificity can prospectively identify broadly neutralizing CD4bs-specific mAbs. Building on this result, we show that epitope mapping and prediction of neutralization breadth can also be accomplished in the assessment of polyclonal serum responses. Thus, this study identifies a set of CD4bs bnAb signature amino acid residues and demonstrates that sensitivity to mutations at signature positions is sufficient to predict neutralization breadth of polyclonal sera with a high degree of accuracy across cohorts and across clades.
RI Hedestam, Gunilla Karlsson/AAN-9616-2021; Bonsignori,
   Mattia/AAE-7678-2019; Zolla-Pazner, Susan/S-1864-2019; Cheng,
   Hao/K-9631-2019; Sundling, Christopher/H-7707-2019; Krebs,
   Shelly/D-8015-2016
OI Bonsignori, Mattia/0000-0003-2973-2101; Zolla-Pazner,
   Susan/0000-0002-0750-2666; Cheng, Hao/0000-0002-5368-3613; Sundling,
   Christopher/0000-0002-6138-690X; Krebs, Shelly/0000-0003-1136-1760;
   Gorny, Miroslaw/0000-0002-2714-8780
EI 2379-3708
PD MAR 8
PY 2018
VL 3
IS 5
AR e97018
DI 10.1172/jci.insight.97018
UT WOS:000426879000009
PM 29515029
ER

PT J
AU Yang, HT
   Zhou, Y
   Zong, CQ
AF Yang, Haitong
   Zhou, Yu
   Zong, Chengqing
TI Bilingual Semantic Role Labeling Inference via Dual Decomposition
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB This article focuses on bilingual Semantic Role Labeling (SRL); its goal is to annotate semantic roles on both sides of the parallel bilingual texts (bi-texts). Since rich bilingual information is encoded, bilingual SRL has been applied in many natural-language processing (NLP) tasks such as machine translation (MT), cross-lingual information retrieval (IR), and the like. A feasible way of performing bilingual SRL is using monolingual SRL systems to perform SRL on each side of bi-texts separately. However, it is difficult to obtain consistent SRL results on both sides of bi-texts in this way. Some works have tried to jointly infer bilingual SRL because there are many complementary language cues on both sides of bi-texts and they reported better performance than monolingual systems. However, there are two limits in the existing methods. First, the existing methods often require high inference costs due to the complex objective function. Second, the existing methods fully adopt the candidates generated by monolingual SRL systems, but many candidates are discarded in the argument pruning or identification stage of monolingual systems. In this article, we propose two strategies to overcome these limits. We utilize a simple but efficient technique: Dual Decomposition to search for consistent results for both sides of bi-texts. On the other hand, we propose a method called Bi-Directional Projection (BDP) to recover arguments discarded in monolingual SRL systems.
   We evaluate our method on a standard parallel benchmark: the OntoNotes dataset. The experimental results show that our method yields significant improvements over the state-of-the-art monolingual systems. In addition, our approach is also better and faster than existing methods due to BDP and Dual Decomposition.
OI Zong, Chengqing/0000-0002-9864-3818
SN 2375-4699
EI 2375-4702
PD MAR
PY 2016
VL 15
IS 3
AR 15
DI 10.1145/2835493
UT WOS:000373913600005
ER

PT J
AU Sharma, S
   Shekhar, S
   Gautam, S
   Chauhan, KD
   Sharma, B
AF Sharma, Shreya
   Shekhar, Shashank
   Gautam, Sanjeev
   Chauhan, K. D.
   Sharma, Bhasha
TI Invigoration of polymer bioinks for additive manufacturing of human
   tissues and organs
SO EMERGENT MATERIALS
AB The emanating paragon of personalized medical care utilizes discrete patient data to customize clinical therapy. While the principal cynosure so far is the formulation of ameliorated therapeutics contingent on "omics" data, the notion outstretches all embodiments of customized treatment. Howbeit, the dearth of in vitro tissue and organ models competent of mimicking human physiology gravely impede the development and clinical translation of drugs and therapies with higher in vivo efficiency. Bioprinting (a form of additive manufacturing) enables us to effectively address the perpetual limitations for the manufacturing of hierarchically organized living constructs with complex structural and functional organization through the precise spatial positioning of multiple materials and cells. Additive manufacturing translates computer-aided design virtual 3D models into physical objects. By digital splicing of tomographic data, 3D scan, or computer-aided design, layer-by-layer fabrication of target objects can be achieved bereft the requirement for molds or machining. As polymeric materials are by far the most exploited class of materials, the anecdote discusses the processing of polymers and the development of polymers and advanced polymeric systems, especially for bioprinting. Facets of polymer design, additives, and processing parameters as they harmonize to exalting build speed and improved veracity, stability, functionality, mechanical attributes, porosity, and surface finish are explored. As the field matures, additive manufacturing is poised to proffer patient-specific tissue and organ substitutes, reproducible microtissues for drug screening and disease modeling, personalized drug delivery systems, as well as customized medical devices; therefore, we also highlight the most pressing challenges facing the research domain to revolutionize modern medicine and healthcare.
SN 2522-5731
EI 2522-574X
PD AUG
PY 2022
VL 5
IS 4
BP 1241
EP 1250
DI 10.1007/s42247-021-00285-4
EA AUG 2021
UT WOS:000682481000002
ER

PT J
AU Rajan, K
   Brinkhaus, HO
   Sorokina, M
   Zielesny, A
   Steinbeck, C
AF Rajan, Kohulan
   Brinkhaus, Henning Otto
   Sorokina, Maria
   Zielesny, Achim
   Steinbeck, Christoph
TI DECIMER-Segmentation: Automated extraction of chemical structure
   depictions from scientific literature
SO JOURNAL OF CHEMINFORMATICS
AB Chemistry looks back at many decades of publications on chemical compounds, their structures and properties, in scientific articles. Liberating this knowledge (semi-)automatically and making it available to the world in open-access databases is a current challenge. Apart from mining textual information, Optical Chemical Structure Recognition (OCSR), the translation of an image of a chemical structure into a machine-readable representation, is part of this workflow. As the OCSR process requires an image containing a chemical structure, there is a need for a publicly available tool that automatically recognizes and segments chemical structure depictions from scientific publications. This is especially important for older documents which are only available as scanned pages. Here, we present DECIMER (Deep lEaming for Chemical IMagE Recognition) Segmentation, the first open-source, deep learning-based tool for automated recognition and segmentation of chemical structures from the scientific literature. The workflow is divided into two main stages. During the detection step, a deep learning model recognizes chemical structure depictions and creates masks which define their positions on the input page. Subsequently, potentially incomplete masks are expanded in a post-processing workflow. The performance of DECIMER Segmentation has been manually evaluated on three sets of publications from different publishers. The approach operates on bitmap images of journal pages to be applicable also to older articles before the introduction of vector images in PDFs. By making the source code and the trained model publicly available, we hope to contribute to the development of comprehensive chemical data extraction workflows. In order to facilitate access to DECIMER Segmentation, we also developed a web application. The web application, available at https://decimer.ai , lets the user upload a pdf file and retrieve the segmented structure depictions.
RI Rajan, Kohulan/HNB-4502-2023
OI Rajan, Kohulan/0000-0003-1066-7792; Brinkhaus, Henning
   Otto/0000-0002-6664-2183; Steinbeck, Christoph/0000-0001-6966-0814
SN 1758-2946
PD MAR 8
PY 2021
VL 13
IS 1
AR 20
DI 10.1186/s13321-021-00496-1
UT WOS:000627252400002
PM 33685498
ER

PT J
AU Boscarino, S
   Cho, SY
   Russo, G
   Yun, SB
AF Boscarino, Sebastiano
   Cho, Seung-Yeon
   Russo, Giovanni
   Yun, Seok-Bae
TI High Order Conservative Semi-Lagrangian Scheme for the BGK Model of the
   Boltzmann Equation
SO COMMUNICATIONS IN COMPUTATIONAL PHYSICS
AB In this paper, we present a conservative semi-Lagrangian finite-difference scheme for the BGK model. Classical semi-Lagrangian finite difference schemes, coupled with an L-stable treatment of the collision term, allow large time steps, for all the range of Knudsen number [17, 27,30]. Unfortunately, however, such schemes are not conservative. Lack of conservation is analyzed in detail, and two main sources are identified as its cause. First, when using classical continuous Maxwellian, conservation error is negligible only if velocity space is resolved with sufficiently large number of grid points. However, for a small number of grid points in velocity space such error is not negligible, because the parameters of the Maxwellian do not coincide with the discrete moments. Secondly, the non-linear reconstruction used to prevent oscillations destroys the translation invariance which is at the basis of the conservation properties of the scheme. As a consequence the schemes show a wrong shock speed in the limit of small Knudsen number. To treat the first problem and ensure machine precision conservation of mass, momentum and energy with a relatively small number of velocity grid points, we replace the continuous Maxwellian with the discrete Maxwellian introduced in [22]. The second problem is treated by implementing a conservative correction procedure based on the flux difference form as in [26]. In this way we can construct conservative semi-Lagrangian schemes which are Asymptotic Preserving (AP) for the underlying Euler limit, as the Knudsen number vanishes. The effectiveness of the proposed scheme is demonstrated by extensive numerical tests.
OI BOSCARINO, Sebastiano/0000-0002-3447-8016
SN 1815-2406
EI 1991-7120
PD JAN
PY 2021
VL 29
IS 1
BP 1
EP 56
DI 10.4208/cicp.OA-2020-0050
UT WOS:000595171300001
ER

PT J
AU Bavandpour, M
   Mahmoodi, MR
   Strukov, DB
AF Bavandpour, Mohammad
   Mahmoodi, Mohammad R.
   Strukov, Dmitri B.
TI aCortex: An Energy-Efficient Multipurpose Mixed-Signal Inference
   Accelerator
SO IEEE JOURNAL ON EXPLORATORY SOLID-STATE COMPUTATIONAL DEVICES AND
   CIRCUITS
AB We introduce "aCortex," an extremely energy-efficient, fast, compact, and versatile neuromorphic processor architecture suitable for the acceleration of a wide range of neural network inference models. The most important feature of our processor is a configurable mixed-signal computing array of vector-by-matrix multiplier (VMM) blocks utilizing embedded nonvolatile memory arrays for storing weight matrices. Analog peripheral circuitry for data conversion and high-voltage programming are shared among a large array of VMM blocks to facilitate compact and energy-efficient analog-domain VMM operation of different types of neural network layers. Other unique features of aCortex include configurable chain of buffers and data buses, simple and efficient instruction set architecture and its corresponding multiagent controller, programmable quantization range, and a customized refresh-free embedded dynamic random access memory. The energy-optimal aCortex with 4-bit analog computing precision was designed in a 55-nm process with embedded NOR flash memory. Its physical performance was evaluated using experimental data from testing individual circuit elements and physical layout of key components for several common benchmarks, namely, Inception-vl and ResNet-152, two state-of-the-art deep feedforward networks for image classification, and GNTM, Google's deep recurrent network for language translation. The system-level simulation results for these benchmarks show the energy efficiency of 97, 106, and 336 TOp/J, respectively, combined with up to 15 TOp/s computing throughput and 0.27-MB/mm(2) storage efficiency. Such estimated performance results compare favorably with those of previously reported mixed-signal accelerators based on much less mature aggressively scaled resistive switching memories.
OI Bavandpour, Mohammad/0000-0001-6425-9087; , Dmitri/0000-0002-4526-4347
SN 2329-9231
PD JUN
PY 2020
VL 6
IS 1
BP 98
EP 106
DI 10.1109/JXCDC.2020.2999581
UT WOS:000545575000013
ER

PT C
AU Patwary, M
   Chabbi, M
   Jun, H
   Huang, JJ
   Diamos, G
   Church, K
AF Patwary, Mostofa
   Chabbi, Milind
   Jun, Heewoo
   Huang, Jiaji
   Diamos, Gregory
   Church, Kenneth
GP IEEE
TI Language Modeling at Scale
SO 2019 IEEE 33RD INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM (IPDPS 2019)
SE International Parallel and Distributed Processing Symposium IPDPS
CT 33rd IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 20-24, 2019
CL Rio de Janeiro, BRAZIL
SP IEEE, IEEE Comp Soc
AB We show how Zipf's Law can be used to scale up language modeling (LM) to take advantage of more training data and more GPUs. LM plays a key role in many important natural language applications such as speech recognition and machine translation. Scaling up LM is important since it is widely accepted by the community that there is no data like more data. Eventually, we would like to train on terabytes (TBs) of text (trillions of words). Modern training methods are far from this goal, because of various bottlenecks, especially memory (within GPUs) and communication (across GPUs). This paper shows how Zipf's Law can address these bottlenecks by grouping parameters for common words and character sequences, because U << N, where U is the number of unique words (types) and N is the size of the training set (tokens). For a local batch size K with G GPUs and a D-dimension embedding matrix, we reduce the original per-GPU memory and communication asymptotic complexity from Theta(GKD) to Theta(GK +UD). Empirically, we find U proportional to (GK)(0.64) on four publicly available large datasets. When we scale up the number of GPUs to 64, a factor of 8, training time speeds up by factors up to 6.7 x (for character LMs) and 6.3 x (for word LMs) with negligible loss of accuracy. Our weak scaling on 192 GPUs on the Tieba dataset shows a 35% improvement in LM prediction accuracy by training on 93 GB of data (2.5 x larger than publicly available SOTA dataset), but taking only 1.25 x increase in training time, compared to 3 GB of the same dataset running on 6 GPUs.
RI Church, Kenneth/AAV-9667-2021; Church, Kenneth/GYR-1624-2022
OI Church, Kenneth/0000-0001-8378-6069; Church, Kenneth/0000-0001-8378-6069
SN 1530-2075
BN 978-1-7281-1246-6
PY 2019
BP 590
EP 599
DI 10.1109/IPDPS.2019.00068
UT WOS:000539043300056
ER

PT C
AU Hanumanthappa, M
   Rashmi, S
   Reddy, MV
AF Hanumanthappa, M.
   Rashmi, S.
   Reddy, Mallamma V.
GP IEEE
TI Metrics for evaluating phonetics machine translation in Natural Language
   Processing through Modified Edit Distance algorithm-A Naive Approach
SO 2015 INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND INFORMATICS
   (ICCCI)
CT International Conference on Computer Communication and Informatics ICCCI
CY JAN 08-10, 2015
CL Coimbatore, INDIA
SP Sri Shakthi Inst Of Engn And Technol, IEEE Madras Sect, IEEE, IESA
AB Uninhabited mistakes while writing happens are unstoppable. There are certain common errors that occur during writing such as missing letters, extra letters, disordered letters, and misspelled letters. These kind of common spelling errors are called phonetics spelling errors. These are of a major concern while dealing with phonetics. Out of various problems that the phoneticians are trying to solve, major portion of it concentrates on varieties of spelling errors. Phonetic structures are greatly emphasized based on the effectiveness, appropriateness and accuracy. In order to keep abreast with the changing and challenging trends of Natural Language Processing (NLP), it is of great importance that one should resolve the problems of spelling errors. To achieve the goal, numerous realistic and practical approaches have to be adopted that make use of spelling correction algorithms such as Edit distance, Habit distance, Soundex and Asoundex. Through the analysis of these algorithms, a new interface is put forward that calculates the Edit distance, thereby showing the overall comparative study of phonetic algorithms with the proposed modified Edit Distance algorithm. The interface computes the Edit distance between two strings in appropriate and intuitive way, contemplating with the comparisons shown in the distance table. The Results show that an average of 0.937 recall and 0.947 precision have been achieved with the F-measure 0.9417. Through these results, it is evident that the recall and F-measures are improved in the proposed Edit-Distance algorithm. The revised version of the edit distance algorithm consistently attains finer quality results in comparison with the traditional edit distance algorithm.
RI Reddy, Mallamma/AEW-8878-2022
OI Siddalingappa, Rashmi/0000-0001-9786-8436
BN 978-1-4799-6805-3
PY 2015
UT WOS:000380444700050
ER

PT J
AU Davey, J
   Stewart, MEB
   Drummer, OH
AF Davey, Janet
   Stewart, Margaret Ellen Birchland
   Drummer, Olaf H.
TI The value of CT imaging of Horus in determining the method of
   mummification and the sex of the mummy
SO JOURNAL OF MEDICAL IMAGING AND RADIATION ONCOLOGY
AB IntroductionRadiology was used to determine the sex of a child mummy who had conflicting records based on two different translations of a name written in a section of papyrus inserted into the mummy wrappings and also to determine the type of mummification used to preserve the body.
   MethodsAncient texts of Herodotus and Diodorus Siculus were consulted for references to mummification, and Nicholson Museum records provided details of the mummy which was examined at Central Sydney Imaging using Toshiba Aquilion 64 CT machine (Toshiba Medical Systems Corporation, Tochigi, Japan). The original CT scan data were loaded into a Vitrea 2 (Vital Images, Minnetonka, MN, USA) workstation at the Victorian Institute of Forensic Medicine, Melbourne, Australia, for further study.
   ResultsThe scans showed that the child had been elaborately mummified according to ancient descriptions albeit with one variation. The provenance of the child was unknown but stylistically appeared to be from the Greco-Roman Period of ancient Egypt. Interpretation of the CT images determined that the child was male, had died of unknown cause and had been excerebrated and eviscerated post-mortem when the heart was removed. Unexplained inclusions were identified within the abdomen and thorax. Broken and displaced ribs showed evidence of a previous endoscopic investigation.
   ConclusionThis study provided evidence that CT scanning was an excellent non-invasive modality to evaluate ancient mummies in its ability to demonstrate fine anatomical detail and identify post-mortem changes. The study underlined the role of using current medical practice to determine sex rather than relying on ancient texts and uncorroborated opinion.
RI Drummer, Olaf/H-7094-2014
OI Drummer, Olaf/0000-0001-8953-0312
SN 1754-9477
EI 1754-9485
PD DEC
PY 2013
VL 57
IS 6
BP 657
EP 662
DI 10.1111/1754-9485.12070
UT WOS:000327441700004
PM 24283553
ER

PT J
AU Livesay, SB
   Collier, SE
   Bitton, DA
   Bahler, J
   Ohi, MD
AF Livesay, S. Brent
   Collier, Scott E.
   Bitton, Danny A.
   Baehler, Juerg
   Ohi, Melanie D.
TI Structural and Functional Characterization of the N Terminus of
   Schizosaccharomyces pombe Cwf10
SO EUKARYOTIC CELL
AB The spliceosome is a dynamic macromolecular machine that catalyzes the removal of introns from pre-mRNA, yielding mature message. Schizosaccharomyces pombe Cwf10 (homolog of Saccharomyces cerevisiae Snu114 and human U5-116K), an integral member of the U5 snRNP, is a GTPase that has multiple roles within the splicing cycle. Cwf10/Snu114 family members are highly homologous to eukaryotic translation elongation factor EF2, and they contain a conserved N-terminal extension (NTE) to the EF2-like portion, predicted to be an intrinsically unfolded domain. Using S. pombe as a model system, we show that the NTE is not essential, but cells lacking this domain are defective in pre-mRNA splicing. Genetic interactions between cwf10-Delta NTE and other pre-mRNA splicing mutants are consistent with a role for the NTE in spliceosome activation and second-step catalysis. Characterization of Cwf10-NTE by various biophysical techniques shows that in solution the NTE contains regions of both structure and disorder. The first 23 highly conserved amino acids of the NTE are essential for its role in splicing but when overexpressed are not sufficient to restore pre-mRNA splicing to wild-type levels in cwf10-Delta NTE cells. When the entire NTE is overexpressed in the cwf10-Delta NTE background, it can complement the truncated Cwf10 protein in trans, and it immunoprecipitates a complex similar in composition to the late-stage U5.U2/U6 spliceosome. These data show that the structurally flexible NTE is capable of independently incorporating into the spliceosome and improving splicing function, possibly indicating a role for the NTE in stabilizing conformational rearrangements during a splice cycle.
RI Bahler, Jurg/B-4572-2009
OI Bahler, Jurg/0000-0003-4036-1532
SN 1535-9778
EI 1535-9786
PD NOV
PY 2013
VL 12
IS 11
BP 1472
EP 1489
DI 10.1128/EC.00140-13
UT WOS:000326159800007
PM 24014766
ER

PT J
AU Luna, A
   Karac, EI
   Sunshine, M
   Chang, L
   Nussinov, R
   Aladjem, MI
   Kohn, KW
AF Luna, Augustin
   Karac, Evrim I.
   Sunshine, Margot
   Chang, Lucas
   Nussinov, Ruth
   Aladjem, Mirit I.
   Kohn, Kurt W.
TI A formal MIM specification and tools for the common exchange of MIM
   diagrams: an XML-Based format, an API, and a validation method
SO BMC BIOINFORMATICS
AB Background: The Molecular Interaction Map (MIM) notation offers a standard set of symbols and rules on their usage for the depiction of cellular signaling network diagrams. Such diagrams are essential for disseminating biological information in a concise manner. A lack of software tools for the notation restricts wider usage of the notation. Development of software is facilitated by a more detailed specification regarding software requirements than has previously existed for the MIM notation.
   Results: A formal implementation of the MIM notation was developed based on a core set of previously defined glyphs. This implementation provides a detailed specification of the properties of the elements of the MIM notation. Building upon this specification, a machine-readable format is provided as a standardized mechanism for the storage and exchange of MIM diagrams. This new format is accompanied by a Java-based application programming interface to help software developers to integrate MIM support into software projects. A validation mechanism is also provided to determine whether MIM datasets are in accordance with syntax rules provided by the new specification.
   Conclusions: The work presented here provides key foundational components to promote software development for the MIM notation. These components will speed up the development of interoperable tools supporting the MIM notation and will aid in the translation of data stored in MIM diagrams to other standardized formats. Several projects utilizing this implementation of the notation are outlined herein. The MIM specification is available as an additional file to this publication. Source code, libraries, documentation, and examples are available at http://discover.nci.nih.gov/mim.
RI Aladjem, Mirit/G-2169-2010; Karac, Evrim Itir/C-3170-2015
OI Aladjem, Mirit/0000-0002-1875-3110; Karac, Evrim
   Itir/0000-0001-7119-922X; Nussinov, Ruth/0000-0002-8115-6415
SN 1471-2105
PD MAY 17
PY 2011
VL 12
AR 167
DI 10.1186/1471-2105-12-167
UT WOS:000291720700003
PM 21586134
ER

PT J
AU LaConte, SM
   Peltier, SJ
   Hu, XPP
AF LaConte, Stephen M.
   Peltier, Scott J.
   Hu, Xiaoping P.
TI Real-time fMRI using brain-state classification
SO HUMAN BRAIN MAPPING
AB We have implemented a real-time functional magnetic resonance imaging system based on multivariate classification. This approach is distinctly different from spatially localized real-time implementations, since it does not require prior assumptions about functional localization and individual performance strategies, and has the ability to provide feedback based on intuitive translations of brain state rather than localized fluctuations. Thus this approach provides the capability for a new class of experimental designs in which real-time feedback control of the stimulus is possible-rather than using a fixed paradigm, experiments can adaptively evolve as subjects receive brain-state feedback. In this report, we describe our implementation and characterize its performance capabilities. We observed similar to 80% classification accuracy using whole brain, block-design, motor data. Within both left and right motor task conditions, important differences exist between the initial transient period produced by task switching (changing between rapid left or right index finger button presses) and the subsequent stable period during sustained activity. Further analysis revealed that very high accuracy is achievable during stable task periods, and that the responsiveness of the classifier to changes in task condition can be much faster than signal time-to-peak rates. Finally, we demonstrate the versatility of this implementation with respect to behavioral task, suggesting that our results are applicable across a spectrum of cognitive domains. Beyond basic research, this technology can complement electroencephalography-based brain computer interface research, and has potential applications in the areas of biofeedback rehabilitation, lie detection, learning studies, virtual reality-based training, and enhanced conscious awareness.
OI Hu, Xiaoping/0000-0001-7014-5983
SN 1065-9471
EI 1097-0193
PD OCT
PY 2007
VL 28
IS 10
BP 1033
EP 1044
DI 10.1002/hbm.20326
UT WOS:000249990700011
PM 17133383
ER

PT J
AU Estiri, H
   Strasser, ZH
   Rashidian, S
   Klann, JG
   Wagholikar, KB
   McCoy, TH
   Murphy, SN
AF Estiri, Hossein
   Strasser, Zachary H.
   Rashidian, Sina
   Klann, Jeffrey G.
   Wagholikar, Kavishwar B.
   McCoy, Thomas H.
   Murphy, Shawn N.
TI An objective framework for evaluating unrecognized bias in medical AI
   models predicting COVID-19 outcomes
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
AB Objective The increasing translation of artificial intelligence (AI)/machine learning (ML) models into clinical practice brings an increased risk of direct harm from modeling bias; however, bias remains incompletely measured in many medical AI applications. This article aims to provide a framework for objective evaluation of medical AI from multiple aspects, focusing on binary classification models. Materials and Methods Using data from over 56 000 Mass General Brigham (MGB) patients with confirmed severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), we evaluate unrecognized bias in 4 AI models developed during the early months of the pandemic in Boston, Massachusetts that predict risks of hospital admission, ICU admission, mechanical ventilation, and death after a SARS-CoV-2 infection purely based on their pre-infection longitudinal medical records. Models were evaluated both retrospectively and prospectively using model-level metrics of discrimination, accuracy, and reliability, and a novel individual-level metric for error. Results We found inconsistent instances of model-level bias in the prediction models. From an individual-level aspect, however, we found most all models performing with slightly higher error rates for older patients. Discussion While a model can be biased against certain protected groups (ie, perform worse) in certain tasks, it can be at the same time biased towards another protected group (ie, perform better). As such, current bias evaluation studies may lack a full depiction of the variable effects of a model on its subpopulations. Conclusion Only a holistic evaluation, a diligent search for unrecognized bias, can provide enough information for an unbiased judgment of AI bias that can invigorate follow-up investigations on identifying the underlying roots of bias and ultimately make a change.
RI ; Wagholikar, Kavishwar/M-1249-2013
OI Rashidian, Sina/0000-0003-1210-2939; Estiri,
   Hossein/0000-0002-0204-8978; Strasser, Zachary/0000-0002-4846-6059;
   Wagholikar, Kavishwar/0000-0002-6219-861X
SN 1067-5027
EI 1527-974X
PD JUL 12
PY 2022
VL 29
IS 8
BP 1334
EP 1341
DI 10.1093/jamia/ocac070
EA MAY 2022
UT WOS:000796629100001
PM 35511151
ER

PT J
AU Kashyap, S
   Morse, KE
   Patel, B
   Shah, NH
AF Kashyap, Sehj
   Morse, Keith E.
   Patel, Birju
   Shah, Nigam H.
TI A survey of extant organizational and computational setups for deploying
   predictive models in health systems
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
AB Objective: Artificial intelligence (AI) and machine learning (ML) enabled healthcare is now feasible for many health systems, yet little is known about effective strategies of system architecture and governance mechanisms for implementation. Our objective was to identify the different computational and organizational setups that early-adopter health systems have utilized to integrate AI/ML clinical decision support (AI-CDS) and scrutinize their trade-offs.
   Materials and Methods: We conducted structured interviews with health systems with AI deployment experience about their organizational and computational setups for deploying AI-CDS at point of care.
   Results: We contacted 34 health systems and interviewed 20 healthcare sites (58% response rate). Twelve (60%) sites used the native electronic health record vendor configuration for model development and deployment, making it the most common shared infrastructure. Nine (45%) sites used alternative computational configurations which varied significantly. Organizational configurations for managing AI-CDS were distinguished by how they identified model needs, built and implemented models, and were separable into 3 major types: Decentralized translation (n = 10, 50%), IT Department led (n = 2, 10%), and Al in Healthcare (AIHC) Team (n =8, 40%).
   Discussion: No singular computational configuration enables all current use cases for AI-CDS. Health systems need to consider their desired applications for AI-CDS and whether investment in extending the off-the-shelf infrastructure is needed. Each organizational setup confers trade-offs for health systems planning strategies to implement AI-CDS.
   Conclusion: Health systems will be able to use this framework to understand strengths and weaknesses of alternative organizational and computational setups when designing their strategy for artificial intelligence.
OI Morse, Keith/0000-0002-8307-1642; Kashyap, Sehj/0000-0003-0276-2183
SN 1067-5027
EI 1527-974X
PD NOV
PY 2021
VL 28
IS 11
BP 2445
EP 2450
DI 10.1093/jamia/ocab154
EA AUG 2021
UT WOS:000711702400015
PM 34423364
ER

PT J
AU Zeiss, CJ
   Shin, D
   Vander Wyk, B
   Beck, AP
   Zatz, N
   Sneiderman, CA
   Kilicoglu, H
AF Zeiss, Caroline J.
   Shin, Dongwook
   Vander Wyk, Brent
   Beck, Amanda P.
   Zatz, Natalie
   Sneiderman, Charles A.
   Kilicoglu, Halil
TI Menagerie: A text-mining tool to support animal-human translation in
   neurodegeneration research
SO PLOS ONE
AB Discovery studies in animals constitute a cornerstone of biomedical research, but suffer from lack of generalizability to human populations. We propose that large-scale interrogation of these data could reveal patterns of animal use that could narrow the translational divide. We describe a text-mining approach that extracts translationally useful data from PubMed abstracts. These comprise six modules: species, model, genes, interventions/disease modifiers, overall outcome and functional outcome measures. Existing National Library of Medicine natural language processing tools (SemRep, GNormPlus and the Chemical annotator) underpin the program and are further augmented by various rules, term lists, and machine learning models. Evaluation of the program using a 98-abstract test set achieved F1 scores ranging from 0.75-0.95 across all modules, and exceeded F1 scores obtained from comparable baseline programs. Next, the program was applied to a larger 14,481 abstract data set (2008-2017). Expected and previously identified patterns of species and model use for the field were obtained. As previously noted, the majority of studies reported promising outcomes. Longitudinal patterns of intervention type or gene mentions were demonstrated, and patterns of animal model use characteristic of the Parkinson's disease field were confirmed. The primary function of the program is to overcome low external validity of animal model systems by aggregating evidence across a diversity of models that capture different aspects of a multifaceted cellular process. Some aspects of the tool are generalizable, whereas others are field-specific. In the initial version presented here, we demonstrate proof of concept within a single disease area, Parkinson's disease. However, the program can be expanded in modular fashion to support a wider range of neurodegenerative diseases.
OI Zeiss, Caroline/0000-0003-1181-3544
SN 1932-6203
PD DEC 17
PY 2019
VL 14
IS 12
AR e0226176
DI 10.1371/journal.pone.0226176
UT WOS:000534238700012
PM 31846471
ER

PT J
AU Igual, C
   Pardo, LA
   Hahne, JM
   Igual, J
AF Igual, Caries
   Pardo, Luis A., Jr.
   Hahne, Janne M.
   Igual, Jorge
TI Myoelectric Control for Upper Limb Prostheses
SO ELECTRONICS
AB State-of-the-art high-end prostheses are electro-mechanically able to provide a great variety of movements. Nevertheless, in order to functionally replace a human limb, it is essential that each movement is properly controlled. This is the goal of prosthesis control, which has become a growing research field in the last decades, with the ultimate goal of reproducing biological limb control. Therefore, exploration and development of prosthesis control are crucial to improve many aspects of an amputee's life. Nowadays, a large divergence between academia and industry has become evident in commercial systems. Although several studies propose more natural control systems with promising results, basic one degree of freedom (DoF), a control switching system is the most widely used option in industry because of simplicity, robustness and inertia. A few classification controlled prostheses have emerged in the last years but they are still a low percentage of the used ones. One of the factors that generate this situation is the lack of robustness of more advanced control algorithms in daily life activities outside of laboratory conditions. Because of this, research has shifted towards more functional prosthesis control. This work reviews the most recent literature in upper limb prosthetic control. It covers commonly used variants of possible biological inputs, its processing and translation to actual control, mostly focusing on electromyograms as well as the problems it will have to overcome in near future.
OI Pardo, Luis/0000-0002-0361-971X; Igual, Jorge/0000-0003-3408-4014;
   Igual, Carles/0000-0002-7416-5313
EI 2079-9292
PD NOV
PY 2019
VL 8
IS 11
AR 1244
DI 10.3390/electronics8111244
UT WOS:000502269500040
ER

PT J
AU Ling, SY
   Xu, RT
   Bandeira, AS
AF Ling, Shuyang
   Xu, Ruitu
   Bandeira, Afonso S.
TI ON THE LANDSCAPE OF SYNCHRONIZATION NETWORKS: A PERSPECTIVE FROM
   NONCONVEX OPTIMIZATION
SO SIAM JOURNAL ON OPTIMIZATION
AB Studying the landscape of nonconvex cost functions is key towards a better understanding of optimization algorithms widely used in signal processing, statistics, and machine learning. Meanwhile, the famous Kuramoto model has been an important mathematical model for studying the synchronization phenomena of coupled oscillators over various network topologies. In this paper, we bring together these two seemingly unrelated objects by investigating the optimization landscape of a nonlinear function E(theta) = 1/2 Sigma(1 <= i,j <= n) a(ij)(1 - cos(theta(i) - theta(j))) associated with an underlying net- work and exploring the relationship between the existence of local minima and the network topology. This function arises naturally in the Burer-Monteiro method applied to Z(2) synchronization as well as matrix completion on the torus. Moreover, it corresponds to the energy function of the homogeneous Kuramoto model on complex networks for coupled oscillators. We prove that the minimizer of the energy function is unique up to a global translation under deterministic dense graphs and Erdos-Renyi random graphs with tools from optimization and random matrix theory. Consequently, the stable equilibrium of the corresponding homogeneous Kuramoto model is unique and the basin of attraction for the synchronous state of these coupled oscillators is the whole phase space minus a set of measure zero. In addition, our results address when the Burer-Monteiro method recovers the ground truth exactly from highly incomplete observations in Z(2) synchronization and shed light on the robustness of nonconvex optimization algorithms with respect to certain types of so-called monotone adversaries. Numerical simulations are performed to illustrate our results.
SN 1052-6234
EI 1095-7189
PY 2019
VL 29
IS 3
BP 1879
EP 1907
DI 10.1137/18M1217644
UT WOS:000487929500007
ER

PT J
AU Wu, YD
   Chen, H
AF Wu, Yi-Da
   Chen, Hsin
TI The Diffusion Network in Analog VLSI Exploiting Noise-Induced Stochastic
   Dynamics to Regenerate Various Continuous Paths
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
AB The Diffusion Network (DN) is a stochastic recurrent network capable of learning to regenerate various distributions of continuous-valued, continuous-time paths. By generalizing the data variability with internal stochasticity, the DN is found useful for distinguishing time-varying, biomedical signals reliably. In addition, the DN is a generalized form of the hidden Markov model and the Kalman filter, both of which have been useful in many applications. However, the continuous-time dynamics of the DN are governed by stochastic differential equations, making the DN unfavorable for execution in a digital computer. This paper presents the translation of the DN into analog very large scale integration (VLSI). By exploiting the natural differential current-voltage relationship of capacitors, the stochastic differential equations are computed by analog VLSI simultaneously in real time. The stochasticity required by the DN in VLSI is induced by a multi-channel noise generator on-chip, such that the DN actually uses noise-induced stochastic dynamics to generate continuous paths. Moreover, log-domain representation is employed to increase the dynamic range for diffusion processes, as well as to facilitate the subthreshold operation for power reduction. As subthreshold operation is prone to more nonlinear effects, the biasing conditions and operation ranges that minimize the effects are identified. Afterwards, a DN system-on-a-chip with four stochastic units is fabricated with the 0.18 mu m CMOS technology. The measurement results reveal the DN in VLSI is able to regenerate a variety of continuous paths with noise-induced stochastic dynamics in VLSI. Moreover, the practical utility of the DN system is demonstrated in the context of recognizing electrocardiograms.
OI Wu, Yi-Da/0000-0001-5149-5419
SN 1549-8328
EI 1558-0806
PD JUN
PY 2015
VL 62
IS 6
BP 1617
EP 1626
DI 10.1109/TCSI.2015.2416811
UT WOS:000356935700019
ER

PT J
AU Ying, XM
   Cao, Y
   Wu, JY
   Liu, Q
   Cha, L
   Li, WJ
AF Ying, Xiaomin
   Cao, Yuan
   Wu, Jiayao
   Liu, Qian
   Cha, Lei
   Li, Wuju
TI sTarPicker: A Method for Efficient Prediction of Bacterial sRNA Targets
   Based on a Two-Step Model for Hybridization
SO PLOS ONE
AB Background: Bacterial sRNAs are a class of small regulatory RNAs involved in regulation of expression of a variety of genes. Most sRNAs act in trans via base-pairing with target mRNAs, leading to repression or activation of translation or mRNA degradation. To date, more than 1,000 sRNAs have been identified. However, direct targets have been identified for only approximately 50 of these sRNAs. Computational predictions can provide candidates for target validation, thereby increasing the speed of sRNA target identification. Although several methods have been developed, target prediction for bacterial sRNAs remains challenging.
   Results: Here, we propose a novel method for sRNA target prediction, termed sTarPicker, which was based on a two-step model for hybridization between an sRNA and an mRNA target. This method first selects stable duplexes after screening all possible duplexes between the sRNA and the potential mRNA target. Next, hybridization between the sRNA and the target is extended to span the entire binding site. Finally, quantitative predictions are produced with an ensemble classifier generated using machine-learning methods. In calculations to determine the hybridization energies of seed regions and binding regions, both thermodynamic stability and site accessibility of the sRNAs and targets were considered. Comparisons with the existing methods showed that sTarPicker performed best in both performance of target prediction and accuracy of the predicted binding sites.
   Conclusions: sTarPicker can predict bacterial sRNA targets with higher efficiency and determine the exact locations of the interactions with a higher accuracy than competing programs. sTarPicker is available at http://ccb.bmi.ac.cn/starpicker/.
RI Li, Wu/AHA-4320-2022
OI /0000-0002-2681-8711; Li, Wuju/0000-0003-4613-9692
SN 1932-6203
PD JUL 22
PY 2011
VL 6
IS 7
AR e22705
DI 10.1371/journal.pone.0022705
UT WOS:000293097300081
PM 21799937
ER

PT J
AU Baykal, E
   Dogan, H
   Ercin, ME
   Ersoz, S
   Ekinci, M
AF Baykal, Elif
   Dogan, Hulya
   Ercin, Mustafa Emre
   Ersoz, Safak
   Ekinci, Murat
TI Transfer learning with pre-trained deep convolutional neural networks
   for serous cell classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
AB Serous effusion is a condition of excess accumulation of fluids in serous cavities due to different underlying pathological conditions. The basis of cytopathological assessment of serous effusions is the identification of cells in the fluid based on their morphology and texture. This assessment is a physically and mentally laborious task, and it can also lead to variability among pathologists. In literature, only a small number of feature-based methods are conducted for automated serous cell classification. In this study, a transfer learning with pre-trained deep convolutional neural networks (ConvNets) is proposed to automatically identify 11 different categories of serous cells in effusion cytology. Unlike the methods which rely on the extraction of cellular features such as morphology and texture, this method is an appearance-based machine learning approach. We fine-tuned four pre-trained ConvNet architectures that are AlexNet, GoogleNet, ResNet and DenseNet on the serous cell dataset. To reduce the overfitting effect, we augmented the data by image rotation, translation, and mirroring. The proposed method was evaluated on both original and augmented sets of serous cells derived from a publicly available dataset. Among the four ConvNet models, ResNet and DenseNet obtained the highest accuracies of 93.44% and 92.90%. However, when two models were compared in terms of accuracy and model complexity, ResNet-TL was selected as the best network model. When compared to the results without data augmentation, data augmentation increased the accuracy rate approximately 10%. Results show that higher classification results were achieved than other traditional methods without requiring precise segmentation.
RI Ekinci, Murat/A-9653-2012; Kablan, Elif Baykal/AAS-4282-2020; ersöz,
   safak/AAM-9041-2021; Ercin, Mustafa Emre/AAU-6389-2020; Dogan,
   Hulya/AAW-9173-2021
OI Ercin, Mustafa Emre/0000-0002-7340-8045; 
SN 1380-7501
EI 1573-7721
PD JUN
PY 2020
VL 79
IS 21-22
BP 15593
EP 15611
DI 10.1007/s11042-019-07821-9
UT WOS:000538675900067
ER

PT C
AU Nie, B
   Xu, JW
   Alter, J
   Chen, HF
   Smirni, E
AF Nie, Bin
   Xu, Jianwu
   Alter, Jacob
   Chen, Haifeng
   Smirni, Evgenia
GP IEEE
TI Mining Multivariate Discrete Event Sequences for Knowledge Discovery and
   Anomaly Detection
SO 2020 50TH ANNUAL IEEE/IFIP INTERNATIONAL CONFERENCE ON DEPENDABLE
   SYSTEMS AND NETWORKS (DSN 2020)
SE International Conference on Dependable Systems and Networks
CT 50th IEEE/IFIP Annual International Conference on Dependable Systems and
   Networks (DSN)
CY JUN 29-JUL 02, 2020
CL Valencia, SPAIN
SP IEEE, IFIP, IEEE Comp Soc, Intel, King Abdullah Univ Sci & Technol, Oracle, Commonwealth Cyber Initiat, Univ Politecnica Valencia, DISCA, Univ Politecnica Valencia
AB Modern physical systems deploy large numbers of sensors to record at different time-stamps the status of different systems components via measurements such as temperature, pressure, speed, but also the component's categorical state. Depending on the measurement values, there are two kinds of sequences: continuous and discrete. For continuous sequences, there is a host of state-of-the-art algorithms for anomaly detection based on time-series analysis, but there is a lack of effective methodologies that are tailored specifically to discrete event sequences.
   This paper proposes an analytics framework for discrete event sequences for knowledge discovery and anomaly detection. During the training phase, the framework extracts pairwise relationships among discrete event sequences using a neural machine translation model by viewing each discrete event sequence as a "natural language". The relationship between sequences is quantified by how well one discrete event sequence is "translated" into another sequence. These pairwise relationships among sequences are aggregated into a multivariate relationship graph that clusters the structural knowledge of the underlying system and essentially discovers the hidden relationships among discrete sequences. This graph quantifies system behavior during normal operation. During testing, if one or more pairwise relationships are violated, an anomaly is detected. The proposed framework is evaluated on two real-world datasets: a proprietary dataset collected from a physical plant where it is shown to be effective in extracting sensor pairwise relationships for knowledge discovery and anomaly detection, and a public hard disk drive dataset where its ability to effectively predict upcoming disk failures is illustrated.
SN 1530-0889
BN 978-1-7281-5809-9
PY 2020
BP 552
EP 563
DI 10.1109/DSN48063.2020.00067
UT WOS:000617924900047
ER

PT J
AU Bhatti, MH
   Khan, J
   Khan, MUG
   Iqbal, R
   Aloqaily, M
   Jararweh, Y
   Gupta, B
AF Bhatti, Muhammad Hamza
   Khan, Javeria
   Khan, Muhammad Usman Ghani
   Iqbal, Razi
   Aloqaily, Moayad
   Jararweh, Yaser
   Gupta, Brij
TI Soft Computing-Based EEG Classification by Optimal Feature Selection and
   Neural Networks
SO IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS
AB Brain computer interface translates electroencephalogram (EEG) signals into control commands so that paralyzed people can control assistive devices. This human thought translation is a very challenging process as EEG signals contain noise. For noise removal, a bandpass filter or a filter bank is used. However, these techniques also remove useful information from the signal. Furthermore, after feature extraction, there are such features which do not play any significant role in effective classification. Thus, soft computing-based EEG classification followed by extraction and then selection of optimal features can produce better results. In this paper, subband common spatial patterns using sequential backward floating selection is being proposed in order to classify motor-imagery-based EEG signals. The signal is decomposed into subband using a filter bank having overlapped frequency cutoffs. Linear discriminant analysis followed by common spatial pattern is applied to the output of each filter for features extraction. Then, sequential backward floating selection is applied for selection of optimal features to train radial basis function neural networks. Two different datasets have been used for evaluation of results, i.e., Open BCI dataset and EEG signals acquired by Emotiv Epoc. The proposed system shows an overall accuracy of 93.05% and 85.00% for both datasets, respectively. The results show that the proposed optimal feature selection and neural network-based classification approach with overlapped frequency bands is an effective method for EEG classification as compared to previous techniques.
RI Gupta, Brij B/E-9813-2011; Jararweh, Yaser/ABE-6543-2021; Aloqaily,
   Moayad/AAV-9016-2021; Bhatti, Muhammad Hamza/AAH-1001-2020; Aloqaily,
   Moayad/AAJ-2598-2020
OI Gupta, Brij B/0000-0003-4929-4698; Aloqaily, Moayad/0000-0003-2443-7234;
   khan, Javeria/0000-0002-0723-5385
SN 1551-3203
EI 1941-0050
PD OCT
PY 2019
VL 15
IS 10
BP 5747
EP 5754
DI 10.1109/TII.2019.2925624
UT WOS:000492292500036
ER

PT J
AU Zhang, H
   Liang, YC
   Han, SY
   Peng, C
   Li, Y
AF Zhang, Hui
   Liang, Yanchun
   Han, Siyu
   Peng, Cheng
   Li, Ying
TI Long Noncoding RNA and Protein Interactions: From Experimental Results
   to Computational Models Based on Network Methods
SO INTERNATIONAL JOURNAL OF MOLECULAR SCIENCES
AB Non-coding RNAs with a length of more than 200 nucleotides are long non-coding RNAs (lncRNAs), which have gained tremendous attention in recent decades. Many studies have confirmed that lncRNAs have important influence in post-transcriptional gene regulation; for example, lncRNAs affect the stability and translation of splicing factor proteins. The mutations and malfunctions of lncRNAs are closely related to human disorders. As lncRNAs interact with a variety of proteins, predicting the interaction between lncRNAs and proteins is a significant way to depth exploration functions and enrich annotations of lncRNAs. Experimental approaches for lncRNA-protein interactions are expensive and time-consuming. Computational approaches to predict lncRNA-protein interactions can be grouped into two broad categories. The first category is based on sequence, structural information and physicochemical property. The second category is based on network method through fusing heterogeneous data to construct lncRNA related heterogeneous network. The network-based methods can capture the implicit feature information in the topological structure of related biological heterogeneous networks containing lncRNAs, which is often ignored by sequence-based methods. In this paper, we summarize and discuss the materials, interaction score calculation algorithms, advantages and disadvantages of state-of-the-art algorithms of lncRNA-protein interaction prediction based on network methods to assist researchers in selecting a suitable method for acquiring more dependable results. All the related different network data are also collected and processed in convenience of users, and are available at https://github.com/HAN-Siyu/APINet/.
OI Li, Ying/0000-0002-7804-149X
EI 1422-0067
PD MAR 21
PY 2019
VL 20
IS 6
AR 1284
DI 10.3390/ijms20061284
UT WOS:000465523400011
PM 30875752
ER

PT C
AU Chien, JT
AF Chien, Jen-Tzung
GP Assoc Comp Machinery
TI Deep Bayesian Mining, Learning and Understanding
SO KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON
   KNOWLEDGE DISCOVERY AND DATA MINING
CT 25th ACM SIGKDD International Conference on Knowledge Discovery & Data
   Mining (KDD)
CY AUG 04-08, 2019
CL Anchorage, AK
SP Assoc Comp Machinery, Assoc Comp Machinery SIGKDD, Assoc Comp Machinery SIGMOD
AB This tutorial addresses the advances in deep Bayesian mining and learning for natural language with ubiquitous applications ranging from speech recognition to document summarization, text classification, text segmentation, information extraction, image caption generation, sentence generation, dialogue control, sentiment classification, recommendation system, question answering and machine translation, to name a few. Traditionally, "deep learning" is taken to be a learning process where the inference or optimization is based on the real-valued deterministic model. The "semantic structure" in words, sentences, entities, actions and documents drawn from a large vocabulary may not be well expressed or correctly optimized in mathematical logic or computer programs. The "distribution function" in discrete or continuous latent variable model for natural language may not be properly decomposed or estimated. This tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced Bayesian models and deep models including hierarchical Dirichlet process, Chinese restaurant process, hierarchical Pitman-Yor process, Indian buffet process, recurrent neural network (RNN), long short-term memory, sequence-to-sequence model, variational auto-encoder (VAE), generative adversarial network (GAN), attention mechanism, memory-augmented neural network, skip neural network, stochastic neural network, predictive state neural network, policy neural network. We present how these models are connected and why they work for a variety of applications on symbolic and complex patterns in natural language. The variational inference and sampling method are formulated to tackle the optimization for complicated models. The word and sentence embeddings, clustering and co-clustering are merged with linguistic and semantic constraints. A series of case studies are presented to tackle different issues in deep Bayesian mining, learning and understanding. At last, we will point out a number of directions and outlooks for future studies.
OI Chien, Jen-Tzung/0000-0003-3466-8941
BN 978-1-4503-6201-6
PY 2019
BP 3197
EP 3198
DI 10.1145/3292500.3332267
UT WOS:000485562503048
ER

PT C
AU Arakeri, MP
   Keerthana, NS
   Madhura, M
   Sankar, A
   Munnavar, T
AF Arakeri, Megha P.
   Keerthana, N. S.
   Madhura, M.
   Sankar, Anusha
   Munnavar, Tazeen
GP IEEE
TI Assistive Technology for the Visually Impaired Using Computer Vision
SO 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS
   AND INFORMATICS (ICACCI)
CT 7th International Conference on Computing, Communications and
   Informatics (ICACCI)
CY SEP 19-22, 2018
CL Bangalore, INDIA
SP PES Inst Technol, Bangalore South Campus, IEEE, IEEE Communicat Soc, IEEE Photon Soc, IEEE Robot & Automat Soc
AB India has more than a quarter of the world's 36 million blind people. Educating the blind to avoid unemployment among their population is one of the most challenging problems faced by blind schools today. Although many schools resort to the use of Braille to eradicate illiteracy among them, its steep learning curve, insufficient availability and high cost makes it quite unapproachable. Braille Literacy Statistics in India indicate that out of the 12 million blind people in the country, less than 10 percent learn Braille. It is evident that one of the most crucial issues faced by the blind and the visually impaired is the inability to read and learn without the use of Braille. In order to overcome this issue, there is a need to develop a system that can assist the visually impaired in reading. Hence, the proposed solution is to design an inexpensive wearable device that uses computer vision to read out any form of text around the user in various alignments and lighting conditions. The system makes use of a Raspberry Pi with a compatible camera to capture the content around the visually impaired or blind person and reads it out to them in a regional language. A sensor is also incorporated to notify the user of the distance to the nearest object at his eye level and the device enumerates various objects in its sight. The system is based on the combination of image processing, machine learning and speech synthesis techniques. The observed accuracy combining both the optical character recognition and the object recognition algorithms was found to be 84%.
OI Arakeri, Megha/0000-0003-0340-5794
BN 978-1-5386-5314-2
PY 2018
BP 1725
EP 1730
UT WOS:000455682100292
ER

PT J
AU Pustina, D
   Coslett, HB
   Ungar, L
   Faseyitan, OK
   Medaglia, JD
   Avants, B
   Schwartz, MF
AF Pustina, Dorian
   Coslett, Harry Branch
   Ungar, Lyle
   Faseyitan, Olufunsho K.
   Medaglia, John D.
   Avants, Brian
   Schwartz, Myrna F.
TI Enhanced Estimations of Post-Stroke Aphasia Severity Using Stacked
   Multimodal Predictions
SO HUMAN BRAIN MAPPING
AB The severity of post-stroke aphasia and the potential for recovery are highly variable and difficult to predict. Evidence suggests that optimal estimation of aphasia severity requires the integration of multiple neuroimaging modalities and the adoption of new methods that can detect multivariate brain-behavior relationships. We created and tested a multimodal framework that relies on three information sources (lesion maps, structural connectivity, and functional connectivity) to create an array of unimodal predictions which are then fed into a final model that creates stacked multimodal predictions (STAMP). Crossvalidated predictions of four aphasia scores (picture naming, sentence repetition, sentence comprehension, and overall aphasia severity) were obtained from 53 left hemispheric chronic stroke patients (age: 57.1 +/- 12.3 yrs, post-stroke interval: 20 months, 25 female). Results showed accurate predictions for all four aphasia scores (correlation true vs. predicted: r = 0.79-0.88). The accuracy was slightly smaller but yet significant (r = 0.66) in a full split crossvalidation with each patient considered as new. Critically, multimodal predictions produced more accurate results that any single modality alone. Topological maps of the brain regions involved in the prediction were recovered and compared with traditional voxel-based lesion-to-symptom maps, revealing high spatial congruency. These results suggest that neuroimaging modalities carry complementary information potentially useful for the prediction of aphasia scores. More broadly, this study shows that the translation of neuroimaging findings into clinically useful tools calls for a shift in perspective from unimodal to multimodal neuroimaging, from univariate to multivariate methods, from linear to nonlinear models, and, conceptually, from inferential to predictive brain mapping. (C) 2017 Wiley Periodicals, Inc.
OI Faseyitan, Olufunsho/0009-0001-7302-3014; avants,
   brian/0000-0002-4212-3362
SN 1065-9471
EI 1097-0193
PD NOV
PY 2017
VL 38
IS 11
BP 5603
EP 5615
DI 10.1002/hbm.23752
UT WOS:000412553900019
PM 28782862
ER

PT J
AU Amster, A
   Jentzsch, J
   Pasupuleti, H
   Subramanian, KG
AF Amster, Andy
   Jentzsch, Joseph
   Pasupuleti, Ham
   Subramanian, K. G.
TI Completeness, accuracy, and computability of National Quality
   Forum-specified eMeasures
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
AB Objective To analyze the completeness, computability, and accuracy of specifications for five National Quality Forum-specified (NQF) eMeasures spanning ambulatory, post-discharge, and emergency care within a comprehensive, integrated electronic health record (EHR) environment.
   Materials and methods To evaluate completeness, we assessed eMeasure logic, data elements, and value sets. To evaluate computability, we assessed the translation of eMeasure algorithms to programmable logic constructs and the availability of EHR data elements to implement specified data criteria, using a de-identified clinical data set from Kaiser Permanente Northwest. To assess accuracy, we compared eMeasure results with those obtained independently by existing audited chart abstraction methods used for external and internal reporting.
   Results One measure specification was incomplete; missing applicable LOINC codes rendered it non-computable. For three of four computable measures, data availability issues occurred; the literal specification guidance for a data element differed from the physical implementation of the data element in the EHR. In two cases, cross-referencing specified data elements to EHR equivalents allowed variably accurate measure computation. Substantial data availability issues occurred for one of the four computable measures, producing highly inaccurate results.
   Discussion Existing clinical workflows, documentation, and coding in the EHR were significant barriers to implementing eMeasures as specified. Implementation requires redesigning business or clinical practices and, for one measure, systemic EHR modifications, including clinical text search capabilities.
   Conclusions Five NQF eMeasures fell short of being machine-consumable specifications. Both clinical domain and technological expertise are required to implement manually intensive steps from data mapping to text mining to EHR-specific eMeasure implementation.
SN 1067-5027
EI 1527-974X
PD MAR
PY 2015
VL 22
IS 2
BP 409
EP 416
DI 10.1136/amiajnl-2014-002865
UT WOS:000352771500018
PM 25326598
ER

PT J
AU Wong, MD
   Dazai, J
   Walls, JR
   Gale, NW
   Henkelman, RM
AF Wong, Michael D.
   Dazai, Jun
   Walls, Johnathon R.
   Gale, Nicholas W.
   Henkelman, R. Mark
TI Design and Implementation of a Custom Built Optical Projection
   Tomography System
SO PLOS ONE
AB Optical projection tomography (OPT) is an imaging modality that has, in the last decade, answered numerous biological questions owing to its ability to view gene expression in 3 dimensions (3D) at high resolution for samples up to several cm(3). This has increased demand for a cabinet OPT system, especially for mouse embryo phenotyping, for which OPT was primarily designed for. The Medical Research Council (MRC) Technology group (UK) released a commercial OPT system, constructed by Skyscan, called the Bioptonics OPT 3001 scanner that was installed in a limited number of locations. The Bioptonics system has been discontinued and currently there is no commercial OPT system available. Therefore, a few research institutions have built their own OPT system, choosing parts and a design specific to their biological applications. Some of these custom built OPT systems are preferred over the commercial Bioptonics system, as they provide improved performance based on stable translation and rotation stages and up to date CCD cameras coupled with objective lenses of high numerical aperture, increasing the resolution of the images. Here, we present a detailed description of a custom built OPT system that is robust and easy to build and install. Included is a hardware parts list, instructions for assembly, a description of the acquisition software and a free download site, and methods for calibration. The described OPT system can acquire a full 3D data set in 10 minutes at 6.7 micron isotropic resolution. The presented guide will hopefully increase adoption of OPT throughout the research community, for the OPT system described can be implemented by personnel with minimal expertise in optics or engineering who have access to a machine shop.
RI HENKELMAN, MARK/W-6847-2019
SN 1932-6203
PD SEP 4
PY 2013
VL 8
IS 9
AR e73491
DI 10.1371/journal.pone.0073491
UT WOS:000324515600106
PM 24023880
ER

PT J
AU Wu, LW
   Liao, HC
   Hu, JS
   Lo, PC
AF Wu, Li-Wei
   Liao, Hsien-Cheng
   Hu, Jwu-Sheng
   Lo, Pei-Chen
TI Brain-controlled robot agent: an EEG-based e Robot agent
SO INDUSTRIAL ROBOT-THE INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH AND
   APPLICATION
AB Purpose - This paper aims to present a novel embedded-internet robot system based on an internet robot agent and the brain-computer interface (BCI) scheme.
   Design/methodology/approach - A highly flexible and well-integrated embedded ethernet robot (e Robot) was designed with enhanced mobility. In the e Robot, a circuit core module called a tiny network bridge (TNB) is designed to reduce robotic system cost and increase its mobility and developmental flexibility. The TNB enables users to control e Robot motion via embedded ethernet technology. Through electroencephalogram (EEG) feedback training, the command translation unit (CTU) and alertness level detection unit (ADU) allow the e Robot to perform specific motions (for example, lying down or standing up) to reflect alertness levels of the user, and move forward, turn left or right following the user's command.
   Findings - After a short training period, subjects could achieve at least 70 percent accuracy in the CTU game testing. And the error rate of ADU, estimated from the results of classifying 496 labeled EEG epochs, was approximately 10.7 percent. Combining an encoding procedure, the commands issued from the CTU could prevent the robot from performing undesired actions.
   Originality/value - The e Robot could reflect some physiological human states and be controlled by users with our economical design and only two bipolar EEG channels adopted. Thus, users could make the EEG-based e Robot agent his or her representative. Based on the proposed EEG-based e Robot system, a robot with increased sophistication will be developed in the future for use by disabled patients.
SN 0143-991X
EI 1758-5791
PY 2008
VL 35
IS 6
BP 507
EP 519
DI 10.1108/01439910810909501
UT WOS:000262013000006
ER

PT J
AU Zhang, XY
   Cerna, AEU
   Stough, JV
   Chen, YD
   Carry, BJ
   Alsaid, A
   Raghunath, S
   VanMaanen, DP
   Fornwalt, BK
   Haggerty, CM
AF Zhang, Xiaoyan
   Cerna, Alvaro E. Ulloa
   Stough, Joshua, V
   Chen, Yida
   Carry, Brendan J.
   Alsaid, Amro
   Raghunath, Sushravya
   VanMaanen, David P.
   Fornwalt, Brandon K.
   Haggerty, Christopher M.
TI Generalizability and quality control of deep learning-based 2D
   echocardiography segmentation models in a large clinical dataset
SO INTERNATIONAL JOURNAL OF CARDIOVASCULAR IMAGING
AB Use of machine learning (ML) for automated annotation of heart structures from echocardiographic videos is an active research area, but understanding of comparative, generalizable performance among models is lacking. This study aimed to (1) assess the generalizability of five state-of-the-art ML-based echocardiography segmentation models within a large Geisinger clinical dataset, and (2) test the hypothesis that a quality control (QC) method based on segmentation uncertainty can further improve segmentation results. Five models were applied to 47,431 echocardiography studies that were independent from any training samples. Chamber volume and mass from model segmentations were compared to clinically-reported values. The median absolute errors (MAE) in left ventricular (LV) volumes and ejection fraction exhibited by all five models were comparable to reported inter-observer errors (IOE). MAE for left atrial volume and LV mass were similarly favorable to respective IOE for models trained for those tasks. A single model consistently exhibited the lowest MAE in all five clinically-reported measures. We leveraged the tenfold cross-validation training scheme of this best-performing model to quantify segmentation uncertainty. We observed that removing segmentations with high uncertainty from 14 to 71% studies reduced volume/mass MAE by 6-10%. The addition of convexity filters improved specificity, efficiently removing < 10% studies with large MAE (16-40%). In conclusion, five previously published echocardiography segmentation models generalized to a large, independent clinical dataset-segmenting one or multiple cardiac structures with overall accuracy comparable to manual analyses-with variable performance. Convexity-reinforced uncertainty QC efficiently improved segmentation performance and may further facilitate the translation of such models.
OI Haggerty, Christopher/0000-0002-3227-4490; Chen,
   Yida/0000-0002-4018-6095
SN 1569-5794
EI 1573-0743
PD AUG
PY 2022
VL 38
IS 8
BP 1685
EP 1697
DI 10.1007/s10554-022-02554-7
EA FEB 2022
UT WOS:000761267300003
PM 35201510
ER

PT J
AU Comminal, R
   Spangenberg, J
AF Comminal, Raphael
   Spangenberg, Jon
TI Three-dimensional cellwise conservative unsplit geometric VOF schemes
SO JOURNAL OF COMPUTATIONAL PHYSICS
AB This work presents two unsplit geometric VOF schemes that extend the two-dimensional cellwise conservative unsplit (CCU) scheme (Comminal et al. (2015) [49]) to three dimensions. The novelty of the 3D-CCU schemes lies in the representation of the streaksurfaces of donating regions by polyhedral surfaces whose vertices are calculated with the 4th order Runge-Kutta scheme. Moreover, the advected liquid volumes are computed using a truncation algorithm (Lopez et al. (2019) [62]) suited for arbitrary non-convex and self-intersecting polyhedra, which removes the need for tetrahedral decomposition. The 3D-CCU advection schemes were coupled to three interface reconstruction methods (Youngs' method, the Mixed Youngs-Centered scheme, and the Least-Square Fit algorithm). The resulting VOF methods were tested in classical benchmark advection tests, including translation, rigid-body rotation, shear and deformation flows. The proposed 3D-CCU schemes conserve the liquid volume and maintain the physical boundedness of liquid volume fractions to the machine precision. The 3D-CCU schemes perform favorably compared to other unsplit geometric VOF schemes when coupled to Youngs' interface reconstruction method. Moreover, the 3D-CCU schemes coupled to the Least-Square Fit algorithm are more accurate than most other VOF schemes that use a second-order accurate interface reconstruction, except those where a 3D extension of the Mosso-Swartz interface reconstruction is employed. The comparison of the different VOF schemes highlights the importance of coupling accurate interface reconstruction methods with accurate unsplit advection schemes. (C) 2021 The Author(s). Published by Elsevier Inc.
RI Comminal, Raphaël/D-1621-2018
OI Comminal, Raphaël/0000-0003-3764-5550; Spangenberg,
   Jon/0000-0002-5411-6821
SN 0021-9991
EI 1090-2716
PD OCT 1
PY 2021
VL 442
AR 110479
DI 10.1016/j.jcp.2021.110479
EA JUN 2021
UT WOS:000671273100005
ER

PT J
AU St Louis, EK
   Videnovic, A
AF St Louis, Erik K.
   Videnovic, Aleksandar
TI Sleep Neurology's Toolkit at the Crossroads: Challenges and
   Opportunities in Neurotherapeutics Lost and Found in Translation
SO NEUROTHERAPEUTICS
AB We find ourselves at our present crossroads with a well-traveled toolkit, perhaps too well worn but with aspirational hopes and dreams for the field of sleep neurotherapeutics. This volume is organized thematically into six topical domains that parallel the major subspecialty areas of contemporary clinical sleep neurology practice, as well as novel directions and opportunities. The issue begins with an overview of the central disorders of hypersomnolence, including narcolepsy, idiopathic hypersomnia and other hypersomnia disorders, and the related use of the entire broad range of stimulant and wake-promoting pharmacotherapies. Next, the range of behavioral therapies, application of light and light restriction and melatonin therapies, and hypnotic pharmacotherapies useful in insomnia and circadian sleep-wake rhythm disorders are reviewed, followed by an overview of treatment options for sleep-related breathing disorders including positive airway pressure and the novel approach of hypoglossal neurostimulation for obstructive sleep apnea. The parasomnias and sleep-related movement disorders, including NREM disorders of arousal, REM parasomnias (nightmares and isolated sleep paralysis and idiopathic/isolated REM sleep behavior disorder, and restless legs syndrome are then discussed, and the applications of sleep neurotherapeutics in sleep and neurological disease are reviewed, including neurodevelopmental, epileptic, autoimmune encephalopathies, and neurodegenerative diseases. Last, the novel directions and opportunities in sleep neurology offered by cannabinoid therapies and machine learning/artificial intelligence methodology conclude this comprehensive survey of contemporary sleep neurology. We hope that you find this volume to be a useful and inspirational support tool for the work that matters most, your care of all our sleep neurology patients in the clinics.
RI Videnovic, Aleksandar/HKV-3524-2023
OI St. Louis, Erik/0000-0002-2833-8826
SN 1933-7213
EI 1878-7479
PD JAN
PY 2021
VL 18
IS 1
BP 1
EP 5
DI 10.1007/s13311-021-01032-7
EA APR 2021
UT WOS:000636964200001
PM 33821447
ER

PT J
AU Bi, XL
   Yuan, Y
   Xiao, B
   Li, WS
   Gao, XB
AF Bi, Xiuli
   Yuan, Yuan
   Xiao, Bin
   Li, Weisheng
   Gao, Xinbo
TI 2D-LCoLBP: A Learning Two-Dimensional Co-Occurrence Local Binary Pattern
   for Image Recognition
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
AB The rotation, scale and translation invariance of extracted features have a high significance in image recognition. Local binary pattern (LBP) and LBP-based descriptors have been widely used in image recognition due to feature discrimination and computational efficiency. However, most of the existing LBP-based descriptors have been designed to achieve rotation invariance while fail to achieve scale invariance. Moreover, it is usually difficult to achieve a good trade-off between the feature discrimination and the feature dimension. In this work, a learning 2D co-occurrence LBP termed 2D-LCoLBP is proposed to address these issues. Firstly, a weighted joint histogram is constructed in different neighborhoods and scales of an image to represent the multi-neighborhood and multi-scale LBP (2D-MLBP) and achieve the rotation invariance. A feature learning strategy is then designed to learn the compact and robust descriptor (2D-LCoLBP) from LBP pattern pairs across different scales in the extracted 2D-MLBP to characterize the most stable local structures and achieve the scale invariance, as well as decrease the feature dimension and improve the noise robustness. Finally, a linear SVM classifier is employed for recognition. We applied the proposed 2D-LCoLBP on four image recognition tasks-texture, object, face and food recognition with ten image databases. Experimental results show that 2D-LCoLBP has obviously low feature dimension but outperforms the state-of-the-art LBP-based descriptors in terms of recognition accuracy under noise-free, Gaussian noise and JPEG compression conditions.
OI Bi, Xiuli/0000-0003-3134-217X
SN 1057-7149
EI 1941-0042
PY 2021
VL 30
BP 7228
EP 7240
DI 10.1109/TIP.2021.3104163
UT WOS:000686764400001
PM 34403337
ER

PT J
AU Vaezi, M
   Pishkenari, HN
   Nemati, A
AF Vaezi, Mehran
   Nejat Pishkenari, Hossein
   Nemati, Alireza
TI Mechanism of C-60 rotation and translation on hexagonal boron-nitride
   monolayer
SO JOURNAL OF CHEMICAL PHYSICS
AB Newly synthesized nanocars have shown great potential to transport molecular payloads. Since wheels of nanocars dominate their motion, the study of the wheels helps us to design a suitable surface for them. We investigated C-60 thermal diffusion on the hexagonal boron-nitride (h-BN) monolayer as the wheel of nanocars. We calculated C-60 potential energy variation during the translational and rotational motions at different points on the substrate. The study of the energy barriers and diffusion coefficients of the molecule at different temperatures indicated three noticeable changes in the C-60 motion regime. C-60 starts to slide on the surface at 30 K-40 K, slides freely on the boron-nitride monolayer at 100 K-150 K, and shows rolling motions at temperatures higher than 500 K. The anomaly parameter of the motion reveals that C-60 has a diffusive motion on the boron-nitride substrate at low temperatures and experiences superdiffusion with Levy flight motions at higher temperatures. A comparison of the fullerene motion on the boron-nitride and graphene surfaces demonstrated that the analogous structure of the graphene and hexagonal boron-nitride led to similar characteristics such as anomaly parameters and the temperatures at which the motion regime changes. The results of this study empower us to predict that fullerene prefers to move on boron-nitride sections on a hybrid substrate composed of graphene and boron-nitride. This property can be utilized to design pathways or regions on a surface to steer or trap the C-60 or other molecular machines, which is a step toward directional transportation at the molecular scale.
OI Nejat Pishkenari, Hossein/0000-0002-3487-3198; Vaezi,
   Mehran/0000-0002-7422-3026; Nemati, Alireza/0000-0001-8743-8854
SN 0021-9606
EI 1089-7690
PD DEC 21
PY 2020
VL 153
IS 23
AR 234702
DI 10.1063/5.0029490
UT WOS:000599773200002
PM 33353326
ER

PT S
AU Geng, XJ
   Kang, X
   Wong, PCM
AF Geng, Xiujuan
   Kang, Xin
   Wong, Patrick C. M.
BE Ilieva, M
   Lau, WKW
TI Autism spectrum disorder risk prediction: A systematic review of
   behavioral and neural investigations
SO AUTISM
SE Progress in Molecular Biology and Translational Science
AB A reliable diagnosis of autism spectrum disorder (ASD) is difficult to make until after toddlerhood. Detection in an earlier age enables early intervention, which is typically more effective. Recent studies of the development of brain and behavior in infants and toddlers have provided important insights in the diagnosis of autism. This extensive review focuses on published studies of predicting the diagnosis of autism during infancy and toddlerhood younger than 3 years using behavioral and neuroimaging approaches. After screening a total of 782 papers, 17 neuroimaging and 43 behavioral studies were reviewed. The features for prediction consist of behavioral measures using screening tools, observational and experimental methods, brain volumetric measures, and neural functional activation and connectivity patterns. The classification approaches include logistic regression, linear discriminant function, decision trees, support vector machine, and deep learning based methods. Prediction performance has large variance across different studies. For behavioral studies, the sensitivity varies from 20% to 100%, and specificity ranges from 48% to 100%. The accuracy rates range from 61% to 94% in neuroimaging studies. Possible factors contributing to this inconsistency may be partially due to the heterogeneity of ASD, different targeted populations (i.e., high-risk group for ASD and general population), age when the features were collected, and validation procedures. The translation to clinical practice requires extensive further research including external validation with large sample size and optimized feature selection. The use of multi-modal features, e.g., combination of neuroimaging and behavior, is worth further investigation to improve the prediction accuracy.
RI Kang, Xin/GPW-6190-2022; Kang, Xin/AAV-7919-2020
OI Kang, Xin/0000-0002-1126-5771; Geng, Xiujuan/0000-0003-4953-0208
SN 1877-1173
BN 978-0-12-821242-4
PY 2020
VL 173
BP 91
EP 137
DI 10.1016/bs.pmbts.2020.04.015
UT WOS:000613905600005
PM 32711819
ER

PT J
AU Masmoudi, A
   Mdhaffar, S
   Sellami, R
   Belguith, LH
AF Masmoudi, Abir
   Mdhaffar, Salima
   Sellami, Rahma
   Belguith, Lamia Hadrich
TI Automatic Diacritics Restoration for Tunisian Dialect
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB Modern Standard Arabic, as well as Arabic dialect languages, are usually written without diacritics. The absence of these marks constitute a real problem in the automatic processing of these data by NLP tools. Indeed, writing Arabic without diacritics introduces several types of ambiguity. First, a word without diacratics could have many possible meanings depending on their diacritization. Second, undiacritized surface forms of an Arabic word might have as many as 200 readings depending on the complexity of its morphology [12]. In fact, the agglutination property of Arabic might produce a problem that can only be resolved using diacritics. Third, without diacritics a word could have many possible parts of speech (POS) instead of one. This is the case with the words that have the same spelling and POS tag but a different lexical sense, or words that have the same spelling but different POS tags and lexical senses [8]. Finally, there is ambiguity at the grammatical level (syntactic ambiguity). In this article, we propose the first work that investigates the automatic diacritization of Tunisian Dialect texts. We first describe our annotation guidelines and procedure. Then, we propose two major models, namely a statistical machine translation (SMT) and a discriminative model as a sequence classification task based on Conditional Random Fields (CRF). In the second approach, we integrate POS features to influence the generation of diacritics. Diacritics restoration was performed at both the word and the character levels. The results showed high scores of automatic diacritization based on the CRF system (Word Error Rate (WER) 21.44% for CRF and WER 34.6% for SMT).
RI Belguith, Lamia Hadrich/GWU-9641-2022
OI Belguith, Lamia Hadrich/0000-0002-4868-657X; mdhaffar,
   salima/0000-0002-8472-6890
SN 2375-4699
EI 2375-4702
PD JUL
PY 2019
VL 18
IS 3
AR 28
DI 10.1145/3297278
UT WOS:000496767600009
ER

PT C
AU Kocich, D
AF Kocich, David
BE Ivan, I
   Horak, J
   Inspektor, T
TI Multilingual Sentiment Mapping Using Twitter, Open Source Tools, and
   Dictionary Based Machine Translation Approach
SO DYNAMICS IN GISCIENCE
SE Lecture Notes in Geoinformation and Cartography
CT GIS Ostrava Conference
CY 2017
CL Ostrava, CZECH REPUBLIC
SP EuroSDR, EuroGEO
AB Online social networks are a popular communication tool for internet users. Millions of users share opinions on different aspects of everyday life. Therefore, microblogging websites are rich sources of data for opinion mining and sentiment analysis. Our current research based on the analysis of migration using various social networks required to implement a tool for automated multilingual analysis of sentiment from as many languages as possible. Usually, all available tools handle to work only with English written texts which are the most common on the social media. Few open source tools which can process French, German and Spanish texts exist too, but it is not optimal to reimplement and join different approaches together. Another requirement is the ability to process dynamic data streams and static historical datasets with high efficiency. Lesser accuracy and completeness of evaluated messages is acceptable as a counterweight for these general requirements. The paper presents sample data collection from Twitter for the opinion mining purposes. We perform multilingual sentiment analysis of the collected data and briefly explain experimental results. The analysis is made with the use of custom built solution utilising the AFINN-165 which is manually evaluated dictionary of English words. This dictionary was translated into other languages using Google Translate API that was tested during the process. It is then possible to determine positive, negative and neutral sentiment. Results of the research bring new insights, offer a possibility for wider use and allow optimisation of the wordlists/tool resulting in the better results of future research. Geospatial analysis of first experimental results undercovers interesting relation between time, location and a sentiment which enables readers to think of various use cases.
SN 1863-2246
EI 1863-2351
BN 978-3-319-61297-3; 978-3-319-61296-6
PY 2018
BP 223
EP 238
DI 10.1007/978-3-319-61297-3_16
UT WOS:000457178200016
ER

PT J
AU Roth, HR
   Lu, L
   Liu, JM
   Yao, JH
   Seff, A
   Cherry, K
   Kim, L
   Summers, RM
AF Roth, Holger R.
   Lu, Le
   Liu, Jiamin
   Yao, Jianhua
   Seff, Ari
   Cherry, Kevin
   Kim, Lauren
   Summers, Ronald M.
TI Improving Computer-Aided Detection Using Convolutional Neural Networks
   and Random View Aggregation
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
AB Automated computer-aided detection (CADe) has been an important tool in clinical practice and research. State-of-the-art methods often show high sensitivities at the cost of high false-positives (FP) per patient rates. We design a two-tiered coarse-to-fine cascade framework that first operates a candidate generation system at sensitivities similar to 100% of but at high FP levels. By leveraging existing CADe systems, coordinates of regions or volumes of interest (ROI or VOI) are generated and function as input for a second tier, which is our focus in this study. In this second stage, we generate 2D (two-dimensional) or 2.5D views via sampling through scale transformations, random translations and rotations. These random views are used to train deep convolutional neural network (ConvNet) classifiers. In testing, the ConvNets assign class (e.g., lesion, pathology) probabilities for a new set of random views that are then averaged to compute a final per-candidate classification probability. This second tier behaves as a highly selective process to reject difficult false positives while preserving high sensitivities. The methods are evaluated on three data sets: 59 patients for sclerotic metastasis detection, 176 patients for lymph node detection, and 1,186 patients for colonic polyp detection. Experimental results show the ability of ConvNets to generalize well to different medical imaging CADe applications and scale elegantly to various data sets. Our proposed methods improve performance markedly in all cases. Sensitivities improved from 57% to 70%, 43% to 77%, and 58% to 75% at 3 FPs per patient for sclerotic metastases, lymph nodes and colonic polyps, respectively.
RI Lu, Le/AAD-7619-2020; Summers, Ronald/AAX-6290-2021; Yao,
   Jianhua/GQZ-6627-2022
OI Lu, Le/0000-0002-6799-9416; Yao, Jianhua/0000-0001-9157-9596; Roth,
   Holger/0000-0002-3662-8743
SN 0278-0062
EI 1558-254X
PD MAY
PY 2016
VL 35
IS 5
SI SI
BP 1170
EP 1181
DI 10.1109/TMI.2015.2482920
UT WOS:000375550500003
PM 26441412
ER

PT J
AU Allahyar, A
   Yazdi, HS
   Harati, A
AF Allahyar, Amin
   Yazdi, Hadi Sadoghi
   Harati, Ahad
TI Constrained Semi-Supervised Growing Self-Organizing Map
SO NEUROCOMPUTING
AB Semi-supervised clustering tries to surpass the limits of unsupervised clustering using extra information contained in occasional labeled data points. However, providing such labeled samples is not always possible or easy in real world applications. A weaker, yet still very useful option is providing constraints on the unlabeled training samples, which is the focus of the Constrained Semi-Supervised (CSS) clustering. On the other hand, online learning has gained considerable amount of interests in real world problems with massive sample size or streaming behavior, as lack of memory and computational resources seriously restrict the application of the offline and batch methods. However, the existing algorithms for online CSS clustering problem either assumed that the entire dataset is available and added constraints incrementally or considered chunks of constrained data points and applied an offline CSS clustering algorithm. Thus, none of them can be categorized as a genuine online CSS clustering algorithm.
   In this paper, we propose CS2GS, an online CSS clustering algorithm. CS2GS is constructed by modifying the online learning process of Semi-Supervised Growing Self-Organizing Map, and converting it to an iterative constrained metric learning problem that can be solved using the Bregman's iterative projections. The proposed CS2GS is studied via a series of thorough tests using synthetic and real data including selections from UCI datasets and FEP - a recent bilingual corpus used for sentence aligning stage of machine translation. Experimental results show the effectiveness of CS2GS in online CSS clustering, and prove that indeed, the limits of the system accuracy may be pushed higher using unlabeled samples. (C) 2014 Elsevier B.V. All rights reserved.
RI Harati, Ahad/B-8915-2015; Harati, Ahad/P-4468-2015; sadoghiyazdi,
   hadi/T-9515-2019
OI Harati, Ahad/0000-0001-7263-0309; Harati, Ahad/0000-0001-7263-0309;
   Allahyar, Amin/0000-0003-2567-0273
SN 0925-2312
EI 1872-8286
PD JAN 5
PY 2015
VL 147
BP 456
EP 471
DI 10.1016/j.neucom.2014.06.039
UT WOS:000343337600045
ER

PT J
AU Bedi, H
   Marzo, J
AF Bedi, Harvinder
   Marzo, John
TI The Biomechanics of Medial Patellofemoral Ligament Repair Followed by
   Lateral Retinacular Release
SO AMERICAN JOURNAL OF SPORTS MEDICINE
CT 35th Annual Meeting of the
   American-Orthopaedic-Society-for-Sports-Medicine (AOSSM)
CY JUL 09-12, 2009
CL Keystone, CO
SP Amer Orthopaed Soc Sports Med (AOSSM)
AB Background: Repair of the medial patellofemoral ligament (MPFL) for acute patellar instability has recently become popular, with good clinical success rates reported in the literature. Usually, a lateral retinacular release (LRR) is added to the medial repair in an effort to "rebalance" the patella. In the native knee, however, isolated LRR reduces the force required to displace the patella laterally and may be an undesirable component of instability surgery.
   Hypothesis: The authors' hypothesis was that LRR, when performed after MPFL repair, would reduce the force required to displace the patella laterally.
   Study Design: Controlled laboratory study.
   Methods: Eight fresh-frozen human cadaveric knees were prepared as a model for acute patellar dislocation by transecting the MPFL at its patellar attachment. The knees were sequentially tested in the native (control), cut MPFL, repaired MPFL, and repaired MPFL with LRR conditions. Each knee was mounted and tested on an MTS machine that measured the amount of force required to displace the patella 1 cm laterally. Testing was done at 0 degrees, 15 degrees, 30 degrees, 45 degrees, and 60 degrees of knee flexion.
   Results: Cutting the MPFL reduced the force required to displace the patella 1 cm laterally by 14% to 22% compared with the native knee. Repair of the ligament restored the ability of the patella to resist lateral force. Adding a lateral release to the repair reduced the force required to displace the patella 1 cm by 7% to 11% compared with the MPFL-repaired knee.
   Conclusion: After repair of the MPFL, adding an LRR lowered the ability of the patella to resist lateral displacement.
SN 0363-5465
EI 1552-3365
PD JUL
PY 2010
VL 38
IS 7
BP 1462
EP 1467
DI 10.1177/0363546510373581
UT WOS:000279304200021
PM 20601605
ER

PT J
AU SAKO, H
   AVIITZHAK, HI
AF SAKO, H
   AVIITZHAK, HI
TI A NEUROCOMPUTATIONAL APPROACH TO THE CORRESPONDENCE PROBLEM IN COMPUTER
   VISION
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
AB A problem which often arises in computer vision is that of matching corresponding points of images. In the case of object recognition, for example, the computer compares new images to templates from a library of known objects. A common way to perform this comparison is to extract feature points from the images and compare these points with the template points. Another common example is the case of motion detection, where feature points of a video image are compared to those of the previous frame. Note that in both of these examples, the point correspondence is complicated by the fact that the point sets are not only randomly ordered but have also been distorted by an unknown transformation and having quite different coordinates. In the case of object recognition, there exists a transformation from the object being viewed, to its projection onto the camera's imaging plane, while in the motion detection case, this transformation represents the motion (translation and rotation) of the object. If the parameters of the transformation are completely unknown, then all n! permutations must be compared (n: number of feature points). For each permutation, the ensuing transformation is computed using the least-squared projection method. The exponentially large computation required for this is prohibitive. A neural computational method is proposed to solve these combinatorial problems. This method obtains the best correspondence matching and also finds the associated transform parameters. The method was applied to two dimensional point correspondence and three-to-two dimensional correspondence. Finally, this connectionist approach extends readily to a Boltzmann machine implementation. This implementation is desirable when the transformation is unknown, as it is less sensitive to local minima regardless of initial conditions.
SN 0916-8532
PD APR
PY 1994
VL E77D
IS 4
BP 507
EP 515
UT WOS:A1994NH67100019
ER

PT J
AU Ta, HT
   Rahman, AS
   Majumder, N
   Hussain, A
   Najjar, L
   Howard, N
   Poria, S
   Gelbukh, A
AF Ta, Hoang Thang
   Rahman, Abu Bakar Siddiqur
   Majumder, Navonil
   Hussain, Amir
   Najjar, Lotfollah
   Howard, Newton
   Poria, Soujanya
   Gelbukh, Alexander
TI WikiDes: A Wikipedia-based dataset for generating short descriptions
   from paragraphs
SO INFORMATION FUSION
AB As free online encyclopedias with massive volumes of content, Wikipedia and Wikidata are key to many Natural Language Processing (NLP) tasks, such as information retrieval, knowledge base building, machine translation, text classification, and text summarization. In this paper, we introduce WikiDes, a novel dataset to generate short descriptions of Wikipedia articles for the problem of text summarization. The dataset consists of over 80k English samples on 6987 topics. We set up a two-phase summarization method - description generation (Phase I) and candidate ranking (Phase II) - as a strong approach that relies on transfer and contrastive learning. For description generation, T5 and BART show their superiority compared to other small-scale pre-trained models. By applying contrastive learning with the diverse input from beam search, the metric fusion-based ranking models outperform the direct description generation models significantly up to approximate to 22 ROUGE in topic-exclusive split and topic-independent split. Furthermore, the outcome descriptions in Phase II are supported by human evaluation in over 45.33% chosen compared to 23.66% in Phase I against the gold descriptions. In the aspect of sentiment analysis, the generated descriptions cannot effectively capture all sentiment polarities from paragraphs while doing this task better from the gold descriptions. The automatic generation of new descriptions reduces the human efforts in creating them and enriches Wikidata-based knowledge graphs. Our paper shows a practical impact on Wikipedia and Wikidata since there are thousands of missing descriptions. Finally, we expect WikiDes to be a useful dataset for related works in capturing salient information from short paragraphs. The curated dataset is publicly available at: https://github.com/declare-lab/WikiDes.
RI Ta, Thang/AAW-7174-2021; Poria, Soujanya/L-8361-2015
OI Ta, Thang/0000-0003-0321-5106; Poria, Soujanya/0000-0003-3167-2208
SN 1566-2535
EI 1872-6305
PD FEB
PY 2023
VL 90
BP 265
EP 282
DI 10.1016/j.inffus.2022.09.022
UT WOS:000888090300005
ER

PT J
AU Bronkhorst, AJ
   Ungerer, V
   Oberhofer, A
   Gabriel, S
   Polatoglou, E
   Randeu, H
   Uhlig, C
   Pfister, H
   Mayer, Z
   Holdenrieder, S
AF Bronkhorst, Abel J.
   Ungerer, Vida
   Oberhofer, Angela
   Gabriel, Sophie
   Polatoglou, Eleni
   Randeu, Hannah
   Uhlig, Carsten
   Pfister, Heiko
   Mayer, Zsuzsanna
   Holdenrieder, Stefan
TI New Perspectives on the Importance of Cell-Free DNA Biology
SO DIAGNOSTICS
AB Body fluids are constantly replenished with a population of genetically diverse cell-free DNA (cfDNA) fragments, representing a vast reservoir of information reflecting real-time changes in the host and metagenome. As many body fluids can be collected non-invasively in a one-off and serial fashion, this reservoir can be tapped to develop assays for the diagnosis, prognosis, and monitoring of wide-ranging pathologies, such as solid tumors, fetal genetic abnormalities, rejected organ transplants, infections, and potentially many others. The translation of cfDNA research into useful clinical tests is gaining momentum, with recent progress being driven by rapidly evolving preanalytical and analytical procedures, integrated bioinformatics, and machine learning algorithms. Yet, despite these spectacular advances, cfDNA remains a very challenging analyte due to its immense heterogeneity and fluctuation in vivo. It is increasingly recognized that high-fidelity reconstruction of the information stored in cfDNA, and in turn the development of tests that are fit for clinical roll-out, requires a much deeper understanding of both the physico-chemical features of cfDNA and the biological, physiological, lifestyle, and environmental factors that modulate it. This is a daunting task, but with significant upsides. In this review we showed how expanded knowledge on cfDNA biology and faithful reverse-engineering of cfDNA samples promises to (i) augment the sensitivity and specificity of existing cfDNA assays; (ii) expand the repertoire of disease-specific cfDNA markers, thereby leading to the development of increasingly powerful assays; (iii) reshape personal molecular medicine; and (iv) have an unprecedented impact on genetics research.
EI 2075-4418
PD SEP
PY 2022
VL 12
IS 9
AR 2147
DI 10.3390/diagnostics12092147
UT WOS:000858673700001
PM 36140548
ER

PT J
AU Xue, N
AF Xue, Nan
TI Analysis Model of Spoken English Evaluation Algorithm Based on
   Intelligent Algorithm of Internet of Things
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
AB With the in-depth promotion of the national strategy for the integration of artificial intelligence technology and entity development, speech recognition processing technology, as an important medium of human-computer interaction, has received extensive attention and motivated research in industry and academia. However, the existing accurate speech recognition products are based on massive data platform, which has the problems of slow response and security risk, which makes it difficult for the existing speech recognition products to meet the application requirements for timely translation of speech with high response time and network security requirements under the condition of network instability and insecurity. Based on this, this paper studies the analysis model of oral English evaluation algorithm based on Internet of things intelligent algorithm in speech recognition technology. Firstly, based on the automatic machine learning and lightweight learning strategy, a lightweight technology of automatic speech recognition depth neural network adapted to the edge computing power is proposed. Secondly, the quantitative evaluation of Internet of things intelligent classification algorithm and big data analysis in this system is described. In the evaluation, the evaluation method of oral English characteristics is adopted. At the same time, the Internet of things intelligent classification algorithm and big data analysis strategy are used to evaluate the accuracy of oral English. Finally, the experimental results show that the oral English feature recognition system based on Internet of things intelligent classification algorithm and big data analysis has the advantages of good reliability, high intelligence, and strong ability to resist subjective factors, which proves the advantages of Internet of things intelligent classification algorithm and big data analysis in English feature recognition.
SN 1687-5265
EI 1687-5273
PD MAR 27
PY 2022
VL 2022
AR 8469945
DI 10.1155/2022/8469945
UT WOS:000793542600001
PM 35387241
ER

PT J
AU Okita, T
   Terayama, S
   Tsugawa, K
   Kobayashi, K
   Okumura, M
   Itakura, M
   Suzuki, K
AF Okita, T.
   Terayama, S.
   Tsugawa, K.
   Kobayashi, K.
   Okumura, M.
   Itakura, M.
   Suzuki, K.
TI Construction of machine-learning Zr interatomic potentials for
   identifying the formation process of c-type dislocation loops
SO COMPUTATIONAL MATERIALS SCIENCE
AB In this study, a Neural Network Potential (NNP) using an Artificial Neural Network (ANN) was developed for Zr, which is used as fuel claddings in light water reactors. The reference data were obtained through first-principles calculations of various quantities, such as strained hexagonal-closed-packed (hcp) cells, strained face-centered cubic cells, cells containing a vacancy, several vacancies, and surface and gamma-surface energies on all five slip planes in the hcp structures. These data were converted to training data for the ANN, which were invariant to the rotation and translation of the atoms and independent of the number of atoms in the cells. The ANN was defined as a three-layer structure and the number of the nodes was set to 26-12-18-1. The NNP reproduced the firstprinciples calculations, particularly for the shear deformation, vacancy formation energy, surface energies, and gamma-surface energies, with much higher accuracy than any of the existing potentials that have been developed for classical molecular dynamics simulations. The NNP was applied to identify the formation process of c-type dislocation loops in Zr, which is a key microstructure responsible for abrupt increases in hydrogen absorption. The formation process was determined by the balance of the vacancy formation energy, surface energy and the gamma-surface energy on the basal plane, both of which were precisely reproduced only by the NNP developed in this study. The formation process was identified based on the atomistic behavior of the NNP.
RI Okumura, Masahiko/T-7993-2018; Okumura, Masahiko/ABG-7686-2021; Okita,
   Taira/AAZ-4657-2021
OI Okumura, Masahiko/0000-0001-7709-0241; Okumura,
   Masahiko/0000-0001-7709-0241; 
SN 0927-0256
EI 1879-0801
PD FEB 1
PY 2022
VL 202
AR 110865
DI 10.1016/j.commatsci.2021.110865
EA OCT 2021
UT WOS:000718888900005
ER

PT J
AU Fischell, JM
   Fishman, PS
AF Fischell, Jonathan M.
   Fishman, Paul S.
TI A Multifaceted Approach to Optimizing AAV Delivery to the Brain for the
   Treatment of Neurodegenerative Diseases
SO FRONTIERS IN NEUROSCIENCE
AB Despite major advancements in gene therapy technologies, there are no approved gene therapies for diseases which predominantly effect the brain. Adeno-associated virus (AAV) vectors have emerged as the most effective delivery vector for gene therapy owing to their simplicity, wide spread transduction and low immunogenicity. Unfortunately, the blood-brain barrier (BBB) makes IV delivery of AAVs, to the brain highly inefficient. At IV doses capable of widespread expression in the brain, there is a significant risk of severe immune-mediated toxicity. Direct intracerebral injection of vectors is being attempted. However, this method is invasive, and only provides localized delivery for diseases known to afflict the brain globally. More advanced methods for AAV delivery will likely be required for safe and effective gene therapy to the brain. Each step in AAV delivery, including delivery route, BBB transduction, cellular tropism and transgene expression provide opportunities for innovative solutions to optimize delivery efficiency. Intra-arterial delivery with mannitol, focused ultrasound, optimized AAV capsid evolution with machine learning algorithms, synthetic promotors are all examples of advanced strategies which have been developed in pre-clinical models, yet none are being investigated in clinical trials. This manuscript seeks to review these technological advancements, and others, to improve AAV delivery to the brain, and to propose novel strategies to build upon this research. Ultimately, it is hoped that the optimization of AAV delivery will allow for the human translation of many gene therapies for neurodegenerative and other neurologic diseases.</p>
EI 1662-453X
PD SEP 24
PY 2021
VL 15
AR 747726
DI 10.3389/fnins.2021.747726
UT WOS:000705060300001
PM 34630029
ER

PT C
AU Shahbazi, R
   Sharma, R
   Fard, FH
AF Shahbazi, Ramin
   Sharma, Rishab
   Fard, Fatemeh H.
GP IEEE COMP SOC
TI API2Com: On the Improvement of Automatically Generated Code Comments
   Using API Documentations
SO 2021 IEEE/ACM 29TH INTERNATIONAL CONFERENCE ON PROGRAM COMPREHENSION
   (ICPC 2021)
SE International Conference on Program Comprehension
CT 29th IEEE/ACM International Conference on Program Comprehension (ICPC) /
   18th IEEE/ACM International Conference on Mining Software Repositories
   (MSR)
CY MAY 22-30, 2021
CL ELECTR NETWORK
SP IEEE, Assoc Comp Machinery, IEEE Comp Soc, IEEE Tech Council Software Engn, ACM Special Interest Grp Software Engn
AB Code comments can help in program comprehension and are considered as important artifacts to help developers in software maintenance. However, the comments are mostly missing or are outdated, specially in complex software projects. As a result, several automatic comment generation models are developed as a solution. The recent models explore the integration of external knowledge resources such as Unified Modeling Language class diagrams to improve the generated comments. In this paper, we propose API2Com, a model that leverages the Application Programming Interface Documentations (API Docs) as a knowledge resource for comment generation. The API Docs include the description of the methods in more details and therefore, can provide better context in the generated comments. The API Docs are used along with the code snippets and Abstract Syntax Trees in our model.
   We apply the model on a large Java dataset of over 130,000 methods and evaluate it using both Transformer and RNN-base architectures. Interestingly, when API Docs are used, the performance increase is negligible. We therefore run different experiments to reason about the results. For methods that only contain one API, adding API Docs improves the results by 4% BLEU score on average (BLEU score is an automatic evaluation metric used in machine translation). However, as the number of APIs that are used in a method increases, the performance of the model in generating comments decreases due to long documentations used in the input. Our results confirm that the API Docs can be useful in generating better comments, but, new techniques are required to identify the most informative ones in a method rather than using all documentations simultaneously.
OI Fard, Fatemeh/0000-0002-4505-6257
SN 1092-8138
BN 978-1-6654-1403-6
PY 2021
BP 411
EP 421
DI 10.1109/ICPC52881.2021.00049
UT WOS:000693398800042
ER

PT J
AU Shukla, PK
   Chaurasiya, RK
   Verma, S
AF Shukla, Praveen Kumar
   Chaurasiya, Rahul Kumar
   Verma, Shrish
TI Performance improvement of P300-based home appliances control
   classification using convolution neural network
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
AB P300 speller-based brain-computer interface (BCI) is an immediate correspondence from a human brain to a computer that depends on the translation of mind reactions produced by stimulus of a subject utilizing a P300 speller. No muscle movements are required for this communication. The present study helps the disabled people (viz.patients with spinal cord injury, spastic cerebral palsy, locomotive diseases, etc.) ease their lives by accessing light, fan, mobile device, door, television, electric heater, etc. A novel 2 x 3 matrix consisting of home appliances visuals has been proposed as a P300 paradigm. Once the matrix visualization is completed, auditory feedback was provided and the chosen command was executed. It enables six menus to be navigated for hadling six electronic systems with up to 30 control commands. The objective of this research is to develop a P300-based BCI system for operating different electronic appliances at home. The existing BCI-based P300 spellers with standard machine learning methods suffers from low information transfer rate (ITR) and poor classification accuracy. With the application of convolution neural network (CNN) for classification, the proposed system improves the performance in terms of P300 classification & target appliances detection. The proposed system is designed to be user-convenient & cost-effective in terms of hardware design. The experiments have been performed on the dataset acquired from 30 target item selections from nine subjects using 16 channel actiCAP Xpress EEG recorders. The experimental result demonstrates that the proposed CNN model achieved 90% classification accuracy. It also offers ITR of 22.3 bits per minute which is substantially greater than the existing methods. The presented approach shows its novelty in the real-time applications.
OI Chaurasiya, Rahul/0000-0002-0911-0869
SN 1746-8094
EI 1746-8108
PD JAN
PY 2021
VL 63
AR 102220
DI 10.1016/j.bspc.2020.102220
UT WOS:000591530700013
ER

PT J
AU Spigler, S
   Geiger, M
   Wyart, M
AF Spigler, Stefano
   Geiger, Mario
   Wyart, Matthieu
TI Asymptotic learning curves of kernel methods: empirical data versus
   teacher-student paradigm
SO JOURNAL OF STATISTICAL MECHANICS-THEORY AND EXPERIMENT
AB How many training data are needed to learn a supervised task? It is often observed that the generalization error decreases as n(-beta) where n is the number of training examples and beta is an exponent that depends on both data and algorithm. In this work we measure beta when applying kernel methods to real datasets. For MNIST we find beta approximate to 0.4 and for CIFAR10 beta approximate to 0.1, for both regression and classification tasks, and for Gaussian or Laplace kernels. To rationalize the existence of non-trivial exponents that can be independent of the specific kernel used, we study the teacher-student framework for kernels. In this scheme, a teacher generates data according to a Gaussian random field, and a student learns them via kernel regression. With a simplifying assumption-namely that the data are sampled from a regular lattice-we derive analytically beta for translation invariant kernels, using previous results from the kriging literature. Provided that the student is not too sensitive to high frequencies, beta depends only on the smoothness and dimension of the training data. We confirm numerically that these predictions hold when the training points are sampled at random on a hypersphere. Overall, the test error is found to be controlled by the magnitude of the projection of the true function on the kernel eigenvectors whose rank is larger than n. Using this idea we predict the exponent beta from real data by performing kernel PCA, leading to beta approximate to 0.36 for MNIST and beta approximate to 0.07 for CIFAR10, in good agreement with observations. We argue that these rather large exponents are possible due to the small effective dimension of the data.
RI wyart, matthieu/L-3640-2013
OI wyart, matthieu/0000-0003-0644-0990
SN 1742-5468
PD DEC
PY 2020
VL 2020
IS 12
AR 124001
DI 10.1088/1742-5468/abc61d
UT WOS:000600808700001
ER

PT J
AU Maspero, M
   Houweling, AC
   Savenije, MHF
   van Heijst, TCF
   Verhoeff, JJC
   Kotte, ANTJ
   van den Berg, CAT
AF Maspero, Matteo
   Houweling, Antonetta C.
   Savenije, Mark H. F.
   van Heijst, Tristan C. F.
   Verhoeff, Joost J. C.
   Kotte, Alexis N. T. J.
   van den Berg, Cornelis A. T.
TI A single neural network for cone-beam computed tomography-based
   radiotherapy of head-and-neck, lung and breast cancer
SO PHYSICS & IMAGING IN RADIATION ONCOLOGY
AB Background and purpose Adaptive radiotherapy based on cone-beam computed tomography (CBCT) requires high CT number accuracy to ensure accurate dose calculations. Recently, deep learning has been proposed for fast CBCT artefact corrections on single anatomical sites. This study investigated the feasibility of applying a single convolutional network to facilitate dose calculation based on CBCT for head-and-neck, lung and breast cancer patients.
   Materials and Methods Ninety-nine patients diagnosed with head-and-neck, lung or breast cancer undergoing radiotherapy with CBCT-based position verification were included in this study. The CBCTs were registered to planning CT according to clinical procedures. Three cycle-consistent generative adversarial networks (cycle-GANs) were trained in an unpaired manner on 15 patients per anatomical site generating synthetic-CTs (sCTs). Another network was trained with all the anatomical sites together. Performances of all four networks were compared and evaluated for image similarity against rescan CT (rCT). Clinical plans were recalculated on rCT and sCT and analysed through voxel-based dose differences and gamma-analysis.
   Results A sCT was generated in 10 s. Image similarity was comparable between models trained on different anatomical sites and a single model for all sites. Mean dose differences <0.5% were obtained in high-dose regions. Mean gamma (3%, 3 mm) pass-rates were achieved for all sites.
   Conclusion Cycle-GAN reduced CBCT artefacts and increased similarity to CT, enabling sCT-based dose calculations. A single network achieved CBCT-based dose calculation generating synthetic CT for head-and-neck, lung, and breast cancer patients with similar performance to a network specifically trained for each anatomical site.
RI Maspero, Matteo/C-1102-2016
OI Maspero, Matteo/0000-0003-0347-3375; Verhoeff, Joost
   J.C./0000-0001-9673-0793
EI 2405-6316
PD APR
PY 2020
VL 14
BP 24
EP 31
DI 10.1016/j.phro.2020.04.002
UT WOS:000645139500005
PM 33458310
ER

PT J
AU Patel, N
   Henry, A
   Scarsbrook, A
AF Patel, N.
   Henry, A.
   Scarsbrook, A.
TI The value of MR textural analysis in prostate cancer
SO CLINICAL RADIOLOGY
AB Current diagnosis and treatment stratification of patients with suspected prostate cancer relies on a combination of histological and magnetic resonance imaging (MRI) findings. The aim of this article is to provide a brief overview of prostate pathological grading as well as the relevant aspects of multiparametric (MRI) mpMRI, before indicating the potential that magnetic resonance textural analysis (MRTA) offers within prostate cancer. A review of the evidence base on MRTA in prostate cancer will enable discussion of the utility of this field while also indicating recommendations to future research. Radiomic textural analysis allows the assessment of spatial inter-relationships between pixels within an image by use of mathematical methods. First-order textural analysis is better understood and may have more clinical validity than higher-order textural features. Textural features extracted from apparent diffusion coefficient maps have shown the most potential for clinical utility in MRTA of prostate cancers. Future studies should aim to integrate machine learning techniques to better represent the role of MRTA in prostate cancer clinical practice. Nomenclature should be used to reduce misidentification between first-order and second-order energy and entropy. Automated methods of segmentation should be encouraged in order to reduce problems associated with inclusion of normal tissue within regions of interest. The retrospective and small-scale nature of most published studies, make it difficult to draw meaningful conclusions. Future larger prospective studies are required to validate the textural features indicated to have potential in characterisation and/or diagnosis of prostate cancer before translation into routine clinical practice. (C) 2018 The Royal College of Radiologists. Published by Elsevier Ltd. All rights reserved.
OI Henry, Ann/0000-0002-5379-6618; Patel, Nishil/0000-0001-7106-881X;
   Scarsbrook, Andrew/0000-0002-4243-032X
SN 0009-9260
EI 1365-229X
PD NOV
PY 2019
VL 74
IS 11
BP 876
EP 885
DI 10.1016/j.crad.2018.11.007
UT WOS:000490192300007
PM 30573283
ER

PT J
AU Gilman, J
   Singleton, C
   Tennant, RK
   James, P
   Howard, TP
   Lux, T
   Parker, DA
   Love, J
AF Gilman, James
   Singleton, Chloe
   Tennant, Richard K.
   James, Paul
   Howard, Thomas P.
   Lux, Thomas
   Parker, David A.
   Love, John
TI Rapid, Heuristic Discovery and Design of Promoter Collections in
   Non-Model Microbes for Industrial Applications
SO ACS SYNTHETIC BIOLOGY
AB Well-characterized promoter collections for synthetic biology applications are not always available in industrially relevant hosts. We developed a broadly applicable method for promoter identification in atypical microbial hosts that requires no a priori understanding of cis-regulatory element structure. This novel approach combines bioinformatic filtering with rapid empirical characterization to expand the promoter toolkit and uses machine learning to improve the understanding of the relationship between DNA sequence and function. Here, we apply the method in Geobacillus thermoglucosidasius, a thermophilic organism with high potential as a synthetic biology chassis for industrial applications. Bioinformatic screening of G. kaustophilus, G. stearothermophilus, G. thermodenitrificans, and G. thermoglucosidasius resulted in the identification of 636 100 bp putative promoters, encompassing the genome-wide design space and lacking known transcription factor binding sites. Eighty of these sequences were characterized in vivo, and activities covered a 2-log range of predictable expression levels. Seven sequences were shown to function consistently regardless of the downstream coding sequence. Partition modeling identified sequence positions upstream of the canonical -35 and -10 consensus motifs that were predicted to strongly influence regulatory activity in Geobacillus, and artificial neural network and partial least squares regression models were derived to assess if there were a simple, forward, quantitative method for in silico prediction of promoter function. However, the models were insufficiently general to predict pre hoc promoter activity in vivo, most probably as a result of the relatively small size of the training data set compared to the size of the modeled design space.
OI James, Paul/0000-0001-9214-1641; Gilman, James/0000-0001-7250-7909;
   Howard, Thomas/0000-0002-5546-4043
SN 2161-5063
PD MAY
PY 2019
VL 8
IS 5
BP 1175
EP 1186
DI 10.1021/acssynbio.9b00061
UT WOS:000468697000027
PM 30995831
ER

PT J
AU Dai, JZ
   Xiong, SW
AF Dai, Jiazhu
   Xiong, Siwei
TI An Evasion Attack against Stacked Capsule Autoencoder
SO ALGORITHMS
AB Capsule networks are a type of neural network that use the spatial relationship between features to classify images. By capturing the poses and relative positions between features, this network is better able to recognize affine transformation and surpass traditional convolutional neural networks (CNNs) when handling translation, rotation, and scaling. The stacked capsule autoencoder (SCAE) is a state-of-the-art capsule network that encodes an image in capsules which each contain poses of features and their correlations. The encoded contents are then input into the downstream classifier to predict the image categories. Existing research has mainly focused on the security of capsule networks with dynamic routing or expectation maximization (EM) routing, while little attention has been given to the security and robustness of SCAEs. In this paper, we propose an evasion attack against SCAEs. After a perturbation is generated based on the output of the object capsules in the model, it is added to an image to reduce the contribution of the object capsules related to the original category of the image so that the perturbed image will be misclassified. We evaluate the attack using an image classification experiment on the Mixed National Institute of Standards and Technology Database (MNIST), Fashion-MNIST, and German Traffic Sign Recognition Benchmark (GTSRB) datasets, and the average attack success rate can reach 98.6%. The experimental results indicate that the attack can achieve high success rates and stealthiness. This finding confirms that the SCAE has a security vulnerability that allows for the generation of adversarial samples. Our work seeks to highlight the threat of this attack and focus attention on SCAE's security.
OI , Dai/0000-0002-1883-0171
EI 1999-4893
PD FEB
PY 2022
VL 15
IS 2
AR 32
DI 10.3390/a15020032
UT WOS:000762721000001
ER

PT J
AU Al Taee, A
   Hosseini, S
   Khushaba, RN
   Zia, T
   Lin, CT
   Al-Jumaily, A
AF Al Taee, Ahmed
   Hosseini, Seyedehmarzieh
   Khushaba, Rami N.
   Zia, Tanveer
   Lin, Chin-Teng
   Al-Jumaily, Adel
TI Deep Learning Inspired Feature Engineering for Classifying Tremor
   Severity
SO IEEE ACCESS
AB Bio-signals pattern recognition systems can be impacted by several factors with a potential to limit their associated performance and clinical translation. Among these factors, selecting the optimum feature extraction method, that can effectively exploit the interaction between the temporal and spatial information, is the most prominent. Despite the potential of deep learning (DL) models for extracting temporal, spatial, or temporal-spatial information, they are typically restricted by their need for a large amount of training data. The deep wavelet scattering transform (WST) is a relatively recent advancement within the DL literature to replace expensive convolution neural networks models with computationally less demanding methods. However, while some studies have used WST to extract features from biological signals, it has not been investigated before for electromyogram (EMG) and electroencephalogram (EEG) signals feature extraction. To investigate the hypothesis of the usefulness of WST for processing EMG and EEG signals, this study used a tremor dataset collected by the authors from people with tremor disorders. Specifically, the proposed work achieved three goals: (a) study the performance of extracting features from low-density EMG signals (8 channels), using the WST approach, (b) study the effect of extracting the features from high-density EEG signals (33 channels), using WST and study its robustness against changing the spatial and temporal aspects of classification accuracy, and (c) classify tremor severity using the WST method and compare the results with other well-known feature extraction approaches. The classification error rates were significantly reduced (maximum of nearly 12%) compared with other feature sets.
RI Hosseini, seyedehmarzieh/HKO-9396-2023; Khushaba, Rami/O-1038-2015; Zia,
   Tanveer/C-1499-2016; Lin, Chin-Teng (CT)/G-8129-2017; Al-Jumaily,
   Adel/A-5301-2014
OI Khushaba, Rami/0000-0001-8528-8979; Zia, Tanveer/0000-0003-3802-5687;
   Lin, Chin-Teng (CT)/0000-0001-8371-8197; Taee,
   Ahmed/0000-0001-6111-8764; Al-Jumaily, Adel/0000-0003-0297-2463
SN 2169-3536
PY 2022
VL 10
BP 105377
EP 105386
DI 10.1109/ACCESS.2022.3210344
UT WOS:000866423300001
ER

PT J
AU Fu, HZ
   Zhou, T
   Li, S
   Frangi, AF
AF Fu, Huazhu
   Zhou, Tao
   Li, Shuo
   Frangi, Alejandro F.
TI Guest Editorial Generative Adversarial Networks in Biomedical Image
   Computing
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
AB The papers in this special section focus on generative adversarial networks in biomedical image computing. The field of biomedical imaging has obtained great progress from Roentgen's original discovery of the X-ray to the current imaging tools, including Magnetic Resonance Imaging (MRI), Positron Emission Tomography (PET), Computed Tomography (CT), and Ultrasound (US). The benefits of using these non-invasive imaging technologies are to assess the current condition of an organ or tissue, which can be used to monitor a patient over time over time for accurate and timely diagnosis and treatment.With the development of imaging technologies, developing advanced artificial intelligence algorithms for automated image analysis has shown the potential to change many aspects of clinical applications within the next decade. Meanwhile, these advanced technologies have also brought new issues and challenges. Thus, there has been a growing demand for biomedical imaging computing to be a component of clinical trials and device improvement. Currently, Generative adversarial networks (GANs) have been attached growing interests in the computer vision community due to their capability of data generation or translation. GAN-based models are able to learn from a set of training data and generate new data with the same characteristics as the training ones, which have also proven to be the state of the art for generating sharp and realistic images. More importantly, GAN has been rapidly applied to many traditional and novel applications in the medical domain, such as image reconstruction, segmentation, diagnosis, synthesis, and so on. Despite GAN substantial progress in these areas, their application to medical image computing still faces challenges and unsolved problems remain.
RI Frangi, Alejandro F/C-6500-2008; Fu, Huazhu/A-1411-2014; Li,
   Shuo/HLV-7870-2023; Li, Shuo/F-9736-2017
OI Frangi, Alejandro F/0000-0002-2675-528X; Fu, Huazhu/0000-0002-9702-5524;
   Li, Shuo/0000-0002-5184-3230
SN 2168-2194
EI 2168-2208
PD JAN
PY 2022
VL 26
IS 1
BP 4
EP 6
DI 10.1109/JBHI.2021.3134004
UT WOS:000745829300005
ER

PT J
AU Bollepalli, SC
   Sevakula, RK
   Au-Yeung, WTM
   Kassab, MB
   Merchant, FM
   Bazoukis, G
   Boyer, R
   Isselbacher, EM
   Armoundas, AA
AF Bollepalli, Sandeep Chandra
   Sevakula, Rahul K.
   Au-Yeung, Wan-Tai M.
   Kassab, Mohamad B.
   Merchant, Faisal M.
   Bazoukis, George
   Boyer, Richard
   Isselbacher, Eric M.
   Armoundas, Antonis A.
TI Real-Time Arrhythmia Detection Using Hybrid Convolutional Neural
   Networks
SO JOURNAL OF THE AMERICAN HEART ASSOCIATION
AB Background Accurate detection of arrhythmic events in the intensive care units (ICU) is of paramount significance in providing timely care. However, traditional ICU monitors generate a high rate of false alarms causing alarm fatigue. In this work, we develop an algorithm to improve life threatening arrhythmia detection in the ICUs using a deep learning approach. Methods and Results This study involves a total of 953 independent life-threatening arrhythmia alarms generated from the ICU bedside monitors of 410 patients. Specifically, we used the ECG (4 channels), arterial blood pressure, and photoplethysmograph signals to accurately detect the onset and offset of various arrhythmias, without prior knowledge of the alarm type. We used a hybrid convolutional neural network based classifier that fuses traditional handcrafted features with features automatically learned using convolutional neural networks. Further, the proposed architecture remains flexible to be adapted to various arrhythmic conditions as well as multiple physiological signals. Our hybrid- convolutional neural network approach achieved superior performance compared with methods which only used convolutional neural network. We evaluated our algorithm using 5-fold cross-validation for 5 times and obtained an accuracy of 87.5%+/- 0.5%, and a score of 81%+/- 0.9%. Independent evaluation of our algorithm on the publicly available PhysioNet 2015 Challenge database resulted in overall classification accuracy and score of 93.9% and 84.3%, respectively, indicating its efficacy and generalizability. Conclusions Our method accurately detects multiple arrhythmic conditions. Suitable translation of our algorithm may significantly improve the quality of care in ICUs by reducing the burden of false alarms.
RI Bazoukis, George/AAM-4006-2020; Au-Yeung, Wan-Tai/AAV-6097-2020
OI Au-Yeung, Wan-Tai/0000-0003-0198-4630; B, Sandeep
   Chandra/0000-0002-9971-9335; Armoundas, Antonis/0000-0001-5006-1547
EI 2047-9980
PD DEC 7
PY 2021
VL 10
IS 23
AR e023222
DI 10.1161/JAHA.121.023222
UT WOS:000727412400034
PM 34854319
ER

PT J
AU Park, JM
   Sim, JM
   Jung, HM
AF Park, Jong-Min
   Sim, Jae-Min
   Jung, Hyun-Mo
TI Finite Element Simulation of the Flat Crush Behavior of Corrugated
   Packages
SO APPLIED SCIENCES-BASEL
AB Corrugated paperboards are used for packaging because of their high strength-to-weight ratio, recyclability, and biodegradability. Corrugated paperboard consists of a liner and a corrugated medium and has an orthotropic sandwich structure with unique characteristics for each direction owing to its flute shape. In this study, finite element analysis (FEA) was performed on the flat crush behavior of the corrugated paperboard based on the flute type. The stress-strain (SS) curve and shape change of the flute were analyzed during the flat compression. In addition, it was compared with the FEA results through various experiments. The restraints and boundary conditions applied during FEA were used to properly describe the conditions during the experiment. Specifically, the horizontal translation motion of the top and bottom surfaces of the modeled test specimen was constrained during FEA to correspond to the effect of sandpaper attached to the upper and lower plates of the testing machine. This was done to prevent the specimen from sliding in one direction during the flat crush test. The change in the flute shape of the corrugated paperboard by flute type analyzed through experiments and FEA was very similar; although there was a difference in the absolute value between the two methods of the SS curve, the flute type exhibited a similar trend. Therefore, a qualitative comparative study on the flat crush behavior by flute type was possible with the FEA method, as in this study. Further studies on the material properties of the corrugated paperboard components and the modeling methods of the corrugated paperboard will enable the FEA-based simulation technique to be an alternative tool that can replace the flat crush test.
OI Jung, Hyun Mo/0000-0002-7310-3081
EI 2076-3417
PD SEP
PY 2021
VL 11
IS 17
AR 7867
DI 10.3390/app11177867
UT WOS:000695561100001
ER

PT J
AU Maron, RC
   Haggenmuller, S
   von Kalle, C
   Utikal, JS
   Meier, F
   Gellrich, FF
   Hauschild, A
   French, LE
   Schlaak, M
   Ghoreschi, K
   Kutzner, H
   Heppt, MV
   Haferkamp, S
   Sondermann, W
   Schadendorf, D
   Schilling, B
   Hekler, A
   Krieghoff-Henning, E
   Kather, JN
   Frohling, S
   Lipka, DB
   Brinker, TJ
AF Maron, Roman C.
   Haggenmueller, Sarah
   von Kalle, Christof
   Utikal, Jochen S.
   Meier, Friedegund
   Gellrich, Frank F.
   Hauschild, Axel
   French, Lars E.
   Schlaak, Max
   Ghoreschi, Kamran
   Kutzner, Heinz
   Heppt, Markus V.
   Haferkamp, Sebastian
   Sondermann, Wiebke
   Schadendorf, Dirk
   Schilling, Bastian
   Hekler, Achim
   Krieghoff-Henning, Eva
   Kather, Jakob N.
   Froehling, Stefan
   Lipka, Daniel B.
   Brinker, Titus J.
TI Robustness of convolutional neural networks in recognition of pigmented
   skin lesions
SO EUROPEAN JOURNAL OF CANCER
AB Background: A basic requirement for artificial intelligence (AI)-based image analysis systems, which are to be integrated into clinical practice, is a high robustness. Minor changes in how those images are acquired, for example, during routine skin cancer screening, should not change the diagnosis of such assistance systems.
   Objective: To quantify to what extent minor image perturbations affect the convolutional neural network (CNN)-mediated skin lesion classification and to evaluate three possible solutions for this problem (additional data augmentation, test-time augmentation, anti-aliasing).
   Methods: We trained three commonly used CNN architectures to differentiate between dermoscopic melanoma and nevus images. Subsequently, their performance and susceptibility to minor changes ('brittleness') was tested on two distinct test sets with multiple images per lesion. For the first set, image changes, such as rotations or zooms, were generated artificially. The second set contained natural changes that stemmed from multiple photographs taken of the same lesions.
   Results: All architectures exhibited brittleness on the artificial and natural test set. The three reviewed methods were able to decrease brittleness to varying degrees while still maintaining performance. The observed improvement was greater for the artificial than for the natural test set, where enhancements were minor.
   Conclusions: Minor image changes, relatively inconspicuous for humans, can have an effect on the robustness of CNNs differentiating skin lesions. By the methods tested here, this effect can be reduced, but not fully eliminated. Thus, further research to sustain the performance of AI classifiers is needed to facilitate the translation of such systems into the clinic. (C) 2020 The Author(s). Published by Elsevier Ltd.
RI Haferkamp, Sebastian/ABD-7390-2021; Kather, Jakob Nikolas/D-4279-2015;
   Haferkamp, Sebastian/AAN-3649-2021; Meier, Friedegund/HTN-0745-2023;
   Schadendorf, Dirk/AAE-8206-2019
OI Haferkamp, Sebastian/0000-0002-3894-8345; Kather, Jakob
   Nikolas/0000-0002-3730-5348; Meier, Friedegund/0000-0003-4340-9706;
   Schadendorf, Dirk/0000-0003-3524-7858; Haggenmuller,
   Sarah/0000-0002-7961-1781; Schlaak, Max/0000-0002-1663-8098; Brinker,
   Titus Josef/0000-0002-3620-5919; French, Lars/0000-0002-4629-1486; von
   Kalle, Christof/0000-0001-9221-3297; Ghoreschi,
   Kamran/0000-0002-5526-7517; Gellrich, Frank
   Friedrich/0000-0002-2164-4644
SN 0959-8049
EI 1879-0852
PD MAR
PY 2021
VL 145
BP 81
EP 91
DI 10.1016/j.ejca.2020.11.020
EA JAN 2021
UT WOS:000625301200009
PM 33423009
ER

PT J
AU Omar, N
   Al-Tashi, Q
AF Omar, Nazlia
   Al-Tashi, Qasem
TI Arabic Nested Noun Compound Extraction Based on Linguistic Features and
   Statistical Measures
SO GEMA ONLINE JOURNAL OF LANGUAGE STUDIES
AB The extraction of Arabic nested noun compound is significant for several research areas such as sentiment analysis, text summarization, word categorization, grammar checker, and machine translation. Much research has studied the extraction of Arabic noun compound using linguistic approaches, statistical methods, or a hybrid of both. A wide range of the existing approaches concentrate on the extraction of the bi-gram or tri-gram noun compound. Nonetheless, extracting a 4-gram or 5-gram nested noun compound is a challenging task due to the morphological, orthographic, syntactic and semantic variations. Many features have an important effect on the efficiency of extracting a noun compound such as unit-hood, contextual information, and term-hood. Hence, there is a need to improve the effectiveness of the Arabic nested noun compound extraction. Thus, this paper proposes a hybrid linguistic approach and a statistical method with a view to enhance the extraction of the Arabic nested noun compound. A number of pre-processing phases are presented, including transformation, tokenization, and normalisation. The linguistic approaches that have been used in this study consist of a part-of-speech tagging and the named entities pattern, whereas the proposed statistical methods that have been used in this study consist of the NC-value, NTC-value, NLC-value, and the combination of these association measures. The proposed methods have demonstrated that the combined association measures have outperformed the NLC-value, NTC-value, and NC-value in terms of nested noun compound extraction by achieving 90%, 88%, 87%, and 81% for bigram, trigram, 4-gram, and 5-gram, respectively.
RI Omar, Nazlia/L-9901-2019; AL-TASHI, QASEM/O-1632-2019
OI AL-TASHI, QASEM/0000-0001-7208-693X; Omar, Nazlia/0000-0002-8173-8933
SN 1675-8021
PD MAY
PY 2018
VL 18
IS 2
BP 93
EP 107
DI 10.17576/gema-2018-1802-07
UT WOS:000433914700007
ER

PT J
AU Guha, A
   Hazelwood, K
   Soffa, ML
AF Guha, Apala
   Hazelwood, Kim
   Soffa, Mary Lou
TI DBT Path Selection for Holistic Memory Efficiency and Performance
SO ACM SIGPLAN NOTICES
CT 6th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution
   Environments
CY MAR 17-19, 2010
CL Pittsburgh, PA
AB Dynamic binary translators (DBTs) provide powerful platforms for building dynamic program monitoring and adaptation tools. DBTs, however, have high memory demands because they cache translated code and auxiliary code to a software code cache and must also maintain data structures to support the code cache. The high memory demands make it difficult for memory-constrained embedded systems to take advantage of DBT-based tools. Previous research on DBT memory management focused on the translated code and auxiliary code only. However, we found that data structures are comparable to the code cache in size. We show that the translated code size, auxiliary code size and the data structure size interact in a complex manner, depending on the path selection (trace selection and link formation) strategy. Therefore, holistic memory efficiency (comprising translated code, auxiliary code and data structures) cannot be improved by focusing on the code cache only. In this paper, we use path selection for improving holistic memory efficiency which in turn impacts performance in memory-constrained environments. Although there has been previous research on path selection, such research only considered performance in memory-unconstrained environments.
   The challenge for holistic memory efficiency is that the path selection strategy results in complex interactions between the memory demand components. Also, individual aspects of path selection and the holistic memory efficiency may impact performance in complex ways. We explore these interactions to motivate path selection targeting holistic memory demand. We enumerate all the aspects involved in a path selection design and evaluate a comprehensive set of approaches for each aspect. Finally, we propose a path selection strategy that reduces memory demands by 20% and at the same time improves performance by 5-20% compared to an industrial-strength DBT.
SN 0362-1340
EI 1558-1160
PD JUL
PY 2010
VL 45
IS 7
BP 145
EP 156
UT WOS:000280548400013
ER

PT J
AU Ekinci, M
   Aykut, M
AF Ekinci, Murat
   Aykut, Murat
TI Improved gait recognition by multiple-projections normalization
SO MACHINE VISION AND APPLICATIONS
AB Recognizing people by gait promises to be useful for identifying individuals from a distance; in this regard, improved techniques are under development. In this paper, an improved method for gait recognition is proposed. Binarized silhouette of a motion object is first represented by four 1-D signals that are the basic image features called the distance vectors. The distance vectors are differences between the bounding box and silhouette, and extracted using four projections to silhouette. Fourier Transform is employed as a preprocessing step to achieve translation invariant for the gait patterns accumulated from silhouette sequences that are extracted from the subjects' walk in different speed and/or different time. Then, eigenspace transformation is applied to reduce the dimensionality of the input feature space. Support vector machine (SVM)-based pattern classification technique is then performed in the lower-dimensional eigenspace for recognition. The input feature space is alternatively constructed by using two different approaches. The four projections (1-D signals) are independently classified in the first approach. A fusion task is then applied to produce the final decision. In the second approach, the four projections are concatenated to have one vector and then pattern classification with one vector is performed in the lower-dimensional eigenspace for recognition. The experiments are carried out on the most well-known public gait databases: the CMU, the USF, SOTON, and NLPR human gait databases. To effectively understand the performance of the algorithm, the experiments are executed and presented as increasing amounts of the gait cycles of each person available during the training procedure. Finally, the performance of the proposed algorithm is comparatively illustrated to take into consideration the published gait recognition approaches.
RI AYKUT, Murat/AAV-9658-2020; Ekinci, Murat/A-9653-2012
OI Aykut, Murat/0000-0003-0100-6343
SN 0932-8092
EI 1432-1769
PD FEB
PY 2010
VL 21
IS 2
BP 143
EP 161
DI 10.1007/s00138-008-0144-0
UT WOS:000273479200004
ER

PT J
AU Zheng, GY
   Zhang, X
   Haschtmann, D
   Gedet, P
   Dong, X
   Nolte, LP
AF Zheng, Guoyan
   Zhang, Xuan
   Haschtmann, Daniel
   Gedet, Philippe
   Dong, Xiao
   Nolte, Lutz-Peter
TI A robust and accurate two-stage approach for automatic recovery of
   distal locking holes in computer-assisted intramedullary nailing of
   femoral shaft fractures
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
AB It has been recognized that one of the most difficult steps in intramedullary nailing of femoral shaft fractures is the distal locking-the insertion of distal transverse interlocking screws, for which it is necessary to know the positions and orientations of the distal locking holes (DLHs) of the intramedullary nail (IMN). This paper presents a robust and accurate approach for solving this problem based on two calibrated and registered fluoroscopic images. The problem is formulated as a two-stage model-based optimal fitting process. The first stage, nail detection, automatically estimates the axis of the distal part of the IMN (DP-IMN) by iteratively fitting a cylindrical model to the images. The second stage, pose recovery, resolves the translations and the rotations of the DLHs around the estimated axis by iteratively fitting the geometrical models of the DLHs to the images. An iterative best matched projection point (IBMPP) algorithm is combined with random sample strategies to effectively and robustly solve the fitting problems in both stages. We designed and conducted comprehensive experiments to validate the robustness and the accuracy of the present approach. Our in vitro experiments show on average less than 14 s execution time on a Linux machine, a mean angular error of 0.48 degrees (std = 0.21 degrees), and a mean translational error of 0.09 mm (std = 0.04 mm). We conclude that the present approach is fast, robust, and accurate for distal locking applications.
RI Zheng, Guoyan/C-8079-2014; , Guoyan/M-3617-2018
OI , Guoyan/0000-0003-4173-0379
SN 0278-0062
EI 1558-254X
PD FEB
PY 2008
VL 27
IS 2
BP 171
EP 187
DI 10.1109/TMI.2007.904692
UT WOS:000252815200003
PM 18334439
ER

PT J
AU Deshmukh, AV
   Perlmutter, GS
   Zilberfarb, JL
   Wilson, DR
AF Deshmukh, AV
   Perlmutter, GS
   Zilberfarb, JL
   Wilson, DR
TI Effect of subacromial decompression on laxity of the acromioclavicular
   joint: Biomechanical testing in a cadaveric model
SO JOURNAL OF SHOULDER AND ELBOW SURGERY
AB Subacromial decompression is a well-accepted treatment for impingement syndrome when nonoperative therapies have failed. However, recent clinical data have raised concern that arthroscopic subacromial decompression may lead to laxity of the acromioclavicu-lar joint and, potentially, predispose patients to late postoperative acromioclavicular joint pain. Our goal was to determine whether subacromial decompression with co-planing of the distal clavicle alters the laxity, or compliance, of the acromioclavicular joint in a cad-averic model. Eighteen cadaveric shoulders were dissected and tested in a specially designed rig, driven by a hydraulic materials testing machine. One hundred-Newton loads were applied to the distal clavicle in the superior, posterior, and anterior directions, while acromioclavicular joint motion was recorded with a 3-dimensional infrared optical measurement system. Acromioplasty was performed with a posterior-referenced cutting block technique and included co-planing of the distal clavicle in all specimens. Joint compliance before and after subacromial decompression was compared with the paired t test. Subacromial decompression increased anteroposterior compliance by 13%, from 8.8 +/- 2.9 mm (mean +/- SD) in the intact joint to 9.9 +/- 3.1 mm (P = 001). Subacromial decompression increased superior compliance by 32%, from 3.1 +/- 1.5 mm in the native specimen to 4.1 +/- 1.8 mm (P = .03). These observations may have implications for the technique of acromioplasty. Although the immediate result of acromioplasty with co-planing appears to be on increase in the compli-ance of the acromioclavicular joint, the clinical significance of these findings has yet to be determined.
RI Wilson, D/T-7980-2019
OI Wilson, David/0000-0001-6893-0894
SN 1058-2746
PD MAY-JUN
PY 2004
VL 13
IS 3
BP 338
EP 343
DI 10.1016/j.jse.2004.01.004
UT WOS:000221267300014
PM 15111906
ER

PT J
AU Spahn, CMT
   Grassucci, RA
   Penczek, P
   Frank, J
AF Spahn, CMT
   Grassucci, RA
   Penczek, P
   Frank, J
TI Direct three-dimensional localization and positive identification of RNA
   helices within the ribosome by means of genetic tagging and
   cryo-electron microscopy
SO STRUCTURE WITH FOLDING & DESIGN
AB Background: Ribosomes are complex macromolecular machines that perform the translation of the genetic message. Cryo-electron microscopic (cryo-EM) maps of the Escherichia coli 70S ribosome are approaching a resolution of 10 Angstrom and X-ray maps of the 30S and 50S subunits are now available at 5 Angstrom. These maps show a lot of details about the inner architecture of the ribosome and ribosomal RNA helices are clearly visible. However, in the absence of further biological information, even at the higher resolution of the X-ray maps many rRNA helices can be placed only tentatively. Here we show that genetic tagging in combination with cryo-EM can place and orient double-stranded RNA helices with high accuracy.
   Results: A tRNA sequence inserted into the E. coli 23S ribosomal RNA gene, at one of the points of sequence expansion in eukaryotic ribosomes, is visible in the cryo-EM map as a peripheral 'foot' structure. By tracing its acceptor-stem end, the location of helix 63 in domain IV and helix 98 in domain VI of the 50S subunit could be precisely determined.
   Conclusions: Our study demonstrates for the first time that features of a three-dimensional cryo-EM map of an asymmetric macromolecular complex can be interpreted in terms of secondary and primary structure. Using the identified helices as a starting point, it is possible to model and interpret, in molecular terms, a larger portion of the ribosome. Our results might be also useful in interpreting and refining the current X-ray maps.
SN 0969-2126
PD DEC 15
PY 1999
VL 7
IS 12
BP 1567
EP 1573
DI 10.1016/S0969-2126(00)88347-1
UT WOS:000084430700015
PM 10647187
ER

PT J
AU Tachicart, R
   Bouzoubaa, K
AF Tachicart, Ridouane
   Bouzoubaa, Karim
TI Moroccan Arabic vocabulary generation using a rule-based approach
SO JOURNAL OF KING SAUD UNIVERSITY-COMPUTER AND INFORMATION SCIENCES
AB NLP resources play a crucial role in the building of many NLP applications. The importance of these resources depends not only on their size and coverage but also on the richness and the precision of the annotated information they provide. In the case of resource-scarce languages such as Moroccan Arabic, the building of NLP applications is limited due to the lack of these resources. To overcome this problem, we follow a rule-based approach to generate a Moroccan morphological vocabulary (MORV) which constitutes the first step addressing the problem of Moroccan morphological generation. MORV is designed and implemented based on two main components: On one hand, an MA lexicon and a list of fully annotated affixes and clitics that we have created specifically to ensure the generation process. On the other hand, a set of rules covering the concatenation and the orthographic adjustments of the gen-erated words. Moreover, given a base form, MORV outputs more than 4.5 M Moroccan words with rich morphological features such as tense, gender, number, state, etc. We tested the coverage of MORV on texts collected from Moroccan social media and realized that it reaches a vocabulary coverage of 84% and a precision of 94%. This system is a benefit for building other NLP applications such as spell checking, morphological analysis, and machine translation. (c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
SN 1319-1578
EI 2213-1248
PD NOV
PY 2022
VL 34
IS 10
BP 8538
EP 8548
DI 10.1016/j.jksuci.2021.02.013
PN A
UT WOS:000916037800015
ER

PT J
AU Fatania, K
   Clark, A
   Frood, R
   Scarsbrook, A
   Al-Qaisieh, B
   Currie, S
   Nix, M
AF Fatania, Kavi
   Clark, Anna
   Frood, Russell
   Scarsbrook, Andrew
   Al-Qaisieh, Bashar
   Currie, Stuart
   Nix, Michael
TI Harmonisation of scanner-dependent contrast variations in magnetic
   resonance imaging for radiation oncology, using style-blind
   auto-encoders
SO PHYSICS & IMAGING IN RADIATION ONCOLOGY
AB Background and purpose: Magnetic Resonance Imaging (MRI) exhibits scanner dependent contrast, which limits generalisability of radiomics and machine-learning for radiation oncology. Current deep-learning harmonisation requires paired data, retraining for new scanners and often suffers from geometry-shift which alters anatomical information. The aim of this study was to investigate style-blind auto-encoders for MRI harmonisation to accommodate unpaired training data, avoid geometry-shift and harmonise data from previously unseen scanners. Materials and methods: A style-blind auto-encoder, using adversarial classification on the latent-space, was designed for MRI harmonisation. The public CC359 T1-w MRI brain dataset includes six scanners (three manufacturers, two field strengths), of which five were used for training. MRI from all six (including one unseen) scanner were harmonised to common contrast. Harmonisation extent was quantified via Kolmogorov-Smirnov testing of residual scanner dependence of 3D radiomic features, and compared to WhiteStripe normalisation. Anatomical content preservation was measured through change in structural similarity index on contrast-cycling (delta SSIM). Results: The percentage of radiomics features showing statistically significant scanner-dependence was reduced from 41% (WhiteStripe) to 16% for white matter and from 39% to 27% for grey matter. delta SSIM < 0.0025 on harmonisation and de-harmonisation indicated excellent anatomical content preservation. Conclusions: Our method harmonised MRI contrast effectively, preserved critical anatomical details at high fidelity, trained on unpaired data and allowed zero-shot harmonisation. Robust and clinically translatable harmonisation of MRI will enable generalisable radiomic and deep-learning models for a range of applications, including radiation oncology treatment stratification, planning and response monitoring.
RI Frood, Russell/I-4196-2019
OI Frood, Russell/0000-0003-2681-9922; Clark, Anna/0000-0003-4359-3697;
   Scarsbrook, Andrew/0000-0002-4243-032X
EI 2405-6316
PD APR
PY 2022
VL 22
BP 115
EP 122
DI 10.1016/j.phro.2022.05.005
UT WOS:000805208500006
PM 35619643
ER

PT C
AU Hsiao, SJ
   Lia, KY
   Sung, WT
AF Hsiao, Sung-Jung
   Lia, Kuang-Yow
   Sung, Wen-Tsai
GP IEEE
TI Employing Cross-Platform Smart Home Control System with IOT Technology
   Based
SO 2016 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C)
CT International Symposium on Computer, Consumer and Control (IS3C)
CY JUL 04-06, 2016
CL Natl Chin Yi Univ Technol, Xian, PEOPLES R CHINA
SP Xian Univ Sci & Technol, IEEE Ind Elect Soc, IEEE, IEEE Comp Soc, Natl Chung Hsing Univ, City Univ Hong Kong, Kyushu Inst Technol
HO Natl Chin Yi Univ Technol
AB The proposed method changes the original remote controller for home appliances become IOT (internet of things) technology-based and cross-platform control by the smart phone remote wireless control. In our research, smart phone will replace the traditional remote control operation. When the controller press mobile Web App, in addition to the circuit module will emitting infrared signals, our hardware module will also upload information to the cloud database. Such an innovative approach would be able to provide accurate monitoring by real-time monitoring status and real-time analysis. In the proposed smart home embedded system, data sent back from each sensor inside the household can be instantaneously analyzed; Furthermore, the use of Network Address Translation (NAT) technology to control remotely via the Internet. In terms of the construction process of the smart factory system, this dissertation proposes an instantaneous method that carries out the monitoring of factory area temperature, humidity and air quality using smart mobile phone. At the same time, the system detects potential flame, analyze and monitor power loading. These monitoring also include shock detection of operating machines in factory premises. The study proposes integrating ZigBee and Wi-Fi protocol smart monitoring system in the structure of the whole factory. Via ZigBee communication Protocol, the sensors in the factory transmit messages and the instantaneously detected data to the integrated regulating system.
   Lastly, this research study will, in depth, analyse hands-on problems generated during instantaneous integration of signal packing for various communication protocols. As well as composing the know-how of overcoming these problems using the innovative methods of this study while proposing efficient solution schemes. The above become the greatest features in the building of this integrated regulation system.
OI Lian, Kuang-Yow/0000-0002-5692-9279
BN 978-1-5090-3071-2
PY 2016
BP 264
EP 267
DI 10.1109/IS3C.2016.77
UT WOS:000387180300067
ER

PT J
AU Panwar, B
   Raghava, GPS
AF Panwar, Bharat
   Raghava, Gajendra P. S.
TI Prediction of uridine modifications in tRNA sequences
SO BMC BIOINFORMATICS
AB Background: In past number of methods have been developed for predicting post-translational modifications in proteins. In contrast, limited attempt has been made to understand post-transcriptional modifications. Recently it has been shown that tRNA modifications play direct role in the genome structure and codon usage. This study is an attempt to understand kingdom-wise tRNA modifications particularly uridine modifications (UMs), as majority of modifications are uridine-derived.
   Results: A three-steps strategy has been applied to develop an efficient method for the prediction of UMs. In the first step, we developed a common prediction model for all the kingdoms using a dataset from MODOMICS-2008. Support Vector Machine (SVM) based prediction models were developed and evaluated by five-fold cross-validation technique. Different approaches were applied and found that a hybrid approach of binary and structural information achieved highest Area under the curve (AUC) of 0.936. In the second step, we used newly added tRNA sequences (as independent dataset) of MODOMICS-2012 for the kingdom-wise prediction performance evaluation of previously developed (in the first step) common model and achieved performances between the AUC of 0.910 to 0.949. In the third and last step, we used different datasets from MODOMICS-2012 for the kingdom-wise individual prediction models development and achieved performances between the AUC of 0.915 to 0.987.
   Conclusions: The hybrid approach is efficient not only to predict kingdom-wise modifications but also to classify them into two most prominent UMs: Pseudouridine (Y) and Dihydrouridine (D). A webserver called tRNAmod (http://crdd.osdd.net/raghava/trnamod/) has been developed, which predicts UMs from both tRNA sequences and whole genome.
RI Raghava, Gajendra P.S./AAA-2413-2022; Panwar, Bharat/H-9790-2019;
   Raghava, Gajendra/B-1717-2009
OI Raghava, Gajendra P.S./0000-0002-8902-2876; 
SN 1471-2105
PD OCT 2
PY 2014
VL 15
AR 326
DI 10.1186/1471-2105-15-326
UT WOS:000344892400001
PM 25272949
ER

PT J
AU Feng, HM
   Liao, KL
AF Feng, Hsuan-Ming
   Liao, Kuo-Lung
TI Hybrid evolutionary fuzzy learning scheme in the applications of
   traveling salesman problems
SO INFORMATION SCIENCES
AB This study develops a hybrid evolutionary fuzzy learning algorithm that automatically determines the near optimal traveling path in large-scale traveling salesman problems (LSTSPs). Identifying solutions for LSTSPs is one of the most complicated topics in the field of global combinatorial optimization problems. The proposed hybrid evolutionary fuzzy learning scheme combines the advantages of the adaptive fuzzy C-means (FCM), simple MAX-MIN merging concept, simulated annealing (SA) learning algorithm and an efficient table transform-based particle swarm optimization (TPSO). This study uses the proposed method to deal with the large-size TSP routing system.
   The evolutionary TPSO learning algorithm is applied to optimize the traveling table, which in turn extracts the appropriate traveling table sequence codes for approaching the shorter traveling path. The SA local optimal learning algorithm works after the TPSO learning scheme, using three operators to acquire the optimal traveling solution, inversion, translation and switching. The other considerable notation is to divide the large-scale cities into suitable subgroup cities to improve the efficiency of training machine. The popular FCM algorithm is a valid unsupervised clustering method that identifies the relational grades of a given traveling city dataset, separating them into popular categories. Based on the critical issue in maximal city number to break the city nodes of the traveling loop, and reconnect suitable nodes again with the minimal distance searching procedure, the proposed simple but powerful MAX-MIN merging algorithm to rebuild the new traveling path. Various sizes of TSP testing instances reveal that the developed hybrid evolutionary fuzzy learning algorithm achieves better results than other learning methods in both the quality of routing and computing time. (C) 2014 Elsevier Inc. All rights reserved.
SN 0020-0255
EI 1872-6291
PD JUN 20
PY 2014
VL 270
BP 204
EP 225
DI 10.1016/j.ins.2014.02.098
UT WOS:000335635600012
ER

PT J
AU Gunawardana, Y
   Niranjan, M
AF Gunawardana, Yawwani
   Niranjan, Mahesan
TI Bridging the gap between transcriptome and proteome measurements
   identifies post-translationally regulated genes
SO BIOINFORMATICS
AB Motivation: Despite much dynamical cellular behaviour being achieved by accurate regulation of protein concentrations, messenger RNA abundances, measured by microarray technology, and more recently by deep sequencing techniques, are widely used as proxies for protein measurements. Although for some species and under some conditions, there is good correlation between transcriptome and proteome level measurements, such correlation is by no means universal due to post-transcriptional and post-translational regulation, both of which are highly prevalent in cells. Here, we seek to develop a data-driven machine learning approach to bridging the gap between these two levels of high-throughput omic measurements on Saccharomyces cerevisiae and deploy the model in a novel way to uncover mRNA-protein pairs that are candidates for post-translational regulation.
   Results: The application of feature selection by sparsity inducing regression (l(1) norm regularization) leads to a stable set of features: i.e. mRNA, ribosomal occupancy, ribosome density, tRNA adaptation index and codon bias while achieving a feature reduction from 37 to 5. A linear predictor used with these features is capable of predicting protein concentrations fairly accurately (R-2 = 0: 86). Proteins whose concentration cannot be predicted accurately, taken as outliers with respect to the predictor, are shown to have annotation evidence of post-translational modification, significantly more than random subsets of similar size P<0.02. In a data mining sense, this work also shows a wider point that outliers with respect to a learning method can carry meaningful information about a problem domain.
OI Niranjan, Mahesan/0000-0001-7021-140X
SN 1367-4803
EI 1460-2059
PD DEC 1
PY 2013
VL 29
IS 23
BP 3060
EP 3066
DI 10.1093/bioinformatics/btt537
UT WOS:000327508300015
PM 24045772
ER

PT J
AU Mohammad, SM
   Dorr, BJ
   Hirst, G
   Turney, PD
AF Mohammad, Saif M.
   Dorr, Bonnie J.
   Hirst, Graeme
   Turney, Peter D.
TI Computing Lexical Contrast
SO COMPUTATIONAL LINGUISTICS
AB Knowing the degree of semantic contrast between words has widespread application in natural language processing, including machine translation, information retrieval, and dialogue systems. Manually created lexicons focus on opposites, such as hot and cold. Opposites are of many kinds such as antipodals, complementaries, and gradable. Existing lexicons often do not classify opposites into the different kinds, however. They also do not explicitly list word pairs that are not opposites but yet have some degree of contrast in meaning, such as warm and cold or tropical and freezing. We propose an automatic method to identify contrasting word pairs that is based on the hypothesis that if a pair of words, A and B, are contrasting, then there is a pair of opposites, C and D, such that A and C are strongly related and B and D are strongly related. (For example, there exists the pair of opposites hot and cold such that tropical is related to hot, and freezing is related to cold.) We will call this the contrast hypothesis.We begin with a large crowdsourcing experiment to determine the amount of human agreement on the concept of oppositeness and its different kinds. In the process, we flesh out key features of different kinds of opposites. We then present an automatic and empirical measure of lexical contrast that relies on the contrast hypothesis, corpus statistics, and the structure of a Roget-like thesaurus. We show how, using four different data sets, we evaluated our approach on two different tasks, solving most contrasting word questions and distinguishing synonyms from opposites. The results are analyzed across four parts of speech and across five different kinds of opposites. We show that the proposed measure of lexical contrast obtains high precision and large coverage, outperforming existing methods.
RI Hirst, Graeme/A-1825-2008; Turney, Peter/AAI-8278-2021
OI Turney, Peter/0000-0003-0909-4085; Dorr, Bonnie/0000-0003-4356-5813;
   Mohammad, Saif/0000-0003-2716-7516
SN 0891-2017
EI 1530-9312
PD SEP
PY 2013
VL 39
IS 3
BP 555
EP 590
DI 10.1162/COLI_a_00143
UT WOS:000325864800004
ER

PT J
AU Menghi, C
   Planert, J
   Melsen, B
AF Menghi, C
   Planert, J
   Melsen, B
TI 3-D experimental identification of force systems from orthodontic loops
   activated for first order corrections
SO ANGLE ORTHODONTIST
AB Intrd-arch irregularities can be corrected using wire of low stiffness, wires of increasing stiffnesses, or by the activation of loops built into the appliance. While the orthodontist controls only the magnitude of force when leveling with continuous arches, the configuration and positioning of loops offer the possibility of controlling the type and direction of force. In the present study, force systems developed by the L-loop, the T-looy, and the rectangular (R-) loop were analyzed with respect to the force systems acting for first order irregularities, buccolingual movement, and rotation along the long axis of the tooth. An interbracket distance of 21 mm was chosen, and the loops were analyzed in a testing machine that made it possible to register forces and moments simultaneously in three planes of space. The activations included a symmetrical translation of 1 mm made in steps of .2 mm, corresponding to a buccolingual movement, and 10-degree rotations clockwise and counterclockwise in steps of one degree. Force systems were recorded during activation and de activation. Loops made of TMA wire delivered 40% of the force delivered by the same loops made of stainless steel wire. The T-loop generated a force system that deviated qualitatively only slightly from that delivered by a straight wire, The L-loop generated a force system that was dependent on orientation; constancy was better corresponding to the anterior part of the loop. It was evident that the rectangular loop was capable of generating any desired moment-to-force ratio, and the R-loop demonstrated a high degree of constancy of the force system. Rectangular loops should, therefore, be preferred for making first order corrections.
SN 0003-3219
PD FEB
PY 1999
VL 69
IS 1
BP 49
EP 57
UT WOS:000078406800015
PM 10022185
ER

PT J
AU Thukroo, IA
   Bashir, R
   Giri, KJ
AF Thukroo, Irshad Ahmad
   Bashir, Rumaan
   Giri, Kaiser J.
TI Spoken Language Identification Using Prosody, Phonotactics, and
   Acoustics: A Review
SO JOURNAL OF INFORMATION & KNOWLEDGE MANAGEMENT
AB Spoken language identification (LID) is the identification of language present in a speech segment despite its size (duration and speed), ambiance (topic and emotion), and moderator (gender, age, demographic region). Information Technology has touched new vistas for a couple of decades mostly to simplify the day-to-day life of humans. One of the key contributions of Information Technology is the application of Artificial Intelligence to achieve better results. The advent of artificial intelligence has given rise to a new branch of Natural Language Processing (NLP) called Computational Linguistics, which generates frameworks for intelligently manipulating spoken language knowledge and has brought human- machine into a new stage. In this context, speech has arisen to be one of the imperative forms of interfaces, which is the basic mode of communication for us, and generally the most preferred one. Recognition of the spoken language is a frontend for several technologies, like multiple languages conversation systems, expressed translation software, multilingual speech recognition, spoken word extraction, speech production systems. This paper reviews and summarises the different levels of information that can be used for language identification. A broad study of acoustic, phonetic, and prosody features has been provided and various classifiers have been used for spoken language identification specifically for Indian languages. This paper has investigated various existing spoken language identification models implemented using prosodic, phonotactic, acoustic, and deep learning approaches, the datasets used, and performance measures utilized for their analysis. It also highlights the main features and challenges faced by these models. Moreover, this review analyses the efficiency of the spoken language models that can help the researchers to propose new language identification models for speech signals.
OI Giri, Kaiser/0000-0001-8792-5011
SN 0219-6492
EI 1793-6926
PD DEC
PY 2022
VL 21
IS 04
AR 2250057
DI 10.1142/S0219649222500575
EA JUL 2022
UT WOS:000848599300001
ER

PT J
AU Rafudeen, A
AF Rafudeen, Auwais
TI Cultivating the worshipful self in an algorithmic age: Reflections on an
   Asadian conclusion
SO HTS TEOLOGIESE STUDIES-THEOLOGICAL STUDIES
AB In a recent book, Secular Translations: Nation State, Modern State and Calculative Reason, Talal Asad is concerned with how the language of calculation and abstraction, inaugurated by modernity and accelerated by our current algorithmic reality, erodes the language of cultivated embodiment typical of religious worldviews and the virtues that such embodiment seeks to develop. These languages are predicated upon and cultivate different types of selves that are fundamentally at variance with each other. It is not that that one cannot cultivate the worshipful, virtuous self in our algorithmic reality, but Asad???s pessimistic conclusion is that the conditions for such cultivation are being made increasingly difficult as we seemingly hasten towards a posthuman future. Asad here echoes thinkers such as Leon Kass and Michael Sandel who have also expressed disquiet about the loss of cultivated embodiment in such a future, but in an important meta sense, he goes beyond them by interrogating the underlying language we use to frame our discussions in this area. The purpose of this article is to bring an awareness to this Asadian argument, which, I believe, should at the very least give us some pause for thought as technology plunges us into new and unknowing horizons. Contribution: Despite the many laudable accomplishments of modernity in the techno-scientific sphere, vital questions remain about its ability to bring about overall human flourishing. Among others, the thought of Talal Asad provides a way to think about why the promised potential of modernity in this regard has not been realised and, concomitantly, why traditional, embodied teachings of religion continue to be critical in thinking about the future.
OI Rafudeen, Auwais/0000-0001-5443-1461
SN 0259-9422
EI 2072-8050
PD APR 11
PY 2022
VL 78
IS 4
AR a7247
DI 10.4102/hts.v78i4.7247
UT WOS:000798213600001
ER

PT J
AU Basu, D
   Jain, A
   Ghosh, U
   Datta, R
AF Basu, Deborsi
   Jain, Abhishek
   Ghosh, Uttam
   Datta, Raja
TI A Reverse Path-Flow Mechanism for Latency Aware Controller Placement in
   vSDN Enabled 5G Network
SO IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS
AB Long distance communication links may severely affect the cyber-physical systems (CPSs) in 5G (and future 6G) networks and degrade its reliability and resilience by disrupting the quality index of network latency. Further, centralized network architectures have low fault tolerance and are prone to security threats. Virtualized software defined network (vSDN)-enabled 5G networks closely monitor these facts and redefine the existing network topology to find potential locations for deploying controller and hypervisor instances. In this article, we propose an approach of dynamically deploying controller-hypervisor (C-H) pair(s) to provide a variety of network functions like differentiation between control and data signals, various translation functions, etc., with ultra low latency (ULL). The system model deals with real network topology and four well-defined network latency matrices with a mixed integer linear programming model to optimize latency objectives. A reverse path-flow mechanism (RPFM) has been proposed to provide feasible solutions by keeping the network load, and controller capacity under a tolerance limit. We have further minimized the H-plane load by distributing the network resources based on the arrival time of SERVICE_IN requests from the users. Simulation results show that our proposed technique achieves significant reduction in latency and an evolved-ULL (e-ULL) experience, where all real-time user demands are handled efficiently. The proposed approach can also be used for similar critical localization problems like service chain mapping in 5G-NR, baseband unit deployment in 5G C-RAN and firewall deployment in distributed CPS.
RI BASU, DEBORSI/AAU-1760-2020; Ghosh, Uttam/CAF-9098-2022; Ghosh,
   Uttam/CAI-5749-2022
OI BASU, DEBORSI/0000-0002-0089-9656; Ghosh, Uttam/0000-0003-1698-8888;
   Ghosh, Uttam/0000-0003-1698-8888; Datta, Raja/0000-0001-8851-9381; Jain,
   Abhishek/0000-0001-5369-5625
SN 1551-3203
EI 1941-0050
PD OCT
PY 2021
VL 17
IS 10
BP 6885
EP 6893
DI 10.1109/TII.2020.3046565
UT WOS:000673414500031
ER

PT J
AU Ren, Z
   Liu, T
   Liu, GD
AF Ren, Zhong
   Liu, Tao
   Liu, Guodong
TI Classification and discrimination of real and fake blood based on
   photoacoustic spectroscopy combined with particle swarm optimized
   wavelet neural networks
SO PHOTOACOUSTICS
AB In this work, photoacoustic spectroscopy was employed to distinguish real blood from fake blood rapidly, accurately, and recoverably. To achieve this goal, a photoacoustic detection system for blood was established in the forward mode. In the experiments, four kinds of animal blood and two kinds of fake blood in a total of 150 groups were used. The time-resolved photoacoustic signal and peak-to-peak values (PPVs) of all blood were captured in 700-1064 nm with intervals of 5 nm. Experimental results show that the amplitudes, profiles, peakpoint time, and PPVs are different between real and fake blood. Although the PPVs of real blood are larger than those of the fake ones at 700-850 nm, the differences in PPVs are not obvious at 850-1064 nm, especially when there are spectral overlaps of PPVs. To accurately classify and discriminate real and fake blood, a wavelet neural network (WNN) was used to train 120 groups of blood and test 30 groups of blood. Moreover, the particle swarm optimization (PSO) algorithm was used to optimize the weights and thresholds, as well as the translation and scale factors of the Morlet-liked wavelet basis function of the WNN. Under optimal parameters, the correct rate of the WNN-PSO algorithm was improved from 63.3% to 96.7%. Next, principal component analysis (PCA) was combined into the WNN-PSO algorithm to further improve the correct rate. The results indicate that the correct rate of the PCA-WNN-PSO algorithm with 10 principal components reaches 100 %. Therefore, photoacoustic spectroscopy combined with the PCA-WNN-PSO algorithm exhibits excellent performance in the classification and discrimination of real and fake blood.
SN 2213-5979
PD SEP
PY 2021
VL 23
AR 100278
DI 10.1016/j.pacs.2021.100278
EA JUN 2021
UT WOS:000687229000006
PM 34141580
ER

PT J
AU Hynst, J
   Navrkalova, V
   Pal, K
   Pospisilova, S
AF Hynst, Jakub
   Navrkalova, Veronika
   Pal, Karol
   Pospisilova, Sarka
TI Bioinformatic strategies for the analysis of genomic aberrations
   detected by targeted NGS panels with clinical application
SO PEERJ
AB Molecular profiling of tumor samples has acquired importance in cancer research, but currently also plays an important role in the clinical management of cancer patients. Rapid identification of genomic aberrations improves diagnosis, prognosis and effective therapy selection. This can be attributed mainly to the development of next-generation sequencing (NGS) methods, especially targeted DNA panels. Such panels enable a relatively inexpensive and rapid analysis of various aberrations with clinical impact specific to particular diagnoses. In this review, we discuss the experimental approaches and bioinformatic strategies available for the development of an NGS panel for a reliable analysis of selected biomarkers. Compliance with defined analytical steps is crucial to ensure accurate and reproducible results. In addition, a careful validation procedure has to be performed before the application of NGS targeted assays in routine clinical practice. With more focus on bioinformatics, we emphasize the need for thorough pipeline validation and management in relation to the particular experimental setting as an integral part of the NGS method establishment. A robust and reproducible bioinformatic analysis running on powerful machines is essential for proper detection of genomic variants in clinical settings since distinguishing between experimental noise and real biological variants is fundamental. This review summarizes state-of-the-art bioinformatic solutions for careful detection of the SNV/Indels and CNVs for targeted sequencing resulting in translation of sequencing data into clinically relevant information. Finally, we share our experience with the development of a custom targeted NGS panel for an integrated analysis of biomarkers in lymphoproliferative disorders.
RI Hynst, Jakub/HPE-0457-2023; Pál, Karol/E-3031-2012; Navrkalova,
   Veronika/E-1331-2012
OI Hynst, Jakub/0000-0002-0079-845X; Navrkalova,
   Veronika/0000-0003-3020-1578; Pospisilova, Sarka/0000-0001-7136-2680
SN 2167-8359
PD MAR 31
PY 2021
VL 9
AR e10897
DI 10.7717/peerj.10897
UT WOS:000635103900002
PM 33850640
ER

PT J
AU Tahir, M
   Hayat, M
   Khan, S
   Chong, KT
AF Tahir, Muhammad
   Hayat, Maqsood
   Khan, Shahzad
   Chong, Kil To
TI Prediction of Piwi-Interacting RNAs and Their Functions via
   Convolutional Neural Network
SO IEEE ACCESS
AB In eukaryotic cells, Piwi-interacting RNAs (piRNAs) are the type of short chain non-coding RNA molecules, which interconnect with PIWI proteins. It performs various cellular and genetic functions such as gene-specific protein translation, expression regulation, maintenance, and formulation of germ cells. Seeing the prominent contribution of piRNA in eukaryotic organism cells, many attempts were made to identify it computationally, however, unsatisfactory results were obtained. So, it is requisite to extend the concept of a computational tool in such a way that accurately represents piRNA. In this regard, intelligent and high discriminative deep learning i.e., the convolutional neural network based sequential-computational model known as "piRNA-CNN" is carried out for the prediction of piRNA. RNA sequences are mathematically expressed using the natural language processing method namely: word2vec in order to get prominent, relevant, and high variated numerical descriptors. The proposed "piRNA-CNN" model yields an accuracy of 93.83% for the first-layer in which the provided query RNA molecule is predicted as non-piRNA or piRNA. In case of the piRNA, the proposed model identified the query as mRNA deadenylation or without deadenylation in the second layer, and achieved 91.19% of accuracy. The obtained outcomes authenticated that the piRNA-CNN model exposed substantial results matched to the current tools stated in the literature, so far. It is further expected that the suggested predictive tool will assist scientists and researchers to design improved computational tools.
RI Hayat, Maqsood/ABB-7275-2021; Hayat, Maqsood/M-5941-2018
OI Hayat, Maqsood/0000-0001-5456-2664
SN 2169-3536
PY 2021
VL 9
BP 54233
EP 54240
DI 10.1109/ACCESS.2021.3070083
UT WOS:000640997600001
ER

PT J
AU Josephson, CB
   Wiebe, S
AF Josephson, Colin B.
   Wiebe, Samuel
TI Precision Medicine: Academic dreaming or clinical reality?
SO EPILEPSIA
AB Precision medicine can be distilled into a concept of accounting for an individual's unique collection of clinical, physiologic, genetic, and sociodemographic characteristics to provide patient-level predictions of disease course and response to therapy. Abundant evidence now allows us to determine how an average person with epilepsy will respond to specific medical and surgical treatments. This is useful, but not readily applicable to an individual patient. This has brought into sharp focus the desire for a more individualized approach through which we counsel people based on individual characteristics, as opposed to population-level data. We are now accruing data at unprecedented rates, allowing us to convert this ideal into reality. In addition, we have access to growing volumes of administrative and electronic health records data, biometric, imaging, genetics data, microbiome, and other "omics" data, thus paving the way toward phenome-wide association studies and "the epidemiology of one." Despite this, there are many challenges ahead. The collating, integrating, and storing sensitive multimodal data for advanced analytics remains difficult as patient consent and data security issues increase in complexity. Agreement on many aspects of epilepsy remains imperfect, rendering models sensitive to misclassification due to a lack of "ground truth." Even with existing data, advanced analytics models are prone to overfitting and often failure to generalize externally. Finally, uptake by clinicians is often hindered by opaque, "black box" algorithms. Systematic approaches to data collection and model generation, and an emphasis on education to promote uptake and knowledge translation, are required to propel epilepsy-based precision medicine from the realm of the theoretical into routine clinical practice.
OI Josephson, Colin/0000-0001-7052-1651
SN 0013-9580
EI 1528-1167
PD MAR
PY 2021
VL 62
SU 2
SI SI
BP S78
EP S89
DI 10.1111/epi.16739
EA NOV 2020
UT WOS:000589929800001
PM 33205406
ER

PT J
AU Zwanenburg, A
AF Zwanenburg, Alex
TI Radiomics in nuclear medicine: robustness, reproducibility,
   standardization, and how to avoid data analysis traps and replication
   crisis
SO EUROPEAN JOURNAL OF NUCLEAR MEDICINE AND MOLECULAR IMAGING
AB Radiomics in nuclear medicine is rapidly expanding. Reproducibility of radiomics studies in multicentre settings is an important criterion for clinical translation. We therefore performed a meta-analysis to investigate reproducibility of radiomics biomarkers in PET imaging and to obtain quantitative information regarding their sensitivity to variations in various imaging and radiomics-related factors as well as their inherent sensitivity. Additionally, we identify and describe data analysis pitfalls that affect the reproducibility and generalizability of radiomics studies. After a systematic literature search, 42 studies were included in the qualitative synthesis, and data from 21 were used for the quantitative meta-analysis. Data concerning measurement agreement and reliability were collected for 21 of 38 different factors associated with image acquisition, reconstruction, segmentation and radiomics-specific processing steps. Variations in voxel size, segmentation and several reconstruction parameters strongly affected reproducibility, but the level of evidence remained weak. Based on the meta-analysis, we also assessed inherent sensitivity to variations of 110 PET image biomarkers. SUVmean and SUVmax were found to be reliable, whereas image biomarkers based on the neighbourhood grey tone difference matrix and most biomarkers based on the size zone matrix were found to be highly sensitive to variations, and should be used with care in multicentre settings. Lastly, we identify 11 data analysis pitfalls. These pitfalls concern model validation and information leakage during model development, but also relate to reporting and the software used for data analysis. Avoiding such pitfalls is essential for minimizing bias in the results and to enable reproduction and validation of radiomics studies.
RI Zwanenburg, Alex/AAF-6476-2020
OI Zwanenburg, Alex/0000-0002-0342-9545
SN 1619-7070
EI 1619-7089
PD DEC
PY 2019
VL 46
IS 13
BP 2638
EP 2655
DI 10.1007/s00259-019-04391-8
UT WOS:000502971900003
PM 31240330
ER

PT J
AU Alneamy, JSM
   Alnaish, ZAH
   Hashim, SZM
   Alnaish, RAH
AF Alneamy, Jamal Salahaldeen Majeed
   Alnaish, Zakaria A. Hameed
   Hashim, S. Z. Mohd
   Alnaish, Rahma A. Hamed
TI Utilizing hybrid functional fuzzy wavelet neural networks with a
   teaching learning-based optimization algorithm for medical disease
   diagnosis
SO COMPUTERS IN BIOLOGY AND MEDICINE
AB Accurate medical disease diagnosis is considered to be an important classification problem. The main goal of the classification process is to determine the class to which a certain pattern belongs. In this article, a new classification technique based on a combination of The Teaching Learning-Based Optimization (TLBO) algorithm and Fuzzy Wavelet Neural Network (FWNN) with Functional Link Neural Network (FLNN) is proposed. In-addition, the TLBO algorithm is utilized for training the new hybrid Functional Fuzzy Wavelet Neural Network (FFWNN) and optimizing the learning parameters, which are weights, dilation and translation. To evaluate the performance of the proposed method, five standard medical datasets were used: Breast Cancer, Heart Disease, Hepatitis, Pima-Indian diabetes and Appendicitis. The efficiency of the proposed method is evaluated using 5 fold cross-validation and 10-fold cross-validation in terms of mean square error (MSE), classification accuracy, running time, sensitivity, specificity and kappa. The experimental results show that the efficiency of the proposed method for the medical classification problems is 98.309%, 91.1%, 91.39%, 88.67% and 93.51% for the Breast Cancer, Heart Disease, Hepatitis, Pima-Indian diabetes and Appendicitis datasets, respectively, in terms of accuracy after 30 runs for each dataset with low computational complexity. In addition, it has been observed that the proposed method has efficient performance compared with the performance of other methods found in the related previous studies.
RI Hamed, Zakaria/CAJ-4578-2022; Hashim, Siti Zaiton Mohd/AAE-5401-2020;
   Alnaish, Zakaria/ABE-5362-2020
OI Hamed, Zakaria/0000-0002-7597-5326; Alnaish, Rahma A/0000-0001-5068-1519
SN 0010-4825
EI 1879-0534
PD SEP
PY 2019
VL 112
AR 103348
DI 10.1016/j.compbiomed.2019.103348
UT WOS:000487566700005
PM 31356992
ER

PT J
AU Shin, DK
AF Shin, Dong-Kil
TI Verification of the performance of rotatable jig for a single cantilever
   beam method using the finite element analysis
SO JOURNAL OF MECHANICAL SCIENCE AND TECHNOLOGY
AB The performance of new jig for single cantilever beam test method was verified by finite element analysis. Two types of jig were designed for a small specimen that had relatively short length compared to the width of cantilever; one was simple fixed jig and the other was specially designed rotatable jig. The rotatable jig has a rotatable seesaw which adjusts the experimental misalignments between the specimen and test machine. Among the three translational and three rotational misalignments, following three important factors were considered; rotation about x-axis, rotation about z-axis, and translation in y-axis. Adhesive layer was modeled by cohesive zone element, and crack propagation behavior and the deviation of energy release rate were investigated. The fixed jig showed undesired asymmetric crack propagation and large deviation of energy release rate when it had rotational misalignment about x-axis. However, the proposed new rotatable jig showed almost symmetrical crack propagation and small deviation of energy release rate regardless of misalignments. Rotational motion of the seesaw automatically compensated the rotational misalignment of the specimen. The rotatable jig also showed relatively small deviation of energy release rate compared with the fixed jig by the rotational misalignment about the z-axis. In contrast, the rotatable jig showed deviation of energy release rate by translational misalignments in the y-axis. However, the magnitude of the deviation was very small within the controllable range of experimental misalignment. In conclusion, it was found out that the proposed jig was appropriate for the measurement of adhesion of a small specimen by single cantilever beam method.
SN 1738-494X
EI 1976-3824
PD FEB
PY 2017
VL 31
IS 2
BP 777
EP 784
DI 10.1007/s12206-017-0129-x
UT WOS:000395121500030
ER

PT J
AU Shao, MW
   Wei, ZZ
   Hu, MJ
   Zhang, GJ
AF Shao, Mingwei
   Wei, Zhenzhong
   Hu, Mengjie
   Zhang, Guangjun
TI Calibration method for a vision guiding-based laser-tracking measurement
   system
SO MEASUREMENT SCIENCE AND TECHNOLOGY
AB Laser-tracking measurement systems (laser trackers) based on a vision-guiding device are widely used in industrial fields, and their calibration is important. As conventional methods typically have many disadvantages, such as difficult machining of the target and overdependence on the retroreflector, a novel calibration method is presented in this paper. The retroreflector, which is necessary in the normal calibration method, is unnecessary in our approach. As the laser beam is linear, points on the beam can be obtained with the help of a normal planar target. In this way, we can determine the function of a laser beam under the camera coordinate system, while its corresponding function under the laser-tracker coordinate system can be obtained from the encoder of the laser tracker. Clearly, when several groups of functions are confirmed, the rotation matrix can be solved from the direction vectors of the laser beams in different coordinate systems. As the intersection of the laser beams is the origin of the laser-tracker coordinate system, the translation matrix can also be determined. Our proposed method not only achieves the calibration of a single laser-tracking measurement system but also provides a reference for the calibration of a multistation system. Simulations to evaluate the effects of some critical factors were conducted. These simulations show the robustness and accuracy of our method. In real experiments, the root mean square error of the calibration result reached 1.46 mm within a range of 10 m, even though the vision-guiding device focuses on a point approximately 5 m away from the origin of its coordinate system, with a field of view of approximately 200 mm x 200 mm.
SN 0957-0233
EI 1361-6501
PD AUG
PY 2015
VL 26
IS 8
AR 085009
DI 10.1088/0957-0233/26/8/085009
UT WOS:000362220900020
ER

PT J
AU Libert, A
   Wittevrongel, B
   Camarrone, F
   Van Hulle, MM
AF Libert, Arno
   Wittevrongel, Benjamin
   Camarrone, Flavio
   Van Hulle, Marc M.
TI Phase-Spatial Beamforming Renders a Visual Brain Computer Interface
   Capable of Exploiting EEG Electrode Phase Shifts in Motion-Onset Target
   Responses
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
AB Objective: in this work, we aim to develop a more efficient visual motion-onset based Brain-computer interface (BCI). Brain-computer interfaces provide communication facilities that do not rely on the brain's usual pathways. Visual BCIs are based on changes in EEG activity in response to attended flashing or flickering targets. A less taxing way to encode such targets is with briefly moving stimuli, the onset of which elicits a lateralized EEG potential over the parieto-occipital scalp area called the motion-onset visual evoked potential (mVEP). Methods: We recruited 21 healthy subjects for an experiment in which motion-onset stimulations translating leftwards (LT) or rightwards (RT) were encoding 9 displayed targets. We propose a novel algorithm that exploits the phase-shift between EEG electrodes to improve target decoding performance. We hereto extend the spatiotemporal beamformer (stBF) with a phase extracting procedure, leading to the phase-spatial beamformer (psBF). Results: we show that psBF performs significantly better than the stBF (p < 0.001 for 1 and 2 stimulus repetitions and p < 0.01 for 3 to 5 stimulus repetitions), as well as the previously validated linear support-vector machines (p < 0.001 for 5 stimulus repetitions and p < 0.01 for 1,2 and 6 stimulus repetitions) and stepwise linear discriminant analysis decoders (p < 0.001 for all repetitions) when simultaneously addressing timing and translation direction. Conclusion: We provide evidence of decodability of joint direction and target in mVEP responses. Significance: the described methods can aid in the development of a faster and more comfortable BCI based on mVEPs.
OI Libert, Arno/0000-0002-1939-982X
SN 0018-9294
EI 1558-2531
PD MAY
PY 2022
VL 69
IS 5
BP 1802
EP 1812
DI 10.1109/TBME.2021.3136938
UT WOS:000803112800029
PM 34932468
ER

PT J
AU Sobez, LM
   Kim, SH
   Angstwurm, M
   Stormann, S
   Pforringer, D
   Schmidutz, F
   Prezzi, D
   Kelly-Morland, C
   Sommer, WH
   Sabel, B
   Norenberg, D
   Berndt, M
   Galie, F
AF Sobez, L. M.
   Kim, S. H.
   Angstwurm, M.
   Stoermann, S.
   Pfoerringer, D.
   Schmidutz, F.
   Prezzi, D.
   Kelly-Morland, C.
   Sommer, W. H.
   Sabel, B.
   Noerenberg, D.
   Berndt, M.
   Galie, F.
TI Creating high-quality radiology reports in foreign languages through
   multilingual structured reporting
SO EUROPEAN RADIOLOGY
AB Objectives Globalization and migration are increasing the demand for reports in different languages. We aimed to examine if structured reports created by non-German-speaking radiologists with multilingual templates show significant differences in quality to structured reports and free-text reports by German native speakers. Methods We used structured templates that allow radiologists to report in their mother tongue and then switch the report language to German or English automatically using proprietary software. German- and English-speaking radiology residents created structured reports in both German and English with these templates. Reports for three different exam types were created (intensive care chest x-ray, shoulder x-ray specifically for degenerative processes, and CT pulmonary angiogram for pulmonary embolism). The report quality of automatically translated German structured reports by English-speaking radiologists and German structured reports by German radiologists was then evaluated by German clinicians with a standardized questionnaire. The questionnaire was designed to assess attributes including content, comprehensibility, clinical consequences, and overall quality. Results Structured reports by English-speaking radiologists that were automatically translated into German and German structured reports by German radiologists both received very high or high overall quality ratings in the majority of cases, showing no significant differences in quality. Likewise, no significant differences were observed between the two report types regarding comprehensibility and clinical consequences. Structured reports by German radiologists received significantly better ratings for overall quality and comprehensibility compared to free-text reports by German radiologists. Conclusions Multilingual structured reporting templates may serve as a feasible tool for creating high-quality radiology reports in foreign languages.
RI Prezzi, Davide/AAZ-2219-2020; Pförringer, PD Dr. med.
   Dominik/AAI-2368-2019
OI Pförringer, PD Dr. med. Dominik/0000-0002-0682-8293
SN 0938-7994
EI 1432-1084
PD NOV
PY 2019
VL 29
IS 11
BP 6038
EP 6048
DI 10.1007/s00330-019-06206-8
UT WOS:000490625400032
PM 31028444
ER

PT J
AU Toporisic, T
AF Toporisic, Tomaz
TI Spatial Machines of the Theatre as the Dynamics of Crossing the
   Boundaries of Semiotic Systems
SO ARS & HUMANITAS
AB On the basis of a study of six examples from contemporary theatre and performing arts, the essay will examine how Lotman's concept of the semiosphere as an ecosystem covering both the space and time of performance can be applied to the environmental, economic and political aspects of the theatrical within the post-colonial and intercultural space. His notion of the semiosphere as a spatio-temporal phenomenon, a combination of different (non)verbal languages that are in constant dialogue with one another, will be used for the analysis of spatial relations and space policies within contemporary performing arts in order to discover how the act of mise en scene creates semiotic languages, which are not a simple sum of individual systems, but are characterised as a dynamic interactivity, establishing the theatrical event. The subject of the analysis will be theatrical performances as semiotic spaces of transitional forms that arise between different media, the crossing of the boundaries between the stage and the auditorium, changes in the dynamics of relations between actors and spectators within the process of creation and reception. We will link Lotman's "theatre's position as an intermediary between the moving and nondiscrete real world and the immobile and discrete world of the representational arts" (Lotman, Universe of the Mind) to Jacques Ranciere's notion of an emancipated spectator and Nicolas Bourriaud's notion of translation, art as an exploration of the bonds that engulf the word and picture, time, and space. Our aim will be to research the dynamics of semiotic languages within space, the interactivity they establish within performative practice.
RI Toporišič, Tomaž/AAG-2075-2019
OI Toporišič, Tomaž/0000-0001-9636-9635
SN 1854-9632
EI 2350-4218
PY 2019
VL 13
IS 2
BP 268
EP 284
DI 10.4312/ars.13.2.268-284
UT WOS:000504899500017
ER

PT J
AU Bach, NX
   Linh, ND
   Phuong, TM
AF Ngo Xuan Bach
   Nguyen Dieu Linh
   Tu Minh Phuong
TI An empirical study on POS tagging for Vietnamese social media text
SO COMPUTER SPEECH AND LANGUAGE
AB Part-of-speech (POS) tagging is a fundamental task in natural language processing (NLP). A robust POS tagger plays an important role in most NLP problems and applications, including syntactic parsing, semantic parsing, machine translation, and question answering. Although a lot of efficient POS taggers has been developed for general, conventional text, little work has been done for social media text. In this paper, we present an empirical study on POS tagging for Vietnamese social media text, which shows several challenges compared with tagging for general text. Social media text does not always conform to formal grammars and correct spelling. It also uses abbreviations, foreign words, and emoticons frequently. A POS tagger developed for conventional text would perform poorly on such noisy data. We address this problem by proposing a tagging model based on Conditional Random Fields (CRFs) with various kinds of features for Vietnamese social media text. We also investigate the effect of features extracted from word clusters under the Brown and canonical correlation analysis (CCA) based clustering in semi-supervised settings. We introduce an annotated corpus for POS tagging, which consists of more than four thousand sentences from Facebook, the most popular social network in Vietnam. Using this corpus, we performed a series of experiments to evaluate the proposed model. Our model achieved 88.26% and 88.92% tagging accuracy in supervised and semi-supervised scenarios, respectively, which are nearly 12% improvement over vnTagger, a state-of-the-art and most widely used Vietnamese POS tagger developed for general, conventional text. In addition, the semi-supervised model outperformed, in terms of accuracy, the version of vnTagger trained on the same Facebook dataset, showing the usefulness of word cluster features.' (C) 2017 Elsevier Ltd. All rights reserved.
RI Furtado, Kássia/AAU-5007-2020; Phuong, Tu Minh/Q-4204-2019
OI Phuong, Tu Minh/0000-0001-6415-228X
SN 0885-2308
EI 1095-8363
PD JUL
PY 2018
VL 50
BP 1
EP 15
DI 10.1016/j.csl.2017.12.004
UT WOS:000427479600001
ER

PT J
AU Wetter, R
   Popov, VL
AF Wetter, Robbin
   Popov, Valentin L.
TI The Influence of System Dynamics on the Frictional Resistance: Insights
   from a Discrete Model
SO TRIBOLOGY LETTERS
AB In order to examine the influence of system dynamics on sliding friction, we introduce the so-called micro-walking machine. This model consists of a rigid body with a number of elastic contact spots that is pulled by a constantly moving base. The system slides with dry friction on a rigid substrate. The kinematic coupling of the rotation and the translation of the rigid body results in varying normal and tangential forces at the contact spots. For certain parameter ranges, this leads to self-excited oscillations in the vertical direction. A particular dynamic mode occurs which is characterized by a strong correlation between low or even zero normal forces and a fast-forward motion. This effect is referred to as micro-walking. In addition to an experimental rig, we use numerical integration and an extensive parameter study for the analysis. In theory, the reduction in the frictional resistance reaches up to 98 %. These results are confirmed by the experiments where the maximal reduction was 73 %. Our model shows that micro-vibrations play an important role for the dynamic influences on the frictional resistance of systems that exhibit apparently smooth sliding. The identification of the critical parameter range enables the systematic control of frictional resistance through the adjustment of attributes such as geometry and stiffness. In addition, it is possible to deduce guidelines for how tribological test rigs should be designed in order to get reliable results.
RI Popov, Valentin L./I-5041-2012
OI Popov, Valentin L./0000-0003-0506-3804
SN 1023-8883
EI 1573-2711
PD FEB
PY 2016
VL 61
IS 2
AR 15
DI 10.1007/s11249-015-0635-x
UT WOS:000368597500004
ER

PT C
AU Gong, TX
   Li, SM
   Tan, CL
AF Gong, Tianxia
   Li, Shimiao
   Tan, Chew Lim
BE Gregoire, E
TI A Semantic Similarity Language Model to Improve Automatic Image
   Annotation
SO 22ND INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE
   (ICTAI 2010), PROCEEDINGS, VOL 1
SE Proceedings-International Conference on Tools With Artificial
   Intelligence
CT 22nd International Conference on Tools with Artificial Intelligence
CY OCT 27-29, 2010
CL Arras, FRANCE
SP CPS, IEEE Comp Soc, Biolog & Artificial Intelligence Soc
AB In recent years, with the rapid proliferation of digital images, the need to search and retrieve the images accurately, efficiently, and conveniently is becoming more acute. Automatic image annotation with image semantic content has attracted increasing attention, as it is the preprocess of annotation based image retrieval which provides users accurate, efficient, and convenient image retrieval with image understanding. Different machine learning approaches have been used to tackle the problem of automatic image annotation; however, most of them focused on exploring the relationship between images and annotation words and neglected the relationship among the annotation words. In this paper, we propose a framework of using language models to represent the word-to-word relation and thus to improve the performance of existing image annotation approaches utilizing probabilistic models. We also propose a specific language model - the semantic similarity language model to estimate the semantic similarity among the annotation words so that annotations that are more semantically coherent will have higher probability to be chosen to annotate the image. To illustrate the general idea of using language model to improve current image annotation systems, we added the language model on top of the two specific image annotation models - the translation model (TM) and the cross media relevance model (CMRM). We tested the improved models on a widely used image annotation corpus - the Corel 5K dataset. Our results show that by adding the semantic similarity language model, the performance of image annotation improves significantly in comparison with the original models. Our proposed language model can also be applied to other image annotation approaches using word probability conditioned on image or word-image joint probability as well.
SN 1082-3409
BN 978-0-7695-4263-8
PY 2010
DI 10.1109/ICTAI.2010.35
UT WOS:000287041000027
ER

PT J
AU Knowlton, JR
   Bubunenko, M
   Andrykovitch, M
   Guo, W
   Routzahn, KM
   Waugh, DS
   Court, DL
   Ji, XH
AF Knowlton, JR
   Bubunenko, M
   Andrykovitch, M
   Guo, W
   Routzahn, KM
   Waugh, DS
   Court, DL
   Ji, XH
TI A spring-loaded state of NusG in its functional cycle is suggested by
   X-ray crystallography and supported by site-directed mutants
SO BIOCHEMISTRY
AB Transcription factor NusG is present in all prokaryotes, and orthologous proteins have also been identified in yeast and humans. NusG contains a 27-residue KOW motif, found in ribosomal protein L24 where it interacts with rRNA. NusG in Escherichia coli (EcNusG) is an essential protein and functions as a regulator of Rho-dependent transcription termination, phage lambda N and rRNA transcription antitermination, and phage HK022 Nun termination. Relative to EcNusG, Aquifex aeolicus NusG (AaNusG). and several other bacterial NusG proteins contain a variable insertion sequence of similar to70 residues in the central region of the molecule. Recently, crystal structures of AaNusG in space groups P2(1) and I222 have been reported; the authors conclude that there are no conserved dimers among the contacting molecules in the crystals [Steiner, T., Kaiser, J. T., Marinkovic, S., Huber, R., and Wahl, M. C. (2002) EMBO J. 21, 4641-4653]. We have independently determined the structures of AaNusG also in two crystal forms, P2(1) and C222(1), and surprisingly found that AaNusG molecules form domain-swapped dimers in both crystals. Additionally, polymerization is also observed in the P2(1) crystal. A unique "ball-and-socket" junction dominates the intermolecular interactions within both oligomers. We believe that this interaction is a clue to the function of the molecule and propose a spring-loaded state in the functional cycle of NusG. The importance of the ball-and-socket junction for the function of NusG is supported by the functional analysis of site-directed mutants.
RI Ji, Xinhua/C-9664-2012
OI Ji, Xinhua/0000-0001-6942-1514
SN 0006-2960
PD MAR 4
PY 2003
VL 42
IS 8
BP 2275
EP 2281
DI 10.1021/bi0272508
UT WOS:000181193100003
PM 12600194
ER

PT J
AU Walters, WP
   Barzilay, R
AF Walters, W. Patrick
   Barzilay, Regina
TI Applications of Deep Learning in Molecule Generation and Molecular
   Property Prediction
SO ACCOUNTS OF CHEMICAL RESEARCH
AB CONSPECTUS: Recent advances in computer hardware and software have led to a revolution in deep neural networks that has impacted fields ranging from language translation to computer vision. Deep learning has also impacted a number of areas in drug discovery, including the analysis of cellular images and the design of novel routes for the synthesis of organic molecules. While work in these areas has been impactful, a complete review of the applications of deep learning in drug discovery would be beyond the scope of a single Account. In this Account, we will focus on two key areas where deep learning has impacted molecular design: the prediction of molecular properties and the de novo generation of suggestions for new molecules.
   One of the most significant advances in the development of quantitative structure-activity relationships (QSARs) has come from the application of deep learning methods to the prediction of the biological activity and physical properties of molecules in drug discovery programs. Rather than employing the expert-derived chemical features typically used to build predictive models, researchers are now using deep learning to develop novel molecular representations. These representations, coupled with the ability of deep neural networks to uncover complex, nonlinear relationships, have led to state-of-the-art performance. While deep learning has changed the way that many researchers approach QSARs, it is not a panacea. As with any other machine learning task, the design of predictive models is dependent on the quality, quantity, and relevance of available data. Seemingly fundamental issues, such as optimal methods for creating a training set, are still open questions for the field. Another critical area that is still the subject of multiple research efforts is the development of methods for assessing the confidence in a model.
   Deep learning has also contributed to a renaissance in the application of de novo molecule generation. Rather than relying on manually defined heuristics, deep learning methods learn to generate new molecules based on sets of existing molecules. Techniques that were originally developed for areas such as image generation and language translation have been adapted to the generation of molecules. These deep learning methods have been coupled with the predictive models described above and are being used to generate new molecules with specific predicted biological activity profiles. While these generative algorithms appear promising, there have been only a few reports on the synthesis and testing of molecules based on designs proposed by generative models. The evaluation of the diversity, quality, and ultimate value of molecules produced by generative models is still an open question. While the field has produced a number of benchmarks, it has yet to agree on how one should ultimately assess molecules "invented" by an algorithm.
OI Walters, W. Patrick/0000-0003-2860-7958
SN 0001-4842
EI 1520-4898
PD JAN 19
PY 2021
VL 54
IS 2
BP 263
EP 270
DI 10.1021/acs.accounts.0c00699
UT WOS:000612345900002
PM 33370107
ER

PT J
AU Artignan, X
   Smitsmans, MHP
   Lebesque, JV
   Jaffray, DA
   van Her, M
   Bartelink, H
AF Artignan, X
   Smitsmans, MHP
   Lebesque, JV
   Jaffray, DA
   van Her, M
   Bartelink, H
TI Online ultrasound image guidance for radiotherapy of prostate cancer:
   Impact of image acquisition on prostate displacement
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
AB Aim: Numerous studies reported the use of ultrasound image-guidance system to assess and correct patient setup during radiotherapy for prostate cancer. We conducted a study to demonstrate and quantify prostate displacement resulting from pressure of the probe on the abdomen during transabdominal ultrasound image acquisition for prostate localization.
   Material and Methods: Ten healthy volunteers were asked to undergo one imaging procedure. The procedure was performed in a condition that simulates the localization of prostate during online ultrasound guidance. A 3D ultrasound machine was used. The procedure started with the placement of the probe on the abdomen above the pubis symphysis. The probe was tilted in a caudal and posterior direction until the prostate and seminal vesicle were visualized. The probe was then fixed with a rigid arm, which maintained the probe in a static position during image acquisition. The probe was then moved, in a short time, stepwise toward the prostate, acquiring images at each step. The prostate and seminal vesicles were identified and selected in all planes. The first 3D volume was used as reference 1, to which all other scans were matched using a gray value matching algorithm.
   Results: Prostate motion was quantified as a 3D translation relative to the patient coordinate system. The resulting translations represented the amount of prostate movement as a function of probe displacement. Between 7 and 11 images were obtained per volunteer, with a maximal probe displacement ranging between 3 and 6 cm. Prostate displacement was measured in all volunteers for all the probe steps and in all directions. The largest displacements occurred in the posterior direction in all volunteers. The absolute prostate motion was less than 5 mm in 100% of the volunteers after 1 cm of probe displacement, in 80% after 1.5 cm, in 40% after 2 cm, in 10% after 2.5 cm, and 0% after 3 cm. To achieved a good-quality ultrasound images, the probe requires an average displacement of 1.2 cm, and this results in an average prostate displacement of 3.1 turn. No correlations were observed between prostate motion and prostate-probe distance or bladder size.
   Conclusion: Probe pressure during ultrasound image acquisition causes prostate displacement, which is correlated to the amount of probe displacement from initial contact. The induced uncertainty associated with this process needs to be carefully evaluated to determine a safe margin to be employed during online ultrasound image-guided radiotherapy of the prostate. (C) 2004 Elsevier Inc.
OI Jaffray, David/0000-0001-7378-7543
SN 0360-3016
PD JUN 1
PY 2004
VL 59
IS 2
BP 595
EP 601
DI 10.1016/j.ijrobp.2004.01.043
UT WOS:000221440800037
PM 15145181
ER

PT J
AU Shen, J
   Ren, CL
   Zeng, HQ
AF Shen, Jie
   Ren, Changliang
   Zeng, Huaquiang
TI Membrane-Active Molecular Machines
SO ACCOUNTS OF CHEMICAL RESEARCH
AB Both biological and artificial membrane transporters mediate passivetransmembrane ionflux predominantly via either channel or carrier mechanisms, tightlyregulating the transport of materials entering and exiting the cell. One early elegant exampleunclassifiable as carriers or channels was reported by Smith who derivatized a phospholipidmolecule into an anion transporter, facilitating membrane transport via a two-station relaymechanism (Smith et al.J. Am. Chem. Soc.2008, 130, 17274-17275). Our journey towardblurring or even breaking the boundaries defined by the carrier and channel mechanisms startsin January of 2018 when seeing a child swinging on the swing at the playground park. Sincethen, I have been wondering whether we could build a nanoscale-sized molecular swing able toperform the swing function at the molecular level to induce transmembrane ionflux. Suchresearch journey culminates in several membrane-active artificial molecular machines, includingmolecular swings, ionfishers, ion swimmers, rotors, tetrapuses and dodecapuses thatpermeabilize the membrane via swinging, ion-fishing, swimming, rotating, or swing-relayingactions, respectively. Except for molecular ion swimmers, these unconventional membrane transporters in their most stable statesreadily span across the entire membrane in a way akin to channels. With built-inflexible arms that can swing or bend in the dynamicmembrane environment, they transport ions via constantly changing ion permeation pathways that are more defined than carriersbut less defined than channels. Applying the same benzo-crown ether groups as the sole ion-binding and -transporting units, thesetransporters however differ immensely in ion transport property. While the maximal K+transport activity is achieved by themolecular swing also termed"motional channel"that displays an EC50value of 0.021 mol % relative to lipid and transports K+ions atrate 27% faster than gramicidin A, the highest K+/Na+selectivity of 18.3 is attained by the molecular ionfisher, with the highestNa+/K+selectivity of 13.7 by the molecular dodecapus. Having EC50values of 0.49-1.60 mol % and K+/Na+values of 1.1-6.3,molecular rotors and tetrapuses are found to be generally active but weakly to moderately K+-selective. For molecular ion swimmersthat contain 10 to 14 carbon atom alkyl linkers, they all turn out to be highly active (EC50= 0.18-0.41 mol %) and highly selective(RK+/RNa+= 7.0-9.5) transporters. Of special note are crown ether-appended molecular dodecapuses that establish the C60-fullerenecore as an excellent platform to allow for a direct translation of solution binding affinity to transmembrane ion transport selectivity,providing ade novobasis for rationally designing artificial ion transporters with high transport selectivity. Considering remarkablecytotoxic activities displayed by molecular swings and ion swimmers, the varied types of existing and emerging unconventionalmembrane transporters with enhanced activities and selectivities eventually might lead to medical benefits in the future.
RI Zeng, Huaqiang/B-8540-2014
OI Zeng, Huaqiang/0000-0002-8246-2000
SN 0001-4842
EI 1520-4898
PD APR 19
PY 2022
VL 55
IS 8
BP 1148
EP 1159
DI 10.1021/acs.accounts.1c00804
UT WOS:000792770000006
PM 35345880
ER

PT J
AU Benjamin, M
   Yik, S
AF Benjamin, Madonna
   Yik, Steven
TI Precision Livestock Farming in Swine Welfare: A Review for Swine
   Practitioners
SO ANIMALS
AB Simple Summary The increasing implementation of technological advances originally developed for video gaming (PlayStation, Xbox) is helping to progress livestock production so that it is both more efficient and more focused on the welfare of the animals. Such advances are necessary to ensure that innovations can emerge from applications using cameras, microphones and sensors to enhance the farmers' eyes, ears and nose in everyday farming. This technology for remote monitoring of livestock, termed precision livestock farming, is the ability to automatically track individual livestock in real time. The goal of this review is to apprise swine veterinarians and their clientele on precision livestock farming with a general introduction to the technology available, a review of research and commercially available technology and the implications and opportunities for swine practitioners and farmers. Drawing from pig welfare criteria in the Common Swine Industry Audit, this review explains how these applications can be used to improve swine welfare within current pork production stakeholder expectations. Swine veterinarians and specialists, by virtue of their animal advocacy role, interpretation of benchmarking data, and stewardship in regulatory and commodity programs, can play a broader role in facilitating the transfer of precision livestock farming and technology to their clients.
   Abstract The burgeoning research and applications of technological advances are launching the development of precision livestock farming. Through sensors (cameras, microphones and accelerometers), images, sounds and movements are combined with algorithms to non-invasively monitor animals to detect their welfare and predict productivity. In turn, this remote monitoring of livestock can provide quantitative and early alerts to situations of poor welfare requiring the stockperson's attention. While swine practitioners' skills include translation of pig data entry into pig health and well-being indices, many do not yet have enough familiarity to advise their clients on the adoption of precision livestock farming practices. This review, intended for swine veterinarians and specialists, (1) includes an introduction to algorithms and machine learning, (2) summarizes current literature on relevant sensors and sensor network systems, and drawing from industry pig welfare audit criteria, (3) explains how these applications can be used to improve swine welfare and meet current pork production stakeholder expectations. Swine practitioners, by virtue of their animal and client advocacy roles, interpretation of benchmarking data, and stewardship in regulatory and traceability programs, can play a broader role as advisors in the transfer of precision livestock farming technology, and its implications to their clients.
RI Gemus, Madonna/ABA-3084-2020
OI Gemus, Madonna/0000-0001-9731-2139
SN 2076-2615
PD APR
PY 2019
VL 9
IS 4
AR 133
DI 10.3390/ani9040133
UT WOS:000467298500015
PM 30935123
ER

PT J
AU Knop, S
AF Knop, Seta
TI Crossing the Borders of the Literary Character: Faust and Spengler
SO PRIMERJALNA KNJIZEVNOST
AB With Oswald Spengler and his epochal work The Decline of the West the hero of Goethe's canonical poem ultimately crossed the borders of the literary character and became the personification of the Western (European) man, characterized by insatiable striving, ceaseless activity and dynamic orientation towards the infinitely open space and time.
   Spengler conceived his "Morphology of world literatures" as a cyclical history of cultures which, like living organisms, go through the periods of growth, blossom, exhaustion and finally decay, when we no longer speak of culture, but of civilization. Faust is for Spengler "the portrait of the whole cultures" - in his character we can trace the transition from the living culture to dead civilization: the passionate dreamer from the first part of the poem, written in 1808, turns in the second part, written a quarter of a century later, into a Saint-Simonistic engineer and organizer (as well as colonizer) and becomes the modern homo faber.
   Faustian culture is for Spengler first of all the culture of will; it is the culture of incessant activity driven by the imperative you musts, and is as such in polar opposition to the Apollonian culture of the ancient Greeks, which shows little interest for constant changing of the world. Spengler thus substitutes the Nietzschean couple Apollonian/Dionysian with the couple Apollonian/Faustian, directly referring to Faust's translation of the ancient Greek expression logos with the word der Tat.
   The time of civilization is the time of technical sciences, the time of materialism, mechanicism and faith in experiments, atoms and numbers. The Faustian will reaches its perfection in the symbol of machine, by the help of which it wants to master and enslave the nature; but it turns out that by doing this the Faustian man has also enslaved himself. In accordance to Hegelian dialectics of master and slave (or Adorno's and Horkheimer's dialectics of enlightenment) his victory over nature turns into its opposition, for he has become the slave of his own creativity. The machine pushed him on the way from which there is no return; it works without stopping and forces him to work with it.
   In this ambiguity the "reactionary modernists" Spengler (who is also ironically depicted in Thomas Mann's Doktor Faustus in the character of dr. Breisacher) seems to be less optimistic than Goethe, on whose hero he has build his Faustian man. With Spengler Faust became the character who embodies the contradictions of modern age; his insatiable striving for knowledge is not only something "positive" which is supposed to bring benefit to the mankind, but can also - implemented in reality - display its "negative", destructive side.
SN 0351-1189
PD DEC
PY 2010
VL 33
IS 3
BP 251
EP 264
UT WOS:000286043100014
ER

PT J
AU Chun, J
   Zhang, H
   Gach, HM
   Olberg, S
   Mazur, T
   Green, O
   Kim, T
   Kim, H
   Kim, JS
   Mutic, S
   Park, JC
AF Chun, Jaehee
   Zhang, Hao
   Gach, H. Michael
   Olberg, Sven
   Mazur, Thomas
   Green, Olga
   Kim, Taeho
   Kim, Hyun
   Kim, Jin Sung
   Mutic, Sasa
   Park, Justin C.
TI MRI super-resolution reconstruction for MRI-guided adaptive radiotherapy
   using cascaded deep learning: In the presence of limited training data
   and unknown translation model
SO MEDICAL PHYSICS
AB Purpose Deep learning (DL)-based super-resolution (SR) reconstruction for magnetic resonance imaging (MRI) has recently been receiving attention due to the significant improvement in spatial resolution compared to conventional SR techniques. Challenges hindering the widespread implementation of these approaches remain, however. Low-resolution (LR) MRIs captured in the clinic exhibit complex tissue structures obfuscated by noise that are difficult for a simple DL framework to handle. Moreover, training a robust network for a SR task requires abundant, perfectly matched pairs of LR and high-resolution (HR) images that are often unavailable or difficult to collect. The purpose of this study is to develop a novel SR technique for MRI based on the concept of cascaded DL that allows for the reconstruction of high-quality SR images in the presence of insufficient training data, an unknown translation model, and noise. Methods The proposed framework, based on the concept named cascaded deep learning, consists of three components: (a) a denoising autoencoder (DAE) trained using clinical LR noisy MRI scans that have been processed with a nonlocal means filter that generates denoised LR data; (b) a down-sampling network (DSN) trained with a small amount of paired LR/HR data from volunteers that allows for the generation of perfectly paired LR/HR data for the training of a generative model; and (c) the proposed SR generative model (p-SRG) trained with data generated by the DSN that maps from LR inputs to HR outputs. After training, LR clinical images may be fed through the DAE and p-SRG to yield SR reconstructions of the LR input. The application of this framework was explored in two settings: 3D breath-hold MRI axial SR reconstruction from LR axial scans (<3 sec/vol) and in the enhancement of the spatial resolution of LR 4D-MRI acquisitions (0.5 sec/vol). Results The DSN produces LR scans from HR inputs with a higher fidelity to true, LR clinical scans compared to conventional k-space down-sampling methods based on the metrics of root mean square error (RMSE) and structural similarity index (SSIM). Furthermore, HR outputs generated by the p-SRG exhibit improved scores in the peak signal-to-noise ratio, normalized RMSE, SSIM, and in the blind/reference-less image spatial quality evaluator assessment compared to conventional approaches to MRI SR. Conclusions The robust, SR reconstruction method for MRI based on the novel cascaded deep learning framework is an end-to-end method for producing detail-preserving SR reconstructions from noisy, LR clinical MRI scans. Fourfold enhancements in spatial resolution facilitate target delineation and motion management during radiation therapy, enabling precise MRI-guided radiation therapy with 3D LR breath-hold MRI and 4D-MRI in a clinically feasible time frame.
OI Kim, Jin Sung/0000-0003-1415-6471
SN 0094-2405
EI 2473-4209
PD SEP
PY 2019
VL 46
IS 9
BP 4148
EP 4164
DI 10.1002/mp.13717
EA AUG 2019
UT WOS:000480178900001
ER

PT J
AU Chen, XJ
   Bagci, U
AF Chen, Xinjian
   Bagci, Ulas
TI 3D automatic anatomy segmentation based on iterative graph-cut-ASM
SO MEDICAL PHYSICS
AB Purpose: This paper studies the feasibility of developing an automatic anatomy segmentation (AAS) system in clinical radiology and demonstrates its operation on clinical 3D images.
   Methods: The AAS system, the authors are developing consists of two main parts: object recognition and object delineation. As for recognition, a hierarchical 3D scale-based multiobject method is used for the multiobject recognition task, which incorporates intensity weighted ball-scale (b-scale) information into the active shape model (ASM). For object delineation, an iterative graph-cut-ASM (IGCASM) algorithm is proposed, which effectively combines the rich statistical shape information embodied in ASM with the globally optimal delineation capability of the GC method. The presented IGCASM algorithm is a 3D generalization of the 2D GC-ASM method that they proposed previously in Chen et al. [Proc. SPIE, 7259, 72590C1-72590C-8 (2009)]. The proposed methods are tested on two datasets comprised of images obtained from 20 patients (10 male and 10 female) of clinical abdominal CT scans, and 11 foot magnetic resonance imaging (MRI) scans. The test is for four organs (liver, left and right kidneys, and spleen) segmentation, five foot bones (calcaneus, tibia, cuboid, talus, and navicular). The recognition and delineation accuracies were evaluated separately. The recognition accuracy was evaluated in terms of translation, rotation, and scale (size) error. The delineation accuracy was evaluated in terms of true and false positive volume fractions (TPVF, FPVF). The efficiency of the delineation method was also evaluated on an Intel Pentium IV PC with a 3.4 GHZ CPU machine.
   Results: The recognition accuracies in terms of translation, rotation, and scale error over all organs are about 8 mm, 10 degrees and 0.03, and over all foot bones are about 3.5709 mm, 0.35 degrees and 0.025, respectively. The accuracy of delineation over all organs for all subjects as expressed in TPVF and FPVF is 93.01% and 0.22%, and all foot bones for all subjects are 93.75% and 0.28%, respectively. While the delineations for the four organs can be accomplished quite rapidly with average of 78 s, the delineations for the five foot bones can be accomplished with average of 70 s.
   Conclusions: The experimental results showed the feasibility and efficacy of the proposed automatic anatomy segmentation system: (a) the incorporation of shape priors into the GC framework is feasible in 3D as demonstrated previously for 2D images; (b) our results in 3D confirm the accuracy behavior observed in 2D. The hybrid strategy IGCASM seems to be more robust and accurate than ASM and GC individually; and (c) delineations within body regions and foot bones of clinical importance can be accomplished quite rapidly within 1.5 min. (C) 2011 American Association of Physicists in Medicine. [DOI: 10.1118/1.3602070]
RI Chen, Xinjian/E-8592-2016; Bagci, Ulas/A-4225-2012; zhang,
   feng/L-7009-2016
OI Bagci, Ulas/0000-0001-7379-6829; Chen, Xinjian/0000-0001-9627-6009;
   Chen, Xinjian/0000-0002-0871-293X
SN 0094-2405
EI 2473-4209
PD AUG
PY 2011
VL 38
IS 8
BP 4610
EP 4622
DI 10.1118/1.3602070
UT WOS:000293417500022
PM 21928634
ER

PT J
AU Murphy, RG
   Gilmore, A
   Senevirathne, S
   O'Reilly, PG
   Wilson, ML
   Jain, S
   McArt, DG
AF Murphy, Ross G.
   Gilmore, Alan
   Senevirathne, Seedevi
   O'Reilly, Paul G.
   Wilson, Melissa LaBonte
   Jain, Suneil
   McArt, Darragh G.
TI Particle swarm optimization artificial intelligence technique for gene
   signature discovery in transcriptomic cohorts
SO COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL
AB The development of gene signatures is key for delivering personalized medicine, despite only a few signatures being available for use in the clinic for cancer patients. Gene signature discovery tends to revolve around identifying a single signature. However, it has been shown that various highly predictive signatures can be produced from the same dataset. This study assumes that the presentation of top ranked signatures will allow greater efforts in the selection of gene signatures for validation on external datasets and for their clinical translation. Particle swarm optimization (PSO) is an evolutionary algorithm often used as a search strategy and largely represented as binary PSO (BPSO) in this domain. BPSO, however, fails to produce succinct feature sets for complex optimization problems, thus affecting its overall runtime and optimization performance. Enhanced BPSO (EBPSO) was developed to overcome these shortcomings. Thus, this study will validate unique candidate gene signatures for different underlying biology from EBPSO on transcriptomics cohorts. EBPSO was consistently seen to be as accurate as BPSO with substantially smaller feature signatures and significantly faster runtimes. 100% accuracy was achieved in all but two of the selected data sets. Using clinical transcriptomics cohorts, EBPSO has demonstrated the ability to identify accurate, succinct, and significantly prognostic signatures that are unique from one another. This has been proposed as a promising alternative to overcome the issues regarding traditional single gene signature generation. Interpretation of key genes within the signatures provided biological insights into the associated functions that were well correlated to their cancer type. (c) 2022 Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/ licenses/by-nc-nd/4.0/).
OI Murphy, Ross/0000-0001-8583-8635; LaBonte, Melissa/0000-0002-0354-413X;
   jain, suneil/0000-0001-7429-4791
SN 2001-0370
PY 2022
VL 20
BP 5547
EP 5563
DI 10.1016/j.csbj.2022.09.033
UT WOS:000874656300003
PM 36249564
ER

PT J
AU Simeonov, PL
AF Simeonov, PL
TI On using nomadic services for distributed intelligence
SO MICROPROCESSORS AND MICROSYSTEMS
AB This paper presents a next generation integrated IN architecture among Flexible Intelligent Network Elements (FINE) based on the multimedia multimode (client, server and agent) IN Service Node concept (Proc. ICCE '97, Cannes (1997) 77), to perform a crafty Unified Media Communications Service (UMCS) across heterogeneous networks. The FINE architecture represents a network of configurable interworking elements allowing user access to a Unified Message Store (UMS) and Universal Communications Channel (UCC) via traditional PSTN/ISDN/PLMN equipment such as telephones, pagers and fax machines on the one side, and networked computers and mobile terminals equipped with mail readers and Web browsers on the other side, to enable both on-line and off-line interactions. A virtual cluster of FINEs within an integrated personal communications network is dynamically configured in a distributed or centralised manner according to user profile requirements, network size and performance to provide artful messaging, telephony and (IE)-E-3 services (Intelligent Inter-, Intra- and Extranet) in a changing environment.
   The FINE consists of a Channel Matrix Switch (CMS), several Resource Platforms (RP) containing Media Conversion Processors (MCP) and Channel Managers (CM) to perform the media translation and routing in the required interchange formats, an Internet Gateway (IG) to hold the subscribers' mailboxes and provide the internet connectivity, and a FINE Controller (FINEC) to realise the FINE Service Logic (FSL) and manage the FINEs.
   Each FINEC can be deployed in some of the three modes - independent (server), dependent (client) and autonomous (agent) - with respect to the user/network configuration, thus allowing a dynamically configurable (per user/per node/per service) centralised or distributed service architecture.
   The FINE itself is or,organised along with other nodes by a Network Operation Support Environment (NOSE), a service oriented and TMN compliant Operation, Administration & Maintenance Centre.
   Service logic can be transferred, installed and mounted on demand among the FINE Controllers and the terminal equipment to provide optimal QoS. (C) 2000 Elsevier Science B.V. All rights reserved.
RI Simeonov, Plamen/T-4786-2017
OI Simeonov, Plamen/0000-0003-2672-4405
SN 0141-9331
PD OCT 15
PY 2000
VL 24
IS 6
BP 291
EP 297
DI 10.1016/S0141-9331(00)00089-2
UT WOS:000089672300002
ER

PT J
AU Fuentes-Pineda, G
   Meza-Ruiz, IV
AF Fuentes-Pineda, Gibran
   Meza-Ruiz, Ivan, V
TI Topic discovery in massive text corpora based on Min-Hashing
SO EXPERT SYSTEMS WITH APPLICATIONS
AB Topics have proved to be a valuable source of information for exploring, discovering, searching and representing the contents of text corpora. They have also been useful for different natural language processing tasks such as text classification, text summarization and machine translation. Most existing topic discovery approaches require the number of topics to be provided beforehand. However, an appropriate number of topics for a given corpus depends on its characteristics and is often difficult to estimate. In addition, in order to handle massive amounts of text documents, the vocabulary must be reduced considerably and large computer clusters and/or GPUs are typically required. This paper describes Sampled Min-Hashing (SMH), a scalable approach to topic discovery which does not require the number of topics to be specified in advance and can handle massive text corpora and large vocabularies using modest computer resources. The basic idea behind SMH is to generate multiple random partitions of the corpus vocabulary to find sets of highly co-occurring words, which are then clustered to produce the final topics. An extensive qualitative and quantitative evaluation on the 20 Newsgroups, Reuters, Spanish Wikipedia and English Wikipedia corpora shows that SMH is able to consistently discover meaningful and coherent topics at scale. Remarkably, the time required by SMH grows linearly with the size of the corpus and the number of words in the vocabulary; a non-parallel implementation of SMH was able to discover topics from the whole English version of Wikipedia (5M documents approximately) with a vocabulary of 1M words in less than 7 h. Our findings provide further evidence of the relevance and generality of beyond-pairwise co-occurrences for pattern discovery on large-scale discrete data, which opens the door for other applications and several interesting research directions. (C) 2019 Elsevier Ltd. All rights reserved.
RI Ruiz, Ivan Vladimir Meza/D-4592-2014; Fuentes-Pineda, Gibran/G-4527-2018
OI Ruiz, Ivan Vladimir Meza/0000-0002-7239-1480; Fuentes-Pineda,
   Gibran/0000-0002-1964-8208
SN 0957-4174
EI 1873-6793
PD DEC 1
PY 2019
VL 136
BP 62
EP 72
DI 10.1016/j.eswa.2019.06.024
UT WOS:000484871300006
ER

PT J
AU Kim, H
   Kim, S
   Lee, S
   Jang, ES
AF Kim, Hyungyu
   Kim, Sowon
   Lee, Seungwook
   Jang, Euee S.
TI Parser description-based bitstream parser generation for MPEG RMC
   framework
SO SIGNAL PROCESSING-IMAGE COMMUNICATION
AB In this paper, we present a bitstream syntax description scheme that enables the automatic generation of a bitstream parser in the reconfigurable media coding (RMC) framework. In the RMC framework, a standard video decoder can be defined with a set of functional units (FUs) pre-defined in a tool library and a decoder description containing the interconnections between the FUs and the bitstream parser description. The FUs in the tool library are codec-independent in that any FU can be reused. In contrast, the decoder description is codec-specific. In particular, the bitstream parser description is required for the generation of the bitstream parser FU in the RMC framework. There have been several works on bitstream parser description and parser FU generation; however, conventional methods have mainly focused on built-in parser generation during the design time, rather than on the automatic generation of the parser FU in the run-time from the description. As a response to this problem, we propose a bitstream parser description format and a run-time parser generation mechanism based on a generic parser FU. The proposed language aims to support run-time parser FU generation by describing three types of information: control flow, external functions, and parser interfaces. The control flow description is described based on the finite state machine concept, making the translation of the BSD in run-time easy. Throughout the paper, we show how the proposed scheme is better suited for the MPEG RMC framework than the existing description formats. We also discuss the implementation of the generic parser FU (GPFU) to show that the run-time parser generation can be done efficiently with the proposed description format. A simulation result using the generic parser FU based on the existing MPEG standards (MPEG-4 SP and SC3DMC) is provided as an existential proof. (C) 2013 Elsevier B.V. All rights reserved.
SN 0923-5965
EI 1879-2677
PD NOV
PY 2013
VL 28
IS 10
SI SI
BP 1255
EP 1277
DI 10.1016/j.image.2013.08.011
UT WOS:000328233200005
ER

PT J
AU Brumberg, JS
   Nieto-Castanon, A
   Kennedy, PR
   Guenther, FH
AF Brumberg, Jonathan S.
   Nieto-Castanon, Alfonso
   Kennedy, Philip R.
   Guenther, Frank H.
TI Brain-computer interfaces for speech communication
SO SPEECH COMMUNICATION
AB This paper briefly reviews current silent speech methodologies for normal and disabled individuals. Current techniques utilizing electromyographic (EMG) recordings of vocal tract movements are useful for physically healthy individuals but fail for tetraplegic individuals who do not have accurate voluntary control over the speech articulators. Alternative methods utilizing EMG from other body parts (e.g., hand, arm, or facial muscles) or electroencephalography (EEG) can provide capable silent communication to severely paralyzed users, though current interfaces are extremely slow relative to normal conversation rates and require constant attention to a computer screen that provides visual feedback and/or cueing. We present a novel approach to the problem of silent speech via an intracortical microelectrode brain-computer interface (BCI) to predict intended speech information directly from the activity of neurons involved in speech production. The predicted speech is synthesized and acoustically fed back to the user with a delay under 50 ms. We demonstrate that the Neurotrophic Electrode used in the BCI is capable of providing useful neural recordings for over 4 years, a necessary property for BCIs that need to remain viable over the lifespan of the user. Other design considerations include neural decoding techniques based on previous research involving BCIs for computer cursor or robotic arm control via prediction of intended movement kinematics from motor cortical signals in monkeys and humans. Initial results from a study of continuous speech production with instantaneous acoustic feedback show the BCI user was able to improve his control over an artificial speech synthesizer both within and across recording sessions. The success of this initial trial validates the potential of the intracortical microelectrode-based approach for providing a speech prosthesis that can allow much more rapid communication rates. (C) 2010 Elsevier By. All rights reserved.
OI Brumberg, Jonathan/0000-0001-5739-968X; Nieto-Castanon,
   Alfonso/0000-0002-3451-3475
SN 0167-6393
EI 1872-7182
PD APR
PY 2010
VL 52
IS 4
SI SI
BP 367
EP 379
DI 10.1016/j.specom.2010.01.001
UT WOS:000276026400009
PM 20204164
ER

PT J
AU Liu, ZC
   Li, JL
   Mao, CX
   Wang, D
   Guan, ZT
   Xie, C
   Li, JQ
   Qi, YZ
AF Liu, Zhichao
   Li, Junlin
   Mao, Chengxiong
   Wang, Dan
   Guan, Zhitao
   Xie, Cong
   Li, Jingqi
   Qi, Yuanzhuo
TI Hierarchical frequency control strategy of doubly-fed induction diesel
   generator under emergency condition
SO ENERGY REPORTS
CT 2nd International Conference on Power Engineering (ICPE)
CY DEC 09-11, 2021
CL Nanning, PEOPLES R CHINA
AB Natural disasters lead to the uncertain topological structure of the urban distribution network. It is difficult for the communication system to recover quickly, which brings great difficulties to restoring the power supply. Therefore, the deployment of an emergency power supply is one of the critical measures to ensure the stable operation of isolated network systems and reduce power loss. Compared with the traditional synchronous diesel generator (SDG) as an emergency power supply, a doubly-fed induction diesel generator (DFIDG) has the advantages of flexible and controllable, rapid response and high operation efficiency. This paper presents a layered frequency control strategy for a doubly-fed induction diesel generator in an emergency scenario. Firstly, the models of doubly-fed induction diesel generator and its control system, prime mover and its speed regulation system are established. Secondly, the hierarchical frequency control strategy is proposed, including primary integrated frequency control (including droop control and virtual inertia control) and secondary frequency regulation control based on translation method. The virtual inertia control can make the doubly-fed machine quickly release the rotor kinetic energy when the frequency changes rapidly, so as to improve the frequency supportability. According to the overall shortage of the system and the maximum output power of the doubly-fed induction diesel generator, the strategy calculates the secondary frequency regulation power adjustment as the DFIDG power setting value, and then can realize automatic secondary frequency regulation without a communication system. Finally, simulation results verify the effectiveness of the proposed strategy. (c) 2022 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/). Peer-review under responsibility of the scientific committee of the 2021 The 2nd International Conference on Power Engineering, ICPE, 2021.
RI Wang, Dan/T-6041-2018
OI Wang, Dan/0000-0002-8230-6243
SN 2352-4847
PD AUG
PY 2022
VL 8
SU 5
BP 657
EP 667
DI 10.1016/j.egyr.2022.02.257
EA MAR 2022
UT WOS:000770818700079
ER

PT J
AU Supek, F
   Skunca, N
   Repar, J
   Vlahovicek, K
   Smuc, T
AF Supek, Fran
   Skunca, Nives
   Repar, Jelena
   Vlahovicek, Kristian
   Smuc, Tomislav
TI Translational Selection Is Ubiquitous in Prokaryotes
SO PLOS GENETICS
AB Codon usage bias in prokaryotic genomes is largely a consequence of background substitution patterns in DNA, but highly expressed genes may show a preference towards codons that enable more efficient and/or accurate translation. We introduce a novel approach based on supervised machine learning that detects effects of translational selection on genes, while controlling for local variation in nucleotide substitution patterns represented as sequence composition of intergenic DNA. A cornerstone of our method is a Random Forest classifier that outperformed previous distance measure-based approaches, such as the codon adaptation index, in the task of discerning the (highly expressed) ribosomal protein genes by their codon frequencies. Unlike previous reports, we show evidence that translational selection in prokaryotes is practically universal: in 460 of 461 examined microbial genomes, we find that a subset of genes shows a higher codon usage similarity to the ribosomal proteins than would be expected from the local sequence composition. These genes constitute a substantial part of the genome-between 5% and 33%, depending on genome size-while also exhibiting higher experimentally measured mRNA abundances and tending toward codons that match tRNA anticodons by canonical base pairing. Certain gene functional categories are generally enriched with, or depleted of codon-optimized genes, the trends of enrichment/depletion being conserved between Archaea and Bacteria. Prominent exceptions from these trends might indicate genes with alternative physiological roles; we speculate on specific examples related to detoxication of oxygen radicals and ammonia and to possible misannotations of asparaginyl-tRNA synthetases. Since the presence of codon optimizations on genes is a valid proxy for expression levels in fully sequenced genomes, we provide an example of an "adaptome" by highlighting gene functions with expression levels elevated specifically in thermophilic Bacteria and Archaea.
RI Vlahoviček, Kristian/D-9661-2011; Supek, Fran/B-2359-2012
OI Vlahoviček, Kristian/0000-0002-5705-2464; Supek,
   Fran/0000-0002-7811-6711
SN 1553-7404
PD JUN
PY 2010
VL 6
IS 6
AR e1001004
DI 10.1371/journal.pgen.1001004
UT WOS:000279805200033
PM 20585573
ER

PT J
AU Mu, ZX
   Cai, ZH
   Zeng, CN
   Li, ZF
   Liang, XF
   Yang, F
   Chen, TY
   Dong, SJ
   Deng, CM
   Niu, SP
AF Mu, Zixin
   Cai, Zhenhua
   Zeng, Chunnian
   Li, Zifan
   Liang, Xufeng
   Yang, Fan
   Chen, Tingyang
   Dong, Shujuan
   Deng, Chunming
   Niu, Shaopeng
TI A point cloud registration-based calibration algorithm for robot offline
   programming automatic loading in aero-grinding applications
SO INDUSTRIAL ROBOT-THE INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH AND
   APPLICATION
AB Purpose During the process of the robotic grinding and polishing operations on aero-engine blades, the key problem of calibration error lies in fixture error and uneven margin. To solve this problem, this paper aims to propose a novel method to achieve rapid online calibration of the workpiece coordinate system through laser-based measurement techniques. Design/methodology/approach The authors propose a calibration strategy based on point cloud registration algorithm. The main principle is presented as follows: aero blade mounted on clamping end-effector is hold by industry robot, the whole device is then scanned by a 3D laser scanner to obtain its surface point cloud, and a fast segmentation method is used to acquire the point cloud of the workpiece. Combining Super4PCS algorithm with trimmed iterative closest point, we can align the key points of the scanned point cloud and the sampled points of the blade model, thus obtaining the translation and rotation matrix for calculating the workpiece coordinate and machining allowance. The proposed calibration strategy is experimentally validated, and the positioning error, as well as the margin distribution, is finally analyzed. Findings The experimental results show that the algorithm can well accomplish the task of cross-source, partial data and similar local features of blade point cloud registration with high precision. The total time spent on point cloud alignment of 100,000 order of magnitude blade is about 4.2 s, and meanwhile, the average point cloud alignment error is reduced to below 0.05 mm. Originality/value An improved point cloud registration method is proposed and introduced into the calibration process of a robotic system. The online calibration technique improves the accuracy and efficiency of the calibration process and enhances the automation of the robotic grinding and polishing system.
RI Li, ZiFan/HJH-1806-2023
SN 0143-991X
EI 1758-5791
PD SEP 20
PY 2022
VL 49
IS 6
BP 1218
EP 1228
DI 10.1108/IR-12-2021-0284
EA MAY 2022
UT WOS:000797116000001
ER

PT J
AU Panagiotou, E
   Chochlakis, G
   Grammatikopoulos, L
   Charou, E
AF Panagiotou, Emmanouil
   Chochlakis, Georgios
   Grammatikopoulos, Lazaros
   Charou, Eleni
TI Generating Elevation Surface from a Single RGB Remotely Sensed Image
   Using Deep Learning
SO REMOTE SENSING
AB Generating Digital Elevation Models (DEM) from satellite imagery or other data sources constitutes an essential tool for a plethora of applications and disciplines, ranging from 3D flight planning and simulation, autonomous driving and satellite navigation, such as GPS, to modeling water flow, precision farming and forestry. The task of extracting this 3D geometry from a given surface hitherto requires a combination of appropriately collected corresponding samples and/or specialized equipment, as inferring the elevation from single image data is out of reach for contemporary approaches. On the other hand, Artificial Intelligence (AI) and Machine Learning (ML) algorithms have experienced unprecedented growth in recent years as they can extrapolate rules in a data-driven manner and retrieve convoluted, nonlinear one-to-one mappings, such as an approximate mapping from satellite imagery to DEMs. Therefore, we propose an end-to-end Deep Learning (DL) approach to construct this mapping and to generate an absolute or relative point cloud estimation of a DEM given a single RGB satellite (Sentinel-2 imagery in this work) or drone image. The model has been readily extended to incorporate available information from the non-visible electromagnetic spectrum. Unlike existing methods, we only exploit one image for the production of the elevation data, rendering our approach less restrictive and constrained, but suboptimal compared to them at the same time. Moreover, recent advances in software and hardware allow us to make the inference and the generation extremely fast, even on moderate hardware. We deploy Conditional Generative Adversarial networks (CGAN), which are the state-of-the-art approach to image-to-image translation. We expect our work to serve as a springboard for further development in this field and to foster the integration of such methods in the process of generating, updating and analyzing DEMs.
RI Grammatikopoulos, Lazaros/AAY-5691-2021
OI Grammatikopoulos, Lazaros/0000-0002-3858-1352
EI 2072-4292
PD JUN
PY 2020
VL 12
IS 12
AR 2002
DI 10.3390/rs12122002
UT WOS:000550355600001
ER

PT J
AU Ehsan, T
   Hussain, S
AF Ehsan, Toqeer
   Hussain, Sarmad
TI Analysis of Experiments on Statistical and Neural Parsing for a
   Morphologically Rich and Free Word Order Language Urdu
SO IEEE ACCESS
AB This article presents an analysis of experiments with statistical and neural parsing techniques for Urdu, a widely spoken South Asian language. We demonstrate state of the art constituency parsing results for an Urdu treebank. Urdu is a morphologically rich and is characterized by free word order. Language representation (e.g. input type, lemmatization, word clusters), part of speech tag set, phrase labels and the size of a training corpus are crucial for parsing such languages. In this article, probabilistic context-free grammars, data-oriented parsing, and recursive neural network based models have been experimented with several linguistic features which show improvements in the parsing results. Features include syntactic sub-categorization of POS tags, empirically learned horizontal and vertical markovizations and lexical head words. These features enable dependency information for case markers and add phrasal and lexical context to the parse trees. The data-oriented parsing and recursive neural network model give an f-score of 87.1 by considering gold POS tags in the test set, on textual input, they show a performance with f-scores of 83.4 and 84.2, respectively. To overcome the issue of data sparsity due to the morphological richness, lemmatization and unsupervised word clustering have been performed. A treebank should cover most probable word orders of the language so that models can learn various orders accurately. To analyze the order coverage of the treebank and learning capability of different parsers, a test set has been prepared conditioning different word orders. This test set is evaluated with the best performing parsing models and with gold POS tags, f-scores are above 90 and on textual input, the average f-score is 87.6.
OI Ehsan, Toqeer/0000-0002-6724-6705
SN 2169-3536
PY 2019
VL 7
BP 161776
EP 161793
DI 10.1109/ACCESS.2019.2949950
UT WOS:000497169800070
ER

PT J
AU Zhang, JD
   Chow, CY
AF Zhang, Jia-Dong
   Chow, Chi-Yin
TI SEMAX: Multi-Task Learning for Improving Recommendations
SO IEEE ACCESS
AB Personalization plays an essential role in recommender systems, in which the key task is to predict personalized ratings of users on new items. Recently, a lot of work investigates deep learning-based collaborative filtering techniques to increase the accuracy of rating prediction. However, most exiting works focus on the recommendation task itself. Actually, the multi-task learning exploits an inductive transfer mechanism to enhance the generalization performance of the main task by using the domain information contained in other related tasks. Multi-task learning has shown effectiveness in various real-world problems, including regression and machine translation. To this end, this study proposes a new framework, called SEMAX that extends our previous model SEMA via multi-task learning for improving recommendations, in which the recommendation task gets the domain information from the other task. Specifically, in the recommendation task, SEMAX learns semantic meanings from texts and temporal dynamics from text sequences for both users and items based on our developed hierarchical and symmetrical recurrent neural networks (RNNs) with the long short-term memory. Furthermore, SEMAX exploits the related task that predicts the rating of a text written by a user for an item to reinforce the recommendation task that predicts the rating of the user on the item, because the text can be an important predictor of the rating given by the user to the item. Moreover, SEMAX predicts the rating of a text based on an attention mechanism to choose user-item-specific words so as to generalize the performance of learned word embeddings, user and item representations. Finally, we conduct a comprehensive evaluation for SEMAX using two large-scale real-world review datasets collected from Amazon and Yelp. The experimental results show that the SEMAX achieves significantly superior performance compared to other state-of-the-art recommendation techniques.
SN 2169-3536
PY 2019
VL 7
BP 2305
EP 2314
DI 10.1109/ACCESS.2018.2886256
UT WOS:000455880300001
ER

PT C
AU Aziz, TA
   Sunitha, C
AF Aziz, Anisha T.
   Sunitha, C.
BE Mauri, JL
   Thampi, SM
   Wozniak, M
   Marques, O
   Krishnaswamy, D
   Sahni, S
   Callegari, C
   Takagi, H
   Bojkovic, ZS
   Vinod, M
   Prasad, NR
   Calero, JMA
   Rodrigues, J
   Que, XY
   Meghanathan, N
   Sandhu, R
   Au, E
TI A Hybrid Parts Of Speech Tagger for Malayalam Language
SO 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS
   AND INFORMATICS (ICACCI)
CT International Conference on Advances in Computing, Communications and
   Informatics ICACCI
CY AUG 10-13, 2015
CL SCMS Grp of Inst, Aluva, INDIA
SP SCMS Sch of Engn & Technol, IEEE Commun Soc, IEEE SMC, acm
HO SCMS Grp of Inst
AB Parts of speech tagging is an important research topic in Natural Language Processing research are. Since it is one among the first steps of any natural language processing (NLP) techniques such as machine translation, if any error happens for tagging the same will repeat in the whole NLP process. So far works had been done on POS tagging based on SVM, MBLP, HMM, Ngram. All of these methods were not fixing the problem of ambiguity. So for fixing ambiguity, we put forward a new Hybrid tagger for Malayalam. The combination of traditional rules and n-gram may produce better result compared to other methodologies. And also the ambiguity will be reduced by enriching the bigram dictionary. A bigram dictionary of co-occurring words are built with their tags. About 100000 more words are there in bigram dictionary. A corpus for Malayalam must be built which may be supposed to access by the model. It contains about 100000 words which are Malayalam words as well as the words originated from English. Since it's a hybrid tagger, we can take advantage of both traditional rules as well as bigrams. Also the heart of the research is the rule set, which contains 267 manually created rules. Rules can be applied with help of a morph analyzer. Rules are also used for tagging if bigram and corpus can't be referred for tagging. The proposed method when tested on 150 words, only 11 words were not identified, and obtained 90.5% accuracy. For the unidentified words, it can be caused by either the root word may not be in corpus or bigram, or the absence of rule. So adding the word, bigram or rule, we can improve the result and enhance the work. Addition is simple task. The size of bigram dictionary, corpus, and rule set and accuracy of morph analyzer influences the performance of the system.
BN 978-1-4799-8792-4
PY 2015
BP 1502
EP 1507
UT WOS:000380475900250
ER

PT J
AU Chen, XM
   Longstaff, A
   Fletcher, S
   Myers, A
AF Chen, Xiaomei
   Longstaff, Andrew
   Fletcher, Simon
   Myers, Alan
TI Analysing and evaluating a dual-sensor autofocusing method for measuring
   the position of patterns of small holes on complex curved surfaces
SO SENSORS AND ACTUATORS A-PHYSICAL
AB This paper proposes and discusses an active dual-sensor autofocusing method for measuring the positioning errors of arrays of small holes on complex curved surfaces. The dual-sensor unit combines an optical vision sensor and a tactile probe and is designed to achieve rapid automated measurements in a way that can be adapted to be suitable for deployment on a manufacturing machine tool. Mathematical analysis is performed to establish the magnitude of the deviation from the optimal focal length that is induced by the autofocussing method. This evaluation is based on the geometrical relationship and interaction between the radius of the tactile probe with both the measured holes and the complex-curved surface. A description is provided of a laboratory-based standalone dual-sensor autofocusing unit and test rig that was built to perform experimental validation of the method. This system is estimated to have a focusing uncertainty of 11 mu m deriving mainly from the inaccuracy of the X-Z translation stage and the maximum permissible error of the tactile probe.
   A case study is presented which evaluates the accuracy of a pattern of empty set 0.5 mm small holes on an elliptic cylinder. A mathematical analysis of that problem and practical results from both the tactile and optical sensors are provided and discussed. It is estimated that the deviation in optimal focusing induced by this automated method is between -23 mu m and +95 mu m. This is sufficiently accurate to ensure that the optical device can capture the entire space outline of each of the small holes on the complex curve surface clearly and can therefore identify its centroid from the image to provide a measurement of the position. (C) 2014 Elsevier B.V. All rights reserved.
RI Longstaff, Andrew P/A-1423-2011
OI Longstaff, Andrew P/0000-0002-2886-3305; Fletcher,
   Simon/0000-0001-6963-0826; Myers, Alan/0000-0001-9257-6784
SN 0924-4247
PD APR 1
PY 2014
VL 210
BP 86
EP 94
DI 10.1016/j.sna.2014.02.011
UT WOS:000334984300011
ER

PT J
AU McNamara, JE
   Regmi, R
   Lovelock, DM
   Yorke, ED
   Goodman, KA
   Rimner, A
   Mostafavi, H
   Mageras, GS
AF McNamara, Joseph E.
   Regmi, Rajesh
   Lovelock, D. Michael
   Yorke, Ellen D.
   Goodman, Karyn A.
   Rimner, Andreas
   Mostafavi, Hassan
   Mageras, Gig S.
TI Toward correcting drift in target position during radiotherapy via
   computer-controlled couch adjustments on a programmable Linac
SO MEDICAL PHYSICS
AB Purpose: Real-time tracking of respiratory target motion during radiation therapy is technically challenging, owing to rapid and possibly irregular breathing variations. The authors report on a method to predict and correct respiration-averaged drift in target position by means of couch adjustments on an accelerator equipped with such capability.
   Methods: Dose delivery is broken up into a sequence of 10 s field segments, each followed by a couch adjustment based on analysis of breathing motion from an external monitor as a surrogate of internal target motion. Signal averaging over three respiratory cycles yields a baseline representing target drift. A Kalman filter predicts the baseline position 5 s in advance, for determination of the couch correction. The method's feasibility is tested with a motion phantom programmed according to previously recorded patient signals. Computed couch corrections are preprogrammed into a research mode of an accelerator capable of computer-controlled couch translations synchronized with the motion phantom. The method's performance is evaluated with five cases recorded during hypofractionated treatment and five from respiration-correlated CT simulation, using a root-mean-squared deviation (RMSD) of the baseline from the treatment planned position.
   Results: RMSD is reduced in all 10 cases, from a mean of 4.9 mm (range 2.7-9.4 mm) before correction to 1.7 mm (range 0.7-2.3 mm) after correction. Treatment time is increased similar to 5% relative to that for no corrections.
   Conclusions: This work illustrates the potential for reduction in baseline respiratory drift with periodic adjustments in couch position during treatment. Future treatment machine capabilities will enable the use of "on-the-fly" couch adjustments during treatment. (C) 2013 American Association of Physicists in Medicine.
OI Mageras, Gikas/0000-0001-9851-4306; Rimner, Andreas/0000-0002-1214-3856
SN 0094-2405
EI 2473-4209
PD MAY
PY 2013
VL 40
IS 5
AR 051719
DI 10.1118/1.4802736
UT WOS:000318553900022
PM 23635267
ER

PT J
AU Sunitha, KVN
   Kalyani, N
AF Sunitha, K. V. N.
   Kalyani, N.
TI Improving word coverage using unsupervised morphological analyser
SO SADHANA-ACADEMY PROCEEDINGS IN ENGINEERING SCIENCES
AB Powerful computers are needed for processing tasks related to human languages these days. Human languages, also called natural languages, are highly versatile systems of encoding information and can capture information of various domains. To enable a computer to process information in human languages, the language needs to be appropriately 'described' to the computer, i.e. the language needs to be 'modelled'. In this work, we present an approach for acquisition of morphology of inflectional language like Hindi. It is an unsupervised learning approach, suitable for languages with a rich concatenative morphology. Broadly, our work is carried out in three steps: 1. Acquire the morphology of Hindi from a raw (un annotated) Central Institute of Indian Languages (CIIL), Mysore text corpus, 2. prepare clusters and prepare stem bag and suffix bag, 3. use the morphological knowledge to decompose given word as stems and suffixes according to their morphological behaviour and add new words. A prime motivation behind this work is to eventually develop an unsupervised morphological analyser which is language-independent (used for Hindi). Second motivation is to develop a Morphological segmentation which is language-independent as it is shown that study of morphology would benefit to a range of NLP tasks such as speech recognition, speech synthesis, machine translation and information retrieval.
   Though Hindi is an important and a national language in India, little computational work has been done so far in this direction. Our work is one of the first efforts in this regard and can be considered pioneering. There are many such languages for which it is very important to have a suitable but inexpensive computational acquisition process. Languages receive very little attention of computational linguistic research both in terms of availability of funds and number of researchers. We however do not claim that our approach is a solution for all such languages. Different languages have characteristics that require individual research attention.
RI Kalyani, Nara/AAC-7304-2019; K.V.N.Sunitha/E-9652-2013
OI Kalyani, Nara/0000-0001-5364-7834; K.V.N.Sunitha/0000-0002-1790-8678
SN 0256-2499
EI 0973-7677
PD OCT
PY 2009
VL 34
IS 5
BP 703
EP 715
DI 10.1007/s12046-009-0041-x
UT WOS:000272730900002
ER

PT J
AU Wersing, H
   Korner, E
AF Wersing, H
   Korner, E
TI Learning optimized features for hierarchical models of invariant object
   recognition
SO NEURAL COMPUTATION
AB There is an ongoing debate over the capabilities of hierarchical neural feedforward architectures for performing real-world invariant object recognition. Although a variety of hierarchical models exists, appropriate supervised and unsupervised learning methods are still an issue of intense research. We propose a feedforward model for recognition that shares components like weight sharing, pooling stages, and competitive nonlinearities with earlier approaches but focuses on new methods for learning optimal feature-detecting cells in intermediate stages of the hierarchical network. We show that principles of sparse coding, which were previously mostly applied to the initial feature detection stages, can also be employed to obtain optimized intermediate complex features. We suggest a new approach to optimize the learning of sparse features under the constraints of a weight-sharing or convolutional architecture that uses pooling operations to achieve gradual invariance in the feature hierarchy. The approach explicitly enforces symmetry constraints like translation invariance on the feature set. This leads to a dimension reduction in the search space of optimal features and allows determining more efficiently the basis representatives, which achieve a sparse decomposition of the input. We analyze the quality of the learned feature representation by investigating the recognition performance of the resulting hierarchical network on object and face databases. We show that a hierarchy with features learned on a single object data set can also be applied to face recognition without parameter changes and is competitive with other recent machine learning recognition approaches. To investigate the effect of the interplay between sparse coding and processing nonlinearities, we also consider alternative feedforward pooling nonlinearities such as presynaptic maximum selection and sum-of-squares integration. The comparison shows that a combination of strong competitive nonlinearities with sparse coding offers the best recognition performance in the difficult scenario of segmentation-free recognition in cluttered surround. We demonstrate that for both learning and recognition, a precise segmentation of the objects is not necessary.
SN 0899-7667
EI 1530-888X
PD JUL
PY 2003
VL 15
IS 7
BP 1559
EP 1588
DI 10.1162/089976603321891800
UT WOS:000183421400006
PM 12816566
ER

PT J
AU Farag, NM
   Zaghloul, MS
   El-Gebaly, RH
   Hassan, ZE
   Hamza, NM
   Mohamad, EA
AF Farag, Nehad M.
   Zaghloul, Mohamed Saad
   El-Gebaly, Reem H.
   Hassan, Zeinab El-Taher
   Hamza, Noha M.
   Mohamad, Ebtesam A.
TI A comprehensive method for calculating total body irradiation
SO JOURNAL OF MEDICAL IMAGING AND RADIATION SCIENCES
AB Purpose: To provide means for calculating the dose received by various tissues of the patient, calculate lung shield, and verify received dose using a phantom as a tool for quality assurance for a planned Total Body Irradiation (TBI) procedure in radiotherapy. Method: Using Microsoft Visual Basic, MATLAB, and Python, a pro-gram for Total Body Irradiation Calculation in Radiotherapy (TBICR) is constructed. It uses patient translation and beam zone method for total body irradiation calculations to compute the proper dose received by the patient and determine the lung shield thickness. There are three main user-friendly interfaces in the application. The first one allows the user to upload the TBI topography and estimate the distances needed for TBI calculations. The second one enables the user to count the number of beam zones needed for each point and estimate the effective area (A(eff)) for each level. The third interface estimates the velocity required to deliver the relative dose depending on patient separation, Monitor Units (MU), couch speed and travel distance. It allows the user to compute the required lung shield thickness, read any patient's CT DICOM file and acquire dose in any distinct location using machine learning model to predict the dose. Results: The TBICR software has been successfully validated by reproducing all of the manual calculations in an exact and timely manner. TBICR generated more accurate results and confirmed the absorbed dose to patient through measurements on Anderson phantom. Conclusions: A computer program for the calculation of total body irradiation (TBI) is described in full. The dose received at each pointon the patient, the calculation of lung shield and the determination of the velocity and time required for the couch movement are all made possible using the software. The ease of use, precision, data storage and printing are some important features of the present software.
SN 1939-8654
PD SEP
PY 2022
VL 53
IS 3
BP 460
EP 470
DI 10.1016/j.jmir.2022.06.013
EA AUG 2022
UT WOS:000862969800020
PM 35907770
ER

PT J
AU Shen, ZX
   Yang, Y
AF Shen, Zhaoxin
   Yang, Ying
TI Real-Time Regulation Model of Physical Fitness Training Intensity Based
   on Wavelet Recursive Fuzzy Neural Network
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
AB It has been widely used in signal processing, image processing, speech recognition and synthesis, pattern recognition, machine vision, machinery fault diagnosis and monitoring, and other scientific and technological fields and has achieved great results. The application potential in nonlinear system identification is increasing. According to the theory of "overload recovery" and "functional reserve", the mathematical model of "load-fitness state" is established to understand the adaptation characteristics and individual characteristics of athletes to sports training. The model is used to simulate the values and time required to reach the maximum fitness state for four types of precompetition reduction plans and to provide a reference for the development of precompetition training plans. The data required for parameter estimation were the actual training data of six outstanding basketball athletes (mean age 18.2 +/- 0.75, mean training years 4.6 +/- 0.49). And the coaches' training plan was not intervened during the test. In order to further reduce the biaxial synchronization error of the sports platform and improve the stability of the system, the wavelet transformation capable of time-varying signal analysis and the recursive structure with dynamic capability were combined with the fuzzy neural network, and the learning ability of the neural network was used to learn and adjust the scaling and translation factors in the wavelet function, the mean and standard deviation in the fuzzy structure, and the connection weights between the layers, according to the biaxial synchronization. The simulation results show that the designed global sliding mode controller can improve the convergence speed of tracking error and ensure the single-axis tracking accuracy of the H-type motion platform compared with the traditional sliding mode controller, and the tracking accuracy and synchronization accuracy of the system can be further improved after adding the cross-coupled synchronization controller, but the improvement of synchronization control accuracy is not very satisfactory due to the fixed selection of the parameters of the cross-coupled controller. Further improvement is needed.
OI Shen, Zhaoxin/0000-0002-6237-4230
SN 1687-5265
EI 1687-5273
PD APR 22
PY 2022
VL 2022
AR 2078642
DI 10.1155/2022/2078642
UT WOS:000793377000004
PM 35498205
ER

PT J
AU Zhang, J
   Li, C
   Liu, GM
   Min, M
   Wang, C
   Li, JY
   Wang, YT
   Yan, HM
   Zuo, ZT
   Huang, W
   Chen, HF
AF Zhang, Jiang
   Li, Chen
   Liu, Ganwanming
   Min, Min
   Wang, Chong
   Li, Jiyi
   Wang, Yuting
   Yan, Hongmei
   Zuo, Zhentao
   Huang, Wei
   Chen, Huafu
TI A CNN-transformer hybrid approach for decoding visual neural activity
   into text
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
AB Background and Objective: Most studies used neural activities evoked by linguistic stimuli such as phrases or sentences to decode the language structure. However, compared to linguistic stimuli, it is more common for the human brain to perceive the outside world through non-linguistic stimuli such as natural images, so only relying on linguistic stimuli cannot fully understand the information perceived by the human brain. To address this, an end-to-end mapping model between visual neural activities evoked by non-linguistic stimuli and visual contents is demanded.
   Methods: Inspired by the success of the Transformer network in neural machine translation and the convolutional neural network (CNN) in computer vision, here a CNN-Transformer hybrid language decoding model is constructed in an end-to-end fashion to decode functional magnetic resonance imaging (fMRI) signals evoked by natural images into descriptive texts about the visual stimuli. Specifically, this model first encodes a semantic sequence extracted by a two-layer 1D CNN from the multi-time visual neural activity into a multi-level abstract representation, then decodes this representation, step by step, into an English sentence.
   Results: Experimental results show that the decoded texts are semantically consistent with the corresponding ground truth annotations. Additionally, by varying the encoding and decoding layers and modifying the original positional encoding of the Transformer, we found that a specific architecture of the Transformer is required in this work.
   Conclusions: The study results indicate that the proposed model can decode the visual neural activities evoked by natural images into descriptive text about the visual stimuli in the form of sentences. Hence, it may be considered as a potential computer-aided tool for neuroscientists to understand the neural mechanism of visual information processing in the human brain in the future. (C) 2021 Elsevier B.V. All rights reserved.
SN 0169-2607
EI 1872-7565
PD FEB
PY 2022
VL 214
AR 106586
DI 10.1016/j.cmpb.2021.106586
UT WOS:000754693200015
PM 34963092
ER

PT J
AU Wang, J
   Luo, YY
   Yi, WM
   Xie, X
AF Wang, Jing
   Luo, Yiyu
   Yi, Weiming
   Xie, Xiang
TI Speaker-Independent Audio-Visual Speech Separation Based on Transformer
   in Multi-Talker Environments
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
AB Speech separation is the task of extracting target speech while suppressing background interference components. In applications like video telephones, visual information about the target speaker is available, which can be leveraged for multi-speaker speech separation. Most previous multi-speaker separation methods are mainly based on convolutional or recurrent neural networks. Recently, Transformer-based Seq2Seq models have achieved state-of-the-art performance in various tasks, such as neural machine translation (NMT), automatic speech recognition (ASR), etc. Transformer has showed an advantage in modeling audio-visual temporal context by multi-head attention blocks through explicitly assigning attention weights. Besides, Transformer doesn't have any recurrent sub-networks, thus supporting parallelization of sequence computation. In this paper, we propose a novel speaker-independent audio-visual speech separation method based on Transformer, which can be flexibly applied to unknown number and identity of speakers. The model receives both audiovisual streams, including noisy spectrogram and speaker lip embeddings, and predicts a complex time-frequency mask for the corresponding target speaker. The model is made up by three main components: audio encoder, visual encoder and Transformer-based mask generator. Two different structures of encoders are investigated and compared, including ResNet-based and Transformer-based. The performance of the proposed method is evaluated in terms of source separation and speech quality metrics. The experimental results on the benchmark GRID dataset show the effectiveness of the method on speaker-independent separation task in multi-talker environments. The model generalizes well to unseen identities of speakers and noise types. Though only trained on 2-speaker mixtures, the model achieves reasonable performance when tested on 2-speaker and 3-speaker mixtures. Besides, the model still shows an advantage compared with previous audio-visual speech separation works.
SN 1745-1361
PD APR
PY 2022
VL E105D
IS 4
BP 766
EP 777
DI 10.1587/transinf.2021EDP7020
UT WOS:000790987300003
ER

PT J
AU Hemrungrojn, S
   Tangwongchai, S
   Charoenboon, T
   Panasawat, M
   Supasitthumrong, T
   Chaipresertsud, P
   Maleevach, P
   Likitjaroen, Y
   Phanthumchinda, K
   Maes, M
AF Hemrungrojn, Solaphat
   Tangwongchai, Sookjaroen
   Charoenboon, Thammanard
   Panasawat, Muthita
   Supasitthumrong, Thitiporn
   Chaipresertsud, Pisit
   Maleevach, Pacharaporn
   Likitjaroen, Yuttachai
   Phanthumchinda, Kammant
   Maes, Michael
TI Use of the Montreal Cognitive Assessment Thai Version to Discriminate
   Amnestic Mild Cognitive Impairment from Alzheimer's Disease and Healthy
   Controls: Machine Learning Results
SO DEMENTIA AND GERIATRIC COGNITIVE DISORDERS
AB Background: The Montreal Cognitive Assessment (MoCA) is an effective and applicable screening instrument to confirm the diagnosis of amnestic mild cognitive impairment (aMCI) from patients with Alzheimer's disease (AD) and healthy controls (HCs). Objectives: This study aimed to determine the reliability and validity of the following: (a) Thai translation of the MoCA (MoCA-Thai) and (b) delineate the key features of aMCI based on the MoCA subdomains. Methods: This study included 60 HCs, 61 aMCI patients, and 60 AD patients. The MoCA-Thai shows adequate psychometric properties including internal consistency, concurrent validity, test-retest validity, and inter-rater reliability. Results: The MoCA-Thai may be employed as a diagnostic criterion to make the diagnosis of aMCI, whereby aMCI patients are discriminated from HC with an area under the receiver-operating characteristic (AUC-ROC) curve of 0.813 and from AD patients with an AUC-ROC curve of 0.938. The best cutoff scores of the MoCA-Thai to discriminate aMCI from HC is <= 24 and from AD > 16. Neural network analysis showed that (a) aberrations in recall was the most important feature of aMCI versus HC with impairments in language and orientation being the second and third most important features and (b) aberrations in visuospatial skills and executive functions were the most important features of AD versus aMCI and that impairments in recall, language, and orientation but not attention, concentration, and working memory, further discriminated AD from aMCI. Conclusions: The MoCA-Thai is an appropriate cognitive assessment tool to be used in the Thai population for the diagnosis of aMCI and AD.
RI Maes, Michael/B-8546-2011; Supasitthumrong, Thitiporn/R-7686-2019
OI Maes, Michael/0000-0002-2012-871X; Supasitthumrong,
   Thitiporn/0000-0001-6555-0781; Phanasathit, Muthita/0000-0002-9196-634X
SN 1420-8008
EI 1421-9824
PD AUG
PY 2021
VL 50
IS 2
BP 183
EP 194
DI 10.1159/000517822
UT WOS:000688545100011
PM 34325427
ER

PT J
AU Ahmed, S
   Kabir, M
   Arif, M
   Khan, ZU
   Yu, DJ
AF Ahmed, Saeed
   Kabir, Muhammad
   Arif, Muhammad
   Khan, Zaheer Ullah
   Yu, Dong-Jun
TI DeepPPSite: A deep learning-based model for analysis and prediction of
   phosphorylation sites using efficient sequence information
SO ANALYTICAL BIOCHEMISTRY
AB Phosphorylation is a ubiquitous type of post-translational modification (PTM) that occurs in both eukaryotic and prokaryotic cells where in a phosphate group binds with amino acid residues. These specific residues, i.e., serine (S), threonine (T), and tyrosine (Y), exhibit diverse functions at the molecular level. Recent studies have determined that some diseases such as cancer, diabetes, and neurodegenerative diseases are caused by abnormal phosphorylation. Based on its potential applications in biological research and drug development, the large-scale identification of phosphorylation sites has attracted interest. Existing wet-lab technologies for targeting phosphorylation sites are overpriced and time consuming. Thus, computational algorithms that can efficiently accelerate the annotation of phosphorylation sites from massive protein sequences are needed. Numerous machine learning-based methods have been implemented for phosphorylation sites prediction. However, despite extensive efforts, existing computational approaches continue to have inadequate performance, particularly in terms of overall ACC, MCC, and AUC. In this paper, we report a novel deep learning-based predictor to overcome these performance hurdles, DeepPPSite, which was constructed using a stacked long short-term memory recurrent network for predicting phosphorylation sites. The proposed technique expediently learns the protein representations from conjoint protein descriptors. The experimental results indicated that our model achieved superior performance on the training dataset for S, T and Y, with MCC values of 0.608, 0.602, and 0.558, respectively, using a 10-fold cross-validation test. We further determined the generalization efficacy of the proposed predictor DeepPPSite by conducting a rigorous independent test. The predictive MCC values were 0.358, 0.356, and 0.350 for the S, T, and Y phosphorylation sites, respectively. Rigorous cross-validation and independent validation tests for the three types of phosphorylation sites demonstrated that the designed DeepPPSite tool significantly outperforms state-of-the-art methods.
RI Kabir, Muhammad/P-3384-2016
OI Kabir, Muhammad/0000-0002-2488-1653; Arif, Muhammad/0000-0003-3950-6618;
   Ahmed, Saeed/0000-0001-6910-7613
SN 0003-2697
EI 1096-0309
PD JAN 1
PY 2021
VL 612
AR 113955
DI 10.1016/j.ab.2020.113955
UT WOS:000597176900004
PM 32949607
ER

PT J
AU Srinivasa, K
   Thilagam, PS
AF Srinivasa, K.
   Thilagam, P. Santhi
TI CLUSTERING AND BOOTSTRAPPING BASED FRAMEWORK FOR NEWS KNOWLEDGE BASE
   COMPLETION
SO COMPUTING AND INFORMATICS
AB Extracting the facts, namely entities and relations, from unstructured sources is an essential step in any knowledge base construction. At the same time, it is also necessary to ensure the completeness of the knowledge base by incremen-tally extracting the new facts from various sources. To date, the knowledge base completion is studied as a problem of knowledge refinement where the missing facts are inferred by reasoning about the information already present in the knowledge base. However, facts missed while extracting the information from multilingual sources are ignored. Hence, this work proposed a generic framework for know-ledge base completion to enrich a knowledge base of crime-related facts extracted from online news articles in the English language, with the facts extracted from low resourced Indian language Hindi news articles. Using the framework, informa-tion from any low-resourced language news articles can be extracted without using language-specific tools like POS tags and using an appropriate machine translation tool. To achieve this, a clustering algorithm is proposed, which explores the redun-dancy among the bilingual collection of news articles by representing the clusters with knowledge base facts unlike the existing Bag of Words representation. From each cluster, the facts extracted from English language articles are bootstrapped to extract the facts from comparable Hindi language articles. This way of boot-strapping within the cluster helps to identify the sentences from a low-resourced language that are enriched with new information related to the facts extracted from a high-resourced language like English. The empirical result shows that the proposed clustering algorithm produced more accurate and high-quality clusters for monolingual and cross-lingual facts, respectively. Experiments also proved that the proposed framework achieves a high recall rate in extracting the new facts from Hindi news articles.
RI Thilagam P, Santhi/GQA-3682-2022
OI Thilagam P, Santhi/0000-0002-8359-1330; k, srinivasa/0000-0002-5341-865X
SN 1335-9150
PY 2021
VL 40
IS 2
BP 318
EP 340
DI 10.31577/cai_2021_2_318
UT WOS:000718900400004
ER

PT J
AU Tang, FG
   Liu, Y
   Li, Y
   Peng, ZW
AF Tang, Fang-Gui
   Liu, Yu
   Li, Yang
   Peng, Zi-Wen
TI A unified multi-level spectral-temporal feature learning framework for
   patient-specific seizure onset detection in EEG signals
SO KNOWLEDGE-BASED SYSTEMS
AB Epileptic seizure onset detection in electroencephalography (EEG) signals is a challenging task due to the severe variation of seizures. Recently, automatic seizure onset detection frameworks fail to fully consider both nonstationary and stochastic characteristics of EEGs in nature, which may lead to information default and further produce suboptimal recognition performance consequently. In this work, we propose a patient-specific seizure onset detection method based on fully exploration of auxiliary supplementary spectral-temporal information in EEG signals. Specifically, prior to feature extraction procedure, EEG signals are firstly decomposed into 5 groups of coefficients at different levels based on the clinical interest. Representative feature in temporal-domain, which is a translation of the nonlinear property of EEG signals, is then extracted by a combination of principal component analysis and common spatial pattern (PCA-CSP) and multivariate multiscale sample entropy (MMSE) in parallel and dimensionally reduced by a tree-based feature selection algorithm. Supplementary information in spectral-domain is further explored by the proposed unified maximum mean discrepancy autoencoder (uMMD-AE). Finally, an optimal combination of features above is identified and fed into a series of support vector machine classifiers with a decision fusion module for the intelligent recognition of epileptic EEGs. The proposed method achieves an average sensitivity, latency and false detection rate of 97.2%, 1.10s and 0.64/h respectively on Children Hospital Boston-Massachusetts Institute of Technology (CHB-MIT) Scalp EEG Database. Competitive experimental results demonstrate the efficacy of the proposed unified multi-level spectral-temporal feature learning framework in epileptic EEG recognition, validating its effectiveness in the automatic patient-specific seizure onset detection. (C) 2020 Published by Elsevier B.V.
RI Li, Yang/AAJ-2985-2020
SN 0950-7051
EI 1872-7409
PD OCT 12
PY 2020
VL 205
AR 106152
DI 10.1016/j.knosys.2020.106152
UT WOS:000566719900003
ER

PT C
AU Li, X
   Qin, T
   Yang, J
   Liu, TY
AF Li, Xiang
   Qin, Tao
   Yang, Jian
   Liu, Tie-Yan
BE Lee, DD
   Sugiyama, M
   Luxburg, UV
   Guyon, I
   Garnett, R
TI LightRNN: Memory and Computation-Efficient Recurrent Neural Networks
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 29 (NIPS 2016)
SE Advances in Neural Information Processing Systems
CT 30th Conference on Neural Information Processing Systems (NIPS)
CY 2016
CL Barcelona, SPAIN
AB Recurrent neural networks (RNNs) have achieved state-of-the-art performances in many natural language processing tasks, such as language modeling and machine translation. However, when the vocabulary is large, the RNN model will become very big (e.g., possibly beyond the memory capacity of a GPU device) and its training will become very inefficient. In this work, we propose a novel technique to tackle this challenge. The key idea is to use 2-Component (2C) shared embedding for word representations. We allocate every word in the vocabulary into a table, each row of which is associated with a vector, and each column associated with another vector. Depending on its position in the table, a word is jointly represented by two components: a row vector and a column vector. Since the words in the same row share the row vector and the words in the same column share the column vector, we only need 2 root vertical bar V vertical bar vectors to represent a vocabulary of vertical bar V vertical bar unique words, which are far less than the vertical bar V vertical bar vectors required by existing approaches. Based on the 2-Component shared embedding, we design a new RNN algorithm and evaluate it using the language modeling task on several benchmark datasets. The results show that our algorithm significantly reduces the model size and speeds up the training process, without sacrifice of accuracy (it achieves similar, if not better, perplexity as compared to state-of-the-art language models). Remarkably, on the One-Billion-Word benchmark Dataset, our algorithm achieves comparable perplexity to previous language models, whilst reducing the model size by a factor of 40-100, and speeding up the training process by a factor of 2. We name our proposed algorithm LightRNN to reflect its very small model size and very high training speed.
SN 1049-5258
PY 2016
VL 29
UT WOS:000458973704037
ER

PT J
AU Meisel, C
   El Atrache, R
   Jackson, M
   Schubach, S
   Ufongene, C
   Loddenkemper, T
AF Meisel, Christian
   El Atrache, Rima
   Jackson, Michele
   Schubach, Sarah
   Ufongene, Claire
   Loddenkemper, Tobias
TI Machine learning from wristband sensor data for wearable, noninvasive
   seizure forecasting
SO EPILEPSIA
AB Objective Seizure forecasting may provide patients with timely warnings to adapt their daily activities and help clinicians deliver more objective, personalized treatments. Although recent work has convincingly demonstrated that seizure risk assessment is in principle possible, these early approaches relied largely on complex, often invasive setups including intracranial electrocorticography, implanted devices, and multichannel electroencephalography, and required patient-specific adaptation or learning to perform optimally, all of which limit translation to broad clinical application. To facilitate broader adaptation of seizure forecasting in clinical practice, noninvasive, easily applicable techniques that reliably assess seizure risk without much prior tuning are crucial. Wristbands that continuously record physiological parameters, including electrodermal activity, body temperature, blood volume pulse, and actigraphy, may afford monitoring of autonomous nervous system function and movement relevant for such a task, hence minimizing potential complications associated with invasive monitoring and avoiding stigma associated with bulky external monitoring devices on the head. Methods Here, we applied deep learning on multimodal wristband sensor data from 69 patients with epilepsy (total duration > 2311 hours, 452 seizures) to assess its capability to forecast seizures in a statistically significant way. Results Using a leave-one-subject-out cross-validation approach, we identified better-than-chance predictability in 43% of the patients. Time-matched seizure surrogate data analyses indicated forecasting not to be driven simply by time of day or vigilance state. Prediction performance peaked when all sensor modalities were used, and did not differ between generalized and focal seizure types, but generally increased with the size of the training dataset, indicating potential further improvement with larger datasets in the future. Significance Collectively, these results show that statistically significant seizure risk assessments are feasible from easy-to-use, noninvasive wearable devices without the need of patient-specific training or parameter optimization.
OI Meisel, Christian/0000-0003-2984-5480; El Atrache,
   Rima/0000-0002-5600-1120; Schubach Branch, Sarah/0000-0002-6329-5761
SN 0013-9580
EI 1528-1167
PD DEC
PY 2020
VL 61
IS 12
BP 2653
EP 2666
DI 10.1111/epi.16719
EA OCT 2020
UT WOS:000576593400001
PM 33040327
ER

PT J
AU Du, ZD
   Guo, Q
   Zhao, YW
   Chen, YJ
   Xu, ZW
   Zhi, T
AF Du, Zidong
   Guo, Qi
   Zhao, Yongwei
   Chen, Yunji
   Xu, Zhiwei
   Zhi, Tian
TI Self-Aware Neural Network Systems: A Survey and New Perspective
SO PROCEEDINGS OF THE IEEE
AB Neural network (NN) processors are specially designed to handle deep learning tasks by utilizing multilayer artificial NNs. They have been demonstrated to be useful in broad application fields such as image recognition, speech processing, machine translation, and scientific computing. Meanwhile, innovative self-aware techniques, whereby a system can dynamically react based on continuously sensed information from the execution environment, have attracted attention from both academia and industry. Actually, various self-aware techniques have been applied to NN systems to significantly improve the computational speed and energy efficiency. This article surveys state-of-the-art self-aware NN systems (SaNNSs), which can be achieved at different layers, that is, the architectural layer, the physical layer, and the circuit layer. At the architectural layer, SaNNS can be characterized from a data-centric perspective where different data properties (i.e., data value, data precision, dataflow, and data distribution) are exploited. At the physical layer, various parameters of physical implementation are considered. At the circuit layer, different logics and devices can be used for high efficiency. In fact, the self-awareness of existing SaNNS is still in a preliminary form. We propose a comprehensive SaNNS from a new perspective, that is, the model layer, to exploit more opportunities for high efficiency. The proposed system is called as MinMaxNN, which features model switching and elastic sparsity based on monitored information from the execution environment. The model switching mechanism implies that models (i.e., min and max model) dynamically switch given different inputs for both efficiency and accuracy. The elastic sparsity mechanism indicates that the sparsity of NNs can be dynamically adjusted in each layer for efficiency. The experimental results show that compared with traditional SaNNS, MinMaxNN can achieve $5.64\times $ and 19.66% performance improvement and energy reduction, respectively, without notable loss of accuracy and negative effects on developers' productivity.
OI Chen, Yunji/0000-0003-3925-5185; zhao, yong wei/0000-0002-5503-4457; Xu,
   Zhiwei/0000-0002-1480-7265
SN 0018-9219
EI 1558-2256
PD JUL
PY 2020
VL 108
IS 7
BP 1047
EP 1067
DI 10.1109/JPROC.2020.2977722
UT WOS:000544973500006
ER

PT J
AU Lee, JE
   Yoo, SB
   Leigh, JH
AF Lee, Jeong-Eun
   Yoo, Su Bin
   Leigh, Ja-Ho
TI Transcultural validation of the return-to-work self-efficacy scale in
   Korean patients with work-related injuries
SO BMC PUBLIC HEALTH
AB BackgroundThis study aimed to develop a Korean version of the Return-to-Work Self-Efficacy (RTWSE)-19 Scale using forward- and backward-translation and investigate the validity of the RTWSE Scale specifically for Korean workers with work-related injuries.MethodsParticipants were 202 injured workers who had filed a claim accepted by the workers' compensation system and had received medical rehabilitation at workers' compensation hospitals following a work-related musculoskeletal injury. Among these participants, 88.1% were male, 54.5% were over 45years, 45.5% were manufacturing employees, and 54.5% were craft or machine operator and assemblers. The 19 item RTWSE-19 scale was developed by Shaw et al. and have three underlying subscales: (i) meeting job demands, (ii) modifying job tasks, and (iii) communicating needs to others. Statistical analysis included exploratory factor analysis (maximum likelihood estimation with oblique quartimin rotation), internal consistency reliability using Cronbach's alpha, and correlations with related measures: pain intensity; fear-avoidance beliefs; general health; depression; and general self-efficacy.ResultsUsing exploratory factor analysis, three factors with 17 items were identified: meeting job demands, modifying job tasks, and communicating needs to others. The removal of two items in the modifying job tasks domain resulted in an increased reliability. The Korean version of the RTWSE-17 showed reasonable model fit (CFI=.963; TLI=.943; RMSEA=.068; SRMR=0.029), satisfactory reliability (r =0.925), no floor and ceiling effect, and construct validity.ConclusionsThe Korean RTWSE-17 scale was found to possess good psychometric properties and could address different injury types ranging from fractures to amputations involved in sub-acute and rehabilitation phases in the Korean context. This study's findings provide insights for practitioners and researchers to return to work after rehabilitation in a Korean clinical and workplace setting.
OI Leigh, Ja-Ho/0000-0003-0465-6392
EI 1471-2458
PD JUN 3
PY 2020
VL 20
IS 1
DI 10.1186/s12889-020-08979-w
UT WOS:000540259000010
PM 32493252
ER

PT J
AU Crole, RL
AF Crole, R. L.
TI The representational adequacy of HYBRID
SO MATHEMATICAL STRUCTURES IN COMPUTER SCIENCE
AB The HYBRID system (Ambler et al. 2002b), implemented within Isabelle/HOL, allows object logics to be represented using higher order abstract syntax (HOAS), and reasoned about using tactical theorem proving in general, and principles of (co)induction in particular. The form of HOAS provided by HYBRID is essentially a lambda calculus with constants.
   Of fundamental interest is the form of the lambda abstractions provided by HYBRID. The user has the convenience of writing lambda abstractions using names for the binding variables. However, each abstraction is actually a definition of a de Bruijn expression, and HYBRID can unwind the user's abstractions (written with names) to machine friendly de Bruijn expressions (without names). In this sense the formal system contains a hybrid of named and nameless bound variable notation.
   In this paper, we present a formal theory in a logical framework, which can be viewed as a model of core HYBRID, and state and prove that the model is representationally adequate for HOAS. In particular, it is the canonical translation function from lambda-expressions to HYBRID that witnesses adequacy. We also prove two results that characterise how HYBRID represents certain classes of lambda-expression.
   We provide the first detailed proof to be published that proper locally nameless de Bruijn expressions and alpha-equivalence classes of lambda-expressions are in bijective correspondence. This result is presented as a form of de Bruijn representational adequacy, and is a key component of the proof of HYBRID adequacy.
   The HYBRID system contains a number of different syntactic classes of expression, and associated abstraction mechanisms. Hence, this paper also aims to provide a self-contained theoretical introduction to both the syntax and key ideas of the system. Although this paper will be of considerable interest to those who wish to work with Hybrid in Isabelle/HOL, a background in automated theorem proving is not essential.
SN 0960-1295
EI 1469-8072
PD JUN
PY 2011
VL 21
IS 3
BP 585
EP 646
DI 10.1017/S0960129511000041
UT WOS:000290523300003
ER

PT J
AU Ng, YB
   Fernando, B
AF Ng, Yan Bin
   Fernando, Basura
TI Forecasting Future Action Sequences With Attention: A New Approach to
   Weakly Supervised Action Forecasting
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
AB Future human action forecasting from partial observations of activities is an important problem in many practical applications such as assistive robotics, video surveillance and security. We present a method to forecast actions for the unseen future of the video using a neural machine translation technique that uses encoder-decoder architecture. The input to this model is the observed RGB video, and the objective is to forecast the correct future symbolic action sequence. Unlike prior methods that make action predictions for some unseen percentage of video one for each frame, we predict the complete action sequence that is required to accomplish the activity. We coin this task action sequence forecasting. To cater for two types of uncertainty in the future predictions, we propose a novel loss function. We show a combination of optimal transport and future uncertainty losses help to improve results. We evaluate our model in three challenging video datasets (Charades, MPII cooking and Breakfast). We extend our action sequence forecasting model to perform weakly supervised action forecasting on two challenging datasets, the Breakfast and the 50Salads. Specifically, we propose a model to predict actions of future unseen frames without using frame level annotations during training. Using Fisher vector features, our supervised model outperforms the state-of-the-art action forecasting model by 0.83% and 7.09% on the Breakfast and the 50Salads datasets respectively. Our weakly supervised model is only 0.6% behind the most recent state-of-the-art supervised model and obtains comparable results to other published fully supervised methods, and sometimes even outperforms them on the Breakfast dataset. Most interestingly, our weakly supervised model outperforms prior models by 1.04% leveraging on proposed weakly supervised architecture, and effective use of attention mechanism and loss functions.
OI Fernando, Basura/0000-0002-6920-9916
SN 1057-7149
EI 1941-0042
PY 2020
VL 29
BP 8880
EP 8891
DI 10.1109/TIP.2020.3021497
UT WOS:000571723000006
PM 32915738
ER

PT J
AU Jochumsen, M
   Cremoux, S
   Robinault, L
   Lauber, J
   Arceo, JC
   Navid, MS
   Nedergaard, RW
   Rashid, U
   Haavik, H
   Niazi, IK
AF Jochumsen, Mads
   Cremoux, Sylvain
   Robinault, Lucien
   Lauber, Jimmy
   Arceo, Juan Carlos
   Navid, Muhammad Samran
   Nedergaard, Rasmus Wiberg
   Rashid, Usman
   Haavik, Heidi
   Niazi, Imran Khan
TI Investigation of Optimal Afferent Feedback Modality for Inducing Neural
   Plasticity with A Self-Paced Brain-Computer Interface
SO SENSORS
AB Brain-computer interfaces (BCIs) can be used to induce neural plasticity in the human nervous system by pairing motor cortical activity with relevant afferent feedback, which can be used in neurorehabilitation. The aim of this study was to identify the optimal type or combination of afferent feedback modalities to increase cortical excitability in a BCI training intervention. In three experimental sessions, 12 healthy participants imagined a dorsiflexion that was decoded by a BCI which activated relevant afferent feedback: (1) electrical nerve stimulation (ES) (peroneal nerve-innervating tibialis anterior), (2) passive movement (PM) of the ankle joint, or (3) combined electrical stimulation and passive movement (Comb). The cortical excitability was assessed with transcranial magnetic stimulation determining motor evoked potentials (MEPs) in tibialis anterior before, immediately after and 30 min after the BCI training. Linear mixed regression models were used to assess the changes in MEPs. The three interventions led to a significant (p < 0.05) increase in MEP amplitudes immediately and 30 min after the training. The effect sizes of Comb paradigm were larger than ES and PM, although, these differences were not statistically significant (p > 0.05). These results indicate that the timing of movement imagery and afferent feedback is the main determinant of induced cortical plasticity whereas the specific type of feedback has a moderate impact. These findings can be important for the translation of such a BCI protocol to the clinical practice where by combining the BCI with the already available equipment cortical plasticity can be effectively induced. The findings in the current study need to be validated in stroke populations.
RI Rashid, Usman/W-9208-2018; Haavik, Heidi/AAG-1084-2021; Niazi, Imran
   Khan/M-3346-2019; Arceo, Juan Carlos/AAV-1804-2020; Navid, Muhammad
   Samran/AAD-4558-2019
OI Rashid, Usman/0000-0002-1109-5493; Haavik, Heidi/0000-0001-7182-2085;
   Niazi, Imran Khan/0000-0001-8752-7224; Arceo, Juan
   Carlos/0000-0002-5324-5488; Navid, Muhammad Samran/0000-0002-2849-874X;
   Jochumsen, Mads/0000-0001-7729-4359; Robinault,
   Lucien/0000-0003-4601-2341; Nedergaard, Rasmus Bach/0000-0003-3271-1408
EI 1424-8220
PD NOV
PY 2018
VL 18
IS 11
AR 3761
DI 10.3390/s18113761
UT WOS:000451598900171
PM 30400325
ER

PT J
AU McLachlin, SD
   Ferreira, LM
   Dunning, CE
AF McLachlin, Stewart D.
   Ferreira, Louis M.
   Dunning, Cynthia E.
TI A Refined Technique to Calculate Finite Helical Axes From Rigid Body
   Trackers
SO JOURNAL OF BIOMECHANICAL ENGINEERING-TRANSACTIONS OF THE ASME
AB Finite helical axes (FHAs) are a potentially effective tool for joint kinematic analysis. Unfortunately, no straightforward guidelines exist for calculating accurate FHAs using prepackaged six degree-of-freedom (6DOF) rigid body trackers. Thus, this study aimed to: (1) describe a protocol for calculating FHA parameters from 6DOF rigid body trackers using the screw matrix and (2) to maximize the number of accurate FHAs generated from a given data set using a moving window analysis. Four OPTOTRAK (R) Smart Markers were used as the rigid body trackers, two moving and two fixed, at different distances from the hinge joint of a custom-machined jig. 6DOF pose information was generated from 51 static positions of the jig rotated and fixed in 0.5 deg increments up to 25 deg. Output metrics included the FHA direction cosines, the rotation about the FHA, the translation along the axis, and the intercept of the FHA with the plane normal to the jig's hinge joint. FHA metrics were calculated using the relative tracker rotation from the starting position, and using a moving window analysis to define a minimum acceptable rotational displacement between the moving tracker data points. Data analysis found all FHA rotations calculated from the starting position were within 0.15 deg of the prescribed jig rotation. FHA intercepts were most stable when determined using trackers closest to the hinge axis. Increasing the moving window size improved the FHA direction cosines and center of rotation accuracy. Window sizes larger than 2 deg had an intercept deviation of less than 1 mm. Furthermore, compared to the 0 deg window size, the 2 deg window had a 90% improvement in FHA intercept precision while generating almost an equivalent number of FHA axes. This work identified a solution to improve FHA calculations for biomechanical researchers looking to describe changes in 3D joint motion.
RI Ferreira, Louis M/K-6771-2013
OI Ferreira, Louis M/0000-0001-9881-9177
SN 0148-0731
EI 1528-8951
PD DEC
PY 2014
VL 136
IS 12
AR 124506
DI 10.1115/1.4028413
UT WOS:000345154300016
PM 25162715
ER

PT J
AU Sharma, M
   Wyszkiewicz, PV
   Desaigoudar, V
   Guo, FM
   Capaldi, DPI
   Parraga, G
AF Sharma, Maksym
   Wyszkiewicz, Paulina, V
   Desaigoudar, Vedanth
   Guo, Fumin
   Capaldi, Dante P., I
   Parraga, Grace
TI Quantification of pulmonary functional MRI: state-of-the-art and
   emerging image processing methods and measurements
SO PHYSICS IN MEDICINE AND BIOLOGY
AB Pulmonary functional magnetic resonance imaging (PfMRI) provides a way to non-invasively map and measure the spatial distribution of pulmonary ventilation, perfusion and gas-exchange abnormalities with unprecedented detail of functional processes at the level of airways, alveoli and the alveolar-capillary membrane. Current PfMRI approaches are dominated by hyperpolarized helium-3 (He-3) and xenon-129 (Xe-129) gases, which both provide rapid (8-15 s) and well-tolerated imaging examinations in patients with severe pulmonary diseases and pediatric populations, whilst employing no ionizing radiation. While a number of review papers summarize the required image acquisition hardware and software requirements needed to enable PfMRI, here we focus on the image analysis and processing methods required for reproducible measurements using hyperpolarized gas ventilation MRI. We start with the transition in the literature from qualitative and subjective scoring systems to quantitative and objective measurements which enable precise quantification of the lung's critical structure-function relationship. We provide an overview of quantitative biomarkers and the relevant respiratory system parameters that may be measured using PfMRI methods, outlining the history of developments in the field, current methods and then knowledge gaps and typical limitations. We focus on hyperpolarized noble gas MR image processing methods used for quantifying ventilation and gas distribution in the lungs, and discuss the utility and applications of imaging biomarkers generated through these techniques. We conclude with a summary of the current and future directions to further the development of image processing methods, and discuss the remaining challenges for potential clinical translation of these approaches and their integration into standard clinical workflows.
RI Parraga, Grace/K-6465-2013
SN 0031-9155
EI 1361-6560
PD NOV 21
PY 2022
VL 67
IS 22
AR 22TR01
DI 10.1088/1361-6560/ac9510
UT WOS:000882151300001
PM 36162409
ER

PT J
AU Budde, B
   Maksimenko, V
   Sarink, K
   Seidenbecher, T
   van Luijtelaar, G
   Hahn, T
   Pape, HC
   Luttjohann, A
AF Budde, Bjoern
   Maksimenko, Vladimir
   Sarink, Kelvin
   Seidenbecher, Thomas
   van Luijtelaar, Gilles
   Hahn, Tim
   Pape, Hans-Christian
   Luettjohann, Annika
TI Seizure Prediction in Genetic Rat Models of Absence Epilepsy: Improved
   Performance through Multiple-Site Cortico-Thalamic Recordings Combined
   withMachine Learning
SO ENEURO
AB Seizure prediction is the grand challenge of epileptology. However, effort was devoted to prediction of focal seizures, while generalized seizures were regarded as stochastic events. Long-lasting local field potential (LFP) recordings containing several hundred generalized spike and wave discharges (SWDs), acquired at eight locations in the cortico-thalamic system of absence epileptic rats, were iteratively analyzed in all possible combinations of either two or three recording sites, by a wavelet-based algorithm, calculating the product of the wavelet-energy signaling increases in synchronicity. Sensitivity and false alarm rate of prediction were compared between various combinations, and wavelet spectra of true and false positive predictions were fed to a random forest machine learning algorithm to further differentiate between them. Wavelet analysis of intracortical and cortico-thalamic LFP traces showed a significantly smaller number of false alarms compared with intrathalamic combinations, while predictions based on recordings in Layers IV, V, and VI of the somatosensory-cortex significantly outreached all other combinations in terms of prediction sensitivity. In 24-h out-of-sample recordings of nine Genetic Absence Epilepsy Rats from Strasbourg (GAERS), containing diurnal fluctuations of SWD occurrence, classification of true and false positives by the trained random forest further reduced the false alarm rate by 71%, although at some trade-off between false alarms and sensitivity of prediction, as reflected in relatively low F1 score values. Results provide support for the cortical-focus theory of absence epilepsy and allow the conclusion that SWDs are predictable to some degree. The latter paves the way for the development of closed-loop SWD prediction-prevention systems. Suggestions for a possible translation to human data are outlined.
OI Luttjohann, Annika/0000-0002-9248-1264; Sarink,
   Kelvin/0000-0002-4840-5619
EI 2373-2822
PD JAN-FEB
PY 2022
VL 9
IS 1
AR 0160-21.2021
DI 10.1523/ENEURO.0160-21.2021
UT WOS:000754749800001
PM 34782347
ER

PT J
AU Buongiorno, D
   Cascarano, GD
   De Feudis, I
   Brunetti, A
   Carnimeo, L
   Dimauro, G
   Bevilacqua, V
AF Buongiorno, Domenico
   Cascarano, Giacomo Donato
   De Feudis, Irio
   Brunetti, Antonio
   Carnimeo, Leonarda
   Dimauro, Giovanni
   Bevilacqua, Vitoantonio
TI Deep learning for processing electromyographic signals: A taxonomy-based
   survey
SO NEUROCOMPUTING
AB Deep Learning (DL) has been recently employed to build smart systems that perform incredibly well in a wide range of tasks, such as image recognition, machine translation, and self-driving cars. In several fields the considerable improvement in the computing hardware and the increasing need for big data analytics has boosted DL work. In recent years physiological signal processing has strongly benefited from deep learning. In general, there is an exponential increase in the number of studies concerning the processing of electromyographic (EMG) signals using DL methods. This phenomenon is mostly explained by the current limitation of myoelectric controlled prostheses as well as the recent release of large EMG recording datasets, e.g. Ninapro. Such a growing trend has inspired us to seek and review recent papers focusing on processing EMG signals using DL methods. Referring to the Scopus database, a systematic literature search of papers published between January 2014 and March 2019 was carried out, and sixty-five papers were chosen for review after a full text analysis. The bibliometric research revealed that the reviewed papers can be grouped in four main categories according to the final application of the EMG signal analysis: Hand Gesture Classification, Speech and Emotion Classification, Sleep Stage Classification and Other Applications. The review process also confirmed the increasing trend in terms of published papers, the number of papers published in 2018 is indeed four times the amount of papers published the year before. As expected, most of the analyzed papers (= 60 %) concern the identification of hand gestures, thus supporting our hypothesis. Finally, it is worth reporting that the convolutional neural network (CNN) is the most used topology among the several involved DL architectures, in fact, the sixty percent approximately of the reviewed articles consider a CNN.
   (c) 2020 Elsevier B.V. All rights reserved.
RI Dimauro, Giovanni/AAC-8683-2020; Bevilacqua, Vitoantonio/AAF-5588-2020;
   Buongiorno, Domenico/X-4896-2018
OI Dimauro, Giovanni/0000-0002-4120-5876; Buongiorno,
   Domenico/0000-0002-2024-5369
SN 0925-2312
EI 1872-8286
PD SEP 10
PY 2021
VL 452
BP 549
EP 565
DI 10.1016/j.neucom.2020.06.139
EA JUN 2021
UT WOS:000663092100007
ER

PT J
AU Hamann, F
   Zimmerningkat, LC
   Becker, RA
   Garbers, TB
   Neumann, P
   Hub, JS
   Ficner, R
AF Hamann, Florian
   Zimmerningkat, Lars C.
   Becker, Robert A.
   Garbers, Tim B.
   Neumann, Piotr
   Hub, Jochen S.
   Ficner, Ralf
TI The structure of Prp2 bound to RNA and ADP-BeF3- reveals structural
   features important for RNA unwinding by DEAH-box ATPases
SO ACTA CRYSTALLOGRAPHICA SECTION D-STRUCTURAL BIOLOGY
AB Noncoding intron sequences present in precursor mRNAs need to be removed prior to translation, and they are excised via the spliceosome, a multimegadalton molecular machine composed of numerous protein and RNA components. The DEAH-box ATPase Prp2 plays a crucial role during pre-mRNA splicing as it ensures the catalytic activation of the spliceosome. Despite high structural similarity to other spliceosomal DEAH-box helicases, Prp2 does not seem to function as an RNA helicase, but rather as an RNA-dependent ribonucleoprotein particle-modifying ATPase. Recent crystal structures of the spliceosomal DEAH-box ATPases Prp43 and Prp22, as well as of the related RNA helicase MLE, in complex with RNA have contributed to a better understanding of how RNA binding and processivity might be achieved in this helicase family. In order to shed light onto the divergent manner of function of Prp2, an N-terminally truncated construct of Chaetomium thermophilum Prp2 was crystallized in the presence of ADP-BeF3- and a poly-U-12 RNA. The refined structure revealed a virtually identical conformation of the helicase core compared with the ADP-BeF3-- and RNA-bound structure of Prp43, and only a minor shift of the C-terminal domains. However, Prp2 and Prp43 differ in the hook-loop and a loop of the helix-bundle domain, which interacts with the hook-loop and evokes a different RNA conformation immediately after the 3' stack. On replacing these loop residues in Prp43 by the Prp2 sequence, the unwinding activity of Prp43 was abolished. Furthermore, a putative exit tunnel for the gamma-phosphate after ATP hydrolysis could be identified in one of the Prp2 structures.
SN 2059-7983
PD APR 1
PY 2021
VL 77
BP 496
EP 509
DI 10.1107/S2059798321001194
PN 4
UT WOS:000637815400011
PM 33825710
ER

PT J
AU Delvaux, N
   Vaes, B
   Aertgeerts, B
   Van de Velde, S
   Vander Stichele, R
   Nyberg, P
   Vermandere, M
AF Delvaux, Nicolas
   Vaes, Bert
   Aertgeerts, Bert
   Van de Velde, Stijn
   Vander Stichele, Robert
   Nyberg, Peter
   Vermandere, Mieke
TI Coding Systems for Clinical Decision Support: Theoretical and Real-World
   Comparative Analysis
SO JMIR FORMATIVE RESEARCH
AB Background: Effective clinical decision support systems require accurate translation of practice recommendations into machine-readable artifacts; developing code sets that represent clinical concepts are an important step in this process. Many clinical coding systems are currently used in electronic health records, and it is unclear whether all of these systems are capable of efficiently representing the clinical concepts required in executing clinical decision support systems.
   Objective: The aim of this study was to evaluate which clinical coding systems are capable of efficiently representing clinical concepts that are necessary for translating artifacts into executable code for clinical decision support systems.
   Methods: Two methods were used to evaluate a set of clinical coding systems. In a theoretical approach, we extracted all the clinical concepts from 3 preventive care recommendations and constructed a series of code sets containing codes from a single clinical coding system. In a practical approach using data from a real-world setting, we studied the content of 1890 code sets used in an internationally available clinical decision support system and compared the usage of various clinical coding systems.
   Results: SNOMED CT and ICD-10 (International Classification of Diseases, Tenth Revision) proved to be the most accurate clinical coding systems for most concepts in our theoretical evaluation. In our practical evaluation, we found that International Classification of Diseases (Tenth Revision) was most often used to construct code sets. Some coding systems were very accurate in representing specific types of clinical concepts, for example, LOINC (Logical Observation Identifiers Names and Codes) for investigation results and ATC (Anatomical Therapeutic Chemical Classification) for drugs.
   Conclusions: No single coding system seems to fulfill all the needs for representing clinical concepts for clinical decision support systems. Comprehensiveness of the coding systems seems to be offset by complexity and forms a barrier to usability for code set construction. Clinical vocabularies mapped to multiple clinical coding systems could facilitate clinical code set construction.
RI Van de Velde, Stijn/F-6449-2013; Vander Stichele, Robert/K-7203-2015
OI Van de Velde, Stijn/0000-0001-8908-3823; Aertgeerts,
   Bert/0000-0003-1142-5402; Vermandere, Mieke/0000-0002-0437-6633; Vander
   Stichele, Robert/0000-0001-9118-9651; Vaes, Bert/0000-0001-5244-1930
EI 2561-326X
PD OCT
PY 2020
VL 4
IS 10
AR e16094
DI 10.2196/16094
UT WOS:000853426500009
PM 33084593
ER

PT C
AU Junger, L
   Bolke, JLM
   Tobies, S
   Leupers, R
   Hoffmann, A
AF Juenger, Lukas
   Bolke, Jan Luca Malte
   Tobies, Stephan
   Leupers, Rainer
   Hoffmann, Andreas
BE DiNatale, G
   Bolchini, C
   Vatajelu, EI
TI ARM-on-ARM: Leveraging Virtualization Extensions for Fast Virtual
   Platforms
SO PROCEEDINGS OF THE 2020 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2020)
SE Design Automation and Test in Europe Conference and Exhibition
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 09-13, 2020
CL Grenoble, FRANCE
SP European Design & Automat Assoc, SEMI Strateg Technol Community & Elect Syst Design Alliance, IEEE Council Elect Design Automat, European Elect Chips & Syst Design Initiat, ACM Special Interest Grp Design Automat, Russian Acad Sci, IEEE Comp Soc, Test Technol Tech Council, IEEE Solid State Circuits Soc, Int Federat Informat Proc, Grenoble INP, Inria, Autonomous Intelligent Driving, Cadence, List Ceatech, Leti Ceatech, Univ Grenoble Alpes, Cybersecur Inst, Hisilicon, IEEE Council Elect Design Automat, Intel, NanoElec, Mentor Graph, ST, Synopsys
AB Virtual Platforms (VPs) are an essential enabling technology in the System-on-a-Chip (SoC) development cycle. They are used for early software development and hardware/software codesign. However, since virtual prototyping is limited by simulation performance, improving the simulation speed of VPs has been an active research topic for years. Different strategies have been proposed, such as fast instruction set simulation using Dynamic Binary Translation (DBT). But even fast simulators do not reach native execution speed. They do however allow executing rich Operating System (OS) kernels, which is typically infeasible when another OS is already running.
   Executing multiple OSs on shared physical hardware is typically accomplished by using virtualization, which has a long history on x86 hardware. It enables encapsulated, native code execution on the host processor and has been extensively used in data centers, where many users share hardware resources. When it comes to embedded systems, virtualization has been made available recently. For ARM processors, virtualization was introduced with the ARM Virtualization Extensions for the ARMv7 architecture. Since virtualization allows native guest code execution, near-native execution speeds can be reached.
   In this work we present a VP containing a novel ARMv8 SystemC Transaction Level Modeling 2.0 (TLM) compatible processor model. The model leverages the ARM Virtualization Extensions (VE) via the Linux Kernel-based Virtual Machine (KVM) to execute the target software natively on an ARMv8 host. To enable the integration of the processor model into a loosely-timed VP, we developed an accurate instruction counting mechanism using the ARM Performance Monitors Extension (PMU). The requirements for integrating the processor model into a VP and the integration process are detailed in this work.
   Our evaluations show that speedups of up to 2.57x over state-of-the-art DBT-based simulator can be achieved using our processor model on ARMv8 hardware.
SN 1530-1591
BN 978-3-9819263-4-7
PY 2020
BP 1508
EP 1513
UT WOS:000610549200275
ER

PT J
AU Budge, MD
   Kurdziel, MD
   Baker, KC
   Wiater, JM
AF Budge, Matthew D.
   Kurdziel, Michael D.
   Baker, Kevin C.
   Wiater, J. Michael
TI A biomechanical analysis of initial fixation options for
   porous-tantalum-backed glenoid components
SO JOURNAL OF SHOULDER AND ELBOW SURGERY
AB Background: Porous-tantalum (PT)-backed glenoid components have recently been developed to improve fixation and minimize the incidence of glenoid component loosening, which remains a key limiting factor in long-term survival in total shoulder arthroplasty. PT-backed glenoids promote bony ingrowth as a method of preventing glenoid loosening at the prosthesis-glenoid interface. The use of polymethyl-methacrylate (PMMA) cement for initial fixation may prevent osteointegration due to mechanical occlusion of the porous surface and the nonosteoconductive properties of PMMA. This study aims to investigate alternative fixation methods of PT-backed glenoids in a biomechanical investigation.
   Materials and methods: Nine PT-backed monoblock glenoid components were implanted in a polyurethane bone substitute using either press-fit, PMMA cement, or calcium phosphate cement techniques. A control group of 3 all-polyethylene pegged glenoid components was implanted with PMMA. Glenoid and humeral head components were fixed to a biomechanical testing machine for testing according to ASTM Standard F-2028. The humeral head was translated +/- 1.5 mm along the superior-inferior axis for 50,000 cycles for characterization of glenoid rocking and inferior-superior translation.
   Results: Glenoid compression and glenoid distraction followed similar patterns for PT-backed glenoids. Overall, the all-polyethylene cemented glenoid demonstrated superior fixation compared to all PT-backed groups throughout the test. Glenoids fixed with PMMA cement displayed more favorable initial fixation and resistance to glenoid motion throughout cyclic testing.
   Conclusion: This study showed that among PT-backed glenoids, PMMA fixation provided an increase in stability during initial and final cycles compared to press-fit and calcium-phosphate fixation techniques. This improved stability may enhance the osteointegration of the implant. (C) 2013 Journal of Shoulder and Elbow Surgery Board of Trustees.
OI Baker, Kevin/0000-0001-8257-5673
SN 1058-2746
PD MAY
PY 2013
VL 22
IS 5
BP 709
EP 715
DI 10.1016/j.jse.2012.07.001
UT WOS:000318678200025
PM 22999848
ER

PT J
AU Hauser, T
   LeBeau, R
AF Hauser, Thomas
   LeBeau, Raymond
TI OPTIMIZATION OF A COMPUTATIONAL FLUID DYNAMICS CODE FOR THE MEMORY
   HIERARCHY: A CASE STUDY
SO INTERNATIONAL JOURNAL OF HIGH PERFORMANCE COMPUTING APPLICATIONS
AB With the current shift of increasing the computational power of a processor by including multiple cores instead of increasing the clock frequency, consideration of computational efficiency is gaining increased importance for computational fluid dynamics codes. This is especially critical for applications that require high throughput. For example, applying computational fluid dynamics simulations to multi-disciplinary design optimization requires a large number of similar simulations with different input parameters. Therefore, a reduction in the runtime of the code can lead to large reduction in the design process. In our case study, a two-dimensional, block-structured computational fluid dynamics code was optimized for performance on machines with hierarchical memory systems. This paper illustrates the techniques applied to transform an initial version of the code to an optimized version that yielded performance improvements of 10% for very small cases to about 50% for large test cases that did not fit into the cache memory of the target processor. A detailed performance analysis of the code starting at the global level down to subroutines and data structures is presented in this paper. The performance improvements can be explained through a reduction of cache misses in all levels of the memory hierarchy. The L1 cache misses were reduced by about 50%, the L2 cache misses by about 80% and the translation lookaside buffer misses by about 90% for the optimized version of the code. The code performance was also evaluated for multi-core processors, where efficiency is especially important when several instances of an application are running simultaneously. In this case, the most optimized version, a blocked version of the optimized code, more effectively maintained efficiency as more cores were activated compared to the unblocked version. This illustrates that optimizing cache performance may be increasingly important as the number of cores per processor continues to rise.
OI Hauser, Thomas/0000-0003-1170-6749
SN 1094-3420
EI 1741-2846
PD AUG
PY 2010
VL 24
IS 3
BP 299
EP 318
DI 10.1177/1094342009358413
UT WOS:000280611300004
ER

PT J
AU Ford, JN
   Sweeney, EM
   Skafida, M
   Glynn, S
   Amoashiy, M
   Lange, DJ
   Lin, E
   Chiang, GC
   Osborne, JR
   Pahlajani, S
   de Leon, MJ
   Ivanidze, J
AF Ford, Jeremy N.
   Sweeney, Elizabeth M.
   Skafida, Myrto
   Glynn, Shannon
   Amoashiy, Michael
   Lange, Dale J.
   Lin, Eaton
   Chiang, Gloria C.
   Osborne, Joseph R.
   Pahlajani, Silky
   de Leon, Mony J.
   Ivanidze, Jana
TI Heuristic scoring method utilizing FDG-PET statistical parametric
   mapping in the evaluation of suspected Alzheimer disease and
   frontotemporal lobar degeneration
SO AMERICAN JOURNAL OF NUCLEAR MEDICINE AND MOLECULAR IMAGING
AB Distinguishing frontotemporal lobar degeneration (FTLD) and Alzheimer Disease (AD) on FDG-PET based on qualitative review alone can pose a diagnostic challenge. SPM has been shown to improve diagnostic performance in research settings, but translation to clinical practice has been lacking. Our purpose was to create a heuristic scoring method based on statistical parametric mapping z-scores. We aimed to compare the performance of the scoring method to the initial qualitative read and a machine learning (ML)-based method as benchmarks. FDG-PET/CT or PET/MRI of 65 patients with suspected dementia were processed using SPM software, yielding z-scores from either whole brain (W) or cerebellar (C) normalization relative to a healthy cohort. A non-ML, heuristic scoring system was applied using region counts below a preset z-score cutoff. W z-scores, C z-scores, or WC z-scores (z-scores from both W and C normalization) served as features to build random forest models. The neurological diagnosis was used as the gold standard. The sensitivity of the non-ML scoring system and the random forest models to detect AD was higher than the initial qualitative read of the standard FDG-PET [0.89-1.00 vs. 0.22 (95% CI, 0-0.33)]. A categorical random forest model to distinguish AD, FTLD, and normal cases had similar accuracy than the non-ML scoring model (0.63 vs. 0.61). Our non-ML-based scoring system of SPM z-scores approximated the diagnostic performance of a ML-based method and demonstrated higher sensitivity in the detection of AD compared to qualitative reads. This approach may improve the diagnostic performance.
SN 2160-8407
PY 2021
VL 11
IS 4
BP 313
EP 326
UT WOS:000709287900009
PM 34513285
ER

PT J
AU Ajmi, C
   Zapata, J
   Elferchichi, S
   Zaafouri, A
   Laabidi, K
AF Ajmi, Chiraz
   Zapata, Juan
   Elferchichi, Sabra
   Zaafouri, Abderrahmen
   Laabidi, Kaouther
TI Deep Learning Technology for Weld Defects Classification Based on
   Transfer Learning and Activation Features
SO ADVANCES IN MATERIALS SCIENCE AND ENGINEERING
AB Weld defects detection using X-ray images is an effective method of nondestructive testing. Conventionally, this work is based on qualified human experts, although it requires their personal intervention for the extraction and classification of heterogeneity. Many approaches have been done using machine learning (ML) and image processing tools to solve those tasks. Although the detection and classification have been enhanced with regard to the problems of low contrast and poor quality, their result is still unsatisfying. Unlike the previous research based on ML, this paper proposes a novel classification method based on deep learning network. In this work, an original approach based on the use of the pretrained network AlexNet architecture aims at the classification of the shortcomings of welds and the increase of the correct recognition in our dataset. Transfer learning is used as methodology with the pretrained AlexNet model. For deep learning applications, a large amount of X-ray images is required, but there are few datasets of pipeline welding defects. For this, we have enhanced our dataset focusing on two types of defects and augmented using data augmentation (random image transformations over data such as translation and reflection). Finally, a fine-tuning technique is applied to classify the welding images and is compared to the deep convolutional activation features (DCFA) and several pretrained DCNN models, namely, VGG-16, VGG-19, ResNet50, ResNet101, and GoogLeNet. The main objective of this work is to explore the capacity of AlexNet and different pretrained architecture with transfer learning for the classification of X-ray images. The accuracy achieved with our model is thoroughly presented. The experimental results obtained on the weld dataset with our proposed model are validated using GDXray database. The results obtained also in the validation test set are compared to the others offered by DCNN models, which show a best performance in less time. This can be seen as evidence of the strength of our proposed classification model.
RI Zaafouri, Abderrahmen/AFG-5703-2022
SN 1687-8434
EI 1687-8442
PD AUG 14
PY 2020
VL 2020
AR 1574350
DI 10.1155/2020/1574350
UT WOS:000565209700001
ER

PT J
AU Gong, ZY
   Tao, B
   Qiu, CR
   Yin, ZP
   Ding, H
AF Gong, Zeyu
   Tao, Bo
   Qiu, Chunrong
   Yin, Zhouping
   Ding, Han
TI Trajectory Planning With Shortest Path for Modified Uncalibrated Visual
   Servoing Based on Projective Homography
SO IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING
AB In order to improve the robustness and optimize trajectory of projective homography-based uncalibrated visual servoing (PHUVS) proposed in our previous work, an analytical expression of optimal trajectory for camera in projective homography space is proposed in this article, which is totally free of camera parameters and is corresponding to camera's shortest path in the 3-D space with straight path in translation and minimal geodesic in rotation. The projective homography is computed without scale ambiguity in both planning and tracking stages. The PHUVS controller is modified correspondingly to track the planned trajectory in projective homography space while maintaining superior characteristic of PHUVS under uncalibrated scenario. The simulations and experiments' results reveal the effectiveness and necessity of the proposed trajectory optimization method in the existence of large initial errors. Note to Practitioners-The state-of-the-art visual-guided robotic technology in industry usually requires system calibration, which is often costly, vulnerable, and challenging for ordinary workers. In our previous work, we offered an uncalibrated visual servo method based on projective homography named projective homography-based uncalibrated visual servoing (PHUVS), which is suitable for plug and play application for eye-in-hand robot visual servo tasks. However, PHUVS suffers from some defects, including undesirable 3-D space motion and local convergence. In this article, we proposed the trajectory planning method along with a modified PHUVS controller to improve the original one from the disadvantages mentioned earlier. This planning method is also calibration-free. With pure image information, a straight-line path in translational motion along with minimal geodesic in rotary motion can be achieved. This approach is capable of extending the range of applications for uncalibrated visual servo technology in robotic tasks, such as assembling, painting, and robotic machining.
RI Bo, Tao/AFE-7417-2022; Gong, Zeyu/AAR-9747-2021
OI Gong, Zeyu/0000-0002-8276-675X
SN 1545-5955
EI 1558-3783
PD APR
PY 2020
VL 17
IS 2
BP 1076
EP 1083
DI 10.1109/TASE.2019.2954598
UT WOS:000528673100044
ER

PT J
AU Vaiyapuri, T
   Alaskar, H
AF Vaiyapuri, Thavavel
   Alaskar, Haya
TI Whale Optimization for Wavelet-Based Unsupervised Medical Image
   Segmentation: Application to CT and MR Images
SO INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS
AB Image segmentation plays crucial role in medical analysis and forms the basis tor clinical diagnosis and patient's treatment planning. But the large variation in organ shapes, inhomogeneous intensities, poor contrast, organic nature of textures and complex boundaries in medical images makes segmentation process adverse and challenging. Further, the absence of annotated ground-truth dataset in medical field limits the advantages of the trending deep learning techniques causing several setbacks. Though numerous unsupervised methods are reported in literature to combat the challenges in medical domain, achieving better segmentation quality still remains as an open issue. This mirk aim to address this issue integrating the strength of multiresolution analysis and the meta heuristic optimization techniques for unsupervised medical image segmentation. The proposed approach employs undecimated wavelet frames to extract translation invariant texture and gray information at different orientations to effectively characterize the textures M medical images. Next, the approach introduces the latest meta-heuristic whale optimization algorithm (\VOA), the global optimizer to enhance the performance c unsupervised clustering algorithm With optimized cluster centers to cluster the extracted Wavelet texture features. Moreover; the study contributes to fill the gap in hterature investigating for the first time different intelligence algorithms such as fuzzy, genetic algorithm (GA) and particle swarm optimization (PSO) for unsupervised medical image segmentation to demonstrate the efficacy of the proposed approach. Evaluation was performed on medical CT and MR images based on 'feature similarity (FSIM), dice (DC) and 'feature of merits (F 0Ms). Experimental results demonstrates the supremacy of the proposed approach over other intelligence algorithms. Finally, statistical study with ANOVA analysis was carried out to confirm the significance of the proposed approach in determining the optimal solution and displaying promising segmentation results toward diagnostic support for radiologist. (C) 2020 The Authors. Published by Atlantis Press SARL.
RI alaskar, haya/ABD-7547-2021; Vaiyapuri, Thavavel/AAH-3492-2021; Alaskar,
   Haya/AAM-6119-2020
OI alaskar, haya/0000-0002-1688-0669; Vaiyapuri,
   Thavavel/0000-0001-5494-5278; Alaskar, Haya/0000-0002-1688-0669
SN 1875-6891
EI 1875-6883
PY 2020
VL 13
IS 1
BP 941
EP 953
DI 10.2991/ijcis.d.20065.001
UT WOS:000565532900042
ER

PT J
AU Lindgren, P
   Eriksson, J
   Lindner, M
   Lindner, A
   Pereira, D
   Pinho, LM
AF Lindgren, Per
   Eriksson, Johan
   Lindner, Marcus
   Lindner, Andreas
   Pereira, David
   Pinho, Lus Miguel
TI End-to-End Response Time of IEC 61499 Distributed Applications Over
   Switched Ethernet
SO IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS
AB The IEC 61499 standard provides means to specify distributed control systems in terms of function blocks. For the deployment, each device may hold one or many logical resources, each consisting of a function block network with service interface blocks at the edges. The execution model is event driven (asynchronous), where triggering events may be associated with data (and seen as messages). In this paper, we propose a low-complexity implementation technique allowing to assess end-to-end response times of event chains spanning over a set of networked devices. Based on a translation of IEC 61499 to RTFM1-tasks and resources, the response time for each task in the system at the device-level can be derived using established scheduling techniques. In this paper, we develop a holistic method to provide safe end-to-end response times taking both intra and interdevice delivery delays into account. The novelty of our approach is the accuracy of the system scheduling overhead characterization. While the device-level (RTFM) scheduling overhead was discussed in previous works, the network-level scheduling overhead for switched Ethernets is discussed in this paper. The approach is generally applicable to a wide range of commercial off-the-shelf Ethernet switches without a need for expensive custom solutions to provide hard real-time performance. A behavior characterization of the utilized switch determines the guaranteed response times. As a use case, we study the implementation onto (single-core) Advanced RISC Machine (ARM)-cortex-based devices communicating over a switched Ethernet network. For the analysis, we define a generic switch model and an experimental setup allowing us to study the impact of network topology as well as 802.1Q quality of service in a mixed critical setting. Our results indicate that safe sub millisecond end-to-end response times can be obtained using the proposed approach.
RI Pinho, Luis Miguel/M-3416-2013; Pereira, David/X-6401-2019; Lindner,
   Andreas/E-3022-2017
OI Pinho, Luis Miguel/0000-0001-6888-1340; Pereira,
   David/0000-0002-7561-6649; Lindner, Andreas/0000-0001-5311-1781
SN 1551-3203
EI 1941-0050
PD FEB
PY 2017
VL 13
IS 1
BP 287
EP 297
DI 10.1109/TII.2016.2626463
UT WOS:000395874400029
ER

PT J
AU Cuklina, J
   Hahn, J
   Imakaev, M
   Omasits, U
   Forstner, KU
   Ljubimov, N
   Goebel, M
   Pessi, G
   Fischer, HM
   Ahrens, CH
   Gelfand, MS
   Evguenieva-Hackenberg, E
AF Cuklina, Jelena
   Hahn, Julia
   Imakaev, Maxim
   Omasits, Ulrich
   Foerstner, Konrad U.
   Ljubimov, Nikolay
   Goebel, Melanie
   Pessi, Gabriella
   Fischer, Hans-Martin
   Ahrens, Christian H.
   Gelfand, Mikhail S.
   Evguenieva-Hackenberg, Elena
TI Genome-wide transcription start site mapping of Bradyrhizobium japonicum
   grown free-living or in symbiosis - a rich resource to identify new
   transcripts, proteins and to study gene regulation
SO BMC GENOMICS
AB Background: Differential RNA-sequencing (dRNA-seq) is indispensable for determination of primary transcriptomes. However, using dRNA-seq data to map transcriptional start sites (TSSs) and promoters genome-wide is a bioinformatics challenge. We performed dRNA-seq of Bradyrhizobium japonicum USDA 110, the nitrogen-fixing symbiont of soybean, and developed algorithms to map TSSs and promoters.
   Results: A specialized machine learning procedure for TSS recognition allowed us to map 15,923 TSSs: 14,360 in free-living bacteria, 4329 in symbiosis with soybean and 2766 in both conditions. Further, we provide proteomic evidence for 4090 proteins, among them 107 proteins corresponding to new genes and 178 proteins with N-termini different from the existing annotation (72 and 109 of them with TSS support, respectively). Guided by proteomics evidence, previously identified TSSs and TSSs experimentally validated here, we assign a score threshold to flag 14 % of the mapped TSSs as a class of lower confidence. However, this class of lower confidence contains valid TSSs of low-abundant transcripts. Moreover, we developed a de novo algorithm to identify promoter motifs upstream of mapped TSSs, which is publicly available, and found motifs mainly used in symbiosis (similar to RpoN-dependent promoters) or under both conditions (similar to RpoD-dependent promoters). Mapped TSSs and putative promoters, proteomic evidence and updated gene annotation were combined into an annotation file.
   Conclusions: The genome-wide TSS and promoter maps along with the extended genome annotation of B. japonicum represent a valuable resource for future systems biology studies and for detailed analyses of individual non-coding transcripts and ORFs. Our data will also provide new insights into bacterial gene regulation during the agriculturally important symbiosis between rhizobia and legumes.
RI Pessi, Gabriella/AGW-2342-2022; Förstner, Konrad U./B-1531-2010;
   Gelfand, Mikhail S/F-3425-2012; Ahrens, Christian H./F-4656-2011;
   Evguenieva-Hackenberg, Elena/ABA-8876-2020
OI Förstner, Konrad U./0000-0002-1481-2996; Ahrens, Christian
   H./0000-0002-8148-7257; Evguenieva-Hackenberg,
   Elena/0000-0001-7270-3168; Pessi, Gabriella/0000-0002-8138-5541;
   Gelfand, Mikhail/0000-0003-4181-0846; Cuklina,
   Jelena/0000-0002-3837-9349
SN 1471-2164
PD APR 23
PY 2016
VL 17
AR 302
DI 10.1186/s12864-016-2602-9
UT WOS:000374946400001
PM 27107716
ER

PT C
AU Abood, RH
   Tiun, S
AF Abood, Rehab Hasan
   Tiun, Sabrina
BE Hisyamudin, MNN
   Amir, K
   AlEmran, I
   Rasidi, IM
   Faizal, MBM
   Sani, MJMA
   Mubarak, TAA
   Izzuddin, Z
   Sofian, M
TI A Comparative Study of Open-Domain and Specific-Domain Word Sense
   Disambiguation Based on Quranic Information Retrieval
SO 8TH INTERNATIONAL CONFERENCE ON MECHANICAL AND MANUFACTURING ENGINEERING
   2017 (ICME'17)
SE MATEC Web of Conferences
CT 8th International Conference on Mechanical and Manufacturing Engineering
   (ICME)
CY JUL 22-23, 2017
CL Langkawi, MALAYSIA
SP Univ Tun Hussein Onn Malaysia, Fac Mech & Mfg Engn
AB Information retrieval is the process of analysing typed query as well as to retrieve relevant document according to the user query. Several issues can significantly affect the effectiveness of information retrieval. One of the common issue is the ambiguity lies on the words where a single word could yield several meanings. The process of identifying the exact sense of word is called Word Sense Disambiguation (WSD). Quran is the holly book for nearly 1.5 billion Muslims around the world. In particularly, Quran contains numerous words that can undergone multiple meanings. Therefore, there is a vital demand to apply WSD approach on Quran, in order, to improve the information retrieval. Several WSD approaches have been proposed for Quranic retrieval. However, these approaches are divided into two main categories; open-domain WSD approach and specific-domain WSD approach. Open-domain WSD is an approach that utilizes an open-domain dictionary such as WordNet, that is exploited to provide the exact sense. Whereas, domain-specific WSD approach aims to utilize a restricted training data that contain specific senses related to the domain of Quran. Hence, this study aims to establish a comparative study to investigate the two WSD categories including domain-specific and open-domain. For the domain-specific approach, a predefined example data has been collected to train Yarwosky algorithm which is a semi-supervised machine learning technique. Then, based on the training, such algorithm can classify the exact sense for the words. In contrast, WordNet which is an open-domain dictionary has been used in this study with semantic distances, in order, to identify the similarity between the query word and the results of WordNet's concepts. That dataset that has been used in this study is a Quranic translation. The experimental results have shown the mixed superiority of Yarwosky algorithm and WordNet WSD approach.
OI tiun, sabrina/0000-0002-1134-973X
SN 2261-236X
PY 2017
VL 135
AR 00071
DI 10.1051/matecconf/201713500071
UT WOS:000461100400068
ER

PT J
AU Hirayama, N
   Yoshino, K
   Itoyama, K
   Mori, S
   Okuno, HG
AF Hirayama, Naoki
   Yoshino, Koichiro
   Itoyama, Katsutoshi
   Mori, Shinsuke
   Okuno, Hiroshi G.
TI Automatic Speech Recognition for Mixed Dialect Utterances by Mixing
   Dialect Language Models
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB This paper presents an automatic speech recognition (ASR) system that accepts a mixture of various kinds of dialects. The system recognizes dialect utterances on the basis of the statistical simulation of vocabulary transformation and combinations of several dialect models. Previous dialect ASR systems were based on handcrafted dictionaries for several dialects, which involved costly processes. The proposed system statistically trains transformation rules between a common language and dialects, and simulates a dialect corpus for ASR on the basis of a machine translation technique. The rules are trained with small sets of parallel corpora to make up for the lack of linguistic resources on dialects. The proposed system also accepts mixed dialect utterances that contain a variety of vocabularies. In fact, spoken language is not a single dialect but a mixed dialect that is affected by the circumstances of speakers' backgrounds (e.g., native dialects of their parents or where they live). We addressed two methods to combine several dialects appropriately for each speaker. The first was recognition with language models of mixed dialects with automatically estimated weights that maximized the recognition likelihood. This method performed the best, but calculation was very expensive because it conducted grid searches of combinations of dialect mixing proportions that maximized the recognition likelihood. The second was integration of results of recognition from each single dialect language model. The improvements with this model were slightly smaller than those with the first method. Its calculation cost was, however, inexpensive and it worked in real-time on general workstations. Both methods achieved higher recognition accuracies for all speakers than those with the single dialect models and the common language model, and we could choose a suitable model for use in ASR that took into consideration the computational costs and recognition accuracies.
RI Okuno, Hiroshi G./S-3130-2018
OI Okuno, Hiroshi G./0000-0002-8704-4318
SN 2329-9290
EI 2329-9304
PD FEB
PY 2015
VL 23
IS 2
BP 373
EP 382
DI 10.1109/TASLP.2014.2387414
UT WOS:000348210300013
ER

PT C
AU Sarma, A
   Singh, S
   Jiang, HP
   Zhang, R
   Kandemir, MT
   Das, CR
AF Sarma, Anup
   Singh, Sonali
   Jiang, Huaipan
   Zhang, Rui
   Kandemir, Mahmut T.
   Das, Chita R.
BE Ranzato, M
   Beygelzimer, A
   Dauphin, Y
   Liang, PS
   Vaughan, JW
TI Structured in Space, Randomized in Time: Leveraging Dropout in RNNs for
   Efficient Training
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 34 (NEURIPS 2021)
SE Advances in Neural Information Processing Systems
CT 35th Conference on Neural Information Processing Systems (NeurIPS)
CY DEC 06-14, 2021
CL ELECTR NETWORK
AB Recurrent Neural Networks (RNNs), more specifically their Long Short-Term Memory (LSTM) variants, have been widely used as a deep learning tool for tackling sequence-based learning tasks in text and speech. Training of such LSTM applications is computationally intensive due to the recurrent nature of hidden state computation that repeats for each time step. While sparsity in Deep Neural Nets has been widely seen as an opportunity for reducing computation time in both training and inference phases, the usage of non-ReLU activation in LSTM RNNs renders the opportunities for such dynamic sparsity associated with neuron activation and gradient values to be limited or non-existent. In this work, we identify dropout induced sparsity for LSTMs as a suitable mode of computation reduction. Dropout is a widely used regularization mechanism, which randomly drops computed neuron values during each iteration of training. We propose to structure dropout patterns, by dropping out the same set of physical neurons within a batch, resulting in column (row) level hidden state sparsity, which are well amenable to computation reduction at run-time in general-purpose SIMD hardware as well as systolic arrays. We provide a detailed analysis of how the dropout-induced sparsity propagates through the different stages of network training and how it can be leveraged in each stage. More importantly, our proposed approach works as a direct replacement for existing dropout-based application settings. We conduct our experiments for three representative NLP tasks: language modelling on the PTB dataset, OpenNMT based machine translation using the IWSLT De-En and En-Vi datasets, and named entity recognition sequence labelling using the CoNLL-2003 shared task. We demonstrate that our proposed approach can be used to translate dropout-based computation reduction into reduced training time, with improvement ranging from 1.23x to 1.64x, without sacrificing the target metric.
SN 1049-5258
PY 2021
UT WOS:000925183301022
ER

PT J
AU Mohelska, H
   Sokolova, M
AF Mohelska, Hana
   Sokolova, Marcela
TI MANAGEMENT APPROACHES FOR INDUSTRY 4.0-THE ORGANIZATIONAL CULTURE
   PERSPECTIVE
SO TECHNOLOGICAL AND ECONOMIC DEVELOPMENT OF ECONOMY
AB The Industry 4.0 concept describes a decentralized production chain that extends from design to the supply chain, production, distribution as well as customer service. Cyber Physical Systems (CPS) employ software and internet-connected machines that communicate in real-time to reduce error rates and increase efficiency. The basis is the co-operation of separate control units that are capable of autonomous decision-making, managing the assigned technological unit and in particular becoming an independent and full member of comprehensive production units. The Industry 4.0 concept requires continuous innovation and education that not only depends on the peoples' skills but also on organizational culture. Appropriate managerial approaches play a vital role in the development of organizational culture. Most studies discuss technical aspects, but do not pay attention to managerial approaches and organizational culture, which are a major factor influencing the success of this concept. The aim of the paper is to examine the level of organizational culture in the Czech Republic and to seek appropriate managerial approaches for the development of organizational culture that can support the environment for innovation in the organization and therefore facilitate the entrepreneurship in the Industry 4.0 concept. A partial goal will be, among other things, to identify the implications of Industry 4.0 for human resources. In order to determine organizational culture in organizations, a large study was carried out in the form of a questionnaire survey - the Czech translation of Wallach's Questionnaire (1983). According to the findings, the respondents perceive the organizational culture in the organizations under review is more bureaucratic and supportive than innovative. In their view the signs of innovative culture are not so striking. It is necessary to change managerial approaches to support innovative solutions.
RI Mohelska, Hana/F-9896-2019; Sokolová, Marcela/B-3452-2012
OI Mohelska, Hana/0000-0003-0441-0712; Sokolová,
   Marcela/0000-0002-0641-7750
SN 2029-4913
EI 2029-4921
PY 2018
VL 24
IS 6
BP 2225
EP 2240
DI 10.3846/tede.2018.6397
UT WOS:000454435600004
ER

PT J
AU Barman, I
   Dingari, NC
   Singh, GP
   Kumar, R
   Lang, S
   Nabi, G
AF Barman, Ishan
   Dingari, Narahara Chari
   Singh, Gajendra Pratap
   Kumar, Rajesh
   Lang, Stephen
   Nabi, Ghulam
TI Selective sampling using confocal Raman spectroscopy provides enhanced
   specificity for urinary bladder cancer diagnosis
SO ANALYTICAL AND BIOANALYTICAL CHEMISTRY
AB In recent years, Raman spectroscopy has shown substantive promise in diagnosing bladder cancer, especially due to its exquisite molecular specificity. The ability to reduce false detection rates in comparison to existing diagnostic tools such as photodynamic diagnosis makes Raman spectroscopy particularly attractive as a complementary diagnostic tool for real-time guidance of transurethral resection of bladder tumor (TURBT). Nevertheless, the state-of-the-art high-volume Raman spectroscopic probes have not reached the expected levels of specificity thereby impeding their clinical translation. To address this issue, we propose the use of a confocal Raman probe for bladder cancer diagnosis that can boost the specificity of the diagnostic algorithm based on its suppression of the out-of-focus non-analyte-specific signals emanating from the neighboring normal tissue. In this article, we engineer and apply such a probe, having depth of field of approximately 280 mu m, for Raman spectral acquisition from ex vivo normal and cancerous TURBT samples. Using this clinical dataset, a diagnostic algorithm based on principal component analysis and logistic regression is developed. We demonstrate that this approach results in comparable sensitivity but significantly higher specificity in relation to high-volume Raman spectral data. The application of only two principal components is sufficient for the discrimination of the samples underlining the robustness of the algorithm. Further, no discordance between replicate spectra is observed emphasizing the reproducible nature of the current diagnostic assessment. The high levels of sensitivity and specificity achieved in this proof-of-concept study opens substantive avenues for application of a confocal Raman probe during endoscopic procedures related to diagnosis and treatment of bladder cancer.
RI Singh, Gajendra Pratap/A-2470-2011; Singh, Gajendra Pratap/AFG-4966-2022
OI Singh, Gajendra Pratap/0000-0001-8561-1385; Nabi,
   Ghulam/0000-0002-4864-9445
SN 1618-2642
PD DEC
PY 2012
VL 404
IS 10
BP 3091
EP 3099
DI 10.1007/s00216-012-6424-6
UT WOS:000311310100031
PM 23052868
ER

PT J
AU D'Hooghe, P
   Pereira, H
   Kelley, J
   Anderson, N
   Fuld, R
   Kumparatana, P
   Baldini, T
   Hunt, KJ
AF D'Hooghe, Pieter
   Pereira, Helder
   Kelley, Judas
   Anderson, Nicholas
   Fuld, Richard
   Kumparatana, Pam
   Baldini, Todd
   Hunt, Kenneth J.
TI The CFL fails before the ATFL immediately after combined ligament repair
   in a biomechanical cadaveric model
SO KNEE SURGERY SPORTS TRAUMATOLOGY ARTHROSCOPY
AB Purpose To assess the impact on ankle stability after repairing the ATFL alone compared to repairing both the ATFL and CFL in a biomechanical cadaver model. Methods Ten matched pairs of intact, fresh frozen human cadaver ankles (normal) were mounted to a test machine in 20.0 degrees plantar flexion and 15.0 degrees of internal rotation. Each ankle was loaded to body weight and then tested from 0.0 degrees to 20.0 degrees of inversion. The data recorded were torque at 20.0 degrees and stiffness, peak pressure and contact area in the ankle joint using a Tekscan sensor, rotation of the talus and calcaneus, and translation of the calcaneus using a three-dimensional motion capture system. Ankles then underwent sectioning of the ATFL and CFL (injured), retested, then randomly assigned to ATFL-only Brostrom repair or combined ATFL and CFL repair. Testing was repeated after repair then loaded in inversion to failure (LTF). Results The stiffness of the ankle was not significantly increased compared to the injured condition by repairing the ATFL only (n.s.) or the ATFL/CFL (n.s.). The calcaneus had significantly more rotation than the injured condition in the ATFL-only repair (p = 0.037) but not in the ATFL/CFL repair (n.s.). The ATFL failed at 40.3% higher torque than the CFL, at 17.4 +/- 7.0 N m and 12.4 +/- 4.1 N m, respectively, and 62.0% more rotation, at 43.9 +/- 5.6 degrees and 27.1 +/- 6.8 degrees, respectively. Conclusions There was a greater increase in stiffness following combined ATFL/CFL repair compared to ATFL-only repair, although this did not reach statistical significance. The CFL fails before the ATFL, potentially indicating its vulnerability immediately following repair.
RI Pereira, Hélder/AAI-6217-2020
OI Pereira, Hélder/0000-0003-2220-6766
SN 0942-2056
EI 1433-7347
PD JAN
PY 2020
VL 28
IS 1
SI SI
BP 253
EP 261
DI 10.1007/s00167-019-05626-9
UT WOS:000511719300034
PM 31359101
ER

PT J
AU Affatato, S
   Taddei, P
   Leardini, A
   Giannini, S
   Spinelli, M
   Viceconti, M
AF Affatato, S.
   Taddei, P.
   Leardini, A.
   Giannini, S.
   Spinelli, M.
   Viceconti, M.
TI Wear behaviour in total ankle replacement: A comparison between an in
   vitro simulation and retrieved prostheses
SO CLINICAL BIOMECHANICS
AB Background: To minimise wear of the meniscal component in total ankle replacement, a three-component artificial joint has recently been developed. This new prosthesis has convex spherical tibial and anticlastic talar metal components with non-anatomic but ligament-compatible shapes in the sagittal plane, and a fully conforming ultra-high-molecular-weight-polyethylene meniscal component inserted in between. The in vitro wear of meniscal components can be assessed using a four-station joint simulator. The study was aimed at comparing wear patterns obtained in vitro with those observed in implant retrievals with the same design.
   Methods: The wear tests were run in a joint wear simulator at a frequency of 1.1 Hz for two million cycles. Three bearings within corresponding metal components were subjected to flexion/extension (range 0-58 degrees), anterior-posterior translation (0-5.2 mm), internal-external rotation (-1.9 degrees to +5.7 degrees), and a maximum axial load of 2.6 KN. These conditions were taken from the most recent findings in ankle joint mechanics. Three prostheses of the same type were harvested from patients due to replacement failures not associated with the device, 24, 24 and 9 months, respectively, after implantation. The in vitro worn components and the three retrievals were analysed by using a scanning electron microscope, a Coordinate Measuring Machine, and micro-Raman spectroscopy.
   Findings: Visual and microscopic observations, analyses, and Raman crystallinity-based measurements showed similarity between the patterns generated experimentally in the wear simulator and those seen in retrievals with similar wear life.
   Interpretation: A joint wear simulator like the one used in this study, once configured properly, appears to be suitable to assess wear rates also in total ankle prostheses. (C) 2009 Elsevier Ltd. All rights reserved.
RI Affatato, Saverio/C-6976-2019; Affatato, Saverio/N-5106-2019; Viceconti,
   Marco/ABG-5546-2020; Viceconti, Marco/HNQ-6918-2023; Viceconti,
   Marco/N-9164-2013; Viceconti, Marco/HOF-5985-2023; Leardini,
   Alberto/C-8189-2019
OI Affatato, Saverio/0000-0003-3615-6085; Affatato,
   Saverio/0000-0003-3615-6085; Viceconti, Marco/0000-0002-2293-1530;
   Viceconti, Marco/0000-0002-2293-1530; Viceconti,
   Marco/0000-0002-2293-1530; Viceconti, Marco/0000-0002-2293-1530;
   Leardini, Alberto/0000-0003-3547-7370; TADDEI,
   PAOLA/0000-0001-8478-4508; Spinelli, Michele/0000-0002-8349-301X
SN 0268-0033
PD OCT
PY 2009
VL 24
IS 8
BP 661
EP 669
DI 10.1016/j.clinbiomech.2009.06.006
UT WOS:000269990100011
PM 19643517
ER

PT J
AU Utena, Y
   Takatsu, J
   Sugimoto, S
   Sasai, K
AF Utena, Yohei
   Takatsu, Jun
   Sugimoto, Satoru
   Sasai, Keisuke
TI Trajectory log analysis and cone-beam CT-based daily dose calculation to
   investigate the dosimetric accuracy of intensity-modulated radiotherapy
   for gynecologic cancer
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
AB This study evaluated unexpected dosimetric errors caused by machine control accuracy, patient setup errors, and patient weight changes/internal organ deformations. Trajectory log files for 13 gynecologic plans with seven- or nine-beam dynamic multileaf collimator (MLC) intensity-modulated radiation therapy (IMRT), and differences between expected and actual MLC positions and MUs were evaluated. Effects of patient setup errors on dosimetry were estimated by in-house software. To simulate residual patient setup errors after image-guided patient repositioning, planned dose distributions were recalculated (blurred dose) after the positions were randomly moved in three dimensions 0-2 mm (translation) and 0 degrees-2 degrees (rotation) 28 times per patient. Differences between planned and blurred doses in the clinical target volume (CTV) D-98% and D-2% were evaluated. Daily delivered doses were calculated from cone-beam computed tomography by the Hounsfield unit-to-density conversion method. Fractional and accumulated dose differences between original plans and actual delivery were evaluated by CTV D-98% and D-2%. The significance of accumulated doses was tested by the paired t test. Trajectory log file analysis showed that MLC positional errors were -0.01 +/- 0.02 mm and MU delivery errors were 0.10 +/- 0.10 MU. Differences in CTV D-98% and D-2% were <0.5% for simulated patient setup errors. Differences in CTV D-98% and D-2% were 2.4% or less between the fractional planned and delivered doses, but were 1.7% or less for the accumulated dose. Dosimetric errors were primarily caused by patient weight changes and internal organ deformation in gynecologic radiation therapy.
RI Takatsu, Jun/GRN-9339-2022; Takatsu, Jun/AAG-6937-2021
OI Utena, Yohei/0000-0003-2102-7483; Takatsu, Jun/0000-0001-9848-9251
SN 1526-9914
PD FEB
PY 2021
VL 22
IS 2
BP 108
EP 117
DI 10.1002/acm2.13163
EA JAN 2021
UT WOS:000606449300001
PM 33426810
ER

PT C
AU Sohail, SQ
   Akram, F
   Hussain, N
   Shahzad, A
AF Sohail, Syed Qasim
   Akram, Farooq
   Hussain, Nadeem
   Shahzad, Aamer
BE ZafarUzZaman, M
TI Design and Transition of a Quad Rotor Tail-sitter VTOL UAV with
   Experimental Verification
SO PROCEEDINGS OF 2021 INTERNATIONAL BHURBAN CONFERENCE ON APPLIED SCIENCES
   AND TECHNOLOGIES (IBCAST)
SE International Bhurban Conference on Applied Sciences and Technology
CT 18th International Bhurban Conference on Applied Sciences and
   Technologies (IBCAST)
CY JAN 12-16, 2021
CL Islamabad, PAKISTAN
SP IEEE, Ctr Excellence Sci & Appl Technologies
AB This paper presents the design and development of a quad rotor tail-sitter VTOL UAV (Vertical Take-off and Landing Unmanned Aerial Vehicle). VTOL UAVs have the capability of flying as a fixed-wing aircraft as well as rotorcrafts. This concept may serve well for surveillance, reconnaissance and in hostile environments. Currently different platforms are being utilized by researchers for designing VTOL aircraft which primarily include tilt rotors that serve for vertical take-off and landing and transition is done for translation of hovering configuration to fixed-wing configuration. This paper includes a specific study of the transition mechanism for VTOL UAVs, its transition from hover configuration to fixed-wing configuration, different phases of VTOL design, different configurations of rotors, and flight controller platform used for autopilot for long surveillance missions. This research is then followed by a specific design of tail-sitter VTOL UAVs which include the UAV design which follows an integrated analysis approach in which take-off weight is estimated followed by wing loading and thrust to weight ratio calculations. Design phase include an airfoil analysis using XFLR5 software followed by CAD modelling of UAV and its aerodynamic analysis. This research is then focused on the transition of VTOL UAV from VTOL mode into fixed-wing mode and vice versa. Different parameters involved during this phase are specified. During fabrication phase different techniques were used which include 3D printing of internal airframe of aircraft, laser-cutting of airfoil contours and hotwire cutting of Styrofoam. These techniques were applied using laser cutting and hotwire cutting machines available at the College of Aeronautical Engineering. Fabrication is followed by a series of flight tests which include ground test where aircraft endurance was calculated. Afterwards transition test from hovering mode into fixed-wing mode was carried out. The drone was able to achieve all the desired features successfully.
RI Akram, Farooq/ABE-8260-2021; Shahzad, Aamer/AAE-4394-2020
OI Akram, Farooq/0000-0001-8693-5859; Shahzad, Aamer/0000-0003-3528-5328
SN 2151-1403
BN 978-1-6654-0516-4
PY 2021
BP 244
EP 251
DI 10.1109/IBCAST51254.2021.9393187
UT WOS:000670611600031
ER

PT J
AU Singh, S
   Melnik, R
AF Singh, Sundeep
   Melnik, Roderick
TI Thermal ablation of biological tissues in disease treatment: A review of
   computational models and future directions
SO ELECTROMAGNETIC BIOLOGY AND MEDICINE
AB Percutaneous thermal ablation has proven to be an effective modality for treating both benign and malignant tumours in various tissues. Among these modalities, radiofrequency ablation (RFA) is the most promising and widely adopted approach that has been extensively studied in the past decades. Microwave ablation (MWA) is a newly emerging modality that is gaining rapid momentum due to its capability of inducing rapid heating and attaining larger ablation volumes, and its lesser susceptibility to the heat sink effects as compared to RFA. Although the goal of both these therapies is to attain cell death in the target tissue by virtue of heating above 50 degrees C, their underlying mechanism of action and principles greatly differs. Computational modelling is a powerful tool for studying the effect of electromagnetic interactions within the biological tissues and predicting the treatment outcomes during thermal ablative therapies. Such a priori estimation can assist the clinical practitioners during treatment planning with the goal of attaining successful tumour destruction and preservation of the surrounding healthy tissue and critical structures. This review provides current state-of-the-art developments and associated challenges in the computational modelling of thermal ablative techniques, viz., RFA and MWA, as well as touch upon several promising avenues in the modelling of laser ablation, nanoparticles assisted magnetic hyperthermia and non-invasive RFA. The application of RFA in pain relief has been extensively reviewed from modelling point of view. Additionally, future directions have also been provided to improve these models for their successful translation and integration into the hospital work flow.
RI Singh, Sundeep/AAF-6636-2019; MELNIK, RODERICK/AAT-9345-2021
OI Singh, Sundeep/0000-0002-8342-1622; Melnik, Roderick/0000-0002-1560-6684
SN 1536-8378
EI 1536-8386
PD APR 2
PY 2020
VL 39
IS 2
BP 49
EP 88
DI 10.1080/15368378.2020.1741383
EA APR 2020
UT WOS:000523316200001
PM 32233691
ER

PT J
AU Masmoudi, A
   Khmekhem, ME
   Khrouf, M
   Belguith, LH
AF Masmoudi, Abir
   Khmekhem, Mariem Ellouze
   Khrouf, Mourad
   Belguith, Lamia Hadrich
TI Transliteration of Arabizi into Arabic Script for Tunisian Dialect
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB The evolution of information and communication technology has markedly influenced communication between correspondents. This evolution has facilitated the transmission of information and has engendered new forms of written communication (email, chat, SMS, comments, etc.). Most of these messages and comments are written in Latin script, also called Arabizi. Moreover, the language used in social media and SMS messaging is characterized by the use of informal and non-standard vocabulary, such as repeated letters for emphasis, typos, non-standard abbreviations, and nonlinguistic content like emoticons. Since the Tunisian dialect suffers from the unavailability of basic tools and linguistic resources compared to Modern Standard Arabic, we resort to the use of these written sources as a starting point to build large corpora automatically. In the context of natural language processing and to benefit from these networks' data, transliterating from Arabizi to Arabic script is a necessary step because most recently available tools for processing the Tunisian dialect expect Arabic script input. Indeed, the transliteration task can help construct and enrich parallel corpora and dictionaries for the Tunisian dialect and can be useful for developing various natural language processing applications such as sentiment analysis, opinion mining, topic detection, and machine translation. In this article, we focus on converting the Tunisian dialect text that is written in Latin script to Arabic script following the Conventional Orthography for Dialectal Arabic. Then, we propose two models to transliterate Arabizi into Arabic script for the Tunisian dialect, namely a rule-based model and a discriminative model as a sequence classification task based on conditional random fields). In the first model, we use a set of transliteration rules to convert the Tunisian dialect Arabizi texts to Arabic script. In the second model, transliteration is performed both at word and character levels. In the end, our models got a character error rate of 10.47%.
RI Belguith, Lamia Hadrich/GWU-9641-2022
OI Belguith, Lamia Hadrich/0000-0002-4868-657X
SN 2375-4699
EI 2375-4702
PD MAR
PY 2020
VL 19
IS 2
AR 32
DI 10.1145/3364319
UT WOS:000535728600015
ER

PT C
AU Pati, S
   Aga, S
   Sinclair, MD
   Jayasena, N
AF Pati, Suchita
   Aga, Shaizeen
   Sinclair, Matthew D.
   Jayasena, Nuwan
GP IEEE
TI SeqPoint: Identifying Representative Iterations of Sequence-based Neural
   Networks
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON PERFORMANCE ANALYSIS OF SYSTEMS AND
   SOFTWARE (ISPASS)
SE IEEE International Symposium on Performance Analysis of Systems and
   Software-ISPASS
CT IEEE International Symposium on Performance Analysis of Systems and
   Software (ISPASS)
CY AUG 23-25, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, IMO Ventures, Intel, Qualcomm, Futurewei Technologies, Microsoft, VMWare, Facebook, nVIDIA, SiFive
AB The ubiquity of deep neural networks (DNNs) continues to rise, making them a crucial application class for hardware optimizations. However, detailed profiling and characterization of DNN training remains difficult as these applications often run for hours to days on real hardware. Prior works have exploited the iterative nature of DNNs to profile a few training iterations to represent the entire training run. While such a strategy is sound for networks like convolutional neural networks (CNNs), where the nature of the computation is largely input independent, we observe in this work that this approach is sub-optimal for sequence-based neural networks (SQNNs) such as recurrent neural networks (RNNs). The amount and nature of computations in SQNNs can vary for each input, resulting in heterogeneity across iterations. Thus, arbitrarily selecting a few iterations is insufficient to accurately summarize the behavior of the entire training run.
   To tackle this challenge, we carefully study the factors that impact SQNN training iterations and identify input sequence length as the key determining factor for variations across iterations. We then use this observation to characterize all iterations of an SQNN training run (requiring no profiling or simulation of the application) and select representative iterations, which we term SeqPoints. We analyze two state-of-the-art SQNNs, DeepSpeech2 and Google's Neural Machine Translation (GNMT), and show that SeqPoints can represent their entire training runs accurately, resulting in geomean errors of only 0.11% and 0.53%, respectively, when projecting overall runtime and 0.13% and 1.50% when projecting speedups due to architectural changes. This high accuracy is achieved while reducing the time needed for profiling by 345x and 214x for the two networks compared to full training runs. As a result, SeqPoint can enable analysis of SQNN training runs in mere minutes instead of hours or days.
BN 978-1-7281-4798-7
PY 2020
BP 69
EP 80
DI 10.1109/ISPASS48437.2020.00017
UT WOS:000637280800007
ER

PT J
AU Scherrer, Y
   Erjavec, T
AF Scherrer, Yves
   Erjavec, Tomaz
TI Modernising historical Slovene words
SO NATURAL LANGUAGE ENGINEERING
AB We propose a language-independent word normalisation method and exemplify it on modernising historical Slovene words. Our method relies on character-level statistical machine translation (CSMT) and uses only shallow knowledge. We present relevant data on historical Slovene, consisting of two (partially) manually annotated corpora and the lexicons derived from these corpora, containing historical word-modern word pairs. The two lexicons are disjoint, with one serving as the training set containing 40,000 entries, and the other as a test set with 20,000 entries. The data spans the years 1750-1900, and the lexicons are split into fifty-year slices, with all the experiments carried out separately on the three time periods. We perform two sets of experiments. In the first one - a supervised setting - we build a CSMT system using the lexicon of word pairs as training data. In the second one - an unsupervised setting - we simulate a scenario in which word pairs are not available. We propose a two-step method where we first extract a noisy list of word pairs by matching historical words with cognate modern words, and then train a CSMT system on these pairs. In both sets of experiments, we also optionally make use of a lexicon of modern words to filter the modernisation hypotheses. While we show that both methods produce significantly better results than the baselines, their accuracy and which method works best strongly correlates with the age of the texts, meaning that the choice of the best method will depend on the properties of the historical language which is to be modernised. As an extrinsic evaluation, we also compare the quality of part-of-speech tagging and lemmatisation directly on historical text and on its modernised words. We show that, depending on the age of the text, annotation on modernised words also produces significantly better results than annotation on the original text.
OI Erjavec, Tomaz/0000-0002-1560-4099
SN 1351-3249
EI 1469-8110
PD NOV
PY 2016
VL 22
IS 6
BP 881
EP 905
DI 10.1017/S1351324915000236
UT WOS:000386436900003
ER

PT J
AU Brais, G
   Menard, J
   Mutch, J
   Laflamme, GY
   Petit, Y
   Rouleau, DM
AF Brais, Godefroy
   Menard, Jeremie
   Mutch, Jennifer
   Laflamme, G-Yves
   Petit, Yvan
   Rouleau, Dominique M.
TI Transosseous braided-tape and double-row fixations are better than
   tension band for avulsion-type greater tuberosity fractures
SO INJURY-INTERNATIONAL JOURNAL OF THE CARE OF THE INJURED
AB Introduction: The optimal treatment for avulsion-type greater tuberosity fractures is yet to be determined. Three fixation methods are tested: tension band with #2 wire suture (TB), double-row suture bridge with anchors (DR), and simple transosseous fixation with braided tape (BT).
   Materials and methods: Twenty-four porcine proximal humeri were randomised into three groups: TB, DR and BT. A standardised greater tuberosity (GT) osteotomy was performed at 908 to the humeral diaphysis axis. A mechanical testing machine was used to simulate supraspinatus contraction. The force required to produce 3 mm and 5 mm displacement, as well as complete failure was measured with an axial load cell. Also, three cycles of shoulder flexion/extension with 25 N of supraspinatus contraction were performed. Maximum GT fragment translation and rotation amplitude during one cycle were measured.
   Results: During supraspinatus contraction, DR and BT groups (p < 0.05) were superior to TB group for both displacements. The BT technique had the strongest maximal load to failure (BT = 466 N; DR = 386 N; TB = 320 N). For the flexion/extension, DR and BT groups had less displacement and rotation than TB group (anterio-posterior displacement: BT = 2.0 mm, DR = 1.9 mm, TB = 5.8 mm; anterioposterior angular displacement: BT = 1.4 degrees, DR = 1.0 degrees, TB = 4.8 degrees). No significant difference was observed between DR and BT groups, except for the medio-lateral rotation favouring the DR group.
   Conclusion: In conclusion, BT and DR are good fixation methods to treat displaced avulsion-type greater tuberosity fractures. They have similar mechanical properties, and are stronger and more stable that the TB construct. Potential advantages of the BT over the DR may be a lower cost and easier surgery. Level of evidence: Basic science study (LEVEL II). (C) 2015 Elsevier Ltd. All rights reserved.
OI Petit, Yvan/0000-0003-1428-8191
SN 0020-1383
EI 1879-0267
PD JUN
PY 2015
VL 46
IS 6
BP 1007
EP 1012
DI 10.1016/j.injury.2015.02.007
UT WOS:000355018800012
PM 25799475
ER

PT C
AU Venkatasubramanian, S
   Mohankumar, R
AF Venkatasubramanian, S.
   Mohankumar, R.
BE Smys, S
   Tavares, JMRS
   Balas, VE
TI A Deep Convolutional Neural Network-Based Speech-to-Text Conversion for
   Multilingual Languages
SO COMPUTATIONAL VISION AND BIO-INSPIRED COMPUTING ( ICCVBIC 2021)
SE Advances in Intelligent Systems and Computing
CT 5th International Conference on Computational Vision and Bio Inspired
   Computing (ICCVBIC)
CY NOV 25-26, 2021
CL Coimbatore, INDIA
AB Designers have been processing speech for decades for a wide variety of applications, from mobile communications to automatic reading machines, among others. By eliminating the need for alternative communication methods, speech recognition saves time and money. In the world of electronics and computers, speech is rarely employed because of the complexity and variety of voice signals and noises. Today's technologies allow us to process speech signals quickly and accurately and recognize the text. A real-time translation of speech into written language requires specific techniques, as it must be extremely rapid and nearly error-free to make sense. A person's speech is the most natural and important form of communication. This system converts human speech into a string of words using the speech-to-text (STT) technology. This system's goal is to extract, classify, and recognize information about speech in a variety of ways. Using convolutional neural networks (CNNs) for voice classification, the proposed system is developed. The input signals are classified by CNN on its own since it is a self-optimizing neural network. In addition, high-level features are extracted by convolutional and pooling layer, where the data is classified using fully connected (FC) layer. A database contains pre-recorded speech. Testing and training are the two key aspects of the database. In the training phase, samples from the training database are run through a series of tests to determine their characteristics. Each sample's features are combined to create a feature vector that is stored for future reference. When a sample is supplied to the system for analysis, its features are extracted. There is a comparison between these features and the reference feature vector, and the words with highest similarity are output. MATLAB (V2018a) environment is used to design the system.
RI R, MOHANKUMAR/G-3276-2017
OI R, MOHANKUMAR/0000-0002-9423-9156
SN 2194-5357
EI 2194-5365
BN 978-981-16-9573-5; 978-981-16-9572-8
PY 2022
VL 1420
BP 617
EP 633
DI 10.1007/978-981-16-9573-5_44
UT WOS:000787139600044
ER

PT J
AU Oxley, TJ
   Yoo, PE
   Rind, GS
   Ronayne, SM
   Lee, CMS
   Bird, C
   Hampshire, V
   Sharma, RP
   Morokoff, A
   Williams, DL
   MacIsaac, C
   Howard, ME
   Irving, L
   Vrljic, I
   Williams, C
   John, SE
   Weissenborn, F
   Dazenko, M
   Balabanski, AH
   Friedenberg, D
   Burkitt, AN
   Wong, YT
   Drummond, KJ
   Desmond, P
   Weber, D
   Denison, T
   Hochberg, LR
   Mathers, S
   O'Brien, TJ
   May, CN
   Mocco, J
   Grayden, DB
   Campbell, BCV
   Mitchell, P
   Opie, NL
AF Oxley, Thomas J.
   Yoo, Peter E.
   Rind, Gil S.
   Ronayne, Stephen M.
   Lee, C. M. Sarah
   Bird, Christin
   Hampshire, Victoria
   Sharma, Rahul P.
   Morokoff, Andrew
   Williams, Daryl L.
   MacIsaac, Christopher
   Howard, Mark E.
   Irving, Lou
   Vrljic, Ivan
   Williams, Cameron
   John, Sam E.
   Weissenborn, Frank
   Dazenko, Madeleine
   Balabanski, Anna H.
   Friedenberg, David
   Burkitt, Anthony N.
   Wong, Yan T.
   Drummond, Katharine J.
   Desmond, Patricia
   Weber, Douglas
   Denison, Timothy
   Hochberg, Leigh R.
   Mathers, Susan
   O'Brien, Terence J.
   May, Clive N.
   Mocco, J.
   Grayden, David B.
   Campbell, Bruce C., V
   Mitchell, Peter
   Opie, Nicholas L.
TI Motor neuroprosthesis implanted with neurointerventional surgery
   improves capacity for activities of daily living tasks in severe
   paralysis: first in-human experience
SO JOURNAL OF NEUROINTERVENTIONAL SURGERY
AB Background
   Implantable brain-computer interfaces (BCIs), functioning as motor neuroprostheses, have the potential to restore voluntary motor impulses to control digital devices and improve functional independence in patients with severe paralysis due to brain, spinal cord, peripheral nerve or muscle dysfunction. However, reports to date have had limited clinical translation.
   Methods
   Two participants with amyotrophic lateral sclerosis (ALS) underwent implant in a single-arm, open-label, prospective, early feasibility study. Using a minimally invasive neurointervention procedure, a novel endovascular Stentrode BCI was implanted in the superior sagittal sinus adjacent to primary motor cortex. The participants undertook machine-learning-assisted training to use wirelessly transmitted electrocorticography signal associated with attempted movements to control multiple mouse-click actions, including zoom and left-click. Used in combination with an eye-tracker for cursor navigation, participants achieved Windows 10 operating system control to conduct instrumental activities of daily living (IADL) tasks.
   Results
   Unsupervised home use commenced from day 86 onwards for participant 1, and day 71 for participant 2. Participant 1 achieved a typing task average click selection accuracy of 92.63% (100.00%, 87.50%-100.00%) (trial mean (median, Q1-Q3)) at a rate of 13.81 (13.44, 10.96-16.09) correct characters per minute (CCPM) with predictive text disabled. Participant 2 achieved an average click selection accuracy of 93.18% (100.00%, 88.19%-100.00%) at 20.10 (17.73, 12.27-26.50) CCPM. Completion of IADL tasks including text messaging, online shopping and managing finances independently was demonstrated in both participants.
   Conclusion
   We describe the first-in-human experience of a minimally invasive, fully implanted, wireless, ambulatory motor neuroprosthesis using an endovascular stent-electrode array to transmit electrocorticography signals from the motor cortex for multiple command control of digital devices in two participants with flaccid upper limb paralysis.
RI O'Brien, Terence/AAU-5525-2021; Campbell, Bruce/J-1220-2019; Morokoff,
   Andrew/ABC-2783-2020; O'Brien, Terence/L-8102-2013; Campbell,
   Bruce/AGY-4147-2022; Desmond, Patricia/D-1966-2014
OI Campbell, Bruce/0000-0003-3632-9433; Morokoff,
   Andrew/0000-0002-5159-3438; O'Brien, Terence/0000-0002-7198-8621;
   Denison, Timothy/0000-0002-5404-4004; Williams,
   Cameron/0000-0003-4952-8896; Weber, Douglas/0000-0002-9782-3497;
   Williams, Daryl/0000-0002-6987-5804; Howard, Mark/0000-0001-7772-1496;
   Desmond, Patricia/0000-0002-4803-6323; Balabanski,
   Anna/0000-0003-3209-3101
SN 1759-8478
EI 1759-8486
PD FEB
PY 2021
VL 13
IS 2
BP 102
EP 108
DI 10.1136/neurintsurg-2020-016862
UT WOS:000614238000004
PM 33115813
ER

PT J
AU Naiemi, F
   Ghods, V
   Khalesi, H
AF Naiemi, Fatemeh
   Ghods, Vahid
   Khalesi, Hassan
TI Scene text detection using enhanced Extremal region and convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
AB Text in scene images usually contains significant information. Text detection and recognition in the scene is important for a variety of advanced machine vision applications, such as image and video retrieval, automotive assistance, and multilingual translation. In particular, most text recognition systems require texts to be localized in images beforehand and this is a significant demand. The purpose of this study is to provide a method to detect texts in natural images. The proposed approach combines advantages of extremal region, ER, methods and classification of convolutional neural network, CNN. This significantly reduces the false positives and increases the accuracy of detection. The method of sliding windows is employed with different sizes in order to determine text candidates. Extraction of enhanced ERs is performed in three consecutive stages on three distinct color channels, R, G, and B. Then, the results are combined together by an add method. After grouping, the word candidates are classified to two classes of text and non-text sections by a CNN classifier. By applying non-maximum suppression (NMS) algorithm to the same words, words with the highest probability are selected. The average values of accuracy, recall, precision and F-measure of the proposed text detection model on the ICDAR2013 database are 0.893, 0.962, 0.948, and 0.955, respectively. The optimal cut point of the proposed method is 0.648, which has the highest average accuracy, 91.93%. The AUC of ROC and PR diagrams for the proposed model are 0.851 and 0.718, respectively. These results of AUC for ROC and PR curves showed an outstanding enhancement in comparison with the best detection rate of previous methods. Experimental results on the ICDAR2011, ICDAR2013 and ICDAR2015 databases also demonstrate that our algorithm outperforms the state-of-the-art scene text detection methods.
RI Naiemi, fatemeh/AAR-7469-2020
OI Naiemi, fatemeh/0000-0001-5571-8560
SN 1380-7501
EI 1573-7721
PD OCT
PY 2020
VL 79
IS 37-38
BP 27137
EP 27159
DI 10.1007/s11042-020-09318-2
EA JUL 2020
UT WOS:000551375500004
ER

PT J
AU Saravanan, V
   Lakshmi, PTV
AF Saravanan, Vijayakumar
   Lakshmi, P. T. V.
TI APSLAP: An Adaptive Boosting Technique for Predicting Subcellular
   Localization of Apoptosis Protein
SO ACTA BIOTHEORETICA
AB Apoptotic proteins play key roles in understanding the mechanism of programmed cell death. Knowledge about the subcellular localization of apoptotic protein is constructive in understanding the mechanism of programmed cell death, determining the functional characterization of the protein, screening candidates in drug design, and selecting protein for relevant studies. It is also proclaimed that the information required for determining the subcellular localization of protein resides in their corresponding amino acid sequence. In this work, a new biological feature, class pattern frequency of physiochemical descriptor, was effectively used in accordance with the amino acid composition, protein similarity measure, CTD (composition, translation, and distribution) of physiochemical descriptors, and sequence similarity to predict the subcellular localization of apoptosis protein. AdaBoost with the weak learner as Random-Forest was designed for the five modules and prediction is made based on the weighted voting system. Bench mark dataset of 317 apoptosis proteins were subjected to prediction by our system and the accuracy was found to be 100.0 and 92.4 %, and 90.1 % for self-consistency test, jack-knife test, and tenfold cross validation test respectively, which is 0.9 % higher than that of other existing methods. Beside this, the independent data (N151 and ZW98) set prediction resulted in the accuracy of 90.7 and 87.7 %, respectively. These results show that the protein feature represented by a combined feature vector along with AdaBoost algorithm holds well in effective prediction of subcellular localization of apoptosis proteins. The user friendly web interface "APSLAP" has been constructed, which is freely available at http://apslap.bicpu.edu.in and it is anticipated that this tool will play a significant role in determining the specific role of apoptosis proteins with reliability.
RI Vijayakumar, Saravanan/H-3659-2019; PTV, Lakshmi -/Q-6000-2016
OI Vijayakumar, Saravanan/0000-0001-5145-0384; PTV, Lakshmi
   -/0000-0002-8624-7682
SN 0001-5342
EI 1572-8358
PD DEC
PY 2013
VL 61
IS 4
BP 481
EP 497
DI 10.1007/s10441-013-9197-1
UT WOS:000327894800003
PM 23982307
ER

PT J
AU Alabed, S
   Maiter, A
   Salehi, M
   Mahmood, A
   Daniel, S
   Jenkins, S
   Goodlad, M
   Sharkey, M
   Mamalakis, M
   Rakocevic, V
   Dwivedi, K
   Assadi, H
   Wild, JM
   Lu, HP
   O'Regan, DP
   van der Geest, RJ
   Garg, P
   Swift, AJ
AF Alabed, Samer
   Maiter, Ahmed
   Salehi, Mahan
   Mahmood, Aqeeb
   Daniel, Sonali
   Jenkins, Sam
   Goodlad, Marcus
   Sharkey, Michael
   Mamalakis, Michail
   Rakocevic, Vera
   Dwivedi, Krit
   Assadi, Hosamadin
   Wild, Jim M. M.
   Lu, Haiping
   O'Regan, Declan P. P.
   van der Geest, Rob J. J.
   Garg, Pankaj
   Swift, Andrew J. J.
TI Quality of reporting in AI cardiac MRI segmentation studies - A
   systematic review and recommendations for future studies
SO FRONTIERS IN CARDIOVASCULAR MEDICINE
AB Background: There has been a rapid increase in the number of Artificial Intelligence (AI) studies of cardiac MRI (CMR) segmentation aiming to automate image analysis. However, advancement and clinical translation in this field depend on researchers presenting their work in a transparent and reproducible manner. This systematic review aimed to evaluate the quality of reporting in AI studies involving CMR segmentation. Methods: MEDLINE and EMBASE were searched for AI CMR segmentation studies in April 2022. Any fully automated AI method for segmentation of cardiac chambers, myocardium or scar on CMR was considered for inclusion. For each study, compliance with the Checklist for Artificial Intelligence in Medical Imaging (CLAIM) was assessed. The CLAIM criteria were grouped into study, dataset, model and performance description domains. Results: 209 studies published between 2012 and 2022 were included in the analysis. Studies were mainly published in technical journals (58%), with the majority (57%) published since 2019. Studies were from 37 different countries, with most from China (26%), the United States (18%) and the United Kingdom (11%). Short axis CMR images were most frequently used (70%), with the left ventricle the most commonly segmented cardiac structure (49%). Median compliance of studies with CLAIM was 67% (IQR 59-73%). Median compliance was highest for the model description domain (100%, IQR 80-100%) and lower for the study (71%, IQR 63-86%), dataset (63%, IQR 50-67%) and performance (60%, IQR 50-70%) description domains. Conclusion: This systematic review highlights important gaps in the literature of CMR studies using AI. We identified key items missing-most strikingly poor description of patients included in the training and validation of AI models and inadequate model failure analysis-that limit the transparency, reproducibility and hence validity of published AI studies. This review may support closer adherence to established frameworks for reporting standards and presents recommendations for improving the quality of reporting in this field.
RI Assadi, Hosamadin/HMP-7726-2023
OI Assadi, Hosamadin/0000-0002-6143-8095; Maiter,
   Ahmed/0000-0002-4999-2608; Alabed, Samer/0000-0002-9960-7587; Wild,
   Jim/0000-0002-7246-8660
SN 2297-055X
PD JUL 15
PY 2022
VL 9
AR 956811
DI 10.3389/fcvm.2022.956811
UT WOS:000886089200001
PM 35911553
ER

PT J
AU Caldairou, B
   Foit, NA
   Mutti, C
   Fadaie, F
   Gill, R
   Lee, HM
   Demerath, T
   Urbach, H
   Schulze-Bonhage, A
   Bernasconi, A
   Bernasconi, N
AF Caldairou, Benoit
   Foit, Niels A.
   Mutti, Carlotta
   Fadaie, Fatemeh
   Gill, Ravnoor
   Lee, Hyo Min
   Demerath, Theo
   Urbach, Horst
   Schulze-Bonhage, Andreas
   Bernasconi, Andrea
   Bernasconi, Neda
TI MRI-Based Machine Learning Prediction Framework to Lateralize
   Hippocampal Sclerosis in Patients With Temporal Lobe Epilepsy
SO NEUROLOGY
AB Background and Objectives MRI fails to reveal hippocampal pathology in 30% to 50% of temporal lobe epilepsy (TLE) surgical candidates. To address this clinical challenge, we developed an automated MRI-based classifier that lateralizes the side of covert hippocampal pathology in TLE. Methods We trained a surface-based linear discriminant classifier that uses T1-weighted (morphology) and T2-weighted and fluid-attenuated inversion recovery (FLAIR)/T1 (intensity) features. The classifier was trained on 60 patients with TLE (mean age 35.6 years, 58% female) with histologically verified hippocampal sclerosis (HS). Images were deemed to be MRI negative in 42% of cases on the basis of neuroradiologic reading (40% based on hippocampal volumetry). The predictive model automatically labeled patients as having left or right TLE. Lateralization accuracy was compared to electroclinical data, including side of surgery. Accuracy of the classifier was further assessed in 2 independent TLE cohorts with similar demographics and electroclinical characteristics (n = 57, 58% MRI negative). Results The overall lateralization accuracy was 93% (95% confidence interval 92%-94%), regardless of HS visibility. In MRI-negative TLE, the combination of T2 and FLAIR/T1 intensities provided the highest accuracy in both the training (84%, area under the curve [AUC] 0.95 +/- 0.02) and validation (cohort 1 90%, AUC 0.99; cohort 2 76%, AUC 0.94) cohorts. Discussion This prediction model for TLE lateralization operates on readily available conventional MRI contrasts and offers gain in accuracy over visual radiologic assessment. The combined contribution of decreased T1- and increased T2-weighted intensities makes the synthetic FLAIR/T1 contrast particularly effective in MRI-negative HS, setting the basis for broad clinical translation. Classification of Evidence This study provides Class II evidence that in people with TLE and MRI-negative HS, an automated MRI-based classifier accurately determines the side of pathology.
RI mutti, carlotta/AAC-4994-2022
OI mutti, carlotta/0000-0002-1930-5045; Schulze-Bonhage,
   Andreas/0000-0003-2382-0506
SN 0028-3878
EI 1526-632X
PD OCT 19
PY 2021
VL 97
IS 16
BP E1583
EP E1593
DI 10.1212/WNL.0000000000012699
UT WOS:000708601400020
PM 34475125
ER

PT J
AU Vossler, DG
AF Vossler, David G.
TI Forecasting Seizure Storms Using Epilepsy Wristband Sensors
SO EPILEPSY CURRENTS
AB Machine Learning From Wristband Sensor Data for Wearable, Noninvasive Seizure Forecasting
   Meisel C, El Atrache R, Jackson M, Schubach S, Ufongene C, Loddenkemper T. Epilepsia. 2020;61(12):2653-2666. doi:
   Objective:
   Seizure forecasting may provide patients with timely warnings to adapt their daily activities and help clinicians deliver more objective, personalized treatments. Although recent work has convincingly demonstrated that seizure risk assessment is in principle possible, these early approaches relied largely on complex, often invasive setups including intracranial electrocorticography, implanted devices, and multichannel electroencephalography and required patient-specific adaptation or learning to perform optimally, all of which limit translation to broad clinical application. To facilitate broader adaptation of seizure forecasting in clinical practice, noninvasive, easily applicable techniques that reliably assess seizure risk without much prior tuning are crucial. Wristbands that continuously record physiological parameters, including electrodermal activity, body temperature, blood volume pulse, and actigraphy, may afford monitoring of autonomous nervous system function and movement relevant for such a task, hence minimizing potential complications associated with invasive monitoring and avoiding stigma associated with bulky external monitoring devices on the head.
   Methods:
   Here, we applied deep learning on multimodal wristband sensor data from 69 patients with epilepsy (total duration >2311 hours, 452 seizures) to assess its capability to forecast seizures in a statistically significant way.
   Results:
   Using a leave-one-subject-out cross-validation approach, we identified better-than-chance predictability in 43% of the patients. Time-matched seizure surrogate data analyses indicated forecasting not to be driven simply by time of day or vigilance state. Prediction performance peaked when all sensor modalities were used and did not differ between generalized and focal seizure types but generally increased with the size of the training data set, indicating potential further improvement with larger data sets in the future.
   Significance:
   Collectively, these results show that statistically significant seizure risk assessments are feasible from easy-to-use, noninvasive wearable devices without the need of patient-specific training or parameter optimization.
OI Vossler, David/0000-0003-4823-0537
SN 1535-7597
EI 1535-7511
PD MAR
PY 2021
VL 21
IS 2
BP 99
EP 101
AR 1535759721990062
DI 10.1177/1535759721990062
EA JAN 2021
UT WOS:000624625900001
PM 34025285
ER

PT J
AU McCormack, EA
   Altschuler, GM
   Dekker, C
   Filmore, H
   Willison, KR
AF McCormack, Elizabeth A.
   Altschuler, Gabriel M.
   Dekker, Carien
   Filmore, Heather
   Willison, Keith R.
TI Yeast Phosducin-Like Protein 2 Acts as a Stimulatory Co-Factor for the
   Folding of Actin by the Chaperonin CCT via a Ternary Complex
SO JOURNAL OF MOLECULAR BIOLOGY
AB The eukaryotic chaperonin-containing TCP-1 (CCT) folds the cytoskeletal protein actin. The folding mechanism of this 16-subunit, 1-MDa machine is poorly characterised due to the absence of quantitative in vitro assays. We identified phosducin-like protein 2, Plp2p (=PLP2), as an ATP-elutable binding partner of yeast CCT while establishing the CCT interactome. In a novel in vitro CCT-ACT1 folding assay that is functional under physiological conditions, PLP2 is a stimulatory co-factor. In a single ATP-driven cycle, PLP2-CCT-ACT1 complexes yield 30-fold more native actin than CCT-ACT1 complexes. PLP2 interacts directly with ACT1 through the C-terminus of its thioredoxin fold and the CCT-binding subdomain 4 of actin. The in vitro CCT-ACT1-PLP2 folding cycle of the preassembled complex takes 90 s at 30 degrees C, several times slower than the canonical chaperonin GroEL. The specific interactions between PLP2, CCT and ACTI in the yeast-component in vitro system and the pronounced stimulatory effect of PLP2 on actin folding are consistent with in vivo genetic approaches demonstrating an essential and positive role for PLP2 in cellular processes involving actin in Saccharomyces cerevisiae. In mammalian systems, however, several members of the PLP family, including human PDCL3, the orthologue of PLP2, have been shown to be inhibitory toward CCT-mediated folding of actin in vivo and in vitro. Here, using a rabbit-reticulocyte-derived in vitro translation system, we found that inhibition of p-actin folding by PDCL3 can be relieved by exchanging its acidic C-terminal extension for that of PLP2. It seems that additional levels of regulatory control of CCT activity by this PLP have emerged in higher eukaryotes. (c) 2009 Elsevier Ltd. All rights reserved.
OI Rada, Heather/0000-0003-1477-419X
SN 0022-2836
EI 1089-8638
PD AUG 7
PY 2009
VL 391
IS 1
BP 192
EP 206
DI 10.1016/j.jmb.2009.06.003
UT WOS:000268651400014
PM 19501098
ER

PT J
AU Sanchez, A
   Rotstein, G
   Alsop, N
   Bromberg, JP
   Gollain, C
   Sorensen, S
   Macchietto, S
   Jakeman, C
AF Sanchez, A
   Rotstein, G
   Alsop, N
   Bromberg, JP
   Gollain, C
   Sorensen, S
   Macchietto, S
   Jakeman, C
TI Improving the development of event-driven control systems in the batch
   processing industry. A case study
SO ISA TRANSACTIONS
AB This paper presents the results of an academia-industry collaborative project whose main objective was to test novel techniques for the development of event-driven control systems in the batch processing (e.g., pharmaceutical, fine chemicals, food) industries. Proposed techniques build upon industrial standards and focus on (i) formal synthesis of phase control logic and its automatic translation into procedural code, and (ii) verification of the complete discrete-event control system via dynamic simulation. In order to test the techniques in an engineering environment, a complete discrete-event control system was produced for a benchmark batch process plant based on a standard development method employed by one of the industrial partners. The control system includes functional process specification, control architecture, distributed control system (DCS) proprietary programming code for procedural control at equipment, unit, and process cell levels, and human-machine interfaces. A technical assessment of the development method and the obtained control system was then carried out. Improvements were suggested using the proposed techniques in the specification, code generation and, verification steps. The project assessed the impact of these techniques from both an engineering and economic point of view. Results suggest that the introduction of computer aided engineering (CAE) practices based on the benchmarked techniques and a structured approach could effect a 75% reduction of errors produced in the development process. This translates into estimated overall savings of 7% for green-field projects. Figures were compared with other partners' experience. It is expected that the work load on a given project will shift, increasing the load on process engineers during the specification stage and decreasing the load on the software engineers during the code writing. (C) 2002 ISA-The Instrumentation, Systems, and Automation Society.
RI Sanchez, Arturo/AAD-4335-2020; Sánchez, Arturo/L-3622-2019; Sanchez,
   Arturo/AAF-3153-2019
OI Sánchez, Arturo/0000-0002-4946-1559; Sanchez,
   Arturo/0000-0001-5453-0478; Macchietto, Sandro/0000-0001-6096-8126
SN 0019-0578
PD JUL
PY 2002
VL 41
IS 3
BP 343
EP 363
DI 10.1016/S0019-0578(07)60093-7
UT WOS:000176911600007
PM 12160348
ER

PT J
AU Schlogl, S
   Doherty, G
   Luz, S
AF Schloegl, Stephan
   Doherty, Gavin
   Luz, Saturnino
TI Wizard of Oz Experimentation for Language Technology Applications:
   Challenges and Tools
SO INTERACTING WITH COMPUTERS
AB Wizard of Oz (WOZ) is a well-established method for simulating the functionality and user experience of future systems. Using a human wizard to mimic certain operations of a potential system is particularly useful in situations where extensive engineering effort would otherwise be needed to explore the design possibilities offered by such operations. The WOZ method has been widely used in connection with speech and language technologies, but advances in sensor technology and pattern recognition as well as new application areas such as human-robot interaction have made it increasingly relevant to the design of a wider range of interactive systems. In such cases, achieving acceptable performance at the user interface level often hinges on resource-intensive improvements such as domain tuning, which are better done once the overall design is relatively stable. Although WOZ is recognized as a valuable prototyping technique, surprisingly little effort has been put into exploring it from a methodological point of view. Starting from a survey of the literature, this paper presents a systematic investigation and analysis of the design space for WOZ for language technology applications, and proposes a generic architecture for tool support that supports the integration of components for speech recognition and synthesis as well as for machine translation. This architecture is instantiated in WebWOZ-a new web-based open-source WOZ prototyping platform. The viability of generic support is explored empirically through a series of evaluations. Researchers from a variety of backgrounds were able to create experiments, independent of their previous experience with WOZ. The approach was further validated through a number of real experiments, which also helped to identify a number of possibilities for additional support, and flagged potential issues relating to consistency in wizard performance.
RI Doherty, Gavin/AAH-4939-2019
OI Doherty, Gavin/0000-0002-9617-7008; Schlogl,
   Stephan/0000-0001-7469-4381; Luz, Saturnino/0000-0001-8430-7875
SN 0953-5438
EI 1873-7951
PD NOV
PY 2015
VL 27
IS 6
BP 592
EP 615
DI 10.1093/iwc/iwu016
UT WOS:000364776900003
ER

PT J
AU Wu, CS
   Young, DL
   Wu, HC
AF Wu, C. S.
   Young, D. L.
   Wu, H. C.
TI Simulations of multidimensional interfacial flows by an improved
   volume-of-fluid method
SO INTERNATIONAL JOURNAL OF HEAT AND MASS TRANSFER
AB In this article we present a 2D and 3D practical interface tracking algorithm to reconstruct and advect the interfaces of interfacial flows. The improved volume-of-fluid (VOF) method in this work is composed of three major components: namely (1) the modified piecewise linear interface calculation (PLIC) based interfacial reconstruction; (2) the Lagrangian split fluid advection and (3) redistribution of volume fraction. Most advanced VOF methods employed by the PLIC technique have faced some problems to extend from 2D to 3D study, because the increase in complexity of the geometry primitives involved has made implementations excessively difficult and ultimately infeasible. The improved algorithm in this study is used to capture the interface of the immiscible fluids which are applicable both in 2D and 3D spaces. A computationally efficient and second-order accurate interface reconstruction method is applied. The normal estimation of the interface is approximated by combining the centered column scheme and the Youngs' method. Besides, a linear mapping technique is implemented to improve the efficiency of numerical simulations with regard to the approximation of capturing the interface. The sequence of the Lagrangian advection in each direction is considered to restrain the fragmentation caused by the strong interface deformation as the fluids propagate. It is significant to note that the method can be accurately accomplished by a regular structured mesh without any geometrical modifications such as boundary fitted grids. Next, the mass conservation is numerically assessed, thus allowing computations to reach the machine precision. The computational results include widely used benchmarks in 2D and 3D cases, such as the solid-body translations and rotations, the swirled single vortex and the deformation fields of fluid body. Good results are obtained through some numerical tests by using present algorithm as comparing with other numerical solutions. (C) 2013 Elsevier Ltd. All rights reserved.
SN 0017-9310
PD MAY
PY 2013
VL 60
BP 739
EP 755
DI 10.1016/j.ijheatmasstransfer.2012.12.049
UT WOS:000317534500080
ER

PT J
AU Wang, Q
   Liu, WP
   Wang, XM
   Chen, XH
   Chen, GN
   Wu, QX
AF Wang, Qing
   Liu, Weiping
   Wang, Xiumei
   Chen, Xinghong
   Chen, Guannan
   Wu, Qingxiang
TI A Spatial-Temporal Graph Model for Pronunciation Feature Prediction of
   Chinese Poetry
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
AB With the development of artificial intelligence, speech recognition and prediction have become one of the important research domains with wild applications, such as intelligent control, education, individual identification, and emotion analysis. Chinese poetry reading contains rich features of continuous pronunciations, such as mood, emotion, rhythm schemes, lyric reading, and artistic expression. Therefore, the prediction of the pronunciation characteristics of a Chinese poetry reading is the significance for the presentation of high-level machine intelligence and has the potential to create a high-level intelligent system for teaching children to read Tang poetry. Mel frequency cepstral coefficient (MFCC) is currently used to present important speech features. Due to the complexity and high degree of nonlinearity in poetry reading, however, there is a tough challenge facing accurate pronunciation feature prediction, that is, how to model complex spatial correlations and time dynamics, such as rhyme schemes. As for many current methods, they ignore the spatial and temporal characteristics in MFCC presentation. In addition, these methods are subjected to certain limitations on prediction for long-term performance. In order to solve these problems, we propose a novel spatial-temporal graph model (STGM-MHA) based on multihead attention for the purpose of pronunciation feature prediction of Chinese poetry. The STGM-MHA is designed using an encoder-decoder structure. The encoder compresses the data into a hidden space representation, while the decoder reconstructs the hidden space representation as output. In the model, a novel gated recurrent unit (GRU) module (AGRU) based on multihead attention is proposed to extract the spatial and temporal features of MFCC data effectively. The evaluation comparison of our proposed model versus state-of-the-art methods in six datasets reveals the clear advantage of the proposed model.
RI Chen, Xinghong/HCI-8310-2022; Chen, Guannan/L-8203-2015
OI Chen, Guannan/0000-0001-9296-578X; Wang, Qing/0000-0002-3396-4805
SN 2162-237X
EI 2162-2388
DI 10.1109/TNNLS.2022.3165554
EA APR 2022
UT WOS:000785852100001
PM 35446770
ER

PT J
AU Rusheen, AE
   Barath, AS
   Goyal, A
   Barnett, JH
   Gifford, BT
   Bennet, KE
   Blaha, CD
   Goerss, SJ
   Oh, Y
   Lee, KH
AF Rusheen, Aaron E.
   Barath, Abhijeet S.
   Goyal, Abhinav
   Barnett, J. Hudson
   Gifford, Benjamin T.
   Bennet, Kevin E.
   Blaha, Charles D.
   Goerss, Stephan J.
   Oh, Yoonbae
   Lee, Kendall H.
TI A compact stereotactic system for image-guided surgical intervention
SO JOURNAL OF NEURAL ENGINEERING
AB Objective. Stereotactic technology enables fine navigation to small structures in the human body. While current stereotactic systems facilitate accurate targeting, they are mechanically cumbersome and limited in scope. Here, we hypothesized that a stereotactic system could be developed with a reduced footprint while maintaining broad targeting capabilities in order to improve versatility in frame placement location and surgical workflow. Approach. We designed a stereotactic system around the center-of-arc principle, with mechanical properties that would enable a compact design and ample targeting and trajectory maneuverability. To examine the opportunity for a low-cost rapidly-deployable system we developed two fabrication variants, one using three dimensional (3D)-printing and the other using conventional machining. Mechanical and image-guided accuracies were tested in phantom studies using magnetic resonance imaging (MRI) and computed tomography. Using human cadaver head specimens, we assessed the system's surgical workflow and its ability to reliably and accurately implant electrodes in deep brain stimulation (DBS) surgery. Main results. We developed a small 7.7 x 5.4 cm(2) device platform that rigidly mounts to curvilinear bone and supports the attachment of surgical instrumentation. Attachment of two surgical instruments, an imaging localizer and a compact targeting device, demonstrated successful MRI-guided intervention in phantom studies with a vector error of 1.79 +/- 0.41 mm. Evaluation of the 3D-printed system for DBS surgery confirmed ease of device platform attachment and instrument functionality, as well as demonstrated a surgical targeting accuracy of 1.83 +/- 0.15 mm. In addition, we found the surgical time to be 78.3 +/- 5.4 min for bilateral electrode implantation. Significance. We developed a light and compact stereotactic system whose accuracy is on par with those used clinically. This technology is suitable for clinical translation and its flexibility in positioning will seamlessly expand the capabilities for stereotaxy to treat a wide range of conditions, both within neurosurgery and beyond.
OI Rusheen, Aaron/0000-0001-8029-1167; Oh, Yoonbae/0000-0003-1779-978X;
   Blaha, Charles/0000-0001-5155-1505; Barnett, Joseph/0000-0003-2844-2233;
   Goyal, Abhinav/0000-0002-8465-7418
SN 1741-2560
EI 1741-2552
PD DEC
PY 2020
VL 17
IS 6
AR 066014
DI 10.1088/1741-2552/abc743
UT WOS:000617568000001
PM 33142275
ER

PT C
AU Abu Bakar, Z
   Ismail, NK
   Rawi, MIM
AF Abu Bakar, Zamri
   Ismail, Normaly Kamal
   Rawi, Mohd Izani Mohamed
TI Rule-based Approach on Extraction of Malay Compound Nouns in Standard
   Malay Document
SO INTERNATIONAL RESEARCH AND INNOVATION SUMMIT (IRIS2017)
SE IOP Conference Series-Materials Science and Engineering
CT International Research and Innovation Summit (IRIS)
CY MAY 06-07, 2017
CL Melaka, MALAYSIA
SP Univ Tun Hussein Onn Malaysia
AB Malay compound noun is defined as a form of words that exists when two or more words are combined into a single syntax and it gives a specific meaning. Compound noun acts as one unit and it is spelled separately unless an established compound noun is written closely from two words. The basic characteristics of compound noun can be seen in the Malay sentences which are the frequency of that word in the text itself. Thus, this extraction of compound nouns is significant for the following research which is text summarization, grammar checker, sentiments analysis, machine translation and word categorization. There are many research efforts that have been proposed in extracting Malay compound noun using linguistic approaches. Most of the existing methods were done on the extraction of bi-gram noun+noun compound. However, the result still produces some problems as to give a better result. This paper explores a linguistic method for extracting compound Noun from stand Malay corpus. A standard dataset are used to provide a common platform for evaluating research on the recognition of compound Nouns in Malay sentences. Therefore, an improvement for the effectiveness of the compound noun extraction is needed because the result can be compromised. Thus, this study proposed a modification of linguistic approach in order to enhance the extraction of compound nouns processing. Several pre-processing steps are involved including normalization, tokenization and tagging. The first step that uses the linguistic approach in this study is Part-of-Speech (POS) tagging. Finally, we describe several rules-based and modify the rules to get the most relevant relation between the first word and the second word in order to assist us in solving of the problems. The effectiveness of the relations used in our study can be measured using recall, precision and Fl-score techniques. The comparison of the baseline values is very essential because it can provide whether there has been an improvement in the result.
SN 1757-8981
PY 2017
VL 226
AR 012106
DI 10.1088/1757-899X/226/1/012106
UT WOS:000419293900106
ER

PT J
AU Kretz, R
   Walter, L
   Raab, N
   Zeh, N
   Gauges, R
   Otte, K
   Fischer, S
   Stoll, D
AF Kretz, Robin
   Walter, Larissa
   Raab, Nadja
   Zeh, Nikolas
   Gauges, Ralph
   Otte, Kerstin
   Fischer, Simon
   Stoll, Dieter
TI Spatial Proteomics Reveals Differences in the Cellular Architecture of
   Antibody-Producing CHO and Plasma Cell-Derived Cells
SO MOLECULAR & CELLULAR PROTEOMICS
AB Most of the recombinant biotherapeutics employed today to combat severe illnesses, for example, various types of cancer or autoimmune diseases, are produced by Chi-nese hamster ovary (CHO) cells. To meet the growing demand of these pharmaceuticals, CHO cells are under constant development in order to enhance their stability and productivity. The last decades saw a shift from empirical cell line optimization toward rational cell engi-neering using a growing number of large omics datasets to alter cell physiology on various levels. Especially pro-teomics workflows reached new levels in proteome coverage and data quality because of advances in high -resolution mass spectrometry instrumentation. One type of workflow concentrates on spatial proteomics by usage of subcellular fractionation of organelles with subsequent shotgun mass spectrometry proteomics and machine learning algorithms to determine the subcellular locali-zation of large portions of the cellular proteome at a certain time point. Here, we present the first subcellular spatial proteome of a CHO-K1 cell line producing high titers of recombinant antibody in comparison to the spatial proteome of an antibody-producing plasma cell-derived myeloma cell line. Both cell lines show colocalization of immunoglobulin G chains with chaper-ones and proteins associated in protein glycosylation within the endoplasmic reticulum compartment. However, we report differences in the localization of proteins associated to vesicle-mediated transport, transcription, and translation, which may affect antibody production in both cell lines. Furthermore, pairing subcellular localiza-tion data with protein expression data revealed elevated protein masses for organelles in the secretory pathway in plasma cell-derived MPC-11 (Merwin plasma cell tumor -11) cells. Our study highlights the potential of subcellu-lar spatial proteomics combined with protein expression as potent workflow to identify characteristics of highly efficient recombinant protein-expressing cell lines. Data are available via ProteomeXchange with identifier PXD029115.
OI Stoll, Dieter/0000-0002-8703-7652; Zeh, Nikolas/0000-0003-4889-7761;
   Fischer, Simon/0000-0002-5188-7620
EI 1535-9484
PD OCT
PY 2022
VL 21
IS 10
AR 100278
DI 10.1016/j.mcpro.2022.100278
EA OCT 2022
UT WOS:000869762800002
PM 35934186
ER

PT J
AU Reinertsen, AB
AF Reinertsen, Anne Beate
TI I contain multitudes
SO AUSTRALIAN JOURNAL OF ENVIRONMENTAL EDUCATION
AB The rhizome is like the poem. The growth power of nature and the possibilities of culture simultaneously and reciprocally. It stretches from biological cell and level of particles to our universal dreams and thoughts about and with life. The rhizome as poem is thus a picture and image of the importance of context and movement, production of constant importance for each/other. The picture breaks all patterns always and always creates new, as points and lines affectively collapsing into each/other for each/other. The rhizome as poem - and the consciousness about the preliminarity of processes across preliminary boundaries, opens up for translations and interpretations beyond known vocabularies and in unfinished channels. It possibilizes the realization of more - than - human concepts such as the dissolution of subjectivity turning my identity into a collective: 1 contain multitudes and sing myself.' Knowledge creation and meaning making are thus connected with what situated knowledges makes possible and mobilize, and is about community, not isolated individuals; it is about productive connections and unexpected openings in which every concept is 'trapped' in experience. Informatically we are data subjects of an algorithmic nature. I oxymoronically and indirectly therefore ask how we can become materially identifiable subjects and what would it take to move from a mechanistic approach to education to a more machinic one? Further, are the abstractions one attempts to move from imitation to imagination abstract enough? I poem with the speculative process philosophy of Gilles Deleuze (1925-1995) and Felix Guattari (1930-1992) to think the future, theory and practice in Environmental Education other. Taking part in polysemantic ambiguity becomes attractive as condition to side with the child and it might turn into a strong source of energy for learning and change, trans-scientific collaboration and sustainability. The rhizome is my cosmic writing machine, research design and model.
SN 0814-0626
EI 2049-775X
PD SEP
PY 2022
VL 38
IS 3-4
SI SI
BP 279
EP 297
DI 10.1017/aee.2021.30
EA JAN 2022
UT WOS:000743352900001
ER

PT C
AU Hossain, MS
   Nayla, N
   Rassel, AA
AF Hossain, Md Sabbir
   Nayla, Nishat
   Rassel, Annajiat Alim
GP IEEE
TI PRODUCT MARKET DEMAND ANALYSIS USING NLP IN BANGLISH TEXT WITH SENTIMENT
   ANALYSIS AND NAMED ENTITY RECOGNITION
SO 2022 56TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS)
CT 56th Annual Conference on Information Sciences and Systems (CISS)
CY MAR 09-11, 2022
CL ELECTR NETWORK
AB Product market demand analysis plays a significant role for originating business strategies due to its noticeable impact on the competitive business field. Furthermore, there are roughly 228 million native Bengali speakers, the majority of whom use Banglish text to interact with one another on social media. Consumers are buying and evaluating items on social media with Banglish text as social media emerges as an online marketplace for entrepreneurs. People use social media to find preferred smartphone brands and models by sharing their positive and bad experiences with them. For this reason, our goal is to gather Banglish text data and use sentiment analysis and named entity identification to assess Bangladeshi market demand for smartphones in order to determine the most popular smartphones by gender. We scraped product related data from social media with instant data scrapers and crawled data from Wikipedia and other sites for product information with python web scrapers. Using Python's Pandas and Seaborn libraries, the raw data is filtered using NLP methods. To train our datasets for named entity recognition, we utilized Spacey's custom NER model, Amazon Comprehend Custom NER. A tensorflow sequential model was deployed with parameter tweaking for sentiment analysis. Meanwhile, we used the Google Cloud Translation API to estimate the gender of the reviewers using the BanglaLinga library. In this article, we use natural language processing (NLP) approaches and several machine learning models to identify the most in-demand items and services in the Bangladeshi market. Our model has an accuracy of 87.99% in Spacy Custom Named Entity recognition, 95.51% in Amazon Comprehend Custom NER, and 87.02% in the Sequential model for demand analysis. After Spacy's study, we were able to manage 80% of mistakes related to misspelled words using a mix of Levenshtein distance and ratio algorithms.
RI Rasel, Annajiat Alim/GLT-4370-2022
OI Rasel, Annajiat Alim/0000-0003-0198-3734
BN 978-1-6654-1796-9
PY 2022
BP 166
EP 171
DI 10.1109/CISS53076.2022.9751188
UT WOS:000945325900014
ER

PT J
AU Timonidis, N
   Bakker, R
   Tiesinga, P
AF Timonidis, Nestor
   Bakker, Rembrandt
   Tiesinga, Paul
TI Prediction of a Cell-Class-Specific Mouse Mesoconnectome Using Gene
   Expression Data
SO NEUROINFORMATICS
AB Reconstructing brain connectivity at sufficient resolution for computational models designed to study the biophysical mechanisms underlying cognitive processes is extremely challenging. For such a purpose, a mesoconnectome that includes laminar and cell-class specificity would be a major step forward. We analyzed the ability of gene expression patterns to predict cell-class and layer-specific projection patterns and assessed the functional annotations of the most predictive groups of genes. To achieve our goal we used publicly available volumetric gene expression and connectivity data and we trained computational models to learn and predict cell-class and layer-specific axonal projections using gene expression data. Predictions were done in two ways, namely predicting projection strengths using the expression of individual genes and using the co-expression of genes organized in spatial modules, as well as predicting binary forms of projection. For predicting the strength of projections, we found that ridge (L2-regularized) regression had the highest cross-validated accuracy with a median r(2) score of 0.54 which corresponded for binarized predictions to a median area under the ROC value of 0.89. Next, we identified 200 spatial gene modules using a dictionary learning and sparse coding approach. We found that these modules yielded predictions of comparable accuracy, with a median r(2) score of 0.51. Finally, a gene ontology enrichment analysis of the most predictive gene groups resulted in significant annotations related to postsynaptic function. Taken together, we have demonstrated a prediction workflow that can be used to perform multimodal data integration to improve the accuracy of the predicted mesoconnectome and support other neuroscience use cases.
RI Tiesinga, Paul/D-1901-2010
SN 1539-2791
EI 1559-0089
PD OCT
PY 2020
VL 18
IS 4
BP 611
EP 626
DI 10.1007/s12021-020-09471-x
EA MAY 2020
UT WOS:000535156500001
PM 32448958
ER

PT J
AU Chen, Z
   Zhang, HZ
   Luo, H
   Yang, R
   Zhang, ZZ
   Jiang, C
   Hou, JY
   Zhou, YF
   Xu, Y
   Song, B
   Li, WP
AF Chen, Zhong
   Zhang, Haozhi
   Luo, Huan
   Yang, Rui
   Zhang, Zhengzheng
   Jiang, Chuan
   Hou, Jingyi
   Zhou, Yunfeng
   Xu, Yue
   Song, Bin
   Li, Weiping
TI Contact mechanics after mattress suture repair of medial meniscus
   vertical longitudinal tear: an in vitro study
SO ARCHIVES OF ORTHOPAEDIC AND TRAUMA SURGERY
AB Purpose Most studies have concentrated on the changes in contact pressure and area on the tibiofemoral joint. This study compared the contact mechanics underneath the medial meniscus of a repaired vertical longitudinal tear with that of the intact or the torn ones. Methods In this controlled laboratory study, a 1000 N compressive axial load was applied to eight fresh-frozen cadaveric knees at four flexion angles and four loading conditions using a custom testing apparatus attached to a material testing machine. Intact knees, knees with a medial meniscus vertical longitudinal tear, and knees after meniscal repair were tested. The peak contact pressure and area underneath the meniscus were measured using Fuji pressure-sensitive film. Results A medial meniscus vertical longitudinal tear significantly increased the contact pressure and decreased contact area underneath the meniscus compared with those at the intact meniscus under all tested biomechanical conditions, and repair of the tear can restore the contact pressure and area in most conditions. While the repaired group showed a significantly higher or similar contact pressure compared with the tear group at 90 degrees neutral knee position and at 60 degrees, 90 degrees 5 N center dot m-external rotation and 134 N-anterior tibial translation, and 5 N center dot m-internal rotation at all flexion angles. The contact area corresponding to the aberrant result of the contact pressure in the repaired group was lower than in the intact meniscus group. Conclusions The contact mechanics underneath the meniscus of the repaired medial meniscus vertical longitudinal tear were significantly improved compared with the corresponding tear conditions in most cases, while the contact pressure and area at some certain status after repair were not significantly different from those of the corresponding tear conditions.
RI Song, Bin/AAD-3670-2020
SN 0936-8051
EI 1434-3916
PD SEP
PY 2020
VL 140
IS 9
BP 1221
EP 1230
DI 10.1007/s00402-020-03428-0
EA APR 2020
UT WOS:000527501400003
PM 32306090
ER

PT J
AU Bettoni, M
AF Bettoni, Marco
TI The Yerkish Language. From Operational Methodology to Chimpanzee
   Communication
SO CONSTRUCTIVIST FOUNDATIONS
AB Purpose: Yerkish is an artificial language created in 1971 for the specific purpose of exploring the linguistic potential of nonhuman primates. The aim of this paper is to remind the research community of some important issues and concepts related to Yerkish that seem to have been forgotten or appear to be distorted. These are, particularly, its success, its promising aspects for future research and last but not least that it was Ernst von Glasersfeld who invented Yerkish: he coined the term "lexigrams," created the first 120 of them and designed the grammar that regulated their combination. Design: The first part of this paper begins with a short outline of the context in which the Yerkish language originated: the original LANA project. It continues by presenting the language itself in more detail: first, its design, focusing on its "lexigrams" and its "correlational" grammar ( the connective functions or "correlators" and the combinations of lexigrams, or "correlations"), and then its use by the chimpanzee Lana in formulating sentences. The second part gives a brief introduction to the foundation of Yerkish in Silvio Ceccato's Operational Methodology, particularly his idea of the correlational structure of thought and concludes with the main insights that can be derived from the Yerkish experiment seen in the light of Operational Methodology. Findings: Lana's success in language learning and the success of Yerkish during the past decades are probably due to the characteristics of Yerkish, particularly its foundation in operational methodology. The operation of correlation could be what constitutes thinking in a chimpanzee and an attentional system could be what delivers the mental content that correlation assembles into triads and networks. Research implications: Since no other assessment or explanation of Lana's performances has considered these foundational issues (findings), a new research project or program should validate the above-mentioned hypotheses, particularly the correlational structure of chimpanzee thinking.
SN 1782-348X
PD MAR
PY 2007
VL 2
IS 2-3
BP 32
EP 38
UT WOS:000207447800008
ER

PT J
AU Misra, G
   Wang, WE
   Archer, DB
   Roy, A
   Coombes, SA
AF Misra, Gaurav
   Wang, Wei-en
   Archer, Derek B.
   Roy, Arnab
   Coombes, Stephen A.
TI Automated classification of pain perception using high-density
   electroencephalography data
SO JOURNAL OF NEUROPHYSIOLOGY
AB The translation of brief, millisecond-long pain-eliciting stimuli to the subjective perception of pain is associated with changes in theta, alpha, beta, and gamma oscillations over sensorimotor cortex. However, when a pain-eliciting stimulus continues for minutes, regions beyond the sensorimotor cortex, such as the prefrontal cortex, are also engaged. Abnormalities in prefrontal cortex have been associated with chronic pain states, but conventional, millisecond-long EEG paradigms do not engage prefrontal regions. In the current study, we collected high-density EEG data during an experimental paradigm in which subjects experienced a 4-s, low-or high-intensity pain-eliciting stimulus. EEG data were analyzed using independent component analyses, EEG source localization analyses, and measure projection analyses. We report three novel findings. First, an increase in pain perception was associated with an increase in gamma and theta power in a cortical region that included medial prefrontal cortex. Second, a decrease in lower beta power was associated with an increase in pain perception in a cortical region that included the contralateral sensorimotor cortex. Third, we used machine learning for automated classification of EEG data into low-and high-pain classes. Theta and gamma power in the medial prefrontal region and lower beta power in the contralateral sensorimotor region served as features for classification. We found a leave-one-out cross-validation accuracy of 89.58%. The development of biological markers for pain states continues to gain traction in the literature, and our findings provide new information that advances this body of work.
   NEW & NOTEWORTHY The development of a biological marker for pain continues to gain traction in literature. Our findings show that high- and low-pain perception in human subjects can be classified with 89% accuracy using high- density EEG data from prefrontal cortex and contralateral sensorimotor cortex. Our approach represents a novel neurophysiological paradigm that advances the literature on biological markers for pain.
SN 0022-3077
EI 1522-1598
PD FEB
PY 2017
VL 117
IS 2
BP 786
EP 795
DI 10.1152/jn.00650.2016
UT WOS:000393863600028
PM 27903639
ER

PT C
AU Lin, WC
   Chang, ST
   Lin, YC
   Hsu, MY
   Chang, YT
   Chang, SH
   Huang, TM
AF Lin, Wei-Cheng
   Chang, Shenq-Tsong
   Lin, Yu-Chuan
   Hsu, Ming-Ying
   Chang, Yu-Ting
   Chang, Sheng-Hsiung
   Huang, Ting-Ming
BE Sasian, J
   Youngworth, RN
TI The alignment and iso-static mount bonding technique of the aerospace
   Cassegrain telescope primary mirror
SO OPTICAL SYSTEM ALIGNMENT, TOLERANCING, AND VERIFICATION VI
SE Proceedings of SPIE
CT Conference on Optical System Alignment, Tolerancing, and Verification VI
CY AUG 12-13, 2012
CL San Diego, CA
SP SPIE
AB In order to meet both optical performance and structural stiffness requirements of the aerospace Cassegrain telescope, iso-static mount is used as the interface between the primary mirror and the main plate. This article describes the alignment and iso-static mount bonding technique of the primary mirror by assistance of CMM. The design and assembly of mechanical ground support equipment (MGSE) which reduces the deformation of primary mirror by the gravity effect is also presented. The primary mirror adjusting MGSE consists of X-Y linear translation stages, rotation stage and kinematic constrain platform which provides the function of decenter, orientation, tilt and height adjustment of the posture sequentially. After CMM measurement, the radius of curvature, conic constant, decenter and tilt, etc. will be calculated. According to these results, the posture of the mirror will be adjusted to reduce the tilt by the designed MGSE within 0.02 degrees and the distance deviation from the best fitted profile of mirror to main plate shall be less than 0.01 mm. After that, EC 2216 adhesive is used to bond mirror and iso-static mount. During iso-static mount bonding process, CMM is selected to monitor the relative position deviation of the iso-static mount until the adhesive completely cured. After that, the wave front sensors and strain gauges are used to monitor the strain variation while the iso-static mount mounted in the main plate with the screws by the torque wrench. This step is to prevent deformation of the mirror caused from force of the iso-static mount during the mounting process. In the end, the interferometer is used for the optical performance test with +1G and -1G to check the alignment and bonding technique is well or not.
SN 0277-786X
BN 978-0-8194-9208-1
PY 2012
VL 8491
AR 84910M
DI 10.1117/12.929601
UT WOS:000312209900017
ER

PT C
AU Verma, S
   Kim, WJ
   Shakir, H
AF Verma, S
   Kim, WJ
   Shakir, H
GP ieee
TI Multi-axis maglev nanopositioner for precision manufacturing and
   manipulation applications
SO CONFERENCE RECORD OF THE 2004 IEEE INDUSTRY APPLICATIONS CONFERENCE,
   VOLS 1-4: COVERING THEORY TO PRACTICE
SE IEEE Industry Applications Society Annual Meeting
CT 39th Annual Meeting of the IEEE-Industry-Applications-Society
CY OCT 03-07, 2004
CL Seattle, WA
SP IEEE Ind Applicat Soc
AB We present a 6-axis magnetic levitation (maglev) stage capable of precision positioning down to several nanometers. This stage has a simple and compact mechanical structure advantageous to meet the performance requirements in the next-generation nano manufacturing. It uses the minimum number of linear actuators required to generate all 6-axis motions. Three vertical actuators are used to levitate the moving part, namely the platen, and maintain its vertical position. Other three horizontal actuators control its position and rotation in the horizontal plane. In this paper, we describe the electromechanical design, modeling and control, and the electronic instrumentation to control this maglev system. We modeled the platen as a pure mass due to negligible spring and damping forces while it is levitated without contact. The stage has a light moving-part mass of 0.2126 kg. It is capable of generating translation of 300 pm in the x-, y- and z- axes, and rotation of 3 mrad about the three orthogonal axes. The stage demonstrates position resolution better than 5 nm rms and position noise less than 2 nm rms. The total power consumption by all the actuators is only a fraction of a watt. Experimental results presented in this paper show that the stage can carry, orient, and precisely position a payload as heavy as 0.3 kg. The pull-out force was found to be 8.08 N in the vertical direction. Furthermore, under the effect of a load variation of 0.14 N, the plant recovers its regulated position within 0.6 s. All these experimental results match quite closely with the calculated values because of the accurate plant model and robust controller design. This device can be used as a positioning stage for numerous applications including photolithography for semiconductor manufacturing, microscopic scanning of delicate instruments, fabrication and assembly of nano-structures, and microscale rapid prototyping.
SN 0197-2618
BN 0-7803-8486-5
PY 2004
BP 2084
EP 2091
UT WOS:000225148600305
ER

PT J
AU Venturi, S
   Casey, T
AF Venturi, Simone
   Casey, Tiernan
TI SVD perspectives for augmenting DeepONet flexibility and
   interpretability
SO COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING
AB Deep operator networks (DeepONets) are powerful and flexible architectures that are attracting attention in multiple fields due to their utility for fast and accurate emulation of complex dynamics. As their remarkable generalization capabilities are primarily enabled by their projection-based attribute, in this paper, we investigate connections with low-rank techniques derived from the singular value decomposition (SVD). We demonstrate that some of the concepts behind proper orthogonal decomposition (POD)-neural networks can improve DeepONet's design and training phases. These ideas lead us to a methodology extension that we name SVD-DeepONet. Moreover, through multiple SVD analyses of scenario-and time-aggregated snapshots matrices, we find that DeepONet inherits from its projection-based attribute strong inefficiencies in representing dynamics characterized by symmetries. Inspired by the work on shifted-POD, we develop flexDeepONet, an architecture enhancement that relies on a pre-transformation network for generating a moving reference frame and isolating the rigid components of the dynamics. In this way, the physics can be represented on a latent space free from rotations, translations, and stretches, and an accurate projection can be performed to a low-dimensional basis. In addition to improving DeepONet's flexibility and interpretability, the proposed perspectives increase its generalization capabilities and computational efficiencies. For instance, we show flexDeepONet can accurately surrogate the dynamics of 19 thermodynamic variables in a combustion chemistry application by relying on 95% fewer trainable parameters than that of the 'vanilla' architecture. As stressed in the paper, we argue that DeepONet and SVD-based methods can reciprocally benefit from each other. In particular, the flexibility of the former in leveraging multiple data sources and multifidelity knowledge in the form of both unstructured data and physics-informed constraints has the potential to greatly extend the applicability of methodologies such as POD and principal component analysis (PCA).(c) 2022 Elsevier B.V. All rights reserved.
SN 0045-7825
EI 1879-2138
PD JAN 1
PY 2023
VL 403
AR 115718
DI 10.1016/j.cma.2022.115718
PN A
UT WOS:000896728600001
ER

PT J
AU Boulares, M
   Barnawi, A
AF Boulares, Mehrez
   Barnawi, Ahmed
TI Unsupervised sign language validation process based on hand-motion
   parameter clustering
SO COMPUTER SPEECH AND LANGUAGE
AB Automatic sign language translation process relies mainly on dictionaries of signs to interpret the right meaning of gestures. Due to the lack of large multi sign language dictionaries covering all the aspect of sign languages, the collaborative approach to create signs becomes essential. In fact, the collaborative sign creation process based on Kinect motion capture tool requires the collaboration of non expert users to make sign language dictionaries. However, due to the availability constraint of sign language experts to validate the created signs and the huge amount of signs to be validated manually, the automatic sign language validation process becomes the most suitable solution. In this paper, we present a new automatic and unsupervised sign validation process based on machine learning techniques applied on sign replicas. Given a set of replicas (records) of the same sign created by different non expert sign language user, our main goal is to select the adequate sign records to be used to generate the closest sign signature compared to the one created by sign language expert. For this aim, we present an automatic sign selection and validation solution based on unsupervised clustering of sign motion parameters related to the different sign replicas. We conducted an experimental study to validate 300 ASL signs based on four unsupervised clustering methods, namely, Kernel PCA Kmeans, GMM, Spectral clustering and kernel Kmeans. We concluded that the use our sign validation process using Spectral clustering method allows us to select the right sign replicas to be used to generate the user sign signature. The use of our unsupervised sign validation process onto 3000 ASL sign replicas (300 sign * 10 replicas) lead us to enhance the R2 score average from 0.4830 without sign validation to 0.9123 with sign validation compared to expert sign signature.
SN 0885-2308
EI 1095-8363
PD JAN
PY 2022
VL 71
AR 101256
DI 10.1016/j.csl.2021.101256
UT WOS:000761599000002
ER

PT J
AU Mutinda, FW
   Yada, S
   Wakamiya, S
   Aramaki, E
AF Mutinda, Faith Wavinya
   Yada, Shuntaro
   Wakamiya, Shoko
   Aramaki, Eiji
TI Semantic Textual Similarity in Japanese Clinical Domain Texts Using BERT
SO METHODS OF INFORMATION IN MEDICINE
AB Background Semantic textual similarity (STS) captures the degree of semantic similarity between texts. It plays an important role in many natural language processing applications such as text summarization, question answering, machine translation, information retrieval, dialog systems, plagiarism detection, and query ranking. STS has been widely studied in the general English domain. However, there exists few resources for STS tasks in the clinical domain and in languages other than English, such as Japanese.
   Objective The objective of this study is to capture semantic similarity between Japanese clinical texts (Japanese clinical STS) by creating a Japanese dataset that is publicly available.
   Materials We created two datasets for Japanese clinical STS: (1) Japanese case reports (CR dataset) and (2) Japanese electronic medical records (EMR dataset). The CR dataset was created from publicly available case reports extracted from the CiNii database. The EMR dataset was created from Japanese electronic medical records.
   Methods We used an approach based on bidirectional encoder representations from transformers (BERT) to capture the semantic similarity between the clinical domain texts. BERT is a popular approach for transfer learning and has been proven to be effective in achieving high accuracy for small datasets. We implemented two Japanese pretrained BERT models: a general Japanese BERT and a clinical Japanese BERT. The general Japanese BERT is pretrained on Japanese Wikipedia texts while the clinical Japanese BERT is pretrained on Japanese clinical texts.
   Results The BERT models performed well in capturing semantic similarity in our datasets. The general Japanese BERT outperformed the clinical Japanese BERT and achieved a high correlation with human score (0.904 in the CR dataset and 0.875 in the EMR dataset). It was unexpected that the general Japanese BERT outperformed the clinical Japanese BERT on clinical domain dataset. This could be due to the fact that the general Japanese BERT is pretrained on a wide range of texts compared with the clinical Japanese BERT.
SN 0026-1270
EI 2511-705X
PD JUN
PY 2021
VL 60
SU 01
BP E56
EP E64
DI 10.1055/s-0041-1731390
EA JUL 2021
UT WOS:000670742100003
PM 34237783
ER

PT J
AU Bernchou, U
   Christiansen, RL
   Bertelsen, A
   Tilly, D
   Riis, HL
   Jensen, HR
   Mahmood, F
   Hansen, CR
   Hansen, VN
   Schytte, T
   Brink, C
AF Bernchou, Uffe
   Christiansen, Rasmus L.
   Bertelsen, Anders
   Tilly, David
   Riis, Hans L.
   Jensen, Henrik R.
   Mahmood, Faisal
   Hansen, Christian R.
   Hansen, Vibeke N.
   Schytte, Tine
   Brink, Carsten
TI End-to-end validation of the geometric dose delivery performance of MR
   linac adaptive radiotherapy
SO PHYSICS IN MEDICINE AND BIOLOGY
AB The clinical introduction of hybrid magnetic resonance (MR) guided radiotherapy (RT) delivery systems has led to the need to validate the end-to-end dose delivery performance on such machines. In the current study, an MR visible phantom was developed and used to test the spatial deviation between planned and delivered dose at two 1.5 T MR linear accelerator (MR linac) systems, including pre-treatment imaging, dose planning, online imaging, image registration, plan adaptation, and dose delivery. The phantom consisted of 3D printed plastic and MR visible silicone rubber. It was designed to minimise air gaps close to the radiochromic film used as a dosimeter. Furthermore, the phantom was designed to allow submillimetre, reproducible positioning of the film in the phantom. At both MR linac systems, 54 complete adaptive, MR guided RT workflow sessions were performed. To test the dose delivery performance of the MR linac systems in various adaptive RT (ART) scenarios, the sessions comprised a range of systematic positional shifts of the phantom and imaging or plan adaptation conditions. In each workflow session, the positional translation between the film and the adaptive planned dose was determined. The results showed that the accuracy of the MR linac systems was between 0.1 and 0.9 mm depending on direction. The highest mean deviance observed was in the posterior-anterior direction, and the direction of the error was consistent between centres. The precision of the systems was related to whether the workflow utilized the internal image registration algorithm of the MR linac. Workflows using the internal registration algorithm led to a worse precision (0.2-0.7 mm) compared to workflows where the algorithm was decoupled (0.2 mm). In summary, the spatial deviation between planned and delivered dose of MR-guided ART at the two MR linac systems was well below 1 mm and thus acceptable for clinical use.
OI Brink, Carsten/0000-0003-3906-1962; Mahmood, Faisal/0000-0002-7270-7967;
   Hansen, Christian Ronn/0000-0001-5716-6069; Tilly,
   David/0000-0002-2842-7116; Bernchou, Uffe/0000-0002-5309-2696
SN 0031-9155
EI 1361-6560
PD FEB 21
PY 2021
VL 66
IS 4
AR 045034
DI 10.1088/1361-6560/abd3ed
UT WOS:000617146600001
PM 33321475
ER

PT J
AU Foster, JD
   Nuyujukian, P
   Freifeld, O
   Gao, H
   Walker, R
   Ryu, SI
   Meng, TH
   Murmann, B
   Black, MJ
   Shenoy, KV
AF Foster, Justin D.
   Nuyujukian, Paul
   Freifeld, Oren
   Gao, Hua
   Walker, Ross
   Ryu, Stephen I.
   Meng, Teresa H.
   Murmann, Boris
   Black, Michael J.
   Shenoy, Krishna V.
TI A freely-moving monkey treadmill model
SO JOURNAL OF NEURAL ENGINEERING
AB Objective. Motor neuroscience and brain-machine interface (BMI) design is based on examining how the brain controls voluntary movement, typically by recording neural activity and behavior from animal models. Recording technologies used with these animal models have traditionally limited the range of behaviors that can be studied, and thus the generality of science and engineering research. We aim to design a freely-moving animal model using neural and behavioral recording technologies that do not constrain movement. Approach. We have established a freely-moving rhesus monkey model employing technology that transmits neural activity from an intracortical array using a head-mounted device and records behavior through computer vision using markerless motion capture. We demonstrate the flexibility and utility of this new monkey model, including the first recordings from motor cortex while rhesus monkeys walk quadrupedally on a treadmill. Main results. Using this monkey model, we show that multi-unit threshold-crossing neural activity encodes the phase of walking and that the average firing rate of the threshold crossings covaries with the speed of individual steps. On a population level, we find that neural state-space trajectories of walking at different speeds have similar rotational dynamics in some dimensions that evolve at the step rate of walking, yet robustly separate by speed in other state-space dimensions. Significance. Freely-moving animal models may allow neuroscientists to examine a wider range of behaviors and can provide a flexible experimental paradigm for examining the neural mechanisms that underlie movement generation across behaviors and environments. For BMIs, freely-moving animal models have the potential to aid prosthetic design by examining how neural encoding changes with posture, environment and other real-world context changes. Understanding this new realm of behavior in more naturalistic settings is essential for overall progress of basic motor neuroscience and for the successful translation of BMIs to people with paralysis.
OI Nuyujukian, Paul/0000-0001-7778-5473; Murmann, Boris/0000-0003-3417-8782
SN 1741-2560
EI 1741-2552
PD AUG
PY 2014
VL 11
IS 4
AR 046020
DI 10.1088/1741-2560/11/4/046020
UT WOS:000340046500020
PM 24995476
ER

PT J
AU Lucas, JE
   Thompson, JW
   Dubois, LG
   McCarthy, J
   Tillmann, H
   Thompson, A
   Shire, N
   Hendrickson, R
   Dieguez, F
   Goldman, P
   Schwarz, K
   Patel, K
   McHutchison, J
   Moseley, MA
AF Lucas, Joseph E.
   Thompson, J. Will
   Dubois, Laura G.
   McCarthy, Jeanette
   Tillmann, Hans
   Thompson, Alexander
   Shire, Norah
   Hendrickson, Ron
   Dieguez, Francisco
   Goldman, Phyllis
   Schwarz, Kathleen
   Patel, Keyur
   McHutchison, John
   Moseley, M. Arthur
TI Metaprotein expression modeling for label-free quantitative proteomics
SO BMC BIOINFORMATICS
AB Background: Label-free quantitative proteomics holds a great deal of promise for the future study of both medicine and biology. However, the data generated is extremely intricate in its correlation structure, and its proper analysis is complex. There are issues with missing identifications. There are high levels of correlation between many, but not all, of the peptides derived from the same protein. Additionally, there may be systematic shifts in the sensitivity of the machine between experiments or even through time within the duration of a single experiment.
   Results: We describe a hierarchical model for analyzing unbiased, label-free proteomics data which utilizes the covariance of peptide expression across samples as well as MS/MS-based identifications to group peptides-a strategy we call metaprotein expression modeling. Our metaprotein model acknowledges the possibility of misidentifications, post-translational modifications and systematic differences between samples due to changes in instrument sensitivity or differences in total protein concentration. In addition, our approach allows us to validate findings from unbiased, label-free proteomics experiments with further unbiased, label-free proteomics experiments. Finally, we demonstrate the clinical/translational utility of the model for building predictors capable of differentiating biological phenotypes as well as for validating those findings in the context of three novel cohorts of patients with Hepatitis C.
   Conclusions: Mass-spectrometry proteomics is quickly becoming a powerful tool for studying biological and translational questions. Making use of all of the information contained in a particular set of data will be critical to the success of those endeavors. Our proposed model represents an advance in the ability of statistical models of proteomic data to identify and utilize correlation between features. This allows validation of predictors without translation to targeted assays in addition to informing the choice of targets when it is appropriate to generate those assays.
SN 1471-2105
PD MAY 4
PY 2012
VL 13
AR 74
DI 10.1186/1471-2105-13-74
UT WOS:000308469100001
PM 22559859
ER

PT J
AU Reddy, S
   Rogers, W
   Makinen, VP
   Coiera, E
   Brown, P
   Wenzel, M
   Weicken, E
   Ansari, S
   Mathur, P
   Casey, A
   Kelly, B
AF Reddy, Sandeep
   Rogers, Wendy
   Makinen, Ville-Petteri
   Coiera, Enrico
   Brown, Pieta
   Wenzel, Markus
   Weicken, Eva
   Ansari, Saba
   Mathur, Piyush
   Casey, Aaron
   Kelly, Blair
TI Evaluation framework to guide implementation of AI systems into
   healthcare settings
SO BMJ HEALTH & CARE INFORMATICS
AB Objectives To date, many artificial intelligence (AI) systems have been developed in healthcare, but adoption has been limited. This may be due to inappropriate or incomplete evaluation and a lack of internationally recognised AI standards on evaluation. To have confidence in the generalisability of AI systems in healthcare and to enable their integration into workflows, there is a need for a practical yet comprehensive instrument to assess the translational aspects of the available AI systems. Currently available evaluation frameworks for AI in healthcare focus on the reporting and regulatory aspects but have little guidance regarding assessment of the translational aspects of the AI systems like the functional, utility and ethical components. Methods To address this gap and create a framework that assesses real-world systems, an international team has developed a translationally focused evaluation framework termed 'Translational Evaluation of Healthcare AI (TEHAI)'. A critical review of literature assessed existing evaluation and reporting frameworks and gaps. Next, using health technology evaluation and translational principles, reporting components were identified for consideration. These were independently reviewed for consensus inclusion in a final framework by an international panel of eight expert. Results TEHAI includes three main components: capability, utility and adoption. The emphasis on translational and ethical features of the model development and deployment distinguishes TEHAI from other evaluation instruments. In specific, the evaluation components can be applied at any stage of the development and deployment of the AI system. Discussion One major limitation of existing reporting or evaluation frameworks is their narrow focus. TEHAI, because of its strong foundation in translation research models and an emphasis on safety, translational value and generalisability, not only has a theoretical basis but also practical application to assessing real-world systems. Conclusion The translational research theoretic approach used to develop TEHAI should see it having application not just for evaluation of clinical AI in research settings, but more broadly to guide evaluation of working clinical systems.
RI Kelly, Blair/P-6805-2018
OI Kelly, Blair/0000-0002-9306-8869; Coiera, Enrico/0000-0002-6444-6584;
   Rogers, Wendy/0000-0001-9186-870X; mathur, piyush/0000-0003-3777-8767;
   Casey, Aaron/0000-0003-3224-2162
EI 2632-1009
PD OCT
PY 2021
VL 28
IS 1
AR e100444
DI 10.1136/bmjhci-2021-100444
UT WOS:000708103500001
PM 34642177
ER

PT J
AU Maspero, M
   Bentvelzen, LG
   Savenije, MHF
   Guerreiro, F
   Seravalli, E
   Janssens, GO
   van den Berg, CAT
   Philippens, MEP
AF Maspero, Matteo
   Bentvelzen, Laura G.
   Savenije, Mark H. F.
   Guerreiro, Filipa
   Seravalli, Enrica
   Janssens, Geert O.
   van den Berg, Cornelis A. T.
   Philippens, Marielle E. P.
TI Deep learning-based synthetic CT generation for paediatric brain MR-only
   photon and proton radiotherapy
SO RADIOTHERAPY AND ONCOLOGY
AB Background and Purpose: To enable accurate magnetic resonance imaging (MRI)-based dose calculations, synthetic computed tomography (sCT) images need to be generated. We aim at assessing the feasibility of dose calculations from MRI acquired with a heterogeneous set of imaging protocol for paediatric patients affected by brain tumours.
   Materials and methods: Sixty paediatric patients undergoing brain radiotherapy were included. MR imaging protocols varied among patients, and data heterogeneity was maintained in train/validation/test sets. Three 2D conditional generative adversarial networks (cGANs) were trained to generate sCT from T1-weighted MRI, considering the three orthogonal planes and its combination (multi-plane sCT). For each patient, median and standard deviation (sigma) of the three views were calculated, obtaining a combined sCT and a proxy for uncertainty map, respectively. The sCTs were evaluated against the planning CT in terms of image similarity and accuracy for photon and proton dose calculations.
   Results: A mean absolute error of 61 +/- 14 HU (mean +/- 1 sigma) was obtained in the intersection of the body contours between CT and sCT. The combined multi-plane sCTs performed better than sCTs from any single plane. Uncertainty maps highlighted that multi-plane sCTs differed at the body contours and air cavities. A dose difference of -0.1 +/- 0.3% and 0.1 +/- 0.4% was obtained on the D > 90% of the prescribed dose and mean gamma(2%; 2 mm) pass-rate of 99.5 +/- 0.8% and 99.2 +/- 1.1% for photon and proton planning, respectively.
   Conclusion: Accurate MR-based dose calculation using a combination of three orthogonal planes for sCT generation is feasible for paediatric brain cancer patients, even when training on a heterogeneous dataset. (C) 2020 The Author(s). Published by Elsevier B.V.
RI Maspero, Matteo/C-1102-2016
OI Maspero, Matteo/0000-0003-0347-3375
SN 0167-8140
EI 1879-0887
PD DEC
PY 2020
VL 153
SI SI
BP 197
EP 204
DI 10.1016/j.radonc.2020.09.029
UT WOS:000600731700024
PM 32976877
ER

PT J
AU Jette, C
   Gutierrez, D
   Sastre, S
   Llusa, M
   Combalia, A
AF Jette, Cristian
   Gutierrez, David
   Sastre, Sergi
   Llusa, Manuel
   Combalia, Andres
TI Biomechanical comparison of anterolateral ligament anatomical
   reconstruction with a semi-anatomical lateral extra-articular tenodesis.
   A cadaveric study
SO KNEE
AB Background: To compare the biomechanical behavior of an anterolateral ligament (ALL) anatomical reconstruction and a semianatomical lateral extra-articular tenodesis (LET) in the context of an anterior cruciate ligament (ACL) reconstruction combined with an anterolateral lesion.
   Methods: Twelve cadaveric knees were studied using a testing machine to assess the internal tibial rotation and anterior tibial translation across six surgical states: intact knee, ACL lesion, ACL + ALL lesion, ACL isolated reconstruction, ACL + ALL anatomical reconstruction and ACL + LET procedure. ALL and LET grafts were fixed at full knee extension and neutral rotation.
   Results: Presented with combined ACL and ALL lesions, isolated ACL reconstruction failed to restore the internal tibial rotation to intact-knee values (P> 0.05 for all angles). The addition of both an ALL reconstruction and LET procedure significantly reduced the internal rotation, restoring the rotation laxity to intact-knee values at 0 degrees and 30 degrees of flexion (P < 0.05) and with a certain level of overconstraint at 60 degrees and 90 degrees (mean 3 degrees +/- 2SD). A higher tendency to overconstraint was observed with the LET, but there was no significant difference when comparing the ALL reconstruction with the LET (P > 0.05 for all angles).
   Conclusions: Residual rotational laxity was found after isolated ACL reconstruction in the presence of an anterolateral lesion. The combination of ACL reconstruction with anatomical ALL reconstruction or the LET procedure resulted in restoration to intact-knee values but with a certain degree of overconstraint in higher flexion angles. Both techniques showed optimal biomechanical results with no data supporting the advantage of one over the other. (C) 2019 Elsevier B.V. All rights reserved.
OI Jette, Cristian/0000-0003-1171-7464
SN 0968-0160
EI 1873-5800
PD OCT
PY 2019
VL 26
IS 5
BP 1003
EP 1009
DI 10.1016/j.knee.2019.07.005
UT WOS:000498286200007
PM 31427244
ER

PT J
AU Williams, HL
   Walsh, K
   Diamond, A
   Oniscu, A
   Deans, ZC
AF Williams, Hannah L.
   Walsh, Kathy
   Diamond, Austin
   Oniscu, Anca
   Deans, Zandra C.
TI Validation of the Oncomine((TM)) focus panel for next-generation
   sequencing of clinical tumour samples
SO VIRCHOWS ARCHIV
AB The clinical utility of next-generation sequencing (NGS) for a diverse range of targets is expanding, increasing the need for multiplexed analysis of both DNA and RNA. However, translation into daily use requires a rigorous and comprehensive validation strategy. The aim of this clinical validation was to assess the performance of the Ion Torrent Personal Genome Machine (IonPGM((TM))) and validate the Oncomine((TM)) Focus DNA and RNA Fusion panels for clinical application in solid tumour testing of formalin-fixed, paraffin-embedded (FFPE) tissue. Using a mixture of routine FFPE and reference material across a variety of tissue and specimen types, we sequenced 86 and 31 samples on the Oncomine((TM)) Focus DNA and RNA Fusion assays, respectively. This validation considered a number of parameters including the clinical robustness of the bioinformatics pipeline for variant detection and interpretation. The Oncomine((TM)) Focus DNA assay had a sample and variant-based sensitivity of 99.1 and 97.1%, respectively, and an assay specificity of 100%. The Oncomine((TM)) Focus Fusion panel had a good sensitivity and specificity based upon the samples assessed, however requires further validation to confirm findings due to limited sample numbers. We observed a good sequencing performance based upon amplicon, gene (hotspot variants within gene) and sample specific analysis with 92% of clinical samples obtaining an average amplicon coverage above 500X. Detection of some indels was challenging for the routine IonReporter((TM)) workflow; however, the addition of NextGENeA (R) software improved indel identification demonstrating the importance of both bench and bioinformatic validation. With an increasing number of clinically actionable targets requiring a variety of methodologies, NGS provides a cost-effective and time-saving methodology to assess multiple targets across different modalities. We suggest the use of multiple analysis software to ensure identification of clinically applicable variants.
OI Williams, Hannah/0000-0003-0434-3900
SN 0945-6317
EI 1432-2307
PD OCT
PY 2018
VL 473
IS 4
BP 489
EP 503
DI 10.1007/s00428-018-2411-4
UT WOS:000446380500011
PM 30105577
ER

PT C
AU Meisner, D
   Sadler, CM
   Barroso, LA
   Weber, WD
   Wenisch, TF
AF Meisner, David
   Sadler, Christopher M.
   Barroso, Luiz Andre
   Weber, Wolf-Dietrich
   Wenisch, Thomas F.
GP ACM SIGARCH
TI Power Management of Online Data-Intensive Services
SO ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON
   COMPUTER ARCHITECTURE
CT 38th Annual International Symposium on Computer Architecture
CY JUN 04-08, 2011
CL San Jose, CA
SP ACM SIGARCH, IEEE Computer Soc TCCA, Intel, Google, Microsoft, Oracle, Loongson, IBM, Cavium Networks, HP, VMware, ARM, AMD, Corensic, FusionIO
AB Much of the success of the Internet services model can be attributed to the popularity of a class of workloads that we call Online Data-Intensive (OLDI) services. These workloads perform significant computing over massive data sets per user request but, unlike their offline counterparts (such as MapReduce computations), they require responsiveness in the sub-second time scale at high request rates. Large search products, online advertising,. and machine translation are examples of workloads in this class. Although the load in OLDI services can vary widely during the day, their energy consumption sees little variance due to the lack of energy proportionality of the underlying machinery. The scale and latency sensitivity of OLDI workloads also make them a challenging target for power management techniques.
   We investigate what, if anything, can be done to make OLDI systems more energy-proportional. Specifically, we evaluate the applicability of active and idle low-power modes to reduce the power consumed by the primary server components (processor, memory, and disk), while maintaining tight response time constraints, particularly on 95th-percentile latency. Using Web search as a representative example of this workload class, we first characterize a production Web search workload at cluster-wide scale. We provide a fine-grain characterization and expose the opportunity for power savings using low-power modes of each primary server component. Second, we develop and validate a performance model to evaluate the impact of processor- and memory-based low-power modes on the search latency distribution and consider the benefit of current and foreseeable low-power modes. Our results highlight the challenges of power management for this class of workloads. In contrast to other server workloads, for which idle low-power modes have shown great promise, for OLDI workloads we find that energy-proportionality with acceptable query latency can only be achieved using coordinated, full-system active low-power modes.
BN 978-1-4503-0472-6
PY 2011
BP 319
EP 330
UT WOS:000292709800028
ER

PT C
AU Witus, G
   Hunt, S
   Ellis, RD
AF Witus, Gary
   Hunt, Shawn
   Ellis, R. Darin
BE Gerhart, GR
   Gage, DW
   Shoemaker, CM
TI Experiments in augmented teleoperation for mobile robots - I
SO UNMANNED SYSTEMS TECHNOLOGY IX
SE Proceedings of SPIE
CT Conference on Unmanned Systems Technology IX
CY APR 09-12, 2007
CL Orlando, FL
SP SPIE
AB Teleoperated mobile robots are beginning to be used for a variety of tasks that require movement in close quarters in the vicinity of moving and parked vehicles, buildings and other man-made structures, and the target object for inspection or manipulation. The robots must be close enough to deploy short-range sensors and manipulators, and must be able to maneuver without potentially damaging collisions. Teleoperation is fatiguing and stressful even without the requirement for close positioning. In cooperation with the TARDEC Robotic Mobility Laboratory (TRML), we are investigating approaches to reduce workload and improve performance through augmented teleoperation.
   Human-robot interfaces for teleoperation commonly provide two degrees-of-freedom (DoF) motion control with visual feedback from an on-board egocentric camera and no supplemental distance or orientation cueing. This paper reports on the results of preliminary experiments to assess the effects on man-machine task performance of several options for augmented teleoperation: (a) 3 DoF motion control (rotation and omni-directional translation) versus 2 DoF control (rotation and forward/reverse motion), (b) on-board egocentric camera versus fixed-position overwatch camera versus dual egocentric-and-overwatch cameras, and (c) presence or absence of distance and orientation visual cueing. We examined three dimensions of performance: completion time, spatial accuracy, and workspace area. We investigated effects on the expected completion time and on the variance in completion time. Spatial accuracy had three components: orientation, aimpoint, and distance. We collected performance under different task conditions: (a) three position-and-orientation tolerance or accuracy objectives, and (b) four travel distances between successive inspection points. We collected data from three subjects. We analyzed the main effects and conditional interaction effects among the teleoperation options and task conditions. We were able to draw some definitive conclusions regarding the relative performance of design alternatives, and conditions under which their performance degraded. We made some observations regarding operator behaviors, which suggested some potential augmented teleoperation enhancements.
OI Ellis, Richard/0000-0003-0435-8395
SN 0277-786X
BN 978-0-8194-6683-9
PY 2007
VL 6561
AR 65610R
DI 10.1117/12.720850
UT WOS:000248227700024
ER

PT J
AU Cimicata, G
   Fridkin, G
   Bose, T
   Eyal, Z
   Halfon, Y
   Breiner-Goldstein, E
   Fox, T
   Zimmerman, E
   Bashan, A
   de Val, N
   Wlodawer, A
   Yonath, A
AF Cimicata, Giuseppe
   Fridkin, Gil
   Bose, Tanaya
   Eyal, Zohar
   Halfon, Yehuda
   Breiner-Goldstein, Elinor
   Fox, Tara
   Zimmerman, Ella
   Bashan, Anat
   de Val, Natalia
   Wlodawer, Alexander
   Yonath, Ada
TI Structural Studies Reveal the Role of Helix 68 in the Elongation Step of
   Protein Biosynthesis
SO MBIO
AB The mechanism that regulates the translocation step in ribosomes during protein synthesis is not fully understood. In this work, cryo-EM techniques used to image ribosomes from Staphylococcus aureus after incubation at physiological temperature allowed the identification of a conformation of the helix 68 that has never been observed so far.
   The ribosome, a multicomponent assembly consisting of RNA and proteins, is a pivotal macromolecular machine that translates the genetic code into proteins. The large ribosomal subunit rRNA helix 68 (H68) is a key element in the protein synthesis process, as it coordinates the coupled movements of the actors involved in translocation, including the tRNAs and L1 stalk. Examination of cryo-electron microscopy (cryo-EM) structures of ribosomes incubated for various time durations at physiological temperatures led to the identification of functionally relevant H68 movements. These movements assist the transition of the L1 stalk between its open and closed states. H68 spatial flexibility and its significance to the protein synthesis process were confirmed through its effective targeting with antisense PNA oligomers. Our results suggest that H68 is actively involved in ribosome movements that are central to the elongation process. IMPORTANCE The mechanism that regulates the translocation step in ribosomes during protein synthesis is not fully understood. In this work, cryo-EM techniques used to image ribosomes from Staphylococcus aureus after incubation at physiological temperature allowed the identification of a conformation of the helix 68 that has never been observed so far. We then propose a mechanism in which such helix, switching between two different conformations, actively coordinates the translocation step, shedding light on the dynamics of ribosomal components. In addition, the relevance of helix 68 to ribosome function and its potential as an antibiotic target was proved by inhibiting Staphylococcus aureus ribosomes activity in vitro using oligomers with sequence complementarity.
OI bashan, Anat/0000-0002-7705-0466; Eyal, Zohar/0000-0002-8966-0624
SN 2150-7511
PD APR 26
PY 2022
VL 13
IS 2
AR e00306-22
DI 10.1128/mbio.00306-22
UT WOS:000788061200020
PM 35348349
ER

PT J
AU Esplen, N
   Mendonca, MS
   Bazalova-Carter, M
AF Esplen, Nolan
   Mendonca, Marc S.
   Bazalova-Carter, Magdalena
TI Physics and biology of ultrahigh dose-rate (FLASH) radiotherapy: a
   topical review
SO PHYSICS IN MEDICINE AND BIOLOGY
AB Ultrahigh dose-rate radiotherapy (RT), or 'FLASH' therapy, has gained significant momentum following various in vivo studies published since 2014 which have demonstrated a reduction in normal tissue toxicity and similar tumor control for FLASH-RT when compared with conventional dose-rate RT. Subsequent studies have sought to investigate the potential for FLASH normal tissue protection and the literature has been since been inundated with publications on FLASH therapies. Today, FLASH-RT is considered by some as having the potential to 'revolutionize radiotherapy'. FLASH-RT is considered by some as having the potential to 'revolutionize radiotherapy'.
   The goal of this review article is to present the current state of this intriguing RT technique and to review existing publications on FLASH-RT in terms of its physical and biological aspects. In the physics section, the current landscape of ultrahigh dose-rate radiation delivery and dosimetry is presented. Specifically, electron, photon and proton radiation sources capable of delivering ultrahigh dose-rates along with their beam delivery parameters are thoroughly discussed. Additionally, the benefits and drawbacks of radiation detectors suitable for dosimetry in FLASH-RT are presented. The biology section comprises a summary of pioneering in vitro ultrahigh dose-rate studies performed in the 1960s and early 1970s and continues with a summary of the recent literature investigating normal and tumor tissue responses in electron, photon and proton beams. The section is concluded with possible mechanistic explanations of the FLASH normal-tissue protection effect (FLASH effect). Finally, challenges associated with clinical translation of FLASH-RT and its future prospects are critically discussed; specifically, proposed treatment machines and publications on treatment planning for FLASH-RT are reviewed.
OI Esplen, Nolan/0000-0002-8347-8653
SN 0031-9155
EI 1361-6560
PD DEC 7
PY 2020
VL 65
IS 23
AR 23TR03
DI 10.1088/1361-6560/abaa28
UT WOS:000595999100001
PM 32721941
ER

PT C
AU Ashforth, SA
   Oosterbeek, RN
   Simpson, MC
AF Ashforth, Simon A.
   Oosterbeek, Reece N.
   Simpson, M. Cather
BE Heisterkamp, A
   Herman, PR
   Meunier, M
   Osellame, R
TI Ultrafast pulsed Bessel beams for enhanced laser ablation of bone tissue
   for applications in LASSOS
SO FRONTIERS IN ULTRAFAST OPTICS: BIOMEDICAL, SCIENTIFIC, AND INDUSTRIAL
   APPLICATIONS XVII
SE Proceedings of SPIE
CT Conference on Frontiers in Ultrafast Optics - Biomedical, Scientific,
   and Industrial Applications XVII
CY JAN 29-FEB 02, 2017
CL San Francisco, CA
SP SPIE, Amplitude Syst, APE GmbH, TRUMPF Inc
AB Using a femtosecond pulsed laser system (pulse width = 100fs, repetition rate = 1 kHz, lambda=800nm), a zero-order Bessel beam was generated using a LCOS-Spatial light modulator (LCOS-SLM) with an effective cone angle of 4.56 degrees. Ablation threshold studies of fresh bovine and ovine load bearing cortical bone was identified using the method of least damage and found to be identical at. phi(th) = 0.15 +/- 0.03 J cm(-2), irrespective of the target species. The ablation threshold is significantly reduced compared to the ablation threshold determined for Gaussian beams in bovine and ovine cortical bone (Load Bearing: phi(th) = 0.91 +/- 0.03 J cm(-2), Skull: phi(th) = 1.19 +/- 0.06 J cm(-2)). Incubation effects were investigated and the incubation coefficient was determined to be zeta= 0.93 +/- 0.06, indicating no incubation effects are present. The relationship between tissue removal and the number of pulses applied was explored. By altering the translation rate of the sample under the Bessel region of the incident laser, the number of pulses applied at each point along the linear ablation features was varied. Cross sections of ablation features were measured using scanning electron microscopy (SEM) and maximum depths of the ablation features measured. The ablation rate of bovine and ovine cortical was found to be 2.69 - 13.21 +/- 0.05 mu m pulse(-1) and 2.49 - 12.79 +/- 0.03 mu m pulse(-1) respectively for fluence values ranging from 2.5 - 25.0 Jcm(-2), significantly higher than those of Gaussian beams. Structural analysis of the ablation features using SEM and optical microscopy showed no signs of heat affected zone (HAZ) in the form of thermal shockwave cracking, molten debris deposition or charring of the tissue.
RI Oosterbeek, Reece/H-3226-2019
OI Oosterbeek, Reece/0000-0002-2412-4505
SN 0277-786X
EI 1996-756X
BN 978-1-5106-0629-6; 978-1-5106-0630-2
PY 2017
VL 10094
AR UNSP 100941O
DI 10.1117/12.2250068
UT WOS:000405592300040
ER

PT J
AU Yigzaw, N
   Meshesha, M
   Diriba, C
AF Yigzaw, Netsanet
   Meshesha, Million
   Diriba, Chala
TI A Generic Approach towards Amharic Sign Language Recognition
SO ADVANCES IN HUMAN-COMPUTER INTERACTION
AB In the day-to-day life of communities, good communication channels are crucial for mutual understanding. The hearing-impaired community uses sign language, which is a visual and gestural language. In terms of orientation and expression, it is separate from written and spoken languages. Despite the fact that sign language is an excellent platform for communication among hearing-impaired persons, it has created a communication barrier between hearing-impaired and non-disabled people. To address this issue, researchers have proposed sign language to text translation systems for English and other European languages as a solution. The goal of this research is to design and develop an Amharic digital text converter system using Ethiopian sign language. The proposed system was created with the help of two key deep learning algorithms: a pretrained deep learning model and a Long Short-Term Memory (LSTM). The LSTM was used to extract sequence information from a sequence of image frames of a specific sign language, while the pretrained deep learning model was used to extract features from single frame images. The dataset used to train the algorithms was gathered in video format from Addis Ababa University. Prior to feeding the obtained dataset to the deep learning models, data preprocessing activities such as cleaning and video to image frame segmentation were conducted. The system was trained, validated, and tested using 80%, 10%, and 10% of the 2475 images created during the preprocessing step. Two pretrained deep learning models, EfficientNetB0 and ResNet50, were used in this investigation, and they attained an accuracy of 72.79%. In terms of precision and f1-score, ResNet50 outperformed EfficientNetB0. For the proposed system, a graphical user interface prototype was created, and the best performing model was chosen and implemented. The proposed system can be utilized as a starting point for other researchers to improve upon, based on the outcomes of the experiment. More high-quality training datasets and high-performance training machines, such as GPU-enabled computers, can be added to the system to improve it.
RI Meshesha, Million/HGA-1142-2022
SN 1687-5893
EI 1687-5907
PD SEP 22
PY 2022
VL 2022
AR 1112169
DI 10.1155/2022/1112169
UT WOS:000863341700001
ER

PT J
AU Brew-Sam, N
   Parkinson, A
   Lueck, C
   Brown, E
   Brown, K
   Bruestle, A
   Chisholm, K
   Collins, S
   Cook, M
   Daskalaki, E
   Drew, J
   Ebbeck, H
   Elisha, M
   Fanning, V
   Henschke, A
   Herron, J
   Matthews, E
   Murugappan, K
   Neshev, D
   Nolan, CJ
   Pedley, L
   Phillips, C
   Suominen, H
   Tricoli, A
   Wright, K
   Desborough, J
AF Brew-Sam, Nicola
   Parkinson, Anne
   Lueck, Christian
   Brown, Ellen
   Brown, Karen
   Bruestle, Anne
   Chisholm, Katrina
   Collins, Simone
   Cook, Matthew
   Daskalaki, Eleni
   Drew, Janet
   Ebbeck, Harry
   Elisha, Mark
   Fanning, Vanessa
   Henschke, Adam
   Herron, Jessica
   Matthews, Emma
   Murugappan, Krishnan
   Neshev, Dragomir
   Nolan, Christopher J.
   Pedley, Lachlan
   Phillips, Christine
   Suominen, Hanna
   Tricoli, Antonio
   Wright, Kristine
   Desborough, Jane
TI The current understanding of precision medicine and personalised
   medicine in selected research disciplines: study protocol of a
   systematic concept analysis
SO BMJ OPEN
AB Introduction The terms 'precision medicine' and 'personalised medicine' have become key terms in health-related research and in science-related public communication. However, the application of these two concepts and their interpretation in various disciplines are heterogeneous, which also affects research translation and public awareness. This leads to confusion regarding the use and distinction of the two concepts. Our aim is to provide a snapshot of the current understanding of these concepts.
   Methods and analysis Our study will use Rodgers' evolutionary concept analysis to systematically examine the current understanding of the concepts 'precision medicine' and 'personalised medicine' in clinical medicine, biomedicine (incorporating genomics and bioinformatics), health services research, physics, chemistry, engineering, machine learning and artificial intelligence, and to identify their respective attributes (clusters of characteristics) and surrogate and related terms. A systematic search of the literature will be conducted for 2016-2022 using databases relevant to each of these disciplines: ACM Digital Library, CINAHL, Cochrane Library, F1000Research, IEEE Xplore, PubMed/Medline, Science Direct, Scopus and Web of Science. These are among the most representative databases for the included disciplines. We will examine similarities and differences in definitions of 'precision medicine' and 'personalised medicine' in the respective disciplines and across (sub)disciplines, including attributes of each term. This will enable us to determine how these two concepts are distinguished.
   Ethics and dissemination Following ethical and research standards, we will comprehensively report the methodology for a systematic analysis following Rodgers' concept analysis method. Our systematic concept analysis will contribute to the clarification of the two concepts and distinction in their application in given settings and circumstances. Such a broad concept analysis will contribute to non-systematic syntheses of the concepts, or occasional systematic reviews on one of the concepts that have been published in specific disciplines, in order to facilitate interdisciplinary communication, translational medical research and implementation science.
RI ; Lueck, Christian/O-4031-2016; Murugappan, Krishnan/O-9386-2019
OI Henschke, Adam/0000-0002-2956-0883; Lueck,
   Christian/0000-0003-1537-7612; Brown, Karen/0000-0002-3312-120X; Brown,
   Ellen/0000-0001-7924-4857; Murugappan, Krishnan/0000-0002-6845-4653;
   Parkinson, Anne/0000-0001-9053-0707; Cook, Matthew/0000-0002-3331-9363
SN 2044-6055
PD SEP
PY 2022
VL 12
IS 9
AR e060326
DI 10.1136/bmjopen-2021-060326
UT WOS:000952044200023
PM 36691172
ER

PT J
AU Srinivasan, A
   Sathiyanathan, P
   Yin, L
   Liu, TM
   Lam, A
   Ravikumar, M
   Smith, RAA
   Loh, HP
   Zhang, Y
   Ling, L
   Ng, SK
   Yang, YS
   Lezhava, A
   Hui, J
   Oh, S
   Cool, SM
AF Srinivasan, Akshaya
   Sathiyanathan, Padmapriya
   Yin, Lu
   Liu, Tong Ming
   Lam, Alan
   Ravikumar, Maanasa
   Smith, Raymond Alexander Alfred
   Loh, Han Ping
   Zhang, Ying
   Ling, Ling
   Ng, Say Kong
   Yang, Yuan Sheng
   Lezhava, Alexander
   Hui, James
   Oh, Steve
   Cool, Simon M.
TI Strategies to enhance immunomodulatory properties and reduce
   heterogeneity in mesenchymal stromal cells during ex vivo expansion
SO CYTOTHERAPY
AB Therapies using mesenchymal stromal cells (MSCs) to treat immune and inflammatory conditions are now at an exciting stage of development, with many MSC-based products progressing to phase II and III clinical trials. However, a major bottleneck in the clinical translation of allogeneic MSC therapies is the variable immunomodulatory properties of MSC products due to differences in their tissue source, donor heterogeneity and processes involved in manufacturing and banking. This variable functionality of MSC products likely contributes to the substantial inconsistency observed in the clinical outcomes of phase III trials of MSC therapies; several trials have failed to reach the primary efficacy endpoint. In this review, we discuss various strategies to consistently maintain or enhance the immunomodulatory potency of MSCs during ex vivo expansion, which will enable the manufacture of allogeneic MSC banks that have high potency and low variability. Biophysical and biochemical priming strategies, the use of culture additives such as heparan sulfates, and genetic modification can substantially enhance the immunomodulatory properties of MSCs during in vitro expansion. Furthermore, robust donor screening, the use of biomarkers to select for potent MSC subpopulations, and rigorous quality testing to improve the release criteria for MSC banks have the potential to reduce batch-to-batch heterogeneity and enhance the clinical efficacy of the final MSC product. Machine learning approaches to develop predictive models of individual patient response can enable personalized therapies and potentially establish correlations between in vitro potency measurements and clinical outcomes in human trials. (c) 2022 International Society for Cell & Gene Therapy. Published by Elsevier Inc. All rights reserved.
OI Smith, Raymond Alexander Alfred/0000-0002-0688-2193; Yin,
   Lu/0000-0002-3651-8608; Loh, Han Ping/0000-0003-1972-0190; Ravikumar,
   Maanasa/0000-0002-8755-6567; Liu, Tong Ming/0000-0002-9969-1694
SN 1465-3249
EI 1477-2566
PD MAY
PY 2022
VL 24
IS 5
BP 456
EP 472
DI 10.1016/j.jcyt.2021.11.009
EA APR 2022
UT WOS:000823485000002
PM 35227601
ER

PT J
AU Kapranov, Y
AF Kapranov, Yan
TI Logical-Philosophical Reinterpretation of Retrospective Nature of AI
   Technology in the Modern Globalized World
SO LOGOS-VILNIUS
AB The article presents a logical-philosophical reinterpretation of the retrospective nature of artificial intelligence technology in the modern globalized world through the prism of the disclosure of each individual link of the triad. The origin, formation, and further development of the notion of "intelligence" can be traced within the framework of the link "historical retrospective of the evolution and development of the notion of "intelligence", where we can talk about representatives of the genus Homo (from Homo Habilis, Homo Sapiens to Homo Sapiens Sapiens), whose thinking evolution took place due to the improvement of work tools at each separate stage. The link "philosophical conception of intelligence" made it possible to trace the difference between natural intelligence and artificial intelligence: if natural intelligence is connected with the spiritual world of a human being (Homo Sapiens), which is determined by its natural "substrate", then artificial intelligence is related to the study of the tasks of the human mind intelligent, which are completely separate and related to the creation of systems of "machine" text recognition, its translation into different languages. The link "modern logical-philosophical reinterpretation of the retrospective of artificial intelligence" is the process of transferring natural reality (neural networks of a human being (Homo Sapiens) to artificial reality (neural networks of an artificial human being (Artificial Homo Sapiens). In addition, an attempt was made to present a hypothetical methodological algorithm of artificial intelligence engineering, which consists of three stages: if the first stage is aimed at describing each component of the triad "brain - thinking / cognitive abilities / consciousness - intelligence", characteristic of Homo Sapiens, the second stage is aimed at analyzing the work of any robot for the presence of biological, semiotic and other systems in it, which are an imitation of "neural networks" and "mental models", then the third stage is to simulate weak and strong intelligence.
SN 0868-7692
PY 2022
IS 113
BP 35
EP 45
DI 10.24101/logos.2022.71
UT WOS:000912472100004
ER

PT J
AU Shultzaberger, RK
   Bucheimer, RE
   Rudd, KE
   Schneider, TD
AF Shultzaberger, RK
   Bucheimer, RE
   Rudd, KE
   Schneider, TD
TI Anatomy of Escherichia coli ribosome binding sites
SO JOURNAL OF MOLECULAR BIOLOGY
AB During translational initiation in prokaryotes, the 3' end of the 16S rRNA binds to a region just upstream of the initiation codon. The relationship between this Shine-Dalgarno (SD) region and the binding of ribosomes to translation start-points has been well studied, but a unified mathematical connection between the SD, the initiation codon and the spacing between them has been lacking. Using information theory, we constructed a model that treats these three components uniformly by assigning to the SD and the initiation region (IR) conservations in bits of information, and by assigning to the spacing an uncertainty, also in bits. To build the model, we first aligned the SD region by maximizing the information content there. The ease of this process confirmed the existence of the SD pattern within a set of 4122 reviewed and revised Escherichia coli gene starts. This large data set allowed us to show graphically, by sequence logos, that the spacing between the SD and the initiation region affects both the SD site conservation and its pattern. We used the aligned SD, the spacing, and the initiation region to model ribosome binding and to identify gene starts that do not conform to the ribosome binding site model. A total of 569 experimentally proven starts are more conserved (have higher information content) than the full set of revised starts, which probably reflects an experimental bias against the detection of gene products that have inefficient ribosome binding sites. Models were refined cyclically by removing non-conforming weak sites. After this procedure, models derived from either the original or the revised gene start annotation were similar. Therefore, this information theory-based technique provides a method for easily constructing biologically sensible ribosome binding site models. Such models should be useful for refining gene-start predictions of any sequenced bacterial genome. (C) 2001 Academic Press.
OI Cagnina, Rebecca/0000-0002-4210-7928; Schneider,
   Thomas/0000-0002-9841-1531
SN 0022-2836
EI 1089-8638
PD OCT 12
PY 2001
VL 313
IS 1
BP 215
EP 228
DI 10.1006/jmbi.2001.5040
UT WOS:000171816800016
PM 11601857
ER

PT S
AU Young, DI
   Staniforth, SM
   Hu, RW
AF Young, DI
   Staniforth, SM
   Hu, RW
BE Delp, S
   DiGioia, AM
   Jaramaz, B
TI Three-dimensional measurement of the femur using clinical ultrasound:
   Developing a basis for image guided intramedullary nail fixation of the
   femur
SO MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI 2000
SE Lecture Notes in Computer Science
CT 3rd International Conference on Medical Image Computing and
   Computer-Assisted Intervention
CY OCT 11-14, 2000
CL PITTSBURGH, PA
AB Purpose: Quantify the precision and accuracy in coordinate measurements of anatomic landmarks of the femur using spatially tracked ultrasound (US) images. Establish the limits on coordinate measurement errors required for accurate determination of bone fragment alignment during intramedullary (IM) nail fixation of femoral shift fractures. Relevance: A surgical guidance system based on a three-dimensional (3D) representation of femoral anatomy from US images would eliminate the hazard of radiation exposure and potentially increase the accuracy of IM nailing procedures. Summary: Fiducial spheres (dia. 6.3mm) were embedded in a plastic femur to mark anatomic landmarks. The femur was suspended in a water tank and could be rotated about its long axis. An US probe was mounted to a track above the femur. Images were collected at 5mm increments along the anterior, posterior, lateral and medial aspects. After the US experiment, fiducial centroid locations (x,y,z-coordinates) were measured in a coordinate measuring machine (CCM). Reconstructed fiducial positions from US images were compared to the CMM data to assess precision and accuracy. A numerical model relating errors in landmark coordinate measurements to rigid body alignment was implemented. The mean precision (std-dev.) in fiducial coordinate measurements was 1.69mm, Mean and maximum errors in fiducial positions were 17.65mm and 58.01mm, respectively. At the observed level of accuracy in coordinate measurements, the model predicted rigid body rotation errors of 3.4 (SD = 2.4)degrees and translation errors of 4.7 (SD = 3.2)mm. A proof-of-concept has been demonstrated in the use of clinical US to obtain a quantitative description of femoral anatomy in a 3D framework. The model of error limits provided a basis for assessing the capability of a tracked US system in the context of a clinical criterion for rotational alignment (anteversion angle). Accuracy requirements for landmark coordinate measurements were at the limits of the capability of the current US tracking system.
SN 0302-9743
BN 3-540-41189-5
PY 2000
VL 1935
BP 1220
EP 1228
UT WOS:000171938700131
ER

PT J
AU Schumann, W
   Homuth, G
   Mogk, A
AF Schumann, W
   Homuth, G
   Mogk, A
TI The GroE chaperonin machine is the major modulator of the CIRCE heat
   shock regulon of Bacillus subtilis
SO JOURNAL OF BIOSCIENCES
CT International Workshop on Molecular Biology of Stress Responses
CY OCT 14-17, 1997
CL BANARAS HINDU UNIV, VARANASI, INDIA
HO BANARAS HINDU UNIV
AB Regulation of the heat shock response in bacteria has been studied extensively in Escherichia coli where heat shock genes are classified into three classes and where each class is regulated by a different alternate sigma factor. Bacillus subtilis serves as a second model bacterium to study regulation of the heat shock response in detail. Here, four classes of heat shock genes have been described so far where two are controlled by two different repressor proteins and the third by the alternate sigma factor sigma(B). Class I heat shock genes consists of two operons, the heptacistronic dnaK and the bicistronic groE operon. Transcription of the dnaK operon is complex involving two promoters, premature termination of transcription, mRNA processing and different stabilities of the processed transcripts to ensure the appropriate amounts of heat shock proteins under different growth conditions. The translation product of the hrcA gene, the first gene of the dnaK operon, binds to an operator designated CIRCE element, and its activity is modulated by the GroE chaperonin system. We assume that the HrcA protein, upon de novo synthesis and upon dissociation from its operator, is present in an inactive form and has to be activated by the GroE chaperonin system resulting in an HrcA-GroE reaction cycle. Induction of class I heat shock genes occurs by the appearance of denatured proteins within the cytoplasm which titrate the GroE system. This results in accumulation of inactive HrcA repressor and thereby in induction of class I heat shock genes. Upon removal of the non-native proteins from the cytoplasm, the GroE chaperonin will interact with HrcA and promote folding into its active conformation resulting in turning off of class I heat shock genes. This mechanism ensures adequate adjustment of class I heat shock proteins depending on their actual need.
SN 0250-5991
PD OCT
PY 1998
VL 23
IS 4
BP 415
EP 422
DI 10.1007/BF02936135
UT WOS:000076725300015
ER

PT J
AU Almeida, CA
   Torres-Espin, A
   Huie, JR
   Sun, DM
   Noble-Haeusslein, LJ
   Young, W
   Beattie, MS
   Bresnahan, JC
   Nielson, JL
   Ferguson, AR
AF Almeida, Carlos A.
   Torres-Espin, Abel
   Huie, J. Russell
   Sun, Dongming
   Noble-Haeusslein, Linda J.
   Young, Wise
   Beattie, Michael S.
   Bresnahan, Jacqueline C.
   Nielson, Jessica L.
   Ferguson, Adam R.
TI Excavating FAIR Data: the Case of the Multicenter Animal Spinal Cord
   Injury Study (MASCIS), Blood Pressure, and Neuro-Recovery
SO NEUROINFORMATICS
AB Meta-analyses suggest that the published literature represents only a small minority of the total data collected in biomedical research, with most becoming 'dark data' unreported in the literature. Dark data is due to publication bias toward novel results that confirm investigator hypotheses and omission of data that do not. Publication bias contributes to scientific irreproducibility and failures in bench-to-bedside translation. Sharing dark data by making it Findable, Accessible, Interoperable, and Reusable (FAIR) may reduce the burden of irreproducible science by increasing transparency and support data-driven discoveries beyond the lifecycle of the original study. We illustrate feasibility of dark data sharing by recovering original raw data from the Multicenter Animal Spinal Cord Injury Study (MASCIS), an NIH-funded multi-site preclinical drug trial conducted in the 1990s that tested efficacy of several therapies after a spinal cord injury (SCI). The original drug treatments did not produce clear positive results and MASCIS data were stored in boxes for more than two decades. The goal of the present study was to independently confirm published machine learning findings that perioperative blood pressure is a major predictor of SCI neuromotor outcome (Nielson et al., 2015). We recovered, digitized, and curated the data from 1125 rats from MASCIS. Analyses indicated that high perioperative blood pressure at the time of SCI is associated with poorer health and worse neuromotor outcomes in more severe SCI, whereas low perioperative blood pressure is associated with poorer health and worse neuromotor outcome in moderate SCI. These findings confirm and expand prior results that a narrow window of blood-pressure control optimizes outcome, and demonstrate the value of recovering dark data for assessing reproducibility of findings with implications for precision therapeutic approaches.
RI Torres Espin, Abel/HGA-5068-2022; Torres-Espin, Abel/ABD-1354-2020
OI Torres-Espin, Abel/0000-0002-9787-8738; Ferguson,
   Adam/0000-0001-7102-1608; Noble-Haeusslein, Linda/0000-0002-2653-7047
SN 1539-2791
EI 1559-0089
PD JAN
PY 2022
VL 20
IS 1
BP 39
EP 52
DI 10.1007/s12021-021-09512-z
EA MAR 2021
UT WOS:000624392700001
PM 33651310
ER

PT J
AU Tavarageri, S
   Heinecke, A
   Avancha, S
   Kaul, B
   Goyal, G
   Upadrasta, R
AF Tavarageri, Sanket
   Heinecke, Alexander
   Avancha, Sasikanth
   Kaul, Bharat
   Goyal, Gagandeep
   Upadrasta, Ramakrishna
TI PoIyDL: Polyhedral Optimizations for Creation of High-performance DL
   Primitives
SO ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION
AB Deep Neural Networks (DNNs) have revolutionized many aspects of our lives. The use of DNNs is becoming ubiquitous, including in software for image recognition, speech recognition, speech synthesis, language translation, to name a few. The training of DNN architectures, however, is computationally expensive. Once the model is created, its use in the intended application-the inference task, is computationally heavy too and the inference needs to be fast for real time use. For obtaining high performance today, the code of Deep Learning (DL) primitives optimized for specific architectures by expert programmers exposed via libraries is the norm. However, given the constant emergence of new DNN architectures, creating hand optimized code is expensive, slow and is not scalable.
   To address this performance-productivity challenge, in this article we present compiler algorithms to automatically generate high-performance implementations of DL primitives that closely match the performance of hand optimized libraries. We develop novel data reuse analysis algorithms using the polyhedral model to derive efficient execution schedules automatically. In addition, because most DL primitives use some variant of matrix multiplication at their core, we develop a flexible framework where it is possible to plug in library implementations of the same in lieu of a subset of the loops. We show that such a hybrid compiler plus a minimal library-use approach results in state-of-the-art performance. We develop compiler algorithms to also perform operator fusions that reduce data movement through the memory hierarchy of the computer system. Using Convolution Neural Network (CNN) models and matrix multiplication operations, we demonstrate that our approach automatically creates high performing DNN building blocks whose performance matches the performance of hand-crafted kernels of Intel's oneDNN library on high end CPUs. At the same time, our techniques take only a fraction of time (1/20 or less) compared to AutoTVM, a deep learning auto-tuner to create optimized implementations.
SN 1544-3566
EI 1544-3973
PD JAN
PY 2021
VL 18
IS 1
AR 11
DI 10.1145/3433103
UT WOS:000612575500011
ER

PT J
AU Solis-Escalante, T
   de Kam, D
   Weerdesteyn, V
AF Solis-Escalante, Teodoro
   de Kam, Digna
   Weerdesteyn, Vivian
TI Classification of Rhythmic Cortical Activity Elicited by Whole-Body
   Balance Perturbations Suggests the Cortical Representation of
   Direction-Specific Changes in Postural Stability
SO IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING
AB Postural responses that effectively recover balance following unexpected postural changes need to be tailored to the characteristics of the postural change. We hypothesized that cortical dynamics involved in top-down regulation of postural responses carry information about directional postural changes (i.e., sway) imposed by sudden perturbations to standing balance (i.e., support surface translations). To test our hypothesis, we evaluated the single-trial classification of perturbation-induced directional changes in postural stability from high-density EEG. We analyzed EEG recordings from six young able-bodied individuals and three older individuals with chronic hemiparetic stroke, which were acquired while individuals reacted to low-intensity balance perturbations. Using common spatial patterns for feature extraction and linear discriminant analysis or support vector machines for classification, we achieved classification accuracies above random level (p < 0.05; cross-validated) for the classification of four different sway directions (one vs. the rest scheme). Screening of spectral features (3-50 Hz) revealed that the highest classification performance occurred when low-frequency (3-10 Hz) spectral features were used. Strikingly, the participant-specific classification results were qualitatively similar between young able-bodied individuals and older individuals with chronic hemiparetic stroke. Our findings demonstrate that low-frequency spectral components, corresponding to the cortical theta rhythm, carry direction-specific information about changes in postural stability. Our work presents a new perspective on the cortical representation of postural stability and the possible role of the theta rhythm in the modulation of (directional) reactive balance responses. Importantly, our work provides preliminary evidence that the cortical encoding of direction-specific changes in postural stability is present in chronic hemiparetic stroke.
RI de Kam, Digna/AAI-1945-2019; Weerdesteyn, Vivian/A-9599-2014;
   Solis-Escalante, Teodoro/H-5605-2016
OI de Kam, Digna/0000-0001-6383-0106; Weerdesteyn,
   Vivian/0000-0003-4327-7600; Solis-Escalante, Teodoro/0000-0003-1083-3658
SN 1534-4320
EI 1558-0210
PD NOV
PY 2020
VL 28
IS 11
BP 2566
EP 2574
DI 10.1109/TNSRE.2020.3028966
UT WOS:000589256200023
PM 33021931
ER

PT J
AU Jaffe-Dax, S
   Bermano, AH
   Erel, Y
   Emberson, LL
AF Jaffe-Dax, Sagi
   Bermano, Amit H.
   Erel, Yotam
   Emberson, Lauren L.
TI Video-based motion-resilient reconstruction of three-dimensional
   position for functional near-infrared spectroscopy and
   electroencephalography head mounted probes
SO NEUROPHOTONICS
AB Significance: We propose a video-based, motion-resilient, and fast method for estimating the position of optodes on the scalp.
   Aim: Measuring the exact placement of probes (e.g., electrodes and optodes) on a participant's head is a notoriously difficult step in acquiring neuroimaging data from methods that rely on scalp recordings (e.g., electroencephalography and functional near-infrared spectroscopy) and is particularly difficult for any clinical or developmental population. Existing methods of head measurements require the participant to remain still for a lengthy period of time, are laborious, and require extensive training. Therefore, a fast and motion-resilient method is required for estimating the scalp location of probes.
   Approach: We propose an innovative video-based method for estimating the probes' positions relative to the participant's head, which is fast, motion-resilient, and automatic. Our method builds on capitalizing the advantages and understanding the limitations of cutting-edge computer vision and machine learning tools. We validate our method on 10 adult subjects and provide proof of feasibility with infant subjects.
   Results: We show that our method is both reliable and valid compared to existing state-of-the-art methods by estimating probe positions in a single measurement and by tracking their translation and consistency across sessions. Finally, we show that our automatic method is able to estimate the position of probes on an infant head without lengthy offline procedures, a task that has been considered challenging until now.
   Conclusions: Our proposed method allows, for the first time, the use of automated spatial coregistration methods on developmental and clinical populations, where lengthy, motion-sensitive measurement methods routinely fail. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.
RI Bermano, Amit/GSD-9278-2022; Jaffe-Dax, Sagi/G-6360-2010
OI Erel, Yotam/0000-0001-8319-5111; Jaffe-Dax, Sagi/0000-0002-8759-6980
SN 2329-423X
EI 2329-4248
PD JUL-SEP
PY 2020
VL 7
IS 3
AR 035001
DI 10.1117/1.NPh.7.3.035001
UT WOS:000590145500003
PM 32704521
ER

PT J
AU Moore, JH
   Raghavachari, N
AF Moore, Jason H.
   Raghavachari, Nalini
CA Workshop Speakers
TI Artificial Intelligence Based Approaches to Identify Molecular
   Determinants of Exceptional Health and Life Span-An Interdisciplinary
   Workshop at the National Institute on Aging
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
AB Artificial intelligence (AI) has emerged as a powerful approach for integrated analysis of the rapidly growing volume of multi-omics data, including many research and clinical tasks such as prediction of disease risk and identification of potential therapeutic targets. However, the potential for AI to facilitate the identification of factors contributing to human exceptional health and life span and their translation into novel interventions for enhancing health and life span has not yet been realized. As researchers on aging acquire large scale data both in human cohorts and model organisms, emerging opportunities exist for the application of AI approaches to untangle the complex physiologic process(es) that modulate health and life span. It is expected that efficient and novel data mining tools that could unravel molecular mechanisms and causal pathways associated with exceptional health and life span could accelerate the discovery of novel therapeutics for healthy aging. Keeping this in mind, the National Institute on Aging (NIA) convened an interdisciplinary workshop titled "Contributions of Artificial Intelligence to Research on Determinants and Modulation of Health Span and Life Span" in August 2018. The workshop involved experts in the fields of aging, comparative biology, cardiology, cancer, and computational science/AI who brainstormed ideas on how AI can be leveraged for the analyses of large-scale data sets from human epidemiological studies and animal/model organisms to close the current knowledge gaps in processes that drive exceptional life and health span. This report summarizes the discussions and recommendations from the workshop on future application of AI approaches to advance our understanding of human health and life span.
EI 2624-8212
PY 2019
VL 2
AR 12
DI 10.3389/frai.2019.00012
UT WOS:000751670300012
PM 33733101
ER

PT J
AU Zumaraga, MP
   Medina, PJ
   Recto, JM
   Abrahan, L
   Azurin, E
   Tanchoco, CC
   Jimeno, CA
   Palmes-Saloma, C
AF Zumaraga, Mark Pretzel
   Medina, Paul Julius
   Recto, Juan Miguel
   Abrahan, Lauro
   Azurin, Edelyn
   Tanchoco, Celeste C.
   Jimeno, Cecilia A.
   Palmes-Saloma, Cynthia
TI Targeted next generation sequencing of the entire vitamin D receptor
   gene reveals polymorphisms correlated with vitamin D deficiency among
   older Filipino women with and without fragility fracture
SO JOURNAL OF NUTRITIONAL BIOCHEMISTRY
AB This study aimed to discover genetic variants in the entire 101 kB vitamin D receptor (VDR) gene for vitamin D deficiency in a group of postmenopausal Filipino women using targeted next generation sequencing (TNGS) approach in a case-control study design. A total of 50 women with and without osteoporotic fracture seen at the Philippine Orthopedic Center were included. Blood samples were collected for determination of serum vitamin D, calcium, phosphorus, glucose, blood urea nitrogen, creatinine, aspartate aminotransferase, alanine aminotransferase and as primary source for targeted VDR gene sequencing using the Ion Torrent Personal Genome Machine. The variant calling was based on the GATK best practice workflow and annotated using Annovar tool. A total of 1496 unique variants in the whole 101 -kb VDR gene were identified. Novel sequence variations not registered in the dbSNP database were found among cases and controls at a rate of 23.1% and 16.6% of total discovered variants, respectively. One disease-associated enhancer showed statistically significant association to low serum 25-hydroxy vitamin D levels (Pearson chi-square P-value=0.009). The transcription factor binding site prediction program PROMO predicted the disruption of three transcription factor binding sites in this enhancer region. These findings show the power of TNGS in identifying sequence variations in a very large gene and the surprising results obtained in this study greatly expand the catalog of known VDR sequence variants that may represent an important clue in the emergence of vitamin D deficiency. Such information will also provide the additional guidance necessary toward a personalized nutritional advice to reach sufficient vitamin D status. (C) 2016 Elsevier Inc. All rights reserved.
RI Jimeno, Cecilia Alegado/P-4702-2017
OI Jimeno, Cecilia Alegado/0000-0002-7658-0123; Zumaraga, Mark
   Pretzel/0000-0001-5598-8456
SN 0955-2863
EI 1873-4847
PD MAR
PY 2017
VL 41
BP 98
EP 108
DI 10.1016/j.jnutbio.2016.12.003
UT WOS:000394922700011
PM 28068558
ER

PT J
AU Abdel-Jaber, S
   Belvedere, C
   De Mattia, JS
   Leardini, A
   Affatato, S
AF Abdel-Jaber, Sami
   Belvedere, Claudio
   De Mattia, Jonathan Salvatore
   Leardini, Alberto
   Affatato, Saverio
TI A new protocol for wear testing of total knee prostheses from real joint
   kinematic data: Towards a scenario of realistic simulations of daily
   living activities
SO JOURNAL OF BIOMECHANICS
AB A new tendency in the field of wear testing of total knee replacements is represented by realistic simulations of various motor tasks of daily living (chair sitting and rising, squat, stair ascent, etc.). Various studies have shown in fact the limits of the ISO 14243 standards, in particular the concern about the ability of the level walking simulations to recreate the main wear mechanisms which occur on the knee implant during its in vivo lifespan. The recently proposed protocols for the simulation of these motor tasks still lack accuracy and consistency between the various degrees of freedom, which are necessary for a good replication of the mechanical behavior in a replaced knee. In the present study a realistic scenario for simulation of various motor tasks using a displacement controlled wear testing machine is presented. Stair climbing, chair sit/stand cycle, and squat cycle were analyzed through video-fluoroscopy in a population of knee replacement patients to extract flexion/extension and intra/extra rotation angles, together with anterior/posterior translation. Corresponding axial load data were arranged by gait analysis from a control population. The proposed protocol was tested on a displacement controlled wear simulator.
   Kinematic and load data revealed good consistency across subjects. The knee simulator showed an accurate reproduction of the various motion and load patterns, with average error lower than 5%. The obtained dataset for wear simulator, containing all the displacement and loading parameters for stair climbing, chair sit/stand and squat activities, is fully reported. (C) 2016 Elsevier Ltd. All rights reserved.
RI Belvedere, Claudio/S-6979-2019; Leardini, Alberto/C-8189-2019; Affatato,
   Saverio/N-5106-2019; Affatato, Saverio/C-6976-2019
OI Belvedere, Claudio/0000-0003-4258-2267; Leardini,
   Alberto/0000-0003-3547-7370; Affatato, Saverio/0000-0003-3615-6085;
   Affatato, Saverio/0000-0003-3615-6085
SN 0021-9290
EI 1873-2380
PD SEP 6
PY 2016
VL 49
IS 13
BP 2925
EP 2931
DI 10.1016/j.jbiomech.2016.07.003
UT WOS:000385472300048
PM 27451058
ER

PT J
AU Rompf, T
   Sujeeth, AK
   Brown, KJ
   Lee, H
   Chafi, H
   Olukotun, K
AF Rompf, Tiark
   Sujeeth, Arvind K.
   Brown, Kevin J.
   Lee, HyoukJoong
   Chafi, Hassan
   Olukotun, Kunle
TI Surgical Precision JIT Compilers
SO ACM SIGPLAN NOTICES
CT 35th ACM SIGPLAN Conference on Programming Language Design and
   Implementation (PLDI)
CY JUN 09-11, 2014
CL Edinburgh, SCOTLAND
SP Assoc Comp Machinery Special Interest Grp Programming Languages, NSF
AB Just-in-time (JIT) compilation of running programs provides more optimization opportunities than offline compilation. Modern JIT compilers, such as those in virtual machines like Oracle's HotSpot for Java or Google's V8 for JavaScript, rely on dynamic profiling as their key mechanism to guide optimizations. While these JIT compilers offer good average performance, their behavior is a black box and the achieved performance is highly unpredictable.
   In this paper, we propose to turn JIT compilation into a precision tool by adding two essential and generic metaprogramming facilities: First, allow programs to invoke JIT compilation explicitly. This enables controlled specialization of arbitrary code at run-time, in the style of partial evaluation. It also enables the JIT compiler to report warnings and errors to the program when it is unable to compile a code path in the demanded way. Second, allow the JIT compiler to call back into the program to perform compile-time computation. This lets the program itself define the translation strategy for certain constructs on the fly and gives rise to a powerful JIT macro facility that enables "smart" libraries to supply domain-specific compiler optimizations or safety checks.
   We present Lancet, a JIT compiler framework for Java bytecode that enables such a tight, two-way integration with the running program. Lancet itself was derived from a high-level Java bytecode interpreter: staging the interpreter using LMS (Lightweight Modular Staging) produced a simple bytecode compiler. Adding abstract interpretation turned the simple compiler into an optimizing compiler. This fact provides compelling evidence for the scalability of the staged-interpreter approach to compiler construction.
   In the case of Lancet, JIT macros also provide a natural interface to existing LMS-based toolchains such as the Delite parallelism and DSL framework, which can now serve as accelerator macros for arbitrary JVM bytecode.
OI Rompf, Tiark/0000-0002-2068-3238; Olukotun, Kunle/0000-0002-8779-0636
SN 0362-1340
EI 1558-1160
PD JUN
PY 2014
VL 49
IS 6
BP 41
EP 52
DI 10.1145/2666356.2594316
UT WOS:000344455800008
ER

PT J
AU Wang, M
   Dumas, GA
AF Wang, M
   Dumas, GA
TI Mechanical behavior of the female sacroiliac joint and influence of the
   anterior and posterior sacroiliac ligaments under sagittal loads
SO CLINICAL BIOMECHANICS
AB Objective. The purpose of this study was to examine the mechanical behaviour of the female sacroiliac joint and the effects of its two major ligaments to joint stability.
   Design. A cadaveric model was used to study the mechanical behaviour of the sacroiliac joints, and sequential dissection was performed to examine the contribution of the anterior and posterior sacroiliac ligaments in joint stability.
   Background. Instability of the sacroiliac joints have been suspected as a possible cause of low back pain. Despite several investigations on joint anatomy and joint mobility, its stabilising mechanism is still not dear.
   Methods. Four fresh cadaveric specimens of the female pelvis were tested on an Instron material testing machine. Eccentric compressive force of 60% of the subject's body weight was applied to the pelvis through the sacrum. Relative three-dimensional six-degree-of-freedom movement at the left sacroiliac joints was recorded with a specially designed motion tracking device. The device has an accuracy of 0.01 mm and is compact enough to be mounted across the joint. The test was repeated after sequential selective dissection of the bilateral anterior, and then posterior sacroiliac ligaments.
   Results. Rotation up to 1.2 degrees and translation up to 0.9 mm were measured from the intact specimens. Lateral rotation, which tended to open the top portion of the joint, and sacral nutation were the primary rotations. On average, the rotation angles increased 10% when either the anterior or posterior ligaments were cut, and 30% when both ligaments were cut.
   Conclusions. Lateral rotation and nutation rotation of the sacrum were found to be the predominant motion, though the values were limited to less than 1.2 degrees. Both the anterior and posterior sacroiliac ligaments were found to play an important role in resisting rotations at the joints.
SN 0268-0033
PD JUN-JUL
PY 1998
VL 13
IS 4-5
BP 293
EP 299
DI 10.1016/S0268-0033(98)00088-6
UT WOS:000074639700007
PM 11415799
ER

PT J
AU Hu, X
   Chen, QY
   Wang, HY
   Xia, X
   Lo, D
   Zimmermann, T
AF Hu, Xing
   Chen, Qiuyuan
   Wang, Haoye
   Xia, Xin
   Lo, David
   Zimmermann, Thomas
TI Correlating Automated and Human Evaluation of Code Documentation
   Generation Quality
SO ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY
AB Automatic code documentation generation has been a crucial task in the field of software engineering. It not only relieves developers fromwriting code documentation but also helps them to understand programs better. Specifically, deep-learning-based techniques that leverage large-scale source code corpora have been widely used in code documentation generation. These works tend to use automatic metrics (such as BLEU, METEOR, ROUGE, CIDEr, and SPICE) to evaluate different models. These metrics compare generated documentation to reference texts by measuring the overlapping words. Unfortunately, there is no evidence demonstrating the correlation between these metrics and human judgment. We conduct experiments on two popular code documentation generation tasks, code comment generation and commit message generation, to investigate the presence or absence of correlations between these metrics and human judgments. For each task, we replicate three state-of-the-art approaches and the generated documentation is evaluated automatically in terms of BLEU, METEOR, ROUGE-L, CIDEr, and SPICE. We also ask 24 participants to rate the generated documentation considering three aspects (i.e., language, content, and effectiveness). Each participant is given Java methods or commit diffs along with the target documentation to be rated. The results show that the ranking of generated documentation from automatic metrics is different from that evaluated by human annotators. Thus, these automatic metrics are not reliable enough to replace human evaluation for code documentation generation tasks. In addition, METEOR shows the strongest correlation (with moderate Pearson correlation r about 0.7) to human evaluation metrics. However, it is still much lower than the correlation observed between different annotators (with a high Pearson correlation r about 0.8) and correlations that are reported in the literature for other tasks (e.g., Neural Machine Translation [39]). Our study points to the need to develop specialized automated evaluation metrics that can correlate more closely to human evaluation metrics for code generation tasks.
RI ; Zimmermann, Thomas/C-4377-2019; Lo, David/A-2493-2012
OI Xia, Xin/0000-0002-6302-3256; Zimmermann, Thomas/0000-0003-4905-1469;
   Wang, Haoye/0000-0002-3314-0427; Lo, David/0000-0002-4367-7201
SN 1049-331X
EI 1557-7392
PD OCT
PY 2022
VL 31
IS 4
AR 63
DI 10.1145/3502853
UT WOS:000859387700007
ER

PT J
AU Oi, R
   Ohta, R
   Shiba, Y
   Sano, C
AF Oi, Remi
   Ohta, Ryuichi
   Shiba, Yukiko
   Sano, Chiaki
TI The Importance of "Easy Japanese": Communicating Health Information to
   Foreigners in Japan
SO CUREUS JOURNAL OF MEDICAL SCIENCE
AB The number of foreign workers in Japan has been increasing in recent years. In Shimane Prefecture, people from non-English speaking countries account for most of the foreign resident population. Language barriers pose numerous challenges for this population. Their problems communicating in the medical context, in particular, contribute to their avoidance of hospitals. In addition to translation machines and English, "Easy Japanese" has been found to help Japanese healthcare workers communicate with foreign patients. "Easy Japanese" refers to easy-to-understand Japanese that involves rephrasing words and sentences. The use of Easy Japanese should be promoted among medical professionals in Japan as it is considered a communication skill that can be improved through practice. A voluntary study group was formed among medical students. During the first session, students were presented with background information, explaining why the need for Easy Japanese is increasing. In the second session, they practiced paraphrasing words. Finally, in the third session, they conducted simulated medical communication and practiced Easy Japanese with foreign residents to determine whether they were able to convey their intentions. Participants were recruited via social networking service, with five participants in the first session, five in the second, and eight in the third. Through this project, it became clear that for participants, the usual way of speaking Japanese came first in practice and that it was difficult for them to produce easy-to-understand phrases at the spur of the moment without practice. Additionally, medical students reported that the expressions they acquired through several practice sessions were helpful when talking with international students on campus. The final session involved a student-led Easy Japanese study group. Based on the students' comments, we found that this study group was useful for them. Accordingly, Easy Japanese education should be continued and expanded to more students in the medical field and to the local community, including foreign residents, to measure its effectiveness.
EI 2168-8184
PD JUL 19
PY 2022
VL 14
IS 7
AR e27036
DI 10.7759/cureus.27036
UT WOS:000863298700037
PM 35989778
ER

PT J
AU Yu, HT
   Huang, DG
   Ren, FJ
   Li, LS
AF Yu, Hai-Tao
   Huang, Degen
   Ren, Fuji
   Li, Lishuang
TI Diagnostic Evaluation of Policy-Gradient-Based Ranking
SO ELECTRONICS
AB Learning-to-rank has been intensively studied and has shown significantly increasing values in a wide range of domains, such as web search, recommender systems, dialogue systems, machine translation, and even computational biology, to name a few. In light of recent advances in neural networks, there has been a strong and continuing interest in exploring how to deploy popular techniques, such as reinforcement learning and adversarial learning, to solve ranking problems. However, armed with the aforesaid popular techniques, most studies tend to show how effective a new method is. A comprehensive comparison between techniques and an in-depth analysis of their deficiencies are somehow overlooked. This paper is motivated by the observation that recent ranking methods based on either reinforcement learning or adversarial learning boil down to policy-gradient-based optimization. Based on the widely used benchmark collections with complete information (where relevance labels are known for all items), such as MSLRWEB30K and Yahoo-Set1, we thoroughly investigate the extent to which policy-gradient-based ranking methods are effective. On one hand, we analytically identify the pitfalls of policy-gradient-based ranking. On the other hand, we experimentally compare a wide range of representative methods. The experimental results echo our analysis and show that policy-gradient-based ranking methods are, by a large margin, inferior to many conventional ranking methods. Regardless of whether we use reinforcement learning or adversarial learning, the failures are largely attributable to the gradient estimation based on sampled rankings, which significantly diverge from ideal rankings. In particular, the larger the number of documents per query and the more fine-grained the ground-truth labels, the greater the impact policy-gradient-based ranking suffers. Careful examination of this weakness is highly recommended for developing enhanced methods based on policy gradient.
OI Ren, Fuji/0000-0003-4860-9184; Yu, Hai-Tao/0000-0002-1569-8507
EI 2079-9292
PD JAN
PY 2022
VL 11
IS 1
AR 37
DI 10.3390/electronics11010037
UT WOS:000752433000001
ER

PT J
AU Bratulic, S
   Gatto, F
   Nielsen, J
AF Bratulic, Sinisa
   Gatto, Francesco
   Nielsen, Jens
TI The Translational Status of Cancer Liquid Biopsies
SO REGENERATIVE ENGINEERING AND TRANSLATIONAL MEDICINE
AB Precision oncology aims to tailor clinical decisions specifically to patients with the objective of improving treatment outcomes. This can be achieved by leveraging omics information for accurate molecular characterization of tumors. Tumor tissue biopsies are currently the main source of information for molecular profiling. However, biopsies are invasive and limited in resolving spatiotemporal heterogeneity in tumor tissues. Alternative non-invasive liquid biopsies can exploit patient's body fluids to access multiple layers of tumor-specific biological information (genomes, epigenomes, transcriptomes, proteomes, metabolomes, circulating tumor cells, and exosomes). Analysis and integration of these large and diverse datasets using statistical and machine learning approaches can yield important insights into tumor biology and lead to discovery of new diagnostic, predictive, and prognostic biomarkers. Translation of these new diagnostic tools into standard clinical practice could transform oncology, as demonstrated by a number of liquid biopsy assays already entering clinical use. In this review, we highlight successes and challenges facing the rapidly evolving field of cancer biomarker research. Lay Summary Precision oncology aims to tailor clinical decisions specifically to patients with the objective of improving treatment outcomes. The discovery of biomarkers for precision oncology has been accelerated by high-throughput experimental and computational methods, which can inform fine-grained characterization of tumors for clinical decision-making. Moreover, advances in the liquid biopsy field allow non-invasive sampling of patient's body fluids with the aim of analyzing circulating biomarkers, obviating the need for invasive tumor tissue biopsies. In this review, we highlight successes and challenges facing the rapidly evolving field of liquid biopsy cancer biomarker research.
RI Gatto, Francesco/AAA-6682-2020
OI Gatto, Francesco/0000-0002-9031-9562; Bratulic,
   Sinisa/0000-0002-1663-2227
SN 2364-4133
EI 2364-4141
PD SEP
PY 2021
VL 7
IS 3
BP 312
EP 352
DI 10.1007/s40883-019-00141-2
UT WOS:000698957500006
ER

EF