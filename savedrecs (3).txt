FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Yuh, S
   Lee, K
   Seo, J
AF Yuh, Sanghwa
   Lee, Kongjoo
   Seo, Jungyun
TI Multilingual closed caption translation system for digital television
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
AB In this paper, we present a Korean to Chinese/English/ Japanese multilingual Machine Translation (MT) system of closed captions for Digital Television (DTV). Preliminary experiments, of our closed caption translation with existing base MT systems had shown unsatisfactory result. In order to achieve more accurate translation with the base MT systems, we adopted live resources of multilingual Named Entities and their translingual equivalences from the Web. We also utilize the program information, which the terrestrial broadcasters offer through DTV transport stream, in order to use program specific dictionaries, including the names of characters, locations and organizations. Two more components are adopted for reducing the ambiguities of parsing and word sense disambiguation; sentence simplification for long sentence segmentation and dynamic domain identification for automatic domain dictionary stacking. With these integrated approaches, we could raise the Mean Opinion Score (MOS) of translation accuracy by 0.40 higher than the base MT systems.
OI Lee, Kong Joo/0000-0003-0025-4230; Lee, Kong-Joo/0000-0001-7972-6020
SN 1745-1361
PD JUN
PY 2006
VL E89D
IS 6
BP 1885
EP 1892
DI 10.1093/ietisy/e89-d.6.1885
UT WOS:000238233300015
ER

PT J
AU Chauhan, S
   Daniel, P
   Mishra, A
   Kumar, A
AF Chauhan, Shweta
   Daniel, Philemon
   Mishra, Archita
   Kumar, Abhay
TI AdaBLEU: A Modified BLEU Score for Morphologically Rich Languages
SO IETE JOURNAL OF RESEARCH
AB Machine Translation (MT) depends upon the MT evaluation for comparing several MT systems and gives a measure of their efficiency in terms of translation sentences. Consequently, MT evaluation has become an integral part of the MT procedure and it has led to the development of several MT evaluation metrics which can automatically assess the MT systems. Lexical metrics like BLEU have been mostly used in MT evaluation. However, these metrics poorly represent lexical relationships and impose strict identity matching, leading to less correlation with human evaluation for morphologically rich languages. To overcome the limitations posed by the BLEU evaluation metric for morphologically rich languages, we propose a MT evaluation score called AdaBLEU that is a modified BLEU evaluation score. The proposed score considers the lexical and syntactical properties for any language including the morphologically rich languages. It considers the Parts-of-Speech tags and Dependency Parsing tags along with the BLEU score of sentences. Our modification to the BLEU score does not require multiple reference sentences for evaluation. The evaluation of the performance of AdaBLEU has been conducted by comparing our proposed metric's performance with several other evaluation metrices on different test datasets for different morphological languages. Experimental results show an improved performance in the case of the proposed score.
RI DANIEL, PHILEMON/ABG-2190-2021
OI Chauhan, Shweta/0000-0002-6598-1992
SN 0377-2063
EI 0974-780X
DI 10.1080/03772063.2021.1962745
EA AUG 2021
UT WOS:000687951700001
ER

PT C
AU Brour, M
   Benabbou, A
AF Brour, Mourad
   Benabbou, Abderrahim
BE Boumhidi, J
   Ghanou, Y
   Najah, S
   Nfaoui, E
   Oubenaalla, Y
   Zahi, A
   Zenkouar, K
TI ATLASLang MTS 1: Arabic Text Language into Arabic Sign Language Machine
   Translation System
SO SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING IN DATA
   SCIENCES (ICDS2018)
SE Procedia Computer Science
CT 2nd International Conference on Intelligent Computing in Data Sciences
   (ICDS)
CY OCT 03-05, 2018
CL Fez, MOROCCO
SP Sidi Mohamed Ben Abdellah Univ, Int Neural Network Soc Morocco Reg Chapter
AB Arabic Sign Language (ArSL) is a visual language used by deaf Arabs and some hard of hearing to translate their thinking It is a language in its own right as well as spoken languages such as Arabic or English. It is produced by body, face, and gestures of the hands. Hundreds of thousands of deaf people around the world currently practice it. Each country has its own sign language that deaf people use so it is not universal, but deaf people from different countries communicate easily with each other after a short period of adaptation. This communication becomes difficult when a deaf want to communicate with a normal person with no interpreter available. In this way, building a translation system that can generate real-time statements via a signing avatar is helpful. The system to be developed is a machine translation system from Arabic text to the Arabic sign language, it will allow hearing persons to communicate more easily, using a text written in Arabic by normal person, with people suffering from hard hearing and knowing only sign language. The system must perform a morpho-syntactic analysis of the text in the input and convert it to video sequences phrases playing by a 3D human avatar who expresses the usual signs used by deaf people. In this paper, we present a first version of our machine translation system ATLASLang MTS 1 based on rule-based Interlingua and example-based approaches. It uses SAFAR Platform [11] and ALKHALIL morpho system [1] to extract the morphological properties of each word of the input sentence. Then it generates a video sequence representing the sentence in Arabic sign language based on well-established translation rules and the database of signs. During the translation, if a word of sentence is a proper noun or does not have a correspondence in the database, it will be finger spelled. The main constraint imposed by our machine translation system is the assumption that the sentence given in the input must be completely vowelized. (C) 2019 The Authors. Published by Elsevier B. V.
OI Benabbou, Abderrahim/0000-0003-3968-836X
SN 1877-0509
PY 2019
VL 148
BP 236
EP 245
DI 10.1016/j.procs.2019.01.066
UT WOS:000470962900027
ER

PT J
AU Ma, WT
   Yan, B
   Sun, LY
AF Ma, Wenting
   Yan, Bing
   Sun, Lianyue
TI Generative Adversarial Network-Based Short Sequence Machine Translation
   from Chinese to English
SO SCIENTIFIC PROGRAMMING
AB With the acceleration of economic globalization, the economic contact, information exchange, and financial integration between countries become more and more frequent. In this context, the communication between different languages is also closer, so accurate translation between languages is of great significance. However, existing methods give little thought to short sequence machine translation from Chinese to English. This paper designs a generative adversarial network to solve the above problem. First, a conditional sequence generating adversarial net is constructed, which includes two adversarial submodels: a generator and a discriminator. The generator is designed to generate sentences that are difficult to distinguish from human-translated sentences, and the discriminator is designed to distinguish the sentences generated by the generator from human-translated sentences. In addition, static sentence-level BLEU values will be used as reinforcement targets for the generator. During training, both dynamic discriminators and static BLEU targets are used to evaluate the generated sentences, and the evaluation results are fed back to the generator to guide the generator's learning. Finally, experimental results on English-Chinese translation dataset show that the translation effect is improved by more than 8% compared with the traditional neural machine translation model based on recurrent neural network (RNN) after the introduction of generative adversative network.
SN 1058-9244
EI 1875-919X
PD JAN 28
PY 2022
VL 2022
AR 7700467
DI 10.1155/2022/7700467
UT WOS:000796356200008
ER

PT C
AU Wang, DX
   Fan, K
   Chen, BX
   Xiong, DY
AF Wang, Dexin
   Fan, Kai
   Chen, Boxing
   Xiong, Deyi
GP Assoc Computat Linguist
TI Efficient Cluster-Based k-Nearest-Neighbor Machine Translation
SO PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS)
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB k-Nearest-Neighbor Machine Translation (kNN-MT) has been recently proposed as a non-parametric solution for domain adaptation in neural machine translation (NMT). It aims to alleviate the performance degradation of advanced MT systems in translating out-ofdomain sentences by coordinating with an additional token-level feature-based retrieval module constructed from in-domain data. Previous studies (Khandelwal et al., 2021; Zheng et al., 2021a) have already demonstrated that non-parametric NMT is even superior to models fine-tuned on out-of-domain data. In spite of this success, kNN retrieval is at the expense of high latency, in particular for large datastores. To make it practical, in this paper, we explore a more efficient kNN-MT and propose to use clustering to improve the retrieval efficiency. Concretely, we first propose a cluster-based Compact Network for feature reduction in a contrastive learning manner to compress context features into 90+% lower dimensional vectors. We then suggest a cluster-based pruning solution to filter out 10%-40% redundant nodes in large datastores while retaining translation quality. Our proposed methods achieve better or comparable performance while reducing up to 57% inference latency against the advanced non-parametric MT model on several machine translation benchmarks. Experimental results indicate that the proposed methods maintain the most useful information of the original datastore and the Compact Network shows good generalization on unseen domains.
BN 978-1-955917-21-6
PY 2022
BP 2175
EP 2187
UT WOS:000828702302021
ER

PT C
AU Huang, XC
   Zhang, JC
   Tan, ZX
   Wong, DR
   Luan, HB
   Xu, JF
   Sun, MS
   Liu, Y
AF Huang, Xuancheng
   Zhang, Jiacheng
   Tan, Zhixing
   Wong, Derek F.
   Luan, Huanbo
   Xu, Jingfang
   Sun, Maosong
   Liu, Yang
BE Bessiere, C
TI Modeling Voting for System Combination in Machine Translation
SO PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON
   ARTIFICIAL INTELLIGENCE
CT 29th International Joint Conference on Artificial Intelligence
CY JAN 07-15, 2021
CL ELECTR NETWORK
SP Int Joint Conf Artifical Intelligence
AB System combination is an important technique for combining the hypotheses of different machine translation systems to improve translation performance. Although early statistical approaches to system combination have been proven effective in analyzing the consensus between hypotheses, they suffer from the error propagation problem due to the use of pipelines. While this problem has been alleviated by end-to-end training of multi-source sequence-to-sequence models recently, these neural models do not explicitly analyze the relations between hypotheses and fail to capture their agreement because the attention to a word in a hypothesis is calculated independently, ignoring the fact that the word might occur in multiple hypotheses. In this work, we propose an approach to modeling voting for system combination in machine translation. The basic idea is to enable words in hypotheses from different systems to vote on words that are representative and should get involved in the generation process. This can be done by quantifying the influence of each voter and its preference for each candidate. Our approach combines the advantages of statistical and neural methods since it can not only analyze the relations between hypotheses but also allow for end-to-end training Experiments show that our approach is capable of better taking advantage of the consensus between hypotheses and achieves significant improvements over state-of-the-art baselines on Chinese-English and English-German machine translation tasks.(1)
RI Wong, Derek F/CAI-7740-2022
BN 978-0-9992411-6-5
PY 2020
BP 3694
EP 3701
UT WOS:000764196703115
ER

PT C
AU Feng, Y
   Xie, WY
   Gu, SH
   Shao, CZ
   Zhang, W
   Yang, ZX
   Yu, D
AF Feng, Yang
   Xie, Wanying
   Gu, Shuhao
   Shao, Chenze
   Zhang, Wen
   Yang, Zhengxin
   Yu, Dong
GP Assoc Advancement Artificial Intelligence
TI Modeling Fluency and Faithfulness for Diverse Neural Machine Translation
SO THIRTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THE
   THIRTY-SECOND INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE
   CONFERENCE AND THE TENTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN
   ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 34th AAAI Conference on Artificial Intelligence / 32nd Innovative
   Applications of Artificial Intelligence Conference / 10th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 07-12, 2020
CL New York, NY
SP Assoc Advancement Artificial Intelligence
AB Neural machine translation models usually adopt the teacher forcing strategy for training which requires the predicted sequence matches ground truth word by word and forces the probability of each prediction to approach a 0-1 distribution. However, the strategy casts all the portion of the distribution to the ground truth word and ignores other words in the target vocabulary even when the ground truth word cannot dominate the distribution. To address the problem of teacher forcing, we propose a method to introduce an evaluation module to guide the distribution of the prediction. The evaluation module accesses each prediction from the perspectives of fluency and faithfulness to encourage the model to generate the word which has a fluent connection with its past and future translation and meanwhile tends to form a translation equivalent in meaning to the source. The experiments on multiple translation tasks show that our method can achieve significant improvements over strong baselines.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-835-0
PY 2020
VL 34
BP 59
EP 66
UT WOS:000667722800007
ER

PT J
AU Pessoles, X
   Landon, Y
   Segonds, S
   Rubio, W
AF Pessoles, Xavier
   Landon, Yann
   Segonds, Stephane
   Rubio, Walter
TI Optimisation of workpiece setup for continuous five-axis milling:
   application to a five-axis BC type machining centre
SO INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY
AB When machining complex geometries on five-axis machining centres, the orientation and positioning of the workpiece in the machine workspace are generally chosen arbitrarily by the operator from the Computer-Aided Manufacturing software. Nevertheless, these two factors have considerable influence on the machining time. The present article firstly studies the choice of workpiece orientation. Relying on analysis of the machine's kinematic behaviour, orientations of the workpiece in the machine workspace are proposed minimising the overall distance travelled by the rotary axes. Secondly, choice of workpiece positioning in translation is studied. To this purpose, the work volume in five-axis machining is identified so as to avoid overshooting the machine travels when the program is executed. The optimum positioning is chosen to minimise the overall distance covered by the machine's axes of translation. Finally, the proposed method provides for a workpiece setup to be adopted that minimises the distances covered by the machine axes. This leads to reduced machining time with concomitant gains in productivity and greater respect for the cutter/workpiece relative feed rate for enhanced quality.
OI Rubio, Walter/0000-0003-1123-8164
SN 0268-3768
PD MAR
PY 2013
VL 65
IS 1-4
BP 67
EP 79
DI 10.1007/s00170-012-4151-y
UT WOS:000315389300007
ER

PT J
AU Bhatnagar, S
   Chatterjee, N
AF Bhatnagar, Sahil
   Chatterjee, Niladri
TI Neural machine translation of Hindi and English
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
AB Translation has been one of the oldest problems in natural language processing. Despite its age, it is still one where there is a tremendous scope for improvement and creativity; the quantity and quality of research in it is testament to that fact. The subfield of primarily using deep neural networks for translation has recently started to gain traction. Many techniques have been developed using deep encoder-decoder networks for bilingual translation using both parallel as well as non-parallel corpora. There is a lot of potential in applying concepts such as bilingual embeddings to create generic translation architecture, which doesn't need huge parallel corpora to train. These ideas are particularly pertinent in the case of Indic languages, where it is generally difficult to obtain such corpus. In this paper, we try to adapt some of newest techniques in autoencoder networks and bilingual embeddings to the task of translating between English and Hindi. The models considerably outperform state of the art translating systems for these languages.
SN 1064-1246
EI 1875-8967
PY 2020
VL 39
IS 2
BP 2071
EP 2079
DI 10.3233/JIFS-179873
UT WOS:000568501000008
ER

PT J
AU Marie, B
   Fujita, A
AF Marie, Benjamin
   Fujita, Atsushi
TI Synthesizing Parallel Data of User-Generated Texts with Zero-Shot Neural
   Machine Translation
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
AB Neural machine translation (NMT) systems are usually trained on clean parallel data. They can perform very well for translating clean in-domain texts. However, as demonstrated by previous work, the translation quality significantly worsens when translating noisy texts, such as user-generated texts (UGT) from online social media. Given the lack of parallel data of UGT that can be used to train or adapt NMT systems, we synthesize parallel data of UGT, exploiting monolingual data of UGT through crosslingual language model pre-training and zero-shot NMT systems. This paper presents two different but complementary approaches: One alters given clean parallel data into UGT-like parallel data whereas the other generates translations from monolingual data of UGT. On the MTNT translation tasks, we show that our synthesized parallel data can lead to better NMT systems for UGT while making them more robust in translating texts from various domains and styles.
EI 2307-387X
PY 2020
VL 8
BP 710
EP 725
DI 10.1162/tacl_a_00341
UT WOS:000736531900046
ER

PT C
AU Gu, JT
   Wang, Y
   Cho, K
   Li, VOK
AF Gu, Jiatao
   Wang, Yong
   Cho, Kyunghyun
   Li, Victor O. K.
GP AAAI
TI Search Engine Guided Neural Machine Translation
SO THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 32nd AAAI Conference on Artificial Intelligence / 30th Innovative
   Applications of Artificial Intelligence Conference / 8th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 02-07, 2018
CL New Orleans, LA
SP AAAI
AB In this paper, we extend an attention-based neural machine translation (NMT) model by allowing it to access an entire training set of parallel sentence pairs even after training The proposed approach consists of two stages. In the first stage-retrieval stage, an off-the-shelf, black-box search engine is used to retrieve a small subset of sentence pairs from a training set given a source sentence. These pairs are further filtered based on a fuzzy matching score based on edit distance. In the second stage translation stage, a novel translation model, called search engine guided NMT (SEG-NMT), seamlessly uses both the source sentence and a set of retrieved sentence pairs to perform the translation. Empirical evaluation on three language pairs (En-Fr, En-De, and En-Es) shows that the proposed approach significantly outperforms the baseline approach and the improvement is more significant when more relevant sentence pairs were retrieved.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-800-8
PY 2018
BP 5133
EP 5140
UT WOS:000485488905028
ER

PT J
AU Liu, YP
   Zhang, YN
   Zhang, XC
AF Liu, Yupeng
   Zhang, Yanan
   Zhang, Xiaochen
TI Neural Translation System of Meta-Domain Transfer Based on Self-Ensemble
   and Self-Distillation
SO AUTOMATIC CONTROL AND COMPUTER SCIENCES
AB In order to address the shortcoming that feature representation limitation in machine translation (MT) system, this paper presents a transfer method for features in MT. Its main aim is to solve knowledge transfer of different training corpus in the decoding process. In this paper, the meta domain is modeled. A model agnostic self-ensemble and self-distillation training framework is proposed. The training is divided into model training and meta training to better adapt to the two types of features. In this paper, we have done extensive experiments on the classical neural machine translation system, and the model is compared with the classical methods. The experimental results show that the proposed model has improved in the transfer task of different domains and systems. In this paper, translation knowledge transfer is carried out on the Chinese-English translation dataset in the subdivided domain, which has a significant performance improvement in the news, education and law domain.
SN 0146-4116
EI 1558-108X
PD APR
PY 2022
VL 56
IS 2
BP 109
EP 119
DI 10.3103/S0146411622020109
UT WOS:000797518900002
ER

PT C
AU Jungnickel, R
   Pomp, A
   Kirmse, A
   Li, X
   Samsonov, V
   Meisen, T
AF Jungnickel, Robert
   Pomp, Andre
   Kirmse, Andreas
   Li, Xiang
   Samsonov, Vladimir
   Meisen, Tobias
GP IEEE
TI Evaluation and Comparison of Cross-lingual Text Processing Pipelines
SO 2019 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI
   2019)
CT IEEE Symposium Series on Computational Intelligence (SSCI)
CY DEC 06-09, 2019
CL Xiamen, PEOPLES R CHINA
SP IEEE, IEEE Computat Intelligence Soc, Xiamen Univ, Xi AN Univ Posts & Telecommunicat, Fujian Assoc Artificial Intelligence
AB With the trend of globalization and digitalization, many transnational companies are continuously collecting and storing unstructured text data in different languages. To exploit the business value of such high-volume multilingual text data, cross-lingual information extraction utilizes machine translation and other natural language processing (NLP) techniques to analyze this data. However, results of these analysis heavily depend on the order in which the tasks are performed as well as the used machine translation and NLP approaches or trained models. In this paper, we defined and evaluated a series of cross-lingual text processing pipelines for English and Chinese language. We therefore combine multiple commercial machine translation services with different automatic keyphrase extraction and named entity recognition techniques and evaluate their performance with regards to the order of execution. Hence, we evaluate the combination of machine translation systems and natural language processing techniques with two processing sequences in our experiment. One is to translate the document before extracting keyphrase and named entities. The other is to translate the processing results. The experiment outcomes indicate that translating documents is a better choice than the other way around in both tasks. However, there exists a sub-stantial disparity between the performance of the cross-lingual text processing pipelines and the corresponding monolingual references.
RI Meisen, Tobias/AAD-8010-2019
OI Meisen, Tobias/0000-0002-1969-559X; Jungnickel,
   Robert/0000-0002-9102-722X; Samsonov, Vladimir/0000-0003-4147-6470
BN 978-1-7281-2485-8
PY 2019
BP 417
EP 425
UT WOS:000555467200060
ER

PT C
AU Gu, JT
   Wang, Y
   Cho, K
   Li, VOK
AF Gu, Jiatao
   Wang, Yong
   Cho, Kyunghyun
   Li, Victor O. K.
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Improved Zero-shot Neural Machine Translation via Ignoring Spurious
   Correlations
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB Zero-shot translation, translating between language pairs on which a Neural Machine Translation (NMT) system has never been trained, is an emergent property when training the system in multilingual settings. However, naive training for zero-shot NMT easily fails, and is sensitive to hyper-parameter setting. The performance typically lags far behind the more conventional pivot-based approach which translates twice using a third language as a pivot. In this work, we address the degeneracy problem due to capturing spurious correlations by quantitatively analyzing the mutual information between language IDs of the source and decoded sentences. Inspired by this analysis, we propose to use two simple but effective approaches: (1) decoder pre-training; (2) back-translation. These methods show significant improvement (4 similar to 22 BLEU points) over the vanilla zero-shot translation on three challenging multilingual datasets, and achieve similar or better results than the pivot-based approach.
BN 978-1-950737-48-2
PY 2019
BP 1258
EP 1268
UT WOS:000493046102025
ER

PT C
AU Yang, KH
   Chen, WD
   Lee, HM
   Ho, JM
AF Yang, Kai-Hsiang
   Chen, Wei-Da
   Lee, Hahn-Ming
   Ho, Jan-Ming
GP IEEE Comp Soc
TI Mining translations of Chinese names from web corpora using a query
   expansion technique and Support Vector Machine
SO PROCEEDING OF THE 2007 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB
   INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY, WORKSHOPS
CT IEEE/WIC/ACM International Conference on Intelligent Agent Technology
   and Web Intelligence
CY NOV 02-05, 2007
CL Fremont, CA
SP IEEE Comp Soc TCII, Web Intelligence Consortium, AMC SIGART
AB Chinese name translation is a special case of the problem of named entity translation. It is a very challenging problem because there exist many kinds of Romanization systems and some people like to add additional words into their English names. Translating a scholar's name to its corresponding English name could help find information about his academic achievements. In this paper, we provide a classification for Chinese names, and propose a novel approach to mining Chinese name translations from Web corpora. Our approach is based on three kinds of features, namely the phonetic similarity, the smallest distance, and the number of appearances in the neighborhood, to extract name translation candidates by using a query expansion technique and Support Vector Machine (SVM). Experimental results show that our approach can correctly translate the majority of Chinese names.
BN 978-0-7695-3028-4
PY 2007
BP 530
EP +
DI 10.1109/WI-IATW.2007.64
UT WOS:000253308500118
ER

PT C
AU Ermakova, L
   Miller, T
   Regattin, F
   Bosser, AG
   Borg, C
   Mathurin, E
   Le Corre, G
   Araujo, S
   Hannachi, R
   Boccou, J
   Digue, A
   Damoy, A
   Jeanjean, B
AF Ermakova, Liana
   Miller, Tristan
   Regattin, Fabio
   Bosser, Anne-Gwenn
   Borg, Claudine
   Mathurin, Elise
   Le Corre, Gaelle
   Araujo, Silvia
   Hannachi, Radia
   Boccou, Julien
   Digue, Albin
   Damoy, Aurianne
   Jeanjean, Benoit
BE Barron-Cedeno, A
   DaSanMartino, G
   Esposti, MD
   Sebastiani, F
   Macdonald, C
   Pasi, G
   Hanbury, A
   Potthast, M
   Faggioli, G
   Ferro, N
TI Overview of JOKER@CLEF 2022: Automatic Wordplay and Humour Translation
   Workshop
SO EXPERIMENTAL IR MEETS MULTILINGUALITY, MULTIMODALITY, AND INTERACTION
   (CLEF 2022)
SE Lecture Notes in Computer Science
CT 13th International Conference of the CLEF-Association (CLEF) -
   Experimental IR meets Multilinguality, Multimodality, and Interaction
CY SEP 05-08, 2022
CL Univ Bologna, Bologna, ITALY
SP Conf & Labs Evaluat Forum Assoc
HO Univ Bologna
AB While humour and wordplay are among the most intensively studied problems in the field of translation studies, they have been almost completely ignored in machine translation. This is partly because most AI-based translation tools require a quality and quantity of training data (e.g., parallel corpora) that has historically been lacking for humour and wordplay. The goal of the JOKER@CLEF 2022 workshop was to bring together translators and computer scientists to work on an evaluation framework for wordplay, including data and metric development, and to foster work on automatic methods for wordplay translation. To this end, we defined three pilot tasks: (1) classify and explain instances of wordplay, (2) translate single terms containing wordplay, and (3) translate entire phrases containing wordplay (punning jokes). This paper describes and discusses each of these pilot tasks, as well as the participating systems and their results.
RI ; Ermakova, Liana/N-4386-2018
OI Miller, Tristan/0000-0002-0749-1100; REGATTIN,
   FABIO/0000-0003-3000-3360; Ermakova, Liana/0000-0002-7598-7474; Araujo,
   Silvia/0000-0003-4321-4511
SN 0302-9743
EI 1611-3349
BN 978-3-031-13643-6; 978-3-031-13642-9
PY 2022
VL 13390
BP 447
EP 469
DI 10.1007/978-3-031-13643-6_27
UT WOS:000870333000027
ER

PT C
AU Pan, X
   Wang, MX
   Wu, LW
   Li, L
AF Pan, Xiao
   Wang, Mingxuan
   Wu, Liwei
   Li, Lei
GP Assoc Computat Linguist
TI Contrastive Learning for Many-to-many Multilingual Neural Machine
   Translation
SO 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND
   THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING,
   VOL 1 (ACL-IJCNLP 2021)
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB Existing multilingual machine translation approaches mainly focus on English-centric directions, while the non-English directions still lag behind. In this work, we aim to build a many-to-many translation system with an emphasis on the quality of non-English language directions. Our intuition is based on the hypothesis that a universal cross-language representation leads to better multilingual translation performance. To this end, we propose mRASP2, a training method to obtain a single unified multilingual translation model. mRASP2 is empowered by two techniques: a) a contrastive learning scheme to close the gap among representations of different languages, and b) data augmentation on both multiple parallel and monolingual data to further align token representations. For English-centric directions, mRASP2 outperforms existing best unified model and achieves competitive or even better performance than the pre-trained and fine-tuned model mBART on tens of WMT's translation directions. For non-English directions, mRASP2 achieves an improvement of average 10+ BLEU compared with the multilingual Transformer baseline.
OI Li, Lei/0000-0003-3095-9776
BN 978-1-954085-52-7
PY 2021
BP 244
EP 258
UT WOS:000698663100021
ER

PT C
AU Fomincheva, M
   Specia, L
   Guzman, F
AF Fomincheva, Marina
   Specia, Lucia
   Guzman, Francisco
GP Assoc Computat Linguist
TI Multi-Hypothesis Machine Translation Evaluation
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB Reliably evaluating Machine Translation (MT) through automated metrics is a long-standing problem. One of the main challenges is the fact that multiple outputs can be equally valid. Attempts to minimise this issue include metrics that relax the matching of MT output and reference strings, and the use of multiple references. The latter has been shown to significantly improve the performance of evaluation metrics. However, collecting multiple references is expensive and in practice a single reference is generally used. In this paper, we propose an alternative approach: instead of modelling linguistic variation in human reference we exploit the MT model uncertainty to generate multiple diverse translations and use these: (i) as surrogates to reference translations; (ii) to obtain a quantification of translation variability to either complement existing metric scores or (iii) replace references altogether. We show that for a number of popular evaluation metrics our variability estimates lead to substantial improvements in correlation with human judgements of quality by up 15%.
BN 978-1-952148-25-5
PY 2020
BP 1218
EP 1232
UT WOS:000570978201048
ER

PT J
AU Dewangan, S
   Alva, S
   Joshi, N
   Bhattacharyya, P
AF Dewangan, Shubham
   Alva, Shreya
   Joshi, Nitish
   Bhattacharyya, Pushpak
TI Experience of neural machine translation between Indian languages
SO MACHINE TRANSLATION
AB In this paper we explore neural machine translation (NMT) for Indian languages. Reported work on Indian language Statistical Machine Translation (SMT) demonstrated good performance within the Indo-Aryan family, but relatively poor performance within the Dravidian family as well as between the two families. Interestingly, by common observation NMT generates more fluent output than SMT. This led us to investigate NMT's potential for translation involving Indian languages. The current practice in NMT is to train the models with subword units. Among subwording methods, byte pair encoding (BPE) is a popular choice. We conduct extensive experiments with BPE-based NMT models for Indian languages. An interesting outcome of our study is the finding that the optimal value for BPE merge for Indian language pairs seems to be falling in the range of 0-5000 which is fairly low compared to that observed for European Languages. Additionally, we apply other techniques such as phrase table injection and linguistic feature based enhancements on corpora, plus BERT augmented NMT to boost performance. To the best of our knowledge, this is the first comprehensive study on Indian language NMT (ILNMT) covering major languages in India. As an empirical paper, we expect this work could serve as a benchmark for ILNMT research.
OI Dewangan, Shubham/0000-0003-4834-9829
SN 0922-6567
EI 1573-0573
PD APR
PY 2021
VL 35
IS 1
SI SI
BP 71
EP 99
DI 10.1007/s10590-021-09263-3
EA MAY 2021
UT WOS:000646937300001
ER

PT J
AU Tezcan, A
   Hoste, V
   Macken, L
AF Tezcan, Arda
   Hoste, Veronique
   Macken, Lieve
TI Estimating word-level quality of statistical machine translation output
   using monolingual information alone
SO NATURAL LANGUAGE ENGINEERING
AB Various studies show that statistical machine translation (SMT) systems suffer from fluency errors, especially in the form of grammatical errors and errors related to idiomatic word choices. In this study, we investigate the effectiveness of using monolingual information contained in the machine-translated text to estimate word-level quality of SMT output. We propose a recurrent neural network architecture which uses morpho-syntactic features and word embeddings as word representations within surface and syntactic n-grams. We test the proposed method on two language pairs and for two tasks, namely detecting fluency errors and predicting overall post-editing effort. Our results show that this method is effective for capturing all types of fluency errors at once. Moreover, on the task of predicting post-editing effort, while solely relying on monolingual information, it achieves on-par results with the state-of-the-art quality estimation systems which use both bilingual and monolingual information.
OI Macken, Lieve/0000-0001-7516-7487
SN 1351-3249
EI 1469-8110
PD JAN
PY 2020
VL 26
IS 1
BP 73
EP 94
AR PII S1351324919000111
DI 10.1017/S1351324919000111
UT WOS:000504566700005
ER

PT C
AU Eriguchi, A
   Xie, SF
   Qin, T
   Awadalla, HH
AF Eriguchi, Akiko
   Xie, Shufang
   Qin, Tao
   Awadalla, Hany Hassan
GP ASSOC COMPUTAT LINGUIST
TI Building Multilingual Machine Translation Systems That Serve Arbitrary
   X-Y Translations
SO NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE
   ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES
CT Conference of the
   North-American-Chapter-of-the-Association-for-Computational-Linguistics
   (NAAACL) - Human Language Technologies
CY JUL 10-15, 2022
CL Seattle, WA
SP Assoc Computat Linguist, N Amer Chapter, Amazon Sci, Bloomberg Engn, Google Res, LivepersoMetan, ByteDance, KENSH, Grammarly, Megagon Labs, Microsoft, Reveal Brainspace, Cohere, GResearch, Relativity, Servicenow, ASAPP, Duolingo, Adobe, Linkedin, Babelscape, Rakuten Inst Technol, UC Santa Cruz, Baskin Engn, Nat Language Proc, NSF, ETS, OpenAI, TIAA, Two Sigma, Mag Data
AB Multilingual Neural Machine Translation (MNMT) enables one system to translate sentences from multiple source languages to multiple target languages, greatly reducing deployment costs compared with conventional bilingual systems. The MNMT training benefit, however, is often limited to many-to-one directions. The model suffers from poor performance in one-to-many and many-to-many with zero-shot setup. To address this issue, this paper discusses how to practically build MNMT systems that serve arbitrary X-Y translation directions while leveraging multilinguality with a two-stage training strategy of pretraining and finetuning. Experimenting with the WMT'21 multilingual translation task, we demonstrate that our systems outperform the conventional baselines of direct bilingual models and pivot translation models for most directions, averagely giving +6.0 and +4.1 BLEU, without the need for architecture change or extra data collection. Moreover, we also examine our proposed approach in an extremely large-scale data setting to accommodate practical deployment scenarios.
BN 978-1-955917-71-1
PY 2022
BP 600
EP 606
UT WOS:000859869500044
ER

PT C
AU Song, KT
   Tan, X
   Lu, JF
AF Song, Kaitao
   Tan, Xu
   Lu, Jianfeng
BE Bessiere, C
TI Neural Machine Translation with Error Correction
SO PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON
   ARTIFICIAL INTELLIGENCE
CT 29th International Joint Conference on Artificial Intelligence
CY JAN 07-15, 2021
CL ELECTR NETWORK
SP Int Joint Conf Artifical Intelligence
AB Neural machine translation (NMT) generates the next target token given as input the previous ground truth target tokens during training while the previous generated target tokens during inference, which causes discrepancy between training and inference as well as error propagation, and affects the translation accuracy. In this paper, we introduce an error correction mechanism into NMT, which corrects the error information in the previous generated tokens to better predict the next token. Specifically, we introduce two-stream self-attention from XLNet into NMT decoder, where the query stream is used to predict the next token, and meanwhile the content stream is used to correct the error information from the previous predicted tokens. We leverage scheduled sampling to simulate the prediction errors during training. Experiments on three IWSLT translation datasets and two WMT translation datasets demonstrate that our method achieves improvements over Transformer baseline and scheduled sampling. Further experimental analyses also verify the effectiveness of our proposed error correction mechanism to improve the translation quality.
BN 978-0-9992411-6-5
PY 2020
BP 3891
EP 3897
UT WOS:000764196704004
ER

PT C
AU Zhang, L
   Zhang, T
   Zhang, HB
   Yang, BS
   Ye, W
   Zhang, SK
AF Zhang, Long
   Zhang, Tong
   Zhang, Haibo
   Yang, Baosong
   Ye, Wei
   Zhang, Shikun
GP Assoc Computat Linguist
TI Multi-Hop Transformer for Document-Level Machine Translation
SO 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021)
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 06-11, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, N Amer Chapter, Google Res, Amazon Sci, Apple, Facebook AI, Megagon Labs, Microsoft, Bloomberg Engn, Grammarly, IBM, Vanguard, Duolingo, Babelscape, Human Language Technol, LegalForce
AB Document-level neural machine translation (NMT) has proven to be of profound value for its effectiveness on capturing contextual information. Nevertheless, existing approaches 1) simply introduce the representations of context sentences without explicitly characterizing the inter-sentence reasoning process; and 2) feed ground-truth target contexts as extra inputs at the training time, thus facing the problem of exposure bias. We approach these problems with an inspiration from human behavior - human translators ordinarily emerge a translation draft in their mind and progressively revise it according to the reasoning in discourse. To this end, we propose a novel Multi-Hop Transformer (MHT) which offers NMT abilities to explicitly model the human-like draft-editing and reasoning process. Specifically, our model serves the sentence-level translation as a draft and properly refines its representations by attending to multiple antecedent sentences iteratively. Experiments on four widely used document translation tasks demonstrate that our method can significantly improve documentlevel translation performance and can tackle discourse phenomena, such as coreference error and the problem of polysemy.
BN 978-1-954085-46-6
PY 2021
BP 3953
EP 3963
UT WOS:000895685604007
ER

PT C
AU Chen, JP
   Azogu, O
   Knudson, R
AF Chen, Jiangping
   Azogu, Olajumoke
   Knudson, Ryan
GP IEEE
TI Enabling Multilingual Information Access to Digital Collections: An
   Investigation of Metadata Records Translation
SO 2014 IEEE/ACM JOINT CONFERENCE ON DIGITAL LIBRARIES (JCDL)
SE ACM-IEEE Joint Conference on Digital Libraries JCDL
CT 14th IEEE/ACM Joint Conference on Digital Libraries (JCDL) / 18th
   International Conference on Theory and Practice of Digital Libraries
   (TPDL)
CY SEP 08-12, 2014
CL City Univ London, London, ENGLAND
SP IEEE, ACM
HO City Univ London
AB We conducted a research project exploring machine translation performance on digital metadata records. This short paper reports the background, research purposes, research design, experiments, and evaluation results.
SN 2575-7865
EI 2575-8152
BN 978-1-4799-5569-5
PY 2014
BP 467
EP 468
UT WOS:000383092300086
ER

PT C
AU Huang, S
   Hu, BJ
   Huang, S
   Hu, PF
   Kang, J
   Lv, ZQ
   Yan, JH
   Ju, Q
   Kang, SY
   Tuo, DY
   Li, GZ
   Yolwas, N
AF Huang, Shen
   Hu, Bojie
   Huang, Shan
   Hu, Pengfei
   Kang, Jian
   Lv, Zhiqiang
   Yan, Jinghao
   Ju, Qi
   Kang, Shiyin
   Tuo, Deyi
   Li, Guangzhi
   Yolwas, Nurmemet
GP Int Speech Commun Assoc
TI Multimedia Simultaneous Translation System for Minority Language
   Communication with Mandarin
SO INTERSPEECH 2019
SE Interspeech
CT Interspeech Conference
CY SEP 15-19, 2019
CL Graz, AUSTRIA
AB Speech recognition for minority language is always behind main stream due to lack of resources. This work presents a system for simultaneous translation between Mandarin and major minority languages such as Uyghur, Tibetan in shape of speech, text and images. The general acoustic model is trained via factorized TDNN with lattice free MMI criteria using mixed-units based lexicon model. For each specific language, acoustic model is trained by multi-task mix-lingual modeling with shared bottleneck layers followed by transfer learning. Besides, the system also supports state-of-the-art OCR, TTS, and machine translation, by which language information will be real-time translated, punctuated and pronounced. The machine translation behind the system gets a high rank in WMT 18 Mandarin-English and CWMT 18 minority language translation task. The system has integrated into a micro-app at WeChat and can facilitate communication between Mandarin and Minority languages.
SN 2308-457X
PY 2019
BP 4628
EP 4629
UT WOS:000831796404156
ER

PT J
AU Almagro, M
   Martinez, R
   Montalvo, S
   Fresno, V
AF Almagro, Mario
   Martinez, Raquel
   Montalvo, Soto
   Fresno, Victor
TI A cross-lingual approach to automatic ICD-10 coding of death
   certificates by exploring machine translation
SO JOURNAL OF BIOMEDICAL INFORMATICS
AB Automatic ICD-10 coding is an unresolved challenge in terms of Machine Learning tasks. Despite hospitals generating an enormous amount of clinical documents, data is considerably sparse, associated with a very skewed and unbalanced code distribution, what entails reduced interoperability. In addition, in some languages the availability of coded documents is very limited. This paper proposes a cross-lingual approach based on Machine Translation methods to code death certificates with ICD-10 using supervised learning. The aim of this approach is to increase the availability of coded documents by combining collections of different languages, which may also contribute to reduce their possible bias in the ICD distribution, i.e. to avoid the promotion of a subset of codes due to service or environmental factors. A significant improvement in system performance is achieved for those labels with few occurrences.
RI Montalvo, Soto/AAA-4546-2019
OI Montalvo, Soto/0000-0001-8158-7939; Fresno, Victor/0000-0003-4270-2628;
   Almagro, Mario/0000-0003-4339-2959
SN 1532-0464
EI 1532-0480
PD JUN
PY 2019
VL 94
AR 103207
DI 10.1016/j.jbi.2019.103207
UT WOS:000525692600002
PM 31077817
ER

PT C
AU Rikters, M
   Tomingas, M
   Tuisk, T
   Ernstreits, V
   Fishel, M
AF Rikters, Matiss
   Tomingas, Marili
   Tuisk, Tuuli
   Ernstreits, Valts
   Fishel, Mark
GP Assoc Computa Linguist
TI Machine Translation for Livonian: Catering to 20 Speakers
SO PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB Livonian is one of the most endangered languages in Europe with just a tiny handful of speakers and virtually no publicly available corpora. In this paper we tackle the task of developing neural machine translation (NMT) between Livonian and English, with a two-fold aim: on one hand, preserving the language and on the other - enabling access to Livonian folklore, lifestories and other textual intangible heritage as well as making it easier to create further parallel corpora. We rely on Livonian's linguistic similarity to Estonian and Latvian and collect parallel and monolingual data for the four languages for translation experiments. We combine different low-resource NMT techniques like zero-shot translation, cross-lingual transfer and synthetic data creation to reach the highest possible translation quality as well as to find which base languages are empirically more helpful for transfer to Livonian. The resulting NMT systems and the collected monolingual and parallel data, including a manually translated and verified translation benchmark, are publicly released via the OPUS corpora collection and Huggingface model repository.
BN 978-1-955917-22-3
PY 2022
BP 508
EP 514
UT WOS:000828732800055
ER

PT C
AU Escolano, C
   Costa-jussa, MR
   Fonollosa, JAR
   Segura, C
AF Escolano, Carlos
   Costa-jussa, Marta R.
   Fonollosa, Jose A. R.
   Segura, Carlos
GP IEEE
TI ENABLING ZERO-SHOT MULTILINGUAL SPOKEN LANGUAGE TRANSLATION WITH
   LANGUAGE-SPECIFIC ENCODERS AND DECODERS
SO 2021 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU)
CT IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)
CY DEC 13-17, 2021
CL ELECTR NETWORK
SP Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc
AB Current end-to-end approaches to Spoken Language Translation (SLT) rely on limited training resources, especially for multilingual settings. On the other hand, Multilingual Neural Machine Translation (MultiNMT) approaches rely on higher-quality and more massive data sets. Our proposed method extends a MultiNMT architecture based on language-specific encoders-decoders to the task of Multilingual SLT (MultiSLT). Our method entirely eliminates the dependency from MultiSLT data and it is able to translate while training only on ASR and MultiNMT data.
   Our experiments on four different languages show that coupling the speech encoder to the MultiNMT architecture produces similar quality translations compared to a bilingual baseline (+/- 0.2 BLEU) while effectively allowing for zero-shot MultiSLT. Additionally, we propose using an Adapter module for coupling the speech inputs. This Adapter module produces consistent improvements up to +6 BLEU points on the proposed architecture and +1 BLEU point on the end-toend baseline.
BN 978-1-6654-3739-4
PY 2021
BP 694
EP 701
DI 10.1109/ASRU51503.2021.9688026
UT WOS:000792364700092
ER

PT C
AU Li, LG
   Li, S
   Cui, WQ
   Wei, K
AF Li, Lin-gen
   Li, Shuo
   Cui, Wan-qing
   Wei, Kai
GP Destech Publicat Inc
TI Design and Implementation of Consecutive Interpreting System Based on
   Transformer NMT Model
SO 2018 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION AND NETWORK
   TECHNOLOGY (CCNT 2018)
SE DEStech Transactions on Computer Science and Engineering
CT International Conference on Computer, Communication and Network
   Technology (CCNT)
CY JUN 29-30, 2018
CL Wuzhen, PEOPLES R CHINA
AB The traditional machine translation system with push-to-talk mode is not suitable for the processing of long-time oral translation. This paper proposed a consecutive interpreting system, solving the problem of long-time continuous listening by using pipeline work mode. In this mode, audio sampling is always on during the whole speech. In usage scenarios, audiences of the speeches or lectures can see bilingual subtitles on the projection or on their own device, and this system will keep translating while listens to the speaker. The speech-to-text module is based on the speech recognition model of Baidu open platform, and the translation is based on the Transformer NMT model proposed by Google. The average translation delay time of our system is only about 0.8s in our delay test. This system can play the role of the interpreter in conferences or lectures where translation precision requirement is not high.
SN 2475-8841
BN 978-1-6059-5561-2
PY 2018
VL 291
BP 1
EP 8
UT WOS:000468601400001
ER

PT J
AU Guo, JL
   Zhang, ZR
   Xu, LL
   Chen, BX
   Chen, EH
AF Guo, Junliang
   Zhang, Zhirui
   Xu, Linli
   Chen, Boxing
   Chen, Enhong
TI Adaptive Adapters: An Efficient Way to Incorporate BERT Into Neural
   Machine Translation
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB Large-scale pre-trained language models (e.g., BERT) have attracted great attention in recent years. It is straightforward to fine-tune them on natural language understanding tasks such as text classification, however, effectively and efficiently incorporating them into natural language generation tasks such as neural machine translation remains a challenging problem. In this paper, we integrate two pre-trained BERT models from the source and target language domains into a sequence-to-sequence model by introducing light-weight adapter modules. The adapters are inserted between BERT layers and tuned on downstream tasks, while the parameters of BERT models are fixed during fine-tuning. As pre-trained language models are usually very deep, inserting adapters into all layers will result in a considerable scale of new parameters. To deal with this problem, we introduce latent variables to decide whether using adapters or not in each layer, which are learned during fine-tuning. In this way, the model is able to automatically determine which adapters to use, therefore hugely promoting the parameter efficiency and decoding speed. We evaluate the proposed framework on various neural machine translation tasks. Equipped with parallel sequence decoding, our model consistently outperforms autoregressive baselines while reducing the inference latency by half. With automatic adapter selection, the proposed model further achieves 20% speedup while still outperforming autoregressive baselines. When applied to autoregressive decoding, the proposed model can also achieve comparable performance with the state-of-the-art baseline models.
OI Guo, Junliang/0000-0001-8360-5483; Chen, Enhong/0000-0002-4835-4102;
   Chen, Boxing/0000-0002-3170-4858
SN 2329-9290
EI 2329-9304
PY 2021
VL 29
BP 1740
EP 1751
DI 10.1109/TASLP.2021.3076863
UT WOS:000658326800001
ER

PT J
AU Li, B
   Yao, JM
AF Li, Bin
   Yao, Jianmin
TI Selection of In-Domain Bilingual Sentence Pairs Based on Topic
   Information
SO SCIENTIFIC PROGRAMMING
AB The performance of a machine translation system (MTS) depends on the quality and size of the training data. How to extend the training dataset for the MTS in specific domains with effective methods to enhance the performance of machine translation needs to be explored. A method for selecting in-domain bilingual sentence pairs based on the topic information is proposed. With the aid of the topic relevance of the bilingual sentence pairs to the target domain, subsets of sentence pairs related to the texts to be translated are selected from a large-scale bilingual corpus to train the translation system in specific domains to improve the translation quality for in-domain texts. Through the test, the bilingual sentence pairs are selected by using the proposed method, and further the MTS is trained. In this way, the translation performance is greatly enhanced.
OI Li, Bin/0000-0001-8730-6325; Yao, Jianmin/0000-0003-4747-293X
SN 1058-9244
EI 1875-919X
PD DEC 15
PY 2020
VL 2020
AR 8879570
DI 10.1155/2020/8879570
UT WOS:000605343100001
ER

PT C
AU Zeng, JL
   Liu, Y
   Su, JS
   Ge, YB
   Lu, YJ
   Yin, YJ
   Luo, JB
AF Zeng, Jiali
   Liu, Yang
   Su, Jinsong
   Ge, Yubin
   Lu, Yaojie
   Yin, Yongjing
   Luo, Jiebo
GP Assoc Computat Linguist
TI Iterative Dual Domain Adaptation for Neural Machine Translation
SO 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND
   THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE
CT Conference on Empirical Methods in Natural Language Processing / 9th
   International Joint Conference on Natural Language Processing
   (EMNLP-IJCNLP)
CY NOV 03-07, 2019
CL Hong Kong, HONG KONG
SP Google, Facebook, Apple, ASAPP, Salesforce, Huawei, Baidu, Deepmind, Amazon, PolyAI, Naver, ByteDance, Megagon Labs, Zhuiyi, Verisk, MI
AB Previous studies on the domain adaptation for neural machine translation (NMT) mainly focus on the one-pass transferring out-of-domain translation knowledge to in-domain NMT model. In this paper, we argue that such a strategy fails to fully extract the domain-shared translation knowledge, and repeatedly utilizing corpora of different domains can lead to better distillation of domain-shared translation knowledge. To this end, we propose an iterative dual domain adaptation framework for NMT. Specifically, we first pretrain in-domain and out-of-domain NMT models using their own training corpora respectively, and then iteratively perform bidirectional translation knowledge transfer (from in-domain to out-of-domain and then vice versa) based on knowledge distillation until the in-domain NMT model convergences. Furthermore, we extend the proposed framework to the scenario of multiple out-of-domain training corpora, where the above-mentioned transfer is performed sequentially between the in-domain and each out-of-domain NMT models in the ascending order of their domain similarities. Empirical results on Chinese-English and English-German translation tasks demonstrate the effectiveness of our framework.
OI Luo, Jiebo/0000-0002-4516-9729
BN 978-1-950737-90-1
PY 2019
BP 845
EP 855
UT WOS:000854193300078
ER

PT C
AU Kartbayev, A
AF Kartbayev, Amandyk
BE Huynh, VN
   Inuiguchi, M
   Denoeux, T
TI Learning Word Alignment Models for Kazakh-English Machine Translation
SO INTEGRATED UNCERTAINTY IN KNOWLEDGE MODELLING AND DECISION MAKING, IUKM
   2015
SE Lecture Notes in Artificial Intelligence
CT 4th International Symposium on Integrated Uncertainty in Knowledge
   Modelling and Decision Making (IUKM)
CY OCT 15-17, 2015
CL Nha Trang, VIETNAM
SP Pacific Ocean Univ, VNU Hanoi Univ Engn & Technol, Hanoi Natl Univ Educ, Japan Adv Inst Sci & Technol, Natl Fdn Sci & Technol Dev Vietnam
AB In this paper, we address to the most essential challenges in the word alignment quality. Word alignment is a widely used phenomenon in the field of machine translation. However, a small research has been dedicated to the revealing of its discrete properties. This paper presents word segmentation, the probability distributions, and the statistical properties of word alignment in the transparent and a real life dataset. The result suggests that there is no single best method for alignment evaluation. For Kazakh-English pair we attempted to improve the phrase tables with the choice of alignment method, which need to be adapted to the requirements in the specific project. Experimental results show that the processed parallel data reduced word alignment error rate and achieved the highest BLEU improvement on the random parallel corpora.
RI Kartbayev, Amandyk/ABF-7490-2021
OI Kartbayev, Amandyk/0000-0003-0592-5865
SN 0302-9743
EI 1611-3349
BN 978-3-319-25135-6; 978-3-319-25134-9
PY 2015
VL 9376
BP 326
EP 335
DI 10.1007/978-3-319-25135-6_31
UT WOS:000367593500031
ER

PT J
AU Stapleton, P
   Kin, BLK
AF Stapleton, Paul
   Kin, Becky Leung Ka
TI Assessing the accuracy and teachers' impressions of Google Translate: A
   study of primary L2 writers in Hong Kong
SO ENGLISH FOR SPECIFIC PURPOSES
OI Stapleton, Paul/0000-0003-0733-7944
SN 0889-4906
EI 1873-1937
PD OCT
PY 2019
VL 56
BP 18
EP 34
DI 10.1016/j.esp.2019.07.001
UT WOS:000491614500003
ER

PT J
AU BELONOGOV, GG
   ZELENKOV, YA
   KUZNETSOV, BA
   NOVOSELOV, AP
   KHOROSHILOV, AA
   KHOROSHILOV, AA
AF BELONOGOV, GG
   ZELENKOV, YA
   KUZNETSOV, BA
   NOVOSELOV, AP
   KHOROSHILOV, AA
   KHOROSHILOV, AA
TI COMPUTERIZED COMPILATION AND PROCESSING OF DICTIONARIES FOR
   PHRASEOLOGICAL MACHINE TEXT TRANSLATION SYSTEMS FROM RUSSIAN TO ENGLISH
   AND FROM ENGLISH TO RUSSIAN
SO NAUCHNO-TEKHNICHESKAYA INFORMATSIYA SERIYA 2-INFORMATSIONNYE PROTSESSY I
   SISTEMY
SN 0548-0027
PY 1993
IS 12
BP 16
EP 21
UT WOS:A1993NL10100003
ER

PT C
AU Liu, SY
AF Liu, Siyou
GP IEEE
TI AN EMPIRICAL STUDY ON TASK-ORIENTED DIALOGUE TRANSLATION
SO 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP 2021)
CT IEEE International Conference on Acoustics, Speech and Signal Processing
   (ICASSP)
CY JUN 06-11, 2021
CL ELECTR NETWORK
SP IEEE, Inst Elect & Elect Engineers, Signal Proc Soc
AB Translating conversational text, in particular task-oriented dialogues, is an important application task for machine translation technology. However, it has so far not been extensively explored due to its inherent characteristics including data limitation, discourse, informality and personality. In this paper, we systematically investigate advanced models on the task-oriented dialogue translation task, including sentence-level, document-level and non-autoregressive NMT models. Besides, we explore existing techniques such as data selection, back/forward translation, larger batch learning, finetuning and domain adaptation. To alleviate low-resource problem, we transfer general knowledge from four different pre-training models to the downstream task. Encouragingly, we find that the best model with mBART pre-training pushes the SOTA performance on WMT20 English-German and IWSLT DIALOG Chinese-English datasets up to 62.67 and 23.21 BLEU points, respectively.(1)
BN 978-1-7281-7605-5
PY 2021
BP 7558
EP 7562
DI 10.1109/ICASSP39728.2021.9413521
UT WOS:000704288407167
ER

PT C
AU Geng, XW
   Feng, XC
   Qin, B
AF Geng, Xinwei
   Feng, Xiaocheng
   Qin, Bing
GP Assoc Computat Linguist
TI Learning to Rewrite for Non-Autoregressive Neural Machine Translation
SO 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2021)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 07-11, 2021
CL Punta Cana, DOMINICAN REP
AB Non-autoregressive neural machine translation, which decomposes the dependence on previous target tokens from the inputs of the decoder, has achieved impressive inference speedup but at the cost of inferior accuracy. Previous works employ iterative decoding to improve the translation by applying multiple refinement iterations. However, a serious drawback is that these approaches expose the serious weakness in recognizing the erroneous translation pieces. In this paper, we propose an architecture named REWRITENAT to explicitly learn to rewrite the erroneous translation pieces. Specifically, REWRITENAT utilizes a locator module to locate the erroneous ones, which are then revised into the correct ones by a revisor module. Towards keeping the consistency of data distribution with iterative decoding, an iterative training strategy is employed to further improve the capacity of rewriting. Extensive experiments conducted on several widely-used benchmarks show that REWRITENAT can achieve better performance while significantly reducing decoding time, compared with previous iterative decoding strategies. In particular, REWRITENAT can obtain competitive results with autoregressive translation on WMT14 En <-> De, En <-> Fr and WMT16 Ro -> En translation benchmarks(1).
BN 978-1-955917-09-4
PY 2021
BP 3297
EP 3308
UT WOS:000855966303037
ER

PT C
AU Zhao, L
   Li, F
AF Zhao, Li
   Li, Feng
BE Wang, J
   Zhao, C
   Wu, Y
   Liu, Q
TI Statistical Machine Learning in Natural Language Understanding: Object
   Constraint Language Translator for Business Process
SO 2008 IEEE INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING
   WORKSHOP PROCEEDINGS, VOLS 1 AND 2
CT International Symposium on Knowledge Acquisition and Modeling
CY DEC 21-22, 2008
CL Wuhan, PEOPLES R CHINA
SP IEEE Comp Soc, IEEE
AB Natural language is used to represent human thoughts and human actions. Business rules described by natural language are very hard for machine to understand. In order to let machine know the business rules, parts of business process, we need to translate them into a language which machine can understand. Object constraint language is one of those languages. In this paper we present a statistical machine learning method to understand the natural business rules and then translate them into object constraint language. Subsequently a translation algorithm for business process modeling is also provided. A real case, air cargo load planning process is proposed to illustrate the efficiency and effective of the method and the algorithm. The result has shown that this method and algorithm enrich business process modeling technology and enhance the efficiency of software developers, in business process modeling.
BN 978-1-4244-3529-6
PY 2008
BP 1056
EP +
DI 10.1109/KAMW.2008.4810674
UT WOS:000266694700272
ER

PT C
AU Gu, R
   Chen, M
   Yang, WJ
   Yuan, CF
   Huang, YH
AF Gu, Rong
   Chen, Min
   Yang, Wenjia
   Yuan, Chunfeng
   Huang, Yihua
GP IEEE
TI Seal: Efficient Training Large Scale Statistical Machine Translation
   Models on Spark
SO 2018 IEEE 24TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED
   SYSTEMS (ICPADS 2018)
SE International Conference on Parallel and Distributed Systems -
   Proceedings
CT 24th IEEE International Conference on Parallel and Distributed Systems
   (ICPADS)
CY DEC 11-13, 2018
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc
AB Statistical machine translation (SMT) is an important research branch in natural language processing (NLP). Similar to many other NLP applications, large scale training data can potentially bring higher translation accuracy for SMT models. However, the traditional single-node SMT model training systems can hardly cope with the fast-growing amount of large scale training corpus in the big data era, which makes the urgent requirement of efficient large scale machine translation model training systems. In this paper, we propose Seal, an efficient, scalable, and end-to-end offline SMT model training toolkit based on Apache Spark which is a widely-used distributed data-parallel platform. Seal parallelizes the training process of the entire three key SMT models that are the word alignment model, the translation model, and the N-Gram language model, respectively. To further improve the performance of the model training in Seal, we also propose a number of system optimization methods. In word alignment model training, by optimizing the block size tuning, the overhead of IO operation and communication is greatly reduced. In translation model training, by well encoding the training corpus, the data size transferred over the network can be reduced significantly, thus improving the overall training efficiency. We also optimize the maximum likelihood estimation (MLE) algorithm to solve the data skew issue on the join operation which is adopted both in the translation model training and the language model training. The experiment results show that Seal outperforms the well-known SMT training system Chaski with about 5x speedup for word alignment model training. For the syntactic translation model and language model training, Seal outperforms the existing cutting-edge tools with about 9 similar to 18x speedup and 8 similar to 9x speedup on average, respectively. On the whole, Seal outperforms the existing distributed system with 4 similar to 6x speedup and the single-node system with 9 similar to 60x speedup on average respectively. Besides, Seal achieves near-linear data and node scalability.
SN 1521-9097
BN 978-1-5386-7308-9
PY 2018
BP 118
EP 125
DI 10.1109/ICPADS.2018.00026
UT WOS:000462962600015
ER

PT C
AU Zhang, R
   Zhou, BW
AF Zhang, Rong
   Zhou, Bowen
GP IEEE
TI APPLYING LOG LINEAR MODEL BASED CONTEXT DEPENDENT MACHINE TRANSLATION
   TECHNIQUES TO GRAPHEME-TO-PHONEME CONVERSION
SO 2010 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
CT 2010 IEEE International Conference on Acoustics, Speech, and Signal
   Processing
CY MAR 10-19, 2010
CL Dallas, TX
SP IEEE Signal Proc Soc
AB Grapheme-to-Phoneme conversion is a challenging task for speech recognition and text-to-speech systems for which the functionality of automatically predicting pronunciations for OOV words is highly desirable. In this paper, Grapheme-to-Phoneme conversion is viewed as a special case of sequence translation problem and we propose to tackle it with phrase based log-linear translation model. We improve standard machine translation method by utilizing context dependent units which lead to a better many-to-many alignment between chunks of graphemes and phonemes. Furthermore, hypotheses combination technique is applied to combine outputs generated by multiple translation models trained with different alignment units. Our proposed approach was evaluated on NetTalk and CMUDict datasets. Significant improvements on conversion accuracy are observed on both sets compared to conventional translation method: phoneme level error rates are reduced relatively by 18.4% and 22.5%, respectively. Our approach also performs better than or as good as previously published data driven methods examined on the same tasks.
SN 1520-6149
BN 978-1-4244-4296-6
PY 2010
BP 4634
EP 4637
DI 10.1109/ICASSP.2010.5495551
UT WOS:000287096004137
ER

PT C
AU Kajiwara, T
AF Kajiwara, Tomoyuki
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Negative Lexically Constrained Decoding for Paraphrase Generation
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB Paraphrase generation can be regarded as monolingual translation. Unlike bilingual machine translation, paraphrase generation rewrites only a limited portion of an input sentence. Hence, previous methods based on machine translation often perform conservatively to fail to make necessary rewrites. To solve this problem, we propose a neural model for paraphrase generation that first identifies words in the source sentence that should be paraphrased. Then, these words are paraphrased by the negative lexically constrained decoding that avoids outputting these words as they are. Experiments on text simplification and formality transfer show that our model improves the quality of paraphrasing by making necessary rewrites to an input sentence.
BN 978-1-950737-48-2
PY 2019
BP 6047
EP 6052
UT WOS:000493046109006
ER

PT C
AU Libovicky, J
   Helcl, J
AF Libovicky, Jindrich
   Helcl, Jindrich
GP Assoc Computat Linguist
TI End-to-End Non-Autoregressive Neural Machine Translation with
   Connectionist Temporal Classification
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB Autoregressive decoding is the only part of sequence-to-sequence models that prevents them from massive parallelization at inference time. Non-autoregressive models enable the decoder to generate all output symbols independently in parallel. We present a novel non-autoregressive architecture based on connectionist temporal classification and evaluate it on the task of neural machine translation. Unlike other non-autoregressive methods which operate in several steps, our model can be trained end-to-end. We conduct experiments on the WMT English-Romanian and EnglishGerman datasets. Our models achieve a significant speedup over the autoregressive models, keeping the translation quality comparable to other non-autoregressive models.
RI Helcl, Jindřich/P-4518-2017; Libovický, Jindřich/O-5766-2019
OI Helcl, Jindřich/0000-0001-7737-3743; Libovický,
   Jindřich/0000-0001-7717-4090
BN 978-1-948087-84-1
PY 2018
BP 3016
EP 3021
UT WOS:000865723403025
ER

PT C
AU Rabinovich, E
   Wintner, S
   Lewinsohn, OL
AF Rabinovich, Ella
   Wintner, Shuly
   Lewinsohn, Ofek Luis
BE Gelbukh, A
TI A Parallel Corpus of Translationese
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING, (CICLING
   2016), PT II
SE Lecture Notes in Computer Science
CT 17th International Conference on Intelligent Text Processing and
   Computational Linguistics (CICLing)
CY APR 03-09, 2016
CL Mevlana Univ, Konya, TURKEY
HO Mevlana Univ
AB We describe a set of bilingual English-French and English-German parallel corpora in which the direction of translation is accurately and reliably annotated. The corpora are diverse, consisting of parliamentary proceedings, literary works, transcriptions of TED talks and political commentary. They will be instrumental for research of translationese and its applications to (human and machine) translation; specifically, they can be used for the task of translationese identification, a research direction that enjoys a growing interest in recent years. To validate the quality and reliability of the corpora, we replicated previous results of supervised and unsupervised identification of translationese, and further extended the experiments to additional datasets and languages.
SN 0302-9743
EI 1611-3349
BN 978-3-319-75487-1; 978-3-319-75486-4
PY 2018
VL 9624
BP 140
EP 155
DI 10.1007/978-3-319-75487-1_12
PN II
UT WOS:000540377700012
ER

PT C
AU Xu, SF
   Xiong, Y
AF Xu, Shaofeng
   Xiong, Yun
GP IEEE
TI Automatic Generation of Pseudocode with Attention Seq2seq Model
SO 2018 25TH ASIA-PACIFIC SOFTWARE ENGINEERING CONFERENCE (APSEC 2018)
SE Asia-Pacific Software Engineering Conference
CT 25th Asia-Pacific Software Engineering Conference (APSEC)
CY DEC 04-07, 2018
CL Nara, JAPAN
SP Special Interest Grp Software Engn, Informat Proc Soc Japan
AB Automatic pseudocode generation has become a growing demand for software engineers. However, most code snippets in production environments do not have corresponding pseudocode, because writing comments or textual descriptions of program source code typically consumes a lot of manpower.
   In this paper, we treat pseudocode generation task as a language translation task which means translating programming code into natural language description, and conduct a sophisticated neural machine translation model, attention seq2seq model, on this task. Experiments on a real-world dataset from an open source Python project reveal that seq2seq model could generate understandable pseudocode for practical usage.
SN 1530-1362
BN 978-1-7281-1970-0
PY 2018
BP 711
EP 712
DI 10.1109/APSEC.2018.00101
UT WOS:000474770300088
ER

PT C
AU Haar, S
   Kaiser, L
   Simonot-Lion, F
   Toussaint, J
AF Haar, S
   Kaiser, L
   Simonot-Lion, F
   Toussaint, J
BE Silva, M
   Giua, A
   Colom, JM
TI Equivalence of timed state machines and safe TPN
SO WODES'02: SIXTH INTERNATIONAL WORKSHOP ON DISCRETE EVENT SYSTEMS,
   PROCEEDINGS
CT 6th International Workshop on Discrete Event Systems (WODES 02)
CY OCT 02-04, 2002
CL ZARAGOZA, SPAIN
SP Univ Zaragoza, Comis Int Ciencia Technol, IEEE Control Syst Soc
AB We show that an important subclass of Timed Automata (Alur and Dill [1]), called Timed State Machines, is weakly time equivalent to safe non-Zeno Time Petri Nets (TPNs) in the sense of Merlin and Farber [15]. We present an explicit construction for two-way translation between 1-safe TPNs and TSMs. The translation improves on the efficiency of other methods: the TSM obtained for a given net is polynomial in the size of the reachability graph, and a given TSM is translated into a net whose size grows linearly with that of the automaton model.
BN 0-7695-1683-1
PY 2002
BP 119
EP 124
UT WOS:000178857000017
ER

PT J
AU Chauhan, S
   Daniel, P
   Saxena, S
   Sharma, A
AF Chauhan, Shweta
   Daniel, Philemon
   Saxena, Shefali
   Sharma, Ayush
TI Fully Unsupervised Machine Translation Using Context-Aware Word
   Translation and Denoising Autoencoder
SO APPLIED ARTIFICIAL INTELLIGENCE
AB Learning machine translation by using only monolingual data sets is a complex task as there are many possible ways to connect or associate target sentences with source sentences. The monolingual word embeddings are linearly mapped on a common shared space through robust learning or adversarial training in an unsupervised way, but these learning techniques have fundamental limitations in translating sentences. In this paper, a simple yet effective method has been proposed for fully unsupervised machine translation that is based on cross-lingual sense to word embedding instead of cross-lingual word embedding and language model. We have utilized word sense disambiguation to incorporate the source language context in order to select the sense of a word more appropriately. A language model for considering target language context in lexical choices and denoising autoencoder for language insertion, deletion, and reordering are integrated. The proposed approach eliminates the problem of noisy target language context due to erroneous word translations. This work takes into account the challenge of homonyms and polysemous words in the case of morphologically rich languages. The experiments performed on English-Hindi and Hindi-English using different evaluation metrics show an improvement of +3 points in BLEU and METEOR-Hindi over the baseline system.
RI Daniel, Philemon/S-6095-2016
OI Daniel, Philemon/0000-0002-7133-9488; Chauhan,
   Shweta/0000-0002-6598-1992
SN 0883-9514
EI 1087-6545
PD DEC 31
PY 2022
VL 36
IS 1
DI 10.1080/08839514.2022.2031817
EA FEB 2022
UT WOS:000751544000001
ER

PT C
AU Tomalin, M
   Gales, MJF
   Liu, XA
   Sim, KC
   Sinha, R
   Wang, L
   Woodland, PC
   Yu, K
AF Tomalin, M.
   Gales, M. J. F.
   Liu, X. A.
   Sim, K. C.
   Sinha, R.
   Wang, L.
   Woodland, P. C.
   Yu, K.
GP IEEE
TI Improving speech transcription for Mandarin-English translation
SO 2007 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING, VOL IV, PTS 1-3
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
CT 32nd IEEE International Conference on Acoustics, Speech and Signal
   Processing
CY APR 15-20, 2007
CL Honolulu, HI
SP IEEE Signal Proc Soc
AB This paper describes the development of the CU-HTK Mandarin Speech-To-Text (STT) system and assesses its performance as part of a transcription-translation pipeline which converts broadcast Mandarin audio into English text. Recent improvements to the STT system are described and these give Character Error Rate (CER) gains of 14.3% absolute for a Broadcast Conversation (BC) task and 5.1% absolute for a Broadcast News (BN) task. The output of these STT systems is then post-processed, so that it consists of sentence-like segments, and translated into English text using a Statistical Machine Translation (SMT) system. The performance of the transcription-translation pipeline is evaluated using the Translation Edit Rate (TER) and BLEU metrics. It is shown that improving both the STT system and the post-STT segmentations can lower the TER scores by up to 5.3% absolute and increase the BLEU scores by up to 2.7% absolute.
RI Yu, Kai/B-1772-2012; Sinha, Rohit/AAX-2879-2020
OI Yu, Kai/0000-0002-7102-9826; Sinha, Rohit/0000-0002-0419-6501
SN 1520-6149
PY 2007
BP 97
EP +
UT WOS:000248909200025
ER

PT C
AU Qin, Y
   Specia, L
AF Qin, Ying
   Specia, Lucia
BE Sun, M
   Liu, Z
   Zhang, M
   Liu, Y
TI Insight into Multiple References in an MT Evaluation Metric
SO CHINESE COMPUTATIONAL LINGUISTICS AND NATURAL LANGUAGE PROCESSING BASED
   ON NATURALLY ANNOTATED BIG DATA (CCL 2015)
SE Lecture Notes in Artificial Intelligence
CT 14th China National Conference on Computational Linguistics (CCL) / 3rd
   International Symposium on Natural Language Processing Based on
   Naturally Annotated Big Data (NLP-NABD)
CY NOV 13-14, 2015
CL Guangdong Univ Foreign Studies, Guangzhou, PEOPLES R CHINA
HO Guangdong Univ Foreign Studies
AB Current evaluation metrics in machine translation (MT) make poor use of multiple reference translations. In this paper we focus on the METEOR metric to gain in-depth insights into how best multiple references can be exploited. Results on five score selection strategies reveal that it is not always wise to choose the best (closest to MT) reference to generate the candidate score. We also propose two weighting approaches by taking into account the recurring information among references. The modified METEOR scores significantly increase the correlation with human judgments on accuracy and fluency evaluation at system level.
OI Specia, Lucia/0000-0002-5495-3128
SN 0302-9743
EI 1611-3349
BN 978-3-319-25816-4; 978-3-319-25815-7
PY 2015
VL 9427
BP 131
EP 140
DI 10.1007/978-3-319-25816-4_11
UT WOS:000367710600011
ER

PT J
AU Ren, BB
AF Ren, Beibei
TI The use of machine translation algorithm based on residual and LSTM
   neural network in translation teaching
SO PLOS ONE
AB With the rapid development of big data and deep learning, breakthroughs have been made in phonetic and textual research, the two fundamental attributes of language. Language is an essential medium of information exchange in teaching activity. The aim is to promote the transformation of the training mode and content of translation major and the application of the translation service industry in various fields. Based on previous research, the SCNLSTM (Skip Convolutional Network and Long Short Term Memory) translation model of deep learning neural network is constructed by learning and training the real dataset and the public PTB (Penn Treebank Dataset). The feasibility of the model's performance, translation quality, and adaptability in practical teaching is analyzed to provide a theoretical basis for the research and application of the SCN-LSTM translation model in English teaching. The results show that the capability of the neural network for translation teaching is nearly one times higher than that of the traditional N-tuple translation model, and the fusion model performs much better than the single model, translation quality, and teaching effect. To be specific, the accuracy of the SCN-LSTM translation model based on deep learning neural network is 95.21%, the degree of translation confusion is reduced by 39.21% compared with that of the LSTM (Long Short Term Memory) model, and the adaptability is 0.4 times that of the N-tuple model. With the highest level of satisfaction in practical teaching evaluation, the SCN-LSTM translation model has achieved a favorable effect on the translation teaching of the English major. In summary, the performance and quality of the translation model are improved significantly by learning the language characteristics in translations by teachers and students, providing ideas for applying machine translation in professional translation teaching.
SN 1932-6203
PD NOV 19
PY 2020
VL 15
IS 11
AR e0240663
DI 10.1371/journal.pone.0240663
UT WOS:000603518300010
PM 33211704
ER

PT C
AU Kumar, P
   Srivastava, S
   Joshi, M
AF Kumar, Pankaj
   Srivastava, Sheetal
   Joshi, Monica
BE Bhattacharyya, S
   Das, N
   Maulik, U
   Bhattacharjee, D
   Pan, I
   Bhaumik, H
   Mukherjee, A
   Nakamatsu, K
TI Syntax Directed Translator for English to Hindi Language
SO 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL
   INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN)
CT IEEE International Conference on Research in Computational Intelligence
   and Communication Networks (ICRCICN)
CY NOV 20-22, 2015
CL Kolkata, INDIA
SP IEEE ADVANCING TECHNOL HUMAN, IEEE YOUNGPROFESSIONALS, TEQIP-II
AB Hindi Machine Translation is the conversion of text from one language to other by a computer without human involvement. MT is a part of Natural Language Processing which aims to change text or speech of one natural language to another with the help of software. This conversion helps us to overcome the language barriers. Also with the invent of MT technological and cultural barriers can be conquered easily thereby allowing frequent exchange of knowledge. The present work attempts to build an automatic translation system for conversion of text from English to Hindi. Several works related to Machine Translation have also been presented here. Firstly we take a text as input in English, store it in a file, extract words and punctuations from it and store them in an array, then we do grouping of words, find their meanings in context to the sentence and convert it to the target language i.e. Hindi. During this translation we also deal with several issues like word order, word sense, ambiguity and idioms. Finally when we get the text in Hindi we check it for correctness of grammatical rules of the language
RI Kumar, Pankaj/N-1188-2017
OI Kumar, Pankaj/0000-0001-5597-8792
BN 978-1-4673-6735-6
PY 2015
BP 455
EP 459
UT WOS:000380445600084
ER

PT C
AU Mori, M
   Papotti, P
   Bellomarini, L
   Giudice, O
AF Mori, Marco
   Papotti, Paolo
   Bellomarini, Luigi
   Giudice, Oliver
GP Assoc Computat Linguist
TI Neural Machine Translation for Fact-checking Temporal Claims
SO PROCEEDINGS OF THE FIFTH FACT EXTRACTION AND VERIFICATION WORKSHOP
   (FEVER 2022)
CT 5th Fact Extraction and VERification Workshop (FEVER)
CY MAY 26, 2022
CL Dublin, IRELAND
SP Amazon
AB Computational fact-checking aims at supporting the verification process of textual claims by exploiting trustworthy sources. However, there are large classes of complex claims that cannot be automatically verified, for instance those related to temporal reasoning. To this aim, in this work, we focus on the verification of economic claims against time series sources. Starting from given textual claims in natural language, we propose a neural machine translation approach to produce respective queries expressed in a recently proposed temporal fragment of the Datalog language. The adopted deep neural approach shows promising preliminary results for the translation of 10 categories of claims extracted from real use cases.
BN 978-1-952148-02-6
PY 2022
BP 78
EP 82
UT WOS:000846890600008
ER

PT J
AU Yang, BS
   Wong, DF
   Chao, LS
   Zhang, M
AF Yang, Baosong
   Wong, Derek F.
   Chao, Lidia S.
   Zhang, Min
TI Improving tree-based neural machine translation with dynamic lexicalized
   dependency encoding
SO KNOWLEDGE-BASED SYSTEMS
AB Tree-to-sequence neural machine translation models have proven to be effective in learning the semantic representations from the exploited syntactic structure. Despite their success, tree-to-sequence models have two major issues: (1) the embeddings of constituents at the higher tree levels tend to contribute less in translation; and (2) using a single set of model parameters is difficult to fully capture the syntactic and semantic richness of linguistic phrases. To address the first problem, we proposed a lexicalized dependency model, in which the source-side lexical representations are learned in a head-dependent fashion following a dependency graph. Since the number of dependents is variable, we proposed a variant recurrent neural network (RNN) to jointly consider the long-distance dependencies and the sequential information of words. Concerning the second problem, we adopt a latent vector to dynamically condition the parameters for the composition of each node representation. Experimental results reveal that the proposed model significantly outperforms the recently proposed tree-based methods in English-Chinese and English-German translation tasks with even far fewer parameters. (C) 2019 Elsevier B.V. All rights reserved.
RI Wong, Derek F/CAI-7740-2022
SN 0950-7051
EI 1872-7409
PD JAN 5
PY 2020
VL 188
AR 105042
DI 10.1016/j.knosys.2019.105042
UT WOS:000513295000034
ER

PT C
AU Copen, J
   Kushniruk, A
AF Copen, John
   Kushniruk, Andre
BE McDaniel, JG
TI Televaluation and Usability Assessment of the Human-Machine Interface
   for a Novel Adaptive Health Knowledge Translation System
SO ADVANCES IN INFORMATION TECHNOLOGY AND COMMUNICATION IN HEALTH
SE Studies in Health Technology and Informatics
CT Conference on Revolutionizing Health Care with Informatics
CY FEB 19-22, 2009
CL Victoria, CANADA
AB We describe results from usability assessment of a novel adaptive health knowledge translation system interface. Search or retrieval logic, navigation, and presentation elements are crucial to delivering best content. Design requirements have been enhanced by assessing participant needs and desired features.
SN 0926-9630
BN 978-1-58603-979-0
PY 2009
VL 143
BP 302
EP 308
DI 10.3233/978-1-58603-979-0-302
UT WOS:000274313500047
PM 19380952
ER

PT C
AU Tuan, YL
   El-Kishky, A
   Renduchintala, A
   Chaudhary, V
   Guzman, F
   Specia, L
AF Tuan, Yi-Lin
   El-Kishky, Ahmed
   Renduchintala, Adithya
   Chaudhary, Vishrav
   Guzman, Francisco
   Specia, Lucia
GP Assoc Computat Linguist
TI Quality Estimation without Human-labeled Data
SO 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (EACL 2021)
CT 16th Conference of the
   European-Chapter-of-the-Association-for-Computational-Linguistics (EACL)
CY APR 19-23, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, European Chapter, Grammarly, Facebook AI, Bloomberg Engn, LegalForce, Babelscape
AB Quality estimation aims to measure the quality of translated content without access to a reference translation. This is crucial for machine translation systems in real-world scenarios where high-quality translation is needed. While many approaches exist for quality estimation, they are based on supervised machine learning requiring costly human labelled data. As an alternative, we propose a technique that does not rely on examples from human-annotators and instead uses synthetic training data. We train off-the-shelf architectures for supervised quality estimation on our synthetic data and show that the resulting models achieve comparable performance to models trained on human-annotated data, both for sentence and word-level prediction.
BN 978-1-954085-02-2
PY 2021
BP 619
EP 625
UT WOS:000863557000050
ER

PT J
AU Finch, A
   Sumita, E
   Nakamura, S
AF Finch, Andrew
   Sumita, Eiichiro
   Nakamura, Satoshi
TI Class-Dependent Modeling for Dialog Translation
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
AB This paper presents a technique for class-dependent decoding for statistical machine translation (SMT). The approach differs from previous methods of class-dependent translation in that the class-dependent forms of all models are integrated directly into the decoding process. We employ probabilistic mixture weights between models that can change dynamically on a sentence-by-sentence basis depending on the characteristics of the source sentence. The effectiveness of this approach is demonstrated by evaluating its performance on travel conversation data. We used this approach to tackle the translation of questions and declarative sentences using class-dependent models. To achieve this, our system integrated two sets of models specifically built to deal with sentences that fall into one of two classes of dialog sentence: questions and declarations, with a third set of models built with all of the data to handle the general case. The technique was thoroughly evaluated on data from 16 language pairs using 6 machine translation evaluation metrics. We found the results were corpus-dependent, but in most cases our system was able to improve translation performance, and for some languages the improvements were substantial.
SN 0916-8532
PD DEC
PY 2009
VL E92D
IS 12
BP 2469
EP 2477
DI 10.1587/transinf.E92.D.2469
UT WOS:000273190800022
ER

PT C
AU Lin, JY
   Sun, X
   Ren, XC
   Li, MY
   Su, Q
AF Lin, Junyang
   Sun, Xu
   Ren, Xuancheng
   Li, Muyu
   Su, Qi
GP Assoc Computat Linguist
TI Learning When to Concentrate or Divert Attention: Self-Adaptive
   Attention Temperature for Neural Machine Translation
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB Most of the Neural Machine Translation (NMT) models are based on the sequence-to-sequence (Seq2Seq) model with an encoder-decoder framework equipped with the attention mechanism. However, the conventional attention mechanism treats the decoding at each time step equally with the same matrix, which is problematic since the softness of the attention for different types of words (e.g. content words and function words) should differ. Therefore, we propose a new model with a mechanism called Self-Adaptive Control of Temperature (SACT) to control the softness of attention by means of an attention temperature. Experimental results on the Chinese-English translation and English-Vietnamese translation demonstrate that our model outperforms the baseline models, and the analysis and the case study show that our model can attend to the most relevant elements in the source-side contexts and generate the translation of high quality.
BN 978-1-948087-84-1
PY 2018
BP 2985
EP 2990
UT WOS:000865723403020
ER

PT S
AU Abir, E
   Klein, S
   Miller, D
   Steinbaum, M
AF Abir, E
   Klein, S
   Miller, D
   Steinbaum, M
BE Richardson, SD
TI Fluent machines' EliMT system
SO MACHINE TRANSLATION: FROM RESEARCH TO REAL USERS
SE Lecture Notes in Artificial Intelligence
CT 5th Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 08-12, 2002
CL Tiburon, CA
SP Assoc Machine Translat Americas
AB This paper presents a generalized description of the characteristics and implications of two processes that enable Fluent Machines' machine translation system, called EliMT (a term coined by Dr. Jamie Carbonell after the system's inventor, Eli Abir). These two processes are (1) an automated cross-language database builder and (2) an n-gram connector.
SN 0302-9743
EI 1611-3349
BN 3-540-44282-0
PY 2002
VL 2499
BP 216
EP 219
UT WOS:000189412300022
ER

PT J
AU Bago, P
   Castilho, S
   Celeste, E
   Dunne, J
   Gaspari, F
   Gislason, NR
   Kasen, A
   Klubicka, F
   Kristmannsson, G
   McHugh, H
   Moran, R
   Loinsigh, ON
   Olsen, JA
   Escartin, CP
   Ramesh, A
   Resende, N
   Sheridan, P
   Way, A
AF Bago, Petra
   Castilho, Sheila
   Celeste, Edoardo
   Dunne, Jane
   Gaspari, Federico
   Gislason, Niels Runar
   Kasen, Andre
   Klubicka, Filip
   Kristmannsson, Gauti
   McHugh, Helen
   Moran, Roisin
   Ni Loinsigh, Orla
   Olsen, Jon Arild
   Escartin, Carla Parra
   Ramesh, Akshai
   Resende, Natalia
   Sheridan, Paraic
   Way, Andy
TI SHARING HIGH-QUALITY LANGUAGE RESOURCES IN THE LEGAL DOMAIN TO DEVELOP
   NEURAL MACHINE TRANSLATION FOR UNDER-RESOURCED EUROPEAN LANGUAGES
SO REVISTA DE LLENGUA I DRET-JOURNAL OF LANGUAGE AND LAW
AB This article reports some of the main achievements of the European Union-funded PRINCIPLE project in collecting high-quality language resources (LRs) in the legal domain for four under-resourced European languages: Croatian, Irish, Norwegian, and Icelandic. After illustrating the significance of this work for developing translation technologies in the context of the European Union and the European Economic Area, the article outlines the main steps of data collection, curation, and sharing of the LRs gathered with the support of public and private data contributors. This is followed by a description of the development pipeline and key features of the state-of-the-art, bespoke neural machine translation (MT) engines for the legal domain that were built using this data. The MT systems were evaluated with a combination of automatic and human methods to validate the quality of the LRs collected in the project, and the high-quality LRs were subsequently shared with the wider community via the ELRC-SHARE repository. The main challenges encountered in this work are discussed, emphasising the importance and the key benefits of sharing high-quality digital LRs.
SN 0212-5056
EI 2013-1453
PD DEC
PY 2022
IS 78
BP 9
EP 34
DI 10.2436/rld.i78.2022.3741
UT WOS:000906516000002
ER

PT J
AU Costa-Jussa, MR
   Fonollosa, JAR
AF Costa-Jussa, Marta R.
   Fonollosa, Jose A. R.
TI Latest trends in hybrid machine translation and its applications
SO COMPUTER SPEECH AND LANGUAGE
AB This survey on hybrid machine translation (MT) is motivated by the fact that hybridization techniques have become popular as they attempt to combine the best characteristics of highly advanced pure rule or corpus-based MT approaches. Existing research typically covers either simple or more complex architectures guided by either rule or corpus-based approaches. The goal is to combine the best properties of each type.
   This survey provides a detailed overview of the modification of the standard rule-based architecture to include statistical knowledge, the introduction of rules in corpus-based approaches, and the hybridization of approaches within this last single category. The principal aim here is to cover the leading research and progress in this field of MT and in several related applications. (C) 2014 The Authors. Published by Elsevier Ltd.
RI Fonollosa, José A. R./K-7028-2013; Costa-jussa, Marta R./M-7886-2013
OI Fonollosa, José A. R./0000-0001-9513-7939; Costa-jussa, Marta
   R./0000-0002-5703-520X
SN 0885-2308
EI 1095-8363
PD JUL
PY 2015
VL 32
IS 1
SI SI
BP 3
EP 10
DI 10.1016/j.csl.2014.11.001
UT WOS:000352925700002
ER

PT C
AU Beck, ACS
   Carro, L
AF Beck, ACS
   Carro, L
GP IEEE Comp Soc
TI Dynamic reconfiguration with binary translation: Breaking the ILP
   barrier with software compatibility
SO 42ND DESIGN AUTOMATION CONFERENCE, PROCEEDINGS 2005
SE Design Automation Conference DAC
CT 42nd Design Automation Conference
CY JUN 13-17, 2005
CL Anaheim, CA
SP ACM SIGDA, EDA, IEEE, IEEECASS/CANDE, IEEE Circuits & Syst Soc
AB In this paper we present the impact of dynamically translating any sequence of instructions into combinational logic. The proposed approach combines a reconfigurable architecture with a binary translation mechanism, being totally transparent for the software designer. Besides ensuring software compatibility, the technique allows porting the same code for different machines tracking technological evolutions. The target processor is a Java machine able to execute Java bytecodes. Experimental results show that even code without any available parallelism can benefit from the proposed approach. Algorithms used in the embedded systems domain were accelerated 4.6 times in the mean, while spending 10.89 times less energy in the average. We present results regarding the impact of area and power, and compare the proposed approach with other Java machines, including a VLIW one.
RI Carro, Luigi/I-4144-2013; Carro, Luigi/AAR-8819-2020; Beck, Antonio
   Carlos Schneider/AAD-3552-2020
OI Carro, Luigi/0000-0002-7402-4780; Beck, Antonio Carlos
   Schneider/0000-0002-4492-1747
SN 0738-100X
BN 1-59593-058-2
PY 2005
BP 732
EP 737
UT WOS:000230430300148
ER

PT C
AU Shichman, M
   Gaffney, M
   Fake, EC
   Veridian, LS
AF Shichman, M
   Gaffney, M
   Fake, EC
   Veridian, LS
GP ISIF
   ISIF
TI Foreign language audio information management system
SO PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION FUSION,
   VOL II
CT 5th International Conference on Information Fusion (FUSION 2002)
CY JUL 08-11, 2002
CL ANNAPOLIS, MD
SP IEEE, Georgia Tech Res Inst, USAF Res Lab, US Dept Defense, Missile Defense Agcy, NAVSEA, Oak Ridge Natl Lab, US DOE, USN, Off Res, AIAA, IEE
AB Veridian created a prototype of a foreign language audio information management system that integrates speech recognition technology, machine translation and advanced information retrieval and extraction for Mandarin Chinese. The system automatically processes audio recordings to create a data warehouse of derived information using speech recognition and machine translation technology components. The data warehouse can then be further exploited using information retrieval technology components.
   The prototype system provides the following capabilities:
   Automatically transforming foreign audiofiles into electronic text,
   Transforming foreign text into English text,
   Matching transcribed and translated text and the topics of interest to the analyst,
   Displaying transcribed text by speaker.
   The conclusions imply that while automatic speech processing technology is far from perfect for mass market distribution, it is sufficiently advanced to help with the overload of audio and video data.
BN 0-9721844-2-2
PY 2002
BP 1492
EP 1498
UT WOS:000178107500104
ER

PT C
AU Ma, SB
   Han, YH
AF Ma, Shubo
   Han, Yahong
GP IEEE
TI DESCRIBING IMAGES BY FEEDING LSTM WITH STRUCTURAL WORDS
SO 2016 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA & EXPO (ICME)
SE IEEE International Conference on Multimedia and Expo
CT IEEE International Conference on Multimedia & Expo (ICME)
CY JUL 11-15, 2016
CL Seattle, WA
SP IEEE
AB Generating semantic description draws increasing attention recently. Describing objects with adaptive adjunct words make the sentence more informative. In this paper, we focus on the generation of descriptions for images according to the structural words we have generated such as a tetrad of <object, attribute, activity, scene>. We propose to use deep machine translation method to generate semantically meaningful descriptions. In particular, the description is composed of objects with appropriate adjunct words, corresponding activities and scene. We propose to use a multi-task method to generate structural words. Taking these words sequence as source language, we train a LSTM encoder-decoder machine translation model to output the target language. Experiments on the benchmark datasets demonstrate our method has better performance than state-of-the-art methods of image caption in terms of language generation metrics.
SN 1945-7871
BN 978-1-4673-7258-9
PY 2016
UT WOS:000389574300026
ER

PT C
AU Sajjad, H
   Dalvi, F
   Durrani, N
   Abdelali, A
   Belinkov, Y
   Vogel, S
AF Sajjad, Hassan
   Dalvi, Fahim
   Durrani, Nadir
   Abdelali, Ahmed
   Belinkov, Yonatan
   Vogel, Stephan
BE Barzilay, R
   Kan, MY
TI Challenging Language-Dependent Segmentation for Arabic: An Application
   to Machine Translation and Part-of-Speech Tagging
SO PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2
CT 55th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 30-AUG 04, 2017
CL Vancouver, CANADA
SP Alibaba Grp, Amazon, Apple, Baidu, Bloomberg, Facebook, Google, Samsung, Tencent, eBay, Elsevier, IBM Res, KPMG, Maluuba, Microsoft, Naver Line, NEC, Recruit Inst Technol, SAP, Adobe, Bosch, CVTE, Duolingo, Huawei, Nuance, Oracle, Sogou, Grammarly, Toutiao, Yandex
AB Word segmentation plays a pivotal role in improving any Arabic NLP application. Therefore, a lot of research has been spent in improving its accuracy. Off-the-shelf tools, however, are: i) complicated to use and ii) domain/dialect dependent. We explore three language-independent alternatives to morphological segmentation using: i) data-driven sub-word units, ii) characters as a unit of learning, and iii) word embeddings learned using a character CNN (Convolution Neural Network). On the tasks of Machine Translation and POS tagging, we found these methods to achieve close to, and occasionally surpass state-of-the-art performance. In our analysis, we show that a neural machine translation system is sensitive to the ratio of source and target tokens, and a ratio close to 1 or greater, gives optimal performance.
OI Dalvi, Fahim/0000-0003-1183-7837
BN 978-1-945626-76-0
PY 2017
BP 601
EP 607
DI 10.18653/v1/P17-2095
UT WOS:000493992300095
ER

PT C
AU Rozovskaya, A
   Roth, D
AF Rozovskaya, Alla
   Roth, Dan
BE Erk, K
   Smith, NA
TI Grammatical Error Correction: Machine Translation and Classifiers
SO PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS, VOL 1
CT 54th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY AUG 07-12, 2016
CL Berlin, GERMANY
SP Assoc Computat Linguist, Google, Baidu, Amazon Com, Bloomberg, Facebook, Microsoft Res, eBay, Elsevier, IBM Res, MaluubA, Huawei Technologies, Nuance, Grammarly, VoiceBox Technologies, Yandex, Textkernel, Zalando SE
AB We focus on two leading state-of-the-art approaches to grammatical error correction machine learning classification and machine translation. Based on the comparative study of the two learning frameworks and through error analysis of the output of the state-of-the-art systems, we identify key strengths and weaknesses of each of these approaches and demonstrate their complementarity. In particular, the machine translation method learns from parallel data without requiring further linguistic input and is better at correcting complex mistakes. The classification approach possesses other desirable characteristics, such as the ability to easily generalize beyond what was seen in training, the ability to train without human-annotated data, and the flexibility to adjust knowledge sources for individual error types.
   Based on this analysis, we develop an algorithmic approach that combines the strengths of both methods. We present several systems based on resources used in previous work with a relative improvement of over 20% (and 7.4 F score points) over the previous state-of-the-art.
BN 978-1-945626-00-5
PY 2016
BP 2205
EP 2215
UT WOS:000493806800208
ER

PT J
AU Okumura, A
   Satoh, K
   Ando, S
   Sakai, S
   Yamabana, K
   Watanabe, T
AF Okumura, A
   Satoh, K
   Ando, S
   Sakai, S
   Yamabana, K
   Watanabe, T
TI An automatic speech translation system for travel conversation
SO NEC RESEARCH & DEVELOPMENT
AB We present a speech-to-speech translation system for notebook PC's that helps oral communication between Japanese and English-speaking persons in various situations when traveling abroad. We have especially tried to solve the problem of limitations in the variety of acceptable expressions and situations in conventional approaches to speech-to-speech translation. A solution of this problem is very important since it leads to the realization of a practical speech-to-speech translation system for travelers who encounter various situations during travel abroad, such as hotel and air reservations, ordering in a restaurant and so on. Due to the high accuracy of the compact speech recognition engine and our lexicalized grammar approach to machine translation that utilizes corpus but is oriented to model general linguistic phenomena as well as word-specific ones, a versatile speech-to-speech translation system for travel abroad has been achieved that has a much larger vocabulary and is capable of translating spoken conversations in more situations compared to previous work.
SN 0547-051X
PD JAN
PY 2002
VL 43
IS 1
BP 37
EP 40
UT WOS:000173770600009
ER

PT C
AU Casan, GA
   Castano, M
AF Casan, GA
   Castano, M
BE DelPobil, AP
TI A new approach to codifications for the RECONTRA neural translator
SO PROCEEDINGS OF THE NINTH IASTED INTERNATIONAL CONFERENCE ON ARTIFICIAL
   INTELLIGENCE AND SOFT COMPUTING
CT 9th IASTED International Conference on Artificial Intelligence and Soft
   Computing
CY SEP 12-14, 2005
CL Benidorm, SPAIN
SP Int Assoc Sci & Technol Dev, TC Artificial Intelligence & Expert Syst, IASTED, TC Soft Comp
AB Encouragingly accurate translations have recently been obtained using a connectionist translator called RECONTRA (Recurrent Connectionist Translator). This paper approaches a text-to-text machine translation task more complex than those previously tackled with this translator. The distributed codifications of the lexicons involved in the task were automatically extracted of the hidden layer of a multilayer perceptron with Output delays. The use of a simple pruning method determined the size of the extracted representations, and adopting distributed codifications for the input and output of the multilayer perceptrons, the size and training time of the networks were reduced.
RI Castano, M. Asuncion/ABF-6685-2020; Casañ, Gustavo A/M-8144-2014
OI Castano, M. Asuncion/0000-0002-4010-1813; Casañ, Gustavo
   A/0000-0001-7434-1244
BN 0-88986-536-1
PY 2005
BP 147
EP 152
UT WOS:000233165700027
ER

PT J
AU Jung, H
   Kim, K
   Shin, JH
   Na, SH
   Jung, S
   Woo, S
AF Jung, Heeseung
   Kim, Kangil
   Shin, Jong-Hun
   Na, Seung-Hoon
   Jung, Sangkeun
   Woo, Sangmin
TI Impact of Sentence Representation Matching in Neural Machine Translation
SO APPLIED SCIENCES-BASEL
AB Most neural machine translation models are implemented as a conditional language model framework composed of encoder and decoder models. This framework learns complex and long-distant dependencies, but its deep structure causes inefficiency in training. Matching vector representations of source and target sentences improves the inefficiency by shortening the depth from parameters to costs and generalizes NMTs with a different perspective to cross-entropy loss. In this paper, we propose matching methods to derive the cost based on constant word-embedding vectors of source and target sentences. To find the best method, we analyze the impact of the methods with varying structures, distance metrics, and model capacity in a French to English translation task. An optimally configured method is applied to English translation tasks from and to French, Spanish, and German. In the tasks, the method showed performance improvement by 3.23 BLEU at maximum, with an improvement of 0.71 on average. We evaluated the robustness of this method to various embedding distributions and models, such as conventional gated structures and transformer networks, and empirical results showed that it has a higher chance to improve performance in those models.
OI Na, Seung-Hoon/0000-0002-4372-7125; Woo, Sangmin/0000-0003-4451-9675;
   Jung, Sangkeun/0000-0003-3531-0618
EI 2076-3417
PD FEB
PY 2022
VL 12
IS 3
AR 1313
DI 10.3390/app12031313
UT WOS:000755250700001
ER

PT C
AU Xia, YC
   He, TY
   Tan, X
   Tian, F
   He, D
   Qin, T
AF Xia, Yingce
   He, Tianyu
   Tan, Xu
   Tian, Fei
   He, Di
   Qin, Tao
GP AAAI
TI Tied Transformers: Neural Machine Translation with Shared Encoder and
   Decoder
SO THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 33rd AAAI Conference on Artificial Intelligence / 31st Innovative
   Applications of Artificial Intelligence Conference / 9th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY JAN 27-FEB 01, 2019
CL Honolulu, HI
SP Assoc Advancement Artificial Intelligence
AB Sharing source and target side vocabularies and word embeddings has been a popular practice in neural machine translation (briefly, NMT) for similar languages (e.g., English to French or German translation). The success of such word-level sharing motivates us to move one step further: we consider model-level sharing and tie the whole parts of the encoder and decoder of an NMT model. We share the encoder and decoder of Transformer (Vaswani et al. 2017), the state-of-the-art NMT model, and obtain a compact model named Tied Transformer. Experimental results demonstrate that such a simple method works well for both similar and dissimilar language pairs. We empirically verify our framework for both supervised NMT and unsupervised NMT: we achieve a 35:52 BLEU score on IWSLT 2014 German to English translation, 28:98/29:89 BLEU scores on WMT 2014 English to German translation without/with monolingual data, and a 22:05 BLEU score on WMT 2016 unsupervised German to English translation.
OI Qin, Tao/0000-0002-9095-0776
SN 2159-5399
EI 2374-3468
BN 978-1-57735-809-1
PY 2019
BP 5466
EP 5473
UT WOS:000485292605061
ER

PT C
AU Tu, LF
   Pang, RYZ
   Wiseman, S
   Gimpel, K
AF Tu, Lifu
   Pang, Richard Yuanzhe
   Wiseman, Sam
   Gimpel, Kevin
GP Assoc Computat Linguist
TI ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine
   Translation
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB We propose to train a non-autoregressive machine translation model to minimize the energy defined by a pretrained autoregressive model. In particular, we view our non-autoregressive translation system as an inference network (Tu and Gimpel, 2018) trained to minimize the autoregressive teacher energy. This contrasts with the popular approach of training a non-autoregressive model on a distilled corpus consisting of the beam-searched outputs of such a teacher model. Our approach, which we call ENGINE (ENerGy-based Inference NEtworks), achieves state-of-the-art non-autoregressive results on the IWSLT 2014 DE-EN and WMT 2016 RO-EN datasets, approaching the performance of autoregressive models.(1)
BN 978-1-952148-25-5
PY 2020
BP 2819
EP 2826
UT WOS:000570978203011
ER

PT J
AU Belles-Calvera, L
   Quintana, RC
AF Belles-Calvera, Lucia
   Caro Quintana, Rocio
TI Is academic discourse accurate when supported by machine translation?
SO QUADERNS DE FILOLOGIA-ESTUDIS LINGUISTICS
AB Classroom discourse has aroused interest among scholars and educators (Deroey, 2015; Mauranen, 2012; Hyland, 2010), particularly the use of metadiscoursal markers. However, little attention has been paid to these features when they are supported by machine translation (MT) engines in content and language integrated learning (CLIL) contexts. The aim of this paper is to describe the use and frequency of hedges and boosters employed in the fields of History and Heritage and Psychology and analyse the accuracy of the equivalents obtained from two MT engines, namely DeepL and Google Translate. To this end, a small corpus consisting of two seminars was compiled and qualitative and quantitative methods were implemented to determine the frequency and the accuracy of the linguistic structures under study. The results revealed that even though the interactional devices provided by MT engines are highly accurate, some omissions and mistranslations may occur. These findings may be valuable for CUL lecturers interested in classroom discourse, as well as for translation researchers working with bilingual and multilingual corpora who seek to assess the accuracy of translation tools.
SN 1135-416X
EI 2444-1449
PY 2023
VL 27
BP 171
EP 201
DI 10.7203/QF.27.24671
UT WOS:000899234200008
ER

PT J
AU Yang, ZY
   Pinto-Alva, L
   Dernoncourt, F
   Ordonez, V
AF Yang, Ziyan
   Pinto-Alva, Leticia
   Dernoncourt, Franck
   Ordonez, Vicente
TI Backpropagation-Based Decoding for Multimodal Machine Translation
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
AB People are able to describe images using thousands of languages, but languages share only one visual world. The aim of this work is to use the learned intermediate visual representations from a deep convolutional neural network to transfer information across languages for which paired data is not available in any form. Our work proposes using backpropagation-based decoding coupled with transformer-based multilingual-multimodal language models in order to obtain translations between any languages used during training. We particularly show the capabilities of this approach in the translation of German-Japanese and Japanese-German sentence pairs, given a training data of images freely associated with text in English, German, and Japanese but for which no single image contains annotations in both Japanese and German. Moreover, we demonstrate that our approach is also generally useful in the multilingual image captioning task when sentences in a second language are available at test time. The results of our method also compare favorably in the Multi30k dataset against recently proposed methods that are also aiming to leverage images as an intermediate source of translations.
EI 2624-8212
PD JAN 17
PY 2022
VL 4
AR 736722
DI 10.3389/frai.2021.736722
UT WOS:000915201200001
PM 35112079
ER

PT C
AU Lin, ZH
   Pan, X
   Wang, MX
   Qiu, XP
   Feng, JT
   Zhou, H
   Li, L
AF Lin, Zehui
   Pan, Xiao
   Wang, Mingxuan
   Qiu, Xipeng
   Feng, Jiangtao
   Zhou, Hao
   Li, Lei
GP Assoc Computat Linguist
TI Pre-training Multilingual Neural Machine Translation by Leveraging
   Alignment Information
SO PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL
   LANGUAGE PROCESSING (EMNLP)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 16-20, 2020
CL ELECTR NETWORK
SP Bloomberg Engn, Google Res, Apple, Amazon Sci, Baidu, Megagon Labs, Facebook, DeepMind, Grammarly, ByteDance, Zeta Alpha, Babelscape, Naver, Adobe, Hitachi, Salesforce, Univ So Calif, Viterbi Sch Engn, Informat Sci Inst
AB We investigate the following question for machine translation (MT): can we develop a single universal MT model to serve as the common seed and obtain derivative and improved models on arbitrary language pairs? We propose mRASP, an approach to pre-train a universal multilingual neural machine translation model. Our key idea in mRASP is its novel technique of random aligned substitution, which brings words and phrases with similar meanings across multiple languages closer in the representation space. We pre-train a mRASP model on 32 language pairs jointly with only public datasets. The model is then fine-tuned on downstream language pairs to obtain specialized MT models. We carry out extensive experiments on 42 translation directions across a diverse settings, including low, medium, rich resource, and as well as transferring to exotic language pairs. Experimental results demonstrate that mRASP achieves significant performance improvement compared to directly training on those target pairs. It is the first time to verify that multiple lowresource language pairs can be utilized to improve rich resource MT. Surprisingly, mRASP is even able to improve the translation quality on exotic languages that never occur in the pretraining corpus. Code, data, and pre-trained models are available at https://github.com/linzehui/mRASP.
RI Qiu, Xipeng/G-4071-2011
OI Qiu, Xipeng/0000-0001-7163-5247; Li, Lei/0000-0003-3095-9776
BN 978-1-952148-60-6
PY 2020
BP 2649
EP 2663
UT WOS:000855160702067
ER

PT C
AU Yamamoto, K
   Takahashi, K
AF Yamamoto, Kazuhide
   Takahashi, Kanji
BE Dong, M
   Tseng, YH
   Lu, Y
   Yu, LC
   Lee, LH
   Wu, CH
   Li, H
TI Japanese Orthographical Normalization Does Not Work for Statistical
   Machine Translation
SO PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE
   PROCESSING (IALP)
SE International Conference on Asian Language Processing
CT International Conference on Asian Language Processing (IALP)
CY NOV 21-23, 2016
CL Tainan, TAIWAN
SP Natl Cheng Kung Univ, Yuan Ze Univ, Chinese & Oriental Languages Informat Proc Soc, IEEE Tainan Sect, Minist Sci & Technol, Ind Technol Res Inst, IEEE Comp Soc
AB We have investigated the effect of normalizing Japanese orthographical variants into a uniform orthography on statistical machine translation (SMT) between Japanese and English. In Japanese, 10% of words have reportedly more than one orthographical variants, which is a promising fact for improving translation quality when we normalize these orthographical variants. However, the results show that SMT with normalization is equivalent to that without normalization by both BLEU and RIBES measurement, even though normalization reduces the size of language models, its perplexity, and the number of out-of-vocabulary words. We discuss the potential reasons in this paper.
SN 2159-1962
EI 2159-1970
BN 978-1-5090-0922-0
PY 2016
BP 133
EP 136
UT WOS:000401528000032
ER

PT C
AU Gonzalez, MM
   Endo, T
AF Gonzalez, Manuel Medina
   Endo, Tsutomu
BA Ao, SI
BF Ao, SI
BE Castillo, O
   Douglas, C
   Feng, DD
   Lee, JA
TI Tense and Mood Decision with Similarity Search in Japanese to Spanish
   Machine Translation
SO IMECS 2009: INTERNATIONAL MULTI-CONFERENCE OF ENGINEERS AND COMPUTER
   SCIENTISTS, VOLS I AND II
SE Lecture Notes in Engineering and Computer Science
CT International Multi-Conference of Engineers and Computer Scientists
CY MAR 18-20, 2009
CL Kowloon, PEOPLES R CHINA
SP Int Assoc Engineers, IAENG, Soc Artificial Intelligence, IAENG, Soc Bioinformat, IAENG, Soc Comp Sci, IAENG, Soc Data Min, IAENG, Soc Elect Engn, IAENG, Soc Imaging Engn, IAENG, Soc Ind Engn, IAENG, Soc Informat Syst Engn, IAENG, Soc Internet Comp & Web Serv, IAENG, Soc Mech Engn, IAENG, Soc Operat Res, IAENG, Soc Sci Comp, IAENG, Soc Software Engn, IAENG, Soc Wireless Networks
AB Tense and mood are pieces of information normally unattended in Japanese to Spanish machine translation as they do not exist formally in the former language. In this paper we propose a new technique to solve this issue by using a tree distance function and the nearest neighbor approach in order to find similar sentences in a knowledge base. A query sentence is input and it is transformed into a tree using a language model; then, a series of similar sentences is retrieved from the knowledge base; the most similar is selected and all the information of the predicates in it is assigned to the predicates in the query sentence. Our technique proves to be accurate as it obtained a 61% of correct results, just below the 63% obtained by Systran.
SN 2078-0958
BN 978-988-17012-2-0
PY 2009
BP 86
EP 91
UT WOS:000266097200017
ER

PT J
AU Madnani, N
   Dorr, BJ
AF Madnani, Nitin
   Dorr, Bonnie J.
TI Generating Targeted Paraphrases for Improved Translation
SO ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY
AB Today's Statistical Machine Translation (SMT) systems require high-quality human translations for parameter tuning, in addition to large bitexts for learning the translation units. This parameter tuning usually involves generating translations at different points in the parameter space and obtaining feedback against human-authored reference translations as to how good the translations. This feedback then dictates what point in the parameter space should be explored next. To measure this feedback, it is generally considered wise to have multiple (usually 4) reference translations to avoid unfair penalization of translation hypotheses which could easily happen given the large number of ways in which a sentence can be translated from one language to another. However, this reliance on multiple reference translations creates a problem since they are labor intensive and expensive to obtain. Therefore, most current MT datasets only contain a single reference. This leads to the problem of reference sparsity. In our previously published research, we had proposed the first paraphrase-based solution to this problem and evaluated its effect on Chinese-English translation. In this article, we first present extended results for that solution on additional source languages. More importantly, we present a novel way to generate "targeted" paraphrases that yields substantially larger gains (up to 2.7 BLEU points) in translation quality when compared to our previous solution (up to 1.6 BLEU points). In addition, we further validate these improvements by supplementing with human preference judgments obtained via Amazon Mechanical Turk.
RI Vieira, Sílvia/B-7913-2013
OI Dorr, Bonnie/0000-0003-4356-5813
SN 2157-6904
EI 2157-6912
PD JUN
PY 2013
VL 4
IS 3
AR 40
DI 10.1145/2483669.2483673
UT WOS:000321223600004
ER

PT C
AU Xu, JT
   Yvon, F
AF Xu, Jitao
   Yvon, Francois
GP Assoc Computat Linguist
TI One Source, Two Targets: Challenges and Rewards of Dual Decoding
SO 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2021)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 07-11, 2021
CL Punta Cana, DOMINICAN REP
AB Machine translation is generally understood as generating one target text from an input source document. In this paper, we consider a stronger requirement: to jointly generate two texts so that each output side effectively depends on the other. As we discuss, such a device serves several practical purposes, from multi-target machine translation to the generation of controlled variations of the target text. We present an analysis of possible implementations of dual decoding, and experiment with four applications. Viewing the problem from multiple angles allows us to better highlight the challenges of dual decoding and to also thoroughly analyze the benefits of generating matched, rather than independent, translations.
BN 978-1-955917-09-4
PY 2021
BP 8533
EP 8546
UT WOS:000860727002049
ER

PT C
AU Chen, KH
   Utiyama, M
   Sumita, E
   Wang, R
   Zhang, M
AF Chen, Kehai
   Utiyama, Masao
   Sumita, Eiichiro
   Wang, Rui
   Zhang, Min
GP Assoc Computa Linguist
TI Synchronous Refinement for Neural Machine Translation
SO FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022)
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB Machine translation typically adopts an encoder-to-decoder framework, in which the decoder generates the target sentence word-by-word in an auto-regressive manner. However, the auto-regressive decoder faces a deep-rooted one-pass issue whereby each generated word is considered as one element of the final output regardless of whether it is correct or not. These generated wrong words further constitute the target historical context to affect the generation of subsequent target words. This paper proposes a novel synchronous refinement method to revise potential errors in the generated words by considering part of the target future context. Particularly, the proposed approach allows the auto-regressive decoder to refine the previously generated target words and generate the next target word synchronously. The experimental results on three widely-used machine translation tasks demonstrated the effectiveness of the proposed approach.
BN 978-1-955917-25-4
PY 2022
BP 2986
EP 2996
UT WOS:000828767403006
ER

PT C
AU Tohyama, H
   Matsubara, S
AF Tohyama, Hitomi
   Matsubara, Shigeki
GP ISCA
TI Influence of Pause Length on Listeners' Impressions in Simultaneous
   Interpretation
SO INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE
   PROCESSING, VOLS 1-5
CT 9th International Conference on Spoken Language Processing/INTERSPEECH
   2006
CY 2006
CL Pittsburgh, PA
SP Int Speech Commun Assoc
AB We have been attempting to realize simultaneous machine interpretation. However, determining the interpreting utterance timing is as difficult as determining translation units. This remains a major concern for the development of such a speech translation system. It is also crucial for the system's users that the speech generated by. the system is clear and easy to listen to. In this paper, we focus attention on the pauses that partly characterize simultaneous interpreters' utterances. We attempt to analyze the results of an experiment conducted using 31 subjects on the relationship between listener-friendliness and the length of pauses in speech, using the CIAIR simultaneous interpretation database as the data source. The results generated some knowledge about listener impressions of simultaneous interpretation, which will be helpful for realizing simultaneous machine interpretation.
OI Matsubara, Shigeki/0000-0003-0416-3635
BN 978-1-60423-449-7
PY 2006
BP 893
EP +
UT WOS:000269965900224
ER

PT C
AU Li, HR
   Lu, W
AF Li, Haoran
   Lu, Wei
BE Meila, M
   Zhang, T
TI Mixed Cross Entropy Loss for Neural Machine Translation
SO INTERNATIONAL CONFERENCE ON MACHINE LEARNING, VOL 139
SE Proceedings of Machine Learning Research
CT International Conference on Machine Learning (ICML)
CY JUL 18-24, 2021
CL ELECTR NETWORK
AB In neural machine translation, cross entropy (CE) is the standard loss function in two training methods of auto-regressive models, i.e., teacher forcing and scheduled sampling. In this paper, we propose mixed cross entropy loss (mixed CE) as a substitute for CE in both training approaches. In teacher forcing, the model trained with CE regards the translation problem as a one-to-one mapping process, while in mixed CE this process can be relaxed to one-to-many. In scheduled sampling, we show that mixed CE has the potential to encourage the training and testing behaviours to be similar to each other, more effectively mitigating the exposure bias problem. We demonstrate the superiority of mixed CE over CE on several machine translation datasets, WMT'16 Ro-En, WMT'16 Ru-En, and WMT' 14 En-De in both teacher forcing and scheduled sampling setups. Furthermore, in WMT'14 En-De, we also find mixed CE consistently outperforms CE on a multi-reference set as well as a challenging paraphrased reference set. We also found the model trained with mixed CE is able to provide a better probability distribution defined over the translation output space. Our code is available at https://github.com/haorannlp/mix.
RI Lu, Wei/AHA-5606-2022
OI Lu, Wei/0000-0003-0827-0382
SN 2640-3498
PY 2021
VL 139
UT WOS:000683104606042
ER

PT C
AU Zhang, YR
   Liu, J
   Kultursay, E
   Kandemir, M
   Pitsianis, N
   Sun, XB
AF Zhang, Yuanrui
   Liu, Jun
   Kultursay, Emre
   Kandemir, Mahmut
   Pitsianis, Nikos
   Sun, Xiaobai
BE DAmbra, P
   Guarracino, M
   Talia, D
TI Scalable Parallelization Strategies to Accelerate NuFFT Data Translation
   on Multicores
SO EURO-PAR 2010 - PARALLEL PROCESSING, PART II
SE Lecture Notes in Computer Science
CT 16th International Euro-Par Conference on Parallel Processing
CY AUG 31-SEP 03, 2010
CL Ischia, ITALY
SP Natl Res Council Italy, High Performance Comp & Networking Inst
AB The non-uniform FFT (NuFFT) has been widely used in many applications. In this paper, we propose two new scalable parallelization strategies to accelerate the data translation step of the NuFFT on multicore machines. Both schemes employ geometric tiling and binning to exploit data locality, and use recursive partitioning and scheduling with dynamic task allocation to achieve load balancing. The experimental results collected from a commercial multicore machine show that, with the help of our parallelization strategies, the data translation step is no longer the bottleneck in the NuFFT computation, even for large data set sizes, with any input sample distribution.
OI Pitsianis, Nikos/0000-0002-7353-3524
SN 0302-9743
EI 1611-3349
BN 978-3-642-15290-0
PY 2010
VL 6272
BP 125
EP +
PN II
UT WOS:000283106500013
ER

PT C
AU Wang, S
   Tu, ZP
   Shi, SM
   Liu, Y
AF Wang, Shuo
   Tu, Zhaopeng
   Shi, Shuming
   Liu, Yang
GP Assoc Computat Linguist
TI On the Inference Calibration of Neural Machine Translation
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB Confidence calibration, which aims to make model predictions equal to the true correctness measures, is important for neural machine translation (NMT) because it is able to offer useful indicators of translation errors in the generated output. While prior studies have shown that NMT models trained with label smoothing are well-calibrated on the ground truth training data, we find that miscalibration still remains a severe challenge for NMT during inference due to the discrepancy between training and inference. By carefully designing experiments on three language pairs, our vork provides in-depth analyses of the correlation between calibration and translation performance as well as linguistic properties of miscalibration and reports a number of interesting findings that might help humans better analyze, understand and improve NMT models. Based on these observations, we further propose a new graduated label smoothing method that can improve both inference calibration and translation performance.
RI Tu, Zhaopeng/AAS-4259-2021
BN 978-1-952148-25-5
PY 2020
BP 3070
EP 3079
UT WOS:000570978203038
ER

PT J
AU Sanchez-Martinez, F
   Forcada, ML
AF Sanchez-Martinez, Felipe
   Forcada, Mikel L.
TI Inferring Shallow-Transfer Machine Translation Rules from Small Parallel
   Corpora
SO JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH
AB This paper describes a method for the automatic inference of structural transfer rules to be used in a shallow-transfer machine translation (MT) system from small parallel corpora. The structural transfer rules are based on alignment templates, like those used in statistical MT. Alignment templates are extracted from sentence-aligned parallel corpora and extended with a set of restrictions which are derived from the bilingual dictionary of the MT system and control their application as transfer rules. The experiments conducted using three different language pairs in the free/open-source MT platform Apertium show that translation quality is improved as compared to word-for-word translation (when no transfer rules are used), and that the resulting translation quality is close to that obtained using hand-coded transfer rules. The method we present is entirely unsupervised and benefits from information in the rest of modules of the MT system in which the inferred rules are applied.
RI Forcada, Mikel/ABG-9539-2020; Sánchez-Martínez, Felipe/G-9689-2016
OI Sánchez-Martínez, Felipe/0000-0002-2295-2630; FORCADA ZUBIZARRETA, Mikel
   L./0000-0003-0843-6442
SN 1076-9757
EI 1943-5037
PY 2009
VL 34
BP 605
EP 635
DI 10.1613/jair.2735
UT WOS:000265865500005
ER

PT C
AU Emami, A
   Chen, SF
AF Emami, Ahmad
   Chen, Stanley F.
GP IEEE
TI MULTI-CLASS MODEL M
SO 2011 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
CT IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP)
CY MAY 22-27, 2011
CL Prague Congress Ctr, Prague, CZECH REPUBLIC
SP Inst Elect & Elect Engineers Signal Processing Soc, IEEE
HO Prague Congress Ctr
AB Model M, a novel class-based exponential language model, has been shown to significantly outperform word n-gram models in state-of-the-art machine translation and speech recognition systems. The model was motivated by the observation that shrinking the sum of the parameter magnitudes in an exponential language model leads to better performance on unseen data. Being a class-based language model, Model M makes use of word classes that are found automatically from training data. In this paper, we extend Model M to allow for different clusterings to be used at different word positions. This is motivated by the fact that words play different roles depending on their position in an n-gram. Experiments on standard NIST and GALE Arabic-to-English development and test sets show improvements in machine translation quality as measured by automatic evaluation metrics.
SN 1520-6149
BN 978-1-4577-0539-7
PY 2011
BP 5516
EP 5519
UT WOS:000296062406056
ER

PT C
AU Mall, S
   Jaiswal, UC
AF Mall, Shachi
   Jaiswal, Umesh Chandra
BE Hoda, MN
TI Evaluation for POS Tagger, Chunk and Resolving Issues in Word Sense
   Disambiguate in Machine Translation for Hindi to English Languages
SO PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON
   COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT
CT 3rd International Conference on Computing for Sustainable Global
   Development (INDIACom)
CY MAR 16-18, 2016
CL New Delhi, INDIA
SP GGSIP Univ, Govt India, Minist Sci & Technol, Dept Sci & Technol, Council Sci & Ind Res, All India Council Tech Educ, Inst Elect & Telecommunicat Engineers, Delhi Ctr, Inst Engn & Technol, Delhi Local Networks, Jagdishprasad Jhabarmal Tibrewala Univ, Bharati Vidyapeeths Inst Comp Applicat & Management, ISTE, Delhi Sect
AB Our paper develops innovative algorithms for machine translation system based on the innovative algorithms for parts of speech tagger, chunking, word sense disambiguate and word translation in English. Parts of speech tagging and chunking for 1657 tokens with 990 phrases for Hindi languages and to calculate the accuracy we created confusion matrix an evaluate Precision, Recall, F-score, Accuracy for chunk accuracy: 81.23%; precision: 66.57%; recall: 73.03%; F-score: 69.65, 90.31, POS accuracy: 94.75%; precision: 90.67%; recall: 93.23%; F-score 91.93. Rule based and learning algorithm (Conditional Random Fields) is used to develop the system.
RI Mall, Dr. Shachi/AHC-4362-2022
OI mall, shachi/0000-0002-4443-4885
BN 978-9-3805-4419-9
PY 2016
BP 14
EP 18
UT WOS:000388117500004
ER

PT C
AU He, YQ
   Ding, L
   Li, Y
AF He, Yanqing
   Ding, Liang
   Li, Ying
BE Yang, M
   Liu, S
TI Research on Domain Adaptation for SMT Based on Specific Domain Knowledge
SO MACHINE TRANSLATION
SE Communications in Computer and Information Science
CT 12th China Workshop on Machine Translation (CWMT)
CY AUG 25-26, 2016
CL Urumqi, PEOPLES R CHINA
SP Chinese Informat Proc Soc China, Chinese Acad Sci, Xinjiang Tech Inst Phys & Chem, GTC Technol Co Ltd, Shenyang YaTrans Network Technol Co Ltd, Guangxi Daring E Commerce Serv Co Ltd, Beijing Lingosail Tech Co Ltd
AB In statistical machine translation, training data usually have the characteristics of diverse sources, multiple themes, different genre, and are often not in accordance with the domain of target text to be translated, resulting in domain adaptive problem. The existing adaptive methods for statistical machine translation aim for the target text and focus on the selection of training data and the adjustment of translation models. These approaches have not specified explicit domain labels for texts or data. This study gives explicit domain labels and uses two examples for specific context knowledge, (1) Domain knowledge based on Chinese Thesaurus are applied to assign domain labels of Chinese Library Classification Number to Chinese texts; (2) Two-dimensional lexicalized domain knowledge, such as Semantic Category and Application Scenarios, is used to label Japanese sentence. Based on the obtained domain labels for development data and test data, the training data can be filtered to achieve the goal of domain consistency. Experiments show that only a part of the training data can gain a comparable translation performance to the whole training data. This shows that the method is efficient and feasible.
SN 1865-0929
EI 1865-0937
BN 978-981-10-3635-4; 978-981-10-3634-7
PY 2016
VL 668
BP 43
EP 60
DI 10.1007/978-981-10-3635-4_5
UT WOS:000431847100005
ER

PT C
AU Rautaray, J
   Hota, A
   Gochhayat, SS
AF Rautaray, Jyotirmayee
   Hota, Asutosh
   Gochhayat, Sai Sankar
BE Behera, HS
   Nayak, J
   Naik, B
   Abraham, A
TI A Shallow Parser-based Hindi to Odia Machine Translation System
SO COMPUTATIONAL INTELLIGENCE IN DATA MINING
SE Advances in Intelligent Systems and Computing
CT 4th International Conference on Computational Intelligence in Data
   Mining (ICCIDM)
CY NOV 11-12, 2017
CL Burla, INDIA
SP Veer Surendra Sai Univ Technol
AB This paper describes a Hindi to Odia machine translation system developed using a popular open-source platform called Apertium. With population of over 1.27 billion, 18 officially recognized languages, 30 regional languages, and over 2000 dialects, the multilingual society of India needs well-developed ICT tools for the citizens to exchange and share information and knowledge between them easily. Though Hindi is the national language of India, still a lot of people of Odisha are unable to understand the information written in Hindi. In this scenario, a suitable Hindi to Odia machine translation system will help the people to understand and use Hindi in a more productive way. For development of such a machine translation system, we decided to use the Apertium platform due to several reasons. It is well suited for building machine translation systems between closely related language pairs, such as Hindi and Odia due to its shallow parser level transfer modules. The use of FST in all the modules makes this much faster as compared to other shallow parser-based platforms. Also, it is available in GPL license under free open-source software. In this paper, we have also demonstrated the linguistic and computational challenges in building linguistic resources for both Hindi and Odia languages. Specifically, the use of TAM (Tense, Aspect, and Modality) concept in transfer module is a unique approach for building transfer rules between Hindi and Odia in Apertium platform. This work can be easily extended to develop MT systems for other Indian language pairs easily.
SN 2194-5357
EI 2194-5365
BN 978-981-10-8055-5; 978-981-10-8054-8
PY 2019
VL 711
BP 51
EP 62
DI 10.1007/978-981-10-8055-5_6
UT WOS:000558382700006
ER

PT C
AU Liang, YL
   Meng, FD
   Xu, JA
   Chen, YF
   Zhou, J
AF Liang, Yunlong
   Meng, Fandong
   Xu, Jinan
   Chen, Yufeng
   Zhou, Jie
GP Assoc Computat Linguist
TI MSCTD: A Multimodal Sentiment Chat Translation Dataset
SO PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS)
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB Multimodal machine translation and textual chat translation have received considerable attention in recent years. Although the conversation in its natural form is usually multimodal, there still lacks work on multimodal machine translation in conversations. In this work, we introduce a new task named Multimodal Chat Translation (MCT), aiming to generate more accurate translations with the help of the associated dialogue history and visual context. To this end, we firstly construct a Multimodal Sentiment Chat Translation Dataset (MSCTD) containing 142,871 English-Chinese utterance pairs in 14,762 bilingual dialogues and 30,370 English-German utterance pairs in 3,079 bilingual dialogues. Each utterance pair, corresponding to the visual context that reflects the current conversational scene, is annotated with a sentiment label. Then, we benchmark the task by establishing multiple baseline systems that incorporate multimodal and sentiment features for MCT. Preliminary experiments on four language directions (English.Chinese and English.German) verify the potential of contextual and multimodal information fusion and the positive impact of sentiment on the MCT task. Additionally, as a by-product of the MSCTD, it also provides two new benchmarks on multimodal dialogue sentiment analysis. Our work can facilitate research on both multimodal chat translation and multimodal dialogue sentiment analysis.(1)
BN 978-1-955917-21-6
PY 2022
BP 2601
EP 2613
UT WOS:000828702302053
ER

PT C
AU Jing, Z
   Zhang, LC
   Jin, CZ
AF Zhang Jing
   Zhang Li-Cui
   Jin Cheng-Zhi
BE Callaghan, V
   Hu, B
   Lin, Z
   Zhang, H
TI A distributed implementation for the seal calculus
SO 2006 1ST INTERNATIONAL SYMPOSIUM ON PERVASIVE COMPUTING AND
   APPLICATIONS, PROCEEDINGS
CT 1st International Symposium on Pervasive Computing and Applications
CY AUG 03-05, 2006
CL Urumchi, PEOPLES R CHINA
SP IEEE Beijing Sect, BCS, UCE, GUT, SDUW, XIFE
AB The Seal calculus is a calculus of mobile computations designed for programming secure distributed applications over large scale open networks such as the Internet. This paper presents a distributed implementation for the Seal calculus based on an abstract machine SAM, a translation from Seal terms to SAM term, a proof of the correctness of such a translation, which asserts that a Seal term and its translation exhibit the same observance behavior, and a prototype Java implementation. The implementation helps to speed up the development of programming languages based on Seal and experimentation of Seal on concrete examples.
BN 1-4244-0325-1
PY 2006
BP 348
EP +
DI 10.1109/SPCA.2006.297596
UT WOS:000240859900064
ER

PT C
AU Thinh, NT
   Tho, TP
   Nga, TTT
AF Nguyen Truong Thinh
   Tuong Phuoc Tho
   Tran Thi Thuy Nga
GP IEEE
TI Robot Supporting for Deaf and Less Hearing People
SO 2017 17TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS
   (ICCAS)
SE International Conference on Control Automation and Systems
CT 17th International Conference on Control, Automation and Systems (ICCAS)
CY OCT 18-21, 2017
CL SOUTH KOREA
SP Korea Tourism Org, Korean Federat Sci & Technol Soc, Jeju Convent & Visitors Bur, Int Convent Ctr Jeju Co Ltd, Seoul Natl Univ, Soft Robot Res Ctr, Jusung Engn Co Ltd, Yujin Robot Co Ltd, RS Automat, RAONTEC Inc, LOT Vacuum Co Ltd, Girls Robot, JEJU St MARYS EYE CTR
AB This paper discusses the development of a service robot for translating spoken language text into signed languages and vice versa. The motivation for our study is the improvement of accessibility to public information announcements for deaf and less hearing people. The robot can translate Vietnamese sign language into speech and recognize Vietnamese/English speech to suitable gesture/sign language. The paper describes the use of service robot in a sign language machine translation system. Several sign language visualization methods were evaluated on the robot. In order to perform this study a machine translation service robot that uses display screen on robot as service-delivery device was developed as well as a 3D avatar. It was concluded that service robot are suitable service-delivery platforms for sign language machine translation systems.
RI Truong Thinh, Nguyen/AAD-7391-2020
OI Tho, Tuong Phuoc/0000-0002-5688-6096
SN 2093-7121
BN 978-89-93215-14-4
PY 2017
BP 889
EP 892
UT WOS:000426974400143
ER

PT C
AU Yang, PC
   Zhang, P
   Chen, BX
   Xie, J
   Luo, WH
AF Yang, Pengcheng
   Zhang, Pei
   Chen, Boxing
   Xie, Jun
   Luo, Weihua
GP Assoc Computat Linguist
TI Context-Interactive Pre-Training for Document Machine Translation
SO 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021)
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 06-11, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, N Amer Chapter, Google Res, Amazon Sci, Apple, Facebook AI, Megagon Labs, Microsoft, Bloomberg Engn, Grammarly, IBM, Vanguard, Duolingo, Babelscape, Human Language Technol, LegalForce
AB Document machine translation aims to translate the source sentence into the target language in the presence of additional contextual information. However, it typically suffers from a lack of doc-level bilingual data. To remedy this, here we propose a simple yet effective context-interactive pre-training approach, which targets benefiting from external large-scale corpora. The proposed model performs inter sentence generation to capture the cross-sentence dependency within the target document, and cross sentence translation to make better use of valuable contextual information. Comprehensive experiments illustrate that our approach can achieve state-of-the-art performance on three benchmark datasets, which significantly outperforms a variety of baselines.
BN 978-1-954085-46-6
PY 2021
BP 3589
EP 3595
UT WOS:000895685603053
ER

PT C
AU Hoang, C
   Le, CA
   Pham, SB
AF Cuong Hoang
   Cuong Anh Le
   Son Bao Pham
BE Xiong, D
   Castelli, E
   Dong, M
   Yen, PTN
TI Improving the Quality of Word Alignment By Integrating Pearson's
   Chi-square Test Information
SO 2012 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP 2012)
SE International Conference on Asian Language Processing
CT International Conference on Asian Language Processing (IALP)
CY NOV 13-15, 2012
CL Hanoi, VIETNAM
SP IEEE, IEEE Comp Soc, Int Res Inst MICA, Hanoi Univ Sci & Technol, Chinese & Oriental Languages Informat Proc Soc (COLIPS), IEEE Singapore Comp Chapter
AB Previous researches mainly focus on the approaches which are essentially inspirited from the log-linear model background in machine learning or other adaptations. However, not a lot of studies deeply focus on improving word-alignment models to enhance the quality of phrase translation table. This research will follow on that approach. The experiments show that this scheme could also improve the quality of the word-alignment component better. Hence, the improvement impacts the quality of translation system in overall around 1% for the BLEU score metric.
RI Le, Cuong Manh/HPE-4613-2023
OI Le, Cuong Manh/0000-0002-8509-4952
SN 2159-1962
EI 2159-1970
BN 978-0-7695-4886-9; 978-1-4673-6113-2
PY 2012
BP 121
EP 124
DI 10.1109/IALP.2012.44
UT WOS:000318948700031
ER

PT C
AU Liu, SJ
   Yang, MY
   Zhao, TJ
AF Liu, Shu-Jie
   Yang, Mu-Yun
   Zhao, Tie-Jun
GP IEEE
TI A cascaded approach to the optimization of translation rules
SO PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   CYBERNETICS, VOLS 1-7
CT 5th International Conference on Machine Learning and Cybernetics
CY AUG 13-16, 2006
CL Dalian, PEOPLES R CHINA
SP IEEE Syst, Man & Cybernet Soc, Hebei Univ, Hong Kong Polytech Univ, Harbin Inst Technol
AB As far as the rule-based machine translation (RBMT) is concerned, the rule acquisition remains as a bottle-neck problem. This paper proposes a cascaded approach to optimize the rule base, which is automatically acquired from the bilingual corpus. Observing the more risk of errors in the upper layer of the parsing tree, we propose in this paper a method which advocates the optimization of rules by a bottom-up strategy so as to take the advantage of correctness of parsing results near the leaf nodes. The experimental results further prove that such cascaded optimization out-performs the usual practice.
OI Yang, Muyun/0000-0002-5940-0266
BN 1-4244-0060-0
PY 2006
BP 4089
EP +
UT WOS:000241452306031
ER

PT C
AU Escolano, C
   Costa-jussa, MR
   Fonollosa, JAR
   Artetxe, M
AF Escolano, Carlos
   Costa-jussa, Marta R.
   Fonollosa, Jose A. R.
   Artetxe, Mikel
GP Assoc Computat Linguist
TI Multilingual Machine Translation: Closing the Gap between Shared and
   Language-specific Encoder-Decoders
SO 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (EACL 2021)
CT 16th Conference of the
   European-Chapter-of-the-Association-for-Computational-Linguistics (EACL)
CY APR 19-23, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, European Chapter, Grammarly, Facebook AI, Bloomberg Engn, LegalForce, Babelscape
AB State-of-the-art multilingual machine translation relies on a universal encoder-decoder, which requires retraining the entire system to add new languages. In this paper, we propose an alternative approach that is based on language-specific encoder-decoders, and can thus be more easily extended to new languages by learning their corresponding modules. So as to encourage a common interlingua representation, we simultaneously train the N initial languages. Our experiments show that the proposed approach outperforms the universal encoder-decoder by 3.28 BLEU points on average, while allowing to add new languages without the need to retrain the rest of the modules. All in all, our work closes the gap between shared and language-specific encoder-decoders, advancing toward modular multilingual machine translation systems that can be flexibly extended in lifelong learning settings.
BN 978-1-954085-02-2
PY 2021
BP 944
EP 948
UT WOS:000863557001002
ER

PT C
AU Saija, K
   Sangeetha, S
   Shah, V
AF Saija, Krunal
   Sangeetha, S.
   Shah, Viral
GP IEEE
TI WordNet Based Sign Language Machine Translation: from English Voice to
   ISL Gloss
SO 2019 IEEE 16TH INDIA COUNCIL INTERNATIONAL CONFERENCE (IEEE INDICON
   2019)
SE Annual IEEE India Conference
CT 16th IEEE-India-Council International Conference (INDICON)
CY DEC 13-15, 2019
CL Rajkot, INDIA
SP IEEE, IEEE India Council, Marwadi Univ
AB Communication is an essential part of human life. For the person with hearing and speaking disability, it is inconvenient to communicate with other people. In this paper, an end-to-end system to convert English voice to Indian Sign Language (ISL) gloss (written form of sign language) is proposed which will help deaf to communicate with others and vice versa. This system accepts English voice as an input and, converts it into the text using the speech recognition. From the recognized English text, ISL gloss is generated using the lexical database called WordNet. The focus of our work is to build a robust sign language machine translation system to convert the English text to ISL gloss using the linguistic database WordNet.
RI S, Sangeetha/V-3705-2017
OI S, Sangeetha/0000-0001-6630-1664
SN 2325-940X
BN 978-1-7281-2327-1
PY 2019
UT WOS:000565452700087
ER

PT J
AU Lo Faro, L
   Thorne, A
   Huang, H
   Charles, P
   Kaisar, M
   Davis, S
   Dengu, F
   Shaheed, S
   Mulvey, J
   Fischer, R
   Nasralla, D
   Kessler, B
   Leuvenink, H
   Friend, P
   Ploeg, R
AF Lo Faro, L.
   Thorne, A.
   Huang, H.
   Charles, P.
   Kaisar, M.
   Davis, S.
   Dengu, F.
   Shaheed, S.
   Mulvey, J.
   Fischer, R.
   Nasralla, D.
   Kessler, B.
   Leuvenink, H.
   Friend, P.
   Ploeg, R.
TI Normothermic Machine Perfusion of the Liver Supports Protein Translation
   and Mitochondrial Function While Reducing Protein Degradation and
   Metabolic Imbalance: A Proteomics Study.
SO AMERICAN JOURNAL OF TRANSPLANTATION
CT American Transplant Congress (ATC)
CY JUN 04-08, 2022
CL ELECTR NETWORK
SN 1600-6135
EI 1600-6143
PD JUN
PY 2022
VL 22
SU 3
SI SI
MA 389
BP 501
EP 502
UT WOS:000842606302385
ER

PT C
AU Nagata, M
   Saito, K
   Yamamoto, K
   Ohashi, K
AF Nagata, Masaaki
   Saito, Kuniko
   Yamamoto, Kazuhide
   Ohashi, Kazuteru
GP COLING
TI A Clustered Global Phrase Reordering Model for Statistical Machine
   Translation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper, we present a novel global reordering model that can be incorporated into standard phrase-based statistical machine translation. Unlike previous local reordering models that emphasize the reordering of adjacent phrase pairs (Tillmann and Zhang, 2005), our model explicitly models the reordering of long distances by directly estimating the parameters from the phrase alignments of bilingual training sentences. In principle, the global phrase reordering model is conditioned on the source and target phrases that are currently being translated, and the previously translated source and target phrases. To cope with sparseness, we use N-best phrase alignments and bilingual phrase clustering, and investigate a variety of combinations of conditioning factors. Through experiments, we show, that the global reordering model significantly improves the translation accuracy of a standard Japanese-English translation task.
BN 978-1-932432-65-7
PY 2006
BP 713
EP 720
UT WOS:000274500200090
ER

PT C
AU Sanchez-Martinez, F
   Perez-Ortiz, JA
   Forcada, ML
AF Sanchez-Martinez, Felipe
   Perez-Ortiz, Juan Antonio
   Forcada, Mikel L.
BE Gelbukh, A
   ReyesGarcia, CA
TI Speeding up target-language driven part-of-speech tagger training for
   machine translation
SO MICAI 2006: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
CT 5th Mexican International Conference on Artificial Intelligence (MICAI
   2006)
CY NOV 13-17, 2006
CL Technol Inst Apizaco, Apizaco, MEXICO
SP SMIA, DGEST, INAOE, ITAM
HO Technol Inst Apizaco
AB When training hidden-Markov-model-based part-of-speech (PoS) taggers involved in machine translation systems in an unsupervised manner the use of target-language information has proven to give better results than the standard Baum-Welch algorithm. The target-language-driven training algorithm proceeds by translating every possible PoS tag sequence resulting from the disambiguation of the words in each source-language text segment into the target language, and using a target-language model to estimate the likelihood of the translation of each possible disambiguation. The main disadvantage of this method is that the number of translations to perform grows exponentially with segment length, translation being the most time-consuming task. In this paper, we present a method that uses a priori knowledge obtained in an unsupervised manner to prune unlikely disambiguations in each text segment, so that the number of translations to be performed during training is reduced. The experimental results show that this new pruning method drastically reduces the amount of translations done during training (and, consequently, the time complexity of the algorithm) without degrading the tagging accuracy achieved.
RI Forcada, Mikel/ABG-9539-2020; Pérez-Ortiz, Juan Antonio/ABE-1266-2021;
   Pérez-Ortiz, Juan Antonio/H-9844-2015; Sánchez-Martínez,
   Felipe/G-9689-2016
OI Pérez-Ortiz, Juan Antonio/0000-0001-7659-8908; Pérez-Ortiz, Juan
   Antonio/0000-0001-7659-8908; Sánchez-Martínez,
   Felipe/0000-0002-2295-2630
SN 0302-9743
EI 1611-3349
BN 978-3-540-49026-5
PY 2006
VL 4293
BP 844
EP +
UT WOS:000244587700081
ER

PT C
AU Cho, WI
   Kim, JW
   Kim, SM
   Kim, NS
AF Cho, Won Ik
   Kim, Ji Won
   Kim, Seok Min
   Kim, Nam Soo
GP Assoc Computat Linguist
TI On Measuring Gender Bias in Translation of Gender-neutral Pronouns
SO GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019)
CT 1st Workshop on Gender Bias in Natural Language Processing (GeBNLP)
CY AUG 02, 2019
CL Florence, ITALY
SP Google, Kaggle
AB Ethics regarding social bias has recently thrown striking issues in natural language processing. Especially for gender-related topics, the need for a system that reduces the model bias has grown in areas such as image captioning, content recommendation, and automated employment. However, detection and evaluation of gender bias in the machine translation systems are not yet thoroughly investigated, for the task being cross-lingual and challenging to define. In this paper, we propose a scheme for making up a test set that evaluates the gender bias in a machine translation system, with Korean, a language with gender-neutral pronouns. Three word/phrase sets are primarily constructed, each incorporating positive/negative expressions or occupations; all the terms are gender-independent or at least not biased to one side severely. Then, additional sentence lists are constructed concerning formality of the pronouns and politeness of the sentences. With the generated sentence set of size 4,236 in total, we evaluate gender bias in conventional machine translation systems utilizing the proposed measure, which is termed here as translation gender bias index (TGBI). The corpus and the code for evaluation is available on-line(1).
BN 978-1-950737-40-6
PY 2019
BP 173
EP 181
UT WOS:000538524700024
ER

PT C
AU Ferdiansyah, V
   Nakagawa, S
AF Ferdiansyah, Veri
   Nakagawa, Seiichi
GP IEEE
TI English to Japanese Spoken Language Translation System for Classroom
   Lectures
SO 2014 INTERNATIONAL CONFERENCE OF ADVANCED INFORMATICS: CONCEPT, THEORY
   AND APPLICATION (ICAICTA)
CT International Conference on Advanced Informatics: Concept, Theory and
   Application (ICAICTA)
CY AUG 20-21, 2014
CL INDONESIA
AB This paper presents our attempt to create English automatic speech recognition (ASR) and English to Japanese statistical machine translation system (SMT). We used MIT OpenCourseWare lectures as our test lecture corpus. Wall Street Journal (WSJ) corpus adapted with MIT OpenCourseWare lectures was used as our acoustic model. MIT OpenCourseWare lecture transcriptions were utilized to create our language model. As for the parallel corpus, we used TED Talks and Japanese-English News Article Alignment Data (JENAAD). Our proposed ASR system can achieve 32.1% word error rate (WER) and our SMT system can achieve 10.95 BLEU.
RI nakagawa, seiichi/L-5543-2019
BN 978-1-4799-5100-0
PY 2014
BP 34
EP 38
UT WOS:000380537600007
ER

PT C
AU Zagar, A
   Robnik-Sikonja, M
AF Zagar, Ales
   Robnik-Sikonja, Marko
BA Mariani, J
BF Mariani, J
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mazo, H
   Odijk, H
   Piperidis, S
TI Slovene SuperGLUE Benchmark: Translation and Evaluation
SO LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION
CT 13th International Conference on Language Resources and Evaluation
   (LREC)
CY JUN 20-25, 2022
CL Marseille, FRANCE
SP Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur
AB We present SuperGLUE benchmark adapted and translated into Slovene using a combination of human and machine translation. We describe the translation process and problems arising due to differences in morphology and grammar. We evaluate the translated datasets in several modes: monolingual, cross-lingual, and multilingual, taking into account differences between machine and human translated training sets. The results show that the monolingual Slovene SloBERTa model is superior to massively multilingual and trilingual BERT models, but these also show a good cross-lingual performance on certain tasks. The performance of Slovene models still lags behind the best English models.
BN 979-10-95546-72-6
PY 2022
BP 2058
EP 2065
UT WOS:000889371702018
ER

PT S
AU Han, CH
   Lavoie, B
   Palmer, M
   Rambow, O
   Kittredge, R
   Korelsky, T
   Kim, N
   Kim, M
AF Han, CH
   Lavoie, B
   Palmer, M
   Rambow, O
   Kittredge, R
   Korelsky, T
   Kim, N
   Kim, M
BE White, JS
TI Handling structural divergences and recovering dropped arguments in a
   Korean/English machine translation system
SO ENVISIONING MACHINE TRANSLATION IN THE INFORMATION FUTURE, PROCEEDINGS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
CT 4th Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 10-14, 2000
CL CUERNAVACA, MEXICO
SP Assoc Machine Translat Americas
AB This paper describes an approach for handling structural divergences and recovering dropped arguments in an implemented Korean to English machine translation system. The approach relies on canonical predicate-argument structures (or dependency structures), which provide a suitable pivot representation for the handling of structural divergences and the recovery of dropped arguments. It can also be converted to and from the interface representations of many off-the-shelf parsers and generators.
OI PALMER, MARTHA/0000-0001-9864-6974
SN 0302-9743
BN 3-540-41117-8
PY 2000
VL 1934
BP 40
EP 53
UT WOS:000174952300005
ER

PT C
AU Miao, GY
   Di, H
   Xu, JN
   Yang, ZC
   Chen, YF
   Ouchi, K
AF Miao, Guoyi
   Di, Hui
   Xu, Jinan
   Yang, Zhongcheng
   Chen, Yufeng
   Ouchi, Kazushige
BE Tang, J
   Kan, MY
   Zhao, D
   Li, S
   Zan, H
TI Improved Quality Estimation of Machine Translation with Pre-trained
   Language Representation
SO NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING (NLPCC 2019), PT I
SE Lecture Notes in Artificial Intelligence
CT 8th CCF International Conference on Natural Language Processing and
   Chinese Computing (NLPCC)
CY OCT 09-14, 2019
CL NW Minzu Univ, Dunhuang, PEOPLES R CHINA
SP China Comp Federat, Dunhuang Acad, State Key Lab Digital Publishing Technol, Lecture Notes Comp Sci, Springer, ACTA Scientiarum Naturalium Univ Pekinensis, China Mobile Res Inst, Tencent AI Lab, JD AI, Gowild, Meituan Dianping, Miaobi, Microsoft, Baidu, GTCOM, Huawei, Xiaomi, Lenovo Res, ByteDance, Keji Data, Gridsum, Sogou, Alibaba, Speech Ocean, Niutrans
HO NW Minzu Univ
AB Translation quality estimation (QE) is a task of estimating the quality of translation output from an unknown machine translation (MT) system without reference at various granularity (sentence/word/phrase) levels, and it has been attracting much attention due to the potential to reduce post-editing human effort. However, QE suffers heavily from the fact that the quality annotation data remain expensive and small. In this paper, we focus on the limited QE data problem and seek to find how to utilize the high level latent features learned by the pre-trained language models for improving QE. Specifically, we explore three strategies to integrate the pre-trained language representations into QE models: (1) a mixed integration model, where the pre-trained language features are mixed with other features for QE; (2) a direct integration model, which regards the pre-trained language model as the only feature extracting component of the entire QE model; and (3) a constrained integration model, where a constraint mechanism is added to optimize the quality prediction based on the direct integration model. Experiments and analysis presented in this paper demonstrate the effectiveness of our approaches on QE task.
SN 0302-9743
EI 1611-3349
BN 978-3-030-32233-5; 978-3-030-32232-8
PY 2019
VL 11838
BP 406
EP 417
DI 10.1007/978-3-030-32233-5_32
UT WOS:000570006100032
ER

PT J
AU Bywood, L
   Georgakopoulou, P
   Etchegoyhen, T
AF Bywood, Lindsay
   Georgakopoulou, Panayota
   Etchegoyhen, Thierry
TI Embracing the threat: machine translation as a solution for subtitling
SO PERSPECTIVES-STUDIES IN TRANSLATION THEORY AND PRACTICE
AB Recent decades have brought significant changes in the subtitling industry, both in terms of workflow and in the context of the market for audiovisual translation (AVT). Machine translation (MT), whilst in regular use in the traditional localisation industry, has not seen a significant uptake in the subtitling arena. The SUMAT project, an EU-funded project which ran from 2011 to 2014, had as its aim the building and evaluation of viable MT solutions for the subtitling industry in nine bidirectional language pairs. As part of the project, a year-long large-scale evaluation of the output of the resulting MT engines was carried out by trained subtitlers. This paper reports on the impetus behind the investigation of MT for subtitling, previous work in this field, and discusses some of the results of this evaluation, in particular an attempt to measure the extent of productivity gain or loss for subtitlers using MT as opposed to working in the traditional way. The paper examines opportunities and limitations of MT as a viable option for work of this nature and makes recommendations for the training of subtitle post-editors.
RI Georgakopoulou, Panayota/AAM-2680-2020
OI Georgakopoulou, Panayota/0000-0001-9780-1813; Bywood,
   Lindsay/0000-0002-1860-6647
SN 0907-676X
EI 1747-6623
PY 2017
VL 25
IS 3
SI SI
BP 492
EP 508
DI 10.1080/0907676X.2017.1291695
UT WOS:000403712900010
ER

PT C
AU Ji, YT
   Hou, HX
   Wu, NE
   Chen, JJ
AF Ji, Yatu
   Hou, Hongxu
   Wu, Nier
   Chen, Junjie
GP Associ Computat Linguist
TI Improving Mongolian-Chinese Neural Machine Translation with
   Morphological Noise
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019:): STUDENT RESEARCH WORKSHOP
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB For the translation of agglutinative language such as typical Mongolian, unknown (UNK) words not only come from the quite restricted vocabulary, but also mostly from misunderstanding of the translation model to the morphological changes. In this study, we introduce a new adversarial training model to alleviate the UNK problem in Mongolian!Chinese machine translation. The training process can be described as three adversarial sub models (generator, value screener and discriminator), playing a win-win game. In this game, the added screener plays the role of emphasizing that the discriminator pays attention to the added Mongolian morphological noise(1) in the form of pseudo-data and improving the training efficiency. The experimental results show that the newly emerged Mongolian!Chinese task is state-of-the-art. Under this premise, the training time is greatly shortened.
OI Ji, Yatu/0000-0001-6460-9921
BN 978-1-950737-47-5
PY 2019
BP 123
EP 135
UT WOS:000521483200016
ER

PT C
AU Lu, JL
   Zhang, JJ
AF Lu, Jinliang
   Zhang, Jiajun
BE Tang, J
   Kan, MY
   Zhao, D
   Li, S
   Zan, H
TI Select the Best Translation from Different Systems Without Reference
SO NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING (NLPCC 2019), PT I
SE Lecture Notes in Artificial Intelligence
CT 8th CCF International Conference on Natural Language Processing and
   Chinese Computing (NLPCC)
CY OCT 09-14, 2019
CL NW Minzu Univ, Dunhuang, PEOPLES R CHINA
SP China Comp Federat, Dunhuang Acad, State Key Lab Digital Publishing Technol, Lecture Notes Comp Sci, Springer, ACTA Scientiarum Naturalium Univ Pekinensis, China Mobile Res Inst, Tencent AI Lab, JD AI, Gowild, Meituan Dianping, Miaobi, Microsoft, Baidu, GTCOM, Huawei, Xiaomi, Lenovo Res, ByteDance, Keji Data, Gridsum, Sogou, Alibaba, Speech Ocean, Niutrans
HO NW Minzu Univ
AB In recent years, neural machine translation (NMT) has made great progress. Different models, such as neural networks using recurrence, convolution and self-attention, have been proposed and various online translation systems can be available. It becomes a big challenge on how to choose the best translation among different systems. In this paper, we attempt to tackle this task and it can be intuitively considered as the Quality Estimation (QE) problem that requires enough human-annotated data in which each translation hypothesis is scored by human. However, we do not have rich data with high-quality human annotations in practice. To solve this problem, we resort to bilingual training data and propose a new method of mixed MT metrics to automatically score the translation hypotheses from different systems with their references so as to construct the pseudo human-annotated data. Based on the pseudo training data, we further design a novel QE model based on Multi-BERT and Bi-RNN with a joint-encoding strategy. Extensive experiments demonstrate that our proposed method can achieve promising results for the task to select the best translation from various systems.
SN 0302-9743
EI 1611-3349
BN 978-3-030-32233-5; 978-3-030-32232-8
PY 2019
VL 11838
BP 355
EP 366
DI 10.1007/978-3-030-32233-5_28
UT WOS:000570006100028
ER

PT C
AU Aliannejadi, M
   Khadivi, S
   Ghidary, SS
   Bokaei, MH
AF Aliannejadi, Mohammad
   Khadivi, Shahram
   Ghidary, Saeed Shiry
   Bokaei, Mohammad Hadi
BE Movaghar, A
   Jamzad, M
   Asadi, H
TI Discriminative Spoken Language Understanding Using Statistical Machine
   Translation Alignment Models
SO ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING, AISP 2013
SE Communications in Computer and Information Science
CT International Symposium on Artificial Intelligence and Signal Processing
   (AISP)
CY DEC 25-26, 2013
CL Sharif Univ Technol, Dept Comp Engn, Tehran, IRAN
HO Sharif Univ Technol, Dept Comp Engn
AB In this paper, we study the discriminative modeling of Spoken Language Understanding (SLU) using Conditional Random Fields (CRF) and Statistical Machine Translation (SMT) alignment models. Previous discriminative approaches to SLU have been dependent on n-gram features. Other previous works have used SMT alignment models to predict the output labels. We have used SMT alignment models to align the abstract labels and trained CRF to predict the labels. We show that the state transition features improve the performance. Furthermore, we have compared the proposed method with two baseline approaches; Hidden Vector States (HVS) and baseline-CRF. The results show that for the F-measure the proposed method outperforms HVS by 1.74% and baseline-CRF by 1.7% on ATIS corpus.
RI Ghidary, Saeed Shiry/AAH-7276-2021
OI Ghidary, Saeed Shiry/0000-0002-9019-3947; Aliannejadi,
   Mohammad/0000-0002-9447-4172
SN 1865-0929
EI 1865-0937
BN 978-3-319-10848-3
PY 2014
VL 427
BP 194
EP +
DI 10.1007/978-3-319-10849-0_20
UT WOS:000349603700020
ER

PT C
AU Saini, N
   Khatri, J
   Jyothi, P
   Bhattacharyya, P
AF Saini, Nikhil
   Khatri, Jyotsana
   Jyothi, Preethi
   Bhattacharyya, Pushpak
GP Assoc Comp Linguist
TI Generating Fluent Translations from Disfluent Text Without Access to
   Fluent References: IIT Bombay@IWSLT2020
SO 17TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE TRANSLATION (IWSLT
   2020)
CT 17th International Conference on Spoken Language Translation (IWSLT)
CY JUL 09-10, 2020
CL ELECTR NETWORK
AB Machine translation systems perform reasonably well when the input is well-formed speech or text. Conversational speech is spontaneous and inherently consists of many disfluencies. Producing fluent translations of disfluent source text would typically require parallel disfluent to fluent training data. However, fluent translations of spontaneous speech are an additional resource that is tedious to obtain. This work describes the submission of IIT Bombay to the Conversational Speech Translation challenge at IWSLT 2020. We specifically tackle the problem of disfluency removal in disfluent-to-fluent text-to-text translation assuming no access to fluent references during training. Common patterns of disfluency are extracted from disfluent references and a noise induction model is used to simulate them starting from a clean monolingual corpus. This synthetically constructed dataset is then considered as a proxy for labeled data during training We also make use of additional fluent text in the target language to help generate fluent translations. This work uses no fluent references during training and beats a baseline model by a margin of 4.21 and 3.11 BLEU points where the baseline uses disfluent and fluent references, respectively.
BN 978-1-952148-07-1
PY 2020
BP 178
EP 186
UT WOS:000563427100022
ER

PT C
AU Wang, Q
   Li, B
   Liu, JQ
   Jiang, BJ
   Zhang, ZY
   Li, YQ
   Lin, Y
   Xiao, T
   Zhu, JB
AF Wang, Qiang
   Li, Bei
   Liu, Jiqiang
   Jiang, Bojian
   Zhang, Zheyang
   Li, Yinqiao
   Lin, Ye
   Xiao, Tong
   Zhu, Jingbo
BE Chen, J
   Zhang, J
TI Towards Building a Strong Transformer Neural Machine Translation System
SO MACHINE TRANSLATION, CWMT 2018
SE Communications in Computer and Information Science
CT 14th China Workshop on Machine Translation (CWMT)
CY OCT 25-26, 2018
CL Wuyi Univ, Wuyishan, PEOPLES R CHINA
SP Chinese Informat Proc Soc China, Fujian Assoc Artificial Intelligence, Wuyi Univ, KINGSOFT, Beijing Sogou Technol Dev Co Ltd, Global Tone Commun Technol Co Ltd, Shenyang YaTrans Network Technol Co, Yunyi Technol Co Ltd, Tencent Technol Co Ltd, Youdao, Teksbotics
HO Wuyi Univ
AB Transformer model based on self-attention mechanism [17] has achieved state-of-the-art in recent evaluations. However, it is still unclear how much room there is for improvement of the translation system based on this model. In this paper we further explore how to build a stronger neural machine system from four aspects, including architectural improvements, diverse ensemble decoding, reranking, and postprocessing. Experimental results on CWMT-18 Chinese. English tasks show that our approach can consistently improve the translation performance of 2.3-3.8 BLEU points than the strong baseline. Particularly, we find that ensemble decoding with a large number of diverse models is crucial for significant improvement.
SN 1865-0929
EI 1865-0937
BN 978-981-13-3083-4; 978-981-13-3082-7
PY 2019
VL 954
BP 101
EP 110
DI 10.1007/978-981-13-3083-4_10
UT WOS:000833545400010
ER

PT C
AU Zhang, M
   Ogata, K
   Nakamura, M
AF Zhang, Min
   Ogata, Kazuhiro
   Nakamura, Masaki
BE Dong, JS
   Zhu, HB
TI Specification Translation of State Machines from Equational Theories
   into Rewrite Theories
SO FORMAL METHODS AND SOFTWARE ENGINEERING
SE Lecture Notes in Computer Science
CT 12th International Conference on Formal Engineering Methods
CY NOV 17-19, 2010
CL Shanghai, PEOPLES R CHINA
SP E China Normal Univ, Software Engn Inst
AB Specifications of state machines in CafeOBJ are called equational theory specifications (EQT Specs) which are based on equational logic, and in Maude are called rewrite theory specifications (RWT Specs) which are based on rewriting logic. The translation from EQT Specs to RWT Specs achieves the collaboration between CafeOBJ's theorem proving facilities and Maude's model checking facilities. However, translated specifications by existing strategies are of inefficiency and rarely used for model checking in practice. This paper defines a specific class of EQT Specs called EADS Specs, and proposes a strategy for the translation from :EADS Specs to RANT Specs. It is proved that translated specifications by the strategy are more efficient than those by existing strategies.
RI Ogata, Kazuhiro/AAV-1342-2020; Zhang, Min/AAY-2920-2021
OI Ogata, Kazuhiro/0000-0002-4441-3259; Zhang, Min/0000-0003-1938-2902
SN 0302-9743
BN 978-3-642-16900-7
PY 2010
VL 6447
BP 678
EP +
UT WOS:000289182700044
ER

PT C
AU Geraldo, AP
   Moreira, VP
   Goncalves, MA
AF Geraldo, Andre Pinto
   Moreira, Viviane P.
   Goncalves, Marcos A.
BE Karlgren, J
   Tarhio, J
   Hyyro, H
TI On-Demand Associative Cross-Language Information Retrieval
SO STRING PROCESSING AND INFORMATION RETRIEVAL, PROCEEDINGS
SE Lecture Notes in Computer Science
CT 16th International Symposium on String Processing and Information
   Retrieval
CY AUG 25-27, 2009
CL Saariselka, FINLAND
SP Univ Tampere, Dept Comp Sci, Federat Finnish Learned Soc, Yahoo Res, Univ Helsinki, Dept Comp Sci, Swedish Inst Comp Sci
AB This paper proposes the use of algorithms for mining association rules as an approach for Cross-Language Information Retrieval. These algorithms have been widely used to analyse market basket data. The idea is to map the problem of Finding associations between sales items to the problem of finding term translations over a parallel corpus. The proposal was validated by means of experiments using queries in two distinct languages: Portuguese and Finnish to retrieve documents in English. The results show that the performance of our proposed approach is comparable to the performance of the monolingual baseline and to query translation via machine translation, even though these systems employ more complex Natural Language Processing techniques. The combination between machine translation and our approach yielded the best results, even outperforming the monolingual baseline.
OI Moreira, Viviane/0000-0003-4400-054X; Goncalves, Marcos
   Andre/0000-0002-2075-3363
SN 0302-9743
EI 1611-3349
BN 978-3-642-03783-2
PY 2009
VL 5721
BP 165
EP +
UT WOS:000273239500016
ER

PT C
AU Bergmanis, T
   Pinnis, M
AF Bergmanis, Toms
   Pinnis, Marcis
GP Assoc Computat Linguist
TI Facilitating Terminology Translation with Target Lemma Annotations
SO 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (EACL 2021)
CT 16th Conference of the
   European-Chapter-of-the-Association-for-Computational-Linguistics (EACL)
CY APR 19-23, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, European Chapter, Grammarly, Facebook AI, Bloomberg Engn, LegalForce, Babelscape
AB Most of the recent work on terminology integration in machine translation has assumed that terminology translations are given already inflected in forms that are suitable for the target language sentence. In day-to-day work of professional translators, however, it is seldom the case as translators work with bilingual glossaries where terms are given in their dictionary forms; finding the right target language form is part of the translation process. We argue that the requirement for apriori specified target language forms is unrealistic and impedes the practical applicability of previous work. In this work, we propose to train machine translation systems using a source-side data augmentation method' that annotates randomly selected source language words with their target language lemmas. We show that systems trained on such augmented data are readily usable for terminology integration in real-life translation scenarios. Our experiments on terminology translation into the morphologically complex Baltic and Uralic languages show an improvement of up to 7 BLEU points over baseline systems with no means for terminology integration and an average improvement of 4 BLEU points over the previous work. Results of the human evaluation indicate a 47.7% absolute improvement over the previous work in term translation accuracy when translating into Latvian.
BN 978-1-954085-02-2
PY 2021
BP 3105
EP 3111
UT WOS:000863557003017
ER

PT C
AU Waijanya, S
   Mingkhwan, A
AF Waijanya, Sajjaporn
   Mingkhwan, Anirach
GP IEEE
TI Thai Poetry Translation to English with Backward Translation Evaluation
SO 2014 NINTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT
   (ICDIM)
CT 9th International Conference on Digital Information Management (ICDIM)
CY SEP 29-OCT 01, 2014
CL Phitsanulok, THAILAND
SP DLINE, Phranakhon Rajabhat Univ, IEEE Technol Management Council
AB The Poetry is an art form of literary works. Poetry Machine Translator is problematic area challenging. It is very important that output of poetry translation should still be poetry. Evaluation of translation will show the quality of translator but Evaluation is still a research topic in itself. This paper will focus on the Thai poetry type "Klonn-Pad" and aim to translate into English keeping terms of prosody. The results of translation between Forward and Backward translation will be compared by BLEU (Bilingual Evaluation Understudy) metric and METEOR (Metric for Evaluation of Translation with Explicit Ordering). The original (Thai) language L1 translates to the target language L2. The result of Forward L1 to L2 is L2out and the result of Backward L2 to L1 is L1out. The BLEU score of Forward (L2out) equaled 0.795, Backward (L1out) equaled 0.885. The METEOR score of Forward (L2out) Precision equaled 0.863, Recall equaled 0.791 and F-Measure equaled 0.840. For Backward (L1out) Precision equaled 0.850, Recall equaled 0.863 and F-Measure equaled 0.856. Based on this study, it can be concluded that the Backward Translation can validate and evaluate quality the Thai poetry machine translators with Poetry's dictionary and Tuning Module. Thus, it is necessary and reasonable that Dictionary of Thai poetry should be develop and improve.
RI Waijanya, Sajjaporn/AAX-5849-2021
OI Waijanya, Sajjaporn/0000-0002-8321-2679
BN 978-1-4799-5421-6
PY 2014
BP 248
EP 253
UT WOS:000364918800043
ER

PT C
AU Garcia, SKB
   Lucero, ES
   Huerta, EB
   Hernandez, JCH
   Cruz, JFR
   Mendez, BEP
AF Bello Garcia, Sergio Khalil
   Sanchez Lucero, Eduardo
   Bonilla Huerta, Edmundo
   Hernandez Hernandez, Jose Crispin
   Ramirez Cruz, Jose Federico
   Pedroza Mendez, Blanca Estela
BE Batyrshin, I
   Gelbukh, A
   Sidorov, G
TI Nahuatl Neural Machine Translation Using Attention Based Architectures:
   A Comparative Analysis for RNNs and Transformers as a Mobile Application
   Service
SO ADVANCES IN SOFT COMPUTING (MICAI 2021), PT II
SE Lecture Notes in Artificial Intelligence
CT 20th Mexican International Conference on Artificial Intelligence (MICAI)
CY OCT 25-30, 2021
CL ELECTR NETWORK
SP Mexican Soc Artificial Intelligence, Inst Politecnico Nacl, Ctr Comp Res
AB Machine Translation is a problem that consists of automating the task of translating a sentence into another target language done by a computer, and is still in research, especially with low-resource languages. The neoteric introduction of attention techniques inside the Natural Language Processing (NLP) field in coalescence with a broader disposal of word-segmentation and Web Scrapping techniques; including the lack of a proper online tool translation for Nahuatl dialect, inspired this work in an effort to produce such a tool. Once availability of suitable corpus via Web Scrapping is searched for with scrutiny, therefore, doubling the state of the art in parallel phrases; several vocabulary files were produced using two sorts of word segmentation tools in order to extract the morphemes and break down the agglutination Nahuatl contains. By performing a comparative analysis between Recurrent Neural Networks (RNNs) and Transformers, incorporating two segmentation techniques and two different corpus, it is possible to improve the state of the art regarding Nahuatl by more than four times the BLEU score (66.45) with second validation by using a Fuzzy similarity library. Such experiments confirmed the hypothesis that by increasing the corpus size by double, using transformers and sub-word segmentation, a translation from Spanish to Nahuatl is the best approach that can be accomplished so far with the current tools; outperforming many times Statistical Machine Translation (SMT) and RNNs which do not contain attention, plus the deployment of an application that serves as a platform for the language.
SN 0302-9743
EI 1611-3349
BN 978-3-030-89820-5; 978-3-030-89819-9
PY 2021
VL 13068
BP 120
EP 139
DI 10.1007/978-3-030-89820-5_10
UT WOS:000769230400010
ER

PT J
AU Yang, MM
   Wang, R
   Chen, KH
   Wang, X
   Zhao, TJ
   Zhang, M
AF Yang, Mingming
   Wang, Rui
   Chen, Kehai
   Wang, Xing
   Zhao, Tiejun
   Zhang, Min
TI A Novel Sentence-Level Agreement Architecture for Neural Machine
   Translation
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB In neural machine translation (NMT), there is a natural correspondence between source and target sentences. The traditional NMT method does not explicitly model the translation agreement on sentence-level. In this article, we propose a comprehensive and novel sentence-level agreement architecture to alleviate this problem. It directly minimizes the difference between the representations of the source-side and target-side sentence on sentence-level. First, we compare a variety of sentence representation strategies and propose a "Gated Sum" sentence representation to achieve better sentence semantic information. Then, rather than a single-layer sentence-level agreement architecture, we further propose a multi-layer sentence agreement architecture to make the source and target semantic spaces closer layer by layer. The proposed agreement module can be integrated into NMT as an additional training objective function, and can also be used to enhance the representation of the source-side sentences. Experiments on the NIST Chinese-to-English and the WMT English-to-German translation tasks show that the proposed agreement architecture achieves significant improvements over state-of-the-art baselines, demonstrating the effectiveness and necessity of exploiting sentence-level agreement for NMT.
RI Chen, Kehai/ABF-1874-2020
OI Yang, Mingming/0000-0001-9896-3232
SN 2329-9290
EI 2329-9304
PY 2020
VL 28
BP 2585
EP 2597
DI 10.1109/TASLP.2020.3021347
UT WOS:000571715800002
ER

PT C
AU Calixto, I
   Liu, Q
   Campbell, N
AF Calixto, Iacer
   Liu, Qun
   Campbell, Nick
BE Barzilay, R
   Kan, MY
TI Doubly-Attentive Decoder for Multi-modal Neural Machine Translation
SO PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1
CT 55th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 30-AUG 04, 2017
CL Vancouver, CANADA
SP Alibaba Grp, Amazon, Apple, Baidu, Bloomberg, Facebook, Google, Samsung, Tencent, eBay, Elsevier, IBM Res, KPMG, Maluuba, Microsoft, Naver Line, NEC, Recruit Inst Technol, SAP, Adobe, Bosch, CVTE, Duolingo, Huawei, Nuance, Oracle, Sogou, Grammarly, Toutiao, Yandex
AB We introduce a Multi-modal Neural Machine Translation model in which a doubly-attentive decoder naturally incorporates spatial visual features obtained using pre-trained convolutional neural networks, bridging the gap between image description and translation. Our decoder learns to attend to source-language words and parts of an image independently by means of two separate attention mechanisms as it generates words in the target language. We find that our model can efficiently exploit not just back-translated in-domain multi-modal data but also large general-domain text-only MT corpora. We also report state-of-the-art results on the Multi30k data set.
OI Coimbra Alves Cavalcanti Calixto, Iacer/0000-0001-6244-7906
BN 978-1-945626-75-3
PY 2017
BP 1913
EP 1924
DI 10.18653/v1/P17-1175
UT WOS:000493984800175
ER

PT C
AU Fadaee, M
   Monz, C
AF Fadaee, Marzieh
   Monz, Christof
GP Assoc Computat Linguist
TI The Unreasonable Volatility of Neural Machine Translation Models
SO NEURAL GENERATION AND TRANSLATION
CT 4th Workshop on Neural Generation and Translation
CY JUL 05-10, 2020
CL ELECTR NETWORK
AB Recent works have shown that while Neural Machine Translation (NMT) models achieve impressive performance, questions about understanding the behaviour of these models remain unanswered. We investigate the unexpected volatility of NMT models where the input is semantically and syntactically correct. We discover that with trivial modifications of source sentences, we can identify cases where unexpected changes happen in the translation and in the worst case lead to mistranslations. This volatile behaviour of translating extremely similar sentences in surprisingly different ways highlights the underlying generalization problem of current NMT models. We find that both RNN and Transformer models display volatile behaviour in 26% and 19% of sentence variations, respectively.
OI Fadaee, Marzieh/0000-0002-4447-1213
BN 978-1-952148-17-0
PY 2020
BP 88
EP 96
UT WOS:000563428500010
ER

PT C
AU Di, P
   Gong, ZX
   Zhou, GD
AF Di, Ping
   Gong, Zhengxian
   Zhou, Guodong
BE Zhu, Q
   Ji, D
   Sun, M
   Zhou, G
TI Comparing the methods of filtering phrases for SMT
SO 11TH CHINESE LEXICAL SEMANTICS WORKSHOP (CKSW2010)
CT 11th Chinese Lexical Semanties Workshop (CLSW2010)
CY MAY 21-23, 2010
CL Soochow Univ, Suzhou, PEOPLES R CHINA
SP Soochow Univ, Sch Comp Sci & Technol, Soochow Univ, Nat Language Process Lab
HO Soochow Univ
AB Most of phrase-based statistical machine translation systems treat word sequences as phrases, whose rationality is not considering. This paper presents two effective methods, C-value and phrase Cohesion value, to discard some entries of a phrase table. With these approaches, we not only reduce search spaces but also keep and even improve the translation performance. Experiments show that the phrase table can be reduced to 78,% with a 0.02 rise in the BLUE score. And the phrase table can be reduced to 47.5% with a 0.0158 rise in the BLUE score.
RI 贡, 正仙/HNJ-1571-2023
BN 978-981-08-8260-0
PY 2010
BP 454
EP 459
UT WOS:000398764800066
ER

PT C
AU Dilshani, WSN
   Yashothara, S
   Uthayasanker, RT
   Jayasena, S
AF Dilshani, W. S. N.
   Yashothara, S.
   Uthayasanker, R. T.
   Jayasena, S.
BE Dong, M
   Bijaksana, MA
   Sujaini, H
   Bijaksana, A
   Romadhony, A
   Ruskanda, FZ
   Nurfadhilah, E
   Aini, LR
TI Linguistic Divergence of Sinhala and Tamil languages in Machine
   Translation
SO 2018 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP)
SE International Conference on Asian Language Processing
CT International Conference on Asian Language Processing (IALP)
CY NOV 15-17, 2018
CL Telkom Univ, Bandung, INDONESIA
SP Indonesia Assoc Computat Lingust, COLIPS, Telkon Univ, IEEE, IEEE, Indonesia Sect Comp Soc Chapter
HO Telkom Univ
AB This paper presents a study of the lexical-semantic divergence between Sinhala and Tamil languages. Study of divergence is critical as differences in linguistic and extra-linguistic features in languages play pivotal roles in translation. This research the first study of the divergence between Sinhala and Tamil languages and is based on Dorr's classification. We propose a computer-assisted divergence study procedure using statistical machine translation, which is easy and gives good performance compared to traditional approaches. Accordingly, this research has the twin aims of revisiting classification of divergence types as outlined by Dorr and outlining some of the new divergence patterns specific to Sinhala and Tamil languages. This study proposes a rule-based algorithm to classify a divergence.
RI Jayasena, Sanath/GXV-8641-2022
SN 2159-1962
EI 2159-1970
BN 978-1-7281-1176-6
PY 2018
BP 13
EP 18
UT WOS:000458678200003
ER

PT J
AU Zhao, LX
   Gao, WR
   Fang, JB
AF Zhao, Lanxin
   Gao, Wanrong
   Fang, Jianbin
TI High-Performance English-Chinese Machine Translation Based on
   GPU-Enabled Deep Neural Networks with Domain Corpus
SO APPLIED SCIENCES-BASEL
AB The ability to automate machine translation has various applications in international commerce, medicine, travel, education, and text digitization. Due to the different grammar and lack of clear word boundaries in Chinese, it is challenging to conduct translation from word-based languages (e.g., English) to Chinese. This article has implemented a GPU-enabled deep learning machine translation system based on a domain-specific corpus. Our system takes English text as input and uses an encoder-decoder model with an attention mechanism based on Google's Transformer to translate the text to Chinese output. The model was trained using a simple self-designed entropy loss function and an Adam optimizer on English-Chinese bilingual text sentences from the News area of the UM-Corpus. The parallel training process of our model can be performed on common laptops, desktops, and servers with one or more GPUs. At training time, we not only track loss over training epochs but also measure the quality of our model's translations with the BLEU score. We also provide an easy-to-use web interface for users so as to manage corpus, training projects, and trained models. The experimental results show that we can achieve a maximum BLEU score of 29.2. We can further improve this score by tuning other hyperparameters. The GPU-enabled model training runs over 15x faster than on a multi-core CPU, which facilitates us having a shorter turn-around time. As a case study, we compare the performance of our model to that of Baidu's, which shows that our model can compete with the industry-level translation system. We argue that our deep-learning-based translation system is particularly suitable for teaching purposes and small/medium-sized enterprises.
EI 2076-3417
PD NOV
PY 2021
VL 11
IS 22
AR 10915
DI 10.3390/app112210915
UT WOS:000723968300001
ER

PT J
AU Wang, YJ
   Xia, YC
   Zhao, L
   Bian, J
   Qin, T
   Chen, EH
   Liu, TY
AF Wang, Yijun
   Xia, Yingce
   Zhao, Li
   Bian, Jiang
   Qin, Tao
   Chen, Enhong
   Liu, Tie-Yan
TI Semi-Supervised Neural Machine Translation via Marginal Distribution
   Estimation
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB Neural machine translation (NMT) heavily relies on parallel bilingual corpora for training. Since large-scale, high-quality parallel corpora are usually costly to collect, it is appealing to exploit monolingual corpora to improve NMT. Inspired by the law of total probability, which connects the probability of a given target-side monolingual sentence to the conditional probability of translating from a source sentence to the target one, we propose to explicitly exploit this connection and help the training procedure of NMT models using monolingual data. The key technical challenge of this approach is that there are exponentially many source sentences for a target monolingual sentence while computing the sum of the conditional probability given each possible source sentence. We address this challenge by leveraging the reverse translation model (target-to-source translation model) to sample several mostly likely source-side sentences and avoid enumerating all possible candidate source sentences. Then we propose two different methods to leverage the law of total probability, including marginal distribution regularization and likelihood maximization of monolingual corpora. Experiment results on English -> French and German -> English tasks demonstrate that our methods achieve significant improvement over several strong baselines.
RI Wang, Yijun/GXW-1763-2022
OI wang, yijun/0000-0002-3372-8167; Chen, Enhong/0000-0002-4835-4102; Qin,
   Tao/0000-0002-9095-0776
SN 2329-9290
EI 2329-9304
PD OCT
PY 2019
VL 27
IS 10
BP 1564
EP 1576
DI 10.1109/TASLP.2019.2921423
UT WOS:000476790000001
ER

PT C
AU Zhang, P
   Xu, XY
   Xiong, DY
AF Zhang, Pei
   Xu, Xueying
   Xiong, Deyi
BE Dong, M
   Bijaksana, MA
   Sujaini, H
   Bijaksana, A
   Romadhony, A
   Ruskanda, FZ
   Nurfadhilah, E
   Aini, LR
TI Active Learning For Neural Machine Translation
SO 2018 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP)
SE International Conference on Asian Language Processing
CT International Conference on Asian Language Processing (IALP)
CY NOV 15-17, 2018
CL Telkom Univ, Bandung, INDONESIA
SP Indonesia Assoc Computat Lingust, COLIPS, Telkon Univ, IEEE, IEEE, Indonesia Sect Comp Soc Chapter
HO Telkom Univ
AB Neural machine translation (NMT) normally requires a large bilingual corpus to train a high-translationquality model. However, building such parallel corpora for many low-resource language pairs is rather expensive. In this paper, we propose to select informative source sentences to build a parallel corpus under the active learning framework so as to reduce the cost of manual translation as much as possible. Particularly, we propose two novel and effective sentence selection methods for active learning: selection based on semantic similarity and decoder probability. Experiments on Indonesian-English and Chinese-English show that our selection approaches are superior to random selection and two conventional selection methods.
SN 2159-1962
EI 2159-1970
BN 978-1-7281-1176-6
PY 2018
BP 153
EP 158
UT WOS:000458678200029
ER

PT C
AU Ding, CC
   Yamamoto, M
AF Ding, Chenchen
   Yamamoto, Mikio
BE Wan, WG
   Luo, FL
   Yu, XQ
TI To Filter Discontinuous Word Alignment for Statistical Machine
   Translationaper
SO 2014 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING
   (ICALIP), VOLS 1-2
CT International Conference on Audio, Language and Image Processing
CY JUL 07-09, 2014
CL Shanghai, PEOPLES R CHINA
AB We propose a language-independent approach to clean up word alignment errors in an aligned parallel corpus, which are caused by the unsupervised word-align process. In such an aligned corpus, we evaluate the alignment patterns of one-to-many discontinuous words by statistical measures of collocation. The alignment of discontinuous words without strong collocation tendencies will be taken as errors and deleted. We conduct experiments on two-directional Japanese-English and German-English translation tasks. The experiment results show the state-of-the-art word alignment filtered by the proposed approach can lead to a better translation performance.
BN 978-1-4799-3903-9
PY 2014
BP 449
EP 453
UT WOS:000380438100090
ER

PT J
AU Zhang, B
   Xiong, DY
   Su, JS
   Duan, H
AF Zhang, Biao
   Xiong, Deyi
   Su, Jinsong
   Duan, Hong
TI A Context-Aware Recurrent Encoder for Neural Machine Translation
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB Neural machine translation (NMT) heavily relies on its encoder to capture the underlying meaning of a source sentence so as to generate a faithful translation. However, most NMT encoders are built upon either unidirectional or bidirectional recurrent neural networks, which either do not deal with future context or simply concatenate the history and future context to form context-dependent word representations, implicitly assuming the independence of the two types of contextual information. In this paper, we propose a novel context-aware recurrent encoder (CAEncoder), as an alternative to the widely-used bidirectional encoder, such that the future and history contexts can be fully incorporated into the learned source representations. Our CAEncoder involves a two-level hierarchy: The bottom level summarizes the history information, whereas the upper level assembles the summarized history and future context into source representations. Additionally, CAEncoder is as efficient as the bidirectional RNN encoder in terms of both training and decoding. Experiments on both Chinese-English and English-German translation tasks show that CAEncoder achieves significant improvements over the bidirectional RNN encoder on a widely-used NMT system.(1)
OI Xiong, Deyi/0000-0002-2353-5038
SN 2329-9290
EI 2329-9304
PD DEC
PY 2017
VL 25
IS 12
BP 2424
EP 2432
DI 10.1109/TASLP.2017.2751420
UT WOS:000417743800016
ER

PT J
AU Salami, S
   Shamsfard, M
   Khadivi, S
AF Salami, Shahram
   Shamsfard, Mehrnoush
   Khadivi, Shahram
TI Phrase-boundary model for statistical machine translation
SO COMPUTER SPEECH AND LANGUAGE
AB This paper proposes a new probabilistic synchronous context-free grammar model for statistical machine translation. The model labels nonterminals with classes of boundary words on the target side of aligned phrase pairs. Labeling of the rules is performed with coarse grained and fine grained nonterminals using POS tags and word clusters trained on the target language corpus. Considering the large size of the proposed model due to the diversity of nonterminals, we have also proposed a novel approach for filtered rule extraction based on the alignment pattern of phrase pairs. Using limited patterns of rules, the extraction of hierarchical rules gets restricted from phrase pairs that are decomposable to two aligned subphrases. The proposed filtered rule extraction decreases the model size and the decoding time considerably with no significant impact on the translation quality. Using BLEU as a metric in our experiments, the proposed model achieved a notable improvement rate over the state-of-the-art hierarchical phrase-based model in the translation from Persian, French and Spanish to English language. This is applicable for all languages, even under-resourced ones having no linguistic tools. (C) 2015 Elsevier Ltd. All rights reserved.
RI Shamsfard, Mehrnoush/I-1707-2019; Shamsfard, Mehrnoush/Q-7671-2019
OI Shamsfard, Mehrnoush/0000-0002-7027-7529; 
SN 0885-2308
EI 1095-8363
PD JUL
PY 2016
VL 38
BP 13
EP 27
DI 10.1016/j.csl.2015.11.005
UT WOS:000371900800002
ER

PT C
AU Cherukuri, H
   Ferrari, A
   Spoletini, P
AF Cherukuri, Himaja
   Ferrari, Alessio
   Spoletini, Paola
BE Gervasi, V
   Vogelsang, A
TI Towards Explainable Formal Methods: From LTL to Natural Language with
   Neural Machine Translation
SO REQUIREMENTS ENGINEERING: FOUNDATION FOR SOFTWARE QUALITY, REFSQ 2022
SE Lecture Notes in Computer Science
CT 28th International Working Conference on Requirements Engineering:
   Foundation for Software Quality (REFSQ)
CY MAR 21-24, 2022
CL Birmingham, ENGLAND
SP Aston Univ, Univ Cologne, Durham Univ, Univ Pisa, Univ Politecnica Catalunya, Int Requirements Engn Board, BCS, EPSRC Res Project Twenty20Insight, Springer
AB [Context and motivation] Requirements formalisation facilitates reasoning about inconsistencies, detection of ambiguities, and identification critical issues in system models. Temporal logic formulae are the natural choice when it comes to formalise requirements associated to desired system behaviours. [Question/problem] Understanding and mastering temporal logic requires a formal background. Means are therefore needed to make temporal logic formulae interpretable by engineers, domain experts and other stakeholders involved in the development process. [Principal ideas/results] In this paper, we propose to use a neural machine translation tool, named OPENNMT, to translate Linear Temporal Logic (LTL) formulae into corresponding natural language descriptions. Our results show that the translation system achieves an average BLEU (BiLingual Evaluation Understudy) score of 93.53%, which corresponds to highquality translations. [Contribution] Our neural model can be applied to assess if requirements have been correctly formalised. This can be useful to requirements analysts, who may have limited confidence with LTL, and to other stakeholders involved in the requirements verification process. Overall, our research preview contributes to bridging the gap between formal methods and requirements engineering, and opens to further research in explainable formal methods.
OI SPOLETINI, PAOLA/0000-0001-7922-4936
SN 0302-9743
EI 1611-3349
BN 978-3-030-98464-9; 978-3-030-98463-2
PY 2022
VL 13216
BP 79
EP 86
DI 10.1007/978-3-030-98464-9_7
UT WOS:000784606100007
ER

PT C
AU Wei, XP
   Yu, H
   Hu, Y
   Weng, RX
   Xing, LX
   Luo, WH
AF Wei, Xiangpeng
   Yu, Heng
   Hu, Yue
   Weng, Rongxiang
   Xing, Luxi
   Luo, Weihua
GP Assoc Computat Linguist
TI Uncertainty-Aware Semantic Augmentation for Neural Machine Translation
SO PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL
   LANGUAGE PROCESSING (EMNLP)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 16-20, 2020
CL ELECTR NETWORK
SP Bloomberg Engn, Google Res, Apple, Amazon Sci, Baidu, Megagon Labs, Facebook, DeepMind, Grammarly, ByteDance, Zeta Alpha, Babelscape, Naver, Adobe, Hitachi, Salesforce, Univ So Calif, Viterbi Sch Engn, Informat Sci Inst
AB As a sequence-to-sequence generation task, neural machine translation (NMT) naturally contains intrinsic uncertainty, where a single sentence in one language has multiple valid counterparts in the other. However, the dominant methods for NMT only observe one of them from the parallel corpora for the model training but have to deal with adequate variations under the same meaning at inference. This leads to a discrepancy of the data distribution between the training and the inference phases. To address this problem, we propose uncertainty-aware semantic augmentation, which explicitly captures the universal semantic information among multiple semantically-equivalent source sentences and enhances the hidden representations with this information for better translations. Extensive experiments on various translation tasks reveal that our approach significantly outperforms the strong baselines and the existing methods.
BN 978-1-952148-60-6
PY 2020
BP 2724
EP 2735
UT WOS:000855160702073
ER

PT C
AU Xiao, T
   Zhu, JB
   Zhang, CL
AF Xiao, Tong
   Zhu, Jingbo
   Zhang, Chunliang
BE Toutanova, K
   Wu, H
TI A Hybrid Approach to Skeleton-based Translation
SO PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS, VOL 2
CT 52nd Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUN 22-27, 2014
CL Baltimore, MD
SP Assoc Computat Linguist, Baidu, Bloomberg, Google, Microsoft, Nuance, Yahoo Labs, Informat Sci Inst, Xerox Res Ctr Europe, Brandeis Univ, Facebook, Yandex, Amazon Com, IBM Watson, Johns Hopkins Univ, A9, AI@ISI, Xerox
AB In this paper we explicitly consider sentence skeleton information for Machine Translation (MT). The basic idea is that we translate the key elements of the input sentence using a skeleton translation model, and then cover the remain segments using a full translation model. We apply our approach to a state-of-the-art phrase-based system and demonstrate very promising BLEU improvements and TER reductions on the NIST Chinese-English MT evaluation data.
BN 978-1-937284-73-2
PY 2014
BP 563
EP 568
UT WOS:000493811100092
ER

PT C
AU Shankarappa, RT
   Tiwari, S
AF Shankarappa, Rashmi T.
   Tiwari, Sourabh
GP IEEE
TI A Faster Approach For Direct Speech to Speech Translation
SO 2022 IEEE WOMEN IN TECHNOLOGY CONFERENCE (WINTECHCON): SMARTER
   TECHNOLOGIES FOR A SUSTAINABLE AND HYPER-CONNECTED WORLD
CT IEEE Women in Technology Conference (WINTECHCON) - Smarter Technologies
   for a Sustainable and Hyper-Connected World
CY JUN 02-03, 2022
CL Qualcomm, Bangalore, INDIA
SP IEEE, IEEE Circuits & Syst Soc, Bangalore Chapter, Cadence, Intel, Synopsys, Texas Instruments, Analog Devices, IBM, Infineon, Samsung
HO Qualcomm
AB As the world is pacing towards globalization, the demand for automatic language translators is increasing rapidly. Traditional translation systems consist of multiple steps like speech recognition, text to text machine translation, and speech generation. Issue with these systems are, latency due to multiple steps and error propagation from first steps toward last steps. Another challenge is that many spoken languages do not have text representation, so traditional system involving speech to text and text to text translation do not work. In this paper, we are presenting a recurrent neural network (RNN) based translation system that can generate a direct waveform of target language audio. We have used the sparse coding technique for the extraction and inversion of audio features. An attention-based multi-layered sequence to sequence model is trained using a novel technique on a dataset of Spanish to English audio and no intermediate text representation is used while training or inference. We have done performance comparison of proposed approaches using latency, bilingual evaluation understudy (BLEU) score and Perceptual Evaluation of Speech Quality PESQ score analysis. The resulting system provides a very fast translation with good translation accuracy and audio quality.
OI Tiwari, Sourabh/0000-0001-7641-2149
BN 978-1-6654-8674-3
PY 2022
DI 10.1109/WINTECHCON55229.2022.9832314
UT WOS:000853091500013
ER

PT C
AU Chen, PZ
   Bogoychev, N
   Heafield, K
   Kirefu, F
AF Chen, Pinzhen
   Bogoychev, Nikolay
   Heafield, Kenneth
   Kirefu, Faheem
GP Assoc Computat Linguist
TI Parallel Sentence Mining by Constrained Decoding
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB We present a novel method to extract parallel sentences from two monolingual corpora, using neural machine translation. Our method relies on translating sentences in one corpus, but constraining the decoding by a prefix tree built on the other corpus. We argue that a neural machine translation system by itself can be a sentence similarity scorer and it efficiently approximates pairwise comparison with a modified beam search. When benchmarked on the BUCC shared task, our method achieves results comparable to other submissions.
OI Heafield, Kenneth/0000-0002-6344-9927
BN 978-1-952148-25-5
PY 2020
BP 1672
EP 1678
UT WOS:000570978201087
ER

PT S
AU Lee, HK
AF Lee, HK
BE Richardson, SD
TI Classification approach to word selection in machine translation
SO MACHINE TRANSLATION: FROM RESEARCH TO REAL USERS
SE Lecture Notes in Artificial Intelligence
CT 5th Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 08-12, 2002
CL Tiburon, CA
SP Assoc Machine Translat Americas
AB We present a classification approach to building a English-Korean machine translation (MT) system. We attempt to build a word-based MT system from scratch using a set of parallel documents, online dictionary queries, and monolingual documents on the web. In our approach, MT problem is decomposed into two sub-problems-word selection problem and word ordering problem of the selected words. In this paper, we will focus on the word selection problem and discuss some preliminary results.
SN 0302-9743
EI 1611-3349
BN 3-540-44282-0
PY 2002
VL 2499
BP 114
EP 123
UT WOS:000189412300012
ER

PT C
AU Bacha, K
   Zrigui, M
AF Bacha, Khaireddine
   Zrigui, Mounir
GP IEEE
TI Towards a model of statistical machine translation Arabic-French
SO 2014 WORLD CONGRESS ON COMPUTER APPLICATIONS AND INFORMATION SYSTEMS
   (WCCAIS)
CT World Congress on Computer Applications and Information Systems (WCCAIS)
CY JAN 17-19, 2014
CL Hammamet, TUNISIA
AB The automatic translation of texts of human origin is a very complex application called to apprehend the universe open text, without any constraint on their nature or diversity. To solve this problem, several attempts have been initiated, each having the objective to obtain a better translation quality of the parallel corpora. But before the various ambiguities of the natural language, the problem of translation is far from easy to solve. To do this, and in order to increase the translation quality, we propose a model for the generation of different semantic cases relating to different components of the sentence to determine the meaning first and then generate the translation into the language target. This allowed us to obtain satisfactory results compared to similar studies using other techniques.
   In our approach, we used a model guided by the semantics to learn the techniques of translation with a similar human performance. Our project is to translate source sentences from Arabic to French through a statistical approach that includes a dictionary and that is automatically evaluated by the BLEU metric to ensure encouraging results even if the tools that we use are very limited.
BN 978-1-4799-3351-8
PY 2014
UT WOS:000363271300100
ER

PT J
AU Wang, X
AF Wang, Xi
TI Translation correction of English phrases based on optimized GLR
   algorithm
SO JOURNAL OF INTELLIGENT SYSTEMS
AB Basic syntactic analysis refers to sentence-level syntactic analysis. In the process of developing the Mat Link English-Chinese machine translation system, the Generalized Maximum Likelihood Ratio algorithm was improved, and a basic English syntax analyzer for English-Chinese translation was designed and implemented. The analyzer approves the structure of the analysis table with a variety of export products, introduces the character mapping function to realize the automatic recognition of the sentence boundary, uses the children of the same level to describe the grammatical structure of the sentence, and realizes the proverb from the original sentence to the target sentence stage conversion. Finally, through the analysis of example sentences, the design concept and working process of the basic grammar are explained.
SN 0334-1860
EI 2191-026X
PD JAN
PY 2021
VL 30
IS 1
BP 868
EP 880
DI 10.1515/jisys-2020-0132
UT WOS:000720948500002
ER

PT J
AU Beyala, VL
   Li Litet, P
   Nkenlifack, MJ
AF Beyala, Vivien L.
   Li Litet, Perrin
   Nkenlifack, Marcellin J.
TI Factored Phrase-Based Statistical Machine Pre-training with Extended
   Transformers
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
AB This paper presents the development of a cascaded hybrid multi-lingual automatic translation system, by allowing a tight coupling between the two underlying research approach in machine translation, namely, the neuronal (deterministic approach) and statistical (probabilistic approach), while fully taking advantage of each method in order to improve translation performance. This architecture addresses two major problems frequently occurring when dealing with morphologically richer languages in MT, that is, the significant number unknown tokens generated due to the presence of out of vocabulary (OOV) words, and size of the output vocabulary. Additionally, we incorporated factors (additional word-level linguistic information) in order to alleviate data sparseness problem or potentially reduce language ambiguity, the factors we considered are lemmatization and Part-of-Speech tags (taking into consideration its various compounds). We combined a fully-factored transformer and a factored PB-SMT, where, the training data is pre-translated using the trained fully-factored transformer, and afterwards employed to build an PB-SMT system, parallelly using the pre-translated development set to tune parameters. Finally, in order to produce the desired results, we operated the FPB-SMT system to re-decode the pre-translated test set in a post-processing step. Experiments performed on translations from Japanese to English and English to Japanese reveals that our proposed cascaded hybrid framework outperforms the strong HMT state-of-the-art by over 8.61% BLEU and 7.25% BLEU, respectively, for validation set, and over 8.70% BLEU and 7.70% BLEU, respectively, for test set.
SN 2158-107X
EI 2156-5570
PD SEP
PY 2020
VL 11
IS 9
BP 51
EP 59
UT WOS:000592987700008
ER

PT C
AU Rai, A
   Shrawankar, U
AF Rai, Ashutosh
   Shrawankar, Urmila
BE Mishra, MK
TI Multilanguage Voice Dictionary for Ubiquitous Environment
SO PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS
   AND COMPUTER NETWORKS (ISCON)
CT International Conference on Information Systems and Computer Networks
   (ISCON)
CY MAR 01-02, 2014
CL Mathura, INDIA
SP GLA Univ, Dept Comp Engn & Applicat, IEEE, Comp Soc India
AB Languages in India play an important role as a communication medium. As the person is traveling from one state to another s/he faces difficulty to communicate in other language with other community. So, the Multilanguage Voice Dictionary is applying for developing Indian language Machine Translation system. This application comprises of two algorithms. The word based translation model with the rule-based model is used as the main technique. The word based translation model is implementing for verb and other type of words. The rule based method is particularly used for Out Of Vocabulary (OOV) words which have to be used as it can't be translated. This is performing by extending a lexicon and writing a set of sample words. The translation is doing through templates associated with the lexicon with the word in other language. The speech processing such as input and output in voice form is to be implemented using speech simulator. For the alphabets of a language, the language word library is using in this application.
RI Shrawankar, Urmila/J-8544-2016
OI Shrawankar, Urmila/0000-0003-4523-9501
BN 978-1-4799-2981-8
PY 2014
BP 45
EP 49
UT WOS:000357369300008
ER

PT C
AU Yamouni, F
AF Yamouni, Farida
BE Okrut, T
   Hetsevich, Y
   Silberztein, M
   Stanislavenka, H
TI A French-Tamazight MT System for Computer Science
SO AUTOMATIC PROCESSING OF NATURAL-LANGUAGE ELECTRONIC TEXTS WITH NOOJ
SE Communications in Computer and Information Science
CT 9th International Conference on Automatic Processing of Natural-Language
   Electronic Texts with NooJ (NooJ)
CY JUN 11-13, 2015
CL Natl Acad Sci, United Inst Informat Problems, Minsk, BYELARUS
SP Univ Franche Comte, NooJ Int Assoc, ELLIADD
HO Natl Acad Sci, United Inst Informat Problems
AB Today, industrial and large-audience Machine Translation software are still producing poor quality results. For example when we use Babelfish to translate the compound term: Entrees sorties physiques, we obtain: Entries physical outputs, instead physical input output. Automatic translating software needs increasingly significant and varied terminological resources. Our aim is to develop a French-Tamazight MT system for computer science compound words. NooJ is the linguistic environment of development.
SN 1865-0929
BN 978-3-319-42471-2; 978-3-319-42470-5
PY 2016
VL 607
BP 208
EP 217
DI 10.1007/978-3-319-42471-2_19
UT WOS:000389639600019
ER

PT C
AU Tantug, AC
   Adali, E
   Oflazer, K
AF Tantug, A. Cuneyd
   Adali, Esref
   Oflazer, Kemal
BE Levi, A
   Savas, E
   Yenigun, H
   Balcisory, S
   Saygin, Y
TI Lexical ambiguity resolution for Turkish in direct transfer machine
   translation models
SO COMPUTER AND INFORMATION SCIENCES - ISCIS 2006, PROCEEDINGS
SE Lecture Notes in Computer Science
CT 21st International Symposium on Computer and Information Sciences (ISCIS
   2006)
CY NOV 01-03, 2006
CL Istanbul, TURKEY
SP Sabanci Univ, Fac Engn & Nat Sci, Sci & Technol Res Council Turkey, Sabanci Univ, Inst Elect & Elect Engineers, Turkey Sect, IFIP
AB This paper presents a statistical lexical ambiguity resolution method in direct transfer machine translation models in which the target language is Turkish. Since direct transfer MT models do not have full syntactic information, most of the lexical ambiguity resolution methods are not very helpful. Our disambiguation model is based on statistical language models. We have investigated the performances of some statistical language model types and parameters in lexical ambiguity resolution for our direct transfer MT system.
RI Tantug, Ahmet Cuneyd/M-4497-2013; Oflazer, Kemal/A-5528-2010
OI Tantug, Ahmet Cuneyd/0000-0003-0524-3397; Oflazer,
   Kemal/0000-0002-4977-0079
SN 0302-9743
EI 1611-3349
BN 3-540-47242-8
PY 2006
VL 4263
BP 230
EP 238
UT WOS:000243130100026
ER

PT C
AU Zhang, ZS
   Wang, R
   Utiyama, M
   Sumita, E
   Zhao, H
AF Zhang, Zhisong
   Wang, Rui
   Utiyama, Masao
   Sumita, Eiichiro
   Zhao, Hai
GP Assoc Computat Linguist
TI Exploring Recombination for Efficient Decoding of Neural Machine
   Translation
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB In Neural Machine Translation (NMT), the decoder can capture the features of the entire prediction history with neural connections and representations. This means that partial hypotheses with different prefixes will be regarded differently no matter how similar they are. However, this might be inefficient since some partial hypotheses can contain only local differences that will not influence future predictions. In this work, we introduce recombination in NMT decoding based on the concept of the "equivalence" of partial hypotheses. Heuristically, we use a simple n-gram suffix based equivalence function and adapt it into beam search decoding. Through experiments on large-scale Chinese-to-English and English-to-Germen translation tasks, we show that the proposed method can obtain similar translation quality with a smaller beam size, making NMT decoding more efficient.
BN 978-1-948087-84-1
PY 2018
BP 4785
EP 4790
UT WOS:000865723404092
ER

PT J
AU Zheng, JW
   Fan, WJ
AF Zheng, Jianwei
   Fan, Wenjun
TI Multivaried acceptance of post-editing in China Attitude, practice, and
   training
SO PRAGMATICS AND SOCIETY
AB Neural machine translation (NMT), proven to be productively and qualitatively competitive, creates great challenges and opportunities for stakeholders in both the market and the education contexts. This paper explores how English-Chinese NMT post-editing (PE) is accepted in China from the perspectives of attitude, practice, and training, based on an integrative digital survey with role-specific popup questions for translators and clients in the market setting, and for translation teachers and students in the education setting. Descriptive statistics and correlation analyses of the survey data suggest Chinese stakeholders' generally moderate view of PE, with outsiders like clients being more optimistic about PE than are insiders like translators. In the market setting, most translators use PE to different degrees in translating primarily informative texts; here, affiliated translators report a more frequent usage, and employ more sophisticated tools than do part-time or freelance translators. Whereas translators, on the whole, fail to notify clients of their own PE usage, or to charge clients for PE and human translation (HT) differently, most clients express their willingness to accept high-quality PE output for the sake of saving cost and time. In the education setting, despite students' concealed usage of PE to do HT assignments to varying degrees, and their wish to learn PE out of concern for their future career, PE is generally not taught in translation classrooms of Chinese universities in the form of teaching PE as a course or integrating PE content into traditional translation course.
SN 1878-9714
EI 1878-9722
PD NOV 4
PY 2022
VL 13
IS 4
BP 644
EP 662
DI 10.1075/ps.19048.zhe
UT WOS:000878986700005
ER

PT J
AU Yu, YX
   Wang, HH
AF Yu, Yuxiu
   Wang, Honghai
TI The Application of Artificial Intelligence in the Dissemination of Local
   Culture in Hainan Province: Taking the Dissemination of Bai Yuchan's
   Thoughts as an Example
SO ADVANCES IN MULTIMEDIA
AB Bai Yuchan's Taoist thought is an important part of Taoist health-preserving thought. Excavating, sorting out, and translating Bai Yuchan's Taoist thought will not only help increase cultural self-confidence and protect traditional culture but also become an important medium for foreign exchanges. With the advent of the digital age, artificial intelligence has helped the dissemination of excellent traditional Chinese culture with its unique technological advantages, improving the effectiveness, intensity, and breadth of cultural dissemination. In domain machine translation, whether domain terms can be correctly translated plays a decisive role in the translation quality. It is of practical significance to effectively integrate domain terms into neural machine translation models and improve the translation quality of domain terms. This paper proposes a method of incorporating new Bai Yuchan's thought term information as prior knowledge into neural machine translation. Using the term dictionary constructed from Bai Yuchan's thought bilingual terminology knowledge base as a medium, two different knowledge integration methods are proposed and compared: (1) term replacement, which means using the target term to replace the source term on the source language side, and (2) term addition, which means splicing the source term and the target term on the source language side and both the source language side and the target language side. Use identifiers as special external knowledge to identify the beginning and end of the target term. Based on the Chinese-English bilingual alignment corpus of New Bai Yuchan's thoughts and the constructed Chinese-English alignment termbase, the experiments are carried out. The results show that on the test set, the BLEU value of the proposed method is 6.38 and 6.38 higher than the baseline experiments, respectively, which proves that the proposed method can effectively incorporate domain terminology knowledge into the translation model and improve the translation quality of domain terminology.
SN 1687-5680
EI 1687-5699
PD OCT 7
PY 2022
VL 2022
AR 7255853
DI 10.1155/2022/7255853
UT WOS:000870002100006
ER

PT C
AU Liao, JW
   Shi, Y
   Gong, M
   Shou, LJ
   Qu, H
   Zeng, M
AF Liao, Junwei
   Shi, Yu
   Gong, Ming
   Shou, Linjun
   Qu, Hong
   Zeng, Michael
GP IEEE
TI Improving Zero-shot Neural Machine Translation on Language-specific
   Encoders-Decoders
SO 2021 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY JUL 18-22, 2021
CL ELECTR NETWORK
SP Int Neural Network Soc, IEEE Computat Intelligence Soc
AB Recently, universal neural machine translation (NMT) with shared encoder-decoder gained good performance on zero-shot translation. Unlike universal NMT, jointly trained language-specific encoders-decoders aim to achieve universal representation across non-shared modules, each of which is for a language or language family. The non-shared architecture has the advantage of mitigating internal language competition, especially when the shared vocabulary and model parameters are restricted in their size. However, the performance of using multiple encoders and decoders on zero-shot translation still lags behind universal NMT. In this work, we study zero-shot translation using language-specific encoders-decoders. We propose to generalize the non-shared architecture and universal NMT by differentiating the Transformer layers between language-specific and interlingua. By selectively sharing parameters and applying cross-attentions, we explore maximizing the representation universality and realizing the best alignment of language-agnostic information. We also introduce a denoising auto-encoding (DAE) objective to jointly train the model with the translation task in a multi-task manner. Experiments on two public multilingual parallel datasets show that our proposed model achieves competitive or better results than universal NMT and the strong pivot baseline. Moreover, we experiment incrementally adding new language to the trained model by only updating the new model parameters. With this little effort, the zero-shot translation between this newly added language and existing languages achieves a comparable result with the model trained jointly from scratch on all languages.
SN 2161-4393
BN 978-0-7381-3366-9
PY 2021
DI 10.1109/IJCNN52387.2021.9534401
UT WOS:000722581708096
ER

PT J
AU Ren, HK
   Mao, X
   Ma, WJ
   Wang, JZ
   Wang, LY
AF Ren, Hongkai
   Mao, Xi
   Ma, Weijun
   Wang, Jizhou
   Wang, Linyun
TI An English-Chinese Machine Translation and Evaluation Method for
   Geographical Names
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
AB In recent years, with increasing international communication and cooperation, the consensus of toponymic information among different countries has become increasingly important. A large number of English geographical names are in urgent need of translation into Chinese, but there are few studies on machine translation of geographical names at present. Therefore, this paper proposes a method of automatically translating English geographical names into Chinese. First, the lexical structure of the geographic names is analyzed to divide the whole name into two parts, the special name and the general name, in an approach based on the statistical template model that implements pointwise mutual information and a directed acyclic graph data structure on the extracted names from different categories of a geographical name corpus. Second, the two parts of the geographic names are translated. The general name can be directly translated via methods of free translation. For the transliteration of the special name, the phonetic symbols are generated based on the cyclic neural network, and then, the syllables are divided based on the minimum entropy and converted into Chinese characters. Finally, the two parts of Chinese characters are combined, and criteria are prepared to evaluate the translation reliability according to the translation process to realize automatic quality inspection and screening of geographical names. As the experimental results show, the method is effective in the translation process of English geographic names into Chinese. This method can be easily extended to other languages such as Arabic.
EI 2220-9964
PD MAR
PY 2020
VL 9
IS 3
AR 139
DI 10.3390/ijgi9030139
UT WOS:000523512400003
ER

PT C
AU Takahashi, K
   Sudoh, K
   Nakamura, S
AF Takahashi, Kosuke
   Sudoh, Katsuhito
   Nakamura, Satoshi
GP Assoc Computat Linguist
TI Automatic Machine Translation Evaluation using Source Language Inputs
   and Cross-lingual Language Model
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB We propose an automatic evaluation method of machine translation that uses source language sentences regarded as additional pseudo references. The proposed method evaluates a translation hypothesis in a regression model. The model takes the paired source, reference, and hypothesis sentence all together as an input. A pretrained large scale cross-lingual language model encodes the input to sentence-pair vectors, and the model predicts a human evaluation score with those vectors. Our experiments show that our proposed method using Cross lingual Language Model (XLM) trained with a translation language modeling (TLM) objective achieves a higher correlation with human judgments than a baseline method that uses only hypothesis and reference sentences. Additionally, using source sentences in our proposed method is confirmed to improve the evaluation performance.
BN 978-1-952148-25-5
PY 2020
BP 3553
EP 3558
UT WOS:000570978203087
ER

PT C
AU Dougal, DK
   Lonsdale, DW
AF Dougal, Duane K.
   Lonsdale, Deryle W.
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mariani, J
   Mazo, H
   Moreno, A
   Odijk, J
   Piperidis, S
TI Improving NMT Quality Using Terminology Injection
SO PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES
   AND EVALUATION (LREC 2020)
CT 12th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 11-16, 2020
CL Marseille, FRANCE
AB Many organizations use domain- or organization-specific words and phrases. This paper explores the use of vetted terminology as an input to neural machine translation (NMT) for improved results: ensuring that the translation of individual terms is consistent with an approved multilingual terminology collection. We discuss, implement, and evaluate a method for injecting terminology and for evaluating terminology injection. Our use of the long short-term memory (LSTM) attention mechanism prevalent in state-of-the-art NMT systems involves attention vectors for correctly identifying semantic entities and aligning the tokens that represent them, both in the source and the target languages. Appropriate terminology is then injected into matching alignments during decoding. We also introduce a new translation metric more sensitive to approved terminological content in MT output.
BN 979-10-95546-34-4
PY 2020
BP 4820
EP 4827
UT WOS:000724697205099
ER

PT C
AU Berard, A
   Calapodescu, I
   Roux, C
AF Berard, Alexandre
   Calapodescu, Ioan
   Roux, Claude
GP Assoc Computat Linguist
TI Naver Labs Europe's Systems for the WMT19 Machine Translation Robustness
   Task
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019)
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB This paper describes the systems that we submitted to the WMT19 Machine Translation robustness task. This task aims to improve MT's robustness to noise found on social media, like informal language, spelling mistakes and other orthographic variations. The organizers provide parallel data extracted from a social media website(1) in two language pairs: French-English and Japanese-English (in both translation directions). The goal is to obtain the best scores on unseen test sets from the same source, according to automatic metrics (BLEU) and human evaluation. We proposed one single and one ensemble system for each translation direction. Our ensemble models ranked first in all language pairs, according to BLEU evaluation. We discuss the preprocessing choices that we made, and present our solutions for robustness to noise and domain adaptation.
BN 978-1-950737-27-7
PY 2019
BP 526
EP 532
UT WOS:000538566200061
ER

PT S
AU Fourla, A
   Yannoutsou, O
AF Fourla, A
   Yannoutsou, O
BE Farwell, D
   Gerber, L
   Hovy, E
TI Implementing MT in the Greek Public Sector: A users' survey
SO MACHINE TRANSLATION AND THE INFORMATION SOUP
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
CT 3rd Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 28-31, 1998
CL LANGHORNE, PENNSYLVANIA
SP Systran Inc, Logos Corp, Globalink Inc, Univ Penn Inst Res Cognitive Sci
AB This paper presents the activities of Euromat (European Machine Translation) office in Greece, which has been functioning as a centre for Machine Translation Services For the Greek Public Sector since 1994. It describes the user profile, his/her attitude towards MT, strategies of promotion and the collected corpus for the first three years. User data were collected by questionnaires, interviews and corpus statistics. The general conclusions which have come out from our surveys are discussed.
SN 0302-9743
BN 3-540-65259-0
PY 1998
VL 1529
BP 300
EP 307
UT WOS:000086659400027
ER

PT J
AU Aktener, I
AF Aktener, Ilgin
TI Censorship and literary translation in Turkey: translating obscenity
   after The Soft Machine and Snuff court cases
SO NEOHELICON
AB In 2011, the Turkish publishers (rfan Sanc and Hasan Basri Cplak) and translators (Suha Sertabibolu and Funda Uncu) of the books The Soft Machine and Snuff were taken to court on the grounds of obscenity. This article investigates the effects of these court cases on Turkish publishers' and translators' subsequent publication/translation behaviours regarding their choice of books to publish/translate and strategies for publishing/translating obscenity. The study is informed by corpus methods and the results are discussed in the light of interviews conducted with Sanc, Sertabibolu and Uncu. The study concludes that although the publishers and translators under investigation continued publishing/translating books containing obscenity, their publication/translation behaviours changed to some degree after the court cases.
OI AKTENER, Ilgin/0000-0001-9166-1362
SN 0324-4652
EI 1588-2810
PD JUN
PY 2019
VL 46
IS 1
BP 347
EP 367
DI 10.1007/s11059-019-00475-4
UT WOS:000468470900023
ER

PT C
AU Sun, ZW
   Huang, SJ
   Wei, HR
   Dai, XY
   Chen, JJ
AF Sun, Zewei
   Huang, Shujian
   Wei, Hao-Ran
   Dai, Xin-yu
   Chen, Jiajun
GP Assoc Advancement Artificial Intelligence
TI Generating Diverse Translation by Manipulating Multi-Head Attention
SO THIRTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THE
   THIRTY-SECOND INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE
   CONFERENCE AND THE TENTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN
   ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 34th AAAI Conference on Artificial Intelligence / 32nd Innovative
   Applications of Artificial Intelligence Conference / 10th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 07-12, 2020
CL New York, NY
SP Assoc Advancement Artificial Intelligence
AB Transformer model (Vaswani et al. 2017) has been widely used in machine translation tasks and obtained state-of-the-art results. In this paper, we report an interesting phenomenon in its encoder-decoder multi-head attention: different attention heads of the final decoder layer align to different word translation candidates. We empirically verify this discovery and propose a method to generate diverse translations by manipulating heads. Furthermore, we make use of these diverse translations with the back-translation technique for better data augmentation. Experiment results show that our method generates diverse translations without a severe drop in translation quality. Experiments also show that back-translation with these diverse translations could bring a significant improvement in performance on translation tasks. An auxiliary experiment of conversation response generation task proves the effect of diversity as well.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-835-0
PY 2020
VL 34
BP 8976
EP 8983
UT WOS:000668126801051
ER

PT J
AU Liao, JW
   Shi, Y
AF Liao, Junwei
   Shi, Yu
TI Rectifying Ill-Formed Interlingual Space: A Framework for Zero-Shot
   Translation on Modularized Multilingual NMT
SO MATHEMATICS
AB The multilingual neural machine translation (NMT) model can handle translation between more than one language pair. From the perspective of industrial applications, the modularized multilingual NMT model (M2 model) that only shares modules between the same languages is a practical alternative to the model that shares one encoder and one decoder (1-1 model). Previous works have proven that the M2 model can benefit from multiway training without suffering from capacity bottlenecks and exhibits better performance than the 1-1 model. However, the M2 model trained on English-centric data is incapable of zero-shot translation due to the ill-formed interlingual space. In this study, we propose a framework to help the M2 model form an interlingual space for zero-shot translation. Using this framework, we devise an approach that combines multiway training with a denoising autoencoder task and incorporates a Transformer attention bridge module based on the attention mechanism. We experimentally show that the proposed method can form an improved interlingual space in two zero-shot experiments. Our findings further extend the use of the M2 model for multilingual translation in industrial applications.
EI 2227-7390
PD NOV
PY 2022
VL 10
IS 22
AR 4178
DI 10.3390/math10224178
UT WOS:000887462500001
ER

PT J
AU Hu, L
   Hu, J
AF Hu, Lian
   Hu, Jing
TI Exploration of the Problems and Solutions Based on the Translation of
   Computer Software into Japanese Language
SO MATHEMATICAL PROBLEMS IN ENGINEERING
AB At present, the research on machine translation mainly focuses on English-Chinese translation, while the research on Japanese college students using Japanese Chinese machine translation software is relatively few. In order to solve the above problems in Chinese Japanese bilingual translation, this paper proposes a phrase translation method based on sequence intersection. This method regards sentences as word sequences and aligns the sequence intersection of all source sentences corresponding to the target sentence in the corpus with Chinese and Japanese sentences containing the phrases to be translated. By fully mining the information of sentence alignment bilingual corpus without word alignment resources, we can obtain high-quality phrase translation, syntactic analysis, and dictionary. Then, we focus on the automatic construction of sentence level aligned bilingual corpus and explore the automatic sentence alignment technology of Chinese and Japanese bilinguals. A ten-year alignment model based on combination cues and core extended square matching is proposed. The preprocessing of the computer corpus and the basic construction of the corpus are completed. This paper also puts forward corresponding countermeasures and approaches to the problems encountered in the construction of computer translation.
SN 1024-123X
EI 1563-5147
PD SEP 6
PY 2022
VL 2022
AR 3712090
DI 10.1155/2022/3712090
UT WOS:000872902600003
ER

PT J
AU Chai, GX
   Wen, QZ
AF Chai, Guoxi
   Wen, Qiaozhi
TI An Interactive English-Chinese Translation System Based on GLA Algorithm
SO JOURNAL OF INFORMATION & KNOWLEDGE MANAGEMENT
AB In view of the longtime interactive English-Chinese translation system, an interactive English-Chinese translation system based on Griffin-Lim algorithm (GLA) is proposed. The hardware design of the system is completed by the hardware structure design, the interactive English-Chinese translation memory design and the interactive English-Chinese translation retrieval system design. Through analysing the semantic characteristics of interactive English-Chinese translation, constructing interactive English-Chinese translation database and designing interactive English-Chinese translation process, the system software design is completed and interactive English-Chinese translation is realised. The results of the system test show that the interactive English-Chinese translation system based on the GLA algorithm cannot only shorten the time of interactive English-Chinese translation, but also accelerate the response speed of the translation system, and greatly improve the overall performance of the interactive English-Chinese translation system.
SN 0219-6492
EI 1793-6926
PD JUL
PY 2022
VL 21
IS SUPP02
SU 2
AR 2240014
DI 10.1142/S0219649222400147
UT WOS:000821701500016
ER

PT C
AU Tu, ZP
   Liu, Y
   Shang, LF
   Liu, XH
   Li, H
AF Tu, Zhaopeng
   Liu, Yang
   Shang, Lifeng
   Liu, Xiaohua
   Li, Hang
GP AAAI
TI Neural Machine Translation with Reconstruction
SO THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 31st AAAI Conference on Artificial Intelligence
CY FEB 04-09, 2017
CL San Francisco, CA
SP Assoc Advancement Artificial Intelligence
AB Although end-to-end Neural Machine Translation (NMT) has achieved remarkable progress in the past two years, it suffers from a major drawback: translations generated by NMT systems often lack of adequacy. It has been widely observed that NMT tends to repeatedly translate some source words while mistakenly ignoring other words. To alleviate this problem, we propose a novel encoder-decoder-reconstructor framework for NMT. The reconstructor, incorporated into the NMT model, manages to reconstruct the input source sentence from the hidden layer of the output target sentence, to ensure that the information in the source side is transformed to the target side as much as possible. Experiments show that the proposed framework significantly improves the adequacy of NMT output and achieves superior translation result over state-of-the-art NMT and statistical MT systems.
RI Tu, Zhaopeng/AAS-4259-2021
SN 2159-5399
EI 2374-3468
PY 2017
BP 3097
EP 3103
UT WOS:000485630703021
ER

PT J
AU Chatterjee, N
   Gupta, S
AF Chatterjee, Niladri
   Gupta, Susmita
TI Efficient Phrase Table pruning for Hindi to English machine translation
   through syntactic and marker-based filtering and hybrid similarity
   measurement
SO NATURAL LANGUAGE ENGINEERING
AB For a given training corpus of parallel sentences, the quality of the output produced by a translation system relies heavily on the underlying similarity measurement criteria. A phrase-based machine translation system derives its output through a generative process using a Phrase Table comprising source and target language phrases. As a consequence, the more effective the Phrase Table is, in terms of its size and the output that may be derived out of it, the better is the expected outcome of the underlying translation system. However, finding the most similar phrase(s) from a given training corpus that can help generate a good quality translation poses a serious challenge. In practice, often there are many parallel phrase entries in a Phrase Table that are either redundant, or do not contribute to the translation results effectively. Identifying these candidate entries and removing them from the Phrase Table will not only reduce the size of the Phrase Table, but should also help in improving the processing speed for generating the translations. The present paper develops a scheme based on syntactic structure and the marker hypothesis (Green 1979, The necessity of syntax markers: two experiments with artificial languages, Journal of Verbal Learning and Behavior) for reducing the size of a Phrase Table, without compromising much on the translation quality of the output, by retaining the non-redundant and meaningful parallel phrases only. The proposed scheme is complemented with an appropriate similarity measurement scheme to achieve maximum efficiency in terms of BLEU scores. Although designed for Hindi to English machine translation, the overall approach is quite general, and is expected to be easily adaptable for other language pairs as well.
SN 1351-3249
EI 1469-8110
PD JAN
PY 2019
VL 25
IS 1
BP 171
EP 210
DI 10.1017/S1351324918000360
UT WOS:000454302800007
ER

PT C
AU Roche, M
   Garbasevschi, OM
AF Roche, Mathieu
   Garbasevschi, Oana Mihaela
BE DeRaedt, L
   Bessiere, C
   Dubois, D
   Doherty, P
   Frasconi, P
   Heintz, F
   Lucas, P
TI WeMiT: Web-Mining for Translation
SO 20TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE (ECAI 2012)
SE Frontiers in Artificial Intelligence and Applications
CT 20th European Conference on Artificial Intelligence (ECAI)
CY AUG 27-31, 2012
CL CNRS, Montpellier, FRANCE
SP European Coordinating Comm Artificial Intelligence, Assoc Francaise Intelligence Artificielle, US AF Res Lab, AF Off Sci Res, European Off Aerosp Res & Dev, Artificial Intelligence, IBM Res, IOS Press, Mines Telecom, Montpellier Agglomerat, Reg Languedoc Roussillon, Univ Montpellier 2, Lab Informatique Robotique Microelectronique Montpellier
HO CNRS
AB The quality of machine translation is often dependent on the quality of lexical transfer from a source language to a target language. In this work we present an automatic method to translate specialized terms. The proposed approach is based on two steps: (1) extraction of candidates for translation into web pages, (2) identification of the most relevant candidates by using web-mining techniques.
OI Roche, Mathieu/0000-0003-3272-8568
SN 0922-6389
EI 1879-8314
BN 978-1-61499-098-7; 978-1-61499-097-0
PY 2012
VL 242
BP 993
EP +
DI 10.3233/978-1-61499-098-7-993
UT WOS:000349006300183
ER

PT C
AU Munkova, D
   Munk, M
   Benko, L
   Absolon, J
AF Munkova, Dasa
   Munk, Michal
   Benko, L'ubomir
   Absolon, Jakub
BE Auer, ME
   Tsiatsos, T
TI From Old Fashioned "One Size Fits All" to Tailor Made Online Training
SO CHALLENGES OF THE DIGITAL TRANSFORMATION IN EDUCATION, ICL2018, VOL 1
SE Advances in Intelligent Systems and Computing
CT 21st International Conference on Interactive Collaborative Learning
   (ICL) / 47th IGIP International Conference on Engineering Pedagogy -
   Teaching and Learning in a Digital World
CY SEP 25-28, 2018
CL GREECE
SP IGIP, Aristotle Univ Thessaloniki
AB Nowadays, post-editing of machine translation output represents a significant element in the translation market and industry. Subsequently, the preparation of future translators must cover not only all routine methods but must be cost-effective, efficient and in accordance with human resources available. That is the reason we use Internet-based technologies more and more. New emerging technologies are very often driven by the marketing power of companies developing and selling applications. Each of us experienced dozens of fantastic features available in teaching software and applications. The core skill of the online educator is to find a balance between our needs and ability to use technology. Since translation demand keeps growing every day, a large number of translators use various technical tools including translation memories, terminology management tools or Machine Translation (MT) technologies and thus increase their productivity and meet this high demand. The post-editing of MT should be only done by a person who is familiar with this method and knows exactly what, how and how much needs to be edited in the text. Otherwise, the sense of post-editing is losing importance, as the work of post-editor would not be more effective as a translator's, who translates the text traditional way "from scratch". The contribution of the paper is to create an online educational system tailored to translators' needs; an online system in which students translate and revise a text, post-edit machine translation output and also assess the quality of the translation.
RI Munk, Michal/N-1724-2017; Benko, Lubomir/C-7713-2019
OI Munk, Michal/0000-0002-9913-3596; Benko, Lubomir/0000-0002-1657-395X;
   Munkova, Dasa/0000-0002-1003-7929
SN 2194-5357
EI 2194-5365
BN 978-3-030-11932-4; 978-3-030-11931-7
PY 2020
VL 916
BP 365
EP 376
DI 10.1007/978-3-030-11932-4_35
UT WOS:000772228000034
ER

PT J
AU Shao, CZ
   Feng, Y
   Zhang, JC
   Meng, FD
   Zhou, J
AF Shao, Chenze
   Feng, Yang
   Zhang, Jinchao
   Meng, Fandong
   Zhou, Jie
TI Sequence-Level Training for Non-Autoregressive Neural Machine
   Translation
SO COMPUTATIONAL LINGUISTICS
AB In recent years, Neural Machine Translation (NMT) has achieved notable results in various translation tasks. However, the word-by-word generation manner determined by the autoregressive mechanism leads to high translation latency of the NMT and restricts its low-latency applications. Non-Autoregressive Neural Machine Translation (NAT) removes the autoregressive mechanism and achieves significant decoding speedup by generating target words independently and simultaneously. Nevertheless, NAT still takes the word-level cross-entropy loss as the training objective, which is not optimal because the output of NAT cannot be properly evaluated due to the multimodality problem. In this article, we propose using sequence-level training objectives to train NAT models, which evaluate the NAT outputs as a whole and correlates well with the real translation quality. First, we propose training NAT models to optimize sequence-level evaluation metrics (e.g., BLEW based on several novel reinforcement algorithms customized for NAT, which outperform the conventional method by reducing the variance of gradient estimation. Second, we introduce a novel training objective for NAT models, which aims to minimize the Bag-of-N-grams (BoN) difference between the model output and the reference sentence. The BoN training objective is differentiable and can be calculated efficiently without doing any approximations. Finally, we apply a three-stage training strategy to combine these two methods to train the NAT model. We validate our approach on four translation tasks (WMT14 EN <-> De, WMT16 EN <-> Ro), which shows that our approach largely outperforms NAT baselines and achieves remarkable performance on all translation tasks. The source code is available at https://github.com/ictnlp/Seq-NAT.
SN 0891-2017
EI 1530-9312
PD DEC
PY 2021
VL 47
IS 4
BP 891
EP 925
DI 10.1162/COLI_a_00421
UT WOS:000753228200006
ER

PT C
AU Axelrod, A
   He, XD
   Deng, L
   Acero, A
   Hwang, MY
AF Axelrod, Amittai
   He, Xiaodong
   Deng, Li
   Acero, Alex
   Hwang, Mei-Yuh
GP IEEE
TI NEW METHODS AND EVALUATION EXPERIMENTS ON TRANSLATING TED TALKS IN THE
   IWSLT BENCHMARK
SO 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
CT IEEE International Conference on Acoustics, Speech and Signal Processing
CY MAR 25-30, 2012
CL Kyoto, JAPAN
SP Inst Elect & Elect Engineers, Signal Processing Soc, IEEE
AB The IWSLT benchmark task is an annual evaluation campaign on spoken language translation held by the International Workshop on Spoken Language Processing (IWSLT). The task is to translate TED talks (www.ted.com). This task presents two unique challenges: Firstly, the underlying topic switches sharply from talk to talk, and each one contains only tens to hundreds of utterances. The translation system therefore needs to adapt to the current topic quickly and dynamically. Secondly, unlike other machine translation benchmark tasks, only a very small relevant parallel corpus (transcripts of TED talks) is available. Therefore, it is necessary to perform accurate translation model estimation with limited data. In this paper, we present our recent progress and two new methods on the IWSLT TED talk translation task from Chinese into English. In particular, to address the first problem, we use unsupervised topic modeling to select additional topic-dependent parallel data from a globally irrelevant corpus. These additional data slices can then be used to build an unsupervised topic-adapted machine translation system. For the second problem, we develop a discriminative training method to estimate the translation models more accurately. Our experimental evaluation results show that both methods improve the translation quality over a state-of-the-art baseline.
SN 1520-6149
BN 978-1-4673-0046-9
PY 2012
BP 4945
EP 4948
UT WOS:000312381405005
ER

PT J
AU Kumar, P
   Pathania, K
   Raman, B
AF Kumar, Puneet
   Pathania, Kshitij
   Raman, Balasubramanian
TI Zero-shot learning based cross-lingual sentiment analysis for sanskrit
   text with insufficient labeled data
SO APPLIED INTELLIGENCE
AB In this paper, a novel method for analyzing the sentiments portrayed by Sanskrit text has been proposed. Sanskrit is one of the world's most ancient languages; however, natural language processing tasks such as machine translation and sentiment analysis have not been explored for it to the full potential because of the unavailability of sufficient labeled data. We solved this issue using a zero-shot learning-based cross-lingual sentiment analysis (CLSA) approach. The CLSA uses the resources from the source language to enhance the sentiment analysis of the target language having insufficient resources. The proposed work translates the text from Sanskrit, a language with insufficient labeled data, to English, with sufficient labeled data for sentiment analysis using a transformer model. A generative adversarial network-based strategy has been proposed to evaluate the maturity of the translations. Then a bidirectional long short-term memory-based model has been implemented to classify the sentiments using the embeddings obtained through translations. The proposed technique has achieved 87.50% accuracy for machine translation and 92.83% accuracy for sentiment classification. Sanskrit-English translations used in this work have been collected through web scraping techniques. In the absence of the ground-truth sentiment class labels, a strategy for evaluating the sentiment scores of the proposed sentiment analysis model has also been presented. A new dataset of Sanskrit text, along with their English translations and sentiment scores, has been constructed.
OI Kumar, Puneet/0000-0002-4318-1353
SN 0924-669X
EI 1573-7497
DI 10.1007/s10489-022-04046-6
EA AUG 2022
UT WOS:000840620400003
ER

PT J
AU Littau, K
AF Littau, Karin
TI Translation's Histories and Digital Futures
SO INTERNATIONAL JOURNAL OF COMMUNICATION
AB Drawing on Latour's actor-network-theory and De Landa's robot historian, this essay asks in what ways translation's past is a prehistory of the present and to what extent nonhuman agents have shaped and are shaping translation. In particular, it examines the impact of computational media on translation and finds that the difference made by the computer as a convergence medium is that, for the first time in history, one medium has become capable of presenting in its entirety the media history of translation. To grasp the changes that translation is undergoing in the 21st century therefore requires a comparative understanding of its relations to the mediascapes of the past, present, and future.
OI Littau, Karin/0000-0002-9304-295X
SN 1932-8036
PY 2016
VL 10
BP 907
EP 928
UT WOS:000369514500021
ER

PT C
AU Sharma, VK
   Mittal, N
AF Sharma, Vijay Kumar
   Mittal, Namita
BE Shankar, BU
   Ghosh, K
   Mandal, DP
   Ray, SS
   Zhang, D
   Pal, SK
TI Named Entity Identification Based Translation Disambiguation Model
SO PATTERN RECOGNITION AND MACHINE INTELLIGENCE, PREMI 2017
SE Lecture Notes in Computer Science
CT 7th International Conference on Pattern Recognition and Machine
   Intelligence (PReMI)
CY DEC 05-08, 2017
CL Indian Stat Inst, Kolkata, INDIA
SP Indian Stat Inst, Machine Intelligence Unit, Int Assoc Pattern Recognit, IEEE Kolkata Sect, Indian Stat Inst, Ctr Soft Comp Res, Web Intelligence Consortium, Int Rough Set Soc, INAE Kolkata Chapter, World Federat Soft Comp, Springer Int Publishing
HO Indian Stat Inst
AB Machine Translation (MT) systems are in growing state for Indian languages, where either a translation or transliteration mechanism is used for a word or phrase. Identifying whether a word needs translation or transliteration mechanism, is still a challenge. Since the Named Entity (NE) terms have a property of similar pronunciation across the languages. So the Named Entity Identification (NEI) will be very useful for disambiguating the word in favor of either translation or transliteration. Term Frequency Model (TFM), i.e., a Cross-Lingual Information Retrieval (CLIR) model is used to evaluate the NEI based translation disambiguation model.
RI Mittal, Namita/AAL-3336-2020
OI Mittal, Namita/0000-0001-6886-9974
SN 0302-9743
EI 1611-3349
BN 978-3-319-69900-4; 978-3-319-69899-1
PY 2017
VL 10597
BP 365
EP 372
DI 10.1007/978-3-319-69900-4_46
UT WOS:000450772100046
ER

PT J
AU Aqlan, F
   Fan, XP
   Alqwbani, A
   Al-Mansoub, A
AF Aqlan, Fares
   Fan, Xiaoping
   Alqwbani, Abdullah
   Al-Mansoub, Akram
TI Arabic-Chinese Neural Machine Translation: Romanized Arabic as Subword
   Unit for Arabic-sourced Translation
SO IEEE ACCESS
AB Morphologically rich and complex languages such as Arabic, pose a major challenge to neural machine translation (NMT) due to the large number of rare words and the inability of NMT to translate them. Unknown word (UNK) symbols are used to represent out-of-vocabulary words because NMT typically operates with a fixed vocabulary size. These rare words can be effectively encoded as sequences of subword units by using algorithms, such as byte pair encoding (BPE), to tackle the UNK problem. However, for languages with highly inflected and morphological variations, such as Arabic, the aforementioned method has its own limitations that make it not effective enough for translation quality. To alleviate the UNK problem and address the inconvenient behavior of BPE when translating the Arabic language, we propose to utilize a romanization system that converts Arabic scripts to subword units. We investigate the effect of our approach on NMT performance under various segmentation scenarios and compare the results with systems trained on original Arabic form. In addition, we integrate Romanized Arabic as an input factor for Arabic-sourced NMT compared with well-known factors, namely, lemma, part-of-speech tags, and morph features. Extensive experiments on Arabic-Chinese translation demonstrate that the proposed approaches can effectively tackle the UNK problem and significantly improve the translation quality for Arabic-sourced translation. Additional experiments in this study focus on developing the NMT system on Chinese-Arabic translation. Before implementing our experiments, we first propose standard criteria for the data filtering of a parallel corpus, which helps in filtering out its noise.
OI Aqlan, Fares/0000-0002-3957-8622
SN 2169-3536
PY 2019
VL 7
BP 133122
EP 133135
DI 10.1109/ACCESS.2019.2941161
UT WOS:000496157000001
ER

PT C
AU Tamura, T
   Wei, YZ
   Utsuro, T
   Nagata, M
AF Tamura, Takuya
   Wei, Yizhen
   Utsuro, Takehito
   Nagata, Masaaki
BE Takama, Y
   Matsumura, N
   Yada, K
   Matsushita, M
   Katagami, D
   Abe, A
   Kashima, H
   Hiraoka, T
   Uchiya, T
   Rzepka, R
TI Machine Translation Utilizing Similar Translation Retrieval
SO ADVANCES IN ARTIFICIAL INTELLIGENCE
SE Advances in Intelligent Systems and Computing
CT 35th Annual Comference of the
   Japanese-Society-for-Artificial-Intelligence (JSAI)
CY JUN 08-11, 2021
CL ELECTR NETWORK
SP Japanese Soc Artificial Intelligence
AB Neural Fuzzy Repair (NFR) system enables an NMT system to improve translation accuracy using similar translations searched from Translation Memory. This paper compared edit distance and sentence-BERT (SBERT) as the similarity measures used in the search for similar translations, and showed that SBERT outperformed edit distance in the case of small corpus sizes. This paper also studied a method to automatically select the most appropriate translation from more than one candidates. Compared to the naive method based on the number of tokens, the method based on the inner product of SBERT's sentence embedding achieved significant improvements. These results prove the effectiveness of the SBERT-based approach in the NFR system.
SN 2194-5357
EI 2194-5365
BN 978-3-030-96451-1; 978-3-030-96450-4
PY 2022
VL 1423
BP 34
EP 44
DI 10.1007/978-3-030-96451-1_4
UT WOS:000772640400004
ER

PT C
AU Hu, BJ
   Han, A
   Zhang, ZY
   Huang, S
   Ju, Q
AF Hu, Bojie
   Han, Ambyer
   Zhang, Zheyang
   Huang, Shen
   Ju, Qi
BE Huang, S
   Knight, K
TI Tencent Minority-Mandarin Translation System
SO MACHINE TRANSLATION, CCMT 2019
SE Communications in Computer and Information Science
CT 15th China Conference on Machine Translation (CCMT)
CY SEP 27-29, 2019
CL Jiangxi Normal Univ, Nanchang, PEOPLES R CHINA
SP Chinese Informat Proc Soc China, Kingsoft AI, Global Tone Commun Technol Co Ltd, Sogou Inc, NiuTrans Res, Tencent Technol Co Ltd
HO Jiangxi Normal Univ
AB This paper describes the submissions of the Tencent minority-mandarin translation system for CCMT19. We participate in 3 translation directions including Uighur -> Chinese, Tibetan -> Chinese and Mongolian -> Chinese. Our systems are neural machine translation systems trained with our improved Marian, and are called TenTrans, which are based on Google's Transformer model architecture. We also adopt most techniques that have been proven effective recently in academia, such as back-translation based sampling, data selection, sequence-level knowledge distillation, ensemble distillation, model ensembling and reranking. By using the above technologies, our submitted systems achieve a stable performance improvement.
SN 1865-0929
EI 1865-0937
BN 978-981-15-1721-1; 978-981-15-1720-4
PY 2019
VL 1104
BP 93
EP 104
DI 10.1007/978-981-15-1721-1_10
UT WOS:000833546400010
ER

PT C
AU Cattoni, R
   Bertoldi, N
   Federico, M
AF Cattoni, Roldano
   Bertoldi, Nicola
   Federico, Marcello
GP ISCA
TI Punctuating Confusion Networks for Speech Translation
SO INTERSPEECH 2007: 8TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH
   COMMUNICATION ASSOCIATION, VOLS 1-4
CT Interspeech Conference 2007
CY AUG 27-31, 2007
CL Antwerp, BELGIUM
AB Translating from confusion networks (CNs) has been proven to be more effective than translating from single best hypotheses. Moreover, it is widely accepted that the availability of good punctuation marks in the input can improve translation quality. At present, no ASR systems can generate punctuation marks in the word graphs, therefore CNs miss punctuation. In this paper we investigate the problem of adding punctuation marks into confusion networks. We investigate different punctuation strategies and show that the use of multiple hypotheses improves translation quality in a large-vocabulary speech translation task.
BN 978-1-60560-316-2
PY 2007
BP 2001
EP 2004
UT WOS:000269998601128
ER

PT J
AU Zhu, JB
   Li, Q
   Xiao, T
AF Zhu, Jingbo
   Li, Qiang
   Xiao, Tong
TI Improving syntactic rule extraction through deleting spurious links with
   translation span alignment
SO NATURAL LANGUAGE ENGINEERING
AB Most statistical machine translation systems typically rely on word alignments to extract translation rules. This approach would suffer from a practical problem that even one spurious word alignment link can prevent some desirable translation rules from being extracted. To address this issue, this paper presents two approaches, referred to as sub-tree alignment and phrase-based forced decoding methods, to automatically learn translation span alignments from parallel data. Then, we improve the translation rule extraction by deleting spurious links and inserting new links based on bilingual translation span correspondences. Some comparison experiments are designed to demonstrate the effectiveness of the proposed approaches.
RI Xiao, Tong/AAP-5944-2020
SN 1351-3249
EI 1469-8110
PD MAR
PY 2015
VL 21
IS 2
BP 227
EP 249
DI 10.1017/S1351324913000260
UT WOS:000351756500003
ER

PT J
AU Vandepitte, S
   Lefever, E
AF Vandepitte, Sonia
   Lefever, Els
TI Translation as a multilingual activity in the digital era
SO REVUE FRANCAISE DE LINGUISTIQUE APPLIQUEE
AB Translation is an age old multilingual activity whose increasingly more important relevance is being captured by today's multidisciplinary character of translation studies. This contribution first sketches the linguistic product-oriented approach, focusing on texts in different languages (translations, their source texts and comparable texts) and investigating highly frequent translation features such as explicitation. Secondly, recent inquiries into the translation process are described, catching glimpses of the translator's multilingual cognitive activity and applying methods of keystroke logging and eye-tracking. A third and final kind of studies has been inspired by the digital advances of recent years, which have led to a drastic change in translators' activities, having them integrate Computer-Aided Translation (CAT) tools into their daily multilingual translation workflow.
SN 1386-1204
EI 1875-368X
PY 2018
VL 23
IS 2
BP 59
EP 71
UT WOS:000452481300006
ER

PT J
AU Vidal, E
   Thollard, F
   de la Higuera, C
   Casacuberta, F
   Carrasco, RC
AF Vidal, E
   Thollard, F
   de la Higuera, C
   Casacuberta, F
   Carrasco, RC
TI Probabilistic finite-state machines - Part II
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB Probabilistic finite- state machines are used today in a variety of areas in pattern recognition or in fields to which pattern recognition is linked. In Part I of this paper, we surveyed these objects and studied their properties. In this Part II, we study the relations between probabilistic finite- state automata and other well- known devices that generate strings like hidden Markov models and n- grams and provide theorems, algorithms, and properties that represent a current state of the art of these objects.
RI ; Casacuberta, Francisco/T-3667-2017
OI , Colin/0000-0002-1703-9572; Casacuberta, Francisco/0000-0002-8497-5598
SN 0162-8828
EI 1939-3539
PD JUL
PY 2005
VL 27
IS 7
BP 1026
EP 1039
DI 10.1109/TPAMI.2005.148
UT WOS:000229024300003
PM 16013751
ER

PT C
AU Miyabe, M
   Yoshino, T
AF Miyabe, Mai
   Yoshino, Takashi
BE Jacko, JA
TI Can Indicating Translation Accuracy Encourage People to Rectify
   Inaccurate Translations?
SO HUMAN-COMPUTER INTERACTION: INTERACTION TECHNIQUES AND ENVIRONMENTS, PT
   II
SE Lecture Notes in Computer Science
CT International Conference on Ergonomics and Health Aspects of Work with
   Computers (EHAWC)/14th International Conference on Human-Computer
   Interaction (HCI)
CY JUL 09-14, 2011
CL Orlando, FL
AB The accuracy of machine translation affects how well people understand each other when communicating. Translation repair can improve the accuracy of translated sentences. Translation repair is typically only used when a user thinks that his/her message is inaccurate. As a result, translation accuracy suffers, because people's judgment in this regard is not always accurate. In order to solve this problem, we propose a method that provides users with an indication of the translation accuracy of their message. In this method, we measure the accuracy of translated sentences using an automatic evaluation method, providing users with three indicators: a percentage, a five-point scale, and a three-point scale. We verified how well these indicators reduce inaccurate judgments, and concluded the following: (1) the indicators did not significantly affect the inaccurate judgments of users; (2) the indication using a five-point scale obtained the highest evaluation, and that using a percentage obtained the second highest evaluation. However, in this experiment, the values we obtained from automatically evaluating translations were not always accurate. We think that incorrect automatic-evaluated values may have led to some inaccurate judgments. If we improve the accuracy of an automatic evaluation method, we believe that the indicators of translation accuracy can reduce inaccurate judgments. In addition, the percentage indicator can compensate for the shortcomings of the five-point scale. In other words, we believe that users may judge translation accuracy more easily by using a combination of these indicators.
SN 0302-9743
BN 978-3-642-21605-3
PY 2011
VL 6762
BP 368
EP 377
UT WOS:000306321200041
ER

PT J
AU Luo, GX
   Yang, YT
   Dong, R
   Chen, YH
   Zhang, WB
AF Luo, Gong-Xu
   Yang, Ya-Ting
   Dong, Rui
   Chen, Yan-Hong
   Zhang, Wen-Bo
TI A Joint Back-Translation and Transfer Learning Method for Low-Resource
   Neural Machine Translation
SO MATHEMATICAL PROBLEMS IN ENGINEERING
AB Neural machine translation (NMT) for low-resource languages has drawn great attention in recent years. In this paper, we propose a joint back-translation and transfer learning method for low-resource languages. It is widely recognized that data augmentation methods and transfer learning methods are both straight forward and effective ways for low-resource problems. However, existing methods, which utilize one of these methods alone, limit the capacity of NMT models for low-resource problems. In order to make full use of the advantages of existing methods and further improve the translation performance of low-resource languages, we propose a new method to perfectly integrate the back-translation method with mainstream transfer learning architectures, which can not only initialize the NMT model by transferring parameters of the pretrained models, but also generate synthetic parallel data by translating large-scale monolingual data of the target side to boost the fluency of translations. We conduct experiments to explore the effectiveness of the joint method by incorporating back-translation into the parent-child and the hierarchical transfer learning architecture. In addition, different preprocessing and training methods are explored to get better performance. Experimental results on Uygur-Chinese and Turkish-English translation demonstrate the superiority of the proposed method over the baselines that use single methods.
RI zhang, wenbo/GWV-7136-2022
SN 1024-123X
EI 1563-5147
PD MAY 31
PY 2020
VL 2020
AR 6140153
DI 10.1155/2020/6140153
UT WOS:000542654800007
ER

PT C
AU Ni, XD
   Liu, XQ
AF Ni, Xiaodan
   Liu, Xiaqing
BE Weiguo, L
   Guiran, C
   Huiyu, Z
TI Application of Computer-Aided Translation on Business English
   Translation
SO PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON SENSOR NETWORK AND
   COMPUTER ENGINEERING
SE AER-Advances in Engineering Research
CT 6th International Conference on Sensor Network and Computer Engineering
   (ICSNCE)
CY JUL 08-10, 2016
CL Xian, PEOPLES R CHINA
AB This paper intends to introduce the application of computer-aided translation technology on business English translation. At the same time, this paper analyzed the advantages and some shortcomings of computer-aided translation. Business English is an applied and highly specialized area of English. As the global economy develops, the demand for business English translation is becoming increasingly large. However, the traditional manual translation is not only slow in speed, the quality is also uneven. Thus, it is difficult to meet the current market demand. Computer-aided translation technology is a combination of translation memory technology and traditional manual translation, which can greatly improve the speed and accuracy of the translation. This paper confirms that although the computer-aided translation is still inadequate, it has a highly practical value and prospect for promotion in business English area.
SN 2352-5401
BN 978-94-6252-217-6
PY 2016
VL 68
BP 322
EP 326
UT WOS:000385403000063
ER

PT J
AU Wang, R
   Zhao, H
   Ploux, S
   Lu, BL
   Utiyama, M
   Sumita, E
AF Wang, Rui
   Zhao, Hai
   Ploux, Sabine
   Lu, Bao-Liang
   Utiyama, Masao
   Sumita, Eiichiro
TI Graph-Based Bilingual Word Embedding for Statistical Machine Translation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB Bilingual word embedding has been shown to be helpful for Statistical Machine Translation (SMT). However, most existing methods suffer from two obvious drawbacks. First, they only focus on simple contexts such as an entire document or a fixed-sized sliding window to build word embedding and ignore latent useful information from the selected context. Second, the word sense but not the word should be the minimal semantic unit; however, most existing methods still use word representation.
   To overcome these drawbacks, this article presents a novel Graph-Based Bilingual Word Embedding (GBWE) method that projects bilingual word senses into a multidimensional semantic space. First, a bilingual word co-occurrence graph is constructed using the co-occurrence and pointwise mutual information between the words. Then, maximum complete subgraphs (cliques), which play the role of a minimal unit for bilingual sense representation, are dynamically extracted according to the contextual information. Consequently, correspondence analysis, principal component analyses, and neural networks are used to summarize the clique-word matrix into lower dimensions to build the embedding model.
   Without contextual information, the proposed GBWE can be applied to lexical translation. In addition, given contextual information, GBWE is able to give a dynamic solution for bilingual word representations, which can be applied to phrase translation and generation. Empirical results show that GBWE can enhance the performance of lexical translation, as well as Chinese/French-to-English and Chinese-to-Japanese phrase-based SMT tasks (IWSLT, NTCIR, NIST, and WAT).
RI Wang, Rui/AAI-1990-2020
OI Wang, Rui/0000-0001-8007-2503; Lu, Bao-Liang/0000-0001-8359-0058
SN 2375-4699
EI 2375-4702
PD AUG
PY 2018
VL 17
IS 4
AR 31
DI 10.1145/3203078
UT WOS:000444668300006
ER

PT J
AU Ning, W
   Fei, JY
   Gonzalez, RL
AF Ning, Wei
   Fei, Jingyi
   Gonzalez, Ruben L., Jr.
TI The ribosome uses cooperative conformational changes to maximize and
   regulate the efficiency of translation
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
AB One of the most challenging unanswered questions regarding the structural biology of biomolecular machines such as the two-subunit ribosome is whether and how these machines coordinate seemingly independent and random conformational fluctuations to maximize and regulate their functional efficiencies. To address this question, we have used ribosome mutagenesis or a ribosome-targeting antibiotic to predictably perturb the dynamics of intersubunit rotation, a structural rearrangement of the ribosome that is essential for the translocation and ejection of ribosome-bound tRNAs during translation. Concomitantly, we have used single-molecule fluorescence resonance energy transfer (smFRET) to characterize the effects of these perturbations on the dynamics of ribosomal L1 stalk movements and ribosome-bound tRNA reconfigurations, conformational changes that are likewise essential for the translocation and ejection of tRNAs during translation. Together with the results of complementary biochemical studies, our smFRET studies demonstrate that the ribosome uses cooperative conformational changes to maximize and regulate the efficiency with which it translocates and ejects tRNAs during translation. We propose that the ribosome employs cooperative conformational changes to efficiently populate global conformational states that are productive for translation, that translation factors exploit this cooperativity as part of their mechanisms of action, and that antibiotics exploit it to maximize the potency with which they inhibit translation. It is likely that similar cooperative conformational changes underlie the function and regulation of other biomolecular machines.
SN 0027-8424
PD AUG 19
PY 2014
VL 111
IS 33
BP 12073
EP 12078
DI 10.1073/pnas.1401864111
UT WOS:000340438800049
PM 25085895
ER

PT J
AU Costa-jussa, MR
   Fonollosa, JAR
   Monte, E
AF Costa-jussa, Marta R.
   Fonollosa, Jose A. R.
   Monte, Enric
TI Recursive alignment block classification technique for word reordering
   in statistical machine translation
SO LANGUAGE RESOURCES AND EVALUATION
AB Statistical machine translation (SMT) is based on alignment models which learn from bilingual corpora the word correspondences between source and target language. These models are assumed to be capable of learning reorderings. However, the difference in word order between two languages is one of the most important sources of errors in SMT. In this paper, we show that SMT can take advantage of inductive learning in order to solve reordering problems. Given a word alignment, we identify those pairs of consecutive source blocks (sequences of words) whose translation is swapped, i.e. those blocks which, if swapped, generate a correct monotonic translation. Afterwards, we classify these pairs into groups, following recursively a co-occurrence block criterion, in order to infer reorderings. Inside the same group, we allow new internal combination in order to generalize the reorder to unseen pairs of blocks. Then, we identify the pairs of blocks in the source corpora (both training and test) which belong to the same group. We swap them and we use the modified source training corpora to realign and to build the final translation system. We have evaluated our reordering approach both in alignment and translation quality. In addition, we have used two state-of-the-art SMT systems: a Phrased-based and an Ngram-based. Experiments are reported on the EuroParl task, showing improvements almost over 1 point in the standard MT evaluation metrics (mWER and BLEU).
RI Fonollosa, José A. R./K-7028-2013; Monte Moreno, Enrique/F-8218-2013;
   Costa-jussà, Marta R./M-7886-2013
OI Fonollosa, José A. R./0000-0001-9513-7939; Monte Moreno,
   Enrique/0000-0002-4907-0494; Costa-jussà, Marta R./0000-0002-5703-520X
SN 1574-020X
EI 1574-0218
PD MAY
PY 2011
VL 45
IS 2
BP 165
EP 179
DI 10.1007/s10579-010-9133-9
UT WOS:000289850000004
ER

PT J
AU Yan, D
   Wang, JY
AF Yan, Da
   Wang, Junyue
TI Teaching data science to undergraduate translation trainees: Pilot
   evaluation of a task-based course
SO FRONTIERS IN PSYCHOLOGY
AB The advancement in technology has changed the workflow and the role of human translator in recent years. The impact from the trend of technology-mediated translation prompted the ratification of technology literacy as a major competence for modern translators. Consequently, teaching of translation technology including but not limited to Computer-aided Translation (CAT) and Machine Translation (MT) became part of comprehensive curricula for translation training programs. However, in many institutions, the teaching of translation technology was haunted by issues such as: narrow scope of curriculum design, outdated technologies, and unbalance between theories and practices in teaching. The study was the pilot evaluation of a tailored course to foster translation trainees' knowledge and abilities of data science. The course was designed to be a fundamental step toward sophisticated translation technologies. During the pilot evaluation of the 8-week course, 85 students (n = 85) were recruited as participants. The study adopted a mix-method design by employing a survey to investigate student's level of satisfaction toward the course and focus group discussion to understand students' attitudes and perceptions of key aspects of the course. By interpreting the results from statistical analysis of the survey (5.39/7) and thematic analysis of the focus group discussion, the course of data science for translators was well received among participants. The evaluation project manifested the feasibility and effectiveness of a translator-oriented data science course.
RI Da, Yan/AAE-3520-2022
OI Yan, Da/0000-0002-1265-9772
SN 1664-1078
PD AUG 3
PY 2022
VL 13
AR 939689
DI 10.3389/fpsyg.2022.939689
UT WOS:000841166400001
PM 35992492
ER

PT C
AU Ke, XH
AF Ke Xiao-hua
GP IEEE Computer Soc
TI An Automatic Translation Evaluation System Based on Semantic
   Similarities and Fuzzy Neartude
SO 2009 INTERNATIONAL CONFERENCE ON ENVIRONMENTAL SCIENCE AND INFORMATION
   APPLICATION TECHNOLOGY, VOL III, PROCEEDINGS,
CT International Conference on Environmental Science and Information
   Application Technology (ESIAT 2009)
CY JUL 04-05, 2009
CL Wuhan, PEOPLES R CHINA
SP Intelligent Informat Technol Applicat Res Assoc, Indt Geodesy & Geophys, Chinese Acad Sci, Engn Technol Press
AB Most current translation assignments and tests are evaluated in manual work instead of machine, as automatic translation assessment has been considered to be very difficult. In this paper, a system was proposed to evaluate the quality of translation based on semantic similarities and fuzzy neartude. The experiment results are promising and indicate that the system can identify the sementic characteristics and yeild scores that correlate with human judgments of translation quality. Our future work is to improve the evaluation strategies and introduce more linguistic resources.
BN 978-0-7695-3682-8
PY 2009
BP 583
EP 586
DI 10.1109/ESIAT.2009.197
UT WOS:000274010700139
ER

PT J
AU Lee, S
   Lee, J
   Moon, H
   Park, C
   Seo, J
   Eo, S
   Koo, S
   Lim, H
AF Lee, Seungjun
   Lee, Jungseob
   Moon, Hyeonseok
   Park, Chanjun
   Seo, Jaehyung
   Eo, Sugyeong
   Koo, Seonmin
   Lim, Heuiseok
TI A Survey on Evaluation Metrics for Machine Translation
SO MATHEMATICS
AB The success of Transformer architecture has seen increased interest in machine translation (MT). The translation quality of neural network-based MT transcends that of translations derived using statistical methods. This growth in MT research has entailed the development of accurate automatic evaluation metrics that allow us to track the performance of MT. However, automatically evaluating and comparing MT systems is a challenging task. Several studies have shown that traditional metrics (e.g., BLEU, TER) show poor performance in capturing semantic similarity between MT outputs and human reference translations. To date, to improve performance, various evaluation metrics have been proposed using the Transformer architecture. However, a systematic and comprehensive literature review on these metrics is still missing. Therefore, it is necessary to survey the existing automatic evaluation metrics of MT to enable both established and new researchers to quickly understand the trend of MT evaluation over the past few years. In this survey, we present the trend of automatic evaluation metrics. To better understand the developments in the field, we provide the taxonomy of the automatic evaluation metrics. Then, we explain the key contributions and shortcomings of the metrics. In addition, we select the representative metrics from the taxonomy, and conduct experiments to analyze related problems. Finally, we discuss the limitation of the current automatic metric studies through the experimentation and our suggestions for further research to improve the automatic evaluation metrics.
OI Lee, Jungseob/0000-0002-9431-6342
EI 2227-7390
PD FEB
PY 2023
VL 11
IS 4
AR 1006
DI 10.3390/math11041006
UT WOS:000940792200001
ER

PT C
AU Akbacak, M
   Franco, H
   Frandsen, M
   Hasan, S
   Jameel, H
   Kathol, A
   Khadivi, S
   Lei, X
   Mandal, A
   Mansour, S
   Precoda, K
   Richey, C
   Vergyri, D
   Wang, W
   Yang, M
   Zheng, J
AF Akbacak, Murat
   Franco, Horacio
   Frandsen, Michael
   Hasan, Sasa
   Jameel, Huda
   Kathol, Andreas
   Khadivi, Shahram
   Lei, Xin
   Mandal, Arindam
   Mansour, Saab
   Precoda, Kristin
   Richey, Colleen
   Vergyri, Dimitra
   Wang, Wen
   Yang, Mei
   Zheng, Jing
GP IEEE
TI RECENT ADVANCES IN SRI'S IRAQCOMM (TM) IRAQI ARABIC-ENGLISH
   SPEECH-TO-SPEECH TRANSLATION SYSTEM
SO 2009 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING, VOLS 1- 8, PROCEEDINGS
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
CT IEEE International Conference on Acoustics, Speech and Signal Processing
CY APR 19-24, 2009
CL Taipei, TAIWAN
SP IEEE, IEEE Signal Proc Soc
AB We summarize recent progress on SRI's IraqComm (TM) Iraqi Arabic-English two-way speech-to-speech translation system. In the past year we made substantial developments in our speech recognition and machine translation technology, leading to significant improvements in both accuracy and speed of the IraqComm system. On the 2008 NIST-evaluation dataset our two-way speech-to-text (S2T) system achieved 6% to 8% absolute improvement in BLEU in both directions, compared to our previous year system [1].
SN 1520-6149
BN 978-1-4244-2353-8
PY 2009
BP 4809
EP +
DI 10.1109/ICASSP.2009.4960707
UT WOS:000268919202277
ER

PT J
AU Lyu, X
   Li, JH
   Zhang, M
   Ding, CC
   Tanaka, H
   Utiyama, M
AF Lyu, Xinglin
   Li, Junhui
   Zhang, Min
   Ding, Chenchen
   Tanaka, Hideki
   Utiyama, Masao
TI Refining History for Future-Aware Neural Machine Translation
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB Neural machine translation uses a decoder to generate target words auto-regressively by predicting the next target word conditioned on a given source sentence and its previously predicted target words, i.e, its translation history, which suffers from two limitations: 1) the prediction of next word depends heavily on the quality of its history information. Moreover, the discrepancy between training and inference exacerbates this limitation; 2) this left-to-right decoding way cannot make full use of the target-side future information, which leads to the issue of unbalanced outputs. On the one hand, we alleviate the first limitation with a history-refining module, which learns to examine the quality of each history word by assigning it a confidence score. The confidence score is further used as a gate to control the amount of its word embedding flowing to the decoder. On the other hand, we attack the second limitation with a future-foreseeing module, which learns the distribution of future translation at each decoding time step. More importantly, we further propose refining history for future-aware NMT since the two modules can be closely incorporated as they focus on different kinds of context. Experimental results on various translation tasks with different scaled datasets, including WMT English$\leftrightarrow${German, French, Romanian}, show that our proposed approach achieves significant improvements over strong Transformer-based NMT baselines.
OI Lyu, Xinglin/0000-0003-1971-6618
SN 2329-9290
EI 2329-9304
PY 2023
VL 31
BP 500
EP 512
DI 10.1109/TASLP.2022.3226332
UT WOS:000900025700004
ER

PT C
AU Hu, YN
   Zhai, K
   Eidelman, V
   Boyd-Graber, J
AF Hu, Yuening
   Zhai, Ke
   Eidelman, Vladimir
   Boyd-Graber, Jordan
BE Toutanova, K
   Wu, H
TI Polylingual Tree-Based Topic Models for Translation Domain Adaptation
SO PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS, VOL 1
CT 52nd Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUN 22-27, 2014
CL Baltimore, MD
SP Assoc Computat Linguist, Baidu, Bloomberg, Google, Microsoft, Nuance, Yahoo Labs, Informat Sci Inst, Xerox Res Ctr Europe, Brandeis Univ, Facebook, Yandex, Amazon Com, IBM Watson, Johns Hopkins Univ, A9, AI@ISI, Xerox
AB Topic models, an unsupervised technique for inferring translation domains improve machine translation quality. However, previous work uses only the source language and completely ignores the target language, which can disambiguate domains. We propose new polylingual tree-based topic models to extract domain knowledge that considers both source and target languages and derive three different inference schemes. We evaluate our model on a Chinese to English translation task and obtain up to 1.2 BLEU improvement over strong baselines.
OI Boyd-Graber, Jordan/0000-0002-7770-4431
BN 978-1-937284-72-5
PY 2014
BP 1166
EP 1176
UT WOS:000493814100110
ER

PT C
AU Meng, FD
   Zhang, JC
AF Meng, Fandong
   Zhang, Jinchao
GP AAAI
TI DTMT: A Novel Deep Transition Architecture for Neural Machine
   Translation
SO THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 33rd AAAI Conference on Artificial Intelligence / 31st Innovative
   Applications of Artificial Intelligence Conference / 9th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY JAN 27-FEB 01, 2019
CL Honolulu, HI
SP Assoc Advancement Artificial Intelligence
AB Past years have witnessed rapid developments in Neural Machine Translation (NMT). Most recently, with advanced modeling and training techniques, the RNN-based NMT (RNMT) has shown its potential strength, even compared with the well-known Transformer (self-attentional) model. Although the RNMT model can possess very deep architectures through stacking layers, the transition depth between consecutive hidden states along the sequential axis is still shallow. In this paper, we further enhance the RNN-based NMT through increasing the transition depth between consecutive hidden states and build a novel Deep Transition RNN-based Architecture for Neural Machine Translation, named DTMT. This model enhances the hidden-to-hidden transition with multiple non-linear transformations, as well as maintains a linear transformation path throughout this deep transition by the well-designed linear transformation mechanism to alleviate the gradient vanishing problem. Experiments show that with the specially designed deep transition modules, our DTMT can achieve remarkable improvements on translation quality. Experimental results on Chinese double right arrow English translation task show that DTMT can outperform the Transformer model by +2.09 BLEU points and achieve the best results ever reported in the same dataset. On WMT14 English double right arrow German and English double right arrow French translation tasks, DTMT shows superior quality to the state-of-the-art NMT systems, including the Transformer and the RNMT+.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-809-1
PY 2019
BP 224
EP 231
UT WOS:000485292600028
ER

PT J
AU El-Fakih, K
   Yevtushenko, N
AF El-Fakih, Khaled
   Yevtushenko, Nina
TI Test Translation for Embedded Finite State Machine Components
SO COMPUTER JOURNAL
AB We consider a composite system consisting of two communicating finite state machines, an embedded component and a context representing the remaining parts of the system. In this article, a method is proposed for translating a complete internal test suite defined over the unobservable alphabets of the embedded component into a complete external test suite defined over the observable external alphabets of the system, assuming that the context is fault-free. Propositions are established to verify the different steps of the proposed method and a detailed application example illustrating these steps is included.
RI Yevtushenko, Nina V./R-6494-2016
SN 0010-4620
EI 1460-2067
PD DEC 1
PY 2016
VL 59
IS 12
BP 1805
EP 1816
DI 10.1093/comjnl/bxw028
UT WOS:000397054600004
ER

PT J
AU Kulkarni, A
   Jayaraman, VK
   Kulkarni, BD
AF Kulkarni, A
   Jayaraman, VK
   Kulkarni, BD
TI Knowledge incorporated support vector machines to detect faults in
   Tennessee Eastman Process
SO COMPUTERS & CHEMICAL ENGINEERING
AB A support vector machine with knowledge incorporation is applied to detect the faults in Tennessee Eastman Process, a benchmark problem in chemical engineering. The knowledge incorporated algorithm takes advantage of the information on horizontal translation invariance in tangent direction of the instances in dataset. This essentially changes the representation of the input data while training the algorithm. These local translations do not alter the class membership of the instances in the dataset. The results on binary as well as multiple fault detection justify the use of knowledge incorporation. (c) 2005 Elsevier Ltd. All rights reserved.
RI KULKARNI, B/C-1371-2009
SN 0098-1354
EI 1873-4375
PD SEP 15
PY 2005
VL 29
IS 10
BP 2128
EP 2133
DI 10.1016/j.compchemeng.2005.06.006
UT WOS:000232838800009
ER

PT C
AU Ture, F
   Lin, J
   Oard, DW
AF Ture, Ferhan
   Lin, Jimmy
   Oard, Douglas W.
GP ASSOC COMP MACHINERY
TI Looking Inside the Box: Context-Sensitive Translation for Cross-Language
   Information Retrieval
SO SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE
   ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL
CT 35th ACM SIGIR Annual International Conference on Research and
   Development in Information Retrieval
CY AUG 12-16, 2012
CL Portland, OR
SP Assoc Comp Machinery Special Interest Grp Informat Retrieval, Assoc Comp Machinery
AB Cross-language information retrieval (CLIR) today is dominated by techniques that use token-to-token mappings from bilingual dictionaries. Yet, state-of-the-art statistical translation models (e.g., using Synchronous Context-Free Grammars) are far richer, capturing multi-term phrases, term dependencies, and contextual constraints on translation choice. We present a novel CLIR framework that is able to reach inside the translation "black box" and exploit these sources of evidence. Experiments on the TREC-5/6 English-Chinese test collection show this approach to be promising.
BN 978-1-4503-1658-3
PY 2012
BP 1105
EP 1106
UT WOS:000693632400174
ER

PT C
AU Wang, S
   Liu, Y
   Wang, C
   Luan, HB
   Sun, MS
AF Wang, Shuo
   Liu, Yang
   Wang, Chao
   Luan, Huanbo
   Sun, Maosong
GP Assoc Computat Linguist
TI Improving Back-Translation with Uncertainty-based Confidence Estimation
SO 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND
   THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE
CT Conference on Empirical Methods in Natural Language Processing / 9th
   International Joint Conference on Natural Language Processing
   (EMNLP-IJCNLP)
CY NOV 03-07, 2019
CL Hong Kong, HONG KONG
SP Google, Facebook, Apple, ASAPP, Salesforce, Huawei, Baidu, Deepmind, Amazon, PolyAI, Naver, ByteDance, Megagon Labs, Zhuiyi, Verisk, MI
AB While back-translation is simple and effective in exploiting abundant monolingual corpora to improve low-resource neural machine translation (NMT), the synthetic bilingual corpora generated by NMT models trained on limited authentic bilingual data are inevitably noisy. In this work, we propose to quantify the confidence of NMT model predictions based on model uncertainty. With word- and sentence-level confidence measures based on uncertainty, it is possible for back-translation to better cope with noise in synthetic bilingual corpora. Experiments on Chinese-English and English-German translation tasks show that uncertainty-based confidence estimation significantly improves the performance of back-translation.(1)
OI Wang, Chao/0000-0002-7427-793X
BN 978-1-950737-90-1
PY 2019
BP 791
EP 802
UT WOS:000854193300073
ER

PT C
AU Tan, X
   Chen, JL
   He, D
   Xia, YC
   Qin, T
   Liu, TY
AF Tan, Xu
   Chen, Jiale
   He, Di
   Xia, Yingce
   Qin, Tao
   Liu, Tie-Yan
GP Assoc Computat Linguist
TI Multilingual Neural Machine Translation with Language Clustering
SO 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND
   THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE
CT Conference on Empirical Methods in Natural Language Processing / 9th
   International Joint Conference on Natural Language Processing
   (EMNLP-IJCNLP)
CY NOV 03-07, 2019
CL Hong Kong, HONG KONG
SP Google, Facebook, Apple, ASAPP, Salesforce, Huawei, Baidu, Deepmind, Amazon, PolyAI, Naver, ByteDance, Megagon Labs, Zhuiyi, Verisk, MI
AB Multilingual neural machine translation (NMT), which translates multiple languages using a single model, is of great practical importance due to its advantages in simplifying the training process, reducing online maintenance costs, and enhancing low-resource and zero-shot translation. Given there are thousands of languages in the world and some of them are very different, it is extremely burdensome to handle them all in a single model or use a separate model for each language pair. Therefore, given a fixed resource budget, e.g., the number of models, how to determine which languages should be supported by one model is critical to multilingual NMT, which, unfortunately, has been ignored by previous work. In this work, we develop a framework that clusters languages into different groups and trains one multilingual model for each cluster. We study two methods for language clustering: (1) using prior knowledge, where we cluster languages according to language family, and (2) using language embedding, in which we represent each language by an embedding vector and cluster them in the embedding space. In particular, we obtain the embedding vectors of all the languages by training a universal neural machine translation model. Our experiments on 23 languages show that the first clustering method is simple and easy to understand but leading to suboptimal translation accuracy, while the second method sufficiently captures the relationship among languages well and improves the translation accuracy for almost all the languages over baseline methods.
BN 978-1-950737-90-1
PY 2019
BP 963
EP 973
UT WOS:000854193301011
ER

PT C
AU Antonopoulos, V
   Demiros, I
   Carayannis, G
   Piperidis, S
AF Antonopoulos, V
   Demiros, I
   Carayannis, G
   Piperidis, S
GP ieee
TI Integrating translation technologies towards a powerful translation web
   service
SO 2004 IEEE CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS, VOLS 1 AND
   2
CT IEEE Conference on Cybernetics and Intelligent Systems
CY DEC 01-03, 2004
CL Singapore, SINGAPORE
SP IEEE
AB Rapid changes in the global marketplace have given rise to new demands and have provided new opportunities for the translation industry. The need for multilinguality in the presentation and business logic layers of most modern systems, applications and services is a great challenge that the translation industry now faces. But even after many years of intense research and many commercial attempts of related products, translation systems of today still fail to completely meet the above needs. Within this framework, an architecture of a modern automatic translation system exploiting current infrastructure and covering today and future needs is proposed in this paper.
BN 0-7803-8643-4
PY 2004
BP 526
EP 531
UT WOS:000227335800094
ER

PT C
AU Perez, A
   Alcaide, JM
   Torres, MI
AF Perez, Alicia
   Alcaide, Jose M.
   Torres, Maria-Ines
GP International Speech Communications Association
TI EuskoParl: a speech and text Spanish-Basque parallel corpus
SO 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3
CT 13th Annual Conference of the
   International-Speech-Communication-Association
CY SEP 09-13, 2012
CL Portland, OR
SP Int Speech Commun Assoc
AB The advances in corpus-based approaches and machine learning techniques have promoted the development of minority languages. The contribution of this work is to acquire a parallel corpus in Spanish and Basque with both text and speech data. In order to be able to compare the systems with those developed for other languages, Europarl corpus was taken as a reference in both domain and size. The acquisition process, carried out within the Basque Parliament reports and speeches, involved subtle differences to that of Europarl acquisition. The resulting corpus is described and a few preliminary experiments on machine translation with Moses are reported.
RI Torres BaraÃano, MarÃa InÃ©s/ABF-7494-2021; Torres, Maria/GVU-3391-2022;
   Pérez, Alicia/S-8562-2016; Torres, María Inés/M-5490-2013; Pérez,
   Alicia/AAF-7338-2019
OI Torres BaraÃano, MarÃa InÃ©s/0000-0002-1773-3214; Pérez,
   Alicia/0000-0003-2638-9598; Torres, María Inés/0000-0002-1773-3214;
   Pérez, Alicia/0000-0003-2638-9598; ALCAIDE SALINAS, JOSE
   MARIA/0000-0002-8798-4385
BN 978-1-62276-759-5
PY 2012
BP 2359
EP 2362
UT WOS:000320827201145
ER

PT C
AU Epaliyana, K
   Ranathunga, S
   Jayasena, S
AF Epaliyana, Koshiya
   Ranathunga, Surangika
   Jayasena, Sanath
GP IEEE
TI Improving Back-Translation with Iterative Filtering and Data Selection
   for Sinhala-English NMT
SO MORATUWA ENGINEERING RESEARCH CONFERENCE (MERCON 2021) / 7TH
   INTERNATIONAL MULTIDISCIPLINARY ENGINEERING RESEARCH CONFERENCE
CT Moratuwa Engineering Research Conference (MERCon) / 7th International
   Multidisciplinary Engineering Research Conference
CY JUL 27-29, 2021
CL Univ Moratuwa, Moratuwa, SRI LANKA
SP IEEE, IEEE Sri Lanka Sect, IEEE Univ Moratuwa Student Branch, Univ Moratuwa, Engn Res Univ, IEEE Sri Lanka Sect, Robot & Automat Soc Chapter, IEEE Power & Energy Soc Chapter, Sri Lanka Sect, IEEE Commun Soc Chapter, Sri Lanka Sect, Univ Moratuwa, Fac Engn, Univ Moratuwa, Fac Grad Studies, Univ Moratuwa, Senate Res Comm
HO Univ Moratuwa
AB Neural Machine Translation (NMI) requires a large amount of parallel data to achieve reasonable results. For low resource settings such as Sinhala-English where parallel data is scarce, NMT tends to give sub-optimal results. This is severe when the translation is domain-specific. One solution for the data scarcity problem is data augmentation. To augment the parallel data for low resource language pairs, commonly available large monolingual corpora can be used. A popular data augmentation technique is Back-Translation (BT). Over the years, there have been many techniques to improve Vanilla BT. Prominent ones are Iterative BT, Filtering, and Data selection. We employ these in Sinhala - English extremely low resource domain-specific translation in order to improve the performance of NMT. In particular, we move forward from previous research and show that by combining these different techniques. an even better result can be obtained. Our combined model provided a +3.0 BLEU score gain over the Vanilla NMT model and a +1.93 BLEU score gain over the Vanilla BT model for Sinhala -> English translation. Furthermore, a +0.65 BLEU score gain over the Vanilla NMT model and a +2.22 BLEU score gain over the Vanilla BT model were observed for English -> Sinhala translation.
RI Ranathunga, Surangika/ADV-0208-2022; Jayasena, Sanath/GXV-8641-2022
BN 978-1-6654-3753-0
PY 2021
BP 438
EP 443
DI 10.1109/MERCON52712.2021.9525800
UT WOS:000788587300077
ER

PT C
AU Liu, L
   Cao, HL
   Zhao, TJ
AF Liu, Lin
   Cao, Hailong
   Zhao, Tiejun
BE Chen, J
   Wang, X
   Wang, L
   Sun, J
   Meng, X
TI Measuring Domain Similarity for Statistical Machine Translation
SO 2013 10TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE
   DISCOVERY (FSKD)
CT 10th International Conference on Fuzzy Systems and Knowledge Discovery
   (FSKD)
CY JUL 23-25, 2013
CL Shenyang, PEOPLES R CHINA
SP IEEE, IEEE Circuits & Syst Soc
AB It is well known that the statistical machine translation (SMT) performance suffers when a model is applied to out-of-domain data. It is also known that the more similar the test domain and the training domain are, the more efficient the training data are for SMT performance. Hence, measuring the similarity of domains is an important task to select appropriate training data. The most widely used method uses the cosine similarity function and word frequency. The lack of exploring other approaches motivates us to propose and compare several similarity measures. Aiming for better SMT performance, we compared 10 similarity measures, which are a combination of 2 feature representations and 5 similarity functions. The results show that using the relative word frequency as the feature representation and using the skew divergence as the similarity function performs the best amongst the 10 measures and outperforms random data selection.
BN 978-1-4673-5253-6
PY 2013
BP 611
EP 615
UT WOS:000341633700102
ER

PT C
AU Saunders, D
   Stahlberg, F
   de Gispert, A
   Byrne, B
AF Saunders, Danielle
   Stahlberg, Felix
   de Gispert, Adria
   Byrne, Bill
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Domain Adaptive Inference for Neural Machine Translation
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB We investigate adaptive ensemble weighting for Neural Machine Translation, addressing the case of improving performance on a new and potentially unknown domain without sacrificing performance on the original domain. We adapt sequentially across two Spanish-English and three English-German tasks, comparing unregularized fine-tuning, L2 and Elastic Weight Consolidation. We then report a novel scheme for adaptive NMT ensemble decoding by extending Bayesian Interpolation with source information, and show strong improvements across test domains without access to the domain label.
BN 978-1-950737-48-2
PY 2019
BP 222
EP 228
UT WOS:000493046100022
ER

PT C
AU Chen, YD
   Shi, XD
   Zhou, CL
   Hong, QY
AF Chen, YD
   Shi, XD
   Zhou, CL
   Hong, QY
GP IEEE
TI A model for ranking sentence pairs in parallel corpora
SO PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   CYBERNETICS, VOLS 1-9
CT 4th International Conference on Machine Learning and Cybernetics
CY AUG 18-21, 2005
CL Canton, PEOPLES R CHINA
SP IEEE Systems, Man & Cybernet TCC, Hong Kong Polytechn Univ, Hebei Univ, S China Univ Technol, Chongqing Univ, Sun Yatsen Univ, Harbin Inst Technol, Int Univ Germany
AB In this paper, the problem of ranking sentence pairs in parallel corpora was addressed for the first time. To solve this problem, a novel model was proposed. In this model, both syntax features and semantics features of sentence pairs are considered. Since most today's Statistical Machine Translation models depend on word alignment, features related to word alignment information are also included. Two experiments were carried out and the results showed that the model had promising performance.
RI Chen, YD/G-4143-2010; Zhou, CL/G-4667-2010
OI Zhou, CL/0000-0002-6779-7670
BN 0-7803-9091-1
PY 2005
BP 3820
EP 3823
UT WOS:000235325605100
ER

PT C
AU Zhou, R
   Xiang, W
AF Zhou, Run
   Xiang, Wei
BE Jiang, ZY
TI Application of speech technology in the translation system
SO Proceedings of the 2016 6th International Conference on Advanced Design
   and Manufacturing Engineering (ICADME 2016)
SE AER-Advances in Engineering Research
CT 6th International Conference on Advanced Design and Manufacturing
   Engineering (ICADME)
CY JUL 23-24, 2016
CL Zhuhai, PEOPLES R CHINA
AB The speech is always the most convenient, most natural way of communication. In this paper, the application of speech technology in the translation system is studied. First, brief the developments and basic theories of speech technology. Then make a deep research for application of Speech Recognition(SR), Text To Speech(TTS) in translation system. Give structure diagrams of SR, TTS technologies and introduce the key modules. Finally, simply analysis the application prospects, needs and challenges of speech technology in various areas.
SN 2352-5401
BN 978-94-6252-249-7
PY 2016
VL 96
BP 429
EP 433
UT WOS:000392735700078
ER

PT J
AU Dorst, AG
   Valdez, S
   Bouman, H
AF Dorst, Aletta G.
   Valdez, Susana
   Bouman, Heather
TI Machine translation in the multilingual classroom How, when and why do
   humanities students at a Dutch university use machine translation?
SO TRANSLATION AND TRANSLANGUAGING IN MULTILINGUAL CONTEXTS
AB Machine Translation (MT), the process by which a computer engine such as Google Translate or Bing automatically translates a text from one language into another without any human involvement, is increasingly used in professional, institutional and everyday contexts for a wide range of purposes. While a growing number of studies has looked at professional translators and translation students, there is currently a lack of research on non-translator users and uses in multilingual contexts. This paper presents a survey examining how, when and why students at Leiden University's Faculty of Humanities use MT. A questionnaire was used to determine which MT engines students use and for what purposes, and gauge their awareness of issues concerning privacy, academic integrity and plagiarism. The findings reveal a widespread adoption of Google Translate and indicate that students use MT predominantly to look up single words, as an alternative to a dictionary. Many seemed sceptical about the value of MT for educational purposes, and many assumed that the use of MT is not permitted by lecturers for graded assignments, especially in courses focusing on language skills. The results demonstrate a clear need for more MT literacy. Students may not need practical training in how to use MT, but there is much room for improvement in terms of when and why they use it.
RI Valdez, Susana/D-8708-2017
OI Valdez, Susana/0000-0001-5461-2078
SN 2352-1805
EI 2352-1813
PD FEB 28
PY 2022
VL 8
IS 1
BP 49
EP 66
DI 10.1075/ttmc.00080.dor
UT WOS:000848197600003
ER

PT C
AU Yang, ZX
   Sun, RL
   Wan, XJ
AF Yang, Zhixian
   Sun, Renliang
   Wan, Xiaojun
GP ASSOC COMPUTAT LINGUIST
TI Nearest Neighbor Knowledge Distillation for Neural Machine Translation
SO NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE
   ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES
CT Conference of the
   North-American-Chapter-of-the-Association-for-Computational-Linguistics
   (NAAACL) - Human Language Technologies
CY JUL 10-15, 2022
CL Seattle, WA
SP Assoc Computat Linguist, N Amer Chapter, Amazon Sci, Bloomberg Engn, Google Res, LivepersoMetan, ByteDance, KENSH, Grammarly, Megagon Labs, Microsoft, Reveal Brainspace, Cohere, GResearch, Relativity, Servicenow, ASAPP, Duolingo, Adobe, Linkedin, Babelscape, Rakuten Inst Technol, UC Santa Cruz, Baskin Engn, Nat Language Proc, NSF, ETS, OpenAI, TIAA, Two Sigma, Mag Data
AB k-nearest-neighbor machine translation (kNNMT), proposed by Khandelwal et al. (2021), has achieved many state-of-the-art results in machine translation tasks. Although effective, kNN-MT requires conducting kNN searches through the large datastore for each decoding step during inference, prohibitively increasing the decoding cost and thus leading to the difficulty for the deployment in real-world applications. In this paper, we propose to move the time-consuming kNN search forward to the preprocessing phase, and then introduce k Nearest Neighbor Knowledge Distillation (kNN-KD) that trains the base NMT model to directly learn the knowledge of kNN. Distilling knowledge retrieved by kNN can encourage the NMT model to take more reasonable target tokens into consideration, thus addressing the overcorrection problem. Extensive experimental results show that, the proposed method achieves consistent improvement over the stateof-the-art baselines including kNN-MT, while maintaining the same training and decoding speed as the standard NMT model.(1)
BN 978-1-955917-71-1
PY 2022
BP 5546
EP 5556
UT WOS:000859869505048
ER

PT J
AU Qiang, JP
   Wu, XD
AF Qiang, Jipeng
   Wu, Xindong
TI Unsupervised Statistical Text Simplification
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
AB Most recent approaches for Text Simplification (TS) have drawn on insights from machine translation to learn simplification rewrites from the monolingual parallel corpus of complex and simple sentences, yet their effectiveness strongly relies on large amounts of parallel sentences. However, there has been a serious problem haunting TS for decades, that is, the availability of parallel TS corpora is scarce or not fit for the learning task. In this paper, we will focus on one especially useful and challenging problem of unsupervised TS without a single parallel sentence. To the best of our knowledge, we present the first unsupervised text simplification system based on phrase-based machine translation system, which leverages a careful initialization of phrase tables and language models. On the widely used WikiLarge and WikiSmall benchmarks, our system respectively obtains 39.08 and 25.12 SARI points, even outperforms some supervised baselines.
RI Wu, Xindong/AAB-6713-2022
OI Wu, Xindong/0000-0003-2396-1704
SN 1041-4347
EI 1558-2191
PD APR 1
PY 2021
VL 33
IS 4
BP 1802
EP 1806
DI 10.1109/TKDE.2019.2947679
UT WOS:000626617900030
ER

PT J
AU Cid, CG
   Colominas, C
   Oliver, A
AF Cid, Clara Ginovart
   Colominas, Carme
   Oliver, Antoni
TI Language industry views on the profile of the post-editor
SO TRANSLATION SPACES
AB The more language service companies (LSCs) include machine translation post-editing (MTPE) in their workflows, the more important it is to know how the PE task is performed, who the post-editors are, and what skills they should have. This research is designed to address such questions. It aims to deepen our knowledge of current practices to later create new training content and adapt existing training methodologies to different types of audiences. Based on the results of a survey of LSCs and other companies who currently use MTPE, we present a picture of evolving practices in the contemporary European MTPE market, and opinions held about this emerging metier. Our research finds that a high level of expertise in MTPE may not necessarily be indicative of the industry, and that the post-editor of MT has a multi- and transdisciplinary profile.
OI Ginovart Cid, Clara/0000-0001-9764-5662; Oliver,
   Antoni/0000-0001-8399-3770
SN 2211-3711
EI 2211-372X
PY 2020
VL 9
IS 2
BP 283
EP 313
DI 10.1075/ts.19010.cid
UT WOS:000635067200006
ER

PT C
AU Tufano, M
   Watson, C
   Bavota, G
   Di Penta, M
   White, M
   Poshyvanyk, D
AF Tufano, Michele
   Watson, Cody
   Bavota, Gabriele
   Di Penta, Massimiliano
   White, Martin
   Poshyvanyk, Denys
BE Huchard, M
   Kastner, C
   Fraser, G
TI An Empirical Investigation into Learning Bug-Fixing Patches in the Wild
   via Neural Machine Translation
SO PROCEEDINGS OF THE 2018 33RD IEEE/ACM INTERNATIONAL CONFERENCE ON
   AUTOMTED SOFTWARE ENGINEERING (ASE' 18)
SE IEEE ACM International Conference on Automated Software Engineering
CT 33rd IEEE/ACM International Conference on Automated Software Engineering
   (ASE)
CY SEP 03-07, 2018
CL Montpellier, FRANCE
SP IEEE, Assoc Comp Machinery, ACM SIGSOFT, ACM SIGAI, CNRS, IEEE CS, Huawei, Berger Levrault, Mobioos, Toyota InfoTechnol Ctr, Reg Occitanie, Inria, LIRMM, Univ Montpellier, Inst Mines Telecom Ecole Mines Telecom, Montpellier Univ Excellence, Investissements DAvenir
AB Millions of open-source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. We mine millions of bug-fixes from the change histories of GitHub repositories to extract meaningful examples of such bug-fixes. Then, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. Our model is able to fix hundreds of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9% of the cases.
RI Di Penta, Massimiliano/AAF-9656-2021
OI BAVOTA, Gabriele/0000-0002-2216-3148; Poshyvanyk,
   Denys/0000-0002-5626-7586
SN 1527-1366
BN 978-1-4503-5937-5
PY 2018
BP 832
EP 837
DI 10.1145/3238147.3240732
UT WOS:000553784500081
ER

PT C
AU Adak, C
AF Adak, Chandranath
GP IEEE
TI A Bilingual Machine Translation System: English & Bengali
SO 2014 FIRST INTERNATIONAL CONFERENCE ON AUTOMATION, CONTROL, ENERGY &
   SYSTEMS (ACES-14)
CT 1st International Conference on Automation, Control, Energy and Systems
   (ACES)
CY FEB 01-02, 2014
CL INDIA
SP Acad Technol, Dept Elect Engn, IEEE
AB Natural language is a fundamental thing of human-society to communicate and interact with one another. In this globalization era, we interact with different regional people as per our interest in social, cultural, economical, educational and professional domain. There are thousands of natural languages exist in our earth. It is quite tough, rather impossible to know all the languages. So we need a computerized approach to convert one natural language to another as per our necessity. This computerized conversion among multiple languages is known as multilingual machine translation. But in this paper we work with a bilingual model, where we concern with two languages: English and Bengali. We use soft computational approach where fuzzy If-Then rule is applied to choose a lemma from prior knowledge; Penn TreeBank PoS tags and HMM tagger are used as lexical class marker to each word in corpora.
RI Adak, Chandranath/O-9723-2016
OI Adak, Chandranath/0000-0002-9085-2770
BN 978-1-4799-3893-3
PY 2014
BP 271
EP 274
UT WOS:000355253900051
ER

PT C
AU Falavigna, D
   Gerosa, M
   Gretter, R
   Giuliani, D
AF Falavigna, D.
   Gerosa, M.
   Gretter, R.
   Giuliani, D.
GP IEEE
TI Phone-to-Word decoding through statistical machine translation and
   complementary system combination
SO 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU
   2009)
CT IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU
   2009)
CY DEC 13-17, 2009
CL Merano, ITALY
AB In this paper, phone-to-word transduction is first investigated by coupling a speech recognizer, generating for each speech segment a phone sequence or a phone confusion network, with the efficient decoder of confusion networks adopted by MOSES, a popular statistical machine translation toolkit. Then, system combination is investigated by combining the outputs of several conventional ASR systems with the output of a system embedding phone-to-word decoding through statistical machine translation.
   Experiments are carried out in the context of a large vocabulary speech recognition task consisting of transcription of speeches delivered in English during the European Parliament Plenary Sessions (EPPS). While only a marginal performance improvements is achieved in system combination experiments when the output of the phone-to-word transducer is included in the combination, partial results show a great potential for improvements.
OI Gerosa, Matteo/0000-0001-7741-0436
BN 978-1-4244-5478-5
PY 2009
BP 519
EP 524
DI 10.1109/ASRU.2009.5373281
UT WOS:000291368500096
ER

PT S
AU McLaughlin, S
   Schwall, U
AF McLaughlin, S
   Schwall, U
BE Farwell, D
   Gerber, L
   Hovy, E
TI Spicing up the information soup: Machine Translation and the Internet
SO MACHINE TRANSLATION AND THE INFORMATION SOUP
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
CT 3rd Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 28-31, 1998
CL LANGHORNE, PENNSYLVANIA
SP Systran Inc, Logos Corp, Globalink Inc, Univ Penn Inst Res Cognitive Sci
AB The Internet is rapidly changing the face of business and dramatically transforming people's working and private lives. These developments present both a challenge and an opportunity to many technologies, one of the most important being Machine Translation. The Internet will soon be the most important medium for offering and finding information, and one of the principle means of communication fur both companies and private users. There are many players on the Internet scene, each with different needs. Some players require help in presenting their information to an international audience, others require help in finding the information they seek and, because the Internet is increasingly multilingual, help in understanding that which they find. This paper attempts to identify the players and their needs, and outlines the products and services with which Machine Translation can help them to fully participate in the Internet revolution.
SN 0302-9743
BN 3-540-65259-0
PY 1998
VL 1529
BP 384
EP 397
UT WOS:000086659400035
ER

PT J
AU MANKAI, C
   MILI, A
AF MANKAI, C
   MILI, A
TI MACHINE TRANSLATION FROM ARABIC TO ENGLISH AND FRENCH
SO INFORMATION SCIENCES-APPLICATIONS
AB As the cognitive processes of natural language understanding and generation are better understood, it is becoming easier, nowadays, to perform machine translation.  In this paper we present our work on machine translation from Arabic to English and French, and illustrate it with a fully operational system, which runs on PC compatibles with Arabic/Latin interface.  This system is an extension of an earlier system, whose task was the analysis of the natural language Arabic.  Thanks to the regularity of its phrase structures and word patterns, Arabic lends itself quite naturally to a Fillmore-like analysis.  The meaning of a phrase is stored in a star-like data structure, where the verb occupies the center of the star and the various noun sentences occupy specific peripheral nodes of the star.  The data structure is then translated into an internal representation in the target language, which is then mapped into the target text.
OI mili, amira/0000-0003-3002-7303
SN 1069-0115
PD MAR
PY 1995
VL 3
IS 2
BP 91
EP 109
DI 10.1016/1069-0115(94)00059-B
UT WOS:A1995QQ30300002
ER

PT C
AU Haque, R
   Moslem, Y
   Way, A
AF Haque, Rejwanul
   Moslem, Yasmin
   Way, Andy
GP Assoc Computat Linguist
TI The ADAPT System Description for the STAPLE 2020 English-to-Portuguese
   Translation Task
SO NEURAL GENERATION AND TRANSLATION
CT 4th Workshop on Neural Generation and Translation
CY JUL 05-10, 2020
CL ELECTR NETWORK
AB This paper describes the ADAPT Centre's submission to STAPLE (Simultaneous Translation and Paraphrase for Language Education) 2020, a shared task of the 4th Workshop on Neural Generation and Translation (WNGT), for the English-to-Portuguese translation task. In this shared task, the participants were asked to produce high-coverage sets of plausible translations given English prompts (input source sentences). We present our English-to-Portuguese machine translation (MT) models that were built applying various strategies, e.g. data and sentence selection, monolingual MT for generating alternative translations, and combining multiple nbest translations. Our experiments show that adding the aforementioned techniques to the baseline yields an excellent performance in the English-to-Portuguese translation task.
RI Moslem, Yasmin/GLS-9436-2022; Haque, Rejwanul/C-4581-2017
OI Moslem, Yasmin/0000-0003-4595-6877; Haque, Rejwanul/0000-0003-1680-0099
BN 978-1-952148-17-0
PY 2020
BP 144
EP 152
UT WOS:000563428500017
ER

PT C
AU Skadins, R
   Sics, V
   Rozis, R
AF Skadins, Raivis
   Sics, Valters
   Rozis, Roberts
BE Utka, A
   Grigonyte, G
   KapociuteDzikiene, J
   Vaicenoniene, J
TI Building the World's Best General Domain MT for Baltic Languages
SO HUMAN LANGUAGE TECHNOLOGIES - THE BALTIC PERSPECTIVE, BALTIC HLT 2014
SE Frontiers in Artificial Intelligence and Applications
CT 6th International Conference on Human Language Technologies - The Baltic
   Perspective (Baltic HLT)
CY SEP 26-27, 2014
CL Kaunas, LITHUANIA
SP Vytautas Magnus Univ, ViaConventus
AB In this paper we present our experience in building machine translation (MT) systems for the languages of the Baltic States: Estonian, Latvian, and Lithuanian. The paper reports on the implementation, research, data, data collection methods, and evaluation of the MT. Results of the evaluation show that it is possible to collect a sufficient amount of data and train MT systems that can compete with Google in quality and even overtake it in general domain MT.
OI Skadins, Raivis/0000-0003-0929-2380
SN 0922-6389
EI 1879-8314
BN 978-1-61499-442-8; 978-1-61499-441-1
PY 2014
VL 268
BP 141
EP 148
DI 10.3233/978-1-61499-442-8-141
UT WOS:000349540000021
ER

PT J
AU Bayatli, S
   Kurnaz, S
   Ali, A
   Washington, JN
   Tyers, FM
AF Bayatli, Sevilay
   Kurnaz, Sefer
   Ali, Aboelhamd
   Washington, Jonathan North
   Tyers, Francis M.
TI Unsupervised Weighting of Transfer Rules in Rule-Based Machine
   Translation using Maximum-Entropy Approach
SO JOURNAL OF INFORMATION SCIENCE AND ENGINEERING
AB In this paper we present an unsupervised method for learning a model to distinguish between ambiguous selection of structural transfer rules in a rule-based machine translation (MT) system. In rule-based MT systems, transfer rules are the component responsible for converting source language morphological and syntactic structures to target language structures. These transfer rules function by matching a source language pattern of lexical items and applying a sequence of actions. There can, however, be more than one potential sequence of actions for each source language pattern. Our model consists of a set of maximum entropy (or logistic regression) classifiers, one trained for each source language pattern, which select the highest probability sequence of rules for a given sequence of patterns. We perform experiments on the Kazakh - Turkish language pair - a low-resource pair of morphologically-rich languages - and compare our model to two reference MT systems, a rule-based system where transfer rules are applied in a left-to-right longest match manner and to a state-of-the-art system based on the neural encoder-decoder architecture. Our system outforms both of these reference systems in three widely used metrics for machine translation evaluation.
SN 1016-2364
PD MAR
PY 2020
VL 36
IS 2
BP 309
EP 322
DI 10.6688/JISE.202003_36(2).0010
UT WOS:000523607200010
ER

PT C
AU Ranta, A
AF Ranta, Aarne
BE Davis, B
   Kaljurand, K
   Kuhn, T
TI Embedded Controlled Languages
SO CONTROLLED NATURAL LANGUAGE, CNL 2014
SE Lecture Notes in Computer Science
CT 4th International Workshop on Controlled Natural Language (CNL)
CY AUG 20-22, 2014
CL Natl Univ Ireland, Galway, IRELAND
HO Natl Univ Ireland
AB Inspired by embedded programming languages, an embedded CNL (controlled natural language) is a proper fragment of an entire natural language (its host language), but it has a parser that recognizes the entire host language. This makes it possible to process out-of-CNL input and give useful feedback to users, instead of just reporting syntax errors. This extended abstract explains the main concepts of embedded CNL implementation in GF (Grammatical Framework), with examples from machine translation and some other ongoing work.
SN 0302-9743
EI 1611-3349
BN 978-3-319-10223-8
PY 2014
VL 8625
BP 1
EP 7
UT WOS:000342920600001
ER

PT C
AU Xu, L
   Cao, XG
   Zhang, BF
   Li, M
AF Xu, Lin
   Cao, Xiaoguang
   Zhang, Bufeng
   Li, Mu
BE Gelbukh, A
TI Comparing and integrating alignment template and standard phrase-based
   statistical machine translation
SO Computational Linguistics and Intelligent Text Processing
SE LECTURE NOTES IN COMPUTER SCIENCE
CT 8th International Conference on Intelligent Text Processing and
   Computational Linguistics
CY FEB 18-24, 2007
CL Mexico City, MEXICO
SP IPN, Nat Language & Text Proc Lab
AB In statistical machine translation (SMT) research, phrase-based methods have been receiving more interest in recent years. In this paper, we first give a brief survey of phrase-based SMT framework, and then make detailed comparisons of two typical implementations: alignment template approach and standard phrase-based approach. At last, we propose an improved model to integrate alignment template into standard phrase-based SMT as a new feature in a log-linear model. Experimental results show that our method outperforms the baseline method.
SN 0302-9743
BN 978-3-540-70938-1
PY 2007
VL 4394
BP 420
EP 431
UT WOS:000244441100037
ER

PT C
AU Knowles, R
   Koehn, P
AF Knowles, Rebecca
   Koehn, Philipp
GP Assoc Computat Linguist
TI Context and Copying in Neural Machine Translation
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB Neural machine translation systems with sub-word vocabularies are capable of translating or copying unknown words. In this work, we show that they learn to copy words based on both the context in which the words appear as well as features of the words themselves. In contexts that are particularly copy-prone, they even copy words that they have already learned they should translate. We examine the influence of context and subword features on this and other types of copying behavior.
BN 978-1-948087-84-1
PY 2018
BP 3034
EP 3041
UT WOS:000865723403028
ER

PT J
AU Zhou, ZH
   Chen, K
   Li, XS
   Zhang, SL
   Wu, YF
   Zhou, YH
   Meng, KY
   Sun, CC
   He, Q
   Fan, WJ
   Fan, ED
   Lin, ZW
   Tan, XL
   Deng, WL
   Yang, J
   Chen, J
AF Zhou, Zhihao
   Chen, Kyle
   Li, Xiaoshi
   Zhang, Songlin
   Wu, Yufen
   Zhou, Yihao
   Meng, Keyu
   Sun, Chenchen
   He, Qiang
   Fan, Wenjing
   Fan, Endong
   Lin, Zhiwei
   Tan, Xulong
   Deng, Weili
   Yang, Jin
   Chen, Jun
TI Sign-to-speech translation using machine-learning-assisted stretchable
   sensor arrays
SO NATURE ELECTRONICS
AB Wearable yarn-based stretchable sensor arrays, combined with machine learning, can be used to translate American Sign Language into speech in real time.
   Signed languages are not as pervasive a conversational medium as spoken languages due to the history of institutional suppression of the former and the linguistic hegemony of the latter. This has led to a communication barrier between signers and non-signers that could be mitigated by technology-mediated approaches. Here, we show that a wearable sign-to-speech translation system, assisted by machine learning, can accurately translate the hand gestures of American Sign Language into speech. The wearable sign-to-speech translation system is composed of yarn-based stretchable sensor arrays and a wireless printed circuit board, and offers a high sensitivity and fast response time, allowing real-time translation of signs into spoken words to be performed. By analysing 660 acquired sign language hand gesture recognition patterns, we demonstrate a recognition rate of up to 98.63% and a recognition time of less than 1 s.
RI Chen, Jun/K-3415-2012; Zhang, Songlin/U-8467-2019; He,
   Qiang/AAI-1026-2019
OI Chen, Jun/0000-0002-3439-0495; Zhang, Songlin/0000-0002-0554-6737; He,
   Qiang/0000-0002-3555-1852; Zhou, Zhihao/0000-0002-2671-0583; Fan,
   Endong/0000-0002-9515-8219
SN 2520-1131
PD SEP
PY 2020
VL 3
IS 9
BP 571
EP 578
DI 10.1038/s41928-020-0428-6
EA JUN 2020
UT WOS:000544143500002
ER

PT J
AU Liu, YP
   Zhang, L
   Zhang, YN
AF Liu, Yupeng
   Zhang, Lei
   Zhang, Yanan
TI Neural Machine Translation Transfer Model Based on Mutual Domain
   Guidance
SO IEEE ACCESS
AB The neural machine translation (NMT) model is a data hungry and domain-sensitive model but it is almost impossible to obtain a large number of labeled data for training it. This requires the use of domain transfer strategy. In order to solve the problem of domain data mismatch, this paper proposes a neural machine translation transfer model based on domain mutual guidance and establishes the continuous impact through the framework of mutual guidance. At the same time, self-ensemble and self-knowledge-distillation are used in these independent domains so that the model will not deviate from the domain too much. Furthermore, the model can better train the models from the batching way of domain data. It mainly uses the pretraining model out of domain, distillation of existing models in domain and data selection in the training process to guide the in-domain model. These are unified in the training framework, so that model training can be continuously and effectively guided in and out of domain. In this study, three typical experiment scenarios were comprehensive tested and our model was compared with many conventional classic methods. The experiment results showed that our proposed "inter-domain transfer training" and "curriculum scheduling agent" was effective and robust. The most important results and findings are that this comprehensive guided training framework (intra-domain and inter-domain) is suitable for the domain transfer in different scenarios, and this framework doesn't increase the decoding cost.
SN 2169-3536
PY 2022
VL 10
BP 101595
EP 101608
DI 10.1109/ACCESS.2022.3208951
UT WOS:000864141800001
ER

PT C
AU Zhang, JX
   Cao, HL
   Zhao, TJ
AF Zhang, Jiexin
   Cao, Hailong
   Zhao, Tiejun
BE Banchs, RE
   Dong, M
   Lu, Y
   Ranaivo-Malancon, B
TI Extracting Parallel Phrases from Comparable Corpora
SO PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE
   PROCESSING (IALP 2014)
SE International Conference on Asian Language Processing
CT International Conference on Asian Language Processing (IALP)
CY OCT 20-22, 2014
CL Kuching, MALAYSIA
SP Chinese & Oriental Languages Informat Proc Soc, Univ Malaysia Sarawak, Fac Comp Sci & Informat Technol, Informat & Commun Technol Unit, Sarawak Convent Bur, Sarawak Energy Bhd, Name Technol Sdn Bhd, Univ Malaysia Sarawak, Inst Social Informat & Technol Innovat, IEEE Singapore Comp Chapter, IEEE Comp Soc, Sarawak Language Technol
AB The state-of-the-art statistical machine translation models are trained with the parallel corpora. However, the traditional SMT loses its power when it comes to language pairs with few bilingual resources. This paper proposes a novel method that treats the phrase extraction as a classification task. We first automatically generate the training and testing phrase pairs for the classifier. Then, we train a SVM classifier which can determine the phrase pairs are either parallel or non-parallel. The proposed approach is evaluated on the translation task of Chinese-English. Experimental results show that the precision of the classifier on test sets is above 75% and the accuracy is above 98%. The quality of the extracted data is also evaluated by measuring the impact on the performance of a state-of-the-art SMT system, which is built with a small parallel corpus. It shows better results over the baseline system.
SN 2159-1962
EI 2159-1970
BN 978-1-4799-5330-1
PY 2014
BP 166
EP 169
UT WOS:000855516700042
ER

PT J
AU Hu, H
   Kubler, S
AF Hu, Hai
   Kubler, Sandra
TI Investigating translated Chinese and its variants using machine learning
SO NATURAL LANGUAGE ENGINEERING
AB Translations are generally assumed to share universal features that distinguish them from texts that are originally written in the same language. Thus, we can argue that these translations constitute their own variety of a language, often called translationese. However, translations are also influenced by their source languages and thus show different characteristics depending on the source language. Consequently, we argue that these variants constitute different "dialects" of translations into the same target language. Studies using machine learning techniques on Indo-European languages have investigated the universal characteristics of translationese and how translations from various source languages differ. However, for typologically very different languages such as Chinese, there are only few corpus studies that tap into the intricate relation between translations and the originals, as well as into the relations among translations themselves. In this contribution, we investigate the following questions: (1) What are the characteristics of Chinese translationese, both in general and with respect to different source languages? (2) Can we find differences not only at the lexical but also on the syntactic level? and (3) Based on the characteristics found in the previous questions, which of the proposed laws and universals can we corroborate based on our evidence from Chinese? We use machine learning to operationalize determining the importance of different characteristics and comparing their importance for our Chinese dataset with characteristics previously reported in studies on English. In addition, our methodology allows us to add syntactic features, which have rarely been used to study translations into Chinese. Our results show that Chinese translations as a whole can be reliably distinguished from non-translations, even based on only five features. More interestingly, typological traces from the source languages can often be found in their translations, therefore creating what we call dialects of translationese. For instance, translations from two Altaic languages exhibit more noun repetition and less frequent use of pronouns. Additionally, some characteristics that are not discriminative for English work well for Chinese, possibly because the distance between Chinese and the source languages is greater than that in English studies.
OI Hu, Hai/0000-0002-2289-9008; Kubler, Sandra/0000-0003-0885-5436
SN 1351-3249
EI 1469-8110
PD MAY
PY 2021
VL 27
IS 3
BP 339
EP 372
AR PII S1351324920000182
DI 10.1017/S1351324920000182
UT WOS:000656232400004
ER

PT J
AU Yu, X
AF Yu, Xue
TI The appeal of green advertisements on consumers' consumption intention
   based on low-resource machine translation
SO JOURNAL OF SUPERCOMPUTING
AB To study the impact of the appeal of green advertisements on consumers' consumption intention, this paper first studies low-resource language machine translation based on Internet of Things (IoT) edge computing. Some related theories, such as low-resource language machine translation (MT) and the appeal of green advertisements, are introduced. Secondly, the questionnaire survey is taken as the research method. Additionally, citizens of a city in China are selected as a research sample to study the relationship between the egoistic and altruistic appeal of green advertisements and impression management mechanisms, the mediating effect of green product attitudes, and consumers' purchase intentions, and draw relevant conclusions. The research results manifest that the low-resource language machine translation based on IoT edge computing has excellent performance, effectively improving the work efficiency and accuracy of low-resource language machine translation. For well-known brands, consumers are mainly young people aged between 26 and 35, and most of these young people have a bachelor's degree. After low-resource language MT interprets the appearance and experience of clothing products, there will be gaps in the actual situation. However, most consumers will still consider continuing to buy such products. In the impression management mechanism, the direct effect value and the mediation effect value of altruistic green advertising are 4.8642 and 4.563, respectively; the values of egoistic green advertising are 5.3652 and 5.89621, respectively. Product attitudes under the altruistic appeal of green advertisements are better than the egoistic appeal. In addition, product attitude will play a partial intermediary role between the altruistic and egoistic appeal of green advertisements and purchase intention. On account of low-resource language MT, this research analyzes the influence of green advertising appeal on consumers' willingness to consume, enriches the relevant theories of consumers' green purchasing willingness and advertising demand, and provides a theoretical basis for subsequent research on the internal impact. It also provides the relevant mechanism of green advertising demand on purchase intention, constructive advertising and marketing suggestions for enterprises, and promotes the green and healthy development of enterprises.
SN 0920-8542
EI 1573-0484
PD MAR
PY 2023
VL 79
IS 5
BP 5086
EP 5108
DI 10.1007/s11227-022-04846-0
EA OCT 2022
UT WOS:000866321800004
ER

PT C
AU Terashima, R
   Echizen-Ya, H
   Araki, K
AF Terashima, Ryo
   Echizen-ya, Hiroshi
   Araki, Kenji
BE Zhang, M
   Li, HZ
   Lua, KT
   Dong, MH
TI Learning Method for Extraction of Partial Correspondence from Parallel
   Corpus
SO 2009 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING
SE International Conference on Asian Language Processing
CT International Conference on Asian Language Processing
CY DEC 07-09, 2009
CL Singapore, SINGAPORE
AB For machine translations using a parallel corpus, it is effective to extract partial correspondences: pairs of phrases of the source language(SL) and target language(TL) in bilingual sentences. However, it is difficult to extract the partial correspondences correctly and efficiently in the data sparse corpus. In this paper, we propose a new learning method that extracts the partial correspondences solely from the parallel corpus without any analytical tools. In the proposed method, the extraction rules are automatically acquired from bilingual sentences using bi-gram statistics in each language sentence and the similarity based on Dice coefficient between SL words and TL words. The acquired extraction rules possess information about the first parts(e.g., "a", "the") or the last parts in phrases. Moreover, the partial correspondences are extracted from the bilingual sentences using the extraction rules correctly and efficiently. Evaluation experiments indicated that our proposed method can improve the translation quality of the learning-type machine translation by correctly and efficiently extracting the partial correspondences in bilingual sentences.
SN 2159-1962
EI 2159-1970
BN 978-0-7695-3904-1
PY 2009
BP 293
EP 298
DI 10.1109/IALP.2009.69
UT WOS:000291662800057
ER

PT C
AU Nastase, V
   Hitschler, J
AF Nastase, Vivi
   Hitschler, Julian
BA Declerck, T
BF Declerck, T
BE Calzolari, N
   Choukri, K
   Cieri, C
   Hasida, K
   Isahara, H
   Maegaard, B
   Mariani, J
   Moreno, A
   Odijk, J
   Piperidis, S
   Tokunaga, T
   Goggi, S
   Mazo, H
TI Correction of OCR Word Segmentation Errors in Articles from the ACL
   Collection through Neural Machine Translation Methods
SO PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE
   RESOURCES AND EVALUATION (LREC 2018)
CT 11th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 07-12, 2018
CL Miyazaki, JAPAN
AB Depending on the quality of the original document, Optical Character Recognition (OCR) can produce a range of errors - from erroneous letters to additional and spurious blank spaces. We applied a sequence-to-sequence machine translation system to correct word-segmentation OCR errors in scientific texts from the ACL collection with an estimated precision and recall above 0.95 on test data. We present the correction process and results.
BN 979-10-95546-00-9
PY 2018
BP 706
EP 711
UT WOS:000725545000113
ER

PT C
AU Vu, TT
   Haffari, G
AF Vu, Thuy-Trang
   Haffari, Gholamreza
GP Assoc Computat Linguist
TI Automatic Post-Editing of Machine Translation: A Neural
   Programmer-Interpreter Approach
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB Automated Post-Editing (PE) is the task of automatically correcting common and repetitive errors found in machine translation (MT) output. In this paper, we present a neural programmer-interpreter approach to this task, resembling the way that humans perform post-editing using discrete edit operations, which we refer to as programs. Our model outperforms previous neural models for inducing PE programs on the WMT17 APE task for German-English up to +1 BLEU score and 0.7 TER scores.
BN 978-1-948087-84-1
PY 2018
BP 3048
EP 3053
UT WOS:000865723403030
ER

PT S
AU Reeder, F
AF Reeder, F
BE Frederking, RE
   Taylor, KB
TI Investigation of intelligibility judgments
SO MACHINE TRANSLATION: FROM REAL USERS TO RESEARCH, PROCEEDINGS
SE LECTURE NOTES IN COMPUTER SCIENCE
CT 6th Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY SEP 28-OCT 02, 2004
CL Washington, DC
SP Assoc Machine Translat Americas
AB This paper describes an intelligibility snap-judgment test. In this exercise, participants are shown a series of human translations and machine translations and are asked to determine whether the author was human or machine. The experiment shows that snap judgments on intelligibility are made successfully and that system rankings on snap judgments are consistent with more detailed intelligibility measures. In addition to demonstrating a quick intelligibility judgment, representing on a few minutes time of each participant, it details the types of errors which led to the snap judgments.
SN 0302-9743
BN 3-540-23300-8
PY 2004
VL 3265
BP 227
EP 235
UT WOS:000224611600025
ER

PT C
AU Fang, QK
   Feng, Y
AF Fang, Qingkai
   Feng, Yang
GP Assoc Computat Linguist
TI Neural Machine Translation with Phrase-Level Universal Visual
   Representations
SO PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS)
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB Multimodal machine translation (MMT) aims to improve neural machine translation (NMT) with additional visual information, but most existing MMT methods require paired input of source sentence and image, which makes them suffer from shortage of sentence-image pairs. In this paper, we propose a phrase-level retrieval-based method for MMT to get visual information for the source input from existing sentence-image data sets so that MMT can break the limitation of paired sentence-image input. Our method performs retrieval at the phrase level and hence learns visual information from pairs of source phrase and grounded region, which can mitigate data sparsity. Furthermore, our method employs the conditional variational auto-encoder to learn visual representations which can filter redundant visual information and only retain visual information related to the phrase. Experiments show that the proposed method significantly outperforms strong baselines on multipleMMTdatasets, especially when the textual context is limited.
BN 978-1-955917-21-6
PY 2022
BP 5687
EP 5698
UT WOS:000828702305055
ER

PT C
AU Nidhi, R
   Singh, T
AF Nidhi, Ritu
   Singh, Tanya
BE Singh, PK
   Panigrahi, BK
   Suryadevara, NK
   Sharma, SK
   Singh, AP
TI SMT Algorithms for Indian Languages - A Case Study of Moses and MT Hub
   for English-Maithili Language Pair
SO PROCEEDINGS OF ICETIT 2019: EMERGING TRENDS IN INFORMATION TECHNOLOGY
SE Lecture Notes in Electrical Engineering
CT 1st International Conference on Emerging Trends in Information
   Technology (ICETIT)
CY JUN 21-22, 2019
CL Inst Informat Technol & Management, New Delhi, INDIA
HO Inst Informat Technol & Management
AB Around 34 million people worldwide speak Maithili. Due to lack of digital content, this language is considered resource poor in the technology and internet space. A vast majority of Maithili speakers cannot access internet due to unavailability of Maithili content on internet and also due to the fact that there is no English to Maithili Machine Translation (EMMT) system available. Creating such useful resource requires sizeable aligned parallel text corpora, divergence research between the source and target language and suitable Statistical Machine Translation (SMT) algorithms. This paper while developing the required linguistic resource for a statistical EMMT, compares the two popular SMT algorithms - Microsoft Translator Hub (MTHub) and Moses for their suitability for the EMMT system, and documents the experiments carried out on these platforms.
RI Singh, Tanya/HQZ-7269-2023
SN 1876-1100
EI 1876-1119
BN 978-3-030-30577-2; 978-3-030-30576-5
PY 2020
VL 605
BP 269
EP 279
DI 10.1007/978-3-030-30577-2_23
UT WOS:000612991500023
ER

PT J
AU Castell-Diaz, J
   Abad-Navarro, F
   de la Morena-Barrio, ME
   Corral, J
   Fernandez-Breis, JT
AF Castell-Diaz, J.
   Abad-Navarro, F.
   de la Morena-Barrio, M. E.
   Corral, J.
   Fernandez-Breis, J. T.
TI Using Machine Learning for Predicting the Effect of Mutations in the
   Initiation Codon
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
AB The effect of mutations has been traditionally predicted by studying what may happen due to the substitution of one amino acid for another one. This approach may be effective for mutations with impact in the function of the protein, but ineffective for mutations in the translation initiation codon. Such mutation might avoid the generation of the protein. Consequently, specific methods for predicting the effect of mutations in the translation initiation codon are needed. We propose a method for predicting the effect of mutations in the canonical translation initiation codon based on a biological model that considers specific features of such mutations, like the distance to a potential alternative initiation codon. Our predictor has been developed using tree-based machine learning algorithms and data extracted from Ensembl. Our final model is able to detect whether a mutation in the canonical initiation codon is deleterious or benign with a precision of 44.28% and an accuracy of 98.32%, which improves the results of state of the art tools such as PolyPhen, SIFT, or CADD for this type of mutation.
RI ; Fernandez Breis, Jesualdo Tomas/F-4269-2010
OI de la Morena-Barrio, Maria Eugenia/0000-0001-7426-4947; Fernandez Breis,
   Jesualdo Tomas/0000-0002-7558-2880; Abad-Navarro,
   Francisco/0000-0003-0201-3115; Castell Diaz, Javier/0000-0001-6923-2174
SN 2168-2194
EI 2168-2208
PD NOV
PY 2022
VL 26
IS 11
BP 5750
EP 5756
DI 10.1109/JBHI.2022.3200966
UT WOS:000882005700049
PM 35998169
ER

PT C
AU Bapna, A
   Firat, O
AF Bapna, Ankur
   Firat, Orhan
GP Assoc Computat Linguist
TI Simple, Scalable Adaptation for Neural Machine Translation
SO 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND
   THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE
CT Conference on Empirical Methods in Natural Language Processing / 9th
   International Joint Conference on Natural Language Processing
   (EMNLP-IJCNLP)
CY NOV 03-07, 2019
CL Hong Kong, HONG KONG
SP Google, Facebook, Apple, ASAPP, Salesforce, Huawei, Baidu, Deepmind, Amazon, PolyAI, Naver, ByteDance, Megagon Labs, Zhuiyi, Verisk, MI
AB Fine-tuning pre-trained Neural Machine Translation (NMT) models is the dominant approach for adapting to new languages and domains. However, fine-tuning requires adapting and maintaining a separate model for each target task. We propose a simple yet efficient approach for adaptation in NMT. Our proposed approach consists of injecting tiny task specific adapter layers into a pre-trained model. These lightweight adapters, with just a small fraction of the original model size, adapt the model to multiple individual tasks simultaneously.
   We evaluate our approach on two tasks: (i) Domain Adaptation and (ii) Massively Multilingual NMT. Experiments on domain adaptation demonstrate that our proposed approach is on par with full fine-tuning on various domains, dataset sizes and model capacities. On a massively multilingual dataset of 103 languages, our adaptation approach bridges the gap between individual bilingual models and one massively multilingual model for most language pairs, paving the way towards universal machine translation.
BN 978-1-950737-90-1
PY 2019
BP 1538
EP 1548
UT WOS:000854193301087
ER

PT C
AU Schlippe, T
   Zhu, CF
   Lemcke, D
   Schultz, T
AF Schlippe, Tim
   Zhu, Chenfei
   Lemcke, Daniel
   Schultz, Tanja
GP IEEE
TI STATISTICAL MACHINE TRANSLATION BASED TEXT NORMALIZATION WITH
   CROWDSOURCING
SO 2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
CT IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP)
CY MAY 26-31, 2013
CL Vancouver, CANADA
SP Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc
AB In [1], we have proposed systems for text normalization based on statistical machine translation (SMT) methods which are constructed with the support of Internet users and evaluated those with French texts. Internet users normalize text displayed in a web interface in an annotation process, thereby providing a parallel corpus of normalized and non-normalized text. With this corpus, SMT models are generated to translate non-normalized into normalized text. In this paper, we analyze their efficiency for other languages. Additionally, we embedded the English annotation process for training data in Amazon Mechanical Turk and compare the quality of texts thoroughly annotated in our lab to those annotated by the Turkers. Finally, we investigate how to reduce the user effort by iteratively applying an SMT system to the next sentences to be edited, built from the sentences which have been annotated so far.
OI Schultz, Tanja/0000-0002-9809-7028
SN 1520-6149
BN 978-1-4799-0356-6
PY 2013
BP 8406
EP 8410
UT WOS:000329611508115
ER

PT S
AU Tomas, J
   Casacuberta, F
AF Tomas, J
   Casacuberta, F
BE Fred, A
   Caelli, T
   Duin, RPW
   Campilho, A
   DeRidder, D
TI Statistical machine translation decoding using target word reordering
SO STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION, PROCEEDINGS
SE Lecture Notes in Computer Science
CT 10th International Symposium on Structural and Syntactic Pattern
   Recognition/5th International Conference on Statistical Techniques in
   Pattern Recognition
CY AUG 18-20, 2004
CL Lisbon, PORTUGAL
SP Inst Telecommun, Inst Super Tecn, Int Assoc Pattern Recognit, Fund Luso-Amer Desenvolvimento
AB In the field of pattern recognition, the design of an efficient decoding algorithm is critical for statistical machine translation. The most common statistical machine translation decoding algorithms use the concept of partial hypothesis. Typically, a partial hypothesis is composed by a subset of source positions, which indicates the words that have been translated in this hypothesis, and a prefix of the target sentence. Thus, the target sentence is generated from left to right obtaining source words in an arbitrary order. We present a new approach, where the source sentence is translated from left to right and the possible word reordering is performed at the target prefix. We implemented this approach using a multi-stack decoding technique for a phrase-based model, and compared it with both a conventional approach and a monotone approach. Our experiments show how the new approach can significantly reduce the search time without increasing the search errors.
SN 0302-9743
EI 1611-3349
BN 3-540-22570-6
PY 2004
VL 3138
BP 734
EP 743
UT WOS:000223398900080
ER

PT C
AU Cai, JS
   Utiyama, M
   Sumita, E
   Zhang, YJ
AF Cai, Jingsheng
   Utiyama, Masao
   Sumita, Eiichiro
   Zhang, Yujie
BE Toutanova, K
   Wu, H
TI Dependency-based Pre-ordering for Chinese-English Machine Translation
SO PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS, VOL 2
CT 52nd Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUN 22-27, 2014
CL Baltimore, MD
SP Assoc Computat Linguist, Baidu, Bloomberg, Google, Microsoft, Nuance, Yahoo Labs, Informat Sci Inst, Xerox Res Ctr Europe, Brandeis Univ, Facebook, Yandex, Amazon Com, IBM Watson, Johns Hopkins Univ, A9, AI@ISI, Xerox
AB In statistical machine translation (SMT), syntax-based pre-ordering of the source language is an effective method for dealing with language pairs where there are great differences in their respective word orders. This paper introduces a novel pre-ordering approach based on dependency parsing for Chinese-English SMT. We present a set of dependency-based pre-ordering rules which improved the BLEU score by 1.61 on the NIST 2006 evaluation data. We also investigate the accuracy of the rule set by conducting human evaluations.
BN 978-1-937284-73-2
PY 2014
BP 155
EP 160
UT WOS:000493811100026
ER

PT J
AU Rajan, K
   Zielesny, A
   Steinbeck, C
AF Rajan, Kohulan
   Zielesny, Achim
   Steinbeck, Christoph
TI STOUT: SMILES to IUPAC names using neural machine translation
SO JOURNAL OF CHEMINFORMATICS
AB Chemical compounds can be identified through a graphical depiction, a suitable string representation, or a chemical name. A universally accepted naming scheme for chemistry was established by the International Union of Pure and Applied Chemistry (IUPAC) based on a set of rules. Due to the complexity of this ruleset a correct chemical name assignment remains challenging for human beings and there are only a few rule-based cheminformatics toolkits available that support this task in an automated manner. Here we present STOUT (SMILES-TO-IUPAC-name translator), a deep-learning neural machine translation approach to generate the IUPAC name for a given molecule from its SMILES string as well as the reverse translation, i.e. predicting the SMILES string from the IUPAC name. In both cases, the system is able to predict with an average BLEU score of about 90% and a Tanimoto similarity index of more than 0.9. Also incorrect predictions show a remarkable similarity between true and predicted compounds.
RI Rajan, Kohulan/HNB-4502-2023
OI Rajan, Kohulan/0000-0003-1066-7792; Steinbeck,
   Christoph/0000-0001-6966-0814
SN 1758-2946
PD APR 27
PY 2021
VL 13
IS 1
AR 34
DI 10.1186/s13321-021-00512-4
UT WOS:000644827200001
PM 33906675
ER

PT J
AU Torres-Hostench, O
AF Torres-Hostench, Olga
TI Translator training outdoors
SO TRANSLATION SPACES
AB Before the COVID-19 pandemic, there was no real need to integrate outdoor education into translation studies, as it was easy to balance indoor and outdoor time before and after translation classes. However, the lockdown has deeply affected not only learning but also the mental and physical health of teachers and students, and outdoor education may contribute to recovery afterwards. The proposals in this paper focus on the benefits that being outdoors has for physical health, knowledge, social relations, mental health and attitude to learning. Moreover, being outdoors allows for social distancing. The activities presented in this paper are related to specialized translation, sight translation, simultaneous interpreting, consecutive interpreting, role-play interpreting, translation theory, song translation, theatre translation, machine translation post-editing, translators' employability, translation project management and, last but not least, intermodal transcreation.
RI Torres-Hostench, Olga/C-9976-2010
OI Torres-Hostench, Olga/0000-0003-1525-0304
SN 2211-3711
EI 2211-372X
PY 2020
VL 9
IS 2
BP 224
EP 254
DI 10.1075/ts.20014.tor
UT WOS:000635067200004
ER

PT J
AU Balashov, Y
AF Balashov, Yuri
TI The boundaries of meaning: a case study in neural machine translation
SO INQUIRY-AN INTERDISCIPLINARY JOURNAL OF PHILOSOPHY
AB The success of deep learning in natural language processing raises intriguing questions about the nature of linguistic meaning and ways in which it can be processed by natural and artificial systems. One such question has to do with subword segmentation algorithms widely employed in language modeling, machine translation, and other tasks since 2016. These algorithms often cut words into semantically opaque pieces, such as 'period', 'on', 't', and 'ist' in 'period|on|t|ist'. The system then represents the resulting segments in a dense vector space, which is expected to model grammatical relations among them. This representation may in turn be used to map 'period|on|t|ist' (English) to 'par|od|ont|iste' (French). Thus, instead of being modeled at the lexical level, translation is reformulated more generally as the task of learning the best bilingual mapping between the sequences of subword segments of two languages; and sometimes even between pure character sequences: 'p|e|r|i|o|d|o|n|t|i|s|t' -> 'p|a|r|o|d|o|n|t|i|s|t|e'. Such segmentations and alignments are at work in highly efficient end-to-end machine translation systems, despite their allegedly opaque nature. But do they have linguistic or philosophical plausibility? I attempt to cast light on this question, in the spirit of making artificial intelligence more transparent and explainable.
OI Balashov, Yuri/0000-0001-7369-2122
SN 0020-174X
EI 1502-3923
DI 10.1080/0020174X.2022.2113429
EA SEP 2022
UT WOS:000853485700001
ER

PT J
AU Lin, ZW
   Fu, JZ
   Yao, XH
   Sun, YF
AF Lin, Zhiwei
   Fu, Jianzhong
   Yao, Xinhua
   Sun, Yangfan
TI Improving machined surface textures in avoiding five-axis singularities
   considering tool orientation angle changes
SO INTERNATIONAL JOURNAL OF MACHINE TOOLS & MANUFACTURE
AB This paper looks into the irregular machined surface textures appearing in the process of avoiding five-axis singularities using the C-space based tool orientation translation method. At first, the mechanism for the appearances of the irregular surface textures is analyzed. A cutting simulation in VERICUT reveals that irregular surface textures are actually caused by lacking control of the tool orientation angles in the orientation modification process. Realizing that, a modified particle swarm optimization (PSO) is inter-graded into the previous tool orientation translation method. In the PSO, the particle evolving equations are redefined and a mutation operation is added. The objective of the PSO is to find an optimal translating vector in the C-space so that the changed tool orientation angles can reach minimum values. In this way, the surface textures can be controlled. Three comparative cutting experiments with fillet endmills are carried out to verify the effect of the proposed method. The experimental results show that: (1) with the tool orientation translation method, the five-axis singular problem can be well avoided; and (2) with the optimal translating vector found by the PSO, the machined surface textures can be greatly improved. (C) 2015 Elsevier Ltd. All rights reserved.
SN 0890-6955
EI 1879-2170
PD NOV
PY 2015
VL 98
BP 41
EP 49
DI 10.1016/j.ijmachtools.2015.09.001
UT WOS:000362858300005
ER

PT C
AU Cavdar, D
   Codreanu, V
   Karakus, C
   Lockman, JA
   Podareanu, D
   Saletore, V
   Sergeev, A
   Smith, DD
   Suthichai, V
   Ta, Q
   Varadharajan, S
   Wilson, LA
   Xu, RG
   Yang, P
AF Cavdar, Derya
   Codreanu, Valeriu
   Karakus, Can
   Lockman, John A., III
   Podareanu, Damian
   Saletore, Vikram
   Sergeev, Alexander
   Smith, Don D., II
   Suthichai, Victor
   Ta, Quy
   Varadharajan, Srinivas
   Wilson, Lucas A.
   Xu, Rengan
   Yang, Pei
BE Weiland, M
   Juckeland, G
   Trinitis, C
   Sadayappan, P
TI Densifying Assumed-Sparse Tensors Improving Memory Efficiency and MPI
   Collective Performance During Tensor Accumulation for Parallelized
   Training of Neural Machine Translation Models
SO HIGH PERFORMANCE COMPUTING, ISC HIGH PERFORMANCE 2019
SE Lecture Notes in Computer Science
CT 34th International Conference on High Performance Computing (ISC High
   Performance)
CY JUN 16-20, 2019
CL Frankfurt, GERMANY
AB Neural machine translation - using neural networks to translate human language - is an area of active research exploring new neuron types and network topologies with the goal of dramatically improving machine translation performance. Current state-of-the-art approaches, such as the multi-head attention-based transformer, require very large translation corpuses and many epochs to produce models of reasonable quality. Recent attempts to parallelize the official TensorFlow "Transformer" model across multiple nodes have hit roadblocks due to excessive memory use and resulting out of memory errors when performing MPI collectives.
   This paper describes modifications made to the Horovod MPI-based distributed training framework to reduce memory usage for transformer models by converting assumed-sparse tensors to dense tensors, and subsequently replacing sparse gradient gather with dense gradient reduction. The result is a dramatic increase in scale-out capability, with CPU-only scaling tests achieving 91% weak scaling efficiency up to 1200 MPI processes (300 nodes), and up to 65% strong scaling efficiency up to 400 MPI processes (200 nodes) using the Stampede2 supercomputer.
RI Xu, Rengan/AAV-4366-2020
OI Xu, Rengan/0000-0002-5230-5530; Podareanu, Damian/0000-0002-4207-8725
SN 0302-9743
EI 1611-3349
BN 978-3-030-20656-7; 978-3-030-20655-0
PY 2019
VL 11501
BP 23
EP 39
DI 10.1007/978-3-030-20656-7_2
UT WOS:000493306600002
ER

PT J
AU Slim, A
   Melouah, A
   Faghihi, U
   Sahib, K
AF Slim, Amel
   Melouah, Ahlem
   Faghihi, Usef
   Sahib, Khouloud
TI Improving Neural Machine Translation for Low Resource Algerian Dialect
   by Transductive Transfer Learning Strategy
SO ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING
AB This study is the first work on a transductive transfer learning approach for low-resource neural machine translation applied to the Algerian Arabic dialect. The transductive approach is based on a fine-tuning transfer learning strategy that transfers knowledge from the parent model to the child model. This strategy helps to solve the learning problem using limited parallel corpora. We tested the approach on a sequence-to-sequence model with and without the Attention mechanism. We first trained the models on a parallel multi-dialects Arabic corpus and then switch them to a low-resource of the Algerian dialect. Transductive transfer learning raises the BLEU score for the Seq2Seq model from 0.3 to more than 34, and for the Attentional-Seq2Seq model from less than 17 to more than 35. The obtained results prove the validity of this approach.
SN 2193-567X
EI 2191-4281
PD AUG
PY 2022
VL 47
IS 8
BP 10411
EP 10418
DI 10.1007/s13369-022-06588-w
EA FEB 2022
UT WOS:000752202100001
PM 35155062
ER

PT C
AU Wang, LJ
   Tu, M
   Zhai, MX
   Wang, HD
   Liu, S
   Kim, SH
AF Wang, Lijie
   Tu, Mei
   Zhai, Mengxia
   Wang, Huadong
   Liu, Song
   Kim, Sang Ha
BE Lan, M
   Wu, Y
   Dong, M
   Lu, Y
   Yang, Y
TI Neural Machine Translation Strategies for Generating Honorific-style
   Korean
SO PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE
   PROCESSING (IALP)
SE International Conference on Asian Language Processing
CT 23rd International Conference on Asian Language Processing (IALP)
CY NOV 15-17, 2019
CL E China Normal Univ, Shanghai, PEOPLES R CHINA
SP Chinese & Oriental Languages Informat Proc Soc, IEEE Singapore Sect, IEEE Singapore SMC Chapter
HO E China Normal Univ
AB Expression with honorifics is an important way of dressing up the language and showing politeness in Korean. For machine translation, generating honorifics is indispensable on the formal occasion when the target language is Korean. However, current Neural Machine Translation (NMT) models ignore generation of honoritics, which causes the limitation of the MT application on business occasion. In order to address the problem, this paper presents two strategies to improve Korean honorific generation ratio: 1) we introduce honorific fusion training (LIFT) loss under the minimum risk training framework to guide the model to generate honorifics; 2) we introduce a data labeling (DL) method which tags the training corpus with distinctive labels without any modification to the model structure. Our experimental results show that the proposed two strategies can significantly improve the honorific generation ratio by 34.35% and 45.59%.
SN 2159-1962
EI 2159-1970
BN 978-1-7281-5014-7
PY 2019
BP 450
EP 455
UT WOS:000653100500079
ER

PT C
AU Mistry, J
   Inden, B
AF Mistry, Jayan
   Inden, Benjamin
GP IEEE
TI An Approach to Sign Language Translation using the Intel RealSense
   Camera
SO 2018 10TH COMPUTER SCIENCE AND ELECTRONIC ENGINEERING CONFERENCE (CEEC)
SE Computer Science and Electronic Engineering Conference
CT 10th Computer Science and Electronic Engineering Conference (CEEC)
CY SEP 19-21, 2018
CL Univ Essex, Colchester, ENGLAND
SP IEEE UKRI Comp Chapter
HO Univ Essex
AB An Intel RealSense camera is used for translating static manual American Sign Language gestures into text. The system uses palm orientation and finger joint data as inputs for either a support vector machine or a neural network whose architecture has been optimized by a genetic algorithm. A data set consisting of 100 samples of 26 gestures (the letters of the alphabet) is extracted from 10 participants. When comparing the different learners in combination with different standard preprocessing techniques, the highest accuracy of 95% is achieved by a support vector machine with a scaling method, as well as principal component analysis, used for preprocessing. The highest performing neural network system reaches 92.1% but produces predictions much faster. We also present a simple software solution that uses the trained classifiers to enable userfriendly sign language translation.
SN 2472-1530
BN 978-1-5386-7275-4
PY 2018
BP 219
EP 224
UT WOS:000467722000042
ER

PT C
AU Vivencio, DP
   Trevelin, LC
AF Vivencio, Diego Pagliarini
   Trevelin, Luis Carlos
GP IEEE
TI Multicore memory subsystem aspects and its influence on the performance
   of modern VMMs
SO 2011 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
CT IEEE International Conference on Systems, Man and Cybernetics (SMC)
CY OCT 09-12, 2011
CL Anchorage, AK
SP IEEE, IEEE Syst, Man & Cybernet Soc (IEEE SMC), IEEE Circuits & Syst Soc (CAS), IEEE Engn, Med & Biol Soc (EMB)
AB The latest multicore processors brought important features for virtualized environments. They added a shared cache level, improving communication among cores, and nested paging support, which enable address translation without intervention of the virtual machine monitor (VMM). The address translation is more expensive when using nested paging, because it is necessary to traverse both guest page tables and VMM managed ones. One way to mitigate this is employing large pages in the mapping of virtual machine memory, reducing the number of translation steps. The purpose of this study is to investigate the influence of memory subsystem on virtual machines using virtual multiprocessing on multicore processors, to determine the set of characteristics that offer better performance. Employing parallelizable tasks, we analyzed the presence of shared cache between cores and the use of large pages by the VMM, comparing the effects of them under shadow and nested paging.
SN 1062-922X
BN 978-1-4577-0653-0
PY 2011
BP 2419
EP 2424
UT WOS:000298615102122
ER

PT J
AU Kim, H
   Jung, HY
   Kwon, H
   Lee, JH
   Na, SH
AF Kim, Hyun
   Jung, Hun-Young
   Kwon, Hongseok
   Lee, Jong-Hyeok
   Na, Seung-Hoon
TI Predictor-Estimator: Neural Quality Estimation Based on Target Word
   Prediction for Machine Translation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB Recently, quality estimation has been attracting increasing interest from machine translation researchers, aiming at finding a good estimator for the "quality" of machine translation output. The common approach for quality estimation is to treat the problem as a supervised regression/classification task using a quality-annotated noisy parallel corpus, called quality estimation data, as training data. However, the available size of quality estimation data remains small, due to the too-expensive cost of creating such data. In addition, most conventional quality estimation approaches rely on manually designed features to model nonlinear relationships between feature vectors and corresponding quality labels. To overcome these problems, this article proposes a novel neural network architecture for quality estimation task-called the predictor-estimator-that considers word prediction as an additional pre-task. The major component of the proposed neural architecture is a word prediction model based on a modified neural machine translation model-a probabilistic model for predicting a target word conditioned on all the other source and target contexts. The underlying assumption is that the word prediction model is highly related to quality estimation models and is therefore able to transfer useful knowledge to quality estimation tasks. Our proposed quality estimation method sequentially trains the following two types of neural models: (1) Predictor: a neural word prediction model trained from parallel corpora and (2) Estimator: a neural quality estimation model trained from quality estimation data. To transfer word a prediction task to a quality estimation task, we generate quality estimation feature vectors from the word prediction model and feed them into the quality estimation model. The experimental results on WMT15 and 16 quality estimation datasets show that our proposed method has great potential in the various sub-challenges.
SN 2375-4699
EI 2375-4702
PD NOV
PY 2017
VL 17
IS 1
AR 3
DI 10.1145/3109480
UT WOS:000415404000003
ER

PT C
AU Ebrahim, S
   Hegazy, D
   Mostafa, MGHM
   El-Beltagy, SR
AF Ebrahim, Sara
   Hegazy, Doaa
   Mostafa, Mostafa Gadal-Haqq M.
   El-Beltagy, Samhaa R.
BE Shaalan, K
   ElBeltagy, SR
TI Detecting and Integrating Multiword Expression into English-Arabic
   Statistical Machine Translation
SO ARABIC COMPUTATIONAL LINGUISTICS (ACLING 2017)
SE Procedia Computer Science
CT 3rd Arabic Computational Linguistics Conference (ACLing)
CY NOV 05-06, 2017
CL British Univ Dubai, Dubai, U ARAB EMIRATES
HO British Univ Dubai
AB In this paper we introduce a new method for detecting a type of English Multiword Expressions (MWEs), which is phrasal verbs, into an English-Arabic phrase-based statistical machine translation (PBSMT) system.
   The detection starts with parsing the English side of the parallel corpus, detecting various linguistic patterns for phrasal verbs and finally integrate them into the En-Ar PBSMT system. In addition, the paper explores the effect of cliticizing specific words in English that have no Arabic equivalent. The results, which reported with the BLEU scores, showed that some patterns achieved significant improvements compared to other patterns and still the baseline achieves the highest score.
   This paper shows that, by detecting more linguistic patterns and integrating them into En-Ar SMT system, translation quality could be improved with other integration methods. Yet, the results show which path is worth to follow and clarifies the perspective that linguistic features are not handled properly in the statistically learned models. (C) 2017 The Authors. Published by Elsevier B.V.
RI Mostafa, Mostafa G. M./HGP-0396-2022
OI Mostafa, Mostafa G. M./0000-0002-3555-4148; El-Beltagy, Samhaa
   R./0000-0002-5769-8054
SN 1877-0509
PY 2017
VL 117
BP 111
EP 118
DI 10.1016/j.procs.2017.10.099
UT WOS:000425029300014
ER

PT C
AU Lepage, Y
   Lieber, J
AF Lepage, Yves
   Lieber, Jean
BE Cox, MT
   Funk, P
   Begum, S
TI Case-Based Translation: First Steps from a Knowledge-Light Approach
   Based on Analogy to a Knowledge-Intensive One
SO CASE-BASED REASONING RESEARCH AND DEVELOPMENT, ICCBR 2018
SE Lecture Notes in Artificial Intelligence
CT 26th International Conference on Case-Based Reasoning (ICCBR)
CY JUL 09-12, 2018
CL Stockholm, SWEDEN
AB This paper deals with case-based machine translation. It is based on a previous work using a proportional analogy on strings, i.e., a quaternary relation expressing that "String A is to string B as string C is to string D". The first contribution of this paper is the rewording of this work in terms of case-based reasoning: a case is a problem-solution pair (A, A') where A is a sentence in an origin language and A', its translation in the destination language. First, three cases (A, A'), (B, B'), (C, C') such that "A is to B as C is to the target problem D" are retrieved. Then, the analogical equation in the destination language "A' is to B' as C' is to x" is solved and D' = x is a suggested translation of D. Although it does not involve any linguistic knowledge, this approach was effective and gave competitive results at the time it was proposed. The second contribution of this work aims at examining how this prior knowledge-light case-based machine translation approach could be improved by using additional pieces of knowledge associated with cases, domain knowledge, retrieval knowledge, and adaptation knowledge, and other principles or techniques from case-based reasoning and natural language processing.
SN 0302-9743
EI 1611-3349
BN 978-3-030-01081-2; 978-3-030-01080-5
PY 2018
VL 11156
BP 563
EP 579
DI 10.1007/978-3-030-01081-2_37
UT WOS:000717233500037
ER

PT S
AU Mikami, S
   Akama, Y
AF Mikami, S
   Akama, Y
BE Girard, JY
TI A study, of Abramsky's Linear Chemical Abstract Machine
SO TYPED LAMBDA CALCULI AND APPLICATIONS
SE LECTURE NOTES IN COMPUTER SCIENCE
CT 4th International Conference on Typed Lambda Calculi and Applications
   (TLCA 99)
CY APR 07-09, 1999
CL LAQUILA, ITALY
AB Abramsky's Linear Chemical Abstract Machine (LCHAM) is a term calculus which corresponds to Linear Logic, via the Curry-Howard isomorphism. We introduce a translation from a linear lambda-calculus into LCHAM. The translation result can be well regarded as a black box with the i/o ports being atomic. We show that one step computation of LCHAM is equivalent to that of the linear lambda-calculus. Then, we prove the principal typing theorem of LCHAM, which implies the decidability of type checking.
OI Akama, Yohji/0000-0002-6652-7150
SN 0302-9743
BN 3-540-65763-0
PY 1999
VL 1581
BP 243
EP 257
UT WOS:000082777100018
ER

PT J
AU Kim, YS
   Oh, YJ
AF Kim, Yu-Seop
   Oh, Yu-Jin
TI Intra-sentence segmentation based on support vector machines in
   English-Korean machine translation systems
SO EXPERT SYSTEMS WITH APPLICATIONS
AB This work is about intra-sentence segmentation performed before syntactic analysis of long sentences composed of at least 20 words in an English-Korean machine translation system. A long sentence has been known to spend enormous computational time and space when it is analyzed syntactically. It can also produce poor translation results. To resolve this problem, we partitioned a long sentence into a few segments to analyze each segment separately. To partition the sentence, firstly, we tried to find candidates for each segment position in the sentence. We then generated input vectors representing lexical contexts of the corresponding candidates and also used the support vector machines (SVM) algorithm to learn and recognize the appropriate segment positions. We used three kernel functions, the linear kernel, the polynomial kernel and the Gaussian kernel, to find optimal hyperplanes classifying proper positions and we compared results obtained from each kernel function. As a result of the experiments, we acquired 0.81, 0.83, and 0.79 f-measure values from the linear, polynomial and Gaussian kernel, respectively. (c) 2007 Elsevier Ltd. All rights reserved.
SN 0957-4174
EI 1873-6793
PD MAY 4
PY 2008
VL 34
IS 4
BP 2673
EP 2682
DI 10.1016/j.eswa.2007.05.032
UT WOS:000253521900044
ER

PT J
AU Li, Z
   Qu, D
   Li, YX
   Xie, CJ
   Chen, Q
AF Li, Zhen
   Qu, Dan
   Li, Yanxia
   Xie, Chaojie
   Chen, Qi
TI A Position Weighted Information Based Word Embedding Model for Machine
   Translation
SO INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS
AB Deep learning technology promotes the development of neural network machine translation (NMT). End-to-End (E2E) has become the mainstream in NMT. It uses word vectors as the initial value of the input layer. The effect of word vector model directly affects the accuracy of E2E-NMT. Researchers have proposed many approaches to learn word representations and have achieved significant results. However, the drawbacks of these methods still limit the performance of E2E-NMT systems. This paper focuses on the word embedding technology and proposes the PW-CBOW word vector model which can present better semantic information. We apply these word vector models on IWSLT14 German-English, WMT14 English-German, WMT14 English-French corporas. The results evaluate the performance of the PW-CBOW model. In the latest E2E-NMT systems, the PW-CBOW word vector model can improve the performance.
SN 0218-2130
EI 1793-6349
PD DEC
PY 2020
VL 29
IS 7-8
SI SI
AR 2040005
DI 10.1142/S0218213020400059
UT WOS:000612860900001
ER

PT C
AU Falavigna, D
AF Falavigna, Daniele
GP Int Speech Commun Assoc
TI Redundancy Reduction in ASR of Spontaneous Speech through Statistical
   Machine Translation
SO 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5
CT 12th Annual Conference of the
   International-Speech-Communication-Association 2011 (INTERSPEECH 2011)
CY AUG 27-31, 2011
CL Florence, ITALY
SP Int Speech Commun Assoc (ISCA)
AB This paper describes a system, based on statistical machine translation, that tries to remove from the output of an automatic audio transcription system non relevant words, such as: erroneously inserted functional words, filled pauses, interjections, word fragments, etc, as well as to repair, at a certain extent, ungrammatical pieces of sentences.
   For this work(1) we decided to concentrate on a political speeches application domain, due to the immediate availability of a parallel corpus of automatic audio transcriptions and related proceedings, manually produced.
   The system can effectively detect and correct several errors (mainly insertions) included in the alignment between a given automatic audio transcription and a reference transcription derived from a corresponding proceeding.
   Preliminary results, expressed in terms of word error rate, show that the proposed approach allows to improve of a relative 5% with respect to the usage of the pure automatic transcription of the audio.
BN 978-1-61839-270-1
PY 2011
BP 1428
EP 1431
UT WOS:000316502200359
ER

PT C
AU Li, LY
   Way, A
   Liu, Q
AF Li, Liangyou
   Way, Andy
   Liu, Qun
BE Erk, K
   Smith, NA
TI Phrase-Level Combination of SMT and TM Using Constrained Word Lattice
SO PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2
CT 54th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY AUG 07-12, 2016
CL Berlin, GERMANY
SP Assoc Computat Linguist, Google, Baidu, Amazon Com, Bloomberg, Facebook, Microsoft Res, eBay, Elsevier, IBM Res, MaluubA, Huawei Technologies, Nuance, Grammarly, VoiceBox Technologies, Yandex, Textkernel, Zalando SE
AB Constrained translation has improved statistical machine translation (SMT) by combining it with translation memory (TM) at sentence-level. In this paper, we propose using a constrained word lattice, which encodes input phrases and TM constraints together, to combine SMT and TM at phrase-level. Experiments on English-Chinese and English-French show that our approach is significantly better than previous combination methods, including sentence-level constrained translation and a recent phrase-level combination.
OI Way, Andy/0000-0001-5736-5930
BN 978-1-945626-01-2
PY 2016
BP 275
EP 280
UT WOS:000493805000045
ER

PT C
AU Li, Y
   Fujimoto, T
AF Li, Yang
   Fujimoto, Takayuki
GP IEEE
TI A Concept of Multi-lingual Translation Application
SO 2018 7TH INTERNATIONAL CONGRESS ON ADVANCED APPLIED INFORMATICS
   (IIAI-AAI 2018)
CT 7th IIAI International Congress on Advanced Applied Informatics
   (IIAI-AAI)
CY JUL 08-13, 2018
CL Yonago, JAPAN
SP Int Inst Appl Informat
AB With the rapid development of globalization, there is a great need for the translation application around the world. Meanwhile, smartphone is becoming a superb tool with its small, lightweight and internet-connected features. Benefiting from an equipped camera, speaker and microphone, translation applications have produced a range of possibilities among text, voice and image translation methods. However, few existing applications offer simultaneous multilingual display translation support and most of them focus on online machine translation, which often generate low accuracy and are not available without the Internet. Based on the above consideration, a concept of multi-lingual translation application is proposed in this paper to improve users' translation efficiency and practicality.
RI Fujimoto, Takayuki/AAI-4868-2021
OI Fujimoto, Takayuki/0000-0001-5259-0565
BN 978-1-5386-7447-5
PY 2018
BP 929
EP 931
DI 10.1109/IIAI-AAI.2018.00187
UT WOS:000494425300176
ER

PT J
AU Yang, SI
   Seo, YA
   Kim, YK
   Ra, D
AF Yang, Seong Il
   Seo, Young Ae
   Kim, Young Kil
   Ra, Dongyul
TI Noun Sense Identification of Korean Nominal Compounds Based on
   Sentential Form Recovery
SO ETRI JOURNAL
AB In a machine translation system, word sense disambiguation has an essential role in the proper translation of words when the target word can be translated differently depending on the context. Previous research on sense identification has mostly focused on adjacent words as context information. Therefore, in the case of nominal compounds, sense tagging of unit nouns mainly depended on other nouns surrounding the target word. In this paper, we present a practical method for the sense tagging of Korean unit nouns in a nominal compound. To overcome the weakness of traditional methods regarding the data sparseness problem, the proposed method adopts complement-predicate relation knowledge that was constructed for machine translation systems. Our method is based on a sentential form recovery technique, which recognizes grammatical relationships between unit nouns. This technique makes use of the characteristics of Korean predicative nouns. To show that our method is effective on text in general domains, the experiments were performed on a test set randomly extracted from article titles in various newspaper sections.
SN 1225-6463
EI 2233-7326
PD OCT
PY 2010
VL 32
IS 5
SI SI
BP 740
EP 749
DI 10.4218/etrij.10.1510.0083
UT WOS:000282921200012
ER

PT C
AU Nakov, P
AF Nakov, Preslav
BE Ghallab, M
   Spyropoulos, CD
   Fakotakis, N
   Avouris, N
TI Improved Statistical Machine Translation Using Monolingual Paraphrases
SO ECAI 2008, PROCEEDINGS
SE Frontiers in Artificial Intelligence and Applications
CT 18th European Conference on Artificial Intelligence
CY JUL 21-25, 2008
CL Univ Patras, Patras, GREECE
SP European Comm Artificial Intelligence, Hellen Artificial Intelligence Soc
HO Univ Patras
AB We propose a novel monolingual sentence paraphrasing method for augmenting the training data for statistical machine translation systems "for free" - by creating it from data that is already available rather than having to create more aligned data. Starting with a syntactic tree, we recursively generate new sentence variants where noun compounds are paraphrased using suitable prepositions, and vice-versa - preposition-containing noun phrases are turned into noun compounds. The evaluation shows an improvement equivalent to 33%-50% of that of doubling the amount of training data.
RI Nakov, Preslav/D-2421-2017
OI Nakov, Preslav/0000-0002-3600-1510
SN 0922-6389
EI 1879-8314
BN 978-1-58603-891-5
PY 2008
VL 178
BP 338
EP +
DI 10.3233/978-1-58603-891-5-338
UT WOS:000273903100065
ER

PT C
AU Ho, TY
   Wang, HC
   Lai, SH
AF Ho, Tien-Yu
   Wang, Hao-Chuan
   Lai, Shong-Hong
GP Assoc Comp Machinery
TI Non-native Language Reading Support with Display of Machine Translation
   Based on Eye-Tracking and Sentence-Level Mapping
SO PROCEEDINGS OF CHINESE CHI 2018: SIXTH INTERNATIONAL SYMPOSIUM OF
   CHINESE CHI (CHINESE CHI 2018)
CT 6th International Symposium of Chinese CHI (Chinese CHI)
CY APR 21-22, 2018
CL Montreal, CANADA
SP ICACHI, ACM SIGCHI, Assoc Comp Machinery
AB In the era of information explosion, individuals often need to read first-hand information online in English, which is a non-native language of most of the people in the world. However, the lack of proficiency toward a non-native language makes it difficult for second-language readers to efficiently understand the contents on the English webpages, especially the long articles. In this work, we propose a novel reading interface to support English as second-language readers with adaptive display of machine translation (MT) using eye tracking, accompanied with sentence-level mapping using background colors. We conducted an experiment to investigate how different methods affect the second-language readers. We found that active translation could help second-language readers comprehend the English article without dazzling them. In addition, sentence-level mapping using background colors not only benefits the mapping between original sentences and their corresponding ones, but also alleviates the problems of line skipping and reading resumption.
OI Lai, Shang-Hong/0000-0002-5092-993X
BN 978-1-4503-6508-6
PY 2018
BP 57
EP 63
DI 10.1145/3202667.3202675
UT WOS:000492996100008
ER

PT J
AU De Pauw, G
   Wagacha, PW
   de Schryver, GM
AF De Pauw, Guy
   Wagacha, Peter Waiganjo
   de Schryver, Gilles-Maurice
TI Exploring the sawa corpus: collection and deployment of a parallel
   corpus English-Swahili
SO LANGUAGE RESOURCES AND EVALUATION
AB Research in machine translation and corpus annotation has greatly benefited from the increasing availability of word-aligned parallel corpora. This paper presents ongoing research on the development and application of the sawa corpus, a two-million-word parallel corpus English-Swahili. We describe the data collection phase and zero in on the difficulties of finding appropriate and easily accessible data for this language pair. In the data annotation phase, the corpus was semi-automatically sentence and word-aligned and morphosyntactic information was added to both the English and Swahili portion of the corpus. The annotated parallel corpus allows us to investigate two possible uses. We describe experiments with the projection of part-of-speech tagging annotation from English onto Swahili, as well as the development of a basic statistical machine translation system for this language pair, using the parallel corpus and a consolidated database of existing English-Swahili translation dictionaries. We particularly focus on the difficulties of translating English into the morphologically more complex Bantu language of Swahili.
RI de Schryver, Gilles-Maurice/D-4740-2011
OI de Schryver, Gilles-Maurice/0000-0001-7272-9878
SN 1574-020X
EI 1574-0218
PD SEP
PY 2011
VL 45
IS 3
SI SI
BP 331
EP 344
DI 10.1007/s10579-011-9159-7
UT WOS:000293709900005
ER

PT J
AU Tran, P
   Dinh, D
   Le, T
   Nguyen, LHB
AF Phuoc Tran
   Dien Dinh
   Tan Le
   Nguyen, Long H. B.
TI Linguistic-Relationships-Based Approach for Improving Word Alignment
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB The unsupervised word alignments (such as GIZA++) are widely used in the phrase-based statistical machine translation. The quality of the model is proportional to the size and the quality of the bilingual corpus. However, for low-resource language pairs such as Chinese and Vietnamese, a result of unsupervised word alignment sometimes is of low quality due to the sparse data. In addition, this model does not take advantage of the linguistic relationships to improve performance of word alignment. Chinese and Vietnamese have the same language type and have close linguistic relationships. In this article, we integrate the characteristics of linguistic relationships into the word alignment model to enhance the quality of Chinese-Vietnamese word alignment. These linguistic relationships are Sino-Vietnamese and content word. The experimental results showed that our method improved the performance of word alignment as well as the quality of machine translation.
RI Tran, Phuoc/GLU-1021-2022; Nguyen, Long/AAW-3430-2020
OI Nguyen, Long/0000-0002-0884-1635; Dinh, Dien/0000-0003-2069-1016
SN 2375-4699
EI 2375-4702
PD NOV
PY 2017
VL 17
IS 1
AR 5
DI 10.1145/3133323
UT WOS:000415404000005
ER

PT J
AU Liang, HS
   Xue, YZ
   Zhao, TJ
AF Liang, Huashen
   Xue, Yongzeng
   Zhao, Tiejun
TI Decorated Phrase Model and Syntax-Based Reordering Model for Statistical
   Machine Translation
SO INTERNATIONAL JOURNAL OF FUZZY SYSTEMS
AB In the past few years, much attention has been paid on extending phrase-based statistical machine translation with syntactic structures. In this paper, we introduce a novel phrase model, in which treebank tags are employed to decorate the bilingual phrase pairs. We use tag sequences, instead of phrase pairs, to train the lexicalized reordering model. Since the number of treebank tags is much smaller than the number of words, the tag sequence based reordering model is smaller and more accurate than the phrase based reordering model. Experiments were carried out on three types of models: the phrase model, the POS tag encapsulated phrase (PTEP) model and the syntactic tag encapsulated phrase (STEP) model. The STEP model obtained higher BLEU-4 score than other models on NIST MT tasks.
SN 1562-2479
EI 2199-3211
PD JUN
PY 2012
VL 14
IS 2
BP 314
EP 319
UT WOS:000306825100016
ER

PT J
AU Ma, JJ
   Huang, DG
   Liu, HX
   Sheng, WF
AF Ma Jianjun
   Huang Degen
   Liu Haixia
   Sheng Wenfeng
TI MT-Oriented English PoS Tagging and Its Application to Noun Phrase
   Chunking
SO CHINA COMMUNICATIONS
AB A hybrid approach to English Part-of-Speech (PoS) tagging with its target application being English-Chinese machine translation in business domain is presented, demonstrating how a present tagger can be adapted to learn from a small amount of data and handle unknown words for the purpose of machine translation. A small size of 998 k English annotated corpus in business domain is built semiautomatically based on a new tagset; the maximum entropy model is adopted, and rule-based approach is used in post-processing. The tagger is further applied in Noun Phrase (NP) chunking. Experiments show that our tagger achieves an accuracy of 98.14%, which is a quite satisfactory result. In the application to NP chunking, the tagger gives rise to 2.21% increase in F-score, compared with the results using Stanford tagger.
RI Ma, Jianjun/AFG-6860-2022
OI Ma, Jianjun/0000-0002-7799-0167
SN 1673-5447
PD MAR
PY 2012
VL 9
IS 3
BP 58
EP 67
UT WOS:000301908400007
ER

PT J
AU Klimova, B
   Pikhart, M
   Benites, AD
   Lehr, C
   Sanchez-Stockhammer, C
AF Klimova, Blanka
   Pikhart, Marcel
   Benites, Alice Delorme
   Lehr, Caroline
   Sanchez-Stockhammer, Christina
TI Neural machine translation in foreign language teaching and learning: a
   systematic review
SO EDUCATION AND INFORMATION TECHNOLOGIES
AB Nowadays, hardly anyone working in the field of foreign language teaching and learning can imagine life without machine translation (MT) tools. Thanks to the rapid development of artificial intelligence, MT now most widely assumes a new form, the so-called Neural Machine Translation (NMT), which offers the potential for a wide application in foreign language learning (FLL). Therefore, the purpose of this review study is to explore different approaches to the efficient implementation of NMT into FLL and provide specific pedagogical implications for best practices. The PRISMA methodology for systematic reviews and meta-analyses was strictly followed. The search was conducted in two well-established databases, specifically Scopus and Web of Science, to generate sufficient data from research articles for further analysis. The findings of this systematic review indicate that NMT is an efficient tool for developing both productive (speaking and writing) and receptive (reading and listening) language skills, including mediation skills, which are relevant for translation. Moreover, the results show that NMT tools are especially suitable for advanced learners of L2, whose higher proficiency level enables them to critically reflect on the output of NMT texts more than beginners or lower-intermediate learners. Thus, the findings of this review study reveal that NMT has valuable implications for L2 pedagogy since it can serve as a very powerful online reference tool for FLL provided that teachers introduce students to its benefits but also limitations by implementing various teaching approaches.
RI Sanchez-Stockhammer, Christina/GZG-5413-2022; Pikhart,
   Marcel/D-8945-2012; Klimova, Blanka/F-7016-2019
OI Pikhart, Marcel/0000-0002-5633-9332; Sanchez-Stockhammer,
   Christina/0000-0002-6294-3579; Delorme Benites,
   Alice/0000-0002-5254-4988; Klimova, Blanka/0000-0001-8000-9766; Lehr,
   Caroline/0000-0002-1690-5117
SN 1360-2357
EI 1573-7608
PD JAN
PY 2023
VL 28
IS 1
BP 663
EP 682
DI 10.1007/s10639-022-11194-2
EA JUL 2022
UT WOS:000821987800001
ER

PT C
AU Aji, AF
   Heafield, K
AF Aji, Alham Fikri
   Heafield, Kenneth
GP Assoc Computat Linguist
TI Compressing Neural Machine Translation Models with 4-bit Precision
SO NEURAL GENERATION AND TRANSLATION
CT 4th Workshop on Neural Generation and Translation
CY JUL 05-10, 2020
CL ELECTR NETWORK
AB Quantization is one way to compress Neural Machine Translation (NMT) models, especially for edge devices. This paper pushes quantization from 8 bits, seen in current work on machine translation, to 4 bits. Instead of fixed-point quantization, we use logarithmic quantization since parameters are skewed towards zero. We then observe that quantizing the bias terms in this way damages quality, so we leave them uncompressed. Bias terms are a tiny fraction of the model so the impact on compression rate is minimal. Retraining is necessary to preserve quality, for which we propose to use an error-feedback mechanism that treats compression errors like noisy gradients. We empirically show that NMT models based on the Transformer or RNN architectures can be compressed up to 4-bit precision without any noticeable quality degradation. Models can be compressed up to binary precision, albeit with lower quality. The RNN architecture appears more robust towards compression, compared to the Transformer.
OI Heafield, Kenneth/0000-0002-6344-9927
BN 978-1-952148-17-0
PY 2020
BP 35
EP 42
UT WOS:000563428500004
ER

PT J
AU Cadwell, P
   O'Brien, S
   Teixeira, CSC
AF Cadwell, Patrick
   O'Brien, Sharon
   Teixeira, Carlos S. C.
TI Resistance and accommodation: factors for the (non-) adoption of machine
   translation among professional translators
SO PERSPECTIVES-STUDIES IN TRANSLATION THEORY AND PRACTICE
AB Despite considerable advances in machine translation (MT), adoption by professional translators still meets with resistance. Research on the human factors associated with MT (non-)adoption is required to understand this state of affairs. We investigate whether two specific groups of professional translators use MT, what reasons they advance for its use/non-use and what factors might explain the reasons given. Participants advanced an equally diverse set of reasons for using MT as for not using it, and this was strongly linked to text type, language pair, quality and trust. Using an agency theory lens, we found evidence of Pickering's dialectics of resistance and accommodation in the focus group data. We also found that one group of translators is more open to the use of MT, and suggest that the socio-technical context of deployment might explain this finding.
SN 0907-676X
EI 1747-6623
PY 2018
VL 26
IS 3
BP 301
EP 321
DI 10.1080/0907676X.2017.1337210
UT WOS:000429993900001
ER

PT C
AU Rodrigues, J
   Gomes, L
   Neale, S
   Querido, A
   Rendeiro, N
   Stajner, S
   Silva, J
   Branco, A
AF Rodrigues, Joao
   Gomes, Luis
   Neale, Steven
   Querido, Andreia
   Rendeiro, Nuno
   Stajner, Sanja
   Silva, Joao
   Branco, Antonio
BE Silva, J
   Ribeiro, R
   Quaresma, P
   Adami, A
   Branco, A
TI Domain-Specific Hybrid Machine Translation from English to Portuguese
SO COMPUTATIONAL PROCESSING OF THE PORTUGUESE LANGUAGE (PROPOR 2016)
SE Lecture Notes in Artificial Intelligence
CT 12th International Conference on the Computational Processing of
   Portuguese (PROPOR)
CY JUL 13-15, 2016
CL Univ Lisbon, Tomar, PORTUGAL
SP Nat Language & Speech Grp, Fac Sci, Dept Informat
HO Univ Lisbon
AB Machine translation (MT) from English to Portuguese has not typically received much attention in existing research. In this paper, we focus on MT from English to Portuguese for the specific domain of information technology (IT), building a small in-domain parallel corpus to address the lack of IT-specific and publicly-available parallel corpora and then adapted an existing hybrid MT system to the new language pair (English to Portuguese). We further improved the initial version of the EN-PT hybrid system by adding various modules to address the most frequently occurring errors in the initial system. In order to assess the improvements achieved by each of these dedicated modules, we compared all versions of our MT system automatically. In addition, we conduct and report on a detailed error analysis of the initial and final versions of our system.
RI Neale, Steven/F-2111-2018; Gomes, Luís/G-1192-2011; Stajner,
   Sanja/AAW-1288-2020
OI Neale, Steven/0000-0003-2551-2267; Gomes, Luís/0000-0003-3119-4189;
   Stajner, Sanja/0000-0002-7780-7035
SN 0302-9743
EI 1611-3349
BN 978-3-319-41552-9; 978-3-319-41551-2
PY 2016
VL 9727
BP 50
EP 61
DI 10.1007/978-3-319-41552-9_5
UT WOS:000386271100005
ER

PT J
AU Costa-jussa, MR
AF Costa-jussa, Marta R.
TI How much hybridization does machine translation Need?
SO JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY
AB Rule-based and corpus-based machine translation (MT) have coexisted for more than 20 years. Recently, boundaries between the two paradigms have narrowed and hybrid approaches are gaining interest from both academia and businesses. However, since hybrid approaches involve the multidisciplinary interaction of linguists, computer scientists, engineers, and information specialists, understandably a number of issues exist. While statistical methods currently dominate research work in MT, most commercial MT systems are technically hybrid systems. The research community should investigate the benefits and questions surrounding the hybridization of MT systems more actively. This paper discusses various issues related to hybrid MT including its origins, architectures, achievements, and frustrations experienced in the community. It can be said that both rule-based and corpus- based MT systems have benefited from hybridization when effectively integrated. In fact, many of the current rule/corpus-based MT approaches are already hybridized since they do include statistics/rules at some point.
RI Costa-jussa, Marta R./M-7886-2013
OI Costa-jussa, Marta R./0000-0002-5703-520X
SN 2330-1635
EI 2330-1643
PD OCT
PY 2015
VL 66
IS 10
BP 2160
EP 2165
DI 10.1002/asi.23517
UT WOS:000361184500016
ER

PT J
AU Rodriguez, L
   Garcia-Varea, I
   Gamez, JA
AF Rodriguez, Luis
   Garcia-Varea, Ismael
   Gamez, Jose A.
TI On the application of different evolutionary algorithms to the alignment
   problem in statistical machine translation
SO NEUROCOMPUTING
CT 4th International Symposium on Neural Networks (ISNN 2007)
CY JUN 03-07, 2007
CL Nanjing, PEOPLES R CHINA
SP Natl Nat Sci Fdn China, KC Wong Educ Fdn, SE Univ China, Chinese Univ Hong Kong, Univ Illinois, Chicago
AB In statistical machine translation, an alignment defines a mapping between the words in the source and in the target sentence. Alignments are used, on the one hand, to train the statistical models and, on the other, during the decoding process to link the words in the source sentence to the words in the partial hypotheses generated. In both cases, the quality of the alignments is crucial for the success of the translation process. In this paper, we propose several evolutionary algorithms for computing alignments between two sentences in a parallel corpus. This algorithm has been tested on different tasks involving different pair of languages. Specifically, in the two shared tasks proposed in the HLT-NAACL 2003 and in the ACL 2005, the EDA-based algorithm outperforms the best participant systems. In addition, the experiments show that, because of the limitations of the well known statistical alignment models, new improvements in alignments quality could not be achieved by using improved search algorithms only. (c) 2007 Elsevier B.V. All rights reserved.
RI Gámez, Jose A. A/K-5098-2014; García-Varea, Ismael/P-6816-2017
OI Gámez, Jose A. A/0000-0003-1188-1117; García-Varea,
   Ismael/0000-0003-3451-7852
SN 0925-2312
EI 1872-8286
PD JAN
PY 2008
VL 71
IS 4-6
BP 755
EP 765
DI 10.1016/j.neucom.2007.10.006
UT WOS:000253663800034
ER

PT J
AU Oh, J
   Choi, YS
AF Oh, Jiun
   Choi, Yong-Suk
TI Reusing Monolingual Pre-Trained Models by Cross-Connecting Seq2seq
   Models for Machine Translation
SO APPLIED SCIENCES-BASEL
AB This work uses sequence-to-sequence (seq2seq) models pre-trained on monolingual corpora for machine translation. We pre-train two seq2seq models with monolingual corpora for the source and target languages, then combine the encoder of the source language model and the decoder of the target language model, i.e., the cross-connection. We add an intermediate layer between the pre-trained encoder and the decoder to help the mapping of each other since the modules are pre-trained completely independently. These monolingual pre-trained models can work as a multilingual pre-trained model because one model can be cross-connected with another model pre-trained on any other language, while their capacity is not affected by the number of languages. We will demonstrate that our method improves the translation performance significantly over the random baseline. Moreover, we will analyze the appropriate choice of the intermediate layer, the importance of each part of a pre-trained model, and the performance change along with the size of the bitext.
OI Choi, Yong Suk/0000-0002-9042-0599
EI 2076-3417
PD SEP
PY 2021
VL 11
IS 18
AR 8737
DI 10.3390/app11188737
UT WOS:000699162300001
ER

PT C
AU Li, JD
   Ataman, D
   Sennrich, R
AF Li, Jiaoda
   Ataman, Duygu
   Sennrich, Rico
GP Assoc Computat Linguist
TI Vision Matters When It Should: Sanity Checking Multimodal Machine
   Translation Models
SO 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2021)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 07-11, 2021
CL Punta Cana, DOMINICAN REP
AB Multimodal machine translation (MMT) systems have been shown to outperform their text-only neural machine translation (NMT) counterparts when visual context is available. However, recent studies have also shown that the performance of MMT models is only marginally impacted when the associated image is replaced with an unrelated image or noise, which suggests that the visual context might not be exploited by the model at all. We hypothesize that this might be caused by the nature of the commonly used evaluation benchmark, also known as Multi30K, where the translations of image captions were prepared without actually showing the images to human translators. In this paper, we present a qualitative study that examines the role of datasets in stimulating the leverage of visual modality and we propose methods to highlight the importance of visual signals in the datasets which demonstrate improvements in reliance of models on the source images. Our findings suggest the research on effective MMT architectures is currently impaired by the lack of suitable datasets and careful consideration must be taken in creation of future MMT datasets, for which we also provide useful insights.(1)
BN 978-1-955917-09-4
PY 2021
BP 8556
EP 8562
UT WOS:000860727002051
ER

PT J
AU Boros, T
   Tufis, D
AF Boros, Tiberiu
   Tufis, Dan
TI ROMANIAN-ENGLISH SPEECH TRANSLATION
SO PROCEEDINGS OF THE ROMANIAN ACADEMY SERIES A-MATHEMATICS PHYSICS
   TECHNICAL SCIENCES INFORMATION SCIENCE
AB Speech to speech (S2S) translation is a complex process designed to enable the communication between individuals that speak different languages and it represents a valuable contribution to (1) science, (2) cross-cultural interaction and (3) global business. Through S2S, a text spoken in one language is automatically recognized, translated and synthesized in another language. This paper presents an overview of our approach to Romanian-English bi-directional speech translation and we cover the methods and technologies used for implementing such a system
RI Tufis, Dan/AAO-4732-2020
SN 1454-9069
PD JAN-MAR
PY 2014
VL 15
IS 1
BP 68
EP 75
UT WOS:000333795600009
ER

PT C
AU Zhang, Y
   Jones, GJF
   Zhang, K
AF Zhang, Ying
   Jones, Gareth J. F.
   Zhang, Ke
BE Peters, C
   Jikoun, V
   Mandl, T
   Muller, H
   Oard, DW
   Penas, A
   Petras, V
   Santos, D
TI Dublin City University at CLEF 2007: Cross-Language Speech Retrieval
   Experiments
SO ADVANCES IN MULTILINGUAL AND MULTIMODAL INFORMATION RETRIEVAL
SE Lecture Notes in Computer Science
CT 8th Workshop of the Cross-Language Evaluation Forum
CY SEP 19-21, 2007
CL Budapest, HUNGARY
AB The Dublin City University participation in the CLEF 2007 CL-SR English task concentrated primarily on issues of topic translation. Our retrieval system used the BM25F model and pseudo relevance feedback. Topics were translated into English using the Yahoo! BabelFish free online service combined with domain-specific translation lexicons gathered automatically from Wikipedia. We explored alternative topic translation methods using these resources. Our results indicate that extending machine translation tools using automatically generated domain-specific translation lexicons can provide improved CLIR effectiveness for this task.
OI Jones, Gareth/0000-0003-2923-8365
SN 0302-9743
BN 978-3-540-85759-4
PY 2008
VL 5152
BP 703
EP +
UT WOS:000260420000089
ER

PT C
AU Chollampatt, S
   Susanto, RH
   Tan, L
   Szymanska, E
AF Chollampatt, Shamil
   Susanto, Raymond Hendy
   Tan, Liling
   Szymanska, Ewa
GP Assoc Computat Linguist
TI Can Automatic Post-Editing Improve NMT?
SO PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL
   LANGUAGE PROCESSING (EMNLP)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 16-20, 2020
CL ELECTR NETWORK
SP Bloomberg Engn, Google Res, Apple, Amazon Sci, Baidu, Megagon Labs, Facebook, DeepMind, Grammarly, ByteDance, Zeta Alpha, Babelscape, Naver, Adobe, Hitachi, Salesforce, Univ So Calif, Viterbi Sch Engn, Informat Sci Inst
AB Automatic post-editing (APE) aims to improve machine translations, thereby reducing human post-editing effort. APE has had notable success when used with statistical machine translation (SMT) systems but has not been as successful over neural machine translation (NMT) systems. This has raised questions on the relevance of APE task in the current scenario. However, the training of APE models has been heavily reliant on large-scale artificial corpora combined with only limited human post-edited data. We hypothesize that APE models have been underperforming in improving NMT translations due to the lack of adequate supervision. To ascertain our hypothesis, we compile a larger corpus of human post-edits of English to German NMT. We empirically show that a state-of-art neural APE model trained on this corpus can significantly improve a strong in-domain NMT system, challenging the current understanding in the field. We further investigate the effects of varying training data sizes, using artificial training data, and domain specificity for the APE task. We release this new corpus under CC BY-NC-SA 4.0 license at https:// github.com/shamilcm/pedra.
BN 978-1-952148-60-6
PY 2020
BP 2736
EP 2746
UT WOS:000855160702074
ER

PT C
AU Tian, JF
   Lan, M
   Wu, YB
   Wang, JG
   Qiu, L
   Li, S
   Jun, L
   Si, L
AF Tian, Junfeng
   Lan, Man
   Wu, Yuanbin
   Wang, Jingang
   Qiu, Long
   Li, Sheng
   Jun, Lang
   Si, Luo
BE Pasi, G
   Piwowarski, B
   Azzopardi, L
   Hanbury, A
TI An Adversarial Joint Learning Model for Low-Resource Language Semantic
   Textual Similarity
SO ADVANCES IN INFORMATION RETRIEVAL (ECIR 2018)
SE Lecture Notes in Computer Science
CT 40th European Conference on Information Retrieval Research (ECIR)
CY MAR 26-29, 2018
CL Grenoble, FRANCE
SP Lab Informatique Grenoble, British Comp Soc, Informat Retrieval Specialist Grp, Naver Labs, Google, Univ Grenoble Alpes, Grenoble INP, Grenoble Alpes Data Inst, Grenoble Alpes Metropole, Labex, ARIA, ACM Special Interest Grp Informat Retrieval, Springer, Persyval Lab
AB Semantic Textual Similarity (STS) of low-resource language is a challenging research problem with practical applications. Traditional solutions employ machine translation techniques to translate the low-resource languages to some resource-rich languages such as English. Hence, the final performance is highly dependent on the quality of machine translation. To decouple the machine translation dependency while still take advantage of the data in resource-rich languages, this work proposes to jointly learn the low-resource language STS task and that of a resource-rich one, which only relies on multilingual word embeddings. In particular, we project the low-resource language word embeddings into the semantic space of the resource-rich language via a translation matrix. To make the projected word embeddings resemble that of the resource-rich language, a language discriminator is introduced as an adversarial teacher. Thus the parameters of sentence similarity neural networks of two tasks can be effectively shared. The plausibility of our model is demonstrated by extensive experimental results.
SN 0302-9743
EI 1611-3349
BN 978-3-319-76941-7; 978-3-319-76940-0
PY 2018
VL 10772
BP 89
EP 101
DI 10.1007/978-3-319-76941-7_7
UT WOS:000443115000007
ER

PT C
AU Marrafa, P
   Amaro, R
   Freire, N
   Mendes, S
AF Marrafa, Palmira
   Amaro, Raquel
   Freire, Nuno
   Mendes, Sara
BE Kuhn, T
   Fuchs, NE
TI Portuguese Controlled Language: Coping with Ambiguity
SO CONTROLLED NATURAL LANGUAGE, CNL 2012
SE Lecture Notes in Computer Science
CT 3rd International Workshop on Controlled Natural Language (CNL)
CY AUG 29-31, 2012
CL Dept Informat, Zurich, SWITZERLAND
SP Univ Zurich, Inst Computat Linguist
HO Dept Informat
AB This paper focuses on strategies to avoid lexical related ambiguity, induced by polysemy or by syntactic function effects, in the context of a system to control Portuguese as a source language for machine translation. This system, which is being developed under wider scope ongoing research, involves two main components - a controlled language for Portuguese and a tool to evaluate the conformity of texts with the controlled language. In a subsidiary way, it also makes use of the Portuguese WordNet (WordNet. PT).
RI Freire, Nuno/AAD-9410-2022; Mendes, Sara/N-8925-2013
OI Freire, Nuno/0000-0002-3632-8046; Mendes, Sara/0000-0002-4635-2197;
   Amaro, Raquel/0000-0002-4923-7186; Marrafa, Palmira/0000-0002-2798-7912
SN 0302-9743
BN 978-3-642-32612-7
PY 2012
VL 7427
BP 152
EP 166
UT WOS:000342921800011
ER

PT J
AU Li, YC
   Li, JH
   Zhang, M
AF Li, Yachao
   Li, Junhui
   Zhang, Min
TI Improving neural machine translation with latent features feedback
SO NEUROCOMPUTING
AB Most state-of-the-art neural machine translation (NMT) models progressively encode feature representation in a bottom-up feed-forward fashion. This traditional encoding mechanism has no guidance from external signals. In computer vision tasks, the feedback connection plays a crucial role, particularly for understanding tasks. In this paper, we propose a simple but effective approach to learn latent feature representations explicitly from input sentences via a latent feature encoder (LFE), which are fed back to an NMT encoder via a top-down feedback mechanism. Through the feedback mechanism, the representations in one layer are influenced by representations of both lower and higher layers, resulting in a more effective encoding mechanism. Besides, to enhance the capability of the LFE in better capturing latent features from the source sentences, we pre-train the LFE via a Denoising Auto-Encoder (DAE) strategy. Experimentation on the large-scale WMT 2014 English-to-German and WMT 2017 Chinese-to-English translation tasks demonstrates that our proposed LFE, either pre-trained with the DAE or not, significantly outperforms the strong baseline. (c) 2021 Elsevier B.V. All rights reserved.
SN 0925-2312
EI 1872-8286
PD NOV 6
PY 2021
VL 463
BP 368
EP 378
DI 10.1016/j.neucom.2021.08.019
EA AUG 2021
UT WOS:000708073900013
ER

PT J
AU Shen, SQ
   Liu, Y
   Sun, MS
AF Shen, Shi-Qi
   Liu, Yang
   Sun, Mao-Song
TI Optimizing Non-Decomposable Evaluation Metrics for Neural Machine
   Translation
SO JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY
AB While optimizing model parameters with respect to evaluation metrics has recently proven to benefit end to-end neural machine translation (NMT), the evaluation metrics used in the training are restricted to be defined at the sentence level to facilitate online learning algorithms. This is undesirable because the final evaluation metrics used in the testing phase are usually non-decomposable (i.e., they are defined at the corpus level and cannot be expressed as the sum of sentence-level metrics). To minimize the discrepancy between the training and the testing, we propose to extend the minimum risk training (MRT) algorithm to take non-decomposable corpus-level evaluation metrics into consideration while still keeping the advantages of online training. This can be done by calculating corpus-level evaluation metrics on a subset of training data at each step in online training. Experiments on Chinese-English and English-French translation show that our approach improves the correlation between training and testing and significantly outperforms the MRT algorithm using decomposable evaluation metrics.
SN 1000-9000
EI 1860-4749
PD JUL
PY 2017
VL 32
IS 4
BP 796
EP 804
DI 10.1007/s11390-017-1760-9
UT WOS:000405580700012
ER

PT C
AU Rios-Vila, A
   Rizo, D
   Calvo-Zaragoza, J
AF Rios-Vila, Antonio
   Rizo, David
   Calvo-Zaragoza, Jorge
BE Llados, J
   Lopresti, D
   Uchida, S
TI Complete Optical Music Recognition via Agnostic Transcription and
   Machine Translation
SO DOCUMENT ANALYSIS AND RECOGNITION, ICDAR 2021, PT III
SE Lecture Notes in Computer Science
CT 16th IAPR International Conference on Document Analysis and Recognition
   (ICDAR)
CY SEP 05-10, 2021
CL ELECTR NETWORK
SP IAPR
AB Optical Music Recognition workflows currently involve several steps to retrieve information from music documents, focusing on image analysis and symbol recognition. However, despite many efforts, there is little research on how to bring these recognition results to practice, as there is still one step that has not been properly discussed: the encoding into standard music formats and its integration within OMR workflows to produce practical results that end-users could benefit from. In this paper, we approach this topic and propose options for completing OMR, eventually exporting the score image into a standard digital format. Specifically, we discuss the possibility of attaching Machine Translation systems to the recognition pipeline to perform the encoding step. After discussing the most appropriate systems for the process and proposing two options for the translation, we evaluate its performance in contrast to a direct-encoding pipeline. Our results confirm that the proposed addition to the pipeline establishes itself as a feasible and interesting solution for complete OMR processes, especially when limited training data is available, which represents a common scenario in music heritage.
OI Calvo-Zaragoza, Jorge/0000-0003-3183-2232; Rios-Vila,
   Antonio/0000-0002-7770-9726
SN 0302-9743
EI 1611-3349
BN 978-3-030-86334-0; 978-3-030-86333-3
PY 2021
VL 12823
BP 661
EP 675
DI 10.1007/978-3-030-86334-0_43
UT WOS:000711646700043
ER

PT C
AU Artetxe, M
   Labaka, G
   Agirre, E
AF Artetxe, Mikel
   Labaka, Gorka
   Agirre, Eneko
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Bilingual Lexicon Induction through Unsupervised Machine Translation
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB A recent research line has obtained strong results on bilingual lexicon induction by aligning independently trained word embeddings in two languages and using the resulting cross-lingual embeddings to induce word translation pairs through nearest neighbor or related retrieval methods. In this paper, we propose an alternative approach to this problem that builds on the recent work on unsupervised machine translation. This way, instead of directly inducing a bilingual lexicon from cross-lingual embeddings, we use them to build a phrase-table, combine it with a language model, and use the resulting machine translation system to generate a synthetic parallel corpus, from which we extract the bilingual lexicon using statistical word alignment techniques. As such, our method can work with any word embedding and cross-lingual mapping technique, and it does not require any additional resource besides the monolingual corpus used to train the embeddings. When evaluated on the exact same cross-lingual embeddings, our proposed method obtains an average improvement of 6 accuracy points over nearest neighbor and 4 points over CSLS retrieval, establishing a new state-of-the-art in the standard MUSE dataset.
RI Labaka, Gorka/G-8236-2011; Agirre, Eneko/H-7323-2015
OI Labaka, Gorka/0000-0003-4611-2502; Agirre, Eneko/0000-0002-0195-4899
BN 978-1-950737-48-2
PY 2019
BP 5002
EP 5007
UT WOS:000493046107052
ER

PT C
AU Sluyter-Gathje, H
   Bourgonje, P
   Stede, M
AF Sluyter-Gaethje, Henny
   Bourgonje, Peter
   Stede, Manfred
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mariani, J
   Mazo, H
   Moreno, A
   Odijk, J
   Piperidis, S
TI Shallow Discourse Parsing for Under-Resourced Languages: Combining
   Machine Translation and Annotation Projection
SO PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES
   AND EVALUATION (LREC 2020)
CT 12th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 11-16, 2020
CL Marseille, FRANCE
AB Shallow Discourse Parsing (SDP), the identification of coherence relations between text spans, relies on large amounts of training data, which so far exists only for English - any other language is in this respect an under-resourced one. For those languages where machine translation from English is available with reasonable quality, MT in conjunction with annotation projection can be an option for producing an SDP resource. In our study, we translate the English Penn Discourse TreeBank into German and experiment with various methods of annotation projection to arrive at the German counterpart of the PDTB. We describe the key characteristics of the corpus as well as some typical sources of errors encountered during its creation. Then we evaluate the GermanPDTB by training components for selected sub-tasks of discourse parsing on this silver data and compare performance to the same components when trained on the gold, original PDTB corpus.
OI Stede, Manfred/0000-0001-6819-2043
BN 979-10-95546-34-4
PY 2020
BP 1044
EP 1050
UT WOS:000724697201015
ER

PT C
AU Fung, I
   Mak, B
AF Fung, Ivan
   Mak, Brian
GP IEEE
TI Multi-Head Attention for End-to-End Neural Machine Translation
SO 2018 11TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING
   (ISCSLP)
CT 11th International Symposium on Chinese Spoken Language Processing
   (ISCSLP)
CY NOV 26-29, 2018
CL Academia Sinica, Taipei, TAIWAN
SP CSLP, ISCA, IEEE, Academia Sinica, Inst Informat Sci, Academia Sinica, Inst Linguistics, Academia Sinica, Res Ctr Informat Technol Innovat, Academia Sinica Ctr Digital Cultures, Bur Foreign Trade, Minist Sci & Technol, Minist Educ, MEDIATEK, iFLYTEK, Sogou, HUAWEI, DATATANG, Unisound, Cyberon, Tancent AI Lab, Merry Elect Co Ltd, EMOTIBOT, Chunghwa Telecom Labs, Ind Technol Res Inst
HO Academia Sinica
AB Inspired by the recent success of Google's Transformer model, works have been done on borrowing the novel idea of multi-head attention to various applications under different architectures. Albeit latest works have adopted this idea using an end-to-end recurrent model on speech recognition and voice search, making use of a similar model on machine translation has not been attempted yet. In this work, we examine multi-head attention under the attention-based recurrent encoder-decoder framework, and conduct detailed analysis on the positional response of multiple heads. Through leveraging the essence of multi-head attention, we are capable of attaining a state-of-the-art result on IWSLT' 15 with 28.48 tokenized BLEU and 53.86% TER, which gives a 0.17 gain in BLEU and 0.37% reduction in TER. Similarly we achieve 25.58 tokenized BLEU and 55.03% TER on WMT' 16, which provide a 0.40 gain in BLEU and 0.32% reduction in TER to the baseline model, respectively. To the best of our knowledge, this is the first work(1) that evaluates the concept of multi-head attention in an end-to-end recurrent network on machine translation tasks.
BN 978-1-5386-5627-3
PY 2018
BP 250
EP 254
UT WOS:000469313700051
ER

PT C
AU Tabrizi, AA
   Mahmud, R
AF Tabrizi, Arash Amini
   Mahmud, Rohana
GP IEEE
TI Issues of Coherence Analysis on English Translations of Quran
SO 2013 FIRST INTERNATIONAL CONFERENCE ON COMMUNICATIONS SIGNAL PROCESSING,
   AND THEIR APPLICATIONS (ICCSPA'13)
SE International Conference on Communications Signal Processing and their
   Applications ICCSPA
CT 1st International Conference on Communications, Signal Processing, and
   their Applications (ICCSPA)
CY FEB 12-14, 2013
CL Amer Univ Sharjah, Sharjah, U ARAB EMIRATES
SP IEEE
HO Amer Univ Sharjah
AB This study shows issues of comparing English translations of Holy Quran and its Arabic text from discourse structure perspective. There are several different translations of Quran, which differ in structure and word domain. In these translations, the order of sentences, phrases, and words is different, which affects computational text analyzing results. It is a new idea to study translations of Quran from entity coherence and lexical cohesion point of view, as a method for evaluating the accuracy and equivalence of existing translations. The results of this study even can be used for machine translation in the future. This research is a preliminary stage of investigating the issues, constructing a platform and defining of some preliminary rules for comparing and evaluating discourse structure of translations.
RI Mahmud, Rohana/B-9588-2010
OI Mahmud, Rohana/0000-0002-8286-3891
SN 2377-682X
BN 978-1-4673-2821-0; 978-1-4673-2820-3
PY 2013
UT WOS:000318427600051
ER

PT C
AU Yang, ZJ
   Gao, YB
   Wang, WY
   Ney, H
AF Yang, Zijian
   Gao, Yingbo
   Wang, Weiyue
   Ney, Hermann
GP Assoc Computat Linguist
TI Predicting and Using Target Length in Neural Machine Translation
SO 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON
   NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020)
CT 1st Conference of the Asia-Pacific Chapter of the
   Association-for-Computational-Linguistics / 10th International Joint
   Conference on Natural Language Processing (AACL-IJCNLP)
CY DEC 04-07, 2020
CL Soochow Univ, ELECTR NETWORK
SP Assoc Computat Linguist, Asia Pacific Chapter, Baidu, Huawei
HO Soochow Univ
AB Attention-based encoder-decoder models have achieved great success in neural machine translation tasks. However, the lengths of the target sequences are not explicitly predicted in these models. This work proposes length prediction as an auxiliary task and set up a sub-network to obtain the length information from the encoder. Experimental results show that the length prediction sub-network brings improvements over the strong baseline system and that the predicted length can be used as an alternative to length normalization during decoding.
RI Wang, Weiyue/HIZ-8247-2022
BN 978-1-952148-91-0
PY 2020
BP 389
EP 395
UT WOS:000857113500041
ER

PT C
AU Al-Ibrahim, R
   Duwairi, RM
AF Al-Ibrahim, Roqayah
   Duwairi, Rehab M.
GP IEEE
TI Neural Machine Translation from Jordanian Dialect to Modern Standard
   Arabic
SO 2020 11TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION
   SYSTEMS (ICICS)
SE International Conference on Information and Communication Systems
CT 11th International Conference on Information and Communication Systems
   (ICICS)
CY APR 07-09, 2020
CL Jordan Univ Sci & Techno, Irbid, JORDAN
SP Atypon, SHMAGH SOC, Green Circle, Inst Elect & Elect Engineers
HO Jordan Univ Sci & Techno
AB The development of cultures and societies all over the world was the first reason for the emergence of many different languages and dialects that differ from each other based on the geographical location of these communities, whether in the Arab countries or Western or other parts of the world. Due to these differences, there is a need to translate these dialects between each other to facilitate their understanding and handling by people who will use them from other communities. The tremendous technological advancement and the flourishing of the era of Deep Learning, has led to the emergence of so-called neural machine translation (NMT), which has significantly facilitated the translation process compared to other methods. In this paper, we present a framework to translate the Jordanian dialect into Modern Standard Arabic (MSA) using Deep Learning, in particular, the RNN encoder-decoder model, which provided good results on the level of our manually created dataset. The conducted experiments using this model were divided into two parts: word level and sentence level, and the results were as follows: loss equals 0.8 and accuracy equals 91.3% when using the model for word to word translation; and loss value equals 3.33 and accuracy equals 63.2% when using the model for sentence translation. These are very encouraging results in this largely unexplored topic.
SN 2471-125X
BN 978-1-7281-6227-0
PY 2020
BP 173
EP 178
DI 10.1109/ICICS49469.2020.239505
UT WOS:000570719500030
ER

PT J
AU Han, C
   Lu, XL
AF Han, Chao
   Lu, Xiaolei
TI Can automated machine translation evaluation metrics be used to assess
   students' interpretation in the language learning classroom?
SO COMPUTER ASSISTED LANGUAGE LEARNING
AB The use of translation and interpreting (T&I) in the language learning classroom is commonplace, serving various pedagogical and assessment purposes. Previous utilization of T&I exercises is driven largely by their potential to enhance language learning, whereas the latest trend has begun to underscore T&I as a crucial skill to be acquired as part of transcultural competence for language learners and future language users. Despite their growing popularity and utility in the language learning classroom, assessing T&I is time-consuming, labor-intensive and cognitively taxing for human raters (e.g., language teachers), primarily because T&I assessment entails meticulous evaluation of informational equivalence between the source-language message and target-language renditions. One possible solution is to rely on automated quality metrics that are originally developed to evaluate machine translation (MT). In the current study, we investigated the viability of using four automated MT evaluation metrics, BLEU, NIST, METEOR and TER, to assess human interpretation. Essentially, we correlated the automated metric scores with the human-assigned scores (i.e., the criterion measure) from multiple assessment scenarios to examine the degree of machine-human parity. Overall, we observed fairly strong metric-human correlations for BLEU (Pearson's r = 0.670), NIST (r = 0.673) and METEOR (r = 0.882), especially when the metric computation was conducted on the sentence level rather than the text level. We discussed these emerging findings and others in relation to the feasibility of operationalizing MT metrics to evaluate students' interpretation in the language learning classroom. Supplemental data for this article is available online at https://doi.org/10.1080/09588221.2021.1968915 .
RI Han, Chao/G-7713-2018
OI Han, Chao/0000-0002-6712-0555; Lu, Xiaolei/0000-0002-6929-4110
SN 0958-8221
EI 1744-3210
DI 10.1080/09588221.2021.1968915
EA AUG 2021
UT WOS:000690828200001
ER

PT J
AU Vu, V
   Nguyen, QP
   Tunyan, EV
   Ock, CY
AF Vu, Van-Hai
   Nguyen, Quang-Phuoc
   Tunyan, Ebipatei Victoria
   Ock, Cheol-Young
TI Improving the Performance of Vietnamese-Korean Neural Machine
   Translation with Contextual Embedding
SO APPLIED SCIENCES-BASEL
AB With the recent evolution of deep learning, machine translation (MT) models and systems are being steadily improved. However, research on MT in low-resource languages such as Vietnamese and Korean is still very limited. In recent years, a state-of-the-art context-based embedding model introduced by Google, bidirectional encoder representations for transformers (BERT), has begun to appear in the neural MT (NMT) models in different ways to enhance the accuracy of MT systems. The BERT model for Vietnamese has been developed and significantly improved in natural language processing (NLP) tasks, such as part-of-speech (POS), named-entity recognition, dependency parsing, and natural language inference. Our research experimented with applying the Vietnamese BERT model to provide POS tagging and morphological analysis (MA) for Vietnamese sentences,, and applying word-sense disambiguation (WSD) for Korean sentences in our Vietnamese-Korean bilingual corpus. In the Vietnamese-Korean NMT system, with contextual embedding, the BERT model for Vietnamese is concurrently connected to both encoder layers and decoder layers in the NMT model. Experimental results assessed through BLEU, METEOR, and TER metrics show that contextual embedding significantly improves the quality of Vietnamese-Korean NMT.
EI 2076-3417
PD DEC
PY 2021
VL 11
IS 23
AR 11119
DI 10.3390/app112311119
UT WOS:000735198900001
ER

PT J
AU Vieira, LN
AF Vieira, Lucas Nunes
TI COGNITIVE EFFORT AND DIFFERENT TASK FOCI IN POST-EDITING OF MACHINE
   TRANSLATION: A THINK-ALOUD STUDY
SO ACROSS LANGUAGES AND CULTURES
AB Post-editing of machine translation is gaining popularity as a solution to the ever-increasing demands placed on human translators. There has been a great deal of research in this area aimed at determining the feasibility of post-editing and at predicting post-editing effort based on source-text features and machine translation errors. However, considerably less is known about the mental workings of post-editing and post-editors' decision-making or, in particular, the relationship between post-editing effort and different mental processes. This paper investigates these issues by analysing data from a think-aloud study through the lens of eye movements and subjective ratings obtained in a separate task. The results show that mental processes associated with grammar and lexis are significantly associated with cognitive effort in post-editing. This association was not observed for other aspects of the task concerning, for example, discourse or the real-world use of the text. In addition, it was noted that lexical issues are linked to long sequences of thought processes. The paper shows that lexis plays a central role in post-editing, and argues that more emphasis should be placed on this issue in future research and in post-editor training.
OI Vieira, Lucas Nunes/0000-0003-3038-4001
SN 1585-1923
EI 1588-2519
PD JUN
PY 2017
VL 18
IS 1
BP 79
EP 105
DI 10.1556/084.2017.18.1.4
UT WOS:000403205300004
ER

PT C
AU Furfaro, A
   Nigro, L
AF Furfaro, Angelo
   Nigro, Libero
BE LoBello, L
   Sauter, T
TI Model checking hierarchical communicating Real-Time State Machines
SO ETFA 2005: 10th IEEE International Conference on Emerging Technologies
   and Factory Automation, Vol 1, Pts 1 and 2, Proceedings
CT 10th IEEE International Conference on Emerging Technologies and Factory
   Automation
CY SEP 19-22, 2005
CL Catania, ITALY
SP Univ Studi Catania, IEEE Ind Elect Soc, Iconics, Schneider, ST Microelect, Medianet Comunicaz SrL
AB Hierarchical Communicating Real-Time State Machines (H-CRSM) is a formal modelling language for the modular development of distributed real-time systems. The formalism is characterized by the rise of state transitions with guarded commands and timing constraints, the adoption of a few distilled statecharts constructs, and the modular specification of timing constraints along a state hierarchy. This paper proposes a translation of H-CRSM into UPPAAL which enables model checking. Translation rests on unfolding a hierarchical model on a flat representation.
RI Furfaro, Angelo/N-2923-2019; Furfaro, Angelo/I-4050-2012
OI Furfaro, Angelo/0000-0003-2537-8918; Furfaro, Angelo/0000-0003-2537-8918
BN 0-7803-9402-X
PY 2005
BP 365
EP 370
UT WOS:000238575500052
ER

PT C
AU Kambhatla, N
   Born, L
   Sarkar, A
AF Kambhatla, Nishant
   Born, Logan
   Sarkar, Anoop
GP Assoc Computat Linguist
TI CipherDAug: Ciphertext based Data Augmentation for Neural Machine
   Translation
SO PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS)
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB We propose a novel data-augmentation technique for neural machine translation based on ROT-k ciphertexts. ROT-k is a simple letter substitution cipher that replaces a letter in the plaintext with the kth letter after it in the alphabet. We first generate multiple ROT-k ciphertexts using different values of k for the plaintext which is the source side of the parallel data. We then leverage this enciphered training data along with the original parallel data via multi-source training to improve neural machine translation. Our method, CipherDAug, uses a co-regularization-inspired training procedure, requires no external data sources other than the original training data, and uses a standard Transformer to outperform strong data augmentation techniques on several datasets by a significant margin. This technique combines easily with existing approaches to data augmentation, and yields particularly strong results in low-resource settings.(1)
BN 978-1-955917-21-6
PY 2022
BP 201
EP 218
UT WOS:000828702300017
ER

PT J
AU Funke, H
   Muhlig, J
   Teubner, J
AF Funke, Henning
   Muehlig, Jan
   Teubner, Jens
TI Low-latency query compilation
SO VLDB JOURNAL
AB Query compilation is a processing technique that achieves very high processing speeds but has the disadvantage of introducing additional compilation latencies. These latencies cause an overhead that is relatively high for short-running and high-complexity queries. In this work, we present Flounder IR and ReSQL, our new approach to query compilation. Instead of using a general purpose intermediate representation (e.g., LLVM IR) during compilation, ReSQL uses Flounder IR, which is specifically designed for database processing. Flounder IR is lightweight and close to machine assembly. This simplifies the translation from IR to machine code, which otherwise is a costly translation step. Despite simple translation, compiled queries still benefit from the high processing speeds of the query compilation technique. We analyze the performance of our approach with micro-benchmarks and with ReSQL, which employs a full translation stack from SQL to machine code. We show reductions in compilation times up to two orders of magnitude over LLVM and show improvements in overall execution time for TPC-H queries up to 5.5x over state-of-the-art systems.
OI Teubner, Jens/0000-0002-0344-5203
SN 1066-8888
EI 0949-877X
PD NOV
PY 2022
VL 31
IS 6
BP 1171
EP 1184
DI 10.1007/s00778-022-00741-5
EA MAY 2022
UT WOS:000793059400001
ER

PT C
AU de Gibert, O
   Goenaga, I
   Armengol-Estape J
   Perez-de-Vinaspre, O
   Parra, C
   Sanchez-Torron, M
   Pinnis, M
   Labaka, G
   Melero, M
AF de Gibert, Ona
   Goenaga, Iakes
   Armengol-Estape, Jordi
   Perez-de-Vinaspre, Olatz
   Parra, Carla
   Sanchez-Torron, Marina
   Pinnis, Marcis
   Labaka, Gorka
   Melero, Maite
BA Mariani, J
BF Mariani, J
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mazo, H
   Odijk, H
   Piperidis, S
TI Unsupervised Machine Translation in Real-World Scenarios
SO LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION
CT 13th International Conference on Language Resources and Evaluation
   (LREC)
CY JUN 20-25, 2022
CL Marseille, FRANCE
SP Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur
AB In this work, we present the work that has been carried on in the MT4All CEF project and the resources that it has generated by leveraging recent research carried out in the field of unsupervised learning. In the course of the project 18 monolingual corpora for specific domains and languages have been collected, and 12 bilingual dictionaries and translation models have been generated. As part of the research, the unsupervised MT methodology based only on monolingual corpora (Artetxe et al., 2017) has been tested on a variety of languages and domains. Results show that in specialised domains, when there is enough monolingual in-domain data, unsupervised results are comparable to those of general domain supervised translation, and that, at any rate, unsupervised techniques can be used to boost results whenever very little data is available.
BN 979-10-95546-72-6
PY 2022
BP 3038
EP 3047
UT WOS:000889371703014
ER

PT C
AU Pal, S
   Lohar, P
   Naskar, SK
AF Pal, Santanu
   Lohar, Pintu
   Naskar, Sudip Kumar
BE Gelbukh, A
TI Role of Paraphrases in PB-SMT
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING, CICLING 2014,
   PART II
SE Lecture Notes in Computer Science
CT 15th Annual Conference on Intelligent Text Processing and Computational
   Linguistics (CICLing)
CY APR 06-12, 2014
CL Ctr Commun & Dev, Kathmandu, NEPAL
SP Inst Politecnico Nacl Centro Invest Computac Nat Language &Text Proc Lab, Mexican Soc Artificial Intelligence
HO Ctr Commun & Dev
AB Statistical Machine Translation (SMT) delivers a convenient format for representing how translation process is modeled. The translations of words or phrases are generally computed based on their occurrence in some bilingual training corpus. However, SMT still suffers for out of vocabulary (OOV) words and less frequent words especially when only limited training data are available or training and test data are in different domains. In this paper, we propose a convenient way to handle OOV and rare words using paraphrasing technique. Initially we extract paraphrases from bilingual training corpus with the help of comparable corpora. The extracted paraphrases are analyzed by conditionally checking the association of their monolingual distribution. Bilingual aligned paraphrases are incorporated as additional training data into the PB-SMT system. Integration of paraphrases into PB-SMT system results in significant improvement.
RI Pal, Santanu/AAB-4161-2021
OI Pal, Santanu/0000-0003-3079-6903
SN 0302-9743
EI 1611-3349
BN 978-3-642-54902-1; 978-3-642-54903-8
PY 2014
VL 8404
BP 242
EP 253
UT WOS:000342990000021
ER

PT J
AU Jooken, L
   Rooryck, G
AF Jooken, Lieve
   Rooryck, Guy
TI The Freedom of Expressing One's Ideas Translating La Mettrie
SO TRANSLATOR
AB This paper discusses the English translation of one of the Enlightenment's main works of materialist philosophy, Julien Offray de La Mettrie's L'homme machine (1747). Radicalizing the mechanical metaphor that Descartes had applied to animals, La Mettrie's work states that the human body and the human soul are instances of the same substance. This early emancipatory expression in favour of a scientific study of the human being took issue with the contemporary theological doxa, revealing the changes and mutations that were taking place in the field of knowledge. The English translation, Man a Machine, appeared in 1749. Drawing on the Bourdieuan concepts of field and habitus and the opposition between ethos and doxa (Maingueneau 2002), this article contextualizes the subversive impact of the original text and offers an analysis of its paratexts, including the reception of the translation in the British periodical press. This is followed by an examination of the translator's textual interventions to reveal how the translation either makes the materialist claims of the original more explicit or polarizes its assumed communicative purpose vis-a-vis the doxa. While L'homme machine could only communicate its dissent in elusive terms, the translation highlights the polemical character of the text and communicates its radical ideas more forcefully to a nation that was considered the most liberal of its time.
SN 1355-6509
PD NOV
PY 2011
VL 17
IS 2
SI SI
BP 233
EP 254
DI 10.1080/13556509.2011.10799488
UT WOS:000296671200004
ER

PT J
AU Killman, J
AF Killman, Jeffrey
TI Context as Achilles' heel of translation technologies Major implications
   for end-users
SO TRANSLATION AND INTERPRETING STUDIES
AB The tools of translation memories and machine translation can be viewed as (not) being able to draw on different aspects of context that are relevant to a particular translation project, such as bilingual text, portions of a text, versions of a text, related text, or extralinguistic context. The aspects of context that the tools can indeed draw on and how well they do so highlight their most important benefits, whereas the aspects of context that the tools may fail to draw on reveal their weaknesses. In cases where, depending on the context, a piece of text being translated may have more than one meaning or a translation of a piece of text may be rendered in more than one way, the contexts the tools are able to draw on are critical. An analysis of different kinds of context in different applications highlights the circumstances in which users of TM and MT tools may risk accepting semantically and lexically undesirable output, as well as when TM tool users may risk inputting contextually inappropriate translations. Further, context is an important consideration when integrating MT output into TM tools. Although TM and MT technologies differ in how they produce translation output, end-users of both tool types may face similar contextual challenges.
SN 1932-2798
EI 1876-2700
PY 2015
VL 10
IS 2
BP 203
EP 222
DI 10.1075/tis.10.2.03kil
UT WOS:000372186100003
ER

PT C
AU Akyurek, E
   Andreas, J
AF Akyurek, Ekin
   Andreas, Jacob
GP Assoc Computat Linguist
TI Lexicon Learning for Few-Shot Neural Sequence Modeling
SO 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND
   THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (ACL-IJCNLP 2021), VOL 1
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB Sequence-to-sequence transduction is the core problem in language processing applications as diverse as semantic parsing, machine translation, and instruction following. The neural network models that provide the dominant solution to these problems are brittle, especially in low-resource settings: they fail to generalize correctly or systematically from small datasets. Past work has shown that many failures of systematic generalization arise from neural models' inability to disentangle lexical phenomena from syntactic ones. To address this, we augment neural decoders with a lexical translation mechanism that generalizes existing copy mechanisms to incorporate learned, decontextualized, token-level translation rules. We describe how to initialize this mechanism using a variety of lexicon learning algorithms, and show that it improves systematic generalization on a diverse set of sequence modeling tasks drawn from cognitive science, formal semantics, and machine translation.(1)
BN 978-1-954085-52-7
PY 2021
BP 4934
EP 4946
UT WOS:000698679200182
ER

PT C
AU Demidenko, S
   Ooi, M
   Akmeliawati, R
   Gupta, GS
   Kuang, YC
   Bailey, D
   Khan, S
   Gamage, N
   Bilal, S
AF Demidenko, S.
   Ooi, M.
   Akmeliawati, R.
   Gupta, G. Sen
   Kuang, Y. C.
   Bailey, D.
   Khan, S.
   Gamage, N.
   Bilal, S.
GP IEEE
TI Developing Automatic Markerless Sign Language Gesture Tracking and
   Recognition System
SO 2019 IEEE INTERNATIONAL SYMPOSIUM ON HAPTIC AUDIO-VISUAL ENVIRONMENTS &
   GAMES (HAVE 2019)
CT 17th IEEE International Symposium on Haptic Audio-Visual Environments
   and Games (HAVE)
CY OCT 03-04, 2019
CL Sunway Univ, Kuala Lumpur, MALAYSIA
SP IEEE, IEEE Instrumentat & Measurement Soc
HO Sunway Univ
AB Machine-based interpretations of sign language hand postures and gestures have long been a specialized research topic in human-computer interaction. Involvement of human subjects and multi-faceted nature of the problem requiring expertise in a multitude of disciplines make sign language interpretation an exigent research problem. Purpose of this paper is to present the experience and findings of international collaborative research conducted over several years on vision-based sign language translation. At first, this paper extends a discussion on sign language and its variations, machine-based translation and its significance. Secondly, a discussion on how three main tasks within the machine translation, namely: a) hand localization and tracking, b) hand posture interpretation, and c) hand gesture interpretation, can be addressed. Finally, research challenges, possible approaches, and future extensions are discussed.
RI Sen Gupta, Gourab/GXH-4852-2022; Bailey, Donald/ABE-2026-2020;
   Demidenko, Serge/AAL-6447-2021
OI Sen Gupta, Gourab/0000-0003-2758-0335; Bailey,
   Donald/0000-0002-1025-3680; Ooi, Melanie/0000-0002-1623-0105;
   Akmeliawati, Rini/0000-0003-0660-2312
BN 978-1-7281-2355-4
PY 2019
UT WOS:000534524900017
ER

PT C
AU Hellrich, J
   Hahn, U
AF Hellrich, Johannes
   Hahn, Udo
BE Kral, P
   Matousek, V
TI Adding Multilingual Terminological Resources to Parallel Corpora for
   Statistical Machine Translation Deteriorates System Performance: A
   Negative Result from Experiments in the Biomedical Domain
SO TEXT, SPEECH, AND DIALOGUE (TSD 2015)
SE Lecture Notes in Artificial Intelligence
CT 18th International Conference on Text, Speech and Dialogue (TSD)
CY SEP 14-17, 2015
CL Pilsen, CZECH REPUBLIC
SP Int Speech Commun Assoc, Czech Soc Cybernet & Informat, Kerio Technol, Univ West Bohemia, Fac Appl Sci, Masaryk Univ, Fac Informat
AB Unlike many other domains, biomedicine not only provides a wide range of parallel text corpora to train statistical machine translation (SMT) systems on, but also offers substantial amounts of 'parallel lexicons' in the form of multilingual terminologies. We included these lexical repositories, together with common parallel text corpora, into a Moses-based SMT system and three commercial systems and performed experiments on four language pairs, three text genres and several corpus sizes to measure the effects of adding the lexical knowledge sources. Much to our surprise, the SMT systems additionally equipped with 'parallel lexicons' underperformed in comparison with those systems trained on parallel text corpora only. This effect could consistently be shown for all systems by Bleu scores, as well as assessments from human judges.
SN 0302-9743
EI 1611-3349
BN 978-3-319-24033-6; 978-3-319-24032-9
PY 2015
VL 9302
BP 506
EP 514
DI 10.1007/978-3-319-24033-6_57
UT WOS:000365947800057
ER

PT J
AU Orodu, KB
   Ekechukwu, GK
   Orodu, OD
AF Orodu, Kale Barbara
   Ekechukwu, Gerald Kelechi
   Orodu, Oyinkepreye David
TI Conventional and machine learning improved prediction of hydrocarbon
   density using volume-translation at high-pressure high-temperature
   conditions
SO ENERGY SOURCES PART A-RECOVERY UTILIZATION AND ENVIRONMENTAL EFFECTS
AB Non-cubic equations of state (nCEOS) are increasingly showing improved performance at predicting volumetric properties of hydrocarbons, nitrogen, and carbon dioxide at high-pressure high-temperature over volume-translation-based cubic equations of state (VT-CEOS). However, since nCEOS are rather complex, a less mathematically complex and more accurate CEOS is desired. Hence, in this study, we have explored different techniques, including conventional (non-linear regression) and machine learning-based approaches (random forest) to predict a more accurate molar volume deviation term of the VT-CEOS. We used an extensive high-pressure and high-temperature PVT dataset ranging from 50 to 150 MPa and 300 - 500 K respectively in this study. The VT was modeled as a function of reduced temperature only as well as reduced temperature and molecular weight/critical pressure of the pure hydrocarbon components.
   Statistical analyses and graphs displayed high performance of the developed predictive models over existing VT-CEOS models applied to HPHT and PC-SAFT. More specifically, the machine learning model gave 99% accuracy while the accuracy of the conventional approach ranged from 60-98%. To the best of the knowledge of the authors, the application of machine learning to estimating volume-translation based on CEOS for pure hydrocarbon components of natural gas and heavy hydrocarbons is nonexistent. This paper presents the first application of physics-based machine learning and the use of features that honors thermodynamic principles for prediction of hydrocarbon density.
RI Ekechukwu, Gerald/AFW-7959-2022; Orodu, Oyinkepreye/AAF-5624-2020;
   Orodu, Oyinkepreye/M-8107-2013
OI Orodu, Oyinkepreye/0000-0002-7269-924X; Orodu, Kale/0000-0003-3249-305X
SN 1556-7036
EI 1556-7230
DI 10.1080/15567036.2021.1915433
EA APR 2021
UT WOS:000640581100001
ER

PT J
AU Elmakias, I
   Vilenchik, D
AF Elmakias, Itamar
   Vilenchik, Dan
TI An Oblivious Approach to Machine Translation Quality Estimation
SO MATHEMATICS
AB Machine translation (MT) is being used by millions of people daily, and therefore evaluating the quality of such systems is an important task. While human expert evaluation of MT output remains the most accurate method, it is not scalable by any means. Automatic procedures that perform the task of Machine Translation Quality Estimation (MT-QE) are typically trained on a large corpus of source-target sentence pairs, which are labeled with human judgment scores. Furthermore, the test set is typically drawn from the same distribution as the train. However, recently, interest in low-resource and unsupervised MT-QE has gained momentum. In this paper, we define and study a further restriction of the unsupervised MT-QE setting that we call oblivious MT-QE. Besides having no access no human judgment scores, the algorithm has no access to the test text's distribution. We propose an oblivious MT-QE system based on a new notion of sentence cohesiveness that we introduce. We tested our system on standard competition datasets for various language pairs. In all cases, the performance of our system was comparable to the performance of the non-oblivious baseline system provided by the competition organizers. Our results suggest that reasonable MT-QE can be carried out even in the restrictive oblivious setting.
OI Vilenchik, Dan/0000-0002-3895-688X; Elmakias, Itamar/0000-0002-9169-9835
EI 2227-7390
PD SEP
PY 2021
VL 9
IS 17
AR 2090
DI 10.3390/math9172090
UT WOS:000695585000001
ER

PT C
AU Borroto, M
   Ricca, F
   Cuteri, B
AF Borroto, Manuel
   Ricca, Francesco
   Cuteri, Bernardo
BE Bandini, S
   Gasparini, F
   Mascardi, V
   Palmonari, M
   Vizzari, G
TI A Neural-Machine-Translation System Resilient to Out of Vocabulary Words
   for Translating Natural Language to SPARQL
SO AIXIA 2021 - ADVANCES IN ARTIFICIAL INTELLIGENCE
SE Lecture Notes in Artificial Intelligence
CT 20th International Conference of the
   Italian-Association-for-Artificial-Intelligence (AIxIA)
CY DEC 01-03, 2021
CL ELECTR NETWORK
SP Italian Assoc Artificial Intelligence, Artificial Intelligence Journal Funding Opportunities Promoting AI Res Program, European Commiss, DG Commun Networks, Content & Technol, Univ Milano Bicocca, Dept Informat, Syst & Commun
AB The development and diffusion of ontologies allowed the creation of large banks of information regarding multiple domains known as knowledge bases. Ontologies propose a way to represent information providing semantic meaning that allows the data to be machineinterpretable. However, enjoying such rich knowledge is a difficult task for the majority of potential users who do not know either the knowledgebase definition or how to write queries with SPARQL. Systems able to translate natural language questions into SPARQL queries have the potential to overcome this problem. In this paper, we propose an approach that combines the Named Entity Recognition and Neural Machine Translation tasks to perform an automatic translation of natural language questions into executables SPARQL queries. The resulting approach provides robustness to the presence of terms that do not occur in the training set. We evaluate the potential of our approach by using Monument and QALD-9, which are well-known datasets for Question Answering over the DBpedia ontology.
SN 0302-9743
EI 1611-3349
BN 978-3-031-08421-8; 978-3-031-08420-1
PY 2022
VL 13196
BP 171
EP 184
DI 10.1007/978-3-031-08421-8_12
UT WOS:000876859300012
ER

PT C
AU Sanchis-Trilles, G
   Casacuberta, F
AF Sanchis-Trilles, German
   Casacuberta, Francisco
BE Hancock, ER
   Wilson, RC
   Windeatt, T
   Ulusoy, I
   Escolano, F
TI Bayesian Adaptation for Statistical Machine Translation
SO STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION
SE Lecture Notes in Computer Science
CT Joint IAPR International Workshop on SSPR & SPR
CY AUG 18-20, 2010
CL Izmir, TURKEY
SP IAPR, Pattern Anal Stat Modelling & Comp Learning
AB In many pattern recognition problems, learning from training samples is a process that requires important amounts of training data and a high computational effort. Sometimes, only limited training data and/or limited computational resources are available, but there is also available a previous system trained for a closely related task and with enough training material. This scenario is very frequent in statistical machine translation and adaptation can be a solution to deal with this problem. In this paper, we present an adaptation technique for (state-of-the-art) log-linear modelling based on the well-known Bayesian learning paradigm. This technique has been applied to statistical machine translation and can be easily extended to other pattern recognition areas in which log-linear models are used. We show empirical results in which a small amount of adaptation data is able to improve both the non-adapted system and a system that optimises the above-mentioned weights only on the adaptation set.
SN 0302-9743
EI 1611-3349
BN 978-3-642-14979-5
PY 2010
VL 6218
BP 620
EP 629
UT WOS:000286412900061
ER

PT C
AU Kchaou, S
   Boujelbane, R
   Belguith, LH
AF Kchaou, Sameh
   Boujelbane, Rahma
   Belguith, Lamia Hadrich
GP IEEE
TI Bottom-up approach to translate Tunisian dialect texts in Social
   Networks
SO 2022 IEEE/ACS 19TH INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND
   APPLICATIONS (AICCSA)
SE International Conference on Computer Systems and Applications
CT 19th IEEE/ACS International Conference on Computer Systems and
   Applications (AICCSA)
CY DEC 05-07, 2022
CL Zayed Univ, Abu Dhabi, U ARAB EMIRATES
SP IEEE, ACS
HO Zayed Univ
AB Dialect translation is a motivating task for both industrial and academic fields. Indeed, migrating to a standard language facilitates communication between people throughout the world, and facilitates application of Natural Language Processing tasks such as automatic opinion analysis, semantic analysis, etc. We describe, in this work, an effort to build a Neural Machine Translation (NMT) model in order to translate the comments posted on social media intended for the Tunisian community. It is a question of dealing with the Tunisian dialect (TD) in Social Networks (SN). Due to the orthographic ambiguity presented by the TD, we experiment different configurations corpora and NMT models following a bottom-up approach. The best configuration resulted in building a translation model which achieved a BLEU score of 69.22% on a test corpus.
SN 2161-5322
BN 979-8-3503-1008-5
PY 2022
DI 10.1109/AICCSA56895.2022.10017688
UT WOS:000932894200031
ER

PT C
AU Zheng, H
   Cheng, Y
   Liu, Y
AF Zheng, Hao
   Cheng, Yong
   Liu, Yang
BE Sierra, C
TI Maximum Expected Likelihood Estimation for Zero-Resource Neural Machine
   Translation
SO PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON
   ARTIFICIAL INTELLIGENCE
CT 26th International Joint Conference on Artificial Intelligence (IJCAI)
CY AUG 19-25, 2017
CL Melbourne, AUSTRALIA
SP Int Joint Conf Artifical Intelligence, Victoria Govt, Melbourne Convent Bur, Artificial Intelligence Journal, Alibaba Grp, Xiaoi, Tencent, JD.com, Meitu Inc, Didi ChuXing, Baidu, Ant Financial Serv Grp, Australian Comp Soc, Natl Sci Fdn, Univ Technol Sydney, Griffith Univ, Univ Sydney, Royal Melbourne Inst Technol Univ, Melbourne Univ, Australian Natl Univ, King Abdullah Univ Sci & Technol, Data61, Adobe, IBM, NNAISENCE, AUBOT, So Univ Sci & Technol, Monash Univ, Auckland Univ Technol, Univ New S Wales, Assumption University of Thailand, Future Univ Hakodate, Deakin Univ, Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, Nanyang Technological University, Federation Univ, Univ Queensland, Facebook, Microsoft, BigML, Essence, Nuance, NVIDIA, XENON
AB While neural machine translation (NMT) has made remarkable progress in translating a handful of resource-rich language pairs recently, parallel corpora are not always readily available for most language pairs. To deal with this problem, we propose an approach to zero-resource NMT via maximum expected likelihood estimation. The basic idea is to maximize the expectation with respect to a pivot-to-source translation model for the intended source-to-target model on a pivot-target parallel corpus. To approximate the expectation, we propose two methods to connect the pivot-to-source and source-to-target models. Experiments on two zero-resource language pairs show that the proposed approach yields substantial gains over baseline methods. We also observe that when trained jointly with the source-to-target model, the pivot-to-source translation model also obtains improvements over independent training.
BN 978-0-9992411-0-3
PY 2017
BP 4251
EP 4257
UT WOS:000764137504053
ER

PT J
AU Liu, SY
   Sun, YQ
   Wang, LY
AF Liu, Siyou
   Sun, Yuqi
   Wang, Longyue
TI Recent Advances in Dialogue Machine Translation
SO INFORMATION
AB Recent years have seen a surge of interest in dialogue translation, which is a significant application task for machine translation (MT) technology. However, this has so far not been extensively explored due to its inherent characteristics including data limitation, discourse properties and personality traits. In this article, we give the first comprehensive review of dialogue MT, including well-defined problems (e.g., 4 perspectives), collected resources (e.g., 5 language pairs and 4 sub-domains), representative approaches (e.g., architecture, discourse phenomena and personality) and useful applications (e.g., hotel-booking chat system). After systematical investigation, we also build a state-of-the-art dialogue NMT system by leveraging a breadth of established approaches such as novel architectures, popular pre-training and advanced techniques. Encouragingly, we push the state-of-the-art performance up to 62.7 BLEU points on a commonly-used benchmark by using mBART pre-training. We hope that this survey paper could significantly promote the research in dialogue MT.
OI SUN, Yuqi/0000-0002-7310-1385; Liu, Siyou/0000-0003-4524-4976; Wang,
   Longyue/0000-0002-9062-6183
EI 2078-2489
PD NOV
PY 2021
VL 12
IS 11
AR 484
DI 10.3390/info12110484
UT WOS:000723757800001
ER

PT J
AU Yang, YX
   Wang, XL
AF Yang, Yanxia
   Wang, Xiangling
TI Predicting student translators' performance in machine translation
   post-editing: interplay of self-regulation, critical thinking, and
   motivation
SO INTERACTIVE LEARNING ENVIRONMENTS
AB Machine translation post-editing (MTPE) has become a common practice in translation industry, which calls much attention in academia. However, little research has been carried out to investigate students' cognitive and motivational individual differences in MTPE. The purpose of the present study was to examine the predictive effects of self-regulation, critical thinking, and motivation on students' MTPE performance. Self-reported data was collected from 109 student translators before and after the post-editing test. Partial least squares structural equation modeling (PLS-SEM) was employed to calculate the data. The findings indicated that self-regulation exerted a direct and positive effect on MTPE performance (beta = .48,p < .001) and was further statistically affected by critical thinking (beta = .46,p < .001) and motivation (beta = .43,p < .001). However, no significant effects were found either from motivation or critical thinking on MTPE performance. To train students with heightened levels of self-regulation is crucial in MTPE teaching and learning.
RI Yang, Yanxia/HSF-5154-2023
OI Wang, Xiangling/0000-0001-8889-7569
SN 1049-4820
EI 1744-5191
PD JAN 2
PY 2023
VL 31
IS 1
BP 340
EP 354
DI 10.1080/10494820.2020.1786407
EA JUL 2020
UT WOS:000547144000001
ER

PT J
AU Jadoon, NK
   Anwar, W
   Bajwa, UI
   Ahmad, F
AF Jadoon, Nadeem Khan
   Anwar, Waqas
   Bajwa, Usama Ijaz
   Ahmad, Farooq
TI Statistical machine translation of Indian languages: a survey
SO NEURAL COMPUTING & APPLICATIONS
AB In this study, performance analysis of a state-of-art phrase-based statistical machine translation (SMT) system is presented on eight Indian languages. State of the art in SMT on different Indian languages to English language has also been discussed briefly. The motivation of this study was to promote the development of SMT and linguistic resources for these Indian language pairs, as the current systems are in infancy stage due to sparse data resources. EMILLE and crowdsourcing parallel corpora have been used in this study for experimental purposes. The study is concluded by presenting the performance of baseline SMT system for Indian languages (Bengali, Gujarati, Hindi, Malayalam, Punjabi, Tamil, Telugu and Urdu) into English with average 10-20% accurate results for all the language pairs. As a result of this study, both of these annotated parallel corpora resources and SMT system will serve as benchmarks for future approaches to SMT in Hindi -> English, Urdu -> English, Punjabi -> English, Telugu -> English, Tamil -> English, Gujarati -> English, Bengali -> English and Malayalam -> English.
OI Bajwa, Usama/0000-0001-5755-1194
SN 0941-0643
EI 1433-3058
PD JUL
PY 2019
VL 31
IS 7
BP 2455
EP 2467
DI 10.1007/s00521-017-3206-2
UT WOS:000478687000035
ER

PT C
AU Joanis, E
   Knowles, R
   Kuhn, R
   Larkin, S
   Littell, P
   Lo, CK
   Stewart, D
   Micher, J
AF Joanis, Eric
   Knowles, Rebecca
   Kuhn, Roland
   Larkin, Samuel
   Littell, Patrick
   Lo, Chi-kiu
   Stewart, Darlene
   Micher, Jeffrey
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mariani, J
   Mazo, H
   Moreno, A
   Odijk, J
   Piperidis, S
TI The Nunavut Hansard Inuktitut-English Parallel Corpus 3.0 with
   Preliminary Machine Translation Results
SO PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES
   AND EVALUATION (LREC 2020)
CT 12th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 11-16, 2020
CL Marseille, FRANCE
AB The Inuktitut language, a member of the Inuit-Yupik-Unangan language family, is spoken across Arctic Canada and noted for its morphological complexity. It is an official language of two territories, Nunavut and the Northwest Territories, and has recognition in additional regions. This paper describes a newly released sentence-aligned Inuktitut-English corpus based on the proceedings of the Legislative Assembly of Nunavut, covering sessions from April 1999 to June 2017. With approximately 1.3 million aligned sentence pairs, this is, to our knowledge, the largest parallel corpus of a polysynthetic language or an Indigenous language of the Americas released to date. The paper describes the alignment methodology used, the evaluation of the alignments, and preliminary experiments on statistical and neural machine translation (SMT and NMT) between Inuktitut and English, in both directions.
BN 979-10-95546-34-4
PY 2020
BP 2562
EP 2572
UT WOS:000724697203065
ER

PT C
AU Hadiwinoto, C
   Ng, HT
AF Hadiwinoto, Christian
   Ng, Hwee Tou
GP AAAI
TI A Dependency-Based Neural Reordering Model for Statistical Machine
   Translation
SO THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 31st AAAI Conference on Artificial Intelligence
CY FEB 04-09, 2017
CL San Francisco, CA
SP Assoc Advancement Artificial Intelligence
AB In machine translation (MT) that involves translating between two languages with significant differences in word order, determining the correct word order of translated words is a major challenge. The dependency parse tree of a source sentence can help to determine the correct word order of the translated words. In this paper, we present a novel reordering approach utilizing a neural network and dependency-based embeddings to predict whether the translations of two source words linked by a dependency relation should remain in the same order or should be swapped in the translated sentence. Experiments on Chinese-to-English translation show that our approach yields a statistically significant improvement of 0.57 BLEU point on benchmark NIST test sets, compared to our prior state-of-the-art statistical MT system that uses sparse dependency-based reordering features.
SN 2159-5399
EI 2374-3468
PY 2017
BP 109
EP 115
UT WOS:000485630700016
ER

PT J
AU Castilho, S
   Resende, N
AF Castilho, Sheila
   Resende, Natalia
TI Post-Editese in Literary Translations
SO INFORMATION
AB In the present study, we investigated the post-editese phenomenon, i.e., the unique features that set machine translated post-edited texts apart from human-translated texts. We used two literary texts, namely, the English children's novel by Lewis Carroll Alice's Adventures in Wonderland (AW) and Paula Hawkins' popular book The Girl on the Train (TGOTT). Both literary texts were Google translated from English into Brazilian Portuguese to investigate whether the post-editese features can be found on the surface of the post-edited (PE) texts. In addition, we examined how the features found in the PE texts differ from the features encountered in the human-translated (HT) and machine translation (MT) versions of the same source text. Results revealed evidence for post-editese for TGOTT only with PE versions being more similar to the MT output than to the HT texts.
OI Resende, Natalia/0000-0002-5248-2457; Castilho,
   Sheila/0000-0002-8416-6555
EI 2078-2489
PD FEB
PY 2022
VL 13
IS 2
AR 66
DI 10.3390/info13020066
UT WOS:000770678000001
ER

PT C
AU Wang, YJ
   Wei, TX
   Liu, Q
   Chen, EH
AF Wang, Yijun
   Wei, Tianxin
   Liu, Qi
   Chen, Enhong
BE Jensen, CS
   Lim, EP
   Yang, DN
   Lee, WC
   Tseng, VS
   Kalogeraki, V
   Huang, JW
   Shen, CY
TI Unpaired Multimodal Neural Machine Translation via Reinforcement
   Learning
SO DATABASE SYSTEMS FOR ADVANCED APPLICATIONS (DASFAA 2021), PT II
SE Lecture Notes in Computer Science
CT 26th International Conference on Database Systems for Advanced
   Applications (DASFAA)
CY APR 11-14, 2021
CL ELECTR NETWORK
AB End-to-end neural machine translation (NMT) heavily relies on parallel corpora for training. However, high-quality parallel corpora are usually costly to collect. To tackle this problem, multimodal content, especially image, has been introduced to help build an NMT system without parallel corpora. In this paper, we propose a reinforcement learning (RL) method to build an NMT system by introducing a sequence-level supervision signal as a reward. Based on the fact that visual information can be a universal representation to ground different languages, we design two different rewards to guide the learning process, i.e., (1) the likelihood of generated sentence given source image and (2) the distance of attention weights given by image caption models. Experimental results on the Multi30K, IAPR-TC12, and IKEA datasets show that the proposed learning mechanism achieves better performance than existing methods.
OI Wei, Tianxin/0000-0003-4450-2005; wang, yijun/0000-0002-3372-8167; Chen,
   Enhong/0000-0002-4835-4102
SN 0302-9743
EI 1611-3349
BN 978-3-030-73196-0; 978-3-030-73197-7
PY 2021
VL 12682
BP 168
EP 185
DI 10.1007/978-3-030-73197-7_11
UT WOS:000886648000011
ER

PT C
AU Barzegar, S
   Davis, B
   Handschuh, S
   Freitas, A
AF Barzegar, Siamak
   Davis, Brian
   Handschuh, Siegfried
   Freitas, Andre
GP IEEE
TI Multilingual Semantic Relatedness using lightweight machine translation
SO 2018 IEEE 12TH INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC)
SE IEEE International Conference on Semantic Computing
CT 12th IEEE International Conference on Semantic Computing (ICSC)
CY JAN 31-FEB 02, 2018
CL Laguna Hills, CA
SP IEEE, IEEE Comp Soc
AB Distributional semantic models are strongly dependent on the size and the quality of the reference corpora, which embeds the commonsense knowledge necessary to build comprehensive models. While high-quality texts containing large-scale commonsense information are present in English, such as Wikipedia, other languages may lack sufficient textual support to build distributional models. This paper proposes using the combination of a lightweight (sloppy) machine translation model and an English Distributional Semantic Model (DSM) to provide higher quality word vectors for languages other than English. Results show that the lightweight MT model introduces significant improvements when compared to language-specific distributional models. Additionally, the lightweight MT outperforms more complex MT methods for the task of word-pair translation.
RI Freitas, Andre/AAT-9885-2020
OI Freitas, Andre/0000-0002-4430-4837; Davis, Brian/0000-0002-5759-2655;
   Barzegar, Siamak/0000-0003-0734-3914
SN 2325-6516
BN 978-1-5386-4407-2
PY 2018
BP 108
EP 114
DI 10.1109/ICSC.2018.00024
UT WOS:000450112200015
ER

PT J
AU Xu, L
   Gao, W
AF Xu, L
   Gao, W
TI Study on translating Chinese into Chinese sign language
SO JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY
AB Sign language is a visual-gestural language mainly used by hearing-impaired people to communicate with each other. Gesture and facial expression are important grammar parts of sign language. In this paper, a text-based transformation method of Chinese-Chinese sign language machine translation is proposed. Gesture and facial expression models are created. And a practical system is implemented. The input of the system is Chinese text. The output of the system is "graphics person" who can gesticulate Chinese sign language accompanied by facial expression that corresponds to the Chinese text entered so as to realize automatic translation from Chinese text to Chinese sign language.
SN 1000-9000
PD SEP
PY 2000
VL 15
IS 5
BP 485
EP 490
DI 10.1007/BF02950413
UT WOS:000090051400012
ER

PT J
AU Verma, K
   Popovi, M
   Poulis, A
   Cherkasova, Y
   HObain, CO
   Mazzone, A
   Milosevic, T
   Davis, B
AF Verma, Kanishk
   Popovi, Maja
   Poulis, Alexandros
   Cherkasova, Yelena
   HObain, Cathal O.
   Mazzone, Angela
   Milosevic, Tijana
   Davis, Brian
TI Leveraging machine translation for cross-lingual fine-grained
   cyberbullying classification amongst pre-adolescents
SO NATURAL LANGUAGE ENGINEERING
AB Cyberbullying is the wilful and repeated infliction of harm on an individual using the Internet and digital technologies. Similar to face-to-face bullying, cyberbullying can be captured formally using the Routine Activities Model (RAM) whereby the potential victim and bully are brought into proximity of one another via the interaction on online social networking (OSN) platforms. Although the impact of the COVID-19 (SARS-CoV-2) restrictions on the online presence of minors has yet to be fully grasped, studies have reported that 44% of pre-adolescents have encountered more cyberbullying incidents during the COVID-19 lockdown. Transparency reports shared by OSN companies indicate an increased take-downs of cyberbullying-related comments, posts or content by artificially intelligen moderation tools. However, in order to efficiently and effectively detect or identify whether a social media post or comment qualifies as cyberbullying, there are a number factors based on the RAM, which must be taken into account, which includes the identification of cyberbullying roles and forms. This demands the acquisition of large amounts of fine-grained annotated data which is costly and ethically challenging to produce. In addition where fine-grained datasets do exist they may be unavailable in the target language. Manual translation is costly and expensive, however, state-of-the-art neural machine translation offers a workaround. This study presents a first of its kind experiment in leveraging machine translation to automatically translate a unique pre-adolescent cyberbullying gold standard dataset in Italian with fine-grained annotations into English for training and testing a native binary classifier for pre-adolescent cyberbullying. In addition to contributing high-quality English reference translation of the source gold standard, our experiments indicate that the performance of our target binary classifier when trained on machine-translated English output is on par with the source (Italian) classifier.
RI Milosevic, Tijana/AEM-4225-2022
OI Milosevic, Tijana/0000-0003-1502-7479; Verma,
   Kanishk/0000-0001-7172-4098
SN 1351-3249
EI 1469-8110
AR PII S1351324922000341
DI 10.1017/S1351324922000341
EA SEP 2022
UT WOS:000850712400001
ER

PT C
AU Alam, M
   Hussain, SU
AF Alam, Mehreen
   Hussain, Sibt Ul
GP IEEE
TI Sequence to Sequence Networks for Roman-Urdu to Urdu Transliteration
SO 2017 INTERNATIONAL MULTI-TOPIC CONFERENCE (INMIC)
CT 20th International Multi-Topic Conference (INMIC)
CY NOV 24-26, 2017
CL FAST UNIV, Lahore, PAKISTAN
SP IEEE, Higher Educ Commiss, FAST Natl Univ Comp & Emerging Sci, FAST Univ Lahore, Fac Comp Sci & Elect Engn
HO FAST UNIV
AB Neural Machine Translation models have replaced the conventional phrase based statistical translation methods since the former takes a generic, scalable, data-driven approach rather than relying on manual, hand-crafted features. The neural machine translation system is based on one neural network that is composed of two parts, one that is responsible for input language sentence and other part that handles the desired output language sentence. This model based on encoder-decoder architecture also takes as input the distributed representations of the source language which enriches the learnt dependencies and gives a warm start to the network. In this work, we transform Roman-Urdu to Urdu transliteration into sequence to sequence learning problem. To this end, we make the following contributions. We create the first ever parallel corpora of Roman-Urdu to Urdu, create the first ever distributed representation of Roman-Urdu and present the first neural machine translation model that transliterates text from Roman-Urdu to Urdu language. Our model has achieved the state-of-the-art results using BLEU as the evaluation metric. Precisely, our model is able to correctly predict sentences up to length 10 while achieving BLEU score of 48.6 on the test set. We are hopeful that our model and our results shall serve as the baseline for further work in the domain of neural machine translation for Roman-Urdu to Urdu using distributed representation.
OI Alam, Mehreen/0000-0001-7663-2598
BN 978-1-5386-2303-9
PY 2017
UT WOS:000428273300001
ER

PT J
AU Macherey, K
   Bender, O
   Ney, H
AF Macherey, Klaus
   Bender, Oliver
   Ney, Hermann
TI Applications of Statistical Machine Translation Approaches to Spoken
   Language Understanding
SO IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB In this paper, we investigate two statistical methods for spoken language understanding based on statistical machine translation. The first approach employs the source-channel paradigm, whereas the other uses the maximum entropy framework. Starting with an annotated corpus, we describe the problem of natural language understanding as a translation from a source sentence to a formal language target sentence. We analyze the quality of different alignment models and feature functions and show that the direct maximum entropy approach outperforms the source channel-based method. Furthermore, we investigate how both methods perform if the input sentences contain speech recognition errors. Finally, we investigate a new approach to combine speech recognition and spoken language understanding. For this purpose, we employ minimum error rate training which directly optimizes the final evaluation criterion. By combining all knowledge sources in a log-linear way, we show that we can decrease both the word error rate and the slot error rate. Experiments were carried out on two German inhouse corpora for spoken dialogue systems.
SN 1558-7916
EI 1558-7924
PD MAY
PY 2009
VL 17
IS 4
BP 803
EP 818
DI 10.1109/TASL.2009.2014262
UT WOS:000274224300007
ER

PT C
AU Wang, X
   Tu, ZP
   Wang, LY
   Shi, SM
AF Wang, Xing
   Tu, Zhaopeng
   Wang, Longyue
   Shi, Shuming
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Exploiting Sentential Context for Neural Machine Translation
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB In this work, we present novel approaches to exploit sentential context for neural machine translation (NMT). Specifically, we first show that a shallow sentential context extracted from the top encoder layer only, can improve translation performance via contextualizing the encoding representations of individual words. Next, we introduce a deep sentential context, which aggregates the sentential context representations from all the internal layers of the encoder to form a more comprehensive context representation. Experimental results on the WMT14 English double right arrow German and English double right arrow French benchmarks show that our model consistently improves performance over the strong TRANSFORMER model (Vaswani et al., 2017), demonstrating the necessity and effectiveness of exploiting sentential context for NMT.
RI Tu, Zhaopeng/AAS-4259-2021
BN 978-1-950737-48-2
PY 2019
BP 6197
EP 6203
UT WOS:000493046109023
ER

PT C
AU Roy, M
   Popowich, F
AF Roy, Maxim
   Popowich, Fred
BE Farzindar, A
   Keselj, V
TI Word Reordering Approaches for Bangla-English Statistical Machine
   Translation
SO ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
CT 23rd Canadian Conference on Artificial Intelligence
CY MAY 31-JUN 02, 2010
CL Ottawa, CANADA
SP Canadian Artificial Intelligence Assoc, Univ Ottawa, NLP Technologies, MultiCorpora R&D, Palomino Syst Innovat, Language Ind Assoc
AB We apply several word reordering techniques to a Bangla-English Statistical Machine Translation (SMT) system. We evaluate the approaches through their impact on the BLEU score for the phrase-based Bangla-English SMT system. According to the experimental results, automatic reordering rules have the most significant impact on the BLEU score. We also provide a new test set with multiple references between Bangla and English for SMT evaluation purposes and evaluate the reordering approaches on the extended test set.
SN 0302-9743
EI 1611-3349
BN 978-3-642-13058-8
PY 2010
VL 6085
BP 282
EP 285
UT WOS:000281548500026
ER

PT J
AU Tezcan, A
   Hoste, V
   Macken, L
AF Tezcan, Arda
   Hoste, Veronique
   Macken, Lieve
TI Estimating post-editing time using a gold-standard set of machine
   translation errors
SO COMPUTER SPEECH AND LANGUAGE
AB With the improved quality of Machine Translation (MT) systems in the last decades, post-editing (the correction of MT errors) has gained importance in Computer-Assisted Translation (CAT) workflows. Depending on the number and the severity of the errors in the MT output, the effort required to post-edit varies from sentence to sentence. The existing Quality Estimation (QE) systems provide quality scores that reflect the quality of an MT output at sentence level or word level. However, they fail to explain the relationship between different types of MT errors and the required post-editing effort to correct them. We suggest a more informative approach to QE in which different types of MT errors are detected in a first step, which are then used to estimate post-editing effort in a second step. In this paper we define the upper boundary of such a system. We use different machine learning methods to estimate Post-Editing Time (PET) by using a gold-standard set of MT errors as features. We show that post-editing time can be estimated with high accuracy when all the translation errors in the MT output are known. Furthermore, we apply feature selection methods and investigate the predictive power of different MT error types on PET. Our results show that the same prediction performance can be achieved by only using a small subset of MT error types, indicating that successful two-step QE systems can be built with less effort in the future, by detecting only the error types with highest predictive power. (C) 2018 Published by Elsevier Ltd.
OI Macken, Lieve/0000-0001-7516-7487
SN 0885-2308
EI 1095-8363
PD MAY
PY 2019
VL 55
BP 120
EP 144
DI 10.1016/j.csl.2018.10.005
UT WOS:000456592100007
ER

PT J
AU Windsor, LC
   Cupit, JG
   Windsor, AJ
AF Windsor, Leah Cathryn
   Cupit, James Grayson
   Windsor, Alistair James
TI Automated content analysis across six languages
SO PLOS ONE
AB Corpus selection bias in international relations research presents an epistemological problem: How do we know what we know? Most social science research in the field of text analytics relies on English language corpora, biasing our ability to understand international phenomena. To address the issue of corpus selection bias, we introduce results that suggest that machine translation may be used to address non-English sources. We use human translation and machine translation (Google Translate) on a collection of aligned sentences from United Nations documents extracted from the Multi-UN corpus, analyzed with a "bag of words" analysis tool, Linguistic Inquiry Word Count (LIWC). Overall, the LIWC indices proved relatively stable across machine and human translated sentences. We find that while there are statistically significant differences between the original and translated documents, the effect sizes are relatively small, especially when looking at psychological processes.
RI Windsor, Leah/AAC-3255-2019
OI Windsor, Leah/0000-0002-4311-1320
SN 1932-6203
PD NOV 20
PY 2019
VL 14
IS 11
AR e0224425
DI 10.1371/journal.pone.0224425
UT WOS:000533881900010
PM 31747404
ER

PT C
AU Datta, G
   Joshi, N
   Gupta, K
AF Datta, Goutam
   Joshi, Nisheeth
   Gupta, Kusum
BE Prasanna, SRM
   Karpov, A
   Samudravijaya, K
   Agrawal, SS
TI Analysis of Automatic Evaluation Metric on Low-Resourced Language:
   BERTScore vs BLEU Score
SO SPEECH AND COMPUTER, SPECOM 2022
SE Lecture Notes in Artificial Intelligence
CT 24th International Conference on Speech and Computer (SPECOM)
CY NOV 14-16, 2022
CL Gurugram, INDIA
SP KIIT Coll Engn
AB The accurate evaluation of machine translation (MT) is a difficult task. Human evaluation (judgment) is considered to be the best, but it is time-consuming. Hence, the importance of developing an automatic evaluation metric got researchers' attention. In this paper, we have done an in-depth analysis of the performance of the MT engine on low-resourced Bengali to English translations. We analyzed the scores generated by automatic metrics such as BLEU and BERTscore. We have computed the scores of the translation engine manually also based on the parameters used in the human evaluation. Finally, we have measured the correlation of BLEU and BERTScore with human judgment and found that BERTScore has a higher correlation with human judgment for our English to Bangla language pair.
SN 0302-9743
EI 1611-3349
BN 978-3-031-20979-6; 978-3-031-20980-2
PY 2022
VL 13721
BP 155
EP 162
DI 10.1007/978-3-031-20980-2_14
UT WOS:000897033300014
ER

PT C
AU Nimmakayala, ST
   Kulkarni, PA
AF Nimmakayala, Surya Tej
   Kulkarni, Prasad A.
GP IEEE
TI Improving Startup Performance in Dynamic Binary Translators
SO 2019 27TH EUROMICRO INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED
   AND NETWORK-BASED PROCESSING (PDP)
SE Euromicro Conference on Parallel Distributed and Network-Based
   Processing
CT 27th Euromicro International Conference on Parallel, Distributed and
   Network-Based Processing (PDP)
CY FEB 13-15, 2019
CL Pavia, ITALY
SP IEEE Comp Soc, Euromicro
AB A Dynamic Binary Translation (DBT) system dynamically translates program binaries built for a guest platform into code for the host machine that runs the program, one basic block at a time. Even after optimizations, auxiliary tasks performed alongside program emulation by the DBT system introduce performance overheads as compared to executing the program on the native guest platform. In this work, we analyze the extent and causes for a DBT system's startup performance latency. We then focus on understanding and alleviating the program translation cost that is a significant contributor to and disproportionately impacts the startup overhead. We propose and assess the potential of a new technique that parallelizes program translations on multi-core machines to reduce its evident run-time costs. We explain the challenges in achieving such parallelization and discuss and evaluate solutions.
SN 1066-6192
BN 978-1-7281-1644-0
PY 2019
BP 67
EP 74
DI 10.1109/EMPDP.2019.8671644
UT WOS:000467257000009
ER

PT C
AU Zhou, JW
   Keung, P
AF Zhou, Jiawei
   Keung, Phillip
GP Assoc Computat Linguist
TI Improving Non-autoregressive Neural Machine Translation with Monolingual
   Data
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB Non-autoregressive (NAR) neural machine translation is usually done via knowledge distillation from an autoregressive (AR) model. Under this framework, we leverage large monolingual corpora to improve the NAR model's performance, with the goal of transferring the AR model's generalization ability while preventing overfitting. On top of a strong NAR baseline, our experimental results on the WMT14 En-De and WMT16 En-Ro news translation tasks confirm that monolingual data augmentation consistently improves the performance of the NAR model to approach the teacher AR model's performance, yields comparable or better results than the best non-iterative NAR methods in the literature and helps reduce overfitting in the training process.
BN 978-1-952148-25-5
PY 2020
BP 1893
EP 1898
UT WOS:000570978202015
ER

PT S
AU Ortiz, D
   Varea, IG
   Casacuberta, F
AF Ortiz, D
   Varea, IG
   Casacuberta, F
BE Perales, FJ
TI An empirical comparison of stack-based decoding algorithms for
   statistical machine translation
SO PATTERN RECOGNITION AND IMAGE ANALYSIS, PROCEEDINGS
SE Lecture Notes in Computer Science
CT 1st Iberian Conference on Pattern Recognition and Image Analysis
CY JUN 04-06, 2003
CL UNIV ILLES BALEARS, DEPT CIENCIES MATH & INFORMAT, MALLORCA, SPAIN
SP MCyT, Int Assoc Pattern Recognit, European Union, Conselleria Innovacio Energia
HO UNIV ILLES BALEARS, DEPT CIENCIES MATH & INFORMAT
AB Unlike other heuristic search algorithms, stack-based decoders have been proved theoretically to guarantee the avoidance of search errors in the decoding phase of a statistical machine translation (SMT) system. The disadvantage of the stack-based decoders are the high computational requirements. Therefore, to make the decoding problem feasible for SMT, some heuristic optimizations have to be performed. However, this yields unavoidable search errors. In this paper, we describe, study, and implement the state of the art stack-based decoding algorithms for SMT making an empirical comparison which focuses specifically on the optimization problems, computational time, and translation results. Results are also presented for two well known task, the TOURIST Task and the HANSARDS task.
OI Ortiz-Martinez, Daniel/0000-0001-5659-6702
SN 0302-9743
EI 1611-3349
BN 3-540-40217-9
PY 2003
VL 2652
BP 654
EP 663
UT WOS:000184832300076
ER

PT C
AU Wolk, K
   Marasek, K
AF Wolk, Krzysztof
   Marasek, Krzysztof
BE Kral, P
   Matousek, V
TI Tuned and GPU-Accelerated Parallel Data Mining from Comparable Corpora
SO TEXT, SPEECH, AND DIALOGUE (TSD 2015)
SE Lecture Notes in Artificial Intelligence
CT 18th International Conference on Text, Speech and Dialogue (TSD)
CY SEP 14-17, 2015
CL Pilsen, CZECH REPUBLIC
SP Int Speech Commun Assoc, Czech Soc Cybernet & Informat, Kerio Technol, Univ West Bohemia, Fac Appl Sci, Masaryk Univ, Fac Informat
AB The multilingual nature of the world makes translation a crucial requirement today. Parallel dictionaries constructed by humans are a widely available resource, but they are limited and do not provide enough coverage for good quality translation purposes, due to out-of-vocabulary words and neologisms. This motivates the use of statistical translation systems, which are unfortunately dependent on the quantity and quality of training data. Such has a very limited availability especially for some languages and very narrow text domains. Is this research we present our improvements to Yalign's mining methodology by reimplementing the comparison algorithm, introducing a tuning scripts and by improving performance using GPU computing acceleration. The experiments are conducted on various text domains and bi-data is extracted from the Wikipedia dumps.
RI Wołk, Krzysztof/E-9957-2015; Marasek, Krzysztof/H-9949-2014
OI Wołk, Krzysztof/0000-0001-5030-334X; Marasek,
   Krzysztof/0000-0003-1344-3524
SN 0302-9743
BN 978-3-319-24033-6; 978-3-319-24032-9
PY 2015
VL 9302
BP 32
EP 40
DI 10.1007/978-3-319-24033-6_4
UT WOS:000365947800004
ER

PT C
AU Nenkova, A
   Chae, J
   Louis, A
   Pitler, E
AF Nenkova, Ani
   Chae, Jieun
   Louis, Annie
   Pitler, Emily
BE Krahmer, E
   Theune, M
TI Structural Features for Predicting the Linguistic Quality of Text
   Applications to Machine Translation, Automatic Summarization and
   Human-Authored Text
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
AB Sentence structure is considered to be an important component of the overall linguistic quality of text. Yet few empirical studies have sought to characterize how and to what extent structural features determine fluency and linguistic quality. We report the results of experiments on the predictive power of syntactic phrasing statistics and other structural features for these aspects of text. Manual assessments of sentence fluency for machine translation evaluation and text quality for summarization evaluation are used as gold-standard. We find that many structural features related to phrase length are weakly but significantly correlated with fluency and classifiers based on the entire suite of structural features can achieve high accuracy in pairwise comparison of sentence fluency and in distinguishing machine translations from human translations. We also test the hypothesis that the learned models capture general fluency properties applicable to human-authored text. The results from our experiments do not support the hypothesis. At the same time structural features and models based on them prove to be robust for automatic evaluation of the linguistic quality of multi-document summaries.
SN 0302-9743
EI 1611-3349
BN 978-3-642-15572-7
PY 2010
VL 5790
BP 222
EP 241
UT WOS:000291366600012
ER

PT C
AU Xu, WJ
   Niu, X
   Carpuat, M
AF Xu, Weijia
   Niu, Xing
   Carpuat, Marine
GP Assoc Computat Linguist
TI Differentiable Sampling with Flexible Reference Word Order for Neural
   Machine Translation
SO 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019),
   VOL. 1
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 02-07, 2019
CL Minneapolis, MN
SP Assoc Computat Linguist, N Amer Chapter, Comp Res Assoc, Comp Community Consortium, Natl Sci Fdn, Natl Rees Council Canada, Google
AB Despite some empirical success at correcting exposure bias in machine translation, scheduled sampling algorithms suffer from a major drawback: they incorrectly assume that words in the reference translations and in sampled sequences are aligned at each time step. Our new differentiable sampling algorithm addresses this issue by optimizing the probability that the reference can be aligned with the sampled output, based on a soft alignment predicted by the model itself. As a result, the output distribution at each time step is evaluated with respect to the whole predicted sequence. Experiments on IWSLT translation tasks show that our approach improves BLEU compared to maximum likelihood and scheduled sampling baselines. In addition, our approach is simpler to train with no need for sampling schedule and yields models that achieve larger improvements with smaller beam sizes.(1)
BN 978-1-950737-13-0
PY 2019
BP 2047
EP 2053
UT WOS:000900116902019
ER

PT C
AU Caglayan, O
   Kuyu, M
   Amac, MS
   Madhyastha, P
   Erdem, E
   Erdem, A
   Specia, L
AF Caglayan, Ozan
   Kuyu, Menekse
   Amac, Mustafa Sercan
   Madhyastha, Pranava
   Erdem, Erkut
   Erdem, Aykut
   Specia, Lucia
GP Assoc Computat Linguist
TI Cross-lingual Visual Pre-training for Multimodal Machine Translation
SO 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (EACL 2021)
CT 16th Conference of the
   European-Chapter-of-the-Association-for-Computational-Linguistics (EACL)
CY APR 19-23, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, European Chapter, Grammarly, Facebook AI, Bloomberg Engn, LegalForce, Babelscape
AB Pre-trained language models have been shown to improve performance in many natural language tasks substantially. Although the early focus of such models was single language pre-training, recent advances have resulted in cross-lingual and visual pre-training methods. In this paper, we combine these two approaches to learn visually-grounded cross-lingual representations. Specifically, we extend the translation language modelling (Lample and Conneau, 2019) with masked region classification and perform pre-training with three-way parallel vision & language corpora. We show that when fine-tuned for multimodal machine translation, these models obtain state-of-the-art performance. We also provide qualitative insights into the usefulness of the learned grounded representations.
OI Madhyastha, Pranava/0000-0002-4438-8161
BN 978-1-954085-02-2
PY 2021
BP 1317
EP 1324
UT WOS:000863557001034
ER

PT C
AU Otterbacher, J
AF Otterbacher, Jahna
BE Ishida, T
   Fussell, SR
   Vossen, PTJM
TI Adoption of translation support technologies in a multilingual work
   environment
SO INTERCULTURAL COLLABORATION
SE Lecture Notes in Computer Science
CT 1st International Workshop on Intercultural Collaboration
CY JAN 25-26, 2007
CL Kyoto, JAPAN
SP Natl Inst Informat, Ctr Excellence Knowledge Soc, Kyoto Univ, Language Grid Project, IEICE Special Interest Grp Intercultural Collaborat
AB We study the adoption of translation support technologies by professors at a multilingual university, using the framework of the Technology Adoption Model (TAM). TAM states that a. user's perceived usefulness and ease of use for the technology ultimately determines her actual use of it. Through a survey and a set of interviews with our subjects, we find that there is evidence for TAM in the context of translation support tools. However, we also find that user adoption. of these tools is a bit more complicated. Users who are able to successfully employ these tools have not only developed strategies to overcome their inaccuracies (e.g. by post-editing machine translated text), they also often compensate for the weaknesses of a given technology by combining the use of multiple tools.
OI Otterbacher, Jahna/0000-0002-7655-7118
SN 0302-9743
BN 978-3-540-73999-9
PY 2007
VL 4568
BP 276
EP 290
UT WOS:000249580400021
ER

PT C
AU Vicic, J
   Kubon, V
AF Vicic, Jernej
   Kubon, Vladislav
BE Kral, P
   Matousek, V
TI A Comparison of MT Methods for Closely Related Languages: A Case Study
   on Czech - Slovak and Croatian - Slovenian Language Pairs
SO TEXT, SPEECH, AND DIALOGUE (TSD 2015)
SE Lecture Notes in Artificial Intelligence
CT 18th International Conference on Text, Speech and Dialogue (TSD)
CY SEP 14-17, 2015
CL Pilsen, CZECH REPUBLIC
SP Int Speech Commun Assoc, Czech Soc Cybernet & Informat, Kerio Technol, Univ West Bohemia, Fac Appl Sci, Masaryk Univ, Fac Informat
AB This paper describes an experiment comparing results of machine translation between two pairs of related Slavic languages. Two language pairs on three different translation platforms were observed in the experiment. One pair represents really very close languages (Czech and Slovak), the other pair are slightly less similar languages (Slovenian and Croatian). The comparison is performed by means of three MT systems, one for each pair representing rule-based approach, the other one representing statistical (same system for both language pairs) approach to the task. Both sets of results are manually evaluated by native speakers of the target languages.
RI Kubon, Vladislav/O-7373-2017
OI Kubon, Vladislav/0000-0001-8696-3972; Vicic, Jernej/0000-0002-7876-5009
SN 0302-9743
EI 1611-3349
BN 978-3-319-24033-6; 978-3-319-24032-9
PY 2015
VL 9302
BP 216
EP 224
DI 10.1007/978-3-319-24033-6_25
UT WOS:000365947800025
ER

PT J
AU de Gispert, A
   Marino, JB
AF de Gispert, A.
   Marino, J. B.
TI On the impact of morphology in English to Spanish statistical MT
SO SPEECH COMMUNICATION
AB This paper presents a thorough study of the impact of morphology derivation on N-gram-based Statistical Machine Translation (SMT) models from English into a morphology-rich language such as Spanish. For this purpose, we define a framework under the assumption that a certain degree of morphology-related information is not only being ignored by current statistical translation models, but also has a negative impact on their estimation due to the data sparseness it causes. Moreover, we describe how this information can be decoupled from the standard bilingual N-gram models and introduced separately by means of a well-defined and better informed feature-based classification task.
   Results are presented for the European Parliament Plenary Sessions (EPPS) English -> Spanish task, showing oracle scores based on to what extent SMT models can benefit from simplifying Spanish morphological surface forms for each Part-Of-Speech category. We show that verb form morphological richness greatly weakens the standard statistical models, and we carry out a posterior morphology classification by defining a simple set of features and applying machine learning techniques.
   In addition to that, we propose a simple technique to deal with Spanish enclitic pronouns. Both techniques are empirically evaluated and final translation results show improvements over the baseline by just dealing with Spanish morphology. In principle, the study is also valid for translation from English into any other Romance language (Portuguese, Catalan, French, Galician, Italian, etc.).
   The proposed method can be applied to both monotonic and non-monotonic decoding scenarios, thus revealing the interaction between word-order decoding and the proposed morphology simplification techniques. Overall results achieve statistically significant improvement over baseline performance in this demanding task. (C) 2008 Elsevier B.V. All rights reserved.
RI Mariño, José/N-1626-2014
OI Mariño, José/0000-0002-9471-8675
SN 0167-6393
EI 1872-7182
PD NOV-DEC
PY 2008
VL 50
IS 11-12
BP 1034
EP 1046
DI 10.1016/j.specom.2008.05.003
UT WOS:000261284100013
ER

PT C
AU Wu, NE
   Hou, HX
   Guo, ZY
   Zheng, W
AF Wu, Nier
   Hou, Hongxu
   Guo, Ziyue
   Zheng, Wei
BE Farkas, I
   Masulli, P
   Otte, S
   Wermter, S
TI Low-Resource Neural Machine Translation Using XLNet Pre-training Model
SO ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING, ICANN 2021, PT V
SE Lecture Notes in Computer Science
CT 30th International Conference on Artificial Neural Networks (ICANN)
CY SEP 14-17, 2021
CL ELECTR NETWORK
AB The methods to improve the quality of low-resource neural machine translation (NMT) include: change the token granularity to reduce the number of low-frequency words; generate pseudo-parallel corpus from large-scale monolingual data to optimize model parameters; Use the auxiliary knowledge of pre-trained model to train NMT model. However, reducing token granularity will result in a large number of invalid operations and increase the complexity of local reordering on the target side. Pseudo-parallel corpus contains noise affect model convergence. Pre-training methods also limit translation quality due to the human error and the assumption of conditional independence. Therefore, we proposed a XLNet based pre-training method, that corrects the defects of the pre-training model, and enhance NMT model for context feature extraction. Experiments are carried out on CCMT2019 Mongolian-Chinese (Mo-Zh), Uyghur-Chinese (Ug-Zh) and Tibetan-Chinese (Ti-Zh) tasks, the results show that the generalization ability and BLEU scores of our method are improved compared with the baseline, which fully verifies the effectiveness of the method.
RI Zheng, Wei/GQQ-8951-2022
SN 0302-9743
EI 1611-3349
BN 978-3-030-86383-8; 978-3-030-86382-1
PY 2021
VL 12895
BP 503
EP 514
DI 10.1007/978-3-030-86383-8_40
UT WOS:000711936300040
ER

PT C
AU Sridhar, VKR
   Barbosa, L
   Bangalore, S
AF Sridhar, Vivek Kumar Rangarajan
   Barbosa, Luciano
   Bangalore, Srinivas
GP Int Speech Commun Assoc
TI A Scalable Approach to Building a Parallel Corpus from the Web
SO 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5
CT 12th Annual Conference of the
   International-Speech-Communication-Association 2011 (INTERSPEECH 2011)
CY AUG 27-31, 2011
CL Florence, ITALY
SP Int Speech Commun Assoc (ISCA)
AB Parallel text acquisition from the Web is an attractive way for augmenting statistical models (e.g., machine translation, cross-lingual document retrieval) with domain representative data. The basis for obtaining such data is a collection of pairs of bilingual Web sites or pages. In this work, we propose a crawling strategy that locates bilingual Web sites by constraining the visitation policy of the crawler to the graph neighborhood of bilingual sites on the Web. Subsequently, we use a novel recursive mining technique that recursively extracts text and links from the collection of bilingual Web sites obtained from the crawling. Our method does not suffer from the computationally prohibitive combinatorial matching typically used in previous work that uses document retrieval techniques to match a collection of bilingual webpages. We demonstrate the efficacy of our approach in the context of machine' translation in the tourism and hospitality domain. The parallel text obtained using our novel crawling strategy results in a relative improvement of 21% in BLEU score (English-to-Spanish) over an out-of-domain seed translation model trained on the European parliamentary proceedings.
OI Barbosa, Luciano/0000-0002-6858-4773
BN 978-1-61839-270-1
PY 2011
BP 2124
EP 2127
UT WOS:000316502201020
ER

PT J
AU Macias, LP
AF Perez Macias, Lorena
TI The Use of the Survey to Find Out About the Perception of Machine
   Translation and Post-Editing in Spain
SO TRANS-REVISTA DE TRADUCTOLOGIA
AB The aim of this contribution is to demonstrate the validity and applicability of an appropriate data collection instrument to collect information on the use and perception of machine translation and post-editing tools in the current Spanish translation market, in this case, a virtual survey. To this end, this study will be contextualised through a review of those theoretical aspects relating to social and qualitative methodology that have been considered most significant for its configuration. Furthermore, the different sub-stages of the development phase of the instrument used will be detailed: design, robustness tests, launch, data collection and reporting of results. In the survey design substage, different studies that have been considered relevant for this work due to their similarity in terms of the methodology used will be cited as background for this work. Next, in the robustness testing sub-stage, the steps taken to optimise the survey design will be described, including the panel of judges and piloting. Then, the procedure carried out to launch the virtual survey, based on the non-probability sampling technique called snowball, will be explained, as well as the method chosen for the data collection. Finally, some of the most relevant data collected on the use and attitude of professional translators with regard to machine translation and post-editing will be presented. The main general conclusions arising from the work carried out will also be presented.
SN 1137-2311
EI 2603-6967
PY 2020
IS 24
BP 375
EP 400
DI 10.24310/TRANS.2020.v0i24.6837
UT WOS:000871236100023
ER

PT J
AU Comelles, E
   Atserias, J
AF Comelles, Elisabet
   Atserias, Jordi
TI VERTa: a linguistic approach to automatic machine translation evaluation
SO LANGUAGE RESOURCES AND EVALUATION
AB Machine translation (MT) is directly linked to its evaluation in order to both compare different MT system outputs and analyse system errors so that they can be addressed and corrected. As a consequence, MT evaluation has become increasingly important and popular in the last decade, leading to the development of MT evaluation metrics aiming at automatically assessing MT output. Most of these metrics use reference translations in order to compare system output, and the most well-known and widely spread work at lexical level. In this study we describe and present a linguistically-motivated metric, VERTa, which aims at using and combining a wide variety of linguistic features at lexical, morphological, syntactic and semantic level. Before designing and developing VERTa a qualitative linguistic analysis of data was performed so as to identify the linguistic phenomena that an MT metric must consider (Comelles et al. 2017). In the present study we introduce VERTa's design and architecture and we report the experiments performed in order to develop the metric and to check the suitability and interaction of the linguistic information used. The experiments carried out go beyond traditional correlation scores and step towards a more qualitative approach based on linguistic analysis. Finally, in order to check the validity of the metric, an evaluation has been conducted comparing the metric's performance to that of other well-known state-of-the-art MT metrics.
OI atserias batalla, jordi/0000-0002-4604-5541; Comelles,
   Elisabet/0000-0002-4753-2712
SN 1574-020X
EI 1574-0218
PD MAR
PY 2019
VL 53
IS 1
BP 57
EP 86
DI 10.1007/s10579-018-9430-2
UT WOS:000460656700003
ER

PT J
AU Nguyen, QP
   Vo, AD
   Shin, JC
   Tran, P
   Ock, CY
AF Quang-Phuoc Nguyen
   Vo, Anh-Dung
   Shin, Joon-Choul
   Phuoc Tran
   Ock, Cheol-Young
TI Korean-Vietnamese Neural Machine Translation System With Korean
   Morphological Analysis and Word Sense Disambiguation
SO IEEE ACCESS
AB Although deep neural networks have recently led to great achievements in machine translation (MT), various challenges are still encountered during the development of Korean-Vietnamese MT systems. Because Korean is a morphologically rich language and Vietnamese is an analytic language, neither have clear word boundaries. The high rate of homographs in Korean causes word ambiguities, which causes problems in neural MT (NMT). In addition, as a low-resource language pair, there is no freely available, adequate Korean-Vietnamese parallel corpus that can be used to train translation models. In this paper, we manually established a lexical semantic network for the special characteristics of Korean as a knowledge base that was used for developing our Korean morphological analysis and word-sense disambiguation system: UTagger. We also constructed a large Korean-Vietnamese parallel corpus, in which we applied the state-of-the-art Vietnamese word segmentation method RDRsegmenter to Vietnamese texts and UTagger to Korean texts. Finally, we built a bi-directional Korean-Vietnamese NMT system based on the attention-based encoder-decoder architecture. The experimental results indicated that UTagger and RDRsegmenter could significantly improve the performance of the Korean-Vietnamese NMT system, achieving remarkable results by 27.79 BLEU points and 58.77 TER points in Korean-to-Vietnamese direction and 25.44 BLEU points and 58.72 TER points in the reverse direction.
RI Tran, Phuoc/GLU-1021-2022
SN 2169-3536
PY 2019
VL 7
BP 32602
EP 32616
DI 10.1109/ACCESS.2019.2902270
UT WOS:000463439400001
ER

PT C
AU Haruna, S
   Taki, K
   Leichsenring, G
   Kanamaru, T
   Tominaga, N
AF Haruna, S
   Taki, K
   Leichsenring, G
   Kanamaru, T
   Tominaga, N
BE Zhong, YX
   Cui, S
   Wang, Y
TI Java translation scheme for consumer electronics home networks
SO 2001 INTERNATIONAL CONFERENCES ON INFO-TECH AND INFO-NET PROCEEDINGS,
   CONFERENCE A-G: INFO-TECH & INFO-NET: A KEY TO BETTER LIFE
CT International Conference on Info-Tech and Info-Net (ICII 2001)
CY OCT 29-NOV 01, 2001
CL BEIJING, PEOPLES R CHINA
SP China Assoc Sci & Technol, IEEE Beijing Ctr, ATM Forume, Beijing Internet Inst, IEEE Communicat Soc, IEEE Comp Soc, IEEE Control Soc, Global Informat Infrastruct Commiss, World Federat Engn Org, Int Federat Informat Proc, Internet Engn Task Force, Int Council Comp Commun, Chinese Inst Electr, Beijing Univ Posts & Telecommunicat
AB Java is considered to be a promising architecture for use in distributing and running programs on consumer electronics according to the progress of a home network. However, as conventional Java requires a large amount of memory and a highly efficient CPU in appliances running virtual machines, it has been difficult to apply it to the consumer electronics field where low cost and low power consumption are prime concerns. In this paper, we propose a Java translation scheme in which a bytecode-to-bytecode translator for a compact virtual machine is implemented in the home gateway located between an internal home network and external networks. As a result, we have been able to obtain a virtual machine architecture that requires only about 1/10 of memory in comparison with conventional JavaVM. Furthermore, the size of distributed class files is reduced to about 40% of the original file size.
BN 7-900081-58-5
PY 2001
BP C220
EP C225
UT WOS:000177471800242
ER

PT C
AU Zhan, RZ
   Liu, XB
   Wong, DF
   Chao, LS
AF Zhan, Runzhe
   Liu, Xuebo
   Wong, Derek F.
   Chao, Lidia S.
GP Assoc Advancement Artificial Intelligence
TI Meta-Curriculum Learning for Domain Adaptation in Neural Machine
   Translation
SO THIRTY-FIFTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THIRTY-THIRD
   CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE AND THE
   ELEVENTH SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 35th AAAI Conference on Artificial Intelligence / 33rd Conference on
   Innovative Applications of Artificial Intelligence / 11th Symposium on
   Educational Advances in Artificial Intelligence
CY FEB 02-09, 2021
CL ELECTR NETWORK
SP Assoc Advancement Artificial Intelligence
AB Meta-learning has been sufficiently validated to be beneficial for low-resource neural machine translation (NMT). However, we find that meta-trained NMT fails to improve the translation performance of the domain unseen at the meta-training stage. In this paper, we aim to alleviate this issue by proposing a novel meta-curriculum learning for domain adaptation in NMT. During meta-training, the NMT first learns the similar curricula from each domain to avoid falling into a bad local optimum early, and finally learns the curricula of individualities to improve the model robustness for learning domain-specific knowledge. Experimental results on 10 different low-resource domains show that meta-curriculum learning can improve the translation performance of both familiar and unfamiliar domains. All the codes and data are freely available at https://github.com/NLP2CT/Meta-Curriculum.
RI Wong, Derek F/CAI-7740-2022
SN 2159-5399
EI 2374-3468
BN 978-1-57735-866-4
PY 2021
VL 35
BP 14310
EP 14318
UT WOS:000681269805111
ER

PT C
AU Ran, Q
   Lin, YK
   Li, P
   Zhou, J
AF Ran, Qiu
   Lin, Yankai
   Li, Peng
   Zhou, Jie
GP Assoc Computat Linguist
TI Learning to Recover from Multi-Modality Errors for Non-Autoregressive
   Neural Machine Translation
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB Non-autoregressive neural machine translation (NAT) predicts the entire target sequence simultaneously and significantly accelerates inference process. However, NAT discards the dependency information in a sentence, and thus inevitably suffers from the multi-modality problem: the target tokens may be provided by different possible translations, often causing token repetitions or missing. To alleviate this problem, we propose a novel semi-autoregressive model RecoverSAT in this work, which generates a translation as a sequence of segments. The segments are generated simultaneously while each segment is predicted token-by-token. By dynamically determining segment length and deleting repetitive segments, RecoverSAT is capable of recovering from repetitive and missing token errors. Experimental results on three widely used benchmark datasets show that our proposed model achieves more than 4x speedup while maintaining comparable performance compared with the corresponding autoregressive model.
OI Li, Peng/0000-0003-1374-5979
BN 978-1-952148-25-5
PY 2020
BP 3059
EP 3069
UT WOS:000570978203037
ER

PT C
AU He, SL
   Tu, ZP
   Wang, X
   Wang, LY
   Lyu, MR
   Shi, SM
AF He, Shilin
   Tu, Zhaopeng
   Wang, Xing
   Wang, Longyue
   Lyu, Michael R.
   Shi, Shuming
GP Assoc Computat Linguist
TI Towards Understanding Neural Machine Translation with Word Importance
SO 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND
   THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE
CT Conference on Empirical Methods in Natural Language Processing / 9th
   International Joint Conference on Natural Language Processing
   (EMNLP-IJCNLP)
CY NOV 03-07, 2019
CL Hong Kong, HONG KONG
SP Google, Facebook, Apple, ASAPP, Salesforce, Huawei, Baidu, Deepmind, Amazon, PolyAI, Naver, ByteDance, Megagon Labs, Zhuiyi, Verisk, MI
AB Although neural machine translation (NMT) has advanced the state-of-the-art on various language pairs, the interpretability of NMT remains unsatisfactory. In this work, we propose to address this gap by focusing on understanding the input-output behavior of NMT models. Specifically, we measure the word importance by attributing the NMT output to every input word through a gradient-based method. We validate the approach on a couple of perturbation operations, language pairs, and model architectures, demonstrating its superiority on identifying input words with higher influence on translation performance. Encouragingly, the calculated importance can serve as indicators of input words that are under-translated by NMT models. Furthermore, our analysis reveals that words of certain syntactic categories have higher importance while the categories vary across language pairs, which can inspire better design principles of NMT architectures for multi-lingual translation.
BN 978-1-950737-90-1
PY 2019
BP 953
EP 962
UT WOS:000854193301010
ER

PT C
AU Xia, MZ
   Huang, GP
   Liu, LM
   Shi, SM
AF Xia, Mengzhou
   Huang, Guoping
   Liu, Lemao
   Shi, Shuming
GP AAAI
TI Graph Based Translation Memory for Neural Machine Translation
SO THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 33rd AAAI Conference on Artificial Intelligence / 31st Innovative
   Applications of Artificial Intelligence Conference / 9th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY JAN 27-FEB 01, 2019
CL Honolulu, HI
SP Assoc Advancement Artificial Intelligence
AB A translation memory (TM) is proved to be helpful to improve neural machine translation (NMT). Existing approaches either pursue the decoding efficiency by merely accessing local information in a TM or encode the global information in a TM yet sacrificing efficiency due to redundancy. We propose an efficient approach to making use of the global information in a TM. The key idea is to pack a redundant TM into a compact graph and perform additional attention mechanisms over the packed graph for integrating the TM representation into the decoding network. We implement the model by extending the state-of-the-art NMT, Transformer. Extensive experiments on three language pairs show that the proposed approach is efficient in terms of running time and space occupation, and particularly it outperforms multiple strong baselines in terms of BLEU scores.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-809-1
PY 2019
BP 7297
EP 7304
UT WOS:000486572501103
ER

PT C
AU Oda, Y
   Arthur, P
   Neubig, G
   Yoshino, K
   Nakamura, S
AF Oda, Yusuke
   Arthur, Philip
   Neubig, Graham
   Yoshino, Koichiro
   Nakamura, Satoshi
BE Barzilay, R
   Kan, MY
TI Neural Machine Translation via Binary Code Prediction
SO PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1
CT 55th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 30-AUG 04, 2017
CL Vancouver, CANADA
SP Alibaba Grp, Amazon, Apple, Baidu, Bloomberg, Facebook, Google, Samsung, Tencent, eBay, Elsevier, IBM Res, KPMG, Maluuba, Microsoft, Naver Line, NEC, Recruit Inst Technol, SAP, Adobe, Bosch, CVTE, Duolingo, Huawei, Nuance, Oracle, Sogou, Grammarly, Toutiao, Yandex
AB In this paper, we propose a new method for calculating the output layer in neural machine translation systems. The method is based on predicting a binary code for each word and can reduce computation time/memory requirements of the output layer to be logarithmic in vocabulary size in the best case. In addition, we also introduce two advanced approaches to improve the robustness of the proposed model: using error-correcting codes and combining softmax and binary codes. Experiments on two English <-> Japanese bidirectional translation tasks show proposed models achieve BLEU scores that approach the softmax, while reducing memory usage to the order of less than 1/10 and improving decoding speed on CPUs by x5 to x10.
BN 978-1-945626-75-3
PY 2017
BP 850
EP 860
DI 10.18653/v1/P17-1079
UT WOS:000493984800079
ER

PT C
AU Imamura, K
   Sumita, E
   Matsumoto, Y
AF Imamura, K
   Sumita, E
   Matsumoto, Y
GP ACL
TI Feedback cleaning of machine translation rules using automatic
   evaluation
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB When rules of transfer-based machine translation (MT) are automatically acquired from bilingual corpora, incorrect/redundant rules are generated due to acquisition errors or translation variety in the corpora. As a new countermeasure to this problem, we propose a feedback cleaning method using automatic evaluation of MT quality, which removes incorrect/redundant rules as a way to increase the evaluation score. BLEU is utilized for the automatic evaluation. The hill-climbing algorithm, which involves features of this task, is applied to searching for the optimal combination of rules. Our experiments show that the MT quality improves by 10% in test sentences according to a subjective evaluation. This is considerable improvement over previous methods.
BN 1-932432-09-4
PY 2003
BP 447
EP 454
UT WOS:000223097500057
ER

PT C
AU Kavitha, KM
   Gomes, L
   Lopes, JGP
AF Kavitha, Karimbi Mahesh
   Gomes, Luis
   Pereira Lopes, Jose Gabriel
BE Bazzan, ALC
   Pichara, K
TI Identification of Bilingual Suffix Classes for Classification and
   Translation Generation
SO ADVANCES IN ARTIFICIAL INTELLIGENCE (IBERAMIA 2014)
SE Lecture Notes in Artificial Intelligence
CT 14th Ibero-American Conference on Artificial Intelligence (AI)
CY NOV 24-27, 2014
CL Santiago, CHILE
SP Pontifica Univ Catolica, Ibero American Artificial Intelligence, Associacao Portuguesa Inteligencia Artificial, Asociacion Espanola Inteligencia Artificial, Sociedad Argentina Informatica, Sociedad Colombiana Computac, Sociedad Cubana Matematica Computac, Sociedad Iberoamericana Inteligencia Artificial, Sociedad Mexicana Inteligencia Artificial, Sociedade Brasileira Computacao, Sociedad Peruana Inteligencia Artificial
AB We examine the possibility of learning bilingual morphology using the translation forms taken from an existing, manually validated, bilingual translation lexicon. The objective is to evaluate the use of bilingual stem and suffix based features on the performance of the existing Support Vector Machine based classifier trained to classify the automatically extracted word-to-word translations. We initially induce the bilingual stem and suffix correspondences by considering the longest sequence common to orthogonally similar translations. Clusters of stem-pairs characterised by identical suffix-pairs are formed, which are then used to generate out-of-vocabulary translations that are identical to, but different from, the previously existing translations, thereby completing the existing lexicon. Using the bilingual stem and suffix correspondences induced from the augmented lexicon we come up with 5 new features that reflects the (non) existence of morphological coverage (agreement) between a term and its translation. Specifically, we examine and evaluate the use of suffix classes, bilingual stem and suffix correspondences as features in selecting correct word-to-word translations from among the automatically extracted ones. With a training data of approximately 35.8K word translations for the language pair English-Portuguese, we identified around 6.4K unique stem pairs and 0.25K unique suffix pairs. Further, experimental results show that the newly added features improved the word-to-word classification accuracy by 9.11% leading to an overall improvement in the classifier accuracy by 2.15% when all translations (single- and multi-word translations) were considered.
RI Gomes, Luís/G-1192-2011; Mahesh, Kavitha Karimbi/A-7720-2015; Mahesh,
   Kavitha Karimbi/W-6194-2019
OI Gomes, Luís/0000-0003-3119-4189; Mahesh, Kavitha
   Karimbi/0000-0002-9773-9674; Pereira Lopes, Jose
   Gabriel/0000-0003-1669-0336
SN 0302-9743
EI 1611-3349
BN 978-3-319-12027-0; 978-3-319-12026-3
PY 2014
VL 8864
BP 154
EP 166
DI 10.1007/978-3-319-12027-0_13
UT WOS:000354873200013
ER

PT C
AU Guo, JL
   Xu, LL
   Chen, EH
AF Guo, Junliang
   Xu, Linli
   Chen, Enhong
GP Assoc Computat Linguist
TI Jointly Masked Sequence-to-Sequence Model for Non-Autoregressive Neural
   Machine Translation
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB The masked language model has received remarkable attention due to its effectiveness on various natural language processing tasks. However, few works have adopted this technique in the sequence-to-sequence models. In this work, we introduce a jointly masked sequence-to-sequence model and explore its application on non-autoregressive neural machine translation (NAT). Specifically, we first empirically study the functionalities of the encoder and the decoder in NAT models, and find that the encoder takes a more important role than the decoder regarding the translation quality. Therefore, we propose to train the encoder more rigorously by masking the encoder input while training. As for the decoder, we propose to train it based on the consecutive masking of the decoder input with an n-gram loss function to alleviate the problem of translating duplicate words. The two types of masks are applied to the model jointly at the training stage. We conduct experiments on five benchmark machine translation tasks, and our model can achieve 27.69/32.24 BLEU scores on WMT14 English-German/German-English tasks with 5+ times speed up compared with an autoregressive model.
BN 978-1-952148-25-5
PY 2020
BP 376
EP 385
UT WOS:000570978200036
ER

PT C
AU Yao, SW
   Wan, XJ
AF Yao, Shaowei
   Wan, Xiaojun
GP Assoc Computat Linguist
TI Multimodal Transformer for Multimodal Machine Translation
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB Multimodal Machine Translation (MMT) aims to introduce information from other modality, generally static images, to improve the translation quality. Previous works propose various incorporation methods, but most of them do not consider the relative importance of multiple modalities. In MMT, equally treating text and images may encode too much irrelevant information from images which may introduce noise. In this paper, we propose the multimodal self-attention in Transformer to solve the issues above. The proposed method learns the representations of images based on the text, which avoids encoding irrelevant information in images. Experiments and visualization analysis demonstrate that our model benefits from visual information and substantially outperforms previous works and competitive baselines in terms of various metrics.
BN 978-1-952148-25-5
PY 2020
BP 4346
EP 4350
UT WOS:000570978204059
ER

PT J
AU Sridhar, VKR
   Bangalore, S
   Narayanan, S
AF Sridhar, Vivek Kumar Rangarajan
   Bangalore, Srinivas
   Narayanan, Shrikanth
TI Enriching machine-mediated speech-to-speech translation using contextual
   information
SO COMPUTER SPEECH AND LANGUAGE
AB Conventional approaches to speech-to-speech (S2S) translation typically ignore key contextual information such as prosody, emphasis, discourse state in the translation process. Capturing and exploiting such contextual information is especially important in machine-mediated S2S translation as it can serve as a complementary knowledge source that can potentially aid the end users in improved understanding and disambiguation. In this work, we present a general framework for integrating rich contextual information in S2S translation. We present novel methodologies for integrating source side context in the form of dialog act (DA) tags, and target side context using prosodic word prominence. We demonstrate the integration of the DA tags in two different statistical translation frameworks, phrase-based translation and a bag-of-words lexical choice model. In addition to producing interpretable DA annotated target language translations, we also obtain significant improvements in terms of automatic evaluation metrics such as lexical selection accuracy and BLEU score. Our experiments also indicate that finer representation of dialog information such as yes no questions, wit-questions and open questions are the most useful in improving translation quality. For target side enrichment, we employ factored translation models to integrate the assignment and transfer of prosodic word prominence (pitch accents) during translation. The factored translation models provide significant improvement in assignment of correct pitch accents to the target words in comparison with a post-processing approach. Our framework is suitable for integrating any word or utterance level contextual information that can be reliably detected (recognized) from speech and/or text. (C) 2011 Elsevier Ltd. All rights reserved.
RI Narayanan, Shrikanth S/D-5676-2012
SN 0885-2308
EI 1095-8363
PD FEB
PY 2013
VL 27
IS 2
SI SI
BP 492
EP 508
DI 10.1016/j.csl.2011.08.001
UT WOS:000312471500007
ER

PT C
AU Chitwirat, P
   Facundes, N
   Sirinaovakul, B
AF Chitwirat, Porntip
   Facundes, Nuttanart
   Sirinaovakul, Booncharoen
GP IEEE
TI English-Thai Machine Translation in a Lexicalist Grammar
SO 2008 INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION
   TECHNOLOGIES
CT International Symposium on Communication and Information Technologies
CY OCT 21-23, 2008
CL Vientiane, LAOS
AB In this research, we develop a machine translation (MT) system to translate useful phrases in tourism domain from English to Thai. We exploit the transfer-based approach within the theoretical framework of Head-Driven Phrase Structure Grammar (HPSG) and a relevant semantic theory, Minimal Recursion Semantics (MRS). The theories are chosen due to their robust computational capabilities. Our MT system is lexicalist in the sense that the semantic transfer takes place at the word level while HPSG ensures deep analyses of source and target languages.
BN 978-1-4244-2335-4
PY 2008
BP 171
EP 174
DI 10.1109/ISCIT.2008.4700176
UT WOS:000265524600034
ER

PT C
AU Zeng, XD
   Chao, LS
   Wong, DF
   Trancoso, I
   Tian, L
AF Zeng, Xiaodong
   Chao, Lidia S.
   Wong, Derek F.
   Trancoso, Isabel
   Tian, Liang
BE Toutanova, K
   Wu, H
TI Toward Better Chinese Word Segmentation for SMT via Bilingual
   Constraints
SO PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS, VOL 1
CT 52nd Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUN 22-27, 2014
CL Baltimore, MD
SP Assoc Computat Linguist, Baidu, Bloomberg, Google, Microsoft, Nuance, Yahoo Labs, Informat Sci Inst, Xerox Res Ctr Europe, Brandeis Univ, Facebook, Yandex, Amazon Com, IBM Watson, Johns Hopkins Univ, A9, AI@ISI, Xerox
AB This study investigates on building a better Chinese word segmentation model for statistical machine translation. It aims at leveraging word boundary information, automatically learned by bilingual character-based alignments, to induce a preferable segmentation model. We propose dealing with the induced word boundaries as soft constraints to bias the continuous learning of a supervised CRFs model, trained by the treebank data (labeled), on the bilingual data (unlabeled). The induced word boundary information is encoded as a graph propagation constraint. The constrained model induction is accomplished by using posterior regularization algorithm. The experiments on a Chinese-to-English machine translation task reveal that the proposed model can bring positive segmentation effects to translation quality.
RI Wong, Derek F/CAI-7740-2022; Wong, Fai/A-7994-2012; Trancoso,
   Isabel/C-5965-2008
OI Wong, Fai/0000-0002-5307-7322; Trancoso, Isabel/0000-0001-5874-6313
BN 978-1-937284-72-5
PY 2014
BP 1360
EP 1369
UT WOS:000493814100128
ER

PT C
AU Hasler, E
   Domhan, T
   Trenous, J
   Tran, K
   Byrne, B
   Hieber, F
AF Hasler, Eva
   Domhan, Tobias
   Trenous, Jonay
   Tran, Ke
   Byrne, Bill
   Hieber, Felix
GP Assoc Computat Linguist
TI Improving the Quality Trade-Off for Neural Machine Translation
   Multi-Domain Adaptation
SO 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2021)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 07-11, 2021
CL Punta Cana, DOMINICAN REP
AB Building neural machine translation systems to perform well on a specific target domain is a well-studied problem. Optimizing system performance for multiple, diverse target domains however remains a challenge. We study this problem in an adaptation setting where the goal is to preserve the existing system quality while incorporating data for domains that were not the focus of the original translation system. We find that we can improve over the performance trade-off offered by Elastic Weight Consolidation with a relatively simple data mixing strategy. At comparable performance on the new domains, catastrophic forgetting is mitigated significantly on strong WMT baselines. Combining both approaches improves the Pareto frontier on this task.
OI Byrne, William/0000-0003-1896-4492
BN 978-1-955917-09-4
PY 2021
BP 8470
EP 8477
UT WOS:000860727002044
ER

PT C
AU Liu, H
   Li, M
   Zhang, J
   Chen, L
AF Liu, Hui
   Li, Miao
   Zhang, Jian
   Chen, Lei
BE Xiong, D
   Castelli, E
   Dong, M
   Yen, PTN
TI Morpheme Segmentation Using Bilingual Features
SO 2012 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP 2012)
SE International Conference on Asian Language Processing
CT International Conference on Asian Language Processing (IALP)
CY NOV 13-15, 2012
CL Hanoi, VIETNAM
SP IEEE, IEEE Comp Soc, Int Res Inst MICA, Hanoi Univ Sci & Technol, Chinese & Oriental Languages Informat Proc Soc (COLIPS), IEEE Singapore Comp Chapter
AB This paper presents an optimizing morphological segmentation metric for statistical machine translation performance. Unlike previous morpheme segmentation work for getting greater linguistic accuracy we focus on factors such as consistency, coverage and granularity, which directly affect MT performance. We propose a novel combination of dictionary information and statistical model, taking advantage of source-target bilingual features. Our method effectively integrates morpheme information while avoiding the complex calculations generated with the traditional usage of the morphemes. Experiments show that the approach outperforms previously proposed ones and provides an improvement of 1.03 and 0.89 BLEU results in both phrased-based and factored-based MT model on the Chinese-Mongolian translation task.
SN 2159-1962
EI 2159-1970
BN 978-0-7695-4886-9; 978-1-4673-6113-2
PY 2012
BP 209
EP 212
DI 10.1109/IALP.2012.52
UT WOS:000318948700053
ER

PT C
AU Motozawa, M
   Murakami, Y
   Pituxcoosuvarn, M
   Takasaki, T
   Mori, Y
AF Motozawa, Mizuki
   Murakami, Yohei
   Pituxcoosuvarn, Mondheera
   Takasaki, Toshiyuki
   Mori, Yumiko
GP ASSOC COMP MACHINERY
TI Conversation Analysis for Facilitation in Children's Intercultural
   Collaboration
SO IDC '21: PROCEEDINGS OF INTERACTION DESIGN AND CHILDREN 2021
CT 20th ACM Interaction Design and Children (IDC) Conference
CY JUN 24-30, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery, Natl & Kapodistrian Univ Athens, LUMS, BRIDGES, EUGAIN, NSF
AB In order to find solutions to various international problems, Global Citizenship Education (GCED) for children must consider the diversity of societies beyond basic issues of language and culture. For GCED, machine translation can be used as a tool to allow children to collaborate without a common language. However, low-resource language speakers often cannot enter the conversation and have difficulties in participating in a collaboration, because existing machine translations have poor translation quality in the low-resource languages. Messages from facilitators play an important role in encouraging children's responses and participation. We, therefore, have analyzed the role of the facilitator in a real-world intercultural children workshop. Specifically, we examine actual conversation log data that links the facilitator's utterances with children's utterances in adjacency pairing. We annotate the paired data with tags and then statistically analyze the tagged data. The analysis results show that some types of facilitator messages can significantly impact the responses of low-resource language speaking children. For example, "request" type utterances tended to encourage responses.
BN 978-1-4503-8452-0
PY 2021
BP 62
EP 68
DI 10.1145/3459990.3460721
UT WOS:000767988500007
ER

PT C
AU Thompson, B
   Post, M
AF Thompson, Brian
   Post, Matt
GP Assoc Computat Linguist
TI Automatic Machine Translation Evaluation in Many Languages via Zero-Shot
   Paraphrasing
SO PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL
   LANGUAGE PROCESSING (EMNLP)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 16-20, 2020
CL ELECTR NETWORK
SP Bloomberg Engn, Google Res, Apple, Amazon Sci, Baidu, Megagon Labs, Facebook, DeepMind, Grammarly, ByteDance, Zeta Alpha, Babelscape, Naver, Adobe, Hitachi, Salesforce, Univ So Calif, Viterbi Sch Engn, Informat Sci Inst
AB We frame the task of machine translation evaluation as one of scoring machine translation output with a sequence-to-sequence paraphraser, conditioned on a human reference. We propose training the paraphraser as a multilingual NMT system, treating paraphrasing as a zero-shot translation task (e.g., Czech to Czech). This results in the paraphraser's output mode being centered around a copy of the input sequence, which represents the best case scenario where the MT system output matches a human reference. Our method is simple and intuitive, and does not require human judgements for training. Our single model (trained in 39 languages) outperforms or statistically ties with all prior metrics on the WMT 2019 segment-level shared metrics task in all languages (excluding Gujarati where the model had no training data). We also explore using our model for the task of quality estimation as a metric-conditioning on the source instead of the reference-and find that it significantly outperforms every submission to the WMT 2019 shared task on quality estimation in every language pair.
BN 978-1-952148-60-6
PY 2020
BP 90
EP 121
UT WOS:000855160700008
ER

PT C
AU Dou, ZY
   Tu, ZP
   Wang, X
   Shi, SM
   Zhang, T
AF Dou, Zi-Yi
   Tu, Zhaopeng
   Wang, Xing
   Shi, Shuming
   Zhang, Tong
GP Assoc Computat Linguist
TI Exploiting Deep Representations for Neural Machine Translation
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB Advanced neural machine translation (NMT) models generally implement encoder and decoder as multiple layers, which allows systems to model complex functions and capture complicated linguistic structures. However, only the top layers of encoder and decoder are leveraged in the subsequent process, which misses the opportunity to exploit the useful information embedded in other layers. In this work, we propose to simultaneously expose all of these signals with layer aggregation and multi-layer attention mechanisms. In addition, we introduce an auxiliary regularization term to encourage different layers to capture diverse information. Experimental results on widely-used WMT14 English double right arrow German and WMT17 Chinese double right arrow English translation data demonstrate the effectiveness and universality of the proposed approach.
BN 978-1-948087-84-1
PY 2018
BP 4253
EP 4262
UT WOS:000865723404038
ER

PT C
AU Suryakanthi, T
   Sharma, K
AF Suryakanthi, T.
   Sharma, Kamlesh
BE Mitra, S
   McIntosh, S
   Nair, I
   Bedi, P
   Rajasree, MS
TI Discourse Translation from English to Telugu
SO PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING
   AND INFORMATICS (WCI-2015)
CT 3rd International Symposium on Women in Computing and Informatics (WCI)
CY AUG 10-13, 2015
CL SCMS Sch Engn & Technol, Aluva, INDIA
SP ACM India, ACM Comm Women Comp India, ICPS, Assoc Comp Machinery Trivandrum Profess Chapter, Int Neural Network Soc India Reg Chapter, ACM Cochin Chapter, IWNN
HO SCMS Sch Engn & Technol
AB Discourses are texts that are above the sentence level. Translating discourses requires special attention as the sentences should be translated keeping the context in mind. The first and second sentence should he interpreted as a whole and not as individual sentences. The present paper deals with translating two types of discourses, compound and complex sentences from English to Telugu language. The paper discusses the design of algorithms to translate compound and complex sentences from English to Telugu. The paper discusses the results obtained by implementing the two algorithms in a machine translation system on sample test suites.
RI Sharma, Kamlesh/L-1935-2019
OI Sharma, Dr. Kamlesh/0000-0002-6000-5933
BN 978-1-4503-3361-0
PY 2015
BP 222
EP 227
DI 10.1145/2791405.2791459
UT WOS:000395824100037
ER

PT C
AU Chen, JX
   Li, X
   Zhang, JR
   Zhou, CL
   Cui, JW
   Wang, B
   Su, JS
AF Chen, Junxuan
   Li, Xiang
   Zhang, Jiarui
   Zhou, Chulun
   Cui, Jianwei
   Wang, Bin
   Su, Jinsong
GP Assoc Computat Linguist
TI Modeling Discourse Structure for Document-level Neural Machine
   Translation
SO WORKSHOP ON AUTOMATIC SIMULTANEOUS TRANSLATION CHALLENGES, RECENT
   ADVANCES, AND FUTURE DIRECTIONS
CT 1st Workshop on Automatic Simultaneous Translation Challenges, Recent
   Advances, and Future Directions (AutoSimTrans)
CY JUL 10, 2020
CL ELECTR NETWORK
AB Recently, document-level neural machine translation (NMT) has become a hot topic in the community of machine translation. De spite its success, most of existing studies ignored the discourse structure information of the input document to be translated, which has shown effective in other tasks. In this paper, we propose to improve document-level NMT with the aid of discourse structure in formation. Our encoder is based on a hierarchical attention network (HAN) (Miculicich et al., 2018). Specifically, we first parse the input document to obtain its discourse structure. Then, we introduce a Transformer-based path encoder to embed the discourse structure information of each word. Finally, we combine the discourse structure information with the word embedding before it is fed into the encoder. Experimental results on the English to-German dataset show that our model can significantly outperform both Transformer and Transformer+HAN.
BN 978-1-952148-23-1
PY 2020
BP 30
EP 36
UT WOS:000563392400005
ER

PT C
AU Costa, AD
   Marim, MC
   Matos, EED
   Torrent, TT
AF Costa, Alexandre Diniz
   Marim, Mateus Coutinho
   da Silva Matos, Ely Edison
   Torrent, Tiago Timponi
BA Mariani, J
BF Mariani, J
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mazo, H
   Odijk, H
   Piperidis, S
TI Domain Adaptation in Neural Machine Translation using a Qualia-Enriched
   FrameNet
SO LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION
CT 13th International Conference on Language Resources and Evaluation
   (LREC)
CY JUN 20-25, 2022
CL Marseille, FRANCE
SP Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur
AB In this paper we present Scylla, a methodology for domain adaptation of Neural Machine Translation (NMT) systems that make use of a multilingual FrameNet enriched with qualia relations as an external knowledge base. Domain adaptation techniques used in NMT usually require fine-tuning and in-domain training data, which may pose difficulties for those working with lesser-resourced languages and may also lead to performance decay of the NMT system for out-of-domain sentences. Scylla does not require fine-tuning of the NMT model, avoiding the risk of model over-fitting and consequent decrease in performance for out-of-domain translations. Two versions of Scylla are presented: one using the source sentence as input, and another one using the target sentence. We evaluate Scylla in comparison to a state-of-the-art commercial NMT system in an experiment in which 50 sentences from the Sports domain are translated from Brazilian Portuguese to English. The two versions of Scylla significantly outperform the baseline commercial system in HTER.
BN 979-10-95546-72-6
PY 2022
BP 1
EP 12
UT WOS:000889371700001
ER

PT C
AU Jonsson, HP
   Simonarson, HB
   Snaebjarnarson, V
   Steingrimsson, S
   Loftsson, H
AF Jonsson, Haukur Pall
   Simonarson, Haukur Barri
   Snaebjarnarson, Vesteinn
   Steingrimsson, Steinpor
   Loftsson, Hrafn
BE Sojka, P
   Kopecek, I
   Pala, K
   Horak, A
TI Experimenting with Different Machine Translation Models in
   Medium-Resource Settings
SO TEXT, SPEECH, AND DIALOGUE (TSD 2020)
SE Lecture Notes in Artificial Intelligence
CT 23rd Annual International Conference on Text, Speech, and Dialogue (TSD)
CY SEP 08-11, 2020
CL ELECTR NETWORK
SP Masaryk Univ, Fac Informat, Univ W Bohemia Plzen, Fac Appl Sci, Lexical Comp Ltd, IBM Ceska Republika spol s r o, Amazon Alexa
AB State-of-the-art machine translation (MT) systems rely on the availability of large parallel corpora, containing millions of sentence pairs. For the Icelandic language, the parallel corpus ParIce exists, consisting of about 3.6 million English-Icelandic sentence pairs. Given that parallel corpora for low-resource languages typically contain sentence pairs in the tens or hundreds of thousands, we classify Icelandic as a medium-resource language for MT purposes. In this paper, we present on-going experiments with different MT models, both statistical and neural, for translating English to Icelandic based on ParIce. We describe the corpus and the filtering process used for removing noisy segments, the different models used for training, and the preliminary automatic and human evaluation. We find that, while using an aggressive filtering approach, the most recent neural MT system (Transformer) performs best, obtaining the highest BLEU score and the highest fluency and adequacy scores from human evaluation for in-domain translation. Our work could be beneficial to other languages for which a similar amount of parallel data is available.
RI Steingrímsson, Steinþór/ACW-9084-2022
OI Jonsson, Haukur Pall/0000-0001-9615-3455; Loftsson,
   Hrafn/0000-0002-9298-4830; Steingrimsson, Steinthor/0000-0002-9776-9507
SN 0302-9743
EI 1611-3349
BN 978-3-030-58323-1; 978-3-030-58322-4
PY 2020
VL 12284
BP 95
EP 103
DI 10.1007/978-3-030-58323-1_10
UT WOS:000611543200010
ER

PT C
AU Li, B
   Lv, CH
   Zhou, ZF
   Zhou, T
   Xiao, T
   Ma, AX
   Zhu, JB
AF Li, Bei
   Lv, Chuanhao
   Zhou, Zefan
   Zhou, Tao
   Xiao, Tong
   Ma, Anxiang
   Zhu, Jingbo
GP Assoc Computat Linguist
TI On Vision Features in Multimodal Machine Translation
SO PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS)
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB Previous work on multimodal machine translation (MMT) has focused on the way of incorporating vision features into translation but little attention is on the quality of vision models. In this work, we investigate the impact of vision models on MMT. Given the fact that Transformer is becoming popular in computer vision, we experiment with various strong models (such as Vision Transformer) and enhanced features (such as object-detection and image captioning). We develop a selective attention model to study the patch-level contribution of an image in MMT. On detailed probing tasks, we find that stronger vision models are helpful for learning translation from the visual modality. Our results also suggest the need of carefully examining MMT models, especially when current benchmarks are small-scale and biased. Our code could be found at https://github.com/libeineu/fairseq_mmt.
BN 978-1-955917-21-6
PY 2022
BP 6327
EP 6337
UT WOS:000828702306034
ER

PT C
AU Sun, H
   Wang, R
   Chen, K
   Utiyama, M
   Sumita, E
   Zhao, T
AF Sun, Haipeng
   Wang, Rui
   Chen, Kehai
   Utiyama, Masao
   Sumita, Eiichiro
   Zhao, Tiejun
GP Assoc Computat Linguist
TI Self-Training for Unsupervised Neural Machine Translation in Unbalanced
   Training Data Scenarios
SO 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021)
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 06-11, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, N Amer Chapter, Google Res, Amazon Sci, Apple, Facebook AI, Megagon Labs, Microsoft, Bloomberg Engn, Grammarly, IBM, Vanguard, Duolingo, Babelscape, Human Language Technol, LegalForce
AB Unsupervised neural machine translation (UNMT) that relies solely on massive monolingual corpora has achieved remarkable results in several translation tasks. However, in real-world scenarios, massive monolingual corpora do not exist for some extremely low-resource languages such as Estonian, and UNMT systems usually perform poorly when there is not adequate training corpus for one language. In this paper, we first define and analyze the unbalanced training data scenario for UNMT. Based on this scenario, we propose UNMT self-training mechanisms to train a robust UNMT system and improve its performance in this case. Experimental results on several language pairs show that the proposed methods substantially outperform conventional UNMT systems.
BN 978-1-954085-46-6
PY 2021
BP 3975
EP 3981
UT WOS:000895685604009
ER

PT C
AU Mallinson, J
   Sennrich, R
   Lapata, M
AF Mallinson, Jonathan
   Sennrich, Rico
   Lapata, Mirella
GP Assoc Computat Linguist
TI Paraphrasing Revisited with Neural Machine Translation
SO 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS
CT 15th Conference of the European-Chapter of the
   Association-for-Computational-Linguistics (EACL)
CY APR 03-07, 2017
CL Valencia, SPAIN
SP Assoc Computat Linguist, European Chapter
AB Recognizing and generating paraphrases is an important component in many natural language processing applications. A well-established technique for automatically extracting paraphrases leverages bilingual corpora to find meaning-equivalent phrases in a single language by "pivoting" over a shared translation in another language. In this paper we revisit bilingual pivoting in the context of neural machine translation and present a paraphrasing model based purely on neural networks. Our model represents paraphrases in a continuous space, estimates the degree of semantic relatedness between text segments of arbitrary length, or generates candidate paraphrases for any source input. Experimental results across tasks and datasets show that neural paraphrases out-perform those obtained with conventional phrase-based pivoting approaches.
OI Sennrich, Rico/0000-0002-1438-4741
BN 978-1-945626-34-0
PY 2017
BP 881
EP 893
UT WOS:000712360800083
ER

PT C
AU Gong, ZX
   Zhou, GD
AF Gong, Zhengxian
   Zhou, Guodong
BE Li, J
   Ji, H
   Zhao, D
   Feng, Y
TI Document-Level Machine Translation Evaluation Metrics Enhanced with
   Simplified Lexical Chain
SO NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING, NLPCC 2015
SE Lecture Notes in Artificial Intelligence
CT 4th CCF International Conference on Natural Language Processing and
   Chinese Computing (NLPCC)
CY OCT 09-13, 2015
CL Jiangxi Normal Univ, Nanchang, PEOPLES R CHINA
SP China Comp Federat, State Key Lab Digital Publishing, Microsoft Res Asia, Sogou Inc, Mingbo Educ, Wanfang Data, SpeechOcean
HO Jiangxi Normal Univ
AB Document-level Machine Translation (MT) has been drawing more and more attention due to its potential of resolving sentence-level ambiguities and inconsistencies with the benefit of wide-range context. However, the lack of simple yet effective evaluation metrics largely impedes the development of such document-level MT systems. This paper proposes to improve traditional MT evaluation metrics by simplified lexical chain, modeling document-level phenomena from the perspectives of text cohesion. Experiments show the effectiveness of such method on evaluating document-level translation quality and its potential of integrating with traditional MT evaluation metrics to achieve higher correlation with human judgments.
RI 贡, 正仙/HNJ-1571-2023
OI zhou, guodong/0000-0002-7887-5099
SN 0302-9743
EI 1611-3349
BN 978-3-319-25207-0; 978-3-319-25206-3
PY 2015
VL 9362
BP 396
EP 403
DI 10.1007/978-3-319-25207-0_35
UT WOS:000380773500035
ER

PT C
AU Amin, MF
   Plis, SM
   Damaraju, E
   Hjelm, D
   Cho, K
   Calhoun, VD
AF Amin, Md Faijul
   Plis, Sergey M.
   Damaraju, Eswar
   Hjelm, Devon
   Cho, KyungHyun
   Calhoun, Vince D.
GP IEEE
TI Multimodal fusion of brain structural and functional imaging with a deep
   neural machine translation approach
SO 2016 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION
   (SSIAI)
SE IEEE Southwest Symposium on Image Analysis and Interpretation
CT IEEE Southwest Symposium on Image Analysis and Interpretation (SSIAI)
CY MAR 06-08, 2016
CL Santa Fe, NM
SP IEEE, IEEE Comp Soc
AB In this work, we study a novel approach of deep neural machine translation to find linkage between multimodal brain imaging data, such as structural MRI (sMRI) and functional MRI (fMRI). The idea is to consider two different imaging views of the same brain like two different languages conveying some common concepts or facts. An important aspect of the translation model is an attention network module that learns alignment between features from fMRI and sMRI. We use independent component analysis (ICA) based features for the translation model. Our study shows significant group differences between healthy controls and patients with schizophrenia in the learned alignments. Furthermore, this novel approach reveals a group differential relation between a cognitive score (attention and vigilance) and alignments that could not be found when individual modality of data were considered.
RI Calhoun, Vince D./ACN-9399-2022; Plis, Sergey/AAA-9928-2022
OI Calhoun, Vince D./0000-0001-9058-0747; Plis, Sergey/0000-0003-0040-0365
SN 1550-5782
BN 978-1-4673-9919-7
PY 2016
BP 1
EP 4
UT WOS:000381755500001
ER

PT C
AU Neubig, G
   Duh, K
AF Neubig, Graham
   Duh, Kevin
BE Toutanova, K
   Wu, H
TI On the Elements of an Accurate Tree-to-String Machine Translation System
SO PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS, VOL 2
CT 52nd Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUN 22-27, 2014
CL Baltimore, MD
SP Assoc Computat Linguist, Baidu, Bloomberg, Google, Microsoft, Nuance, Yahoo Labs, Informat Sci Inst, Xerox Res Ctr Europe, Brandeis Univ, Facebook, Yandex, Amazon Com, IBM Watson, Johns Hopkins Univ, A9, AI@ISI, Xerox
AB While tree-to-string (T2S) translation theoretically holds promise for efficient, accurate translation, in previous reports T2S systems have often proven inferior to other machine translation (MT) methods such as phrase-based or hierarchical phrase-based MT. In this paper, we attempt to clarify the reason for this performance gap by investigating a number of peripheral elements that affect the accuracy of T2S systems, including parsing, alignment, and search. Based on detailed experiments on the English-Japanese and Japanese-English pairs, we show how a basic T2S system that performs on par with phrase-based systems can be improved by 2.6-4.6 BLEU, greatly exceeding existing state-of-the-art methods. These results indicate that T2S systems indeed hold much promise, but the above-mentioned elements must be taken seriously in construction of these systems.
BN 978-1-937284-73-2
PY 2014
BP 143
EP 149
UT WOS:000493811100024
ER

PT J
AU Khullar, P
AF Khullar, Payal
TI Are Ellipses Important for Machine Translation?
SO COMPUTATIONAL LINGUISTICS
AB This article describes an experiment to evaluate the impact of different types of ellipses discussed in theoretical linguistics on Neural Machine Translation (NMT), using English to Hindi/Telugu as source and target languages. Evaluation with manual methods shows that most of the errors made by Google NMT are located in the clause containing the ellipsis, the frequency of such errors is slightly more in Telugu than Hindi, and the translation adequacy shows improvement when ellipses are reconstructed with their antecedents. These findings not only confirm the importance of ellipses and their resolution for MT, but also hint toward a possible correlation between the translation of discourse devices like ellipses with the morphological incongruity of the source and target. We also observe that not all ellipses are translated poorly and benefit from reconstruction, advocating for a disparate treatment of different ellipses in MT research.
SN 0891-2017
EI 1530-9312
PD DEC
PY 2021
VL 47
IS 4
BP 927
EP 937
DI 10.1162/COLI_a_00414
UT WOS:000753228200007
ER

PT S
AU Cote, N
AF Cote, N
BE Farwell, D
   Gerber, L
   Hovy, E
TI System description/demo of Alis Translation Solutions - Overview
SO MACHINE TRANSLATION AND THE INFORMATION SOUP
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
CT 3rd Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 28-31, 1998
CL LANGHORNE, PENNSYLVANIA
SP Systran Inc, Logos Corp, Globalink Inc, Univ Penn Inst Res Cognitive Sci
AB Part software, part process, Alis Translation Solutions (ATS) address the language barrier by tightly integrating a variety of language tools and services which include machine and human translation, on-line dictionaries, search engines, workflow and management tools. During the AMTA-98 conference, Alis Technologies is demonstrating various applications of ATS: Web and Intranet Publishing, Web Browsing, Company Document Circulation, E-mail Communication and Multilingual Site Search.
SN 0302-9743
BN 3-540-65259-0
PY 1998
VL 1529
BP 494
EP 497
UT WOS:000086659400044
ER

PT C
AU Libovicky, J
   Schmid, H
   Fraser, A
AF Libovicky, Jindrich
   Schmid, Helmut
   Fraser, Alexander
GP Assoc Computa Linguist
TI Why don't people use character-level machine translation?
SO FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022)
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB We present a literature and empirical survey that critically assesses the state of the art in character-level modeling for machine translation (MT). Despite evidence in the literature that character-level systems are comparable with subword systems, they are virtually never used in competitive setups in WMT competitions. We empirically show that even with recent modeling innovations in character-level natural language processing, character-level MT systems still struggle to match their subword-based counterparts. Character-level MT systems show neither better domain robustness, nor better morphological generalization, despite being often so motivated. However, we are able to show robustness towards source side noise and that translation quality does not degrade with increasing beam size at decoding time.
RI Libovický, Jindřich/O-5766-2019
OI Libovický, Jindřich/0000-0001-7717-4090
BN 978-1-955917-25-4
PY 2022
BP 2470
EP 2485
UT WOS:000828767402042
ER

PT C
AU Li, GL
   Liu, LM
   Huang, GP
   Zhu, CH
   Zhao, TJ
   Shi, SM
AF Li, Guanlin
   Liu, Lemao
   Huang, Guoping
   Zhu, Conghui
   Zhao, Tiejun
   Shi, Shuming
GP Assoc Computat Linguist
TI Understanding Data Augmentation in Neural Machine Translation: Two
   Perspectives towards Generalization
SO 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND
   THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE
CT Conference on Empirical Methods in Natural Language Processing / 9th
   International Joint Conference on Natural Language Processing
   (EMNLP-IJCNLP)
CY NOV 03-07, 2019
CL Hong Kong, HONG KONG
SP Google, Facebook, Apple, ASAPP, Salesforce, Huawei, Baidu, Deepmind, Amazon, PolyAI, Naver, ByteDance, Megagon Labs, Zhuiyi, Verisk, MI
AB Many Data Augmentation (DA) methods have been proposed for neural machine translation. Existing works measure the superiority of DA methods in terms of their performance on a specific test set, but we find that some DA methods do not exhibit consistent improvements across translation tasks. Based on the observation, this paper makes an initial attempt to answer a fundamental question: what benefits, which are consistent across different methods and tasks, does DA in general obtain? Inspired by recent theoretic advances in deep learning, the paper understands DA from two perspectives towards the generalization ability of a model: input sensitivity and prediction margin, which are defined independent of specific test set thereby may lead to findings with relatively low variance. Extensive experiments show that relatively consistent benefits across five DA methods and four translation tasks are achieved regarding both perspectives.
BN 978-1-950737-90-1
PY 2019
BP 5689
EP 5695
UT WOS:000854193305083
ER

PT C
AU Zhou, H
   Tu, ZP
   Huang, SJ
   Liu, XH
   Li, H
   Chen, JJ
AF Zhou, Hao
   Tu, Zhaopeng
   Huang, Shujian
   Liu, Xiaohua
   Li, Hang
   Chen, Jiajun
BE Barzilay, R
   Kan, MY
TI Chunk-Based Bi-Scale Decoder for Neural Machine Translation
SO PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2
CT 55th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 30-AUG 04, 2017
CL Vancouver, CANADA
SP Alibaba Grp, Amazon, Apple, Baidu, Bloomberg, Facebook, Google, Samsung, Tencent, eBay, Elsevier, IBM Res, KPMG, Maluuba, Microsoft, Naver Line, NEC, Recruit Inst Technol, SAP, Adobe, Bosch, CVTE, Duolingo, Huawei, Nuance, Oracle, Sogou, Grammarly, Toutiao, Yandex
AB In typical neural machine translation (NMT), the decoder generates a sentence word by word, packing all linguistic granularities in the same time-scale of RNN. In this paper, we propose a new type of decoder for NMT, which splits the decode state into two parts and updates them in two different time-scales. Specifically, we first predict a chunk time-scale state for phrasal modeling, on top of which multiple word time-scale states are generated. In this way, the target sentence is translated hierarchically from chunks to words, with information in different granularities being leveraged. Experiments show that our proposed model significantly improves the translation performance over the state-of-the-art NMT model.
RI Tu, Zhaopeng/AAS-4259-2021
BN 978-1-945626-76-0
PY 2017
BP 580
EP 586
DI 10.18653/v1/P17-2092
UT WOS:000493992300092
ER

PT C
AU Maletti, A
AF Maletti, Andreas
BE Brlek, S
   Reutenauer, C
TI Compositions of Tree-to-Tree Statistical Machine Translation Models
SO DEVELOPMENTS IN LANGUAGE THEORY, DLT 2016
SE Lecture Notes in Computer Science
CT 20th International Conference on Developments in Language Theory (DLT)
CY JUL 25-28, 2016
CL Montreal, CANADA
SP Lab Combinatoire Informatique Math
AB Compositions of well-known tree-to-tree translation models used in statistical machine translation are investigated. Synchronous context-free grammars are closed under composition in both the unweighted as well as the weighted case. In addition, it is demonstrated that there is a close connection between compositions of synchronous tree-substitution grammars and compositions of certain tree transducers because the intermediate trees can encode finite-state information. Utilizing these close ties, the composition closure of synchronous tree-substitution grammars is identified in the unweighted and weighted case. In particular, in the weighted case, these results build on a novel lifting strategy that will prove useful also in other setups.
RI Maletti, Andreas/AAP-8067-2020
SN 0302-9743
EI 1611-3349
BN 978-3-662-53132-7; 978-3-662-53131-0
PY 2016
VL 9840
BP 293
EP 305
DI 10.1007/978-3-662-53132-7_24
UT WOS:000389721100024
ER

PT C
AU Chiang, TR
   Chen, YP
   Yeh, YT
   Neubig, G
AF Chiang, Ting-Rui
   Chen, Yi-Pei
   Yeh, Yi-Ting
   Neubig, Graham
GP Assoc Computa Linguist
TI Breaking Down Multilingual Machine Translation
SO FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022)
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB While multilingual training is now an essential ingredient in machine translation (MT) systems, recent work has demonstrated that it has different effects in different multilingual settings, such as many-to-one, one-to-many, and many-to-many learning. These training settings expose the encoder and the decoder in a machine translation model with different data distributions. In this paper, we examine how different varieties of multilingual training contribute to learning these two components of the MT model. Specifically, we compare bilingual models with encoders and/or decoders initialized by multilingual training. We show that multilingual training is beneficial to encoders in general, while it only benefits decoders for low-resource languages (LRLs). We further find the important attention heads for each language pair and compare their correlations during inference. Our analysis sheds light on how multilingual translation models work and enables us to propose methods to improve performance by training with highly related languages. Our many-to-one models for high-resource languages and one-to-many models for LRL outperform the best results reported by Aharoni et al. (2019).
BN 978-1-955917-25-4
PY 2022
BP 2766
EP 2780
UT WOS:000828767402066
ER

PT C
AU Sennrich, R
   Haddow, B
   Birch, A
AF Sennrich, Rico
   Haddow, Barry
   Birch, Alexandra
BE Erk, K
   Smith, NA
TI Improving Neural Machine Translation Models with Monolingual Data
SO PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS, VOL 1
CT 54th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY AUG 07-12, 2016
CL Berlin, GERMANY
SP Assoc Computat Linguist, Google, Baidu, Amazon Com, Bloomberg, Facebook, Microsoft Res, eBay, Elsevier, IBM Res, MaluubA, Huawei Technologies, Nuance, Grammarly, VoiceBox Technologies, Yandex, Textkernel, Zalando SE
AB Neural Machine Translation (NMT) has obtained state-of-the art performance for several language pairs, while only using parallel data for training. Target-side monolingual data plays an important role in boosting fluency for phrase-based statistical machine translation, and we investigate the use of monolingual data for NMT. In contrast to previous work, which combines NMT models with separately trained language models, we note that encoder-decoder NMT architectures already have the capacity to learn the same information as a language model, and we explore strategies to train with monolingual data without changing the neural network architecture. By pairing monolingual training data with an automatic back-translation, we can treat it as additional parallel training data, and we obtain substantial improvements on the WMT 15 task English <-> German (+2.8-3.7 BLEU), and for the low-resourced IWSLT 14 task Turkish -> English (+2.1-3.4 BLEU), obtaining new state-of-the-art results. We also show that fine-tuning on in-domain monolingual and parallel data gives substantial improvements for the IWSLT 15 task English -> German.
OI Sennrich, Rico/0000-0002-1438-4741
BN 978-1-945626-00-5
PY 2016
BP 86
EP 96
UT WOS:000493806800009
ER

PT C
AU Hajic, J
   Hric, J
   Kubon, V
AF Hajic, J
   Hric, J
   Kubon, V
GP acl
TI Machine translation of very close languages
SO 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE
   NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000
   STUDENT RESEARCH WORKSHOP
CT 6th Applied Natural Language Processing Conference/1st Meeting of the
   North American Chapter of the
   Association-for-Computational-Linguistics/ANLP-NAACL 2000 Student
   Research Workshop
CY APR 29-MAY 04, 2000
CL Seattle, WA
SP Assoc Computat Linguist, N Amer Chapter
AB Using examples of the transfer-based MT system between Czech and Russian RUSLAN and the word-for-word MT system with morphological disambiguation between Czech and Slovak CESILKO we argue that for really close languages it is possible to obtain better translation quality by means of simpler methods. The problem of translation to a group of typologically similar languages using a pivot language is also discussed here.
RI Kubon, Vladislav/O-7373-2017; Hajic, Jan/D-3429-2017
OI Kubon, Vladislav/0000-0001-8696-3972; Hajic, Jan/0000-0002-3503-7730
BN 1-55860-704-8
PY 2000
BP 7
EP 12
UT WOS:000223099500002
ER

PT C
AU Sazzed, S
   Jayarathna, S
AF Sazzed, Salim
   Jayarathna, Sampath
GP IEEE Comp Soc
TI A Sentiment Classification in Bengali and Machine Translated English
   Corpus
SO 2019 IEEE 20TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND
   INTEGRATION FOR DATA SCIENCE (IRI 2019)
CT 20th IEEE International Conference on Information Reuse and Integration
   for Data Science (IEEE IRI)
CY JUL 30-AUG 01, 2019
CL Los Angeles, CA
SP IEEE, IEEE Comp Soc, Soc Informat Reuse & Integrat
AB The resource constraints in many languages have made the multi-lingual sentiment analysis approach a viable alternative for sentiment classification. Although a good amount of research has been conducted using a multi-lingual approach in languages like Chinese, Italian, Romanian, etc. very limited research has been done in Bengali. This paper presents a bilingual approach to sentiment analysis by comparing machine translated Bengali corpus to its original form. We apply multiple machine learning algorithms: Logistic Regression (LR), Ridge Regression (RR), Support Vector Machine (SVM), Random Forest (RF), Extra Randomized Trees (ET) and Long Short-Term Memory (LSTM) to a collection of Bengali corpus and corresponding machine translated English version. The results suggest that using machine translation improves classifiers performance in both datasets. Moreover, the results show that the unigram model performs better than higher-order n-gram model in both datasets due to linguistic variations and presence of misspelled words results from complex typing system of Bengali language; sparseness and noise in the machine translated data, and because of small datasets.
BN 978-1-7281-1337-1
PY 2019
BP 107
EP 114
DI 10.1109/IRI.2019.00029
UT WOS:000635408000015
ER

PT C
AU Abdulmumin, I
   Dash, SR
   Dawud, MA
   Parida, S
   Muhammad, SH
   Ahmad, IS
   Panda, S
   Bojar, O
   Galadanci, BS
   Bello, BS
AF Abdulmumin, Idris
   Dash, Satya Ranjan
   Dawud, Musa Abdullahi
   Parida, Shantipriya
   Muhammad, Shamsuddeen Hassan
   Ahmad, Ibrahim Sa'id
   Panda, Subhadarshi
   Bojar, Ondrej
   Galadanci, Bashir Shehu
   Bello, Shehu Bello
BA Mariani, J
BF Mariani, J
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mazo, H
   Odijk, H
   Piperidis, S
TI Hausa Visual Genome: A Dataset for Multi-Modal English to Hausa Machine
   Translation
SO LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION
CT 13th International Conference on Language Resources and Evaluation
   (LREC)
CY JUN 20-25, 2022
CL Marseille, FRANCE
SP Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur
AB Multi-modal Machine Translation (MMT) enables the use of visual information to enhance the quality of translations. The visual information can serve as a valuable piece of context information to decrease the ambiguity of input sentences. Despite the increasing popularity of such a technique, good and sizeable datasets are scarce, limiting the full extent of their potential. Hausa, a Chadic language, is a member of the Afro-Asiatic language family. It is estimated that about 100 to 150 million people speak the language, with more than 80 million indigenous speakers. This is more than any of the other Chadic languages. Despite a large number of speakers, the Hausa language is considered low-resource in natural language processing (NLP). This is due to the absence of sufficient resources to implement most NLP tasks. While some datasets exist, they are either scarce, machine-generated, or in the religious domain. Therefore, there is a need to create training and evaluation data for implementing machine learning tasks and bridging the research gap in the language. This work presents the Hausa Visual Genome (HaVG), a dataset that contains the description of an image or a section within the image in Hausa and its equivalent in English. To prepare the dataset, we started by translating the English description of the images in the Hindi Visual Genome (HVG) into Hausa automatically. Afterward, the synthetic Hausa data was carefully post-edited considering the respective images. The dataset comprises 32,923 images and their descriptions that are divided into training, development, test, and challenge test set. The Hausa Visual Genome is the first dataset of its kind and can be used for Hausa-English machine translation, multi-modal research, and image description, among various other natural language processing and generation tasks.
RI Abdulmumin, Idris/AAP-3518-2021
OI Abdulmumin, Idris/0000-0002-3795-8381
BN 979-10-95546-72-6
PY 2022
BP 6471
EP 6479
UT WOS:000889371706062
ER

PT C
AU Roth, B
   Klakow, D
AF Roth, Benjamin
   Klakow, Dietrich
BE Cunningham, H
   Hanbury, A
   Ruger, S
TI Combining Wikipedia-Based Concept Models for Cross-Language Retrieval
SO ADVANCES IN MULTIDISCIPLINARY RETRIEVAL
SE Lecture Notes in Computer Science
CT 1st Information Retrieval Facility Conference (IRFC 2010)
CY MAY 31, 2010
CL Vienna, AUSTRIA
SP Matrixware Informat Serv, ESTeam, Univ Sheffield, STI Int, Yahoo Labs, BCS
AB As a low-cost ressource that is up-to-date. Wikipedia recently gains attention as a. means to provide cross-language brigding for information retrieval. Contradictory to a previous study, we show that. standard Latent Dirichlet Allocation (LDA) can extract cross-language information that is valuable for IR. by simply normalizing the training data. Furthermore, we show that; LDA and Explicit Semantic Analysis (ESA) complement each other, yielding significant improvements when combined. Such a combination can significantly contribute to retrieval based on machine translation, especially when query translations contain errors. The experiments were perfomed on the Multext JOC corpus mid a CLEF dataset.
SN 0302-9743
EI 1611-3349
BN 978-3-642-13083-0
PY 2010
VL 6107
BP 47
EP 59
UT WOS:000279327000005
ER

PT C
AU Muhammad, U
   Bilal, K
   Khan, A
   Khan, MN
AF Muhammad, Uzair
   Bilal, Kashif
   Khan, Atif
   Khan, M. Nasir
BE Ardil, C
TI AGHAZ: An Expert System Based approach for the Translation of English to
   Urdu
SO PROCEEDINGS OF WORLD ACADEMY OF SCIENCE, ENGINEERING AND TECHNOLOGY, VOL
   6
CT Conference of the World-Academy-of-Science-Engineering-and-Technology
CY JUN 24-26, 2005
CL Sydney, AUSTRALIA
AB Machine Translation (MT (3)) of English text to its Urdu equivalent is a difficult challenge. Lot of attempts has been made, but a few limited solutions are provided till now. We present a direct approach, using an expert system to translate English text into its equivalent Urdu, using The Unicode Standard, Version 4.0 (ISBN 0-321-18578-1) Range: 0600-06FF. The expert system works with a knowledge base that contains grammatical patterns of English and Urdu, as well as a tense and gender-aware dictionary of Urdu words (with their English equivalents).
RI Muhammad, Uzair/J-6211-2012; Bilal, Kashif/AAA-6101-2020
PY 2005
BP 315
EP 319
UT WOS:000261051500076
ER

PT C
AU Rahimi, Z
   Khadivi, S
AF Rahimi, Zahra
   Khadivi, Shahram
GP IEEE
TI Discriminative Source Side Dependency Tree Reordering Model
SO 2014 7TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST)
CT 7th International Symposium on Telecommunications (IST)
CY SEP 09-11, 2014
CL Tehran, IRAN
SP IEEE, IEEE Iran Sect, Minist Informat & Commun Technol, ITRC, IAEEE
AB In this research a novel discriminative reordering model for statistical machine translation is proposed. Source dependency tree is used to define the orientation classes of the reordering model. We use maximum entropy principle to train the model. In addition to the common features used in the discriminative reordering models, two new and effective features are introduced. They are phrase number and orientation memory features. The proposed model is integrated to the decoding phase of the translation. The performance of this method and effect of each individual feature are evaluated on two Persian-English corpora. We observe a relative 5% improvement in terms of BLEU score.
BN 978-1-4799-5359-2
PY 2014
BP 30
EP 34
UT WOS:000392911900006
ER

PT C
AU Hara, K
   Iqbal, ST
AF Hara, Kotaro
   Iqbal, Shamsi T.
GP Assoc Comp Machinery
TI Effect of Machine Translation in Interlingual Conversation: Lessons from
   a Formative Study
SO CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS
   IN COMPUTING SYSTEMS
CT 33rd Annual CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 18-23, 2015
CL Seoul, SOUTH KOREA
SP Assoc Comp Machinery, Assoc Comp Machinery Special Interest Grp Comp Human Interact
AB Language barrier is the primary challenge for effective cross-lingual conversations. Spoken language translation (SLT) is perceived as a cost-effective alternative to less affordable human interpreters, but little research has been done on how people interact with such technology. Using a prototype translator application, we performed a formative evaluation to elicit how people interact with the technology and adapt their conversation style. We conducted two sets of studies with a total of 23 pairs (46 participants). Participants worked on storytelling tasks to simulate natural conversations with 3 different interface settings. Our findings show that collocutors naturally adapt their style of speech production and comprehension to compensate for inadequacies in SLT. We conclude the paper with the design guidelines that emerged from the analysis.
OI Hara, Kotaro/0000-0002-7893-6090
BN 978-1-4503-3145-6
PY 2015
BP 3473
EP 3482
DI 10.1145/2702123.2702407
UT WOS:000412395503056
ER

PT C
AU Wolk, K
   Wolk, A
   Marasek, K
AF Wolk, Krzysztof
   Wolk, Agnieszka
   Marasek, Krzysztof
BE Zgrzywa, A
   Choros, K
   Sieminski, A
TI Implementing Statistical Machine Translation into Mobile Augmented
   Reality Systems
SO MULTIMEDIA AND NETWORK INFORMATION SYSTEMS, MISSI 2016
SE Advances in Intelligent Systems and Computing
CT 10th International on Conference Multimedia and Network Information
   Systems (MISSI)
CY SEP 14-16, 2016
CL POLAND
SP Wroclaw Univ Sci & Technol
AB A statistical machine translation (SMT) capability would be very useful in augmented reality (AR) systems. For example, translating and displaying text in a smart phone camera image would be useful to a traveler needing to read signs and restaurant menus, or reading medical documents when a medical problem arises when visiting a foreign country. Such system would also be useful for foreign students to translate lectures in real time on their mobile devices. However, SMT quality has been neglected in AR systems research, which has focused on other aspects, such as image processing, optical character recognition (OCR), distributed architectures, and user interaction. In addition, general-purpose translation services, such as Google Translate, used in some AR systems are not well-tuned to produce high-quality translations in specific domains and are Internet connection dependent. This research devised SMT methods and evaluated their performance for potential use in AR systems. We give particular attention to domain-adapted SMT systems, in which an SMT capability is tuned to a particular domain of text to increase translation quality. We focus on translation between the Polish and English languages, which presents a number of challenges due to fundamental linguistic differences. However, the SMT systems used are readily extensible to other language pairs. SMT techniques are applied to two domains in translation experiments: European Medicines Agency (EMEA) medical leaflets and the Technology, Entertainment, Design (TED) lectures. In addition, field experiments are conducted on random samples of Polish text found in city signs, posters, restaurant menus, lectures on biology and computer science, and medical leaflets. Texts from these domains are translated by a number of SMT system variants, and the systems' performance is evaluated by standard translation performance metrics and compared. The results appear very promising and encourage future applications of SMT to AR systems.
RI Wołk, Krzysztof/E-9957-2015; Marasek, Krzysztof/H-9949-2014
OI Wołk, Krzysztof/0000-0001-5030-334X; Marasek,
   Krzysztof/0000-0003-1344-3524; Wolk, Agnieszka/0000-0002-9667-2068
SN 2194-5357
EI 2194-5365
BN 978-3-319-43982-2; 978-3-319-43981-5
PY 2017
VL 506
BP 61
EP 73
DI 10.1007/978-3-319-43982-2_6
UT WOS:000398736400006
ER

PT C
AU Chang, CC
   Chuang, SP
   Lee, HY
AF Chang, Chih-Chiang
   Chuang, Shun-Po
   Lee, Hung-yi
GP Associ Computat Linguist
TI Anticipation-Free Training for Simultaneous Machine Translation
SO PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE
   TRANSLATION (IWSLT 2022)
CT 19th International Conference on Spoken Language Translation (IWSLT)
CY MAY 26-27, 2022
CL Dublin, IRELAND
SP Apple, AWS, Meta, Zoom, Microsoft, AppTek
AB Simultaneous machine translation (SimulMT) speeds up the translation process by starting to translate before the source sentence is completely available. It is difficult due to limited context and word order difference between languages. Existing methods increase latency or introduce adaptive read-write policies for SimulMT models to handle local reordering and improve translation quality. However, the long-distance reordering would make the SimulMT models learn translation mistakenly. Specifically, the model may be forced to predict target tokens when the corresponding source tokens have not been read. This leads to aggressive anticipation during inference, resulting in the hallucination phenomenon. To mitigate this problem, we propose a new framework that decompose the translation process into the monotonic translation step and the reordering step, and we model the latter by the auxiliary sorting network (ASN). The ASN rearranges the hidden states to match the order in the target language, so that the SimulMT model could learn to translate more reasonably. The entire model is optimized end-to-end and does not rely on external aligners or data. During inference, ASN is removed to achieve streaming. Experiments show the proposed framework could outperform previous methods with less latency.
BN 978-1-955917-41-4
PY 2022
BP 43
EP 61
UT WOS:000846899900005
ER

PT C
AU Liu, XD
   Zhu, Y
   Jin, YH
AF Liu, Xiao-die
   Zhu, Yun
   Jin, Yao-hong
GP DEStech Publicat, Inc
TI Research on Recognition of Chunks for Reordering in Chinese-English
   Patent Machine Translation
SO INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND SOFTWARE
   ENGINEERING (AISE 2014)
CT International Conference on Artificial Intelligence and Software
   Engineering (AISE)
CY JAN 11-12, 2014
CL Phuket, THAILAND
AB We focused on when to reorder the Chinese NPs "A+(de)+ B", "A+(de)+ B+(de)+ C" or "A+(de)+ B+(de)+ C+(de)+ D" wherein A, B, C and D are separate and smallest chunks for reordering. By comparing Chinese NPs and their English translations, we analyzed the semantic features of the chunks for reordering and summed three types Boundary Words. Using a rule-based method, we built 53 formalized rules with the Boundary Words and the contexts to identify the chunks. At last, we tested our work in a rule-based MT system, and the experimental results showed that our rule-based method was very efficient.
BN 978-1-60595-150-8
PY 2014
BP 179
EP 183
UT WOS:000337476200033
ER

PT C
AU Rong, L
   Chang, MF
   Cai, W
AF Rong, L
   Chang, MF
   Cai, W
BE Wen, TD
TI Machine Translation based on GSM
SO ISTM/2005: 6th International Symposium on Test and Measurement, Vols
   1-9, Conference Proceedings
CT 6th International Symposium on Test and Measurement (ISTM)
CY JUN 01-04, 2005
CL Dalian, PEOPLES R CHINA
SP Chinese Soc Modern Tech Equipment, Chinese Assoc Higher Educ, CSMTE, Test & Measurement Sect, Soc Instrumentat, Measurement & Control, N Univ China, Key Lab Instrumentat Sci & Dynam Measurement, Minist Educ, Natl Key Lab Elect Measurement Technol, Taiyuan Div, Candidate State Key Lab Dynam Measurement, Dalian Univ Tehnol, State Key Lab Coastal & Offshore Engn, NUC, Dept Elect Sci & Technol
AB Machine Translation(MT) is a technology that automatically translate text from one human language into another For instance, an English-to-Chinese MT system translates from English(the source language) into Chinese(the target language). Nowadays, there are plenty of researches on Machine Translation. Among them, the advanced MT methods are large-scale corpus-based and statistic-based. In this article, the origin, the development and the current situation of MT both in our country and in western countries are discussed. Moreover, the existing problems about artificial intelligence and MT are discussed. Based on this talked above, the future trend is also put forward. In addition, the various methods of MT are introduced with the concern of the character and basic principle. Besides that, some typical structures and character of algorithm for MT are discussed in detail. Finally, the author offers a new way for MT That is to carry out MT with the help of GSM in order to make the real-time translation into practice. Hence, the wireless communications based on GSM is studied. Then, the connection between MT and GSM is set up. The key point is to combine the GSM with the MT machine. In this way, GSM-based wireless communications for MT is coming. The comparison between the traditional MT method and this GSM-based method is going. Traditional MT methods are usually based on corpus, electrical dictionary and translation system which can hardly make the interaction between human beings and machines. The GSM-based method adopts practical industry control system that can make the MT go into control system and make the MT system be tested by emulation. The frame built on GSM can put the theory into practical system. As a result, the speed and quality of MT can be improved to a great extent. The attraction of this method can make the interaction between human beings and machine be practical. So MT can be used in a new field.
BN 7-5062-7445-0
PY 2005
BP 1629
EP 1631
UT WOS:000232030701164
ER

PT J
AU Saywell, A
   Bakker, A
   Mielke, J
   Kumagai, T
   Wolf, M
   Garcia-Lopez, V
   Chiang, PT
   Tour, JM
   Grill, L
AF Saywell, Alex
   Bakker, Anne
   Mielke, Johannes
   Kumagai, Takashi
   Wolf, Martin
   Garcia-Lopez, Victor
   Chiang, Pinn-Tsong
   Tour, James M.
   Grill, Leonhard
TI Light-Induced Translation of Motorized Molecules on a Surface
SO ACS NANO
AB Molecular machines are a key component in the vision of molecular nanotechnology and have the potential to transport molecular species and cargo on surfaces. The motion of such machines should be triggered remotely, ultimately allowing a large number of molecules to be propelled by a single source, with light being an attractive stimulus. Here, we report upon the photoinduced translation of molecular machines across a surface by characterizing single molecules before and after illumination. Illumination of molecules containing a motor unit results in an enhancement in the diffusion of the molecules. The effect vanishes if an incompatible photon energy is used or if the motor unit is removed from the molecule, revealing that the enhanced motion is due to the presence of the wavelength-sensitive motor in each molecule.
RI Saywell, Alex/M-5004-2015; Grill, Leonhard/A-9014-2012; García-López,
   Víctor/ABL-0304-2022; Wolf, Martin/Q-3548-2016; Kumagai,
   Takashi/AAY-3162-2021
OI Saywell, Alex/0000-0002-2242-3149; Grill, Leonhard/0000-0002-9247-6502;
   Kumagai, Takashi/0000-0001-7029-062X; Garcia-Lopez,
   Victor/0000-0003-2915-4591
SN 1936-0851
EI 1936-086X
PD DEC
PY 2016
VL 10
IS 12
BP 10945
EP 10952
DI 10.1021/acsnano.6b05650
UT WOS:000391079700038
PM 27783488
ER

PT C
AU Su, TH
   Liu, SC
   Zhou, SJ
AF Su, Tonghua
   Liu, Shuchen
   Zhou, Shengjie
BE Llados, J
   Lopresti, D
   Uchida, S
TI RTNet: An End-to-End Method for Handwritten Text Image Translation
SO DOCUMENT ANALYSIS AND RECOGNITION - ICDAR 2021, PT II
SE Lecture Notes in Computer Science
CT 16th IAPR International Conference on Document Analysis and Recognition
   (ICDAR)
CY SEP 05-10, 2021
CL Lausanne, SWITZERLAND
SP IAPR
AB Text image recognition and translation have a wide range of applications. It is straightforward to work out a two-stage approach: first perform the text recognition, then translate the text to target language. The handwritten text recognition model and the machine translation model are trained separately. Any transcription error may degrade the translation quality. This paper proposes an end-to-end leaning architecture that directly translates English handwritten text in images into Chinese. The handwriting recognition task and translation task are combined in a unified deep learning model. Firstly we conduct a visual encoding, next bridge the semantic gaps using a feature transformer and finally present a textual decoder to generate the target sentence. To train the model effectively, we use transfer learning to improve the generalization of the model under low-resource conditions. The experiments are carried out to compare our method to the traditional two-stage one. The results indicate that the performance of end-to-end model greatly improved as the amount of training data increases. Furthermore, when larger amount of training data is available, the end-to-end model is more advantageous.
OI Su, Tonghua/0000-0002-8869-1664
SN 0302-9743
EI 1611-3349
BN 978-3-030-86331-9
PY 2021
VL 12822
BP 99
EP 113
DI 10.1007/978-3-030-86331-9_7
UT WOS:000770800600007
ER

PT J
AU Way, A
AF Way, A
TI A hybrid architecture for robust MT using LFG-DOP
SO JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE
AB We develop a model for machine translation (MT) based on data-oriented parsing (DOP) allied to the syntactic representations of lexical functional grammar (LFG). We begin by showing that in themselves, none of the main paradigmatic approaches to MT currently suffice to the standard required. Nevertheless, each of these approaches contains elements which if properly harnessed should lead to an overall improvement in translation performance. It is in this new hybrid spirit that our search for a better solution to the problems of MT can be seen. We summarize the original DOP model of Bed, as well as the DOT model of translation of Poutsma on which it is based. We demonstrate that DOT is not guaranteed to produce the correct translation, despite provably deriving the most probable translation. We go on to critically evaluate previous attempts at LFG-MT, commenting briefly on particular problem cases for such systems. We then show how the LFG-DOP model of Bod and Kaplan can be extended to serve as a novel hybrid model for MT which promises to improve upon DOT, as well as the pure LFG-based translation model.
OI Way, Andy/0000-0001-5736-5930
SN 0952-813X
PD JUL-SEP
PY 1999
VL 11
IS 3
BP 441
EP 471
DI 10.1080/095281399146490
UT WOS:000082858000007
ER

PT C
AU Beloucif, M
   Wu, DK
AF Beloucif, Meriem
   Wu, Dekai
GP IEEE
TI SEMANTICALLY DRIVEN INVERSION TRANSDUCTION GRAMMAR INDUCTION FOR EARLY
   STAGE TRAINING OF SPOKEN LANGUAGE TRANSLATION
SO 2016 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2016)
SE IEEE Workshop on Spoken Language Technology
CT IEEE Workshop on Spoken Language Technology (SLT)
CY DEC 13-16, 2016
CL San Diego, CA
SP Inst Elect & Elect Engineers, IEEE Signal Proc Soc
AB We propose an approach in which we inject a crosslingual semantic frame based objective function directly into inversion transduction grammar (ITG) induction in order to semantically train spoken language translation systems. This approach represents a follow-up of our recent work on improving machine translation quality by tuning loglinear mixture weights using a semantic frame based objective function in the late, final stage of statistical machine translation training. In contrast, our new approach injects a semantic frame based objective function back into earlier stages of the training pipeline, during the actual learning of the translation model, biasing learning toward semantically more accurate alignments. Our work is motivated by the fact that ITG alignments have empirically been shown to fully cover crosslingual semantic frame alternations. We show that injecting a crosslingual semantic based objective function for driving ITG induction further sharpens the ITG constraints, leading to better performance than either the conventional ITG or the traditional GIZA++ based approaches.
SN 2639-5479
BN 978-1-5090-4903-5
PY 2016
BP 265
EP 272
UT WOS:000399128000039
ER

PT J
AU Wu, CK
   Shih, CC
   Wang, YC
   Tsai, RTH
AF Wu, Chun-Kai
   Shih, Chao-Chuang
   Wang, Yu-Chun
   Tsai, Richard Tzong-Han
TI Improving low-resource machine transliteration by using 3-way transfer
   learning
SO COMPUTER SPEECH AND LANGUAGE
AB Transfer learning brings improvement to machine translation by using a resource-rich language pair to pretrain the model and then adapting it to the desired language pair. However, to date, there have been few attempts to tackle machine transliteration with transfer learning. In this article, we propose a method of using source-pivot and pivot-target datasets to improve source-target machine transliteration. Our approach first bridges the source-pivot and pivot- target datasets by reducing the distance between source and pivot embeddings. Then, our model learns to translate from the pivot language to the target language. Finally, the source-target dataset is used to fine tune the model. Our experiments show that our method is superior to the transfer learning method. When implemented with a state-of-the-art source-target translation model from NEWS'18, our transfer learning method can improve the accuracy by 1.1%.
OI Tsai, Richard Tzong-Han/0000-0003-0513-107X; ,
   Chun-Kai/0000-0003-4074-9094
SN 0885-2308
EI 1095-8363
PD MAR
PY 2022
VL 72
AR 101283
DI 10.1016/j.csl.2021.101283
EA SEP 2021
UT WOS:000728821200019
ER

PT C
AU Shu, R
   Lee, J
   Nakayama, H
   Cho, K
AF Shu, Raphael
   Lee, Jason
   Nakayama, Hideki
   Cho, Kyunghyun
GP Assoc Advancement Artificial Intelligence
TI Latent-Variable Non-Autoregressive Neural Machine Translation with
   Deterministic Inference Using a Delta Posterior
SO THIRTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THE
   THIRTY-SECOND INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE
   CONFERENCE AND THE TENTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN
   ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 34th AAAI Conference on Artificial Intelligence / 32nd Innovative
   Applications of Artificial Intelligence Conference / 10th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 07-12, 2020
CL New York, NY
SP Assoc Advancement Artificial Intelligence
AB Although neural machine translation models reached high translation quality, the autoregressive nature makes inference difficult to parallelize and leads to high translation latency. Inspired by recent refinement-based approaches, we propose LaNMT, a latent-variable non-autoregressive model with continuous latent variables and deterministic inference procedure. In contrast to existing approaches, we use a deterministic inference algorithm to find the target sequence that maximizes the lowerbound to the log-probability. During inference, the length of translation automatically adapts itself. Our experiments show that the lowerbound can be greatly increased by running the inference algorithm, resulting in significantly improved translation quality. Our proposed model closes the performance gap between non-autoregressive and autoregressive approaches on ASPEC Ja-En dataset with 8.6x faster decoding. On WMT'14 En-De dataset, our model narrows the gap with autoregressive baseline to 2.0 BLEU points with 12.5x speedup. By decoding multiple initial latent variables in parallel and rescore using a teacher model, the proposed model further brings the gap down to 1.0 BLEU point on WMT'14 En-De task with 6.8x speedup.
OI Nakayama, Hideki/0000-0001-8726-2780
SN 2159-5399
EI 2374-3468
BN 978-1-57735-835-0
PY 2020
VL 34
BP 8846
EP 8853
UT WOS:000668126801035
ER

PT C
AU Saleva, J
   Lignos, C
AF Saleva, Jonne
   Lignos, Constantine
GP ASSOC COMPUTAT LINGUIST
TI The Effectiveness of Morphology-aware Segmentation in Low-Resource
   Neural Machine Translation
SO EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE
   ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE STUDENT
   RESEARCH WORKSHOP
CT 16th Conference of the
   European-Chapter-of-the-Association-for-Computational-Linguistics (EACL)
CY APR 19-23, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, European Chapter, Grammarly, Facebook AI, Bloomberg Engn, LegalForce, Babelscape
AB This paper evaluates the performance of several modern subword segmentation methods in a low-resource neural machine translation setting. We compare segmentations produced by applying BPE at the token or sentence level with morphologically-based segmentations from LMVR and MORSEL. We evaluate translation tasks between English and each of Nepali, Sinhala, and Kazakh, and predict that using morphologically-based segmentation methods would lead to better performance in this setting. However, comparing to BPE, we find that no consistent and reliable differences emerge between the segmentation methods. While morphologically-based methods outperform BPE in a few cases, what performs best tends to vary across tasks, and the performance of segmentation methods is often statistically indistinguishable.
BN 978-1-954085-04-6
PY 2021
BP 164
EP 174
UT WOS:000861067300022
ER

PT J
AU Popovic, M
   Ney, H
AF Popovic, Maja
   Ney, Hermann
TI Towards Automatic Error Analysis of Machine Translation Output
SO COMPUTATIONAL LINGUISTICS
AB Evaluation and error analysis of machine translation output are important but difficult tasks. In this article, we propose a framework for automatic error analysis and classification based on the identification of actual erroneous words using the algorithms for computation of Word Error Rate (WER) and Position-independent word Error Rate (PER), which is just a very first step towards development of automatic evaluation measures that provide more specific information of certain translation problems. The proposed approach enables the use of various types of linguistic knowledge in order to classify translation errors in many different ways. This work focuses on one possible set-up, namely, on five error categories: inflectional errors, errors due to wrong word order, missing words, extra words, and incorrect lexical choices. For each of the categories, we analyze the contribution of various POS classes. We compared the results of automatic error analysis with the results of human error analysis in order to investigate two possible applications: estimating the contribution of each error type in a given translation output in order to identify the main sources of errors for a given translation system, and comparing different translation outputs using the introduced error categories in order to obtain more information about advantages and disadvantages of different systems and possibilites for improvements, as well as about advantages and disadvantages of applied methods for improvements. We used Arabic-English Newswire and Broadcast News and Chinese-English Newswire outputs created in the framework of the GALE project, several Spanish and English European Parliament outputs generated during the TC-Star project, and three German-English outputs generated in the framework of the fourth Machine Translation Workshop. We show that our results correlate very well with the results of a human error analysis, and that all our metrics except the extra words reflect well the differences between different versions of the same translation system as well as the differences between different translation systems.
OI Popovic, Maja/0000-0001-8234-8745
SN 0891-2017
EI 1530-9312
PD DEC
PY 2011
VL 37
IS 4
BP 657
EP 688
DI 10.1162/COLI_a_00072
UT WOS:000298118200002
ER

PT J
AU Farhan, W
   Talafha, B
   Abuammar, A
   Jaikat, R
   Al-Ayyoub, M
   Tarakji, AB
   Toma, A
AF Farhan, Wael
   Talafha, Bashar
   Abuammar, Analle
   Jaikat, Ruba
   Al-Ayyoub, Mahmoud
   Tarakji, Ahmad Bisher
   Toma, Anas
TI Unsupervised dialectal neural machine translation
SO INFORMATION PROCESSING & MANAGEMENT
AB In this paper, we present the first work on unsupervised dialectal Neural Machine Translation (NMT), where the source dialect is not represented in the parallel training corpus. Two systems are proposed for this problem. The first one is the Dialectal to Standard Language Translation (D2SLT) system, which is based on the standard attentional sequence-to-sequence model while introducing two novel ideas leveraging similarities among dialects: using common words as anchor points when learning word embeddings and a decoder scoring mechanism that depends on cosine similarity and language models. The second system is based on the celebrated Google NMT (GNMT) system. We first evaluate these systems in a supervised setting (where the training and testing are done using our parallel corpus of Jordanian dialect and Modern Standard Arabic (MSA)) before going into the unsupervised setting (where we train each system once on a SaudiMSA parallel corpus and once on an Egyptian-MSA parallel corpus and test them on the Jordanian-MSA parallel corpus). The highest BLEU score obtained in the unsupervised setting is 32.14 (by D2SLT trained on Saudi-MSA data), which is remarkably high compared with the highest BLEU score obtained in the supervised setting, which is 48.25.
OI Talafha, Bashar/0000-0002-4227-892X; Jaikat, Ruba/0000-0002-1132-3273
SN 0306-4573
EI 1873-5371
PD MAY
PY 2020
VL 57
IS 3
AR 102181
DI 10.1016/j.ipm.2019.102181
UT WOS:000528550100003
ER

PT J
AU Way, A
   Gough, N
AF Way, A
   Gough, N
TI WEBMT: Developing and validating an example-based machine translation
   system using the world wide Web
SO COMPUTATIONAL LINGUISTICS
AB We have developed an example-based machine translation (EBMT) system that uses the World Wide Web for two different purposes: First, we populate the system's memory with translations gathered from rule-based MT systems located on the Web. The source strings input to these systems were extracted automatically from an extremely small subset of the rule types in the Penn-II Treebank. In subsequent stages, the (source, target) translation pairs obtained are automatically transformed into a series of resources that render the translation process more successful. Despite the fact that the output from on-line MT systems is often faulty, we demonstrate in a number of experiments that when used to seed the memories of an EBMT system, they can in fact prove useful in generating translations of high quality in a robust fashion. In addition, we demonstrate the relative gain of EBMT in comparison to on-line systems. Second, despite the perception that the documents available on the Web are of questionable quality, we demonstrate in contrast that such resources are extremely useful in automatically postediting translation candidates proposed by our system.
OI Way, Andy/0000-0001-5736-5930
SN 0891-2017
EI 1530-9312
PD SEP
PY 2003
VL 29
IS 3
BP 421
EP 457
DI 10.1162/089120103322711596
UT WOS:000186631500004
ER

PT C
AU Guimaraes, WW
   Pinto, CLN
   Nobre, CN
   Zarate, LE
AF Guimaraes, Wallison W.
   Pinto, Cristiano L. N.
   Nobre, Cristiane N.
   Zarate, Luis E.
GP IEEE
TI The relevance of upstream and downstream regions of mRNA in the
   Prediction of Translation Initiation Site of the Protein
SO 2017 IEEE 17TH INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND
   BIOENGINEERING (BIBE)
SE IEEE International Conference on Bioinformatics and Bioengineering
CT 17th IEEE International Conference on Bioinformatics and Bioengineering
   (BIBE)
CY OCT 23-25, 2017
CL Herndon, VA
SP IEEE, IEEE Comp Soc, Biol & Artificial Intelligence Soc
AB The correct prediction of Protein Translation Initiation Site is a problem of considerable interest in the molecular biology. In the literature, some papers investigate conservative positions of the mRNA that favor an ideal context for begin of translation, such as Kozak's. The Kozak Consensus is known to reveal some important mRNA upstream region positions to recognize an early translation. This paper investigated the real contribution of these conservative positions, besides analyzing sequences in the downstream region to be considered as non initiators of translation. In this paper, we use the Support Vector Machine classifier and three different scenarios. The results indicate that the proposed methodology was efficient, guaranteeing a gain in the performance of the larger organisms. For the smaller organisms, the three scenarios investigated maintain the same behavior. However, due to the lack of consideration of the upstream region of the mRNA, the proposed methodology allows evaluating organisms not considered in other papers, such as the Caenorhabditis elegans organism.
RI Zarate, Luis/ABA-4565-2020
OI Zarate, Luis/0000-0001-7063-1658
SN 2471-7819
BN 978-1-5386-1324-5
PY 2017
BP 112
EP 118
DI 10.1109/BIBE.2017.00026
UT WOS:000427878000019
ER

PT C
AU Khoroshilov, AA
   Kozerenko, EB
   Nikitin, YV
   Kalinin, YP
   Khoroshilov, AA
AF Khoroshilov, Alexander A.
   Kozerenko, Elena B.
   Nikitin, Yuri, V
   Kalinin, Yuri P.
   Khoroshilov, Alexei A.
GP IEEE
TI Introduction of Phrase Structures into the Example-Based Machine
   Translation System
SO 2019 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND
   COMPUTATIONAL INTELLIGENCE (CSCI 2019)
CT 6th Annual Conference on Computational Science and Computational
   Intelligence (CSCI)
CY DEC 05-07, 2019
CL Las Vegas, NV
AB The formal model of the syntax structure of texts based on representations of phrase structures as generalized syntagms and methods of their automatic construction are described. A new solution to a number of current problems of automatic processing of text information in the field of information search and machine translation, as well as an approach to the problem of unification of syntax structures of sentences and phrase structures constituting the sentences has been proposed. Declarative tools which are a complex of dictionaries and grammatical tables in machine form were created on the basis of large-scale studies of extensive volumes of scientific and technical texts using linguistic and statistical methods.
OI Nikitin, Yury/0000-0002-7641-0247
BN 978-1-7281-5584-5
PY 2019
BP 445
EP 450
DI 10.1109/CSCI49370.2019.00087
UT WOS:000569996300080
ER

PT C
AU Xu, HR
   Van Durme, B
   Murray, K
AF Xu, Haoran
   van Durme, Benjamin
   Murray, Kenton
GP Assoc Computat Linguist
TI BERT, MBERT, or BIBERT? A Study on Contextualized Embeddings for Neural
   Machine Translation
SO 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2021)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 07-11, 2021
CL Punta Cana, DOMINICAN REP
AB The success of bidirectional encoders using masked language models, such as BERT, on numerous natural language processing tasks has prompted researchers to attempt to incorporate these pre-trained models into neural machine translation (NMT) systems. However, proposed methods for incorporating pretrained models are non-trivial and mainly focus on BERT, which lacks a comparison of the impact that other pre-trained models may have on translation performance. In this paper, we demonstrate that simply using the output (contextualized embeddings) of a tailored and suitable bilingual pre-trained language model (dubbed BIBERT) as the input of the NMT encoder achieves state-of-the-art translation performance. Moreover, we also propose a stochastic layer selection approach and a concept of dual-directional translation model to ensure the sufficient utilization of contextualized embeddings. In the case of without using back translation, our best models achieve BLEU scores of 30.45 for En -> De and 38.61 for De -> En on the IWSLT'14 dataset, and 31.26 for En -> De and 34.94 for De -> En on the WMT'14 dataset, which exceeds all published numbers(12).
BN 978-1-955917-09-4
PY 2021
BP 6663
EP 6675
UT WOS:000860727000049
ER

PT C
AU Panda, S
   Gomez, FP
   Flor, M
   Rozovskaya, A
AF Panda, Subhadarshi
   Gomez, Frank Palma
   Flor, Michael
   Rozovskaya, Alla
GP Assoc Computat Linguist
TI Automatic Generation of Distractors for Fill-in-the-Blank Exercises with
   Round-Trip Neural Machine Translation
SO PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2022): STUDENT RESEARCH WORKSHOP
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB In a fill-in-the-blank exercise, a student is presented with a carrier sentence with one word hidden, and a multiple-choice list that includes the correct answer and several inappropriate options, called distractors. We propose to automatically generate distractors using roundtrip neural machine translation: the carrier sentence is translated from English into another (pivot) language and back, and distractors are produced by aligning the original sentence and its round-trip translation. We show that using hundreds of translations for a given sentence allows us to generate a rich set of challenging distractors. Further, using multiple pivot languages produces a diverse set of candidates. The distractors are evaluated against a real corpus of cloze exercises and checked manually for validity. We demonstrate that the proposed method significantly outperforms two strong baselines.(1)
RI Panda, Subhadarshi/GYQ-5080-2022; Flor, Michael/HME-2980-2023
OI Flor, Michael/0000-0002-3320-5729
BN 978-1-955917-23-0
PY 2022
BP 391
EP 401
UT WOS:000828747900031
ER

PT C
AU Wolfel, M
   Kolss, M
   Kraft, F
   Niehues, J
   Paulik, M
   Waibel, A
AF Woelfel, Matthias
   Kolss, Muntsin
   Kraft, Florian
   Niehues, Jan
   Paulik, Matthias
   Waibel, Alex
GP IEEE
TI SIMULTANEOUS MACHINE TRANSLATION OF GERMAN LECTURES INTO ENGLISH:
   INVESTIGATING RESEARCH CHALLENGES FOR THE FUTURE
SO 2008 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY: SLT 2008, PROCEEDINGS
CT IEEE Workshop on Spoken Language Technology
CY DEC 15-19, 2008
CL Goa, INDIA
SP IEEE, IEEE Signal Proc Soc
AB An increasingly globalized world fosters the exchange of students, researchers or employees. As a result, situations in which people of different native tongues are listening to the same lecture become more and more frequent. In many such situations, human interpreters are prohibitively expensive or simply not available. For this reason, and because first prototypes have already demonstrated the feasibility of such systems, automatic translation of lectures receives increasing attention. A large vocabulary and strong variations in speaking style make lecture translation a challenging, however not hopeless, task.
   The scope of this paper is to investigate a variety of challenges and to highlight possible solutions in building a system for simultaneous translation of lectures from German to English. While some of the investigated challenges are more general, e.g. environment robustness, other challenges are more specific for this particular task, e.g. pronunciation of foreign words or sentence segmentation. We also report our progress in building art end-to-end system and analyze its performance in terms of objective and subjective measures.
OI Wolfel, Matthias/0000-0003-1601-5146
BN 978-1-4244-3471-8
PY 2008
BP 233
EP 236
DI 10.1109/SLT.2008.4777883
UT WOS:000266764600059
ER

PT C
AU Cao, Q
   Kuang, SH
   Xiong, DY
AF Cao, Qian
   Kuang, Shaohui
   Xiong, Deyi
BE DeGiacomo, G
   Catala, A
   Dilkina, B
   Milano, M
   Barro, S
   Bugarin, A
   Lang, J
TI Learning to Reuse Translations: Guiding Neural Machine Translation with
   Examples
SO ECAI 2020: 24TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE
SE Frontiers in Artificial Intelligence and Applications
CT 24th European Conference on Artificial Intelligence (ECAI)
CY AUG 29-SEP 08, 2020
CL European Assoc Artificial Intelligence, ELECTR NETWORK
SP Spanish Assoc Artificial Intelligence, Univ Santiago Compostela, Res Ctr Intelligent Technologies
HO European Assoc Artificial Intelligence
AB In this paper, we study the problem of enabling neural machine translation (NMT) to reuse previous translations from similar examples in target prediction. Distinguishing reusable translations from noisy segments and learning to reuse them in NMT are non-trivial. To solve these challenges, we propose an Example-Guided NMT (EGNMT) framework with two models: (1) a noise-masked encoder model that masks out noisy words according to word alignments and encodes the noise-masked sentences with an additional example encoder and (2) an auxiliary decoder model that predicts reusable words via an auxiliary decoder sharing parameters with the primary decoder. We define and implement the two models with the state-of-the-art Transformer. Experiments show that the noise-masked encoder model allows NMT to learn useful information from examples with low fuzzy match scores (FMS) while the auxiliary decoder model is good for high-FMS examples. More experiments on Chinese-English, English-German and English-Spanish translation demonstrate that the combination of the two EGNMT models can achieve improvements of up to +9 BLEU points over the baseline system and +7 BLEU points over a two-encoder Transformer.
OI Xiong, Deyi/0000-0002-2353-5038
SN 0922-6389
EI 1879-8314
BN 978-1-64368-101-6; 978-1-64368-100-9
PY 2020
VL 325
BP 1982
EP 1989
DI 10.3233/FAIA200318
UT WOS:000650971302044
ER

PT C
AU Fan, K
   Wang, JY
   Li, B
   Zhou, FM
   Chen, BX
   Si, L
AF Fan, Kai
   Wang, Jiayi
   Li, Bo
   Zhou, Fengming
   Chen, Boxing
   Si, Luo
GP AAAI
TI "Bilingual Expert" Can Find Translation Errors
SO THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 33rd AAAI Conference on Artificial Intelligence / 31st Innovative
   Applications of Artificial Intelligence Conference / 9th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY JAN 27-FEB 01, 2019
CL Honolulu, HI
SP Assoc Advancement Artificial Intelligence
AB The performances of machine translation (MT) systems are usually evaluated by the metric BLEU when the golden references are provided. However, in the case of model inference or production deployment, golden references are usually expensively available, such as human annotation with bilingual expertise. In order to address the issue of translation quality estimation (QE) without reference, we propose a general framework for automatic evaluation of the translation output for the QE task in the Conference on Statistical Machine Translation (WMT). We first build a conditional target language model with a novel bidirectional transformer, named neural bilingual expert model, which is pre-trained on large parallel corpora for feature extraction. For QE inference, the bilingual expert model can simultaneously produce the joint latent representation between the source and the translation, and real-valued measurements of possible erroneous tokens based on the prior knowledge learned from parallel data. Subsequently, the features will further be fed into a simple Bi-LSTM predictive model for quality estimation. The experimental results show that our approach achieves the state-of-the-art performance in most public available datasets of WMT 2017/2018 QE task.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-809-1
PY 2019
BP 6367
EP 6374
UT WOS:000486572500110
ER

PT C
AU Rahit, KMTH
   Nabil, RH
   Huq, MH
AF Rahit, K. M. Tahsin Hassan
   Nabil, Rashidul Hasan
   Huq, Md Hasibul
BE Arai, K
   Bhatia, R
   Kapoor, S
TI Machine Translation from Natural Language to Code Using Long-Short Term
   Memory
SO PROCEEDINGS OF THE FUTURE TECHNOLOGIES CONFERENCE (FTC) 2019, VOL 1
SE Advances in Intelligent Systems and Computing
CT Future Technologies Conference (FTC)
CY OCT 24-25, 2019
CL San Francisco, CA
AB Making computer programming language more understandable and easy for the human is a longstanding problem. From assembly language to present day's object-oriented programming, concepts came to make programming easier so that a programmer can focus on the logic and the architecture rather than the code and language itself. To go a step further in this journey of removing human-computer language barrier, this paper proposes machine learning approach using Recurrent Neural Network (RNN) and Long-Short Term Memory (LSTM) to convert human language into programming language code. The programmer will write expressions for codes in layman's language, and the machine learning model will translate it to the targeted programming language. The proposed approach yields result with 74.40% accuracy. This can be further improved by incorporating additional techniques, which are also discussed in this paper.
SN 2194-5357
EI 2194-5365
BN 978-3-030-32520-6; 978-3-030-32519-0
PY 2020
VL 1069
BP 56
EP 63
DI 10.1007/978-3-030-32520-6_6
UT WOS:000560947600006
ER

PT C
AU Soky, K
   Li, S
   Mimura, M
   Chu, CH
   Kawahara, T
AF Soky, Kak
   Li, Sheng
   Mimura, Masato
   Chu, Chenhui
   Kawahara, Tatsuya
GP Int Speech Commun Assoc
TI Leveraging Simultaneous Translation for Enhancing Transcription of
   Low-resource Language via Cross Attention Mechanism
SO INTERSPEECH 2022
SE Interspeech
CT Interspeech Conference
CY SEP 18-22, 2022
CL Incheon, SOUTH KOREA
AB This work addresses automatic speech recognition (ASR) of a low-resource language using a translation corpus, which includes the simultaneous translation of the low-resource language. In multi-lingual events such as international meetings and court proceedings, simultaneous interpretation by a human is often available for speeches of low-resource languages. In this setting, we can assume that the content of its back-translation is the same as the transcription of the original speech. Thus, the former is expected to enhance the later process. We formulate this framework as a joint process of ASR and machine translation (MT) and implement it with a combination of cross attention mechanisms of the ASR encoder and the MT encoder. We evaluate the proposed method using the spoken language translation corpus of the Extraordinary Chambers in the Courts of Cambodia (ECCC), achieving a significant improvement in the ASR word error rate (WER) of Khmer by 8.9% relative. The effectiveness is also confirmed in the Fisher-CallHome-Spanish corpus with the reduction of WER in Spanish by 1.7% relative.1
RI Li, Sheng/AGF-2329-2022
OI Li, Sheng/0000-0001-7636-3797
SN 2308-457X
PY 2022
BP 1362
EP 1366
DI 10.21437/Interspeech.2022-343
UT WOS:000900724501109
ER

PT J
AU Guzman, F
   Joty, S
   Marquez, L
   Nakov, P
AF Guzman, Francisco
   Joty, Shafiq
   Marquez, Lluis
   Nakov, Preslav
TI Machine translation evaluation with neural networks
SO COMPUTER SPEECH AND LANGUAGE
AB We present a framework for machine translation evaluation using neural networks in a pairwise setting, where the goal is to select the better translation from a pair of hypotheses, given the reference translation. In this framework, lexical, syntactic and semantic information from the reference and the two hypotheses is embedded into compact distributed vector representations, and fed into a multi-layer neural network that models nonlinear interactions between each of the hypotheses and the reference, as well as between the two hypotheses. We experiment with the benchmark datasets from the WMT Metrics shared task, on which we obtain the best results published so far, with the basic network configuration. We also perform a series of experiments to analyze and understand the contribution of the different components of the network. We evaluate variants and extensions, including fine-tuning of the semantic embeddings, and sentence-based representations modeled with convolutional and recurrent neural networks. In summary, the proposed framework is flexible and generalizable, allows for efficient learning and scoring, and provides an MT evaluation metric that correlates with human judgments, and is on par with the state of the art. (C) 2017 Elsevier Ltd. All rights reserved.
RI Nakov, Preslav/D-2421-2017
OI Nakov, Preslav/0000-0002-3600-1510
SN 0885-2308
EI 1095-8363
PD SEP
PY 2017
VL 45
BP 180
EP 200
DI 10.1016/j.csl.2016.12.005
UT WOS:000403510500011
ER

PT C
AU Choudhary, A
   Singh, M
AF Choudhary, Alka
   Singh, Manjeet
BE Li, WH
   Zhou, JH
TI GB THEORY BASED HINDI TO ENGLISH TRANSLATION SYSTEM
SO 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND
   INFORMATION TECHNOLOGY, VOL 4
CT 2nd IEEE International Conference on Computer Science and Information
   Technology
CY AUG 08-11, 2009
CL Beijing, PEOPLES R CHINA
SP IEEE
AB Many research organizations in India and abroad have started developing translation systems for the Indian languages recently using conventional approaches like Ruled-based or Exampled-based or hybrid. Very few have tried to identify universality of Government and Binding (GB) theory, which emphasizes common phrase structure for all the languages. In this paper, a machine translation system based on GB theory is proposed. The system takes Hindi as source language and English as target language.
RI Singh, Manjeet/GPF-8211-2022
OI Singh, Manjeet/0000-0003-4738-8033
BN 978-1-4244-4518-9
PY 2009
BP 293
EP +
DI 10.1109/ICCSIT.2009.5234543
UT WOS:000279849200065
ER

PT J
AU Larson, JD
   Rodgers, ML
   Hoskins, AA
AF Larson, Joshua D.
   Rodgers, Margaret L.
   Hoskins, Aaron A.
TI Visualizing cellular machines with colocalization single molecule
   microscopy
SO CHEMICAL SOCIETY REVIEWS
AB Many of the cell's macromolecular machines contain multiple components that transiently associate with one another. This compositional and dynamic complexity presents a challenge for understanding how these machines are constructed and function. Colocalization single molecule spectroscopy enables simultaneous observation of individual components of these machines in real-time and grants a unique window into processes that are typically obscured in ensemble assays. Colocalization experiments can yield valuable information about assembly pathways, compositional heterogeneity, and kinetics that together contribute to the development of richly detailed reaction mechanisms. This review focuses on recent advances in colocalization single molecule spectroscopy and how this technique has been applied to enhance our understanding of transcription, RNA splicing, and translation.
RI Rodgers, Margaret L/Q-7404-2017
OI Rodgers, Margaret L/0000-0002-8176-2044
SN 0306-0012
EI 1460-4744
PY 2014
VL 43
IS 4
BP 1189
EP 1200
DI 10.1039/c3cs60208g
UT WOS:000330795000016
PM 23970346
ER

PT C
AU Malik, P
   Baghel, AS
AF Malik, Pooja
   Baghel, Anurag Singh
BE Astya, PN
   Swaroop, A
   Sharma, V
   Singh, M
   Gupta, K
TI An Algorithm for the better Assessment of Machine Translation
SO 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND
   AUTOMATION (ICCCA)
CT IEEE International Conference on Computing, Communication and Automation
   (ICCCA)
CY MAY 05-06, 2017
CL Noida, INDIA
SP IEEE, IEEE UP Sect, GALGOTIAS UNIV, Sch Comp Sci & Engn
AB Machine Translation, sometimes referred by the acronym MT, is one of the important fields of study of computational linguistics that investigates the use of computer software to translate text or speech from one natural language to another. At its basic level, MT performs simple substitution of atomic words in one natural language for words in another language.
   Around the world, numerous systems are available in the market for the assessment of the translation being done by the various translation systems. Even within India, a large number of such evaluation systems are available and a lot of research is still going on to develop a better evaluation system which can beat the results produced by Human Evaluators. Even the main challenge before Indian Researchers is that the evaluation systems which are giving unbeatable results for the translation of Foreign languages (such as German, French, Chinese, etc.) are not even giving considerable results for the translation of Indian Languages (Hindi, Tamil, Telugu, Punjabi, etc.). So at par these evaluation systems cannot be applied as it is to evaluate Machine Translations of Indian Languages.
   Indian languages require a novel approach because of the relatively unrestricted order of words within a word group. In this paper, we are presenting an algorithm (by incorporating different modules of language models like synonym replacement, root word extraction and shallow parsing) which when applied upon the translation of English to Hindi text gives better evaluation results as compared to those algorithms which do not incorporate all these modules. Moreover, our study is limited to English to Hindi language pair and the testing is being with the corpora of agriculture domain.
RI Malik, Pooja/AAG-1724-2019
OI Malik, Pooja/0000-0003-4104-6665
BN 978-1-5090-6471-7
PY 2017
BP 395
EP 399
UT WOS:000427628300071
ER

PT C
AU Wang, JL
   Zhang, GP
   Ye, N
   Zhou, LH
AF Wang, Jinling
   Zhang, Guiping
   Ye, Na
   Zhou, Lanhai
GP IEEE
TI Research on Japanese-Chinese Term Translation Technique Based on
   Multi-features
SO PROCEEDINGS OF THE 2009 CHINESE CONFERENCE ON PATTERN RECOGNITION AND
   THE FIRST CJK JOINT WORKSHOP ON PATTERN RECOGNITION, VOLS 1 AND 2
CT Chinese Conference on Pattern Recognition/1st CJK Joint Workshop on
   Pattern Recognition
CY NOV 04-06, 2009
CL Nanjing, PEOPLES R CHINA
AB Term is the important component of the technical literature; automatic translation methods study on it has important research significance for international technology exchange. Under the background of the machine translation of the Japanese-Chinese patent documents and mainly study the term translation methods, this paper proposes a novel approach for Japanese-Chinese term translation based on multi-features on the basis of the existing IBM-model 4. Our approach effectively utilizes the features of the field attribute of the term and the character similarity between Japanese and Chinese, optimizes and improves the term translation results. The experimental results indicate that our method can make the precision of the term translation improvement 5.5%.
BN 978-1-4244-4199-0
PY 2009
BP 670
EP 674
UT WOS:000278039800138
ER

PT J
AU Vathsala, MK
   Holi, G
AF Vathsala, M. K.
   Holi, Ganga
TI RNN based machine translation and transliteration for Twitter data
SO INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY
AB The present work aims at analyzing the social media data for code-switching and transliterated to English language using the special kind of recurrent neural network (RNN) called Long Short-Term Memory (LSTM) Network. During the course of work, TensorFlow is used to express LSTM suitably. Twitter data is stored in MongoDB to enable easy handling and processing of data. The data is parsed through different fields with the aid of Python script and cleaned using regular expressions. The LSTM model is trained for 1 M data which is further used for transliteration and translation of the Twitter data. Translation and transliteration of social media data enables publicizing the content in the language understood by majority of the population. With this, any content which is anti-social or threat to law and order can be easily verified and blocked at the source.
RI Holi, Ganga/A-3226-2019
OI Holi, Ganga/0000-0003-4797-5887; MK, VATHSALA/0000-0002-1650-5906
SN 1381-2416
EI 1572-8110
PD SEP
PY 2020
VL 23
IS 3
SI SI
BP 499
EP 504
DI 10.1007/s10772-020-09724-9
EA JUN 2020
UT WOS:000539857200001
ER

PT S
AU Matsuhara, M
   Araki, K
   Tochinai, K
AF Matsuhara, M
   Araki, K
   Tochinai, K
BE Mckay, B
   Slaney, J
TI Effectiveness for machine translation method using inductive learning on
   number representation
SO AL 2002: ADVANCES IN ARTIFICIAL INTELLIGENCE
SE Lecture Notes in Artificial Intelligence
CT 15th Australian Joint Conference on Artificial Intelligence
CY DEC 02-06, 2002
CL CANBERRA, AUSTRALIA
AB On our proposed method, source language is translated into target language via Number Representation. A text in the source language is translated into a number representation text. The number representation text is the number string corresponding to the original source language text. The number representation text is translated into a number representation text for the target language. The number representation text is translated into a text in the target language. The text is the translation result finally. A number representation text is more abstract than the original text because the number representation text corresponds to several texts. The system based on our proposed method is able to acquire more translation rules on number representation than that on the original text by Inductive Learning. Moreover, the system disambiguates number representation by its own adaptability. In the experiment, the correct translation rate for our proposed method is higher than that for the method without number representation. Thus, it is proved that our proposed method is more effective for machine translation.
RI Araki, Kenji/F-7573-2012
SN 0302-9743
BN 3-540-00197-2
PY 2002
VL 2557
BP 648
EP 659
UT WOS:000181083100057
ER

PT C
AU Sunil, R
   Manohar, N
   Jayan, V
   Sulochana, KG
AF Sunil, R.
   Manohar, Nimtha
   Jayan, V
   Sulochana, K. G.
BE Negi, A
   Narayana, MGPL
   Rao, NV
   Narayana, ML
   Vemuri, P
   Rao, KD
   Sarma, DS
   Kumar, A
   Devarapalli, H
TI Development of Malayalam Text Generator for translation from English
SO 2011 ANNUAL IEEE INDIA CONFERENCE (INDICON-2011): ENGINEERING
   SUSTAINABLE SOLUTIONS
SE Annual IEEE India Conference
CT Annual IEEE India Conference - Engineering Sustainable Solutons
CY DEC 16-18, 2011
CL BITS Pilani, Hyderabad Campus, Hyderabad, INDIA
SP IEEE, IEEE India Council, IEEE Hyderabad Sect
HO BITS Pilani, Hyderabad Campus
AB The paper presents a strategy for developing Malayalam Text Generator for English Malayalam Machine Aided Translation System using AnglaBharati technology. AnglaBharati uses the Interlingua approach for translation. The Interlingua is a language independent, unambiguous representation of the input text. The text generator converts this intermediate representation into the target language (Malayalam) text. In this paper we examine the major tasks involved in the development of Malayalam Text Generator for translation from English.
RI Vasudevan, Jayan/AAG-7333-2020
OI Vasudevan, Jayan/0000-0002-1810-6407
SN 2325-940X
BN 978-1-4577-1109-1
PY 2011
UT WOS:000394020400074
ER

PT J
AU Yan, L
AF Yan, Li
TI Real-Time Automatic Translation Algorithm for Chinese Subtitles in Media
   Playback Using Knowledge Base
SO MOBILE INFORMATION SYSTEMS
AB Currently, speech technology allows for simultaneous subtitling of live television programs using speech recognition and the respeaking approach. Although many previous studies on the quality of live subtitling utilizing voice recognition have been proposed, little attention has been paid to the quantitative elements of subtitles. Due to the high performance of neural machine translation (NMT), it has become the standard machine translation method. A data-driven translation approach requires high-quality, large-scale training data and powerful computing resources to achieve good performance. However, data-driven translation will face challenges when translating languages with limited resources. This paper's research work focuses on how to integrate linguistic knowledge into the NMT model to improve the translation performance and quality of the NMT system. A method of integrating semantic concept information in the NMT system is proposed to address the problem of out-of-set words and low-frequency terms in the NMT system. This research also provides an NMT-centered read modeling and decoding approach integrating an external knowledge base. The experimental results show that the proposed strategy can effectively increase the MT system's translation performance.
SN 1574-017X
EI 1875-905X
PD JUN 18
PY 2022
VL 2022
AR 5245035
DI 10.1155/2022/5245035
UT WOS:000817627500012
ER

PT J
AU Abaitua, J
AF Abaitua, J
TI Fifteen years of machine translation in Spain
SO PERSPECTIVES-STUDIES IN TRANSLATOLOGY
AB Machine translation is fifteen years old in Spain. Research has gone through three major stages. In 1985 a sudden outbreak of interest appeared in Spain as three transnational companies and the European Community funded the creation of several research groups. Paradoxically, 1992, which was a widely celebrated year in Spain (owing to the 5th centennial of the discovery of America and the Olympic games held in Barcelona), marked the end of that dynamic period. At this point the methods and aims of the field wee reconsidered and funding was dramatically cut. Since 1995, the growing globalization of the economy, the boom of Internet and the demand for multilingual documentation and software has renewed the interest in translation technology.
RI Abaitua, Joseba/R-5642-2019
OI Abaitua, Joseba/0000-0001-6957-8511
SN 0907-676X
PY 1999
VL 7
IS 2
BP 221
EP 239
DI 10.1080/0907676X.1999.9961360
UT WOS:000085507700009
ER

PT J
AU Sanders, GA
   Weiss, BA
   Schlenoff, C
   Steves, MP
   Condon, S
AF Sanders, Gregory A.
   Weiss, Brian A.
   Schlenoff, Craig
   Steves, Michelle P.
   Condon, Sherri
TI Evaluation methodology and metrics employed to assess the TRANSTAC
   two-way, speech-to-speech translation systems
SO COMPUTER SPEECH AND LANGUAGE
AB One of the most difficult challenges that military personnel face when operating in foreign countries is clear and successful communication with the local population. To address this issue, the Defense Advanced Research Projects Agency (DARPA) is funding academic institutions and industrial organizations through the Spoken Language Communication and Translation System for Tactical Use (TRANSTAC) program to develop practical machine translation systems. The goal of the TRANSTAC program is to demonstrate capabilities to rapidly develop and field free-form, two-way, speech-to-speech translation systems that enable speakers of different languages to communicate with one another in real-world tactical situations without an interpreter. Evaluations of these technologies are a significant part of the program and DARPA has asked the National Institute of Standards and Technology (NIST) to lead this effort. This article presents the experimental design of the TRANSTAC evaluations and the metrics, both quantitative and qualitative, that were used to comprehensively assess the systems' performance. (C) 2011 Elsevier Ltd. All rights reserved.
SN 0885-2308
EI 1095-8363
PD FEB
PY 2013
VL 27
IS 2
SI SI
BP 528
EP 553
DI 10.1016/j.csl.2011.05.001
UT WOS:000312471500009
ER

PT C
AU Batoulis, K
   Eid-Sabbagh, RH
   Leopold, H
   Weske, M
   Mendling, J
AF Batoulis, Kimon
   Eid-Sabbagh, Rami-Habib
   Leopold, Henrik
   Weske, Mathias
   Mendling, Jan
BE Franch, X
   Soffer, P
TI Automatic Business Process Model Translation with BPMT
SO ADVANCED INFORMATION SYSTEMS ENGINEERING WORKSHOPS (CAISE)
SE Lecture Notes in Business Information Processing
CT 25th International Conference on Advanced Information Systems
   Engineering (CAiSE)
CY JUN 17-21, 2013
CL Valencia, SPAIN
AB Nowadays, many enterprises use business process models for documenting and supporting their operations. As many enterprises have branches in several countries and provide similar services throughout the globe, there is high potential for re-using these process models. However, the language barrier is a major obstacle for the successful re-use of process models, especially in multi-national companies. In this paper, we address this problem by presenting the Business Process Model Translator (BPMT), a technique for the automated translation of business process models that eases the re-use of business process models and reduces redundant work in multi-national companies. It builds upon the state-of-the-art machine translation system Moses and extends it with word and translation disambiguation considering the context of the domain. As a result, the BPMT can successfully deal with the compact and special language fragments that are typically found in business process models. A two-fold evaluation with the BLEU metric and an expert survey showed improvements of our approach over Moses.
OI Mendling, Jan/0000-0002-7260-524X
SN 1865-1348
BN 978-3-642-38490-5; 978-3-642-38489-9
PY 2013
VL 148
BP 217
EP 228
UT WOS:000345280400021
ER

PT J
AU Costa-jussa, MR
   Allauzen, A
   Barrault, L
   Cho, K
   Schwenk, H
AF Costa-jussa, Martar R.
   Allauzen, Alexandre
   Barrault, Loic
   cho, Kyunghun
   Schwenk, Holger
TI Introduction to the special issue on deep learning approaches for
   machine translation
SO COMPUTER SPEECH AND LANGUAGE
AB Deep learning is revolutionizing speech and natural language technologies since it is offering an effective way to train systems and obtaining significant improvements. The main advantage of deep learning is that, by developing the right architecture, the system automatically learns features from data without the need of explicitly designing them. This machine learning perspective is conceptually changing how speech and natural language technologies are addressed. In the case of Machine Translation (MT), deep learning was first introduced in standard statistical systems. By now, end-to-end neural MT systems have reached competitive results. This special issue introductory paper addresses how deep learning has been gradually introduced in MT. This introduction covers all topics contained in the papers included in this special issue, which basically are: integration of deep learning in statistical MT; development of the end-to-end neural MT system; and introduction of deep learning in interactive MT and MT evaluation. Finally, this introduction sketches some research directions that MT is taking guided by deep learning. (C) 2017 Elsevier Ltd. All rights reserved.
RI ; Costa-jussa, Marta R./M-7886-2013
OI BARRAULT, Loic/0000-0002-0634-6147; Costa-jussa, Marta
   R./0000-0002-5703-520X
SN 0885-2308
EI 1095-8363
PD NOV
PY 2017
VL 46
BP 367
EP 373
DI 10.1016/j.csl.2017.03.001
UT WOS:000407609600021
ER

PT C
AU AleAhmad, A
   Kamalloo, E
   Zareh, A
   Rahgozar, M
   Oroumchian, F
AF AleAhmad, Abolfazl
   Kamalloo, Ehsan
   Zareh, Arash
   Rahgozar, Masoud
   Oroumchian, Farhad
BE Peters, C
TI Cross Language Experiments at Persian@CLEF 2008
SO EVALUATING SYSTEMS FOR MULTILINGUAL AND MULTIMODAL INFORMATION ACCESS
SE Lecture Notes in Computer Science
CT 9th Workshop of the Cross-Language Evaluation Forum (CLEF 2008)
CY SEP 17-19, 2008
CL Aarhus, DENMARK
AB In this study we will discuss our cross language text retrieval experiments of Persian ad hoe track at CLEF 2008. Two teams from University of Tehran were involved in cross language text retrieval part of the track using two different CLIR approaches that are query translation and document translation. For query translation we use a method named Combinatorial Translation Probability (CTP) calculation for estimation of translation probabilities. In the document translation part, we use the Shiraz machine translation system for translation of documents into English. Then we create a Hybrid CLIR system by score-based merging of the two retrieval system results. In addition, we investigated N-grams and a light stemmer in our monolingual experiments.
RI Rahgozar, Maseud/L-1441-2018
OI Rahgozar, Maseud/0000-0002-0836-2642; Oroumchian,
   Farhad/0000-0001-7942-5965
SN 0302-9743
EI 1611-3349
BN 978-3-642-04446-5
PY 2009
VL 5706
BP 105
EP +
UT WOS:000273344500012
ER

PT C
AU Tani, K
   Yuasa, R
   Takikawa, K
   Tamura, A
   Kajiwara, T
   Ninomiya, T
   Kato, T
AF Tani, Kazuki
   Yuasa, Ryoya
   Takikawa, Kazuki
   Tamura, Akihiro
   Kajiwara, Tomoyuki
   Ninomiya, Takashi
   Kato, Tsuneo
BA Mariani, J
BF Mariani, J
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mazo, H
   Odijk, H
   Piperidis, S
TI A Benchmark Dataset for Multi-Level Complexity-Controllable Machine
   Translation
SO LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION
CT 13th International Conference on Language Resources and Evaluation
   (LREC)
CY JUN 20-25, 2022
CL Marseille, FRANCE
SP Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur
AB This paper introduces a new benchmark test dataset for multi-level complexity-controllable machine translation (MLCC-MT), which is an MT that controls the output complexity at more than two levels. In previous studies, MLCC-MT models have been evaluated on a test dataset automatically generated from the Newsela corpus, which is a document-level comparable corpus with document-level complexity. There are three issues with the existing test dataset: first, a source language sentence and its target language sentence are not necessarily an exact translation pair because they are automatically detected. Second, a target language sentence and its simplified target language sentence are not always perfectly parallel since they are automatically aligned. Third, a sentence-level complexity is not always appropriate because it is derived from an article-level complexity associated with the Newsela corpus. Therefore, we created a benchmark test dataset for Japanese-to-English MLCC-MT from the Newsela corpus by introducing an automatic filtering of data with inappropriate sentence-level complexity, manual check for parallel target language sentences with different complexity levels, and manual translation. Furthermore, we implement two MLCC-NMT frameworks with a Transformer architecture and report their performance on our test dataset as baselines for future research. Our test dataset and codes are released.
BN 979-10-95546-72-6
PY 2022
BP 6744
EP 6752
UT WOS:000889371706094
ER

PT C
AU Xu, C
   Wang, J
   Tang, YQ
   Guzman, F
   Rubinstein, BIP
   Cohn, T
AF Xu, Chang
   Wang, Jun
   Tang, Yuqing
   Guzman, Francisco
   Rubinstein, Benjamin I. P.
   Cohn, Trevor
GP ACM
TI A Targeted Attack on Black-Box Neural Machine Translation with Parallel
   Data Poisoning
SO PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021)
CT 30th World Wide Web Conference (WWW)
CY APR 12-23, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery
AB As modern neural machine translation (NMT) systems have been widely deployed, their security vulnerabilities require close scrutiny. Most recently, NMT systems have been found vulnerable to targeted attacks which cause them to produce specific, unsolicited, and even harmful translations. These attacks are usually exploited in a white-box setting, where adversarial inputs causing targeted translations are discovered for a known target system. However, this approach is less viable when the target system is black-box and unknown to the adversary (e.g., secured commercial systems). In this paper, we show that targeted attacks on black-box NMT systems are feasible, based on poisoning a small fraction of their parallel training data. We show that this attack can be realised practically via targeted corruption of web documents crawled to form the system's training data. We then analyse the effectiveness of the targeted poisoning in two common NMT training scenarios: the from-scratch training and the pre-train & fine-tune paradigm. Our results are alarming: even on the state-of-the-art systems trained with massive parallel data (tens of millions), the attacks are still successful (over 50% success rate) under surprisingly low poisoning budgets (e.g., 0.006%). Lastly, we discuss potential defences to counter such attacks.
BN 978-1-4503-8312-7
PY 2021
BP 3638
EP 3650
DI 10.1145/3442381.3450034
UT WOS:000733621803059
ER

PT J
AU Jenkins, J
   Rashad, S
AF Jenkins, Jon
   Rashad, Sherif
TI LeapASL: A platform for design and implementation of real time
   algorithms for translation of American Sign Language using personal
   supervised machine learning models
SO SOFTWARE IMPACTS
AB There is a need for a system that is easy to use, accurate, and portable to translate from American Sign Language (ASL) to English. The proposed innovative system combines Unity's usability with Python's machine learning capabilities to create a platform for real time translation of ASL. The Leap Motion Controller is used to capture hand movements and information to create supervised machine learning models. This system will be able to work in an adaptive way to learn from the signer how they sign individual words to allow for a more robust accuracy than a general model for sign language recognition.
SN 2665-9638
PD MAY
PY 2022
VL 12
AR 100302
DI 10.1016/j.simpa.2022.100302
EA MAY 2022
UT WOS:000844075800025
ER

PT S
AU Andres, J
   Navarro, JR
   Juan, A
   Casacuberta, F
AF Andres, J
   Navarro, JR
   Juan, A
   Casacuberta, F
BE Marques, JS
   PerezdelaBlanca, N
   Pina, P
TI Word translation disambiguation using multinomial classifiers
SO PATTERN RECOGNITION AND IMAGE ANALYSIS, PT 2, PROCEEDINGS
SE Lecture Notes in Computer Science
CT 2nd Iberian Conference on Pattern Recognition and Image Analysis
CY JUN 07-09, 2005
CL Estoril, PORTUGAL
SP Fundacao Oriente, Fundacao Cienc Tecnol, HP Portugal, Inst Syst & Robot, Int Assoc Pattern Recognit
AB This work focuses on a hybrid machine translation system from Spanish into Catalan called SisHiTra. In particular, we focus on its word translation disambiguation module, which has to decide on the correct translation of each ambiguous input word in accordance with its context. We propose the use of statistical pattern recognition techniques for this task and, in particular, multinomial Naive Bayes text classifiers. Extensive empirical results on the use of these classifiers are presented, in which the influence of the window (context) size and parameter smoothing are carefully studied.
RI Navarro-Cerdán, José Ramón/ABG-9662-2020
OI Navarro-Cerdán, José Ramón/0000-0002-6692-5941
SN 0302-9743
EI 1611-3349
BN 3-540-26154-0
PY 2005
VL 3523
BP 622
EP 629
UT WOS:000230027000076
ER

PT C
AU Li, Q
   Jiao, LC
   Gou, SP
AF Li, Qing
   Jiao, Licheng
   Gou, Shuiping
BE Sattar, A
   Kang, BH
TI Wavelet Kernel Matching Pursuit Machine
SO AI 2006: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS
SE Lecture Notes in Computer Science
CT 19th Australian Joint Conference on Artificial Intelligence
CY DEC 04-08, 2006
CL Hobart, AUSTRALIA
AB Kernel Matching Pursuit Machine is a relatively new learning algorithm utilizing Mercer kernels to produce non-linear version of conventional supervised and unsupervised learning algorithm. But the commonly used Mercer kernels can't expand a set of complete bases in the feature space (subspace of the square and integrable space). Hence the decision-function found by the machine can't approximate arbitrary objective function in feature space as precise as possible. Wavelet technique shows promise for both nonstationary signal approximation and classification, so we combine KMPM with wavelet technique to improve the performance of the machine, and put forward a wavelet translation invariant kernel, which is a Mercer admissive kernel by theoretical analysis. The wavelet kernel matching pursuit machine is constructed in this paper by a translation-invariant wavelet kernel. It is shown that WKMPM is much more effective in the problems of regression and pattern recognition by the number of comparable experiments.
SN 0302-9743
EI 1611-3349
BN 978-3-540-49787-5
PY 2006
VL 4304
BP 1157
EP +
UT WOS:000244891200140
ER

PT J
AU De Coster, M
   Dambre, J
AF De Coster, Mathieu
   Dambre, Joni
TI Leveraging Frozen Pretrained Written Language Models for Neural Sign
   Language Translation
SO INFORMATION
AB We consider neural sign language translation: machine translation from signed to written languages using encoder-decoder neural networks. Translating sign language videos to written language text is especially complex because of the difference in modality between source and target language and, consequently, the required video processing. At the same time, sign languages are low-resource languages, their datasets dwarfed by those available for written languages. Recent advances in written language processing and success stories of transfer learning raise the question of how pretrained written language models can be leveraged to improve sign language translation. We apply the Frozen Pretrained Transformer (FPT) technique to initialize the encoder, decoder, or both, of a sign language translation model with parts of a pretrained written language model. We observe that the attention patterns transfer in zero-shot to the different modality and, in some experiments, we obtain higher scores (from 18.85 to 21.39 BLEU-4). Especially when gloss annotations are unavailable, FPTs can increase performance on unseen data. However, current models appear to be limited primarily by data quality and only then by data quantity, limiting potential gains with FPTs. Therefore, in further research, we will focus on improving the representations used as inputs to translation models.
OI De Coster, Mathieu/0000-0002-1103-2441; Dambre, Joni/0000-0002-9373-1210
EI 2078-2489
PD MAY
PY 2022
VL 13
IS 5
AR 220
DI 10.3390/info13050220
UT WOS:000804286100001
ER

PT C
AU Su, JS
   Wu, S
   Xiong, DY
   Lu, YJ
   Han, XP
   Zhang, B
AF Su, Jinsong
   Wu, Shan
   Xiong, Deyi
   Lu, Yaojie
   Han, Xianpei
   Zhang, Biao
GP AAAI
TI Variational Recurrent Neural Machine Translation
SO THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 32nd AAAI Conference on Artificial Intelligence / 30th Innovative
   Applications of Artificial Intelligence Conference / 8th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 02-07, 2018
CL New Orleans, LA
SP AAAI
AB Partially inspired by successful applications of variational recurrent neural networks, we propose a novel variational recurrent neural machine translation (VRNMT) model in this paper. Different from the variational NMT, VRNMT introduces a series of latent random variables to model the translation procedure of a sentence in a generative way, instead of a single latent variable. Specifically, the latent random variables are included into the hidden states of the NMT decoder with elements from the variational autoencoder. In this way, these variables are recurrently generated, which enables them to further capture strong and complex dependencies among the output translations at different timesteps. In order to deal with the challenges in performing efficient posterior inference and large-scale training during the incorporation of latent variables, we build a neural posterior approximator, and equip it with a reparameterization technique to estimate the variational lower bound. Experiments on Chinese English and English-German translation tasks demonstrate that the proposed model achieves significant improvements over both the conventional and variational NMT models.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-800-8
PY 2018
BP 5488
EP 5495
UT WOS:000485488905072
ER

PT C
AU Chow, J
   Madhyastha, P
   Specia, L
AF Chow, Julian
   Madhyastha, Pranava
   Specia, Lucia
GP Assoc Computat Linguist
TI WMDO: Fluency-based Word Mover's Distance for Machine Translation
   Evaluation
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019)
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB We propose WMDO, a metric based on distance between distributions in the semantic vector space. Matching in the semantic space has been investigated for translation evaluation, but the constraints of a translation's word order have not been fully explored. Building on the Word Mover's Distance metric and various word embeddings, we introduce a fragmentation penalty to account for fluency of a translation. This word order extension is shown to perform better than standard WMD, with promising results against other types of metrics.
OI Specia, Lucia/0000-0002-5495-3128; Madhyastha,
   Pranava/0000-0002-4438-8161
BN 978-1-950737-27-7
PY 2019
BP 494
EP 500
UT WOS:000538566200056
ER

PT J
AU Espana-Bonet, C
   Varga, AC
   Barron-Cedeno, A
   van Genabith, J
AF Espana-Bonet, Cristina
   Varga, Adam Csaba
   Barron-Cedeno, Alberto
   van Genabith, Josef
TI An Empirical Analysis of NMT-Derived Interlingual Embeddings and Their
   Use in Parallel Sentence Identification
SO IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING
AB End-to-end neural machine translation has overtaken statistical machine translation in terms of translation quality for some language pairs, specially those with large amounts of parallel data. Besides this palpable improvement, neural networks provide several new properties. A single system can be trained to translate between many languages at almost no additional cost other than training time. Furthermore, internal representations learned by the network serve as a new semantic representation of words-or sentences-which, unlike standard word embeddings, are learned in an essentially bilingual or even multilingual context. In view of these properties, the contribution of the present paper is twofold. First, we systematically study the neural machine translation (NMT) context vectors, i.e., output of the encoder, and their power as an interlingua representation of a sentence. We assess their quality and effectiveness by measuring similarities across translations, as well as semantically related and semantically unrelated sentence pairs. Second, as extrinsic evaluation of the first point, we identify parallel sentences in comparable corpora, obtaining an F-1 = 98.2% on data from a shared task when using only NMT context vectors. Using context vectors jointly with similarity measures F-1 reaches 98.9%.
OI Espana-Bonet, Cristina/0000-0001-5414-4710; Varga, Adam
   Csaba/0000-0002-7564-2054; Barron-Cedeno, Alberto/0000-0003-4719-3420
SN 1932-4553
EI 1941-0484
PD DEC
PY 2017
VL 11
IS 8
BP 1340
EP 1350
DI 10.1109/JSTSP.2017.2764273
UT WOS:000416226000011
ER

PT J
AU Ettelaie, E
   Georgiou, PG
   Narayanan, SS
AF Ettelaie, Emil
   Georgiou, Panayiotis G.
   Narayanan, Shrikanth S.
TI Unsupervised data processing for classifier-based speech translator
SO COMPUTER SPEECH AND LANGUAGE
AB Concept classification has been used as a translation method and has shown notable benefits within the suite of speech-to-speech translation applications. However, the main bottleneck in achieving an acceptable performance with such classifiers is the cumbersome task of annotating large amounts of training data. Any attempt to develop a method to assist in, or to completely automate, data annotation needs a distance measure to compare sentences based on the concept they convey. Here, we introduce a new method of sentence comparison that is motivated from the translation point of view. In this method the imperfect translations produced by a phrase-based statistical machine translation system are used to compare the concepts of the source sentences. Three clustering methods are adapted to support the concept-base distance. These methods are applied to prepare groups of paraphrases and use them as training sets in concept classification tasks. The statistical machine translation is also used to enhance the training data for the classifier which is crucial when such data are sparse. Experiments show the effectiveness of the proposed methods. (C) 2012 Elsevier Ltd. All rights reserved.
RI Narayanan, Shrikanth S/D-5676-2012; Georgiou, Panayiotis
   Panos/E-8387-2018
OI Georgiou, Panayiotis Panos/0000-0002-0790-7161
SN 0885-2308
EI 1095-8363
PD FEB
PY 2013
VL 27
IS 2
SI SI
BP 438
EP 454
DI 10.1016/j.csl.2012.03.001
UT WOS:000312471500004
ER

PT C
AU Barakhnin, VB
   Duisenbayeva, AN
   Kozhemyakina, OY
   Yergaliyev, YN
   Muhamedyev, RI
AF Barakhnin, V. B.
   Duisenbayeva, A. N.
   Kozhemyakina, O. Yu
   Yergaliyev, Y. N.
   Muhamedyev, R., I
GP IOP
TI The automatic processing of the texts in natural language. Some
   bibliometric indicators of the current state of this research area
SO BIGDATA CONFERENCE (FORMERLY INTERNATIONAL CONFERENCE ON BIG DATA AND
   ITS APPLICATIONS)
SE Journal of Physics Conference Series
CT 5th Big Data Conference (BDC)
CY SEP 13, 2018
CL Moscow, RUSSIA
AB This work reviews the bibliometric indicators of a rapidly developing field of research as automatic text processing (Natural language processing). The differential indicators of speed and acceleration were used to evaluate the development dynamics of NLP domains. The evaluation was based on the data from the Science direct bibliometric database. The evaluation of the Russian research segment was conducted according to e-library data. The calculations for the following subdomains of NLP were performed: Grammar Checking, Information Extraction, Text Categorization, Dialog Systems, Speech Recognition, Machine Translation, Information Retrieval, Question Answering, Opinion Mining, Smart advisors and others. The areas with high growth rates (Grammar Checking, Information Extraction, Machine Translation and Question Answering) and the areas that have lost the previously existing dynamics of growth of the publication activity (Information Retrieval, Opinion Mining, Text Categorization) have been identified.
RI Mukhamediev, Ravil/X-1461-2019; Kozhemyakina, Olga Yu./AAG-8715-2019;
   Yergaliyev, Yerlan/AAB-2507-2020; Barakhnin, Vladimir B/A-5856-2014
OI Mukhamediev, Ravil/0000-0002-3727-043X; Kozhemyakina, Olga
   Yu./0000-0003-3619-1120; Barakhnin, Vladimir B/0000-0003-3299-0507;
   Yergaliyev, Yerlan/0000-0001-9632-3784
SN 1742-6588
EI 1742-6596
PY 2018
VL 1117
AR 012001
DI 10.1088/1742-6596/1117/1/012001
UT WOS:000495570900001
ER

PT J
AU Harm, H
   Alumae, T
AF Harm, Henry
   Alumae, Tanel
TI Abstractive Summarization of Broadcast News Stories for Estonian
SO BALTIC JOURNAL OF MODERN COMPUTING
CT 10th Conference on Human Language Technologies - The Baltic Perspective
   (Baltic HLT)
CY OCT 06-07, 2022
CL Riga, LATVIA
SP Tilde, Univ Latvia, Inst Math & Comp Sci
AB We present an approach for generating abstractive summaries for Estonian spoken news stories in a low-resource setting. Given a recording of a radio news story, the goal is to create a summary that captures the essential information in a short format. The approach consists of two steps: automatically generating the transcript and applying a state-of-the-art text summarization system to generate the result. We evaluated a number of models, with the best-performing model leveraging the large English BART model pre-trained on CNN/DailyMail dataset and fine-tuned on machine-translated in-domain data, and with the test data translated to English and back. The method achieved a ROUGE-1 score of 17.22, improving on the alternatives and achieving the best result in human evaluation. The applicability of the proposed solution might be limited in languages where machine translation systems are not mature. In such cases multilingual BART should be considered, which achieved a ROUGE-1 score of 17.00 overall and a score of 16.22 without machine translation based data augmentation.
SN 2255-8942
EI 2255-8950
PY 2022
VL 10
IS 3
BP 511
EP 524
DI 10.22364/bjmc.2022.10.3.23
UT WOS:000867549800024
ER

PT C
AU Choi, M
   Lee, W
   Bae, SJ
   Lee, H
   Park, JH
AF Choi, Min
   Lee, Wonjae
   Bae, Seong-jun
   Lee, Hyunwoo
   Park, Jong-Hyuk
BE Barolli, L
   Li, KF
   Enokido, T
   Xhafa, F
   Takizawa, M
TI Faster Translated Binary Execution on Mobile System through
   Virtualization
SO 2014 IEEE 28TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION
   NETWORKING AND APPLICATIONS (AINA)
SE International Conference on Advanced Information Networking and
   Applications
CT 28th IEEE International Conference on Advanced Information Networking
   and Applications Workshops (IEEE WAINA)
CY MAY 13-16, 2014
CL Univ Victoria, Victoria, CANADA
SP IEEE, IEEE Tech Comm Distributed Proc, IEEE Comp Soc
HO Univ Victoria
AB One of the challenges of the binary translation on virtual machine(VM) is to make a mapping from registers in emulated architecture to registers in the target architecture. The efficiency on the emulated architecture is best translated into efficiency on the target machine if target instructions also operated on register operands. However, conventional binary translators of popular VMs do not take into account instruction dependency among two or more basic blocks. This results in performance degradation due to inter-translation block dependency. Because binary translation makes use of 1 or 2 registers repeatedly for the majority of translation blocks. The translation block corresponds to a guest(emulated) instruction, which in turn the amount of work is not large. Even though there are no dependencies between translation blocks, false dependencies are generated by the repeated use of the same register usage order. In order to resolve the problem, we propose a novel approach maintaining two different register allocation orders, applying them alternatively. We call this as alternative register allocation in this paper. The experimental results show up to 26.3% better performance to conventional method.
SN 1550-445X
BN 978-1-4799-3629-8
PY 2014
BP 465
EP 471
DI 10.1109/AINA.2014.160
UT WOS:000358605300061
ER

PT C
AU Miao, MQ
   Meng, FD
   Liu, YJ
   Zhou, XH
   Zhou, J
AF Miao, Mengqi
   Meng, Fandong
   Liu, Yijin
   Zhou, Xiao-Hua
   Zhou, Jie
GP Assoc Computat Linguist
TI Prevent the Language Model from being Overconfident in Neural Machine
   Translation
SO 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND
   THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (ACL-IJCNLP 2021), VOL 1
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB The Neural Machine Translation (NMT) model is essentially a joint language model conditioned on both the source sentence and partial translation. Therefore, the NMT model naturally involves the mechanism of the Language Model (LM) that predicts the next token only based on partial translation. Despite its success, NMT still suffers from the hallucination problem, generating fluent but inadequate translations. The main reason is that NMT pays excessive attention to the partial translation while neglecting the source sentence to some extent, namely overconfidence of the LM. Accordingly, we define the Margin between the NMT and the LM, calculated by subtracting the predicted probability of the LM from that of the NMT model for each token. The Margin is negatively correlated to the overconfidence degree of the LM. Based on the property, we propose a Margin-based Token-level Objective (MTO) and a Margin-based Sentencelevel Objective (MSO) to maximize the Margin for preventing the LM from being overconfident. Experiments on WMT14 Englishto-German, WMT19 Chinese-to-English, and WMT14 English-to-French translation tasks demonstrate the effectiveness of our approach, with 1.36, 1.50, and 0.63 BLEU improvements, respectively, compared to the Transformer baseline. The human evaluation further verifies that our approaches improve translation adequacy as well as fluency.
OI Zhou, Xiaohua/0000-0001-7935-1222
BN 978-1-954085-52-7
PY 2021
BP 3456
EP 3468
UT WOS:000698679200068
ER

PT C
AU Krupakar, H
   Rajvel, K
   Bharathi, B
   Deborah, SA
   Krishnamurthy, V
AF Krupakar, Hans
   Rajvel, Keerthika
   Bharathi, B.
   Deborah, Angel S.
   Krishnamurthy, Vallidevi
GP IEEE
TI A SURVEY OF VOICE TRANSLATION METHODOLOGIES ACOUSTIC - DIALECT DECODER
SO 2016 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED
   SYSTEMS (ICICES)
CT International Conference on Information Communication and Embedded
   Systems (ICICES)
CY FEB 25-26, 2016
CL Thiruverkadu, INDIA
SP S A Engn Coll, S A Engn Coll, Dept Comp Sci & Engn, S A Engn Coll, Elect Commun & Engn, S A Engn Coll, Elect & Elect Engn
AB Language Translation has always been about inputting source as text/audio and waiting for system to give translated output in desired form. In this paper, we present the Acoustic Dialect Decoder (ADD) - a voice to voice earpiece translation device. We introduce and survey the recent advances made in the field of Speech Engineering, to employ in the ADD, particularly focusing on the three major processing steps of Recognition, Translation and Synthesis. We tackle the problem of machine understanding of natural language by designing a recognition unit for source audio to text, a translation unit for source language text to target language text, and a synthesis unit for target language text to target language speech. Speech from the surroundings will be recorded by the recognition unit present on the ear-piece and translation will start as soon as one sentence is successfully read. This way, we hope to give translated output as and when input is being read. The recognition unit will use Hidden Markov Models (HMMs) Based Tool-Kit (HTK), RNNs with LSTM cells, and the synthesis unit, HMM based speech synthesis system HTS. This system will initially be built as an English to Tamil translation device.
RI Krishnamurthy, Vallidevi/GZA-5938-2022; B., Bharathi/GXV-8824-2022
OI Krishnamurthy, Vallidevi/0000-0001-8445-2036; B.,
   Bharathi/0000-0001-7279-5357
BN 978-1-5090-2552-7
PY 2016
UT WOS:000390717500097
ER

PT C
AU Yang, ZD
   Chen, ZB
   Pang, W
   Wei, W
   Xu, B
AF Yang, ZD
   Chen, ZB
   Pang, W
   Wei, W
   Xu, B
GP IEEE
TI The CASIA phrase-based machine translation system
SO PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON NATURAL
   LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING (IEEE NLP-KE'05)
CT International Conference on Natural Language Processing and Knowledge
   Engineering
CY OCT 30-NOV 01, 2005
CL Wuhan, PEOPLES R CHINA
SP IEEE, AAI, CIPSC, Chinese Assoc Artificial Intelligence, IEEE Signal Proc Soc, IEEE Beijing Sect
AB In this paper we propose a phrase-based translation system. In the system, we use phrase translation model instead of word-based model. An improved method to compute phrase translation probability is studied. A phrase-based decoder we developed employs a beam search algorithm, in which some target language words that have both high frequency of appearance and also fertility zero are introduced to make the result more reasonable. We improve the previously proposed tracing back algorithm to get the best path. Some experiments concerned are presented.
BN 0-7803-9361-9
PY 2005
BP 416
EP 419
UT WOS:000235577200078
ER

PT S
AU Castano, MA
   Casacuberta, F
AF Castano, MA
   Casacuberta, F
BE Mira, J
   SanchezAndres, JV
TI Text-to-text machine translation using the RECONTRA connectionist model
SO ENGINEERING APPLICATIONS OF BIO-INSPIRED ARTIFICIAL NEURAL NETWORKS, VOL
   II
SE Lecture Notes in Computer Science
CT 5th International Work-Conference on Artificial and Natural Neural
   Networks (IWANN 99)
CY JUN 02-04, 1999
CL ALICANTE, SPAIN
SP Asociac Espanola Redes Neuronales, Univ Nacl Educ Distancia, Univ Miguel Hernandez, IFIP, Spanish RIG IEEE Neural Networks Council
AB Encouragingly accurate translations have recently been obtained using a connectionist translator called RECONTRA (Recurrent Connectionist Translator). In contrast to traditional Knowledge-Based systems, this model is built from training data resulting in an Example-Based approach. It directly carries out the translation between the source and target language and employs a simple (recurrent) connectionist topology and a simple training scheme. This paper extends previous work exploring the capabilities of this RECONTRA model to perform text-to-text translations in limited-domain tasks.
RI Castano, M. Asuncion/ABF-6685-2020
OI Castano, M. Asuncion/0000-0002-4010-1813
SN 0302-9743
EI 1611-3349
BN 3-540-66068-2
PY 1999
VL 1607
BP 683
EP 692
UT WOS:000086108300071
ER

PT C
AU Gu, SH
   Feng, Y
   Xie, WY
AF Gu, Shuhao
   Feng, Yang
   Xie, Wanying
GP Assoc Computat Linguist
TI Pruning-then-Expanding Model for Domain Adaptation of Neural Machine
   Translation
SO 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021)
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 06-11, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, N Amer Chapter, Google Res, Amazon Sci, Apple, Facebook AI, Megagon Labs, Microsoft, Bloomberg Engn, Grammarly, IBM, Vanguard, Duolingo, Babelscape, Human Language Technol, LegalForce
AB Domain Adaptation is widely used in practical applications of neural machine translation, which aims to achieve good performance on both general domain and in-domain data. However, the existing methods for domain adaptation usually suffer from catastrophic forgetting, large domain divergence, and model explosion. To address these three problems, we propose a method of "divide and conquer" which is based on the importance of neurons or parameters for the translation model. In this method, we first prune the model and only keep the important neurons or parameters, making them responsible for both general-domain and in-domain translation. Then we further train the pruned model supervised by the original whole model with knowledge distillation. Last we expand the model to the original size and fine-tune the added parameters for the in-domain translation. We conducted experiments on different language pairs and domains and the results show that our method can achieve significant improvements compared with several strong baselines.
BN 978-1-954085-46-6
PY 2021
BP 3942
EP 3952
UT WOS:000895685604006
ER

PT C
AU Nishimura, T
   Akiba, T
AF Nishimura, Tomoki
   Akiba, Tomoyosi
GP IEEE
TI Addressing Unknown Word Problem for Neural Machine Translation using
   Distributed Representations of Words as Input Features
SO 2017 4TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATICS, CONCEPTS,
   THEORY, AND APPLICATIONS (ICAICTA) PROCEEDINGS
CT 4th International Conference on Advanced Informatics Concepts, Theory
   and Applications (ICAICTA)
CY AUG 16-18, 2017
CL Bali, INDONESIA
SP Sekolah Teknik Elektro dan Informatika, Univ Pendidikan Ganesha, IEEE Advancing Technol Human, Univ Sains Malaysia, Toyohashi Univ Technol, Burapha Univ
AB In recent years, the machine translation system based on neural network, called Neural Machie Translation, have attracted much attention, in which the entire translation steps are implemented in a single large neural network. In this framework, dealing with a large vocabulary size on its input (source) and output (target) often make the training computationally intractable. Therefore, the most frequent words in training data are retained to form a small vocabulary (shortlist), and the other, not frequent, words are all mapped to a single shared token. That causes so-called the unknown word problem. In this work, we propose three, rather simple, methods to overcome the unknown word problem based on distributed representation of words. We compared the translation performances of baseline and the proposed methods through experimental evaluation. Though the proposed methods did not improved the baseline in terms of BLEU, we found several evidences that the proposed methods successfully select appropriate target words even if their source words are out-of-vocabulary.
BN 978-1-5386-3001-3
PY 2017
UT WOS:000426983200023
ER

PT C
AU Ye, N
   Wang, YY
   Cai, DF
AF Ye, Na
   Wang, Yuanyuan
   Cai, Dongfeng
BE Huang, S
   Knight, K
TI Incorporating Syntactic Knowledge in Neural Quality Estimation for
   Machine Translation
SO MACHINE TRANSLATION, CCMT 2019
SE Communications in Computer and Information Science
CT 15th China Conference on Machine Translation (CCMT)
CY SEP 27-29, 2019
CL Jiangxi Normal Univ, Nanchang, PEOPLES R CHINA
SP Chinese Informat Proc Soc China, Kingsoft AI, Global Tone Commun Technol Co Ltd, Sogou Inc, NiuTrans Res, Tencent Technol Co Ltd
HO Jiangxi Normal Univ
AB Translation quality estimation aims at evaluating the machine translation output without references. State-of-the-art quality estimation methods based on neural networks have certain capability of implicitly learning the syntactic information from sentence-aligned parallel corpus. However, they still fail to capture the deep structural syntactic details of the sentences. This paper proposes a method that explicitly incorporates source syntax in neural quality estimation. Specifically, the parse trees of source sentences are linearized, and the sequence labels are combined with the source sequence through hierarchical encoding to obtain a more complete and deeper source encoding vector. The hidden relationships between the source syntactic structure and the translation quality are modeled to discover the syntactic errors in the translation. Experimental results on WMT17 quality estimation datasets show that the sentence-level Pearson correlation score and the word-level F-1-mult score can both be improved by the syntactic knowledge.
SN 1865-0929
EI 1865-0937
BN 978-981-15-1721-1; 978-981-15-1720-4
PY 2019
VL 1104
BP 23
EP 34
DI 10.1007/978-981-15-1721-1_3
UT WOS:000833546400003
ER

PT C
AU Dankers, V
   Lucas, CG
   Titov, I
AF Dankers, Verna
   Lucas, Christopher G.
   Titov, Ivan
GP Assoc Computat Linguist
TI Can Transformer be Too Compositional? Analysing Idiom Processing in
   Neural Machine Translation
SO PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS)
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB Unlike literal expressions, idioms' meanings do not directly follow from their parts, posing a challenge for neural machine translation (NMT). NMT models are often unable to translate idioms accurately and over-generate compositional, literal translations. In this work, we investigate whether the non-compositionality of idioms is reflected in the mechanics of the dominant NMT model, Transformer, by analysing the hidden states and attention patterns for models with English as source language and one of seven European languages as target language. When Transformer emits a non-literal translation - i.e. identifies the expression as idiomatic - the encoder processes idioms more strongly as single lexical units compared to literal expressions. This manifests in idioms' parts being grouped through attention and in reduced interaction between idioms and their context. In the decoder's cross-attention, figurative inputs result in reduced attention on source-side tokens. These results suggest that Transformer's tendency to process idioms as compositional expressions contributes to literal translations of idioms.
BN 978-1-955917-21-6
PY 2022
BP 3608
EP 3626
UT WOS:000828702303045
ER

PT C
AU Hoangt, CDV
   Awt, A
   Nguyen, NTH
AF Hoangt, Cong Duy Vu
   Awt, Aiti
   Nguyen, Nhung T. H.
GP Assoc Computat Linguist
TI A Rule-Augmented Statistical Phrase-based Translation System
SO PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS: SYSTEM DEMONSTRATIONS
CT 52nd Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUN 22-27, 2014
CL Baltimore, MD
SP Assoc Computat Linguist, Baidu, Bloomberg, Google, Microsoft, Nuance, Yahoo Labs, Informat Sci Inst, Xerox Res Ctr Europe, Brandeis Univ, Facebook, Yandex, Amazon Com, IBM Watson, Johns Hopkins Univ, A9, AI@ISI, Xerox
AB Interactive or Incremental Statistical Machine Translation (IMT) aims to provide a mechanism that allows the statistical models involved in the translation process to be incrementally updated and improved. The source of knowledge normally comes from users who either post-edit the entire translation or just provide the translations for wrongly translated domain-specific terminologies. Most of the existing work on IMT uses batch learning paradigm which does not allow translation systems to make use of the new input instantaneously. We introduce an adaptive MT framework with a Rule Definition Language (RDL) for users to amend MT results through translation rules or patterns. Experimental results show that our system acknowledges user feedback via RDL which improves the translations of the baseline system on three test sets for Vietnamese to English translation.
BN 978-1-941643-00-6
PY 2014
BP 73
EP 78
UT WOS:000538328300013
ER

PT C
AU Kothur, SSR
   Knowles, R
   Koehn, P
AF Kothur, Sachith Sri Ram
   Knowles, Rebecca
   Koehn, Philipp
GP Assoc Computat Linguist
TI Document-Level Adaptation for Neural Machine Translation
SO NEURAL MACHINE TRANSLATION AND GENERATION
CT 2nd Workshop on Neural Machine Translation and Generation
CY JUL 20, 2018
CL Melbourne, AUSTRALIA
SP Amazon, Apple, Google
AB It is common practice to adapt machine translation systems to novel domains, but even a well-adapted system may be able to perform better on a particular document if it were to learn from a translator's corrections within the document itself. We focus on adaptation within a single document - appropriate for an interactive translation scenario where a model adapts to a human translator's input over the course of a document. We propose two methods: single-sentence adaptation (which performs online adaptation one sentence at a time) and dictionary adaptation (which specifically addresses the issue of translating novel words). Combining the two models results in improvements over both approaches individually, and over baseline systems, even on short documents. On WMT news test data, we observe an improvement of +1.8 BLEU points and +23.3% novel word translation accuracy and on EMEA data (descriptions of medications) we observe an improvement of +2.7 BLEU points and +49.2% novel word translation accuracy.
BN 978-1-948087-40-7
PY 2018
BP 64
EP 73
UT WOS:000538330600009
ER

PT C
AU Wu, LJ
   Tian, F
   Qin, T
   Lai, JH
   Liu, TY
AF Wu, Lijun
   Tian, Fei
   Qin, Tao
   Lai, Jianhuang
   Liu, Tie-Yan
GP Assoc Computat Linguist
TI A Study of Reinforcement Learning for Neural Machine Translation
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB Recent studies have shown that reinforcement learning (RL) is an effective approach for improving the performance of neural machine translation (NMT) system. However, due to its instability, successfully RL training is challenging, especially in real-world systems where deep models and large datasets are leveraged. In this paper, taking several large-scale translation tasks as testbeds, we conduct a systematic study on how to train better NMT models using reinforcement learning. We provide a comprehensive comparison of several important factors (e.g., baseline reward, reward shaping) in RL training. Furthermore, to fill in the gap that it remains unclear whether RL is still beneficial when monolingual data is used, we propose a new method to leverage RL to further boost the performance of NMT systems trained with source/target monolingual data. By integrating all our findings, we obtain competitive results on WMT14 English-German, WMT17 English-Chinese, and WMT17 Chinese-English translation tasks, especially setting a state-of-the-art performance on WMT17 Chinese-English translation task.
BN 978-1-948087-84-1
PY 2018
BP 3612
EP 3621
UT WOS:000865723403086
ER

PT J
AU McGhan, H
   O'Connor, M
AF McGhan, H
   O'Connor, M
TI PicoJava: A direct execution engine for Java bytecode
SO COMPUTER
AB Key to the central promise inherent in Java technology-"write once, run anywhere"-is the fact that Java programs run on the Java virtual machine, insulating them from any contact with the underlying hardware. Consequently, Java programs must execute indirectly through a translation layer built into the Java virtual machine.
   Translation essentially converts Java virtual machine instructions (called bytecodes) into corresponding machine-specific binary instructions. Bytecode is a single image of a program that will execute identically (in principle) on any system equipped with a JVM.
   The first step toward the development of a new class of Java processors was the creation of the bytecode execution engine itself, called the picoJava core. PicoJava directly executes Java bytecode instructions and provides hardware support for other essential functions of the JVM.
   Executing bytecode instructions in hardware eliminates the need for dynamic translation, thus extending the useful range of Java bytecode programs to embedded environments. By the end of 1998, Java processors like Sun's microJava 701 should be available for evaluation from several licensees of the picoJava core technology.
OI O'Connor, Mike/0000-0003-0944-2393
SN 0018-9162
PD OCT
PY 1998
VL 31
IS 10
BP 22
EP +
DI 10.1109/2.722273
UT WOS:000076218700010
ER

PT J
AU Doi, T
   Sumita, E
AF Doi, T
   Sumita, E
TI Splitting input for machine translation using N-gram language model
   together with utterance similarity
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
AB In order to boost the translation quality of corpus-based MT systems for speech translation, the technique of splitting an input utterance appears promising. In previous research, many methods used word-sequence characteristics like N-gram clues among splitting positions. In this paper, to supplement splitting methods based on word-sequence characteristics, we introduce another clue using similarity based on edit-distance. In our splitting method, we generate candidates for utterance splitting based on N-grams, and select the best one by measuring the utterance similarity against a corpus. This selection is founded on the assumption that a corpus-based MT system can correctly translate an utterance that is similar to an utterance in its training corpus. We conducted experiments using three MT systems: two EBMT systems, one of which uses a phrase as a translation unit and the other of which uses an utterance, and an SMT system. The translation results under various conditions were evaluated by objective measures and a subjective measure. The experimental results demonstrate that the proposed method is valuable for the three systems. Using utterance similarity can improve the translation quality.
SN 1745-1361
PD JUN
PY 2005
VL E88D
IS 6
BP 1256
EP 1264
DI 10.1093/ietisy/e88-d.6.1256
UT WOS:000229824200019
ER

PT J
AU Qu, YY
   Guo, JR
   Wang, XM
AF Qu, Yayuan
   Guo, Jirong
   Wang, Xiaoming
TI On Influencing Factors in Metaphor Variation for Five Elements
   Translation in TCM: A Binomial Logistic Regression Analysis
SO IEEE ACCESS
AB Metaphor variation for English translations of Five Elements will impair the effect of Traditional Chinese Medicine (TCM) international communication. Few studies focus on contributing factors in metaphor variants for Five Elements translations. We model the binary designations for the Five-Element metaphor variants to analyze the internal and external language factors affecting the choice of ontological and structural metaphor, with the data from a corpus of six translations of the Inner Canon of Yellow Emperor. Statistical results unveil that the clause type, the syntax of Causer, language varieties, and the interaction of the clause type and language varieties significantly influence the metaphor variants. The complex interplay of the clause type and language varieties can explain people's cognitive differences in conceptualizing five elements. The study sheds light on the research of the Five Elements translation from the view of Construction Grammar and shows the benefit of machine learning technology for quantitatively describing and explaining the metaphor variation. It may hopefully uncover translators' cognitive mechanisms and pave a new way for TCM translation studies.
OI Wang, Xiaoming/0000-0003-3340-6122
SN 2169-3536
PY 2022
VL 10
BP 99675
EP 99685
DI 10.1109/ACCESS.2022.3206538
UT WOS:000861327300001
ER

PT J
AU Zhou, L
   Zhang, JJ
   Zong, CQ
AF Zhou, Long
   Zhang, Jiajun
   Zong, Chengqing
TI Synchronous Bidirectional Neural Machine Translation
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
AB Existing approaches to neural machine translation (NMT) generate the target language sequence token-by-token from left to right. However, this kind of unidirectional decoding framework cannot make full use of the target-side future contexts which can be produced in a right-to-left decoding direction, and thus suffers from the issue of unbalanced outputs. In this paper, we introduce a synchronous bidirectional-neural machine translation (SB-NMT) that predicts its outputs using left-to-right and right-to-left decoding simultaneously and interactively, in order to leverage both of the history and future information at the same time. Specifically, we first propose a new algorithm that enables synchronous bidirectional decoding in a single model. Then, we present an interactive decoding model in which left-to-right (right-to-left) generation does not only depend on its previously generated outputs, but also relies on future contexts predicted by right-to-left (leftto-right) decoding. We extensively evaluate the proposed SB-NMT model on large-scale NIST Chinese-English, WMT14 EnglishGerman, and WMT18 Russian-English translation tasks. Experimental results demonstrate that our model achieves significant improvements over the strong Transformer model by 3.92, 1.49, and 1.04 BLEU points, respectively, and obtains the state-of-the-art performance on Chinese-English and EnglishGerman translation tasks.
OI Zong, Chengqing/0000-0002-9864-3818
EI 2307-387X
PY 2019
VL 7
BP 91
EP 105
DI 10.1162/tacl_a_00256
UT WOS:000736523200006
ER

PT J
AU Adams, K
   Agesen, O
AF Adams, Keith
   Agesen, Ole
TI A comparison of software and hardware techniques for x86 virtualization
SO ACM SIGPLAN NOTICES
CT 12th International Conference on Architectural Support for Programming
   Languages and Operating Systems
CY OCT 21-25, 2006
CL San Jose, CA
SN 0362-1340
EI 1558-1160
PD NOV
PY 2006
VL 41
IS 11
BP 2
EP 13
DI 10.1145/1168918.1168860
UT WOS:000202972600002
ER

PT J
AU Littau, K
AF Littau, Karin
TI Translation and the materialities of communication
SO TRANSLATION STUDIES
AB This article provides the theoretical coordinates for a set of concerns recently emergent in the humanities that place materiality and its cognates, mediality and technicity, at the centre of intellectual enquiry. The fields of media theory and media philosophy on the one hand, and book history and textual bibliography on the other, despite tenuous links between their intellectual traditions, have each in their own way highlighted the importance that objects, things, media and machines play in the very stakes of civilization. This article works through the implications of this thinking for translation and the study of translation.
RI ZHAO, Gary/E-7678-2017
OI Littau, Karin/0000-0002-9304-295X
SN 1478-1700
EI 1751-2921
PD JAN 2
PY 2016
VL 9
IS 1
BP 82
EP 96
DI 10.1080/14781700.2016.1114211
UT WOS:000366699100006
ER

PT C
AU Xiang, B
   Deng, YG
   Gao, YQ
AF Xiang, Bing
   Deng, Yonggang
   Gao, Yuqing
GP IEEE
TI Unsupervised training for Farsi-English speech-to-speech translation
SO 2008 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING, VOLS 1-12
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
CT 33rd IEEE International Conference on Acoustics, Speech and Signal
   Processing
CY MAR 30-APR 04, 2008
CL Las Vegas, NV
AB Speech-to-speech translation has evolved into an attractive area in recent years with significant progress made by various research groups. However, the translation engines usually suffer from the lack of bilingual training data, especially for low-resource languages. In this paper we present an unsupervised training technique to alleviate this problem by taking advantage of available source language data. Different approaches are proposed and compared through extensive experiments conducted on a speech-to-speech translation task between Farsi and English. The translation performance is significantly improved in both directions with the enhanced translation model. A state-of-the-art Farsi automatic speech recognition system is also established in this work.
SN 1520-6149
BN 978-1-4244-1483-3
PY 2008
BP 4977
EP 4980
UT WOS:000257456703228
ER

PT C
AU Yan, R
   Gao, MK
   Pavlick, E
   Callison-Burch, C
AF Yan, Rui
   Gao, Mingkun
   Pavlick, Ellie
   Callison-Burch, Chris
BE Toutanova, K
   Wu, H
TI Are Two Heads Better than One? Crowdsourced Translation via a Two-Step
   Collaboration of Non-Professional Translators and Editors
SO PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS, VOL 1
CT 52nd Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUN 22-27, 2014
CL Baltimore, MD
SP Assoc Computat Linguist, Baidu, Bloomberg, Google, Microsoft, Nuance, Yahoo Labs, Informat Sci Inst, Xerox Res Ctr Europe, Brandeis Univ, Facebook, Yandex, Amazon Com, IBM Watson, Johns Hopkins Univ, A9, AI@ISI, Xerox
AB Crowdsourcing is a viable mechanism for creating training data for machine translation. It provides a low cost, fast turnaround way of processing large volumes of data. However, when compared to professional translation, naive collection of translations from non-professionals yields low-quality results. Careful quality control is necessary for crowdsourcing to work well. In this paper, we examine the challenges of a two-step collaboration process with translation and post-editing by non-professionals. We develop graph-based ranking models that automatically select the best output from multiple redundant versions of translations and edits, and improves translation quality closer to professionals.
BN 978-1-937284-72-5
PY 2014
BP 1134
EP 1144
UT WOS:000493814100107
ER

PT C
AU Fukuda, R
   Sudoh, K
   Nakamura, S
AF Fukuda, Ryo
   Sudoh, Katsuhito
   Nakamura, Satoshi
GP Assoc Comp Linguist
TI NAIST's Machine Translation Systems for IWSLT 2020 Conversational Speech
   Translation Task
SO 17TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE TRANSLATION (IWSLT
   2020)
CT 17th International Conference on Spoken Language Translation (IWSLT)
CY JUL 09-10, 2020
CL ELECTR NETWORK
AB This paper describes NAIST's NMT system submitted to the IWSLT 2020 conversational speech translation task. We focus on the translation disfluent speech transcripts that include ASR errors and non-grammatical utterances. We tried a domain adaptation method by transferring the styles of out-of-domain data (United Nations Parallel Corpus) to be like in-domain data (Fisher transcripts). Our system results showed that the NMT model with domain adaptation outperformed a baseline. In addition, slight improvement by the style transfer was observed.
BN 978-1-952148-07-1
PY 2020
BP 172
EP 177
UT WOS:000563427100021
ER

PT J
AU Fu, J
   Chiba, Y
   Nose, T
   Ito, A
AF Fu, Jiang
   Chiba, Yuya
   Nose, Takashi
   Ito, Akinori
TI Language modeling in speech recognition for grammatical error detection
   based on neural machine translation
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
SN 1346-3969
EI 1347-5177
PY 2020
VL 41
IS 5
BP 788
EP 791
DI 10.1250/ast.41.788
UT WOS:000562996400011
ER

PT C
AU Li, MQ
   Cheng, HD
   Wang, YJ
   Zhang, SJ
   Wu, LT
   Guo, YH
AF Li, Minqin
   Cheng, Haodong
   Wang, Yuanjie
   Zhang, Sijia
   Wu, Liting
   Guo, Yuhang
GP Assoc Computat Linguist
TI BIT's system for the AutoSimTrans 2020
SO WORKSHOP ON AUTOMATIC SIMULTANEOUS TRANSLATION CHALLENGES, RECENT
   ADVANCES, AND FUTURE DIRECTIONS
CT 1st Workshop on Automatic Simultaneous Translation Challenges, Recent
   Advances, and Future Directions (AutoSimTrans)
CY JUL 10, 2020
CL ELECTR NETWORK
AB This paper describes our machine translation systems for the streaming Chinese-to-English translation task of AutoSimTrans 2020. We present a sentence length based method and a sentence boundary detection model based method for the streaming input segmentation. Experimental results of the transcription and the ASR output translation on the development data sets show that the translation system with the detection model based method outperforms the one with the length based method in BLEU score by 1.19 and 0.99 respectively under similar or better latency.
BN 978-1-952148-23-1
PY 2020
BP 37
EP 44
UT WOS:000563392400006
ER

PT J
AU Mauro, VP
   Edelman, GM
AF Mauro, Vincent P.
   Edelman, Gerald M.
TI The ribosome filter redux
SO CELL CYCLE
AB The ribosome filter hypothesis postulates that ribosomes are not simply translation machines but also function as regulatory elements that differentially affect or filter the translation of particular mRNAs. On the basis of new information, we take the opportunity here to review the ribosome filter hypothesis, suggest specific mechanisms of action, and discuss recent examples from the literature that support it.
SN 1538-4101
EI 1551-4005
PD SEP 15
PY 2007
VL 6
IS 18
BP 2246
EP 2251
DI 10.4161/cc.6.18.4739
UT WOS:000251085600010
PM 17890902
ER

PT J
AU Federici, FM
   Al Sharou, K
AF Federici, Federico M.
   Al Sharou, Khetam
TI Moses, time, and crisis translation
SO TRANSLATION AND INTERPRETING STUDIES
AB Training translators to react to sudden emergencies is a challenge. This article presents the results of a training experiment testing the speed of acquisition of the skills necessary to operate the open-source Moses statistical machine translation (SMT) system. A task-based approach was used with trainee translators who had no experience working with MT technology. The experiment is a feasibility study to ascertain whether training on Moses SMT could be considered for long-lasting crisis scenarios. The article reports its findings in four sections. The first section discusses the research context in which 'crisis translation' is defined; the second section illustrates the rationale of the experiment; the third section looks at the results of the training experiment; and the fourth at the trainees' perceptions of their learning processes. The conclusion reflects on the viability of using Moses and on the next phases needed to refine the findings of this first experiment.
RI Federici, Federico Marco/E-9442-2013
OI Federici, Federico Marco/0000-0002-0057-0340
SN 1932-2798
EI 1876-2700
PY 2018
VL 13
IS 3
BP 486
EP 508
DI 10.1075/tis.00026.fed
UT WOS:000449740700008
ER

PT J
AU Yan, R
   Li, J
   Su, XD
   Wang, XM
   Gao, GL
AF Yan, Rong
   Li, Jiang
   Su, Xiangdong
   Wang, Xiaoming
   Gao, Guanglai
TI Boosting the Transformer with the BERT Supervision in Low-Resource
   Machine Translation
SO APPLIED SCIENCES-BASEL
AB Previous works trained the Transformer and its variants end-to-end and achieved remarkable translation performance when there are huge parallel sentences available. However, these models suffer from the data scarcity problem in low-resource machine translation tasks. To deal with the mismatch problem between the big model capacity of the Transformer and the small parallel training data set, this paper adds the BERT supervision on the latent representation between the encoder and the decoder of the Transformer and designs a multi-step training algorithm to boost the Transformer on such a basis. The algorithm includes three stages: (1) encoder training, (2) decoder training, and (3) joint optimization. We introduce the BERT of the target language in the encoder and the decoder training and alleviate the data starvation problem of the Transformer. After the training stage, the BERT will not further attend the inference section explicitly. Another merit of our training algorithm is that it can further enhance the Transformer in the task where there are limited parallel sentence pairs but large amounts of monolingual corpus of the target language. The evaluation results on six low-resource translation tasks suggest that the Transformer trained by our algorithm significantly outperforms the baselines which were trained end-to-end in previous works.
OI Su, Xiangdong/0000-0001-8061-1474
EI 2076-3417
PD JUL
PY 2022
VL 12
IS 14
AR 7195
DI 10.3390/app12147195
UT WOS:000833672300001
ER

PT C
AU Zhang, LL
AF Zhang, Linlin
GP Assoc Computat Linguist
TI ZJU's IWSLT 2021 Speech Translation System
SO IWSLT 2021: THE 18TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE
   TRANSLATION
CT 18th International Conference on Spoken Language Translation (IWSLT)
CY AUG 05-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB In this paper, we describe Zhejiang University's submission to the IWSLT2021 Multilingual Speech Translation Task. This task focuses on speech translation (ST) research across many non-English source languages. Participants can decide whether to work on constrained systems or unconstrained systems which can use external data. We create both cascaded and end-to-end speech translation constrained systems, using the provided data only. In the cascaded approach, we combine Conformer-based automatic speech recognition (ASR) with the Transformer-based neural machine translation (NMT). Our end-to-end direct speech translation systems use ASR pre-trained encoder and multi-task decoders. The submitted systems are ensembled by different cascaded models.
BN 978-1-954085-74-9
PY 2021
BP 144
EP 148
UT WOS:000694723100016
ER

PT C
AU Kanis, J
AF Kanis, Jakub
BE Sojka, P
   Horak, A
   Kopecek, I
   Pala, K
TI Digging Language Model - Maximum Entropy Phrase Extraction
SO TEXT, SPEECH, AND DIALOGUE
SE Lecture Notes in Artificial Intelligence
CT 19th International Conference on Text, Speech, and Dialogue (TSD)
CY SEP 12-16, 2016
CL Brno, CZECH REPUBLIC
SP Masaryk Univ, Fac Informat, Univ W Bohemia, Fac Appl Sci, Lex Comp Ltd, IBM Ceska Republika spol s r o
AB This work introduces our maximum entropy phrase extraction method for the Czech - English translation task. Two different corpora and language models of the different sizes were used to explore a potential of the maximum entropy phrase extraction method and phrase table content optimization. Additionally, two different maximum entropy estimation criteria were compared with the state of the art phrase extraction method too. In the case of a domain oriented translation, maximum entropy phrase extraction significantly improves translation precision.
RI Kanis, Jakub/H-2746-2016; Kanis, Jakub/Y-8629-2019
OI Kanis, Jakub/0000-0001-6001-8884; 
SN 0302-9743
EI 1611-3349
BN 978-3-319-45509-9; 978-3-319-45510-5
PY 2016
VL 9924
BP 46
EP 53
DI 10.1007/978-3-319-45510-5_6
UT WOS:000389707400006
ER

PT J
AU Lee, SM
AF Lee, Sangmin-Michelle
TI The impact of using machine translation on EFL students' writing
SO COMPUTER ASSISTED LANGUAGE LEARNING
AB Although it remains controversial, machine translation (MT) has gained popularity both inside and outside of the classroom. Despite the growing number of students using MT, little is known about its use as a pedagogical tool in the EFL classroom. The present study investigated the role of MT as a CALL tool in EFL writing. Most studies on MT as a tool for L2 learning have focused on student postediting of the translation that MT provides; however, the present study employed a different design with students translating their L1 writing into L2 without the help of MT and then correcting their L2 writing using the MT translation for comparison. Text analysis of students' writing outcomes revealed that MT helped to decrease lexico-grammatical errors and improve student revisions. Using MT for revisions also positively affected student writing strategies and helped them think of writing as a process. The interviews and reflection papers demonstrated that students viewed the use of MT during writing positively. This study found that MT can be a useful aid to language learning, but for it to benefit student learning, teachers must be aware of its limitations and provide adequate guidance to students.
RI Lee, Sangmin/S-7929-2019
OI Lee, Sangmin-Michelle/0000-0002-7686-3537
SN 0958-8221
EI 1744-3210
PD MAR 3
PY 2020
VL 33
IS 3
BP 157
EP 175
DI 10.1080/09588221.2018.1553186
UT WOS:000526447900001
ER

PT C
AU Zhan, RZ
   Liu, XB
   Wong, DF
   Chao, LS
AF Zhan, Runzhe
   Liu, Xuebo
   Wong, Derek F.
   Chao, Lidia S.
GP Assoc Computat Linguist
TI Difficulty-Aware Machine Translation Evaluation
SO ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON
   NATURAL LANGUAGE PROCESSING, VOL 2
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB The high-quality translation results produced by machine translation (MT) systems still pose a huge challenge for automatic evaluation. Current MT evaluation pays the same attention to each sentence component, while the questions of real-world examinations (e.g., university examinations) have different difficulties and weightings. In this paper, we propose a novel difficulty-aware MT evaluation metric, expanding the evaluation dimension by taking translation difficulty into consideration. A translation that fails to be predicted by most MT systems will be treated as a difficult one and assigned a large weight in the final score function, and conversely. Experimental results on the WMT19 English <-> German Metrics shared tasks show that our proposed method outperforms commonly-used MT metrics in terms of human correlation. In particular, our proposed method performs well even when all the MT systems are very competitive, which is when most existing metrics fail to distinguish between them. The source code is freely available at https://github.com/NLP2CT/Difficulty-Aware-MT-Evaluation.
RI Wong, Derek F/CAI-7740-2022
BN 978-1-954085-53-4
PY 2021
BP 26
EP 32
UT WOS:000694699200005
ER

PT C
AU Boitet, C
   Huynh, CP
   Blanchon, H
   Nguyen, HT
AF Boitet, Christian
   Huynh, Cong-Phap
   Blanchon, Herve
   Nguyen, Hong-Thai
BE Cao, T
   Kutsche, RD
   Demaille, A
TI A Web-oriented System to Manage the Translation of an Online
   Encyclopedia Using Classical MT and Deconversion from UNL
SO 2009 IEEE-RIVF INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION
   TECHNOLOGIES: RESEARCH, INNOVATION AND VISION FOR THE FUTURE
CT IEEE-RIVF International Conference on Computing and Communication
   Technologies
CY JUL 13-17, 2009
CL Da Nang Univ Technol, Da Nang, VIETNAM
SP IEEE Vietnam Sect, IEEE Reg 10, IEEE Commun Soc, IEEE Computat Intelligence Soc, Telecom ParisTech, EPITA
HO Da Nang Univ Technol
AB We start from a web-oriented system for evaluating, presenting, processing, enlarging and annotating corpora of translations, previously applied to a real MT evaluation task, involving classical subjective measures, objective n-gram-based scores, and objective post-edition-based task-related evaluation. We describe its recent extension to support the high-quality translation into French of the large on-line Encyclopedia of Life Support Systems (EOLSS) presented as documents each made of a web page and a companion UNL file, by applying contributive on-line human post-edition to results of Machine Translation systems and of UNL deconverters. Target language web pages are generated on the fly from source language ones, using the best target segments available in the database. 25 documents (about 220,000 words) of the EOLSS are now available in French, Spanish, Russian, Arabic and Japanese. MT followed by contributive incremental cheap or free post-edition is now proved to be a viable way of making difficult information available in many languages.
BN 978-1-4244-4567-7
PY 2009
BP 148
EP 155
UT WOS:000272785400024
ER

PT C
AU Mizera-Pietraszko, J
   Kolaczek, G
   Jorge, RR
AF Mizera-Pietraszko, Jolanta
   Kolaczek, Grzegorz
   Jorge, Ricardo Rodriguez
BE Jedrzejowicz, P
   Yildirim, T
   Czarnowski, I
TI Source-Target Mapping Model of Streaming Data Flow for Machine
   Translation
SO 2017 IEEE INTERNATIONAL CONFERENCE ON INNOVATIONS IN INTELLIGENT SYSTEMS
   AND APPLICATIONS (INISTA)
CT IEEE International Conference on INnovations in Intelligent SysTems and
   Applications (INISTA)
CY JUL 03-05, 2017
CL Gdynia, POLAND
SP Yildiz Tech Univ, IEEE Poland Sect, IEEE Syst Man & Cybernet Soc, Gdynia Maritime Univ Students & Alumni Fdn, Gdynia Maritime Univ, IEEE, IEEE Syst Man & Cybernet Soc Chapter, Poland Sect, IEEE Syst Man & Cybernet Soc Tech Comm Computat Collect Intelligence
AB Streaming information flow allows identification of linguistic similarities between language pairs in real time as it relies on pattern recognition of grammar rules, semantics and pronunciation especially when analyzing so called international terms, syntax of the language family as well as tenses transitivity between the languages. Overall, it provides a backbone translation knowledge for building automatic translation system that facilitates processing any of various abstract entities which combine to specify underlying phonological, morphological, semantic and syntactic properties of linguistic forms and that act as the targets of linguistic rules and operations in a source language following professional human translator. Streaming data flow is a process of mining source data into target language transformation during which any inference impedes the system effectiveness by producing incorrect translation. We address a research problem of exploring streaming data from source-target parallels for detection of linguistic similarities between languages originated from different groups.
RI Mizera-Pietraszko, Jolanta JMP/A-3842-2010; Rodriguez,
   Ricardo/GXF-0596-2022; Rodriguez Jorge, Ricardo/N-7903-2017;
   Mizera-Pietraszko, Jolanta/H-8227-2016
OI Rodriguez Jorge, Ricardo/0000-0002-4575-5082; Mizera-Pietraszko,
   Jolanta/0000-0002-2298-5037; Kolaczek, Grzegorz/0000-0001-7125-0988
BN 978-1-5090-5795-5
PY 2017
BP 490
EP 494
UT WOS:000450992400079
ER

PT C
AU Qian, W
   Komiya, K
   Kotani, Y
AF Qian, Wang
   Komiya, Kanako
   Kotani, Yoshiyuki
GP IEEE Comp Soc
TI Automatic Extraction of Chinese/Japanese Translation Patterns Using
   Prefix Span
SO 2011 INTERNATIONAL CONFERENCE ON TECHNOLOGIES AND APPLICATIONS OF
   ARTIFICIAL INTELLIGENCE (TAAI 2011)
SE Conference on Technologies and Applications of Artificial Intelligence
CT 16th Annual International Conference on Technologies and Applications of
   Artificial Intelligence (TAAI)
CY NOV 11-13, 2011
CL Chung Li, TAIWAN
SP IEEE Comp Soc, Taiwanese Assoc AI, Japanese Soc Artificial Intelligence, Yuan Ze Univ, Natl Cent Univ
AB In late years, a large number of translation patterns are required for the pattern based machine translation. We propose an efficient method to extract the Chinese/Japanese translation patterns from the corpora using Prefix Span. We performed word segmentation on the sentence pairs of the parallel corpora, collected the candidate translation patterns from them using Prefix Span, and narrow down the candidates using two criteria: the pointwise mutual information (PMI) and the degree of confidence for the threshold values. The proposed method achieved precision 85% when the PMI is 1.0 and the degree of confidence is 0.15.
RI Komiya, Kanako/ACB-7790-2022
OI Komiya, Kanako/0000-0001-6405-1067
SN 2376-6816
EI 2376-6824
BN 978-0-7695-4601-8
PY 2011
BP 139
EP 144
DI 10.1109/TAAI.2011.31
UT WOS:000399726900022
ER

PT C
AU Aceves-Perez, RM
   Montes-Y-Gomez, M
   Villasenor-Pineda, L
AF Aceves-Perez, Rita M.
   Montes-y-Gomez, Manuel
   Villasenor-Pineda, Luis
BE Gelbukh, A
TI Enhancing Cross-Language Question Answering by combining multiple
   question translations
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING
SE Lecture Notes in Computer Science
CT 8th International Conference on Intelligent Text Processing and
   Computational Linguistics
CY FEB 18-24, 2007
CL Mexico City, MEXICO
SP IPN, Nat Language & Text Proc Lab
AB One major problem of state-of-the-art Cross Language Question Answering systems is the translation of user questions. This paper proposes combining the potential of multiple translation machines in order to improve the final answering precision. In particular, it presents three different methods for this purpose. The first one focuses on selecting the most fluent translation from a given set; the second one combines the passages recovered by several question translations; finally, the third one constructs a new question reformulation by merging word sequences from different translations. Experimental results demonstrated that the proposed approaches allow reducing the error rates in relation to a monolingual question answering exercise.
RI Villasenor-Pineda, Luis/A-2932-2009
OI Villasenor-Pineda, Luis/0000-0003-1294-9128
SN 0302-9743
EI 1611-3349
BN 978-3-540-70938-1
PY 2007
VL 4394
BP 485
EP 493
UT WOS:000244441100043
ER

PT J
AU Sosoni, V
AF Sosoni, Vilelmini
TI Casting some light on experts' experience with translation crowdsourcing
SO JOURNAL OF SPECIALISED TRANSLATION
AB This paper reports on an empirical study concerning professional translators' attitudes towards and experience with translation crowdsourcing. In particular, it seeks to explore how professional translators perceive translation crowdsourcing and what concerns they raise, if any. It also aims at identifying any problems they may face as crowdworkers during the translation process. The investigation takes place in the framework of the TraMOOC (Translation for Massive Open Online Courses) research and innovation project where a crowd of professional translators is used for the translation into Greek (EL) of English (EN) MOOC (Massive Open Online Courses) educational data on the CrowdFlower platform with the end goal of using such translations to train and tune a machine translation (MT) system. It concludes highlighting the unexpected benefits that crowdsourcing may bring to professional translators.
RI Alidadi, Mehdi/HJZ-0235-2023
OI Alidadi, Mehdi/0000-0001-5183-7829; Sosoni,
   Vilelmini/0000-0002-9583-4651
SN 1740-357X
PD JUL
PY 2017
IS 28
BP 362
EP 384
UT WOS:000424447000017
ER

PT C
AU Ohgushi, M
   Neubig, G
   Sakti, S
   Toda, T
   Nakamura, S
AF Ohgushi, Masaya
   Neubig, Graham
   Sakti, Sakriani
   Toda, Tomoki
   Nakamura, Satoshi
BE Bimbot, F
   Cerisara, C
   Fougeron, C
   Gravier, G
   Lamel, L
   Pellegrino, F
   Perrier, P
TI An Empirical Comparison of Joint Optimization Techniques for Speech
   Translation
SO 14TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2013), VOLS 1-5
SE Interspeech
CT 14th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2013)
CY AUG 25-29, 2013
CL Lyon, FRANCE
SP Int Speech Commun Assoc, europa org, amazon, Microsoft, Google, TcL SYTRAL, European Language Resources Assoc, ouaero, imaginove, VOCAPIA res, acapela, speech ocean, ALDEBARAN, orange, vecsys, IBM Res, Raytheon BBN Technol, voxygen
AB Speech translation (ST) systems consist of three major components: automatic speech recognition (ASR), machine translation (MT), and speech synthesis (SS). In general the ASR system is tuned independently to minimize word error rate (WER), but previous research has shown that ASR and MT can be jointly optimized to improve translation quality [1]. Independently, many techniques have recently been proposed for the optimization of MT, such as empirical comparison of joint optimization using minimum error rate training (MERT) [2], pair wise ranking optimization (PRO) [3] and the batch margin infused relaxed algorithm (MIRA) [4]. The first contribution of this paper is an empirical comparison of these techniques in the context of joint optimization. As the last two methods are able to use sparse features, we also introduce lexicalized features using the frequencies of recognized words. In addition, motivated by initial results, we propose a hybrid optimization method that changes the translation evaluation measure depending on the features to be optimized. Experimental results for the best combination of algorithm and features show a gain of 1.3 BLEU points at 27% of the computational cost of previous joint optimization methods.
OI Toda, Tomoki/0000-0001-8146-1279
SN 2308-457X
BN 978-1-62993-443-3
PY 2013
BP 2618
EP 2622
UT WOS:000395050001062
ER

PT C
AU Zhang, JC
   Liu, Q
   Zhou, J
AF Zhang, Jinchao
   Liu, Qun
   Zhou, Jie
BE Sierra, C
TI ME-MD: An Effective Framework for Neural Machine Translation with
   Multiple Encoders and Decoders
SO PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON
   ARTIFICIAL INTELLIGENCE
CT 26th International Joint Conference on Artificial Intelligence (IJCAI)
CY AUG 19-25, 2017
CL Melbourne, AUSTRALIA
SP Int Joint Conf Artifical Intelligence, Victoria Govt, Melbourne Convent Bur, Artificial Intelligence Journal, Alibaba Grp, Xiaoi, Tencent, JD.com, Meitu Inc, Didi ChuXing, Baidu, Ant Financial Serv Grp, Australian Comp Soc, Natl Sci Fdn, Univ Technol Sydney, Griffith Univ, Univ Sydney, Royal Melbourne Inst Technol Univ, Melbourne Univ, Australian Natl Univ, King Abdullah Univ Sci & Technol, Data61, Adobe, IBM, NNAISENCE, AUBOT, So Univ Sci & Technol, Monash Univ, Auckland Univ Technol, Univ New S Wales, Assumption University of Thailand, Future Univ Hakodate, Deakin Univ, Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, Nanyang Technological University, Federation Univ, Univ Queensland, Facebook, Microsoft, BigML, Essence, Nuance, NVIDIA, XENON
AB The encoder-decoder neural framework is widely employed for Neural Machine Translation (NMT) with a single encoder to represent the source sentence and a single decoder to generate target words. The translation performance heavily relies on the representation ability of the encoder and the generation ability of the decoder. To further enhance NMT, we propose to extend the original encoder-decoder framework to a novel one, which has multiple encoders and decoders (ME-MD). Through this way, multiple encoders extract more diverse features to represent the source sequence and multiple decoders capture more complicated translation knowledge. Our proposed ME-MD framework is convenient to integrate heterogeneous encoders and decoders with multiple depths and multiple types. Experiment on Chinese-English translation task shows that our ME-MD system surpasses the state-of-the-art NMT system by 2.1 BLEU points and surpasses the phrase-based Moses by 7.38 BLEU points. Our framework is general and can be applied to other sequence to sequence tasks.
BN 978-0-9992411-0-3
PY 2017
BP 3392
EP 3398
UT WOS:000764137503073
ER

PT J
AU Chen, KH
   Yang, MY
   Zhao, TJ
   Zhang, M
AF Chen, Kehai
   Yang, Muyun
   Zhao, Tiejun
   Zhang, Min
TI Data-Driven Fuzzy Target-Side Representation for Intelligent Translation
   System
SO IEEE TRANSACTIONS ON FUZZY SYSTEMS
AB The encoder-decoder framework has been widely used in various practical artificial intelligence cyber-physical systems, including intelligent translation systems. The decoding process in such a framework usually demands the target-side representation, which is often learned by an autoaggressive decoder to simulate the target context information at the current time-step. However, the autoaggressive decoder only captures the previously generated partial target fragment and fails in simulating the global contextual information. In this article, we propose a new data-driven fuzzy context representation strategy to simulate the global target information. Specifically, we design two fuzzy methods to the global target contextual information, which are bag-of-words of target language generated via a softmax layer from the source-side representation and whole target sentence retrieved from the translation memory according to the source-side representation. Both methods facilitate the autoaggressive decoder to handle the global target context at the current time-step, thereby learning a more effective context vector for the generation of target translation. Extensive experiments on two machine translation tasks demonstrated that the proposed method achieved 3% improvement of BLEU score over a strong baseline.
SN 1063-6706
EI 1941-0034
PD NOV
PY 2022
VL 30
IS 11
BP 4568
EP 4577
DI 10.1109/TFUZZ.2022.3167129
UT WOS:000878174700007
ER

PT C
AU Ni, JW
   Jin, ZJ
   Freitag, M
   Sachan, M
   Scholkopf, B
AF Ni, Jingwei
   Jin, Zhijing
   Freitag, Markus
   Sachan, Mrinmaya
   Scholkopf, Bernhard
GP ASSOC COMPUTAT LINGUIST
TI Original or Translated? A Causal Analysis of the Impact of
   Translationese on Machine Translation Performance
SO NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE
   ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES
CT Conference of the
   North-American-Chapter-of-the-Association-for-Computational-Linguistics
   (NAAACL) - Human Language Technologies
CY JUL 10-15, 2022
CL Seattle, WA
SP Assoc Computat Linguist, N Amer Chapter, Amazon Sci, Bloomberg Engn, Google Res, LivepersoMetan, ByteDance, KENSH, Grammarly, Megagon Labs, Microsoft, Reveal Brainspace, Cohere, GResearch, Relativity, Servicenow, ASAPP, Duolingo, Adobe, Linkedin, Babelscape, Rakuten Inst Technol, UC Santa Cruz, Baskin Engn, Nat Language Proc, NSF, ETS, OpenAI, TIAA, Two Sigma, Mag Data
AB Human-translated text displays distinct features from naturally written text in the same language. This phenomena, known as translationese, has been argued to confound the machine translation (MT) evaluation. Yet, we find that existing work on translationese neglects some important factors and the conclusions are mostly correlational but not causal. In this work, we collect CAUSALMT, a dataset where the MT training data are also labeled with the human translation directions. We inspect two additional critical factors, the traintest direction match (whether the human translation directions in the training and test sets are aligned), and data-model direction match (whether the model learns in the same direction as the human translation direction in the dataset). We show that these two factors have a large causal effect on the MT performance, in addition to the test-model direction mismatch highlighted by existing work on translationese. In light of our findings, we provide a set of suggestions for MT training and evaluation.(1)
BN 978-1-955917-71-1
PY 2022
BP 5303
EP 5320
UT WOS:000859869505031
ER

PT C
AU Nguyen, XP
   Joty, S
   Nguyen, TT
   Kui, W
   Aw, AT
AF Xuan-Phi Nguyen
   Joty, Shafiq
   Nguyen, Thanh-Tung
   Kui, Wu
   Aw, Ai Ti
BE Meila, M
   Zhang, T
TI Cross-model Back-translated Distillation for Unsupervised Machine
   Translation
SO INTERNATIONAL CONFERENCE ON MACHINE LEARNING, VOL 139
SE Proceedings of Machine Learning Research
CT International Conference on Machine Learning (ICML)
CY JUL 18-24, 2021
CL ELECTR NETWORK
AB Recent unsupervised machine translation (UMT) systems usually employ three main principles: initialization, language modeling and iterative back-translation, though they may apply them differently. Crucially, iterative back-translation and denoising auto-encoding for language modeling provide data diversity to train the UMT systems. However, the gains from these diversification processes have seemed to plateau. We introduce a novel component to the standard UMT framework called Cross-model Back-translated Distillation (CBD), that is aimed to induce another level of data diversification that existing principles lack. CBD is applicable to all previous UMT approaches. In our experiments, CBD achieves the state of the art in the WMT' 14 English-French, WMT' 16 English-German and English-Romanian bilingual unsupervised translation tasks, with BLEU scores of 38.2, 30.1, and 36.3, respectively. It also yields 1.5 - 3.3 BLEU improvements in IWSLT English-French and English-German tasks. Through extensive experimental analyses, we show that CBD is effective because it embraces data diversity while other similar variants do not.
SN 2640-3498
PY 2021
VL 139
UT WOS:000768182704022
ER

PT J
AU Handsel, J
   Matthews, B
   Knight, NJ
   Coles, SJ
AF Handsel, Jennifer
   Matthews, Brian
   Knight, Nicola J.
   Coles, Simon J.
TI Translating the InChI: adapting neural machine translation to predict
   IUPAC names from a chemical identifier
SO JOURNAL OF CHEMINFORMATICS
AB We present a sequence-to-sequence machine learning model for predicting the IUPAC name of a chemical from its standard International Chemical Identifier (InChI). The model uses two stacks of transformers in an encoder-decoder architecture, a setup similar to the neural networks used in state-of-the-art machine translation. Unlike neural machine translation, which usually tokenizes input and output into words or sub-words, our model processes the InChI and predicts the IUPAC name character by character. The model was trained on a dataset of 10 million InChI/IUPAC name pairs freely downloaded from the National Library of Medicine's online PubChem service. Training took seven days on a Tesla K80 GPU, and the model achieved a test set accuracy of 91%. The model performed particularly well on organics, with the exception of macrocycles, and was comparable to commercial IUPAC name generation software. The predictions were less accurate for inorganic and organometallic compounds. This can be explained by inherent limitations of standard InChI for representing inorganics, as well as low coverage in the training data.
RI Coles, Simon/A-1795-2009; Knight, Nicola/M-8268-2014; Matthews,
   Brian/I-4698-2014
OI Coles, Simon/0000-0001-8414-9272; Knight, Nicola/0000-0001-8286-3835;
   Matthews, Brian/0000-0002-3342-3160
SN 1758-2946
PD OCT 7
PY 2021
VL 13
IS 1
AR 79
DI 10.1186/s13321-021-00535-x
UT WOS:000704971800001
PM 34620215
ER

PT C
AU Bogoychev, N
   Van der Linde, J
   Heafield, K
AF Bogoychev, Nikolay
   Van der Linde, Jelmer
   Heafield, Kenneth
GP Assoc Computat Linguist
TI TranslateLocally: Blazing-fast translation running on the local CPU
SO 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2021): PROCEEDINGS OF SYSTEM DEMONSTRATIONS
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 07-11, 2021
CL Punta Cana, DOMINICAN REP
AB Every day, millions of people sacrifice their privacy and browsing habits in exchange for online machine translation. Companies and governments with confidentiality requirements often ban online translation or pay a premium to disable logging. To bring control back to the end user and demonstrate speed, we developed translateLocally. Running locally on a desktop or laptop CPU, translateLocally delivers cloud-like translation speed and quality even on 10 year old hardware. The open-source software is based on Marian and runs on Linux, Windows, and macOS.
BN 978-1-955917-11-7
PY 2021
BP 168
EP 174
UT WOS:000855241500020
ER

PT C
AU Salesky, E
   Mader, J
   Klinger, S
AF Salesky, Elizabeth
   Maeder, Julian
   Klinger, Severin
GP IEEE
TI ASSESSING EVALUATION METRICS FOR SPEECH-TO-SPEECH TRANSLATION
SO 2021 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU)
CT IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)
CY DEC 13-17, 2021
CL ELECTR NETWORK
SP Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc
AB Speech-to-speech translation combines machine translation with speech synthesis, introducing evaluation challenges not present in either task alone. How to automatically evaluate speech-to-speech translation is an open question which has not previously been explored. Translating to speech rather than to text is often motivated by unwritten languages or languages without standardized orthographies. However, we show that the previously used automatic metric for this task is best equipped for standardized high-resource languages only. In this work, we first evaluate current metrics for speech-to-speech translation, and second assess how translation to dialectal variants rather than to standardized languages impacts various evaluation methods.
OI Salesky, Elizabeth/0000-0001-6765-1447
BN 978-1-6654-3739-4
PY 2021
BP 733
EP 740
DI 10.1109/ASRU51503.2021.9688073
UT WOS:000792364700097
ER

PT J
AU Niu, X
   Yang, D
   Yang, K
   Pan, HY
   Dou, Y
   Xia, F
AF Niu, Xin
   Yang, Di
   Yang, Ke
   Pan, Hengyue
   Dou, Yong
   Xia, Fei
TI Image translation between high-resolution optical and synthetic aperture
   radar (SAR) data
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
AB This paper presents a novel study: remote-sensing image translation between high-resolution optical and Synthetic Aperture Radar (SAR) data through machine learning approaches. To this end, conditional Generative Adversarial Networks (cGANs) have been proposed with the guide of high-level image features. Efficiency of the proposed methods have been verified with different SAR parameters on three regions from the world: Toronto, Vancouver in Canada and Shanghai in China. The generated SAR and optical images have been evaluated by pixel-based image classification with detailed land cover types including: low and high-density residential area, industry area, construction site, golf course, water, forest, pasture and crops. Results showed that the translated image could effectively keep many land cover types with compatible classification accuracy to the ground truth data. In comparison with state-of-the-art image translation approaches, the proposed methods could improve the translation results under the criteria of common similarity indicators. This is one of first study on multi-source remote-sensing data translation by machine learning.
RI Pan, Hengyue/AAB-7412-2022
SN 0143-1161
EI 1366-5901
PD JUN 18
PY 2021
VL 42
IS 12
BP 4762
EP 4788
DI 10.1080/01431161.2020.1836426
UT WOS:000636053000001
ER

PT C
AU Salami, S
   Shamsfard, M
AF Salami, Shahram
   Shamsfard, Mehrnoush
GP IEEE
TI Monotonic filter for hierarchical translation models
SO 2016 6TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING
   (ICCKE)
CT 6th International Conference on Computer and Knowledge Engineering
   (ICCKE)
CY OCT 20-21, 2016
CL Mashhad, IRAN
SP Ferdowsi Univ Mashhad, Comp Engn Dept
AB The model size and decoding time are known issues in statistical machine translation. Especially, monotonic words order of language pairs makes the size of hierarchical models huge. Considering this fact, the rule extraction method of phrase-boundary model was changed to extract less number of rules. This paper proposes this rule extraction method as a general filter for hierarchical models. Named as monotonic filter, this filter reduces the extracted rules from phrase pairs decomposable to monotonic aligned subphrases. We apply the monotonic filter on the hierarchical phrase-based, SAMT and phrase-boundary models. Our experiments are performed in translations from Persian, German and French to English as the source and target languages with low, medium and high monotonic word order respectively. The reduction amount of the monotonic filter for the model size and decoding time is up to about 70% and 80% respectively, in most cases with no tangible impact on the translation quality.
RI Shamsfard, Mehrnoush/Q-7671-2019; Shamsfard, Mehrnoush/I-1707-2019
OI Shamsfard, Mehrnoush/0000-0002-7027-7529
BN 978-1-5090-3586-1
PY 2016
BP 19
EP 24
UT WOS:000392420000004
ER

PT C
AU Yang, J
   Chen, XL
   Zhang, J
   Zhang, Y
   Waibel, A
AF Yang, J
   Chen, XL
   Zhang, J
   Zhang, Y
   Waibel, A
GP IEEE
   IEEE
TI Dautomatic detection and translation of text from natural scenes
SO 2002 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING, VOLS I-IV, PROCEEDINGS
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
CT IEEE International Conference on Acoustics, Speech, and Signal
   Processing
CY MAY 13-17, 2002
CL ORLANDO, FL
SP IEEE Signal Proc Soc
AB Large amounts of information are embedded in natural scenes. Signs are good examples of natural objects with high information content. In this paper, we discuss problems in automatic detection and translation of text from natural scenes. We describe the challenges of automatic text detection and propose methods to address these challenges. We extend example based machine translation technology for sign translation and present a prototype system for Chinese sign translation. This system is capable of capturing images, automatically detecting and recognizing text, and translating the text into English. The translation can be displayed on a palm size PDA, or synthesized as a voice output message over the earphones.
SN 1520-6149
BN 0-7803-7402-9
PY 2002
BP 2101
EP 2104
UT WOS:000177510400526
ER

PT J
AU Rosu, H
AF Rosu, H
TI Superoscillations and trans-Planckian frequencies
SO NUOVO CIMENTO DELLA SOCIETA ITALIANA DI FISICA B-GENERAL PHYSICS
   RELATIVITY ASTRONOMY AND MATHEMATICAL PHYSICS AND METHODS
AB Superoscillations can explain the arbitrarily high frequencies' paradox in black-hole radiation.
RI Rosu, Haret/E-1955-2011
OI Rosu, Haret/0000-0001-5909-1945
SN 0369-3554
PD JAN
PY 1997
VL 112
IS 1
BP 131
EP 132
UT WOS:A1997WR74300014
ER

PT J
AU Preiss, T
   Hentze, MW
AF Preiss, T
   Hentze, MW
TI Starting the protein synthesis machine: eukaryotic translation
   initiation
SO BIOESSAYS
AB The final assembly of the protein synthesis machinery occurs during translation initiation. This delicate process involves both ends of eukaryotic messenger RNAs as well as multiple sequential protein-RNA and protein-protein interactions. As is expected from its critical position in the gene expression pathway between the transcriptome and the proteome, translation initiation is a selective and highly regulated process. This synopsis summarises the current status of the field and identifies intriguing open questions. (C) 2003 Wiley Periodicals, Inc.
RI Preiss, Thomas/F-7355-2010; Hentze, Matthias W/V-3980-2017
OI Preiss, Thomas/0000-0001-6273-784X; Hentze, Matthias
   W/0000-0002-4023-7876
SN 0265-9247
EI 1521-1878
PD DEC
PY 2003
VL 25
IS 12
BP 1201
EP 1211
DI 10.1002/bies.10362
UT WOS:000187028000009
PM 14635255
ER

PT C
AU Watters, PA
AF Watters, Paul A.
GP IEEE
TI Challenges to Automated Allegory Resolution in Open Source Intelligence
SO 2012 THIRD CYBERCRIME AND TRUSTWORTHY COMPUTING WORKSHOP (CTC 2012)
CT 3rd Cybercrime and Trustworthy Computing Workshop (CTC)
CY OCT 29-30, 2012
CL Univ Ballarat, Ballarat, AUSTRALIA
SP Macquarie Univ, Ctr Adv Comp Algorithms & Cryptography, Ctr Policing, Intelligence & Counter Terrorism, Macquarie Univ, Cybercrime Res Lab, ICSL, Australian Fed Police, IBM, State Govt Victoria, Westpac Banking Corp
HO Univ Ballarat
AB The resolution of lexical ambiguity in machine translation systems often involves the automated, on-line selection of the correct sense of polysemous target words in the context of a clause, phrase or sentence. However, the performance of machine translation systems in emulating this aspect of human language processing has not been entirely successful, to the extent that resolution of entities and terms in natural language could be automated for open source intelligence analysis. Whilst some of these systems confine themselves to processing domain-specific knowledge (e.g., medical terminology), with some success, the popular general-purpose direct translation systems now freely available on the World Wide Web (WWW) are investigated for characteristic semantic processing errors in this study. A ubiquitous sentence ("The quick brown fox jumps over the lazy dog"), an equative metaphor, and a simile are translated into four romance and one Germanic language, with the translation then inverted back to English using the same translation system. It is found that in addition to expected differences in correctly mapping shades of meaning (e.g., "quick" is mapped to "fast"), some spatial meanings are incorrectly transformed, especially for verbs (e.g., "jumps over" becomes "branches over" or "jumps on"). The most serious error is the addition of extra semantic features to individual words, particularly features associated with nouns (e.g., the gender-neutral "fox" becomes the female "vixen"). The implications of these types of errors for the automatic translation of human language - with respect to semantic representation in open source intelligence - are discussed.
OI Watters, Paul/0000-0002-1399-7175
BN 978-0-7695-4940-8; 978-1-4673-6460-7
PY 2012
BP 14
EP 18
DI 10.1109/CTC.2012.8
UT WOS:000319994300003
ER

PT C
AU Fantinuoli, C
   Prandi, B
AF Fantinuoli, Claudio
   Prandi, Bianca
GP Assoc Computat Linguist
TI Towards the evaluation of automatic simultaneous speech translation from
   a communicative perspective
SO IWSLT 2021: THE 18TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE
   TRANSLATION
CT 18th International Conference on Spoken Language Translation (IWSLT)
CY AUG 05-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB In recent years, automatic speech-to-speech and speech-to-text translation has gained momentum thanks to advances in artificial intelligence, especially in the domains of speech recognition and machine translation. The quality of such applications is commonly tested with automatic metrics, such as BLEU, primarily with the goal of assessing improvements of releases or in the context of evaluation campaigns. However, little is known about how the output of such systems is perceived by end users or how they compare to human performances in similar communicative tasks.
   In this paper, we present the results of an experiment aimed at evaluating the quality of a real-time speech translation engine by comparing it to the performance of professional simultaneous interpreters. To do so, we adopt a framework developed for the assessment of human interpreters and use it to perform a manual evaluation on both human and machine performances. In our sample, we found better performance for the human interpreters in terms of intelligibility, while the machine performs slightly better in terms of informativeness. The limitations of the study and the possible enhancements of the chosen framework are discussed. Despite its intrinsic limitations, the use of this framework represents a first step towards a user-centric and communication-oriented methodology for evaluating real-time automatic speech translation.
OI Fantinuoli, Claudio/0000-0003-1312-0741
BN 978-1-954085-74-9
PY 2021
BP 245
EP 254
UT WOS:000694723100029
ER

PT C
AU Lu, WJ
   Zhou, J
   Zhou, LY
   Liu, GS
   Zhang, QH
AF Lu, Wenjie
   Zhou, Jie
   Zhou, Leiying
   Liu, Gongshen
   Zhang, Quanhai
GP IEEE
TI Challenge Training to Simulate Inference in Machine Translation
SO 2020 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN) held as part
   of the IEEE World Congress on Computational Intelligence (IEEE WCCI)
CY JUL 19-24, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc
AB Despite much success has been achieved, neural machine translation (NMT) suffers from exposure bias and evaluation discrepancy. To be specific, the generation inconsistency between the training and inference process further causes error accumulation and distribution disparity. Furthermore, NMT models are generally optimized on word-level cross-entropy loss function but evaluated by sentence-level metrics. This evaluation level mismatch may mislead the promotion of translation performance. To address these two drawbacks, we propose to challenge training to gradually simulate inference. Namely, the decoder is fed with inferred words rather than ground truth words during training with a dynamic probability. To ensure accuracy and integrity, we adopt alignment and tailoring on the inferred words. Therefore, these words can leverage inferred information to help improve the training process. As for the dynamic simulation, we define a novel loss-sensitive probability that can sense the converge of training and finetune itself in turn. Experimental results on IWSLT 2016 German-English and WMT 2019 English-Chinese datasets demonstrate that our methodology can significantly improve translation quality. The approach of alignment and tailoring outperforms previous works. Meanwhile, the proposed loss-sensitive sampling is also useful for other state-of-the-art scheduled sampling methods to achieve further promotion.
SN 2161-4393
BN 978-1-7281-6926-2
PY 2020
UT WOS:000626021402080
ER

PT J
AU Lee, HG
   Kim, MJ
   Quan, Y
   Rim, HC
   Park, SY
AF Lee, Hyoung-Gyu
   Kim, Min-Jeong
   Quan, YingXiu
   Rim, Hae-Chang
   Park, So-Youne
TI Estimating Translation Probabilities Considering Semantic
   Recoverabillity of Phrase Retranslation
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
AB The general method for estimating phrase translation probabilities consists of sequential processes: word alignment, phrase pair extraction, and phrase translation probability calculation. However, during this sequential process, errors may propagate from the word alignment step through the translation. probability calculation step. In this paper, we propose a new method for estimating phrase translation probabilities that reduce the effects of error propagation. By considering the semantic recoverability of phrase retranslation, our method identifies incorrect phrase pairs that have propagated from alignment errors. Furthermore, we define retranslation similarity which represents the semantic recoverability of phrase retranslation, and use this when computing translation probabilities. Experimental results show that the proposed phrase translation estimation method effectively prevents a PBSMT system from selecting incorrect phrase pairs, and consistently improves the translation quality in various language pairs.
SN 1745-1361
PD MAR
PY 2012
VL E95D
IS 3
BP 897
EP 901
DI 10.1587/transinf.E95.D.897
UT WOS:000301614700026
ER

PT J
AU Allauzen, C
   Byrne, B
   de Gispert, A
   Iglesias, G
   Riley, M
AF Allauzen, Cyril
   Byrne, Bill
   de Gispert, Adria
   Iglesias, Gonzalo
   Riley, Michael
TI Pushdown Automata in Statistical Machine Translation
SO COMPUTATIONAL LINGUISTICS
AB This article describes the use of pushdown automata (PDA) in the context of statistical machine translation and alignment under a synchronous context-free grammar. We use PDAs to compactly represent the space of candidate translations generated by the grammar when applied to an input sentence. General-purpose PDA algorithms for replacement, composition, shortest path, and expansion are presented. We describe HiPDT, a hierarchical phrase-based decoder using the PDA representation and these algorithms. We contrast the complexity of this decoder with a decoder based on a finite state automata representation, showing that PDAs provide a more suitable framework to achieve exact decoding for larger synchronous context-free grammars and smaller language models. We assess this experimentally on a large-scale Chinese-to-English alignment and translation task. In translation, we propose a two-pass decoding strategy involving a weaker language model in the first-pass to address the results of PDA complexity analysis. We study in depth the experimental conditions and tradeoffs in which HiPDT can achieve state-of-the-art performance for large-scale SMT.
OI Byrne, William/0000-0003-1896-4492
SN 0891-2017
EI 1530-9312
PD SEP
PY 2014
VL 40
IS 3
BP 687
EP 723
DI 10.1162/COLI_a_00197
UT WOS:000341843500008
ER

PT J
AU Bertoldi, N
   Zens, R
   Federico, M
   Shen, W
AF Bertoldi, Nicola
   Zens, Richard
   Federico, Marcello
   Shen, Wade
TI Efficient Speech Translation Through Confusion Network Decoding
SO IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB This paper describes advances in the use of confusion networks as interface between automatic speech recognition and machine translation. In particular, it presents a decoding algorithm for confusion networks which results as an extension of a state-of-the-art phrase-based text translation decoder. The confusion network decoder significantly improves both in efficiency and performance over previous work along this direction, and outperforms the background text translation system. Experimental results in terms of translation accuracy and decoding efficiency are reported for the task of translating plenary speeches of the European Parliament from Spanish to English and from English to Spanish.
SN 1558-7916
EI 1558-7924
PD NOV
PY 2008
VL 16
IS 8
BP 1696
EP 1705
DI 10.1109/TASL.2008.2002054
UT WOS:000260463800029
ER

PT C
AU Saveski, M
   Trajkovski, I
AF Saveski, Martin
   Trajkovski, Igor
BE Gusev, M
   Mitrevski, P
TI Development of an English-Macedonian Machine Readable Dictionary by
   Using Parallel Corpora
SO ICT INNOVATIONS 2010
SE Communications in Computer and Information Science
CT ICT Innovations Conference 2010
CY SEP 12-15, 2010
CL Ohrid, MACEDONIA
SP Macedonian Soc Informat & Commun Technol, UKIM, Univ Ss Cyril & Methodius, UKIM, Inst Informat, Fac Nat Sci & Math, UKIM, Fac Elect Engn & Informat Technol, Asseco S E Europe, Duna Comp, Lancom Comp, Netcetera, Neocom
AB The dictionaries are one of the most useful lexical resources. However, most of the dictionaries today are not in digital form. This makes them cumbersome for usage by humans and impossible for integration in computer programs. The process of digitalizing an existing traditional dictionary is expensive and labor intensive task. In this paper, we present a method for development of Machine Readable Dictionaries by using the already available resources. Machine readable dictionary consists of simple word-to-word mappings. where word from the source language can be mapped into several optional words in the target language. We present a series of experiments where by using the parallel corpora and open source Statistical Machine Translation tools at our disposal, we managed to develop an English-Macedonian Machine Readable Dictionary containing 23,296 translation pairs (17,708 English and 18,343 Macedonian terms). A subset of the produced dictionary has been manually evaluated and showed accuracy of 79.8%.
SN 1865-0929
BN 978-3-642-19324-8
PY 2011
VL 83
BP 195
EP +
UT WOS:000302390700020
ER

PT C
AU Wu, JZ
AF Wu Jianzhen
BE Pan, JS
   Guo, BL
   Abraham, A
TI Image Moment Based Registration Scheme Utilizing Support Vector Machine
SO FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY,
   VOL 1, PROCEEDINGS
CT 5th International Conference on Information Assurance and Security
CY AUG 18-20, 2009
CL Xidian Univ, Xian, PEOPLES R CHINA
SP Kaohsiung Univ Appl Sci, IEEE Signal Proc Soc, Taiwan Chapter, Taiwanese Assoc Consumer Elect, Machine Intelligence Res Labs, IEEE Syst, Man & Cybernet Soc, TCSC
HO Xidian Univ
AB A novel image registration scheme is proposed in this paper. Six low order image moments are used as image global pattern features and are feed into support vector machine to estimate translation, rotation and scaling parameters. Simulation results show that the proposed registration scheme is accurate and robust to noise.
BN 978-0-7695-3744-3
PY 2009
BP 575
EP 577
DI 10.1109/IAS.2009.175
UT WOS:000275852000132
ER

PT C
AU Chen, KH
   Wang, R
   Utiyama, M
   Sumita, E
   Zhao, TJ
AF Chen, Kehai
   Wang, Rui
   Utiyama, Masao
   Sumita, Eiichiro
   Zhao, Tiejun
GP AAAI
TI Syntax-Directed Attention for Neural Machine Translation
SO THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 32nd AAAI Conference on Artificial Intelligence / 30th Innovative
   Applications of Artificial Intelligence Conference / 8th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 02-07, 2018
CL New Orleans, LA
SP AAAI
AB Attention mechanism, including global attention and local attention, plays a key role in neural machine translation (NMT). Global attention attends to all source words for word prediction. In comparison, local attention selectively looks at fixed-window source words. However, alignment weights for the current target word often decrease to the left and right by linear distance centering on the aligned source position and neglect syntax distance constraints. In this paper, we extend the local attention with syntax-distance constraint, which focuses on syntactically related source words with the predicted target word to learning a more effective context vector for predicting translation. Moreover, we further propose a double context NMT architecture, which consists of a global context vector and a syntax-directed context vector from the global attention, to provide more translation performance for NMT from source representation. The experiments on the large-scale Chinese-to-English and English-to-German translation tasks show that the proposed approach achieves a substantial and significant improvement over the baseline system.
RI Wang, Rui/AAI-1990-2020; Chen, Kehai/ABF-1874-2020
OI Wang, Rui/0000-0001-8007-2503; 
SN 2159-5399
EI 2374-3468
BN 978-1-57735-800-8
PY 2018
BP 4792
EP 4799
UT WOS:000485488904108
ER

PT C
AU Yang, ZG
   Laki, LJ
   Siklosi, B
AF Yang, Zijian Gyozo
   Laki, Laszlo Janos
   Siklosi, Borbala
BE Gelbukh, A
TI Quality Estimation for English-Hungarian Machine Translation Systems
   with Optimized Semantic Features
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING, (CICLING
   2016), PT II
SE Lecture Notes in Computer Science
CT 17th International Conference on Intelligent Text Processing and
   Computational Linguistics (CICLing)
CY APR 03-09, 2016
CL Mevlana Univ, Konya, TURKEY
HO Mevlana Univ
AB Quality estimation at run-time for machine translation systems is an important task. The standard automatic evaluation methods that use reference translations cannot evaluate MT results in real-time and the correlation between the results of these methods and that of human evaluation is very low in the case of translations from English to Hungarian. The new method to solve this problem is called quality estimation, which addresses the task by estimating the quality of translations as a prediction task for which features are extracted from the source and translated sentences only. In this study, we implement quality estimation for English-Hungarian. First, a corpus is created, which contains Hungarian human judgements. Using these human evaluation scores, different quality estimation models are described, evaluated and optimized. We created a corpus for English-Hungarian quality estimation and we developed 27 new semantic features using WordNet and word embedding models, then we created feature sets optimized for Hungarian, which produced better results than the baseline feature set.
RI YANG, ZIJIAN/GRS-4433-2022
SN 0302-9743
EI 1611-3349
BN 978-3-319-75487-1; 978-3-319-75486-4
PY 2018
VL 9624
BP 88
EP 100
DI 10.1007/978-3-319-75487-1_8
PN II
UT WOS:000540377700008
ER

PT C
AU Sun, S
   Sia, S
   Duh, K
AF Sun, Shuo
   Sia, Suzanna
   Duh, Kevin
GP Assoc Computat Linguist
TI CLIReval: Evaluating Machine Translation as a Cross-Lingual Information
   Retrieval Task
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020): SYSTEM DEMONSTRATIONS
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB We present CLIReval, an easy-to-use toolkit for evaluating machine translation (MT) with the proxy task of cross-lingual information retrieval (CLIR). Contrary to what the project name might suggest, CLIReval does not actually require any annotated CUR dataset. Instead, it automatically transforms translations and references used in MT evaluations into a synthetic CUR dataset; it then sets up a standard search engine (Elasticsearch) and computes various information retrieval metrics (e.g., mean average precision) by treating the translations as documents to be retrieved. The idea is to gauge the quality of MT by its impact on the document translation approach to CUR. As a case study, we run CLIReval on the "metrics shared task" of WMT2019; while this extrinsic metric is not intended to replace popular intrinsic metrics such as BLEU, results suggest CLIReval is competitive in many language pairs in terms of correlation to human judgments of quality. CLIReval is publicly available at https://github.com/ssun32/CLIReval.
RI Sun, Shuohao/HGC-6890-2022
BN 978-1-952148-04-0
PY 2020
BP 134
EP 141
UT WOS:000563368700018
ER

PT C
AU Wu, LJ
   Wang, YR
   Xia, YC
   Qin, T
   Lai, JH
   Liu, TY
AF Wu, Lijun
   Wang, Yiren
   Xia, Yingce
   Qin, Tao
   Lai, Jianhuang
   Liu, Tie-Yan
GP Assoc Computat Linguist
TI Exploiting Monolingual Data at Scale for Neural Machine Translation
SO 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND
   THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE
CT Conference on Empirical Methods in Natural Language Processing / 9th
   International Joint Conference on Natural Language Processing
   (EMNLP-IJCNLP)
CY NOV 03-07, 2019
CL Hong Kong, HONG KONG
SP Google, Facebook, Apple, ASAPP, Salesforce, Huawei, Baidu, Deepmind, Amazon, PolyAI, Naver, ByteDance, Megagon Labs, Zhuiyi, Verisk, MI
AB While target-side monolingual data has been proven to be very useful to improve neural machine translation (briefly, NMT) through back translation, source-side monolingual data is not well investigated. In this work, we study how to use both the source-side and targetside monolingual data for NMT, and propose an effective strategy leveraging both of them. First, we generate synthetic bitext by translating monolingual data from the two domains into the other domain using the models pretrained on genuine bitext. Next, a model is trained on a noised version of the concatenated synthetic bitext where each source sequence is randomly corrupted. Finally, the model is fine-tuned on the genuine bitext and a clean version of a subset of the synthetic bitext without adding any noise. Our approach achieves state-of-the-art results on WMT16, WMT17, WMT18 English <-> German translations and WMT19 German <-> French translations, which demonstrate the effectiveness of our method. We also conduct a comprehensive study on how each part in the pipeline works.
BN 978-1-950737-90-1
PY 2019
BP 4207
EP 4216
UT WOS:000854193304035
ER

PT C
AU Haque, R
   Penkale, S
   Jiang, J
   Way, A
AF Haque, Rejwanul
   Penkale, Sergio
   Jiang, Jie
   Way, Andy
BE Xiong, D
   Castelli, E
   Dong, M
   Yen, PTN
TI Source-Side Suffix Stripping for Bengali-to-English SMT
SO 2012 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP 2012)
SE International Conference on Asian Language Processing
CT International Conference on Asian Language Processing (IALP)
CY NOV 13-15, 2012
CL Hanoi, VIETNAM
SP IEEE, IEEE Comp Soc, Int Res Inst MICA, Hanoi Univ Sci & Technol, Chinese & Oriental Languages Informat Proc Soc (COLIPS), IEEE Singapore Comp Chapter
AB Data sparseness is a well-known problem for statistical machine translation (SMT) when morphologically rich and highly inflected languages are involved. This problem become worse in resource-scarce scenarios where sufficient parallel corpora are not available for model training. Recent research has shown that morphological segmentation can be employed on either side of the translation pair to reduce data sparsity. In this work, we consider a highly inflected Indian language as the source-side of the translation pair, Bengali. This paper presents study of morphological segmentation in SMT with a less explored translation pair, Bengali-to-English. We worked with a tiny training set available for this language-pair. We employ a simple suffix-stripping method for lemmatizing inflected Bengali words. We show that our morphological suffix separation process significantly reduces data sparseness. We also show that an SMT model trained on suffix-stripped (source) training data significantly outperforms the state-of-the-art phrase-based SMT (PB-SMT) baseline.
RI Haque, Rejwanul/C-4581-2017
OI Haque, Rejwanul/0000-0003-1680-0099; Way, Andy/0000-0001-5736-5930
SN 2159-1962
EI 2159-1970
BN 978-0-7695-4886-9; 978-1-4673-6113-2
PY 2012
BP 193
EP 196
DI 10.1109/IALP.2012.61
UT WOS:000318948700049
ER

PT J
AU Kim, K
   Park, EJ
   Shin, JH
   Kwon, OW
   Kim, YK
AF Kim, Kangil
   Park, Eun-Jin
   Shin, Jong-Hun
   Kwon, Oh-Woog
   Kim, Young-Kil
TI Divergence-based fine pruning of phrase-based statistical translation
   model
SO COMPUTER SPEECH AND LANGUAGE
AB A widely used automatic translation approach, phrase-based statistical machine translation, learns a probabilistic translation model composed of phrases from a large parallel corpus with a large language model. The translation model is often enormous because of many combinations of source and target phrases, which leads to the restriction of applications to limited computing environments. Entropy-based pruning resolves this issue by reducing the model size while retaining the translation quality. To safely reduce the size, this method detects redundant components by evaluating a relative entropy of models before and after pruning the components. In the literature, this method is effective, but we have observed that it can be improved more by adjusting the divergence distribution determined by the relative entropy. In the results of preliminary experiments, we derive two factors responsible for limiting pruning efficiency of entropy-based pruning. The first factor is proportion of pairs composing translation models with respect to their translation probability and its estimate. The second factor is the exponential increase of the divergence for pairs with low translation probability and estimate. To control the factors, we propose a divergence-based fine pruning using a divergence metric to adapt the curvature change of the boundary conditions for pruning and Laplace smoothing. In practical translation tasks for English-Spanish and English-French language pairs, this method shows statistically significant improvement on the efficiency up to 50% and average 12% more pruning compared to entropy-based pruning to show the same translation quality. (C) 2016 Elsevier Ltd. All rights reserved.
SN 0885-2308
EI 1095-8363
PD JAN
PY 2017
VL 41
BP 146
EP 160
DI 10.1016/j.csl.2016.06.006
UT WOS:000384863900008
ER

PT J
AU Venkatesan, H
AF Venkatesan, Hari
TI The fourth dimension in translation: time and disposability
SO PERSPECTIVES-STUDIES IN TRANSLATION THEORY AND PRACTICE
AB The digital age has brought about exchange of information at unprecedented scales and speeds. Both within multilingual communities and across boundaries, translation is called upon to make information available with greater efficiency. While increasingly mature technology helps in this process, this paper argues for the discipline to put in context the translation phenomena emerging from strategies that have time taken as their prime concern. Specifically, it discusses the principle of disposability of information in determining minimum quality to be achieved as a way to systematically approach time-oriented translation methods. The discussion may have implications for how translation is practiced and understood and also represent a dimension in translation that can be further explored.
OI Venkatesan, Hari/0000-0002-0846-9108
SN 0907-676X
EI 1747-6623
PD JUL 4
PY 2022
VL 30
IS 4
BP 662
EP 677
DI 10.1080/0907676X.2021.1939739
EA JUN 2021
UT WOS:000665637500001
ER

PT C
AU Ding, YRB
   Ray, B
   Devanbu, P
   Hellendoorn, VJ
AF Ding, Yangruibo
   Ray, Baishakhi
   Devanbu, Premkumar
   Hellendoorn, Vincent J.
GP IEEE Comp Soc
TI Patching as Translation: the Data and the Metaphor
SO 2020 35TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE
   ENGINEERING (ASE 2020)
SE IEEE ACM International Conference on Automated Software Engineering
CT 35th IEEE/ACM International Conference on Automated Software Engineering
   (ASE)
CY SEP 21-25, 2020
CL ELECTR NETWORK
SP IEEE, Assoc Comp Machinery, IEEE Comp Soc, Monash Univ, NASA Ames Rese Ctr, IEEE Tech Council Software Engn, ACM SIGAI, ACM Special Interest Grp Software Engn, Deakin Univ
AB Machine Learning models from other fields, like Computational Linguistics, have been transplanted to Software Engineering tasks, often quite successfully. Yet a transplanted model's initial success at a given task does not necessarily mean it is well-suited for the task. In this work, we examine a common example of this phenomenon: the conceit that "software patching is like language translation". We demonstrate empirically that there are subtle, but critical distinctions between sequence-to-sequence models and translation model: while program repair benefits greatly from the former, general modeling architecture, it actually suffers from design decisions built into the latter, both in terms of translation accuracy and diversity. Given these findings, we demonstrate how a more principled approach to model design, based on our empirical findings and general knowledge of software development, can lead to better solutions. Our findings also lend strong support to the recent trend towards synthesizing edits of code conditional on the buggy context, to repair bugs. We implement such models ourselves as "proof-of-concept" tools and empirically confirm that they behave in a fundamentally different, more effective way than the studied translation-based architectures. Overall, our results demonstrate the merit of studying the intricacies of machine learned models in software engineering: not only can this help elucidate potential issues that may be overshadowed by increases in accuracy; it can also help innovate on these models to raise the state-of-the-art further. We will publicly release our replication data and materials at https://github.com/ARiSE- Lab/Patch-as-translation.
SN 1527-1366
BN 978-1-4503-6768-4
PY 2020
BP 275
EP 286
DI 10.1145/3324884.3416587
UT WOS:000651313500025
ER

PT J
AU Farooq, U
   Rahim, MSM
   Khan, NS
   Rasheed, S
   Abid, A
AF Farooq, Uzma
   Mohd Rahim, Mohd Shafry
   Khan, Nabeel Sabir
   Rasheed, Saim
   Abid, Adnan
TI A Crowdsourcing-Based Framework for the Development and Validation of
   Machine Readable Parallel Corpus for Sign Languages
SO IEEE ACCESS
AB Sign languages are used by the deaf and mute community of the world. These are gesture based languages where the subjects use hands and facial expressions to perform different gestures. There are hundreds of different sign languages in the world. Furthermore, like natural languages, there exist different dialects for many sign languages. In order to facilitate the deaf community several different repositories of video gestures are available for many sign languages of the world. These video based repositories do not support the development of an automated language translation systems. This research aims to investigate the idea of engaging the deaf community for the development and validation of a parallel corpus for a sign language and its dialects. As a principal contribution, this research presents a framework for building a parallel corpus for sign languages by harnessing the powers of crowdsourcing with editorial manager, thus it engages a diversified set of stakeholders for building and validating a repository in a quality controlled manner. It further presents processes to develop a word-level parallel corpus for different dialects of a sign language; and a process to develop sentence-level translation corpus comprising of source and translated sentences. The proposed framework has been successfully implemented and involved different stakeholders to build corpus. As a result, a word-level parallel corpus comprising of the gestures of almost 700 words of Pakistan Sign Language (PSL) has been developed. While, a sentence-level translation corpus comprising of more than 8000 sentences for different tenses has also been developed for PSL. This sentence-level corpus can be used in developing and evaluating machine translation models for natural to sign language translation and vice-versa. While the machine-readable word level parallel corpus will help in generating avatar based videos for the translated sentences in different dialects of a sign language.
RI Abid, Adnan/AAM-4134-2020; Khan, Nabeel Sabir/AAV-8828-2021; Rasheed,
   Saim/I-6317-2013
OI Rasheed, Saim/0000-0003-1584-2991
SN 2169-3536
PY 2021
VL 9
BP 91788
EP 91806
DI 10.1109/ACCESS.2021.3091433
UT WOS:000673748600001
ER

PT C
AU Liu, H
   Hong, Y
   Yao, L
   Liu, L
   Yao, JM
   Zhu, QM
AF Liu, Hao
   Hong, Yu
   Yao, Liang
   Liu, Le
   Yao, Jianmin
   Zhu, Qiaoming
BE Chen, WL
   Ma, B
   Zhang, M
   Lu, YF
   Dong, MH
TI A Novel Method to Optimize Training Data for Translation Model
   Adaptation
SO PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE
   PROCESSING
SE International Conference on Asian Language Processing
CT Proceedings of International Conference on Asian Language Processing
CY OCT 24-25, 2015
CL Suzhou, PEOPLES R CHINA
AB In this paper, we explore the method to improve the cross-domain adaptation of current translation models, with the aim to solve the common problem that ambiguous linguistic knowledge in different domain causes a difficult training for a robust translation model. Specially, we propose a novel method to automatically optimize training data for translation model adaptation. The method combines a test sentence and its best candidate translation to generate a pseudo-parallel translation pair. Regarding the pairs as queries, the method follows a twin-track retrieval approach to further mine parallel sentence pairs from large-scale bilingual resources. Experiments show that by using our method, the optimized translation models significantly improve the translation performance by 1.8 BLEU points when only 7.7% of bilingual training data is used.
SN 2159-1962
EI 2159-1970
BN 978-1-4673-9596-0
PY 2015
BP 1
EP 4
UT WOS:000380428000001
ER

PT C
AU Bicici, E
   Dymetman, M
AF Bicici, Ergun
   Dymetman, Marc
BE Gelbukh, A
TI Dynamic translation memory: Using statistical machine translation to
   improve translation memory fuzzy matches
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING
SE Lecture Notes in Computer Science
CT 9th International Conference on Intelligent Text Processing and
   Computational Linguistics
CY FEB 17-23, 2008
CL Univ Haifa, Haifa, ISRAEL
SP Computat Linguist Grp, Univ Haifa, Caesarea Edmond Benjamin de Rothschild Fdn Inst Interdisciplinary Applicat Comp Sci
HO Univ Haifa
AB Professional translators of technical documents often use Translation Memory (TM) systems in order to capitalize on the repetitions frequently observed in these documents. TM systems typically exploit not only complete matches between the source sentence to be translated and some previously translated sentence, but also so-called fuzzy matches, where the source sentence has some substantial commonality with a previously translated sentence. These fuzzy matches can be very worthwhile as a starting point for the human translator, but the translator then needs to manually edit the associated TM-based translation to accommodate the differences with the source sentence to be translated. If part of this process could be automated, the cost of human translation could be significantly reduced. The paper proposes to perform this automation in the following way: a phrase-based Statistical Machine Translation (SMT) system (trained on a bilingual corpus in the same domain as the TM) is combined with the TM fuzzy match, by extracting from the fuzzy-match a large (possibly gapped) bi-phrase that is dynamically added to the usual set of "static" bi-phrases used for decoding the source. We report experiments that show significant improvements in terms of BLEU and NIST scores over both the translations produced by the stand-alone SMT system and the fuzzy-match translations proposed by the stand-alone TM system.
OI Bicici, Ergun/0000-0002-2293-2031
SN 0302-9743
EI 1611-3349
BN 978-3-540-78134-9
PY 2008
VL 4919
BP 454
EP +
UT WOS:000253658200039
ER

PT J
AU Jha, A
   Patil, HY
AF Jha, Abhinav
   Patil, Hemprasad Yashwant
TI A review of machine transliteration, translation, evaluation metrics and
   datasets in Indian Languages
SO MULTIMEDIA TOOLS AND APPLICATIONS
AB In today's global scenario, frequent international and domestic interactions necessitate the application of Machine Transliteration and Translation systems to overcome the language barrier. This paper presents a review of Natural Language Processing (NLP) techniques like Machine Translation (MT) and Machine Transliteration (MTn), along with providing an analytical study of evaluation metrics such as BLEU (BiLingual Evaluation Understudy) score and discussing datasets available for MT and MTn systems in Indian languages. This paper is unique in providing a detailed review of all steps involved in the NLP system development pipeline, from the creation and collection of data to the development of the system, and furthermore, the evaluation and analysis of the system. It also comments on the validity and viability of various evaluation metrics for Indian languages. MT and MTn systems are an evolving field of computational linguistics and are considered to be incredibly challenging to develop. The lack of readily available grammatical rules, the distinction between proper and common nouns, and large datasets, along with additional linguistic complexity compared to many other languages, makes developing such systems for Indian languages even more complicated. It explores different approaches like statistics oriented, example oriented, and neural network-oriented MT techniques implied in MT tasks, along with providing insight into the work carried out so far for Indian languages. The review also discusses the scope for future research in this field. This article determines the current status of available datasets, MT and MTn systems, along with commenting on the validity of currently available evaluation metrics like BLEU for Indian languages. The article also provides a direction in which further research for Indian languages should ideally be headed.
RI Jha, Abhinav/HJI-7828-2023
OI Jha, Abhinav/0000-0002-0085-583X; Yashwant Patil,
   Hemprasad/0000-0002-8572-0765
SN 1380-7501
EI 1573-7721
DI 10.1007/s11042-022-14273-1
EA NOV 2022
UT WOS:000888710500006
ER

PT C
AU Thompson, B
   Gwinnup, J
   Khayrallah, H
   Duh, K
   Koehn, P
AF Thompson, Brian
   Gwinnup, Jeremy
   Khayrallah, Huda
   Duh, Kevin
   Koehn, Philipp
GP Assoc Computat Linguist
TI Overcoming Catastrophic Forgetting During Domain Adaptation of Neural
   Machine Translation
SO 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019),
   VOL. 1
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 02-07, 2019
CL Minneapolis, MN
SP Assoc Computat Linguist, N Amer Chapter, Comp Res Assoc, Comp Community Consortium, Natl Sci Fdn, Natl Rees Council Canada, Google
AB Continued training is an effective method for domain adaptation in neural machine translation. However, in-domain gains from adaptation come at the expense of general-domain performance. In this work, we interpret the drop in general-domain performance as catastrophic forgetting of general-domain knowledge. To mitigate it, we adapt Elastic Weight Consolidation (EWC)-a machine learning method for learning a new task without forgetting previous tasks. Our method retains the majority of general-domain performance lost in continued training without degrading in-domain performance, outperforming the previous state-of-the-art. We also explore the full range of general-domain performance available when some in-domain degradation is acceptable.
BN 978-1-950737-13-0
PY 2019
BP 2062
EP 2068
UT WOS:000900116902021
ER

PT C
AU Joshi, K
   Rajarshi, MB
AF Joshi, Kalyan
   Rajarshi, M. B.
BE Singh, C
   Lehal, GS
   Sengupta, J
   Sharma, DV
   Goyal, V
TI Modified BLEU for Measuring Performance of a Machine-Translation
   Software
SO INFORMATION SYSTEMS FOR INDIAN LANGUAGES
SE Communications in Computer and Information Science
CT International Conference on Infirmation Systems for Indian Languages
   (ICISIL 2011)
CY MAR 09-11, 2011
CL Patiala, INDIA
AB The BLEU score compares various n-grams of words of a MT software with an ideal or reference translation of a sentence. We suggest a Weighted BLEU (WBLEU) which is probably more suitable for translation system for English into an Indian language. Weights are obtained so that the correlation between the weighted BLEU scores and a human evaluator's scores is maximum.
SN 1865-0929
BN 978-3-642-19402-3
PY 2011
VL 139
BP 294
EP 298
UT WOS:000306397600051
ER

PT J
AU De Pauw, G
   de Schryver, GM
   Wagacha, PW
AF De Pauw, Guy
   de Schryver, Gilles-Maurice
   Wagacha, Peter Waiganjo
TI A Corpus-based Survey of Four Electronic Swahili-English Bilingual
   Dictionaries
SO LEXIKOS
AB In this article we survey four different electronic bilingual dictionaries for the language pair Swahili-English. Aided by a data-driven morphological analyzer and part-of-speech tagger, we quantify the coverage of the dictionaries on large monolingual corpora of Swahili. In a second series of experiments, we investigate how applicable the dictionaries are as a tool in the development of a machine translation system, by evaluating bilingual coverage on the parallel SAWA corpus. At the same time we attempt to consolidate the dictionaries into a unified lexicographic database and compare the coverage to that of its composite parts.
RI de Schryver, Gilles-Maurice/D-4740-2011
OI de Schryver, Gilles-Maurice/0000-0001-7272-9878
SN 1684-4904
EI 2224-0039
PY 2009
VL 19
BP 340
EP 352
UT WOS:000272533900019
ER

PT C
AU Minarro-Gimenez, JA
   Hellrich, J
   Schulz, S
AF Minarro-Gimenez, Jose Antonio
   Hellrich, Johannes
   Schulz, Stefan
BE Cornet, R
   StoicuTivadar, L
   Horbst, A
   Calderon, CLP
   Andersen, SK
   HercigonjaSzekeres, M
TI Acquisition of Character Translation Rules for Supporting SNOMED CT
   Localizations
SO DIGITAL HEALTHCARE EMPOWERING EUROPEANS
SE Studies in Health Technology and Informatics
CT 26th Medical Informatics in Europe (MIE) Conference on Digital
   Healthcare Empowering Europeans
CY MAY 27-29, 2015
CL Madrid, SPAIN
SP European Federat Med Informat, Spanish Soc Hlth Informat
AB Translating huge medical terminologies like SNOMED CT is costly and time consuming. We present a methodology that acquires substring substitution rules for single words, based on the known similarity between medical words and their translations, due to their common Latin / Greek origin. Character translation rules are automatically acquired from pairs of English words and their automated translations to German. Using a training set with single words extracted from SNOMED CT as input we obtained a list of 268 translation rules. The evaluation of these rules improved the translation of 60% of words compared to Google Translate and 55% of translated words that exactly match the right translations. On a subset of words where machine translation had failed, our method improves translation in 56% of cases, with 27% exactly matching the gold standard.
RI Giménez, Jose Antonio Miñarro/O-1373-2019; Minarro Gimenez, Jose
   Antonio/N-5791-2014
OI Minarro Gimenez, Jose Antonio/0000-0001-7221-9843
SN 0926-9630
EI 1879-8365
BN 978-1-61499-512-8; 978-1-61499-511-1
PY 2015
VL 210
BP 597
EP 601
DI 10.3233/978-1-61499-512-8-597
UT WOS:000455817000123
PM 25991218
ER

PT C
AU Roy, A
   Grangier, D
AF Roy, Aurko
   Grangier, David
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Unsupervised Paraphrasing without Translation
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB Paraphrasing exemplifies the ability to abstract semantic content from surface forms. Recent work on automatic paraphrasing is dominated by methods leveraging Machine Translation (MT) as an intermediate step. This contrasts with humans, who can paraphrase without being bilingual. This work proposes to learn paraphrasing models from an unlabeled monolingual corpus only. To that end, we propose a residual variant of vector-quantized variational auto-encoder.
   We compare with MT-based approaches on paraphrase identification, generation, and training augmentation. Monolingual paraphrasing outperforms unsupervised translation in all settings. Comparisons with supervised translation are more mixed: monolingual paraphrasing is interesting for identification and augmentation; supervised translation is superior for generation.
BN 978-1-950737-48-2
PY 2019
BP 6033
EP 6039
UT WOS:000493046109004
ER

PT C
AU Yang, ZX
   Zhang, JC
   Meng, FD
   Gu, SH
   Feng, Y
   Zhou, J
AF Yang, Zhengxin
   Zhang, Jinchao
   Meng, Fandong
   Gu, Shuhao
   Feng, Yang
   Zhou, Jie
GP Assoc Computat Linguist
TI Enhancing Context Modeling with a Query-Guided Capsule Network for
   Document-level Translation
SO 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND
   THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE
CT Conference on Empirical Methods in Natural Language Processing / 9th
   International Joint Conference on Natural Language Processing
   (EMNLP-IJCNLP)
CY NOV 03-07, 2019
CL Hong Kong, HONG KONG
SP Google, Facebook, Apple, ASAPP, Salesforce, Huawei, Baidu, Deepmind, Amazon, PolyAI, Naver, ByteDance, Megagon Labs, Zhuiyi, Verisk, MI
AB Context modeling is essential to generate coherent and consistent translation for Document-level Neural Machine Translations. The widely used method for document-level translation usually compresses the context information into a representation via hierarchical attention networks. However, this method neither considers the relationship between context words nor distinguishes the roles of context words. To address this problem, we propose a query-guided capsule networks to cluster context information into different perspectives from which the target translation may concern. Experiment results show that our method can significantly outperform strong baselines on multiple data sets of different domains.
BN 978-1-950737-90-1
PY 2019
BP 1527
EP 1537
UT WOS:000854193301086
ER

PT C
AU Gomaa, YA
   AbuRaya, R
   Omar, A
AF Gomaa, Yasser A.
   AbuRaya, Rania
   Omar, Abdulfattah
GP IEEE
TI The Effects of Information Technology and E-Learning Systems on
   Translation Pedagogy and Productivity of EFL Learners
SO 2019 INTERNATIONAL CONFERENCE ON INNOVATION AND INTELLIGENCE FOR
   INFORMATICS, COMPUTING, AND TECHNOLOGIES (3ICT)
CT International Conference on Innovation and Intelligence for Informatics,
   Computing, and Technologies (3ICT)
CY SEP 22-23, 2019
CL Univ Bahrain, Sakhier, BAHRAIN
HO Univ Bahrain
AB This study addresses the increasing demands for reliable translation services due to the advent of the electronic text, the prolific production of texts in different disciplines, the increasing communication among individuals from different languages and cultures, and the unprecedented development of new technologies, software and applications (referred to as CAT tools). Human translation cannot address these increasing demands of customers and businesses. Hence, this study assumes that translation technologies and machine translation systems can be usefully integrated into translation classrooms for improving learners' performance and translation quality. An experimental study was carried out where 20 Level-6 students, who are attending one translation course in Prince Sattam Bin Abdulaziz University, volunteered to participate in an optional legal translation course. Participants were divided into 2 groups: an experimental group whose instruction was supported by CAT tools, and a control group who were taught using only conventional teaching methods. Results showed that there was a statistically significant difference among CAT users and nonusers in favor of the experimental group (p < .05). It can be concluded then that translation systems and software can be usefully used for improving EFL students' translation skills. The integration of CAT tools into the learning environment not only support the practical and professional skills that well-qualify graduates for the translation industry, but it also creates an environment that enables them to acquire different skills in some related disciplines such as assessment of translation techniques, interaction between humans and the machine, and text analysis. The study suggested that translation instructors should adopt blended learning models where they integrate translation technology with conventional teaching methods. Educational institutions are also recommended to provide professional training for instructors on the use of language software and translation systems.
RI Omar, Abdulfattah/AAI-4943-2020; AbuRaya, Rania/ABB-1864-2020; Gomaa,
   Yasser A./AAC-5271-2020; AbuRaya, Rania/HKF-8520-2023
OI Omar, Abdulfattah/0000-0002-3618-1750; AbuRaya,
   Rania/0000-0002-8479-6872; Gomaa, Yasser A./0000-0003-1503-4337; 
BN 978-1-7281-3012-5
PY 2019
UT WOS:000522258800045
ER

PT J
AU Hisamoto, S
   Post, M
   Duh, K
AF Hisamoto, Sorami
   Post, Matt
   Duh, Kevin
TI Membership Inference Attacks on Sequence-to-Sequence Models: Is My Data
   In Your Machine Translation System?
SO TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
AB Data privacy is an important issue for "machine learning as a service'' providers. We focus on the problem of membership inference attacks: Given a data sample and black-box access to a model's API, determine whether the sample existed in the model's training data. Our contribution is an investigation of this problem in the context of sequence-tosequence models, which are important in applications such as machine translation and video captioning. We define the membership inference problem for sequence generation, provide an open dataset based on state-of-the-artmachine translationmodels, and report initial results on whether thesemodels leakprivate informationagainst several kinds of membership inference attacks.
EI 2307-387X
PY 2020
VL 8
BP 49
EP 63
DI 10.1162/tacl_a_00299
UT WOS:000736531900004
ER

PT S
AU Boguslavsky, IM
   Iomdin, LL
   Lazursky, AV
   Mityushin, LG
   Sizov, VG
   Kreydlin, LG
   Berdichevsky, AS
AF Boguslavsky, IM
   Iomdin, LL
   Lazursky, AV
   Mityushin, LG
   Sizov, VG
   Kreydlin, LG
   Berdichevsky, AS
BE Gelbukh, A
TI Interactive resolution of intrinsic and translational ambiguity in a
   machine translation system
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING
SE Lecture Notes in Computer Science
CT 6th Annual Conference on Intelligent Text Processing and Computational
   Linguistics
CY FEB 13-19, 2005
CL Mexico City, MEXICO
SP Natl Polytech Inst, Nat Language & Text Proc Lab, Ctr Comp Res
AB The paper presents the module of interactive word sense disambiguation and syntactic ambiguity resolution used within a machine translation System, ETAP-3. The method applied consists in asking the user to identify a word sense, or a syntactic interpretation, whenever the system lacks reliable data to make the choice automatically. In lexical disambiguation, part of man-machine dialogue refers to the analysis phase, while the other part is activated during transfer. For this purpose, entries of the working dictionaries of the system are supplemented with clear diagnostic comments and illustrations that enable the user to choose the most appropriate option and in this way channel the course of system operation.
RI Boguslavsky, Igor/A-2885-2014; Boguslavsky, Igor/N-3393-2019; Mityushin,
   Leonid/AAS-2167-2021
OI Boguslavsky, Igor/0000-0003-3390-1449; 
SN 0302-9743
EI 1611-3349
BN 3-540-24523-5
PY 2005
VL 3406
BP 388
EP 399
UT WOS:000228725100042
ER

PT J
AU SATO, S
AF SATO, S
TI MBT2 - A METHOD FOR COMBINING FRAGMENTS OF EXAMPLES IN EXAMPLE-BASED
   TRANSLATION
SO ARTIFICIAL INTELLIGENCE
AB Example-Based Translation is a new approach to machine translation. The basic idea of this approach is very simple: it is to translate a sentence by using translation examples of similar sentences. One of the major issues of Example-Based Translation is to study the utilization of more than one translation example when translating one source sentence.
   This paper proposes MBT2, which is a method of translating complete sentences by using multiple examples. The representation, matching expression, is introduced, which represents the combination of fragments of translation examples. The translation process of MBT2 consists of three stages:
   (1) Making a source-matching expression from a source sentence.
   (2) Transferring a source-matching expression into a target-matching expression.
   (3) Constructing a target sentence from a target-matching expression.
   This mechanism generates several translation candidates and the score of a translation is defined to select the best translation out of them.
SN 0004-3702
PD MAY
PY 1995
VL 75
IS 1
BP 31
EP 49
DI 10.1016/0004-3702(94)00063-7
UT WOS:A1995RF06500003
ER

PT C
AU Sato, M
   Hishiyama, R
AF Sato, Mizuki
   Hishiyama, Reiko
BE Reisman, S
   Ahamed, SI
   Demartini, C
   Conte, T
   Liu, L
   Claycomb, W
   Nakamura, M
   Tovar, E
   Cimato, S
   Lung, CH
   Takakura, H
   Yang, JJ
   Akiyama, T
   Zhang, Z
   Hasan, K
TI An analysis of multi-language simultaneous display in the translation
   system
SO 2017 IEEE 41ST ANNUAL COMPUTER SOFTWARE AND APPLICATIONS CONFERENCE
   (COMPSAC), VOL 2
SE Proceedings International Computer Software and Applications Conference
CT 41st IEEE Annual Computer Software and Applications Conference (COMPSAC)
CY JUL 04-08, 2017
CL Torino, ITALY
SP IEEE, IEEE Comp Soc
AB It is assumed that Japanese can analogize the meaning of original text if they read the original text according to the commonality of written expressions, such as the commonality of Kanji and Chinese characters in case of Chinese-Japanese translations. In this study, participants rewrote translated sentences while viewing simultaneously the original sentences written in Chinese and the translated sentences into Japanese by Language Grid as a machine translation service. We analyzed how chat between a Japanese rewrite worker and Chinese participant was affected when the original sentences and machine-translated text were simultaneously displayed during the rewriting work. Additionally, we analyzed and evaluated the effect of the simultaneous display on the rewritten translated text. We found that the simultaneous display affects the rewriting work such that it is possible to analogize the meaning of the original text. Furthermore, the simultaneous display improved the translation quality of the rewritten translated text.
RI Hishiyama, Reiko/AAX-5498-2021
OI Hishiyama, Reiko/0000-0001-9984-2790
SN 0730-3157
BN 978-1-5386-0367-3
PY 2017
BP 666
EP 671
DI 10.1109/COMPSAC.2017.50
UT WOS:000424861900123
ER

PT C
AU Rygl, J
AF Rygl, Jan
BE Horak, A
   Rychly, P
TI One System to Solve Them All
SO RASLAN 2014: RECENT ADVANCES IN SLAVONIC NATURAL LANGUAGE PROCESSING
SE Recent Advances in Slavonic Natural Language Processing
CT 8th Workshop on Recent Advances in Slavonic Natural Language Processing
   (RASLAN)
CY DEC 05-07, 2014
CL Karlova Studanka, CZECH REPUBLIC
AB People are daily confronted with hundreds of situations in which they could use the knowledge of stylometry. In this paper, I propose a universal system to solve these situations using stylometry features, machine learning techniques and nature language processing tools. The proposed tool can help translation companies to recognize machine translation falsely submitted as a work of a human expert; identify school essays not written by the underwritten student; or cluster product reviews by authors and merge user reviews written by one author using multiple accounts.
   All examples above use same techniques and procedures to solve the problem, therefore it is preferred to merge algorithms and implementation of these tasks to a single framework.
SN 2336-4289
PY 2014
BP 19
EP 26
UT WOS:000374560500003
ER

PT J
AU Xu, XT
   Liu, Y
   Chen, G
   Ye, JB
   Li, ZG
   Lu, HX
AF Xu, Xintao
   Liu, Yi
   Chen, Gang
   Ye, Junbin
   Li, Zhigang
   Lu, Huaxiang
TI A Cooperative Lightweight Translation Algorithm Combined with
   Sparse-ReLU
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
AB In the field of natural language processing (NLP), machine translation algorithm based on Transformer is challenging to deploy on hardware due to a large number of parameters and low parametric sparsity of the network weights. Meanwhile, the accuracy of lightweight machine translation networks also needs to be improved. To solve this problem, we first design a new activation function, Sparse-ReLU, to improve the parametric sparsity of weights and feature maps, which facilitates hardware deployment. Secondly, we design a novel cooperative processing scheme with CNN and Transformer and use Sparse-ReLU to improve the accuracy of the translation algorithm. Experimental results show that our method, which combines Transformer and CNN with the Sparse-ReLU, achieves a 2.32% BLEU improvement in prediction accuracy and reduces the number of parameters of the model by 23%, and the sparsity of the inference model increases by more than 50%.
RI 刘, 毅/GXN-1792-2022
OI 刘, 毅/0000-0003-3056-7713; Xu, Xintao/0000-0002-3389-7518
SN 1687-5265
EI 1687-5273
PD MAY 28
PY 2022
VL 2022
AR 4398839
DI 10.1155/2022/4398839
UT WOS:000819224500011
PM 35669640
ER

PT C
AU Zhang, T
   Zhang, L
   Ye, W
   Li, B
   Sun, JA
   Zhu, XY
   Zhao, W
   Zhang, SK
AF Zhang, Tong
   Zhang, Long
   Ye, Wei
   Li, Bo
   Sun, Jinan
   Zhu, Xiaoyu
   Zhao, Wen
   Zhang, Shikun
GP Assoc Computat Linguist
TI Point, Disambiguate and Copy: Incorporating Bilingual Dictionaries for
   Neural Machine Translation
SO 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND
   THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (ACL-IJCNLP 2021), VOL 1
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB This paper proposes a sophisticated neural architecture to incorporate bilingual dictionaries into Neural Machine Translation (NMT) models. By introducing three novel components: Pointer, Disambiguator, and Copier, our method PDC achieves the following merits inherently compared with previous efforts: (1) Pointer leverages the semantic information from bilingual dictionaries, for the first time, to better locate source words whose translation in dictionaries can potentially be used; (2) Disambiguator synthesizes contextual information from the source view and the target view, both of which contribute to distinguishing the proper translation of a specific source word from multiple candidates in dictionaries; (3) Copier systematically connects Pointer and Disambiguator based on a hierarchical copy mechanism seamlessly integrated with Transformer, thereby building an end-to-end architecture that could avoid error propagation problems in alternative pipeline methods. The experimental results on Chinese-English and English-Japanese benchmarks demonstrate the PDC's overall superiority and effectiveness of each component.
RI Zhang, xiaoyu/HTM-3222-2023; ZHU, XIAOYU/HJY-7240-2023
BN 978-1-954085-52-7
PY 2021
BP 3970
EP 3979
UT WOS:000698679200107
ER

PT C
AU Aharoni, R
   Johnson, M
   Firat, O
AF Aharoni, Roee
   Johnson, Melvin
   Firat, Orhan
GP Assoc Computat Linguist
TI Massively Multilingual Neural Machine Translation
SO 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019),
   VOL. 1
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 02-07, 2019
CL Minneapolis, MN
SP Assoc Computat Linguist, N Amer Chapter, Comp Res Assoc, Comp Community Consortium, Natl Sci Fdn, Natl Rees Council Canada, Google
AB Multilingual neural machine translation (NMT) enables training a single model that supports translation from multiple source languages into multiple target languages. In this paper, we push the limits of multilingual NMT in terms of the number of languages being used. We perform extensive experiments in training massively multilingual NMT models, translating up to 102 languages to and from English within a single model. We explore different setups for training such models and analyze the trade-offs between translation quality and various modeling decisions. We report results on the publicly available TED talks multilingual corpus where we show that massively multilingual many-to-many models are effective in low resource settings, outperforming the previous state-of-the-art while supporting up to 59 languages. Our experiments on a large-scale dataset with 102 languages to and from English and up to one million examples per direction also show promising results, surpassing strong bilingual baselines and encouraging future work on massively multilingual NMT.
BN 978-1-950737-13-0
PY 2019
BP 3874
EP 3884
UT WOS:000900116903092
ER

PT C
AU Du, JH
   Guo, JB
   Wang, S
   Zhang, XY
AF Du, Jinhua
   Guo, Junbo
   Wang, Sha
   Zhang, Xiyuan
BE Sun, M
   Zhang, M
   Lin, D
   Wang, H
TI Multi-classifier Combination for Translation Error Detection
SO CHINESE COMPUTATIONAL LINGUISTICS AND NATURAL LANGUAGE PROCESSING BASED
   ON NATURALLY ANNOTATED BIG DATA
SE Lecture Notes in Artificial Intelligence
CT 12th China National Conference on Chinese Computational Linguistics
   (CCL) / 1st International Symposium on Natural Language Processing Based
   on Naturally Annotated Big Data (NLP-NABD)
CY OCT 10-12, 2013
CL Soochow Univ, Suzhou, PEOPLES R CHINA
HO Soochow Univ
AB This paper proposes a multi-classifier combination strategy to improve translation error detection performance for statistical machine translation (SMT). Specifically, two different classifiers - Maximum Entropy (MaxEnt) and Support Vector Machine (SVM) - over different features perform a binary classification and export classification probabilities for either class. Then a probability product rule based multi-classifier combination strategy is employed to fuse these two classifiers to decrease the classification error rate (CER). Three typical word posterior probabilities (WPP) and three linguistic features as well as their combinations are used in the experiments conducted on Chinese-to-English NIST data sets. Experimental results show that the combination of multiple classifiers reduce the CER by relative 0.15%, 0.94%, and 1.52% compared to the SVM classifier, and relative 1.73%, 1.72%, 2.02% compared to the MaxEnt classifier over three different feature combinations.
SN 0302-9743
EI 1611-3349
BN 978-3-642-41490-9; 978-3-642-41491-6
PY 2013
VL 8208
BP 291
EP 302
UT WOS:000358605100027
ER

PT C
AU Park, K
   Choe, YJ
   Ham, J
AF Park, Kyubyong
   Choe, Yo Joong
   Ham, Jiyeon
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mariani, J
   Mazo, H
   Moreno, A
   Odijk, J
   Piperidis, S
TI Jejueo Datasets for Machine Translation and Speech Synthesis
SO PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES
   AND EVALUATION (LREC 2020)
CT 12th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 11-16, 2020
CL Marseille, FRANCE
AB Jejueo was classified as critically endangered by UNESCO in 2010. Although diverse efforts to revitalize it have been made, there have been few computational approaches. Motivated by this, we construct two new Jejueo datasets: Jejueo Interview Transcripts (JIT) and Jejueo Single Speaker Speech (JSS). The JIT dataset is a parallel corpus containing 170k+ Jejueo-Korean sentences, and the JSS dataset consists of 10k high-quality audio files recorded by a native Jejueo speaker and a transcript file. Subsequently, we build neural systems of machine translation and speech synthesis using them. All resources are publicly available via our GitHub repository. We hope that these datasets will attract interest of both language and machine learning communities.
RI Choe, Yo Joong/AFS-4090-2022
OI Choe, Yo Joong/0000-0002-0614-9477
BN 979-10-95546-34-4
PY 2020
BP 2615
EP 2621
UT WOS:000724697203071
ER

PT C
AU Appicharla, R
   Gupta, KK
   Ekbal, A
   Bhattacharyya, P
AF Appicharla, Ramakrishna
   Gupta, Kamal Kumar
   Ekbal, Asif
   Bhattacharyya, Pushpak
GP Assoc Computat Linguist
TI IITP-MT at WAT2021: Indic-English Multilingual Neural Machine
   Translation using Romanized Vocabulary
SO WAT 2021: THE 8TH WORKSHOP ON ASIAN TRANSLATION
CT 8th Workshop on Asian Translation (WAT)
CY AUG 05-06, 2021
CL ELECTR NETWORK
AB This paper describes the systems submitted to WAT 2021 MultiIndicMT shared task by IITP-MT team. We submit two multilingual Neural Machine Translation (NMT) systems (Indic-to-English and English-to-Indic). We romanize all Indic data and create subword vocabulary which is shared between all Indic languages. We use back-translation approach to generate synthetic data which is appended to parallel corpus and used to train our models. The models are evaluated using BLEU, RIBES and AMFM scores with Indic-to-English model achieving 40.08 BLEU for Hindi-English pair and English-to-Indic model achieving 34.48 BLEU for English-Hindi pair. However, we observe that the shared romanized subword vocabulary is not helping English-to-Indic model at the time of generation, leading it to produce poor quality translations for Tamil, Telugu and Malayalam to English pairs with BLEU score of 8.51, 6.25 and 3.79 respectively.
BN 978-1-954085-63-3
PY 2021
BP 238
EP 243
UT WOS:000686140700029
ER

PT C
AU Goto, N
   Yamamoto, K
   Nakagawa, S
AF Goto, Norioki
   Yamamoto, Kazumasa
   Nakagawa, Seiichi
GP IEEE
TI English to Japanese Spoken Lecture Translation System by Using DNN-HMM
   and Phrase-based SMT
SO 2015 2ND INTERNATIONAL CONFERENCE ON ADVANCED INFORMATICS: CONCEPTS,
   THEORY AND APPLICATIONS ICAICTA
CT 2nd International Conference on Advanced Informatics: Concepts, Theory
   and Applications (ICAICTA)
CY AUG 19-22, 2015
CL Chonburi, THAILAND
SP IEEE, IEEE Thailand Sect, ECTI, SIPA, TOT
AB This paper presents our scheme to translate spoken English lectures into Japanese that consists of an English automatic speech recognition system ( ASR) that utilizes a deep neural network ( DNN) and an English to Japanese phrase-based statistical machine translation system ( SMT). We utilized an existing Wall Street Journal corpus for our acoustic model and adapted it with MIT OpenCourseWare lectures whose transcriptions we also utilized to create our language model. For the parallel corpus of our SMT system, we used TED Talks and Japanese News Article Alignment Data. Our ASR system achieved a word error rate ( WER) of 21.0%, and our SMT system achieved a 3-gram base bilingual evaluation understudy ( BLEU) of 16.8 for text input and 14.6 for speech input, respectively. These scores outperformed our previous system : WER = 32.1% and BLEU = 11.0.
RI nakagawa, seiichi/L-5543-2019
BN 978-1-4673-8143-7
PY 2015
UT WOS:000380390500011
ER

PT J
AU Novitasari, S
   Sakti, S
   Nakamura, S
AF Novitasari, Sashi
   Sakti, Sakriani
   Nakamura, Satoshi
TI Neural Incremental Speech Recognition Toward Real-Time Machine Speech
   Translation
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
AB Real-time machine speech translation systems mimic human interpreters and translate incoming speech from a source language to the target language in real-time. Such systems can be achieved by performing low-latency processing in ASR (automatic speech recognition) module before passing the output to MT (machine translation) and TTS (text-to-speech synthesis) modules. Although several studies recently proposed sequence mechanisms for neural incremental ASR (ISR), these frameworks have a more complicated training mechanism than the standard attention-based ASR because they have to decide the incremental step and learn the alignment between speech and text. In this paper, we propose attention-transfer ISR (AT-ISR) that learns the knowledge from attention-based non-incremental ASR for a low delay end-to-end speech recognition. ISR comes with a trade-off between delay and performance, so we investigate how to reduce AT-ISR delay without a significant performance drop. Our experiment shows that AT-ISR achieves a comparable performance to the non-incremental ASR when the incremental recognition begins after the speech utterance reaches 25% of the complete utterance length. Additional experiments to investigate the effect of ISR on translation tasks are also performed. The focus is to find the optimum granularity of the output unit. The results reveal that our end-to-end subword-level ISR resulted in the best translation quality with the lowest WER and the lowest uncovered-word rate.
SN 0916-8532
EI 1745-1361
PD DEC
PY 2021
VL E104D
IS 12
BP 2195
EP 2208
DI 10.1587/transinf.2021EDP7014
UT WOS:000748954600018
ER

PT J
AU Sosnin, AV
   Balakina, JV
   Kashikhin, AN
AF Sosnin, Alexey V.
   Balakina, Julia V.
   Kashikhin, Andrey N.
TI Interdependence of expert categories and automated metrics applied to
   evaluate translation quality
SO VESTNIK SANKT-PETERBURGSKOGO UNIVERSITETA-YAZYK I LITERATURA
AB The article evaluates the quality of translation; we consider the applied and pragmatic aspects of such evaluation in the conditions of the current rapid increase in the number of texts to be translated. The article summarizes a plethora of assessment principles, each having its merits and drawbacks, and examines the correlation between the categories of adequacy and equivalence as the basic assessment parameters. We conclude that equivalence is oriented towards the result of translation, whereas adequacy indicates whether translation as process corresponds to the communicative situation given. Adequacy is thus viewed as a discursive feature. The article also looks into the possibility of applying these assessment criteria to automated evaluation of translation quality, and compares the specific computer metrics or, algorithms: Cosine Similarity, Word Error Rate, BLEU, ROUGE, NIST, METEOR. We analyze the potential for applying these metrics to man-made rather than machine translated. The n-gram metric for evaluation of translation with explicit ordering Meteor is the most efficient algorithm; however, it can only be applied advantageously to formal standardized texts. The article points out that literary translation can hardly be evaluated on the basis of n-gram correspondences due to it characteristic feature: ample use of non-equivalent units even at the sentence level. The purely mathematical procedures overviewed in the article cannot serve as linguistic meta-models of assessment unless supplemented with syntactic and semantic algorithms.
RI Balakina, Julia/O-8009-2014
OI Balakina, Julia/0000-0002-4942-5953
SN 2541-9358
EI 2541-9366
PY 2022
VL 19
IS 1
BP 125
EP 148
DI 10.21638/spbu09.2022.107
UT WOS:000801222800006
ER

PT C
AU Devlin, J
   Kamali, M
   Subramanian, K
   Prasad, R
   Natarajan, P
AF Devlin, Jacob
   Kamali, Matin
   Subramanian, Krishna
   Prasad, Rohit
   Natarajan, Prem
GP IEEE
TI Statistical Machine Translation as a Language Model for Handwriting
   Recognition
SO 13TH INTERNATIONAL CONFERENCE ON FRONTIERS IN HANDWRITING RECOGNITION
   (ICFHR 2012)
SE International Conference on Handwriting Recognition
CT 13th International Conference on Frontiers in Handwriting Recognition
   (ICFHR)
CY SEP 18-20, 2012
CL Monopoli, ITALY
SP Governo Italiano, Minist Pubblica Amministrazione & Semplificazione, Minist Sviluppo Economico, IAPR, Sigillum Univ Barensis, Rete Puglia, Int Graphonom Soc, Gruppo Italiano Ricercatori Pattern Recognit, Hitachi, A2iA, Traccia, AIIA, AICA, Consorzio Interuniversitario Nazionale lInformatica, Gruppo Ingegneria Informatica, IEEE Comp Soc, DIB
AB When performing handwriting recognition on natural language text, the use of a word-level language model (LM) is known to significantly improve recognition accuracy. The most common type of language model, the n-gram model, decomposes sentences into short, overlapping chunks.
   In this paper, we propose a new type of language model which we use in addition to the standard n-gram LM. Our new model uses the likelihood score from a statistical machine translation system as a reranking feature. In general terms, we automatically translate each OCR hypothesis into another language, and then create a feature score based on how "difficult" it was to perform the translation. Intuitively, the difficulty of translation correlates with how well-formed the input sentence is. In an Arabic handwriting recognition task, we were able to obtain an 0.4% absolute improvement to word error rate (WER) on top of a powerful 5-gram LM.
OI Natarajan, Premkumar/0000-0002-4386-6651
SN 2167-6445
BN 978-0-7695-4774-9; 978-1-4673-2262-1
PY 2012
BP 291
EP 296
DI 10.1109/ICFHR.2012.273
UT WOS:000318947900046
ER

PT C
AU Protaziuk, G
   Kaczynski, M
   Bembenik, R
AF Protaziuk, Grzegorz
   Kaczynski, Marcin
   Bembenik, Robert
BE Ryzko, D
   Gawrysiak, P
   Kryszkiewicz, M
   Rybinski, H
TI Automatic Translation of Multi-word Labels
SO MACHINE INTELLIGENCE AND BIG DATA IN INDUSTRY
SE Studies in Big Data
CT 6th International Conference on Pattern Recognition and Machine
   Intelligence (PREMI)
CY JUN 30-JUL 03, 2015
CL Warsaw, POLAND
AB Application of semantic resources often requires linking phrases expressed in a natural language to formally defined notions. In case of ontologies lexical layers may be used for that purpose. In the paper we propose an automatic machine translation method for translating multi-word labels from lexical layers of domain ontologies. In the method we take advantage of Wikipedia and dictionaries services available on the Internet in order to provide translations of thematic texts from a given area of interest. Experimental evaluation shows usefulness of the proposed method in translating specialized thematic dictionaries.
OI Bembenik, Robert/0000-0002-7771-2351
SN 2197-6503
BN 978-3-319-30315-4; 978-3-319-30314-7
PY 2016
VL 19
BP 99
EP 109
DI 10.1007/978-3-319-30315-4_9
UT WOS:000377507200009
ER

PT C
AU Wang, HF
AF Wang, Hongfei
BE Luo, X
   Luo, Z
   Ni, LM
   Wang, R
TI ATM - Awesome Translation Machine
SO 2014 5TH INTERNATIONAL CONFERENCE ON DIGITAL HOME (ICDH)
SE International Conference on Digital Home
CT 5th International Conference on Digital Home (ICDH)
CY NOV 28-30, 2014
CL Sun Yatsen Univ, Guangzhou, PEOPLES R CHINA
SP Dalian Univ Technol, IEEE Comp Soc, Beijing Univ Technol, Hefei Univ Technol, Natl Nat Sci Fdn China, IEEE
HO Sun Yatsen Univ
AB In this paper, we present the ATM (Awesome Translation Machine), which translates handwriting texts in English into Chinese, and then provides its pronunciations in both the two languages. Specifically, two types of the databases that contain characters and sentences for training the ATM are constructed. Various signal processing techniques are employed sequentially for processing and analyzing the image raw data. After all the preparation stages, we apply multiple pattern recognition techniques, i.e., principle component analysis, linear discriminant analysis, and support vector machines, for the purpose of character recognition. The identified characters are thereby automatically linked to their actual meanings stored. Extensive experiments are conducted to gauge the performance for different techniques.
SN 2372-7160
BN 978-1-4799-4284-8
PY 2014
BP 226
EP 231
DI 10.1109/ICDH.2014.50
UT WOS:000410646200043
ER

PT C
AU Chen, PZ
   Bogoychev, N
   Germann, U
AF Chen, Pinzhen
   Bogoychev, Nikolay
   Germann, Ulrich
GP Assoc Comp Linguist
TI Character Mapping and Ad-hoc Adaptation: Edinburgh's IWSLT 2020 Open
   Domain Translation System
SO 17TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE TRANSLATION (IWSLT
   2020)
CT 17th International Conference on Spoken Language Translation (IWSLT)
CY JUL 09-10, 2020
CL ELECTR NETWORK
AB This paper describes the University of Edinburgh's neural machine translation systems submitted to the IWSLT 2020 open domain Japanese <-> Chinese translation task. On top of commonplace techniques like tokenisation and corpus cleaning, we explore character mapping and unsupervised decoding-time adaptation. Our techniques focus on leveraging the provided data, and we show the positive impact of each technique through the gradual improvement of BLEU.
BN 978-1-952148-07-1
PY 2020
BP 122
EP 129
UT WOS:000563427100014
ER

PT C
AU Zhang, W
   Feng, Y
   Meng, FD
   You, D
   Liu, Q
AF Zhang, Wen
   Feng, Yang
   Meng, Fandong
   You, Di
   Liu, Qun
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Bridging the Gap between Training and Inference for Neural Machine
   Translation
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB Neural Machine Translation (NMT) generates target words sequentially in the way of predicting the next word conditioned on the context words. At training time, it predicts with the ground truth words as context while at inference it has to generate the entire sequence from scratch. This discrepancy of the fed context leads to error accumulation among the way. Furthermore, word-level training requires strict matching between the generated sequence and the ground truth sequence which leads to overcorrection over different but reasonable translations. In this paper, we address these issues by sampling context words not only from the ground truth sequence but also from the predicted sequence by the model during training, where the predicted sequence is selected with a sentence-level optimum. Experiment results on Chinese -> English and WMT'14 English -> German translation tasks demonstrate that our approach can achieve significant improvements on multiple datasets.
BN 978-1-950737-48-2
PY 2019
BP 4334
EP 4343
UT WOS:000493046106085
ER

PT J
AU Sajadi, A
   Borujerdi, MRM
AF Sajadi, Armin
   Borujerdi, Mohammad Reza M.
TI Machine translation based on unification link grammar
SO ARTIFICIAL INTELLIGENCE REVIEW
AB The goal of this article is to develop a translation method based on link grammar. Through this and to make it possible, we introduce a new formalism for syntactic analysis called Unification Link Grammar as a result of adding unification paradigms to link grammar. This brings about some other benefits such as more generative power, less complexity and being well organized for knowledge extraction. Based on this new formalism, we develop a translation method which is completely compatible with the linguistic basis of link grammar. This approach transfers graphs by using some kind of correspondence between the nodes and without using so called sub-constituents, sub-graphs or any similar concept. The introduced algorithm has a linear order time complexity. The implemented system shows the advantages of our approaches in covering complex structures of English language.
SN 0269-2821
EI 1573-7462
PD FEB
PY 2013
VL 39
IS 2
BP 109
EP 132
DI 10.1007/s10462-011-9261-7
UT WOS:000315358400002
ER

PT C
AU Dou, ZY
   Hu, JJ
   Anastasopoulos, A
   Neubig, G
AF Dou, Zi-Yi
   Hu, Junjie
   Anastasopoulos, Antonios
   Neubig, Graham
GP Assoc Computat Linguist
TI Unsupervised Domain Adaptation for Neural Machine Translation with
   Domain-Aware Feature Embeddings
SO 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND
   THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE
CT Conference on Empirical Methods in Natural Language Processing / 9th
   International Joint Conference on Natural Language Processing
   (EMNLP-IJCNLP)
CY NOV 03-07, 2019
CL Hong Kong, HONG KONG
SP Google, Facebook, Apple, ASAPP, Salesforce, Huawei, Baidu, Deepmind, Amazon, PolyAI, Naver, ByteDance, Megagon Labs, Zhuiyi, Verisk, MI
AB The recent success of neural machine translation models relies on the availability of high quality, in-domain data. Domain adaptation is required when domain-specific data is scarce or nonexistent. Previous unsupervised domain adaptation strategies include training the model with in-domain copied monolingual or back-translated data. However, these methods use generic representations for text regardless of domain shift, which makes it infeasible for translation models to control outputs conditional on a specific domain. In this work, we propose an approach that adapts models with domain-aware feature embeddings, which are learned via an auxiliary language modeling task. Our approach allows the model to assign domain-specific representations to words and output sentences in the desired domain. Our empirical results demonstrate the effectiveness of the proposed strategy, achieving consistent improvements in multiple experimental settings. In addition, we show that combining our method with back translation can further improve the performance of the model.(1)
BN 978-1-950737-90-1
PY 2019
BP 1417
EP 1422
UT WOS:000854193301069
ER

PT C
AU Oliveira, F
   Wong, F
   Li, YP
   Zheng, J
AF Oliveira, F
   Wong, F
   Li, YP
   Zheng, J
GP IEEE
TI Unsupervised word sense disambiguation and rules extraction using
   non-aligned bilingual corpus
SO Proceedings of the 2005 IEEE International Conference on Natural
   Language Processing and Knowledge Engineering (IEEE NLP-KE'05)
CT International Conference on Natural Language Processing and Knowledge
   Engineering
CY OCT 30-NOV 01, 2005
CL Wuhan, PEOPLES R CHINA
SP IEEE, AAI, CIPSC, Chinese Assoc Artificial Intelligence, IEEE Signal Proc Soc, IEEE Beijing Sect
AB This. paper presents a statistical Word Sense Disambiguation with application in Portuguese-Chinese Machine Translation systems.. Due to the limited availability of Portuguese-Chinese resources in the form of digital corpora and annotated Treebank, an unsupervised learning and a non-aligned bilingual corpus are applied. The proposed method first identifies words related to each of the ambiguous words based on their surrounding words and relative distance. A mathematical model is then applied in the identification of the most suitable sense of an ambiguous word in terms of the related words. All the senses discovered are converted into a set of rules and stored in the Sense Knowledge base for later use in disambiguation and translation process. Preliminary experiment results show an improvement of 6% in assigning correctly the corresponding translation over the baseline method.
OI Wong, Derek F./0000-0002-5307-7322
BN 0-7803-9361-9
PY 2005
BP 30
EP 35
UT WOS:000235577200007
ER

PT J
AU Fakhrahmad, SM
   Rezapour, AR
   Sadreddini, MH
   Jahromi, MZ
AF Fakhrahmad, S. M.
   Rezapour, A. R.
   Sadreddini, M. H.
   Jahromi, M. Zolghadri
TI A NOVEL APPROACH TO MACHINE TRANSLATION: A PROPOSED LANGUAGE-INDEPENDENT
   SYSTEM BASED ON DEDUCTIVE SCHEMES
SO IRANIAN JOURNAL OF SCIENCE AND TECHNOLOGY-TRANSACTIONS OF ELECTRICAL
   ENGINEERING
AB Compared to corpora-based machine translation methods, rule-based methods have deficiencies, which make them unattractive for the researchers of this field. The first problem is that these methods are language dependent. Rule-based methods require the syntactic information about source and target languages. On the other hand, in many cases, especially for proverbs and specific expressions, syntactic rules are no longer useful. In such cases, the use of example-based approaches is inevitable. In this work, we propose and integrate a set of novel schemes to introduce a new translation system, called BORNA. First a grammar induction method based on the Expectation Maximization (EM) algorithm is proposed. After representing the extracted knowledge in the form of a set of nested finite automata, a recursive model is proposed, which uses a combination of rule and example based techniques. In the translation phase, through a hierarchical chunking process, the input sentence is divided into a set of phrases. Each phrase is searched in the corpus of examples. If the phrase is found, it will not be chunked anymore. Otherwise, the phrase is divided into smaller sub-phrases. The simulation results show that BORNA outperforms its counterparts, significantly. Compared to PARS, Frengly and Google translators, BORNA receives the highest Bleu scores for its translations, while it results in the minimum values for different error measures, including PER, TER and WER.
RI Rezapour, Abdoreza/AAO-2737-2021; Sadreddini, Mohammad Hadi/P-9675-2019
OI Rezapour, Abdoreza/0000-0003-1270-2029; 
SN 2228-6179
EI 2364-1827
PD JUN
PY 2014
VL 38
IS E1
BP 59
EP 72
UT WOS:000348632000004
ER

PT C
AU Jantsch, S
   Norrish, M
AF Jantsch, Simon
   Norrish, Michael
BE Avigad, J
   Mahboubi, A
TI Verifying the LTL to Buchi Automata Translation via Very Weak
   Alternating Automata
SO INTERACTIVE THEOREM PROVING, ITP 2018
SE Lecture Notes in Computer Science
CT 9th International Conference on Interactive Theorem Proving (ITP) Held
   as Part of the Federated Logic Conference (FloC)
CY JUL 09-12, 2018
CL Oxford, ENGLAND
AB We present a formalization of a translation from LTL formulae to generalized Buchi automata in the HOL4 theorem prover. Translations from temporal logics to automata are at the core of model checking algorithms based on automata-theoretic techniques. The translation we verify proceeds in two steps: it produces very weak alternating automata at an intermediate stage, and then ultimately produces a generalized Buchi automaton. After verifying both transformations, we also encode both of these automata models using a generic, functional graph type, and use the CakeML compiler to generate fully verified machine code implementing the translation.
OI Norrish, Michael/0000-0003-1163-8467
SN 0302-9743
EI 1611-3349
BN 978-3-319-94821-8; 978-3-319-94820-1
PY 2018
VL 10895
BP 306
EP 323
DI 10.1007/978-3-319-94821-8_18
UT WOS:000490904100018
ER

PT C
AU Takase, S
   Okazaki, N
AF Takase, Sho
   Okazaki, Naoaki
BA Mariani, J
BF Mariani, J
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mazo, H
   Odijk, H
   Piperidis, S
TI Multi-Task Learning for Cross-Lingual Abstractive Summarization
SO LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION
CT 13th International Conference on Language Resources and Evaluation
   (LREC)
CY JUN 20-25, 2022
CL Marseille, FRANCE
SP Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur
AB We present a multi-task learning framework for cross-lingual abstractive summarization to augment training data. Recent studies constructed pseudo cross-lingual abstractive summarization data to train their neural encoder-decoders. Meanwhile, we introduce existing genuine data such as translation pairs and monolingual abstractive summarization data into training. Our proposed method, Transum, attaches a special token to the beginning of the input sentence to indicate the target task. The special token enables us to incorporate the genuine data into the training data easily. The experimental results show that Transum achieves better performance than the model trained with only pseudo cross-lingual summarization data. In addition, we achieve the top ROUGE score on Chinese-English and Arabic-English abstractive summarization. Moreover, Transum also has a positive effect on machine translation. Experimental results indicate that Transum improves the performance from the strong baseline, Transformer, in Chinese-English, Arabic-English, and English-Japanese translation datasets.
BN 979-10-95546-72-6
PY 2022
BP 3008
EP 3016
UT WOS:000889371703011
ER

PT C
AU Zeng, JL
   Wu, SZ
   Yin, YJ
   Jiang, YF
   Li, M
AF Zeng, Jiali
   Wu, Shuangzhi
   Yin, Yongjing
   Jiang, Yufan
   Li, Mu
GP Assoc Computat Linguist
TI Recurrent Attention for Neural Machine Translation
SO 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2021)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 07-11, 2021
CL Punta Cana, DOMINICAN REP
AB Recent research questions the importance of the dot-product self-attention in Transformer models and shows that most attention heads learn simple positional patterns. In this paper, we push further in this research line and propose a novel substitute mechanism for self-attention: Recurrent AtteNtion (RAN). RAN directly learns attention weights without any token-to-token interaction and further improves their capacity by layer-to-layer interaction. Across an extensive set of experiments on 10 machine translation tasks, we find that RAN models are competitive and outperform their Transformer counterpart in certain scenarios, with fewer parameters and inference time. Particularly, when apply RAN to the decoder of Transformer, there brings consistent improvements by about +0.5 BLEU on 6 translation tasks and +1.0 BLEU on Turkish-English translation task. In addition, we conduct extensive analysis on the attention weights of RAN to confirm their reasonableness. Our RAN is a promising alternative to build more effective and efficient NMT models.
BN 978-1-955917-09-4
PY 2021
BP 3216
EP 3225
UT WOS:000855966303030
ER

PT J
AU Ramati, I
   Pinchevski, A
AF Ramati, Ido
   Pinchevski, Amit
TI Uniform multilingualism: A media genealogy of Google Translate
SO NEW MEDIA & SOCIETY
AB This article applies a media geneaology perspective to examine the operative logic of Google Translate. Tracing machine translation from post-World War II (WWII) rule-based methods to contemporary algorithmic statistical methods, we analyze the underlying power structure of algorithmic and human collaboration that Translate encompasses. Focusing on the relationship between technology, language, and speakers, we argue that the operative logic of Translate represents a new model of translation, which we call uniform multilingualism. In this model, the manifest lingual plurality on the user side is mediated by lingual uniformity on the system side in the form of an English language algorithm, which has recently given way to an artificial neural network interlingual algorithm. We conclude by considering the significance of this recent shift in Translate's algorithm.
RI Ramati, Ido/GQZ-2916-2022
OI Pinchevski, Amit/0000-0001-7839-1732
SN 1461-4448
EI 1461-7315
PD JUL
PY 2018
VL 20
IS 7
BP 2550
EP 2565
DI 10.1177/1461444817726951
UT WOS:000438601800017
ER

PT C
AU Lin, H
   Yao, L
   Yang, BS
   Liu, DYH
   Zhang, HB
   Luo, WH
   Huang, DG
   Su, JS
AF Lin, Huan
   Yao, Liang
   Yang, Baosong
   Liu, Dayiheng
   Zhang, Haibo
   Luo, Weihua
   Huang, Degen
   Su, Jinsong
GP Assoc Computat Linguist
TI Towards User-Driven Neural Machine Translation
SO 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND
   THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (ACL-IJCNLP 2021), VOL 1
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB A good translation should not only translate the original content semantically, but also incarnate personal traits of the original text. For a real-world neural machine translation (NMT) system, these user traits (e.g., topic preference, stylistic characteristics and expression habits) can be preserved in user behavior (e.g., historical inputs). However, current NMT systems marginally consider the user behavior due to: 1) the difficulty of modeling user portraits in zero-shot scenarios, and 2) the lack of user-behavior annotated parallel dataset. To fill this gap, we introduce a novel framework called user-driven NMT. Specifically, a cache-based module and a user-driven contrastive learning method are proposed to offer NMT the ability to capture potential user traits from their historical inputs under a zero-shot learning fashion. Furthermore, we contribute the first Chinese-English parallel corpus annotated with user behavior called UDT-Corpus. Experimental results confirm that the proposed user-driven NMT can generate user-specific translations.
RI Zhang, Haibo/HLP-9266-2023
BN 978-1-954085-52-7
PY 2021
BP 4008
EP 4018
UT WOS:000698679200110
ER

PT C
AU Zhou, CT
   Levy, D
   Li, X
   Ghazvininejad, M
   Neubig, G
AF Zhou, Chunting
   Levy, Daniel
   Li, Xian
   Ghazvininejad, Marjan
   Neubig, Graham
GP Assoc Computat Linguist
TI Distributionally Robust Multilingual Machine Translation
SO 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2021)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 07-11, 2021
CL Punta Cana, DOMINICAN REP
AB Multilingual neural machine translation (MNMT) learns to translate multiple language pairs with a single model, potentially improving both the accuracy and the memory-efficiency of deployed models. However, the heavy data imbalance between languages hinders the model from performing uniformly across language pairs. In this paper, we propose a new learning objective for MNMT based on distributionally robust optimization, which minimizes the worst-case expected loss over the set of language pairs. We further show how to practically optimize this objective for large translation corpora using an iterated best response scheme, which is both effective and incurs negligible additional computational cost compared to standard empirical risk minimization. We perform extensive experiments on three sets of languages from two datasets and show that our method consistently outperforms strong baseline methods in terms of average and per-language performance under both many-to-one and one-to-many translation settings.(1)
BN 978-1-955917-09-4
PY 2021
BP 5664
EP 5674
UT WOS:000855966305062
ER

PT C
AU Karakanta, A
   Negri, M
   Turchi, M
AF Karakanta, Alina
   Negri, Matteo
   Turchi, Marco
GP Assoc Comp Linguist
TI Is 42 the Answer to Everything in Subtitling-oriented Speech
   Translation?
SO 17TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE TRANSLATION (IWSLT
   2020)
CT 17th International Conference on Spoken Language Translation (IWSLT)
CY JUL 09-10, 2020
CL ELECTR NETWORK
AB Subtitling is becoming increasingly important for disseminating information, given the enormous amounts of audiovisual content becoming available daily. Although Neural Machine Translation (NMT) can speed up the process of translating audiovisual content, large manual effort is still required for transcribing the source language, and for spotting and segmenting the text into proper subtitles. Creating proper subtitles in terms of timing and segmentation highly depends on information present in the audio (utterance duration, natural pauses). In this work, we explore two methods for applying Speech Translation (ST) to subtitling: a) a direct end-to-end and b) a classical cascade approach. We discuss the benefit of having access to the source language speech for improving the conformity of the generated subtitles to the spatial and temporal subtitling constraints and show that length' is not the answer to everything in the case of subtitling-oriented ST.
RI Turchi, Marco/AFN-0053-2022
OI Karakanta, Alina/0000-0002-1029-1337; Negri, Matteo/0000-0002-8811-4330
BN 978-1-952148-07-1
PY 2020
BP 209
EP 219
UT WOS:000563427100026
ER

PT C
AU Shao, CZ
   Feng, Y
   Chen, XL
AF Shao, Chenze
   Feng, Yang
   Chen, Xilin
GP Assoc Computat Linguist
TI Greedy Search with Probabilistic N-gram Matching for Neural Machine
   Translation
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB Neural machine translation (NMT) models are usually trained with the word-level loss using the teacher forcing algorithm, which not only evaluates the translation improperly but also suffers from exposure bias. Sequence-level training under the reinforcement framework can mitigate the problems of the word-level loss, but its performance is unstable due to the high variance of the gradient estimation. On these grounds, we present a method with a differentiable sequence-level training objective based on probabilistic n-gram matching which can avoid the reinforcement framework. In addition, this method performs greedy search in the training which uses the predicted words as context just as at inference to alleviate the problem of exposure bias. Experiment results on the NIST Chinese-to-English translation tasks show that our method significantly outperforms the reinforcement-based algorithms and achieves an improvement of 1.5 BLEU points on average over a strong baseline system.
BN 978-1-948087-84-1
PY 2018
BP 4778
EP 4784
UT WOS:000865723404091
ER

PT C
AU Zenkel, T
   Wuebker, J
   DeNero, J
AF Zenkel, Thomas
   Wuebker, Joern
   DeNero, John
GP Assoc Computat Linguist
TI End-to-End NeuralWord Alignment Outperforms GIZA plus
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB Word alignment was once a core unsupervised learning task in natural language processing because of its essential role in training statistical machine translation (MT) models. Although unnecessary for training neural MT models, word alignment still plays an important role in interactive applications of neural machine translation, such as annotation transfer and lexicon injection. While statistical MT methods have been replaced by neural approaches with superior performance, the twenty-year-old GIZA++ toolkit remains a key component of state-of-the-art word alignment systems. Prior work on neural word alignment has only been able to outperform GIZA++ by using its output during training. We present the first end-to-end neural word alignment method that consistently outperforms GIZA++ on three data sets. Our approach repurposes a Transformer model trained for supervised translation to also serve as an unsupervised word alignment model in a manner that is tightly integrated and does not affect translation quality.
BN 978-1-952148-25-5
PY 2020
BP 1605
EP 1617
UT WOS:000570978201081
ER

PT C
AU Zhou, L
   Ding, L
   Duh, K
   Watanabe, S
   Sasano, R
   Takeda, K
AF Zhou, Lei
   Ding, Liang
   Duh, Kevin
   Watanabe, Shinji
   Sasano, Ryohei
   Takeda, Koichi
GP Assoc Computat Linguist
TI Self-Guided Curriculum Learning for Neural Machine Translation
SO IWSLT 2021: THE 18TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE
   TRANSLATION
CT 18th International Conference on Spoken Language Translation (IWSLT)
CY AUG 05-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB In supervised learning, a well-trained model should be able to recover ground truth accurately, i.e. the predicted labels are expected to resemble the ground truth labels as much as possible. Inspired by this, we formulate a difficulty criterion based on the recovery degrees of training examples. Motivated by the intuition that after skimming through the training corpus, the neural machine translation (NMT) model "knows" how to schedule a suitable curriculum according to learning difficulty, we propose a self-guided curriculum learning strategy that encourages the NMT model to learn from easy to hard on the basis of recovery degrees. Specifically, we adopt sentence-level BLEU score as the proxy of recovery degree. Experimental results on translation benchmarks including WMT14 English double right arrow German and WMT17 Chinese double right arrow English demonstrate that our proposed method considerably improves the recovery degree, thus consistently improving the translation performance.
RI Watanabe, Shinji/AEH-1279-2022
OI Watanabe, Shinji/0000-0002-5970-8631
BN 978-1-954085-74-9
PY 2021
BP 206
EP 214
UT WOS:000694723100025
ER

PT C
AU Vamvas, J
   Sennrich, R
AF Vamvas, Jannis
   Sennrich, Rico
GP Assoc Computa Linguist
TI As Little as Possible, as Much as Necessary: Detecting Over- and
   Undertranslations with Contrastive Conditioning
SO PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB Omission and addition of content is a typical issue in neural machine translation. We propose a method for detecting such phenomena with off-the-shelf translation models. Using contrastive conditioning, we compare the likelihood of a full sequence under a translation model to the likelihood of its parts, given the corresponding source or target sequence. This allows to pinpoint superfluous words in the translation and untranslated words in the source even in the absence of a reference translation. The accuracy of our method is comparable to a supervised method that requires a custom quality estimation model.
OI Sennrich, Rico/0000-0002-1438-4741
BN 978-1-955917-22-3
PY 2022
BP 490
EP 500
UT WOS:000828732800053
ER

PT J
AU Ke, X
AF Ke, Xin
TI English synchronous real-time translation method based on reinforcement
   learning
SO WIRELESS NETWORKS
AB For many years, machine translation has been one of the most important and challenging topics in the field of natural language processing. In this work, we discuss and implement the real-time synchronous translation method, and focus on the key technologies to be solved in the translation generation of real-time synchronous translation method. The optimal template selection and phrase translation are the key factors affecting template machine translation. We improve the selection of the optimal template by using the methods of text template direct matching and template selection. In addition, the sequence-to-sequence model based on Recurrent Neural Network (RNN) has achieved good results in the task of translation text generation, but most of these models have the problems of text repetition, and exposure deviation. Aiming at the repetition problems, we propose a hybrid attention composed of stored attention and decoded self-attention, which is overcome by storing historical attention. In order to solve the problem of exposure bias and correct the loss function, we design a new training method based on reinforcement learning. In the experiment, we test the model on the ChinaDaily dataset and take Recall-Oriented Understudy for Gisting Evaluation (ROUGE) as the evaluation index. The results show that mixed attention can greatly improve the repetition problem, the exposure deviation can be eliminated with reinforcement learning, and the integrated model surpasses the State-of-the-Art algorithms in the test set.
SN 1022-0038
EI 1572-8196
DI 10.1007/s11276-022-02910-4
EA FEB 2022
UT WOS:000757925400001
ER

PT J
AU Roggia, S
   Cupertino, F
   Gerada, C
   Galea, M
AF Roggia, Sara
   Cupertino, Francesco
   Gerada, Chris
   Galea, Michael
TI Axial Position Estimation of Conical Shaped Motors for Aerospace
   Traction Applications
SO IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS
CT 8th Annual IEEE Energy Conversion Congress and Exposition (ECCE)
CY SEP 18-22, 2016
CL Milwaukee, WI
SP IEEE, IEEE Power Elect Soc, IEEE Ind Applicat Soc
AB This paper is concerned with the use of conical induction machines. Such machines are extremely valuable when apart from the rotational torque output; an axial translation of the rotor is also required. The inherent attraction between the stator and rotor of any machine combined with the geometry of a conical machine will provide the required axial movement. However, when applied to aerospace applications, where reliability is very important, then full monitoring of the axial position is required. In this paper, an innovative approach aimed at monitoring and controlling the axial translation of a conical induction machine is proposed and investigated. In order to increase the system reliability and also decrease component count as demanded by the application, the methodology is a sensor-less technique based on an innovative variant of the high-frequency injection approach. In this paper, the technique has been fully investigated and experimentally validated on a purposely built instrumented test-rig.
RI Roggia, Sara/HDN-7931-2022
OI Galea, Michael/0000-0002-9094-611X; Cupertino,
   Francesco/0000-0003-4135-4756; Gerada, Chris/0000-0003-4707-4480
SN 0093-9994
EI 1939-9367
PD NOV-DEC
PY 2017
VL 53
IS 6
BP 5405
EP 5414
DI 10.1109/TIA.2017.2717911
UT WOS:000416214600030
ER

PT C
AU Zhou, L
   Zhang, JJ
   Zong, CQ
AF Zhou, Long
   Zhang, Jiajun
   Zong, Chengqing
BE Huang, X
   Jiang, J
   Zhao, D
   Feng, Y
   Hong, Y
TI Look-Ahead Attention for Generation in Neural Machine Translation
SO NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING, NLPCC 2017
SE Lecture Notes in Artificial Intelligence
CT 6th CCF International Conference on Natural Language Processing and
   Chinese Computing (NLPCC)
CY NOV 08-12, 2017
CL Dalian Univ Technol, Dalian, PEOPLES R CHINA
SP China Comp Federat, State Key Lab Digital Publishing Technol, Lecture Notes Comp Sci, Springer, ACTA Scientiarum Naturalium Univ Pekinensis, Global Tone Commun Technol, WeChat, Microsoft, Baidu, Vpark, Gridsum, Toutiao, Sogou, Naturali, XINHUAZHIYUN, Intel Corp, NiuTrans, Lenovo
HO Dalian Univ Technol
AB The attention model has become a standard component in neural machine translation (NMT) and it guides translation process by selectively focusing on parts of the source sentence when predicting each target word. However, we find that the generation of a target word does not only depend on the source sentence, but also rely heavily on the previous generated target words, especially the distant words which are difficult to model by using recurrent neural networks. To solve this problem, we propose in this paper a novel look-ahead attention mechanism for generation in NMT, which aims at directly capturing the dependency relationship between target words. We further design three patterns to integrate our look-ahead attention into the conventional attention model. Experiments on NIST Chinese-to-English and WMT English-to-German translation tasks show that our proposed look-ahead attention mechanism achieves substantial improvements over state-of-the-art baselines.
OI Zong, Chengqing/0000-0002-9864-3818
SN 0302-9743
EI 1611-3349
BN 978-3-319-73618-1; 978-3-319-73617-4
PY 2018
VL 10619
BP 211
EP 223
DI 10.1007/978-3-319-73618-1_18
UT WOS:000491315000018
ER

PT J
AU Arora, KK
   Agrawal, SS
AF Arora, Karunesh Kumar
   Agrawal, Shyam Sunder
TI Source-side Reordering to Improve Machine Translation between Languages
   with Distinct Word Orders
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB English and Hindi have significantly different word orders. English follows the subject-verb-object (SVO) order, while Hindi primarily follows the subject-object-verb (SOV) order. This difference poses challenges to modeling this pair of languages for translation. In phrase-based translation systems, word reordering is governed by the language model, the phrase table, and reordering models. Reordering in such systems is generally achieved during decoding by transposing words within a defined window. These systems can handle local reorderings, and while some phrase-level reorderings are carried out during the formation of phrases, they are weak in learning long-distance reorderings. To overcome this weakness, researchers have used reordering as a step in pre-processing to render the reordered source sentence closer to the target language in terms of word order. Such approaches focus on using parts-of-speech (POS) tag sequences and reordering the syntax tree by using grammatical rules, or through head finalization. This study shows that mere head finalization is not sufficient for the reordering of sentences in the English-Hindi language pair. It describes various grammatical constructs and presents a comparative evaluation of reorderings with the original and the head-finalized representations. The impact of the reordering on the quality of translation. is measured through the BLEU score in phrase-based statistical systems and neural machine translation systems. A significant gain in BLEU score was noted for reorderings in different grammatical constructs.
SN 2375-4699
EI 2375-4702
PD JUL
PY 2021
VL 20
IS 4
AR 69
DI 10.1145/3448252
UT WOS:000721582900016
ER

PT C
AU Sun, HP
   Wang, R
   Chen, KH
   Utiyama, MS
   Sumita, ECRO
   Zhao, TJ
AF Sun, Haipeng
   Wang, Rui
   Chen, Kehai
   Utiyama, Masao
   Sumita, Eiichiro
   Zhao, Tiejun
GP Assoc Computat Linguist
TI Knowledge Distillation for Multilingual Unsupervised Neural Machine
   Translation
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB Unsupervised neural machine translation (UNMT) has recently achieved remarkable results for several language pairs. However, it can only translate between a single language pair and cannot produce translation results for multiple language pairs at the same time. That is, research on multilingual UNMT has been limited. In this paper, we empirically introduce a simple method to translate between thirteen languages using a single encoder and a single decoder, making use of multilingual data to improve UNMT for all language pairs. On the basis of the empirical findings, we propose two knowledge distillation methods to further enhance multilingual UNMT performance. Our experiments on a dataset with English translated to and from twelve other languages (including three language families and six language branches) show remarkable results, surpassing strong unsupervised individual baselines while achieving promising performance between non-English language pairs in zero-shot translation scenarios and alleviating poor performance in low-resource language pairs.
RI Chen, Kehai/ABF-1874-2020
BN 978-1-952148-25-5
PY 2020
BP 3525
EP 3535
UT WOS:000570978203084
ER

PT C
AU Ataman, D
   Federico, M
AF Ataman, Duygu
   Federico, Marcello
BE Gurevych, I
   Miyao, Y
TI Compositional Representation of Morphologically-Rich Input for Neural
   Machine Translation
SO PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS, VOL 2
CT 56th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 15-20, 2018
CL Melbourne, AUSTRALIA
SP Assoc Computat Linguist, Google, ByteDance, Samsung Res, Apple, Facebook, Amazon, Baidu, Recruit Inst Technol, Tencent, IBM Res AI, Microsoft, Naver, Line, CVTE, Digital Hlth crc, Nuance, Huawei, Elsevier, Duolingo, ISI NLP, Australian Govt, Dept Def, Sci & Technol, NYU, Kaggle, Zendesk
AB Neural machine translation (NMT) models are typically trained with fixed-size input and output vocabularies, which creates an important bottleneck on their accuracy and generalization capability. As a solution, various studies proposed segmenting words into sub-word units and performing translation at the sub-lexical level. However, statistical word segmentation methods have recently shown to be prone to morphological errors, which can lead to inaccurate translations. In this paper, we propose to overcome this problem by replacing the source-language embedding layer of NMT with a bi-directional recurrent neural network that generates compositional representations of the input at any desired level of granularity. We test our approach in a low-resource setting with five languages from different morphological typologies, and under different composition assumptions. By training NMT to compose word representations from character trigrams, our approach consistently outperforms (from 1.71 to 2.48 BLEU points) NMT learning embeddings of statistically generated sub-word units.
BN 978-1-948087-34-6
PY 2018
BP 305
EP 311
UT WOS:000493913100049
ER

PT J
AU Shi, CC
   Xiang, Y
   Yu, JS
   Sood, K
   Gao, LX
AF Shi, Chaochen
   Xiang, Yong
   Yu, Jiangshan
   Sood, Keshav
   Gao, Longxiang
TI Machine translation-based fine-grained comments generation for solidity
   smart contracts
SO INFORMATION AND SOFTWARE TECHNOLOGY
AB Context. As self-executing programs on blockchain platforms, smart contracts can build a trusted environment between multi-parties. However, participants who lack programming knowledge usually have difficulties understanding smart contracts by reading the source code. It brings them difficulties and risks when interacting with decentralized applications. Objective. We aim to translate the smart contract source code into natural language descriptions as fine-grained in-line comments to help people better understand, learn and operate smart contracts. Method. We propose an automated translation approach for smart contracts written in Solidity, termed SolcTrans, based on an Syntax Tree (AST) and formal grammar. We have investigated representative Solidity smart contracts, identified the AST parsing paths and core attributes used for translation, and proposed corresponding translation templates for special statements. Then, we leveraged reinforcement learning to train a Probabilistic Context-Free Grammar-based syntax synthesizer used to generate comprehensible English sentences as comments. Result. The experimental results show that SolcTrans outperforms four state-of-the-art neural machine trans-lation models under currently available training data and is less affected by lengths of code snippets and translation outputs. We also conducted a human evaluation among 20 volunteers and asked them to score the generated comments. The results demonstrate that SolcTrans performs well on three metrics: Accuracy, Readability, and Instructiveness. Conclusion. Our approach produces high-quality fine-grained comments for smart contract source code under the small training dataset, which creates a paradigm for future studies.
OI Shi, Chaochen/0000-0002-5543-1655
SN 0950-5849
EI 1873-6025
PD JAN
PY 2023
VL 153
AR 107065
DI 10.1016/j.infsof.2022.107065
UT WOS:000870873400002
ER

PT J
AU Haque, R
   Penkale, S
   Way, A
AF Haque, Rejwanul
   Penkale, Sergio
   Way, Andy
TI TermFinder: log-likelihood comparison and phrase-based statistical
   machine translation models for bilingual terminology extraction
SO LANGUAGE RESOURCES AND EVALUATION
AB Bilingual termbanks are important for many natural language processing applications, especially in translation workflows in industrial settings. In this paper, we apply a log-likelihood comparison method to extract monolingual terminology from the source and target sides of a parallel corpus. The initial candidate terminology list is prepared by taking all arbitrary n-gram word sequences from the corpus. Then, a well-known statistical measure (the Dice coefficient) is employed in order to remove any multi-word terms with weak associations from the candidate term list. Thereafter, the log-likelihood comparison method is applied to rank the phrasal candidate term list. Then, using a phrase-based statistical machine translation model, we create a bilingual terminology with the extracted monolingual term lists. We integrate an external knowledge source-the Wikipedia cross-language link databases-into the terminology extraction (TE) model to assist two processes: (a) the ranking of the extracted terminology list, and (b) the selection of appropriate target terms for a source term. First, we report the performance of our monolingual TE model compared to a number of the state-of-the-art TE models on English-to-Turkish and English-to-Hindi data sets. Then, we evaluate our novel bilingual TE model on an English-to-Turkish data set, and report the automatic evaluation results. We also manually evaluate our novel TE model on English-to-Spanish and English-to-Hindi data sets, and observe excellent performance for all domains.
RI Haque, Rejwanul/C-4581-2017
OI Haque, Rejwanul/0000-0003-1680-0099; Way, Andy/0000-0001-5736-5930
SN 1574-020X
EI 1574-0218
PD JUN
PY 2018
VL 52
IS 2
BP 365
EP 400
DI 10.1007/s10579-018-9412-4
UT WOS:000432144400001
ER

PT C
AU Zhang, JY
   Utiyama, M
   Sumita, E
   Neubig, G
   Nakamura, S
AF Zhang, Jingyi
   Utiyama, Masao
   Sumita, Eiichro
   Neubig, Graham
   Nakamura, Satoshi
BE Erk, K
   Smith, NA
TI A Continuous Space Rule Selection Model for Syntax-based Statistical
   Machine Translation
SO PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS, VOL 1
CT 54th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY AUG 07-12, 2016
CL Berlin, GERMANY
SP Assoc Computat Linguist, Google, Baidu, Amazon Com, Bloomberg, Facebook, Microsoft Res, eBay, Elsevier, IBM Res, MaluubA, Huawei Technologies, Nuance, Grammarly, VoiceBox Technologies, Yandex, Textkernel, Zalando SE
AB One of the major challenges for statistical machine translation (SMT) is to choose the appropriate translation rules based on the sentence context. This paper proposes a continuous space rule selection (CSRS) model for syntax-based SMT to perform this context-dependent rule selection. In contrast to existing maximum entropy based rule selection (MERS) models, which use discrete representations of words as features, the CSRS model is learned by a feed-forward neural network and uses real-valued vector representations of words, allowing for better generalization. In addition, we propose a method to train the rule selection models only on minimal rules, which are more frequent and have richer training data compared to non-minimal rules. We tested our model on different translation tasks and the CSRS model outperformed a baseline without rule selection and the previous MERS model by up to 2.2 and 1.1 points of BLEU score respectively.
BN 978-1-945626-00-5
PY 2016
BP 1372
EP 1381
UT WOS:000493806800130
ER

PT C
AU Li, G
   Liu, L
   Li, X
   Zhu, C
   Zhao, T
   Shi, S
AF Li, Guanlin
   Liu, Lemao
   Li, Xintong
   Zhu, Conghui
   Zhao, Tiejun
   Shi, Shuming
GP Assoc Computat Linguist
TI Understanding and Improving Hidden Representation for Neural Machine
   Translation
SO 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019),
   VOL. 1
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 02-07, 2019
CL Minneapolis, MN
SP Assoc Computat Linguist, N Amer Chapter, Comp Res Assoc, Comp Community Consortium, Natl Sci Fdn, Natl Rees Council Canada, Google
AB Multilayer architectures are currently the gold standard for large-scale neural machine translation. Existing works have explored some methods for understanding the hidden representations, however, they have not sought to improve the translation quality rationally according to their understanding. Towards understanding for performance improvement, we first artificially construct a sequence of nested relative tasks and measure the feature generalization ability of the learned hidden representation over these tasks. Based on our understanding, we then propose to regularize the layer-wise representations with all treeinduced tasks. To overcome the computational bottleneck resulting from the large number of regularization terms, we design efficient approximation methods by selecting a few coarse-to-fine tasks for regularization. Extensive experiments on two widely-used datasets demonstrate the proposed methods only lead to small extra overheads in training but no additional overheads in testing, and achieve consistent improvements (up to +1.3 BLEU) compared to the state-of-the-art translation model.
BN 978-1-950737-13-0
PY 2019
BP 466
EP 477
UT WOS:000900116900046
ER

PT C
AU Schwarzenberg, R
   Harbecke, D
   Macketanz, V
   Avramidis, E
   Moller, S
AF Schwarzenberg, Robert
   Harbecke, David
   Macketanz, Vivien
   Avramidis, Eleftherios
   Moeller, Sebastian
GP ASSOC COMPUTAT LINGUIST
TI Train, Sort, Explain: Learning to Diagnose Translation Models
SO NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE
   ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES:
   PROCEEDINGS OF THE DEMONSTRATIONS SESSION
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 02-07, 2019
CL Minneapolis, MN
SP Assoc Computat Linguist, N Amer Chapter, Comp Res Assoc, Comp Community Consortium, Natl Sci Fdn, Natl Rees Council Canada, Google
AB Evaluating translation models is a trade-off between effort and detail. On the one end of the spectrum there are automatic count-based methods such as BLEU, on the other end linguistic evaluations by humans, which arguably are more informative but also require a disproportionately high effort. To narrow the spectrum, we propose a general approach on how to automatically expose systematic differences between human and machine translations to human experts. Inspired by adversarial settings, we train a neural text classifier to distinguish human from machine translations. A classifier that performs and generalizes well after training should recognize systematic differences between the two classes, which we uncover with neural explainability methods. Our proof-of-concept implementation, DiaMaT, is open source. Applied to a dataset translated by a state-of-the-art neural Transformer model, DiaMaT achieves a classification accuracy of 75% and exposes meaningful differences between humans and the Transformer, amidst the current discussion about human parity.
RI Avramidis, Eleftherios/AEP-2451-2022
OI Avramidis, Eleftherios/0000-0002-5671-573X
BN 978-1-950737-16-1
PY 2019
BP 29
EP 34
UT WOS:000860933000006
ER

PT C
AU Wieting, J
   Berg-Kirkpatrick, T
   Gimpel, K
   Neubig, G
AF Wieting, John
   Berg-Kirkpatrick, Taylor
   Gimpel, Kevin
   Neubig, Graham
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Beyond BLEU: Training Neural Machine Translation with Semantic
   Similarity
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB While most neural machine translation (NMT) systems are still trained using maximum likelihood estimation, recent work has demonstrated that optimizing systems to directly improve evaluation metrics such as BLEU can substantially improve final translation accuracy. However, training with BLEU has some limitations: it doesn't assign partial credit, it has a limited range of output values, and it can penalize semantically correct hypotheses if they differ lexically from the reference. In this paper, we introduce an alternative reward function for optimizing NMT systems that is based on recent work in semantic similarity. We evaluate on four disparate languages translated to English, and find that training with our proposed metric results in better translations as evaluated by BLEU, semantic similarity, and human evaluation, and also that the optimization procedure converges faster. Analysis suggests that this is because the proposed metric is more conducive to optimization, assigning partial credit and providing more diversity in scores than BLEU.(1)
BN 978-1-950737-48-2
PY 2019
BP 4344
EP 4355
UT WOS:000493046106086
ER

PT J
AU Ruan, ZW
   Ji, RR
AF Ruan, Zhiwei
   Ji, Rongrong
TI Topically-informed bilingually-constrained recursive autoencoders for
   statistical machine translation
SO COMMUNICATIONS IN INFORMATION AND SYSTEMS
AB Learning high-quality phrase vector representations is one of important research topics in statistical machine translation (SMT). Towards phrase embeddings, most existing works mainly explore syntactic and semantic clues among internal words within phrases, which are however insufficient for representation learning due to the lack of context information. In this paper, we propose topically informed bilingually-constrained recursive autoencoders for SMT, which substantially extends the conventional bilingually constrained recursive autoencoders by exploiting latent topics in two ways. First, we introduce topical contexts to induce topical phrase embeddings. Second, word topic assignments from a latent topic model are leveraged to constrain the learning of word and topic embeddings, both of which form the base of the contextual phrase embedding learning in the proposed model. Experiment results on Chinese-English translation show that the proposed model significantly improves the translation quality on NIST test sets.
SN 1526-7555
EI 2163-4548
PY 2018
VL 18
IS 1
BP 53
EP 72
UT WOS:000434452900003
ER

PT C
AU Unanue, IJ
   Parnell, J
   Piccardi, M
AF Unanue, Inigo Jauregi
   Parnell, Jacob
   Piccardi, Massimo
GP Assoc Computat Linguist
TI BERTTune: Fine-Tuning Neural Machine Translation with BERTScore
SO ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON
   NATURAL LANGUAGE PROCESSING, VOL 2
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB Neural machine translation models are often biased toward the limited translation references seen during training. To amend this form of overfitting, in this paper we propose fine-tuning the models with a novel training objective based on the recently-proposed BERTScore evaluation metric. BERTScore is a scoring function based on contextual embeddings that overcomes the typical limitations of n-gram-based metrics (e.g. synonyms, paraphrases), allowing translations that are different from the references, yet close in the contextual embedding space, to be treated as substantially correct. To be able to use BERTScore as a training objective, we propose three approaches for generating soft predictions, allowing the network to remain completely differentiable end-to-end. Experiments carried out over four, diverse language pairs have achieved improvements of up to 0:58 pp (3:28%) in BLEU score and up to 0:76 pp (0:98%) in BERTScore (FBERT) when fine-tuning a strong baseline.
OI Piccardi, Massimo/0000-0001-9250-6604
BN 978-1-954085-53-4
PY 2021
BP 915
EP 924
UT WOS:000694699200115
ER

PT J
AU ARONSON, A
AF ARONSON, A
TI THE THEATRICAL WRITINGS OF MOTTA,FABRIZIO,CARINI TRANSLATIONS OF
   'TRATTATO SOPRA LA STRUTTURA DE THEATRI E SCENE', 1676 AND 'CONSTRUZIONE
   DE TEATRI E MACHINE TEATRALI', 1688 - LARSON,OK
SO THEATRE JOURNAL
SN 0192-2882
PD MAY
PY 1989
VL 41
IS 2
BP 256
EP 257
UT WOS:A1989U510000025
ER

PT J
AU Grandy, CA
   Donnan, JR
   Peddle, JT
   Romme, K
   Kim, S
   Gamble, JM
AF Grandy, Catherine Anne
   Donnan, Jennifer R.
   Peddle, Justin T.
   Romme, Kristen
   Kim, Satpyul
   Gamble, John-Michael
TI A systematic assessment of the availability and clinical drug
   information coverage of machine-readable clinical drug data sources for
   building knowledge translation products (vol 25, pg 1240, 2018)
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
RI Romme, Kristen/AAB-9037-2019
OI Romme, Kristen/0000-0003-1859-1913
SN 1067-5027
EI 1527-974X
PD JAN
PY 2019
VL 26
IS 1
BP 91
EP 91
DI 10.1093/jamia/ocy141
UT WOS:000461520100015
ER

PT C
AU Hu, JJ
   Xia, MZ
   Neubig, G
   Carbonell, J
AF Hu, Junjie
   Xia, Mengzhou
   Neubig, Graham
   Carbonell, Jaime
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Domain Adaptation of Neural Machine Translation by Lexicon Induction
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB It has been previously noted that neural machine translation (NMT) is very sensitive to domain shift. In this paper, we argue that this is a dual effect of the highly lexicalized nature of NMT, resulting in failure for sentences with large numbers of unknown words, and lack of supervision for domain-specific words. To remedy this problem, we propose an unsupervised adaptation method which fine-tunes a pre-trained out-of-domain NMT model using a pseudo-in-domain corpus. Specifically, we perform lexicon induction to extract an in-domain lexicon, and construct a pseudo-parallel in-domain corpus by performing word-for-word back-translation of monolingual in-domain target sentences. In five domains over twenty pairwise adaptation settings and two model architectures, our method achieves consistent improvements without using any in-domain parallel sentences, improving up to 14 BLEU over unadapted models, and up to 2 BLEU over strong back-translation baselines.
RI Hu, Junjie/P-1397-2018
OI Hu, Junjie/0000-0001-8909-3319
BN 978-1-950737-48-2
PY 2019
BP 2989
EP 3001
UT WOS:000493046104047
ER

PT C
AU Imada, K
   Nakamura, K
AF Imada, Keita
   Nakamura, Katsuhiko
BE Daelemans, W
   Goethals, B
   Morik, K
TI Towards Machine Learning of Grammars and Compilers of Programming
   Languages
SO MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, PART II,
   PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
CT European Conference on Principles of Data Mining and Knowledge Discovery
CY SEP 15-19, 2008
CL Antwerp, BELGIUM
SP Univ Antwerp, Computat Linguist Flanders, Google, hp, VADIS, COGNOS, European Off Aerosp, SPSS, textkernel, Data Mining & Knowledge Discovery, IBM, Machine Learning
AB This paper discusses machine learning of grammars and compilers of programming languages from samples of translation from source programs into object codes. This work is an application of incremental learning of definite clause grammars (DCGs) and syntax directed translation schema (SDTS), which is implemented in the Synapse system. The main experimental result is that Synapse synthesized a set of SDTS rules for translating extended arithmetic expressions with function calls and assignment operators into object codes from positive and negative samples of the translation. The object language is a simple intermediate language based on inverse Polish notation. These rules contain an unambiguous context free grammar for the extended arithmetic expressions, which specifies the precedence and associativity of the operators. This approach can be used for designing and implementing a new programming language by giving the syntax and semantics in the form of the samples of the translation.
SN 0302-9743
EI 1611-3349
BN 978-3-540-87480-5
PY 2008
VL 5212
BP 98
EP 112
PN II
UT WOS:000260075900007
ER

PT C
AU Li, ZC
   Wang, R
   Chen, KH
   Utiyama, M
   Sumita, E
   Zhang, ZS
   Zhao, H
AF Li, Zuchao
   Wang, Rui
   Chen, Kehai
   Utiyama, Masao
   Sumita, Eiichiro
   Zhang, Zhuosheng
   Zhao, Hai
GP Assoc Advancement Artificial Intelligence
TI Explicit Sentence Compression for Neural Machine Translation
SO THIRTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THE
   THIRTY-SECOND INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE
   CONFERENCE AND THE TENTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN
   ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 34th AAAI Conference on Artificial Intelligence / 32nd Innovative
   Applications of Artificial Intelligence Conference / 10th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 07-12, 2020
CL New York, NY
SP Assoc Advancement Artificial Intelligence
AB State-of-the-art Transformer-based neural machine translation (NMT) systems still follow a standard encoder-decoder framework, in which source sentence representation can be well done by an encoder with self-attention mechanism. Though Transformer-based encoder may effectively capture general information in its resulting source sentence representation, the backbone information, which stands for the gist of a sentence, is not specifically focused on. In this paper, we propose an explicit sentence compression method to enhance the source sentence representation for NMT. In practice, an explicit sentence compression goal used to learn the backbone information in a sentence. We propose three ways, including backbone source-side fusion, target-side fusion, and both-side fusion, to integrate the compressed sentence into NMT. Our empirical tests on the WMT English-to-French and English-to-German translation tasks show that the proposed sentence compression method significantly improves the translation performances over strong baselines.
RI Zhang, Zhuosheng/AAF-4919-2020
SN 2159-5399
EI 2374-3468
BN 978-1-57735-835-0
PY 2020
VL 34
BP 8311
EP 8318
UT WOS:000668126800084
ER

PT C
AU Yang, Z
   Chen, LF
   Nguyen, ML
AF Yang, Zhen
   Chen, Laifu
   Minh Le Nguyen
BE Phuong, TM
   LeNguyen, M
   Chau, NM
TI Regularizing Forward and Backward Decoding to Improve Neural Machine
   Translation
SO PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND
   SYSTEMS ENGINEERING (KSE)
SE International Conference on Knowledge and Systems Engineering
CT 10th International Conference on Knowledge and Systems Engineering (KSE)
CY NOV 01-03, 2018
CL Ho Chi Minh City, VIETNAM
SP IEEE, IEEE Vietnam Sect, PTIT, Natl Fdn Sci & Technol Dev, Japan Adv Inst Sci & Technol, STARS, FPT Univ, FPT TECH, VCCorp
AB The common recurrent neural network (RNN) based sequential decoder of the neural machine translation (NMT) model can only translate from one direction, which makes the model overfit in the forward direction and leaves backward information of target sentences unexploited. We propose to use a regularization loss to encourage NMT decoder to exploit bidirectional information of target sentences. Beside of forward decoding, we train an extra set of decoding components to predict translation from backward, and use regularization to enforce the forward and backward hidden states at the same time step have connection. During training phase, the forward hidden states can encode future information from the backward hidden states; while during test phase, we only use the enhanced forward decoding components to translate. Our empirical experiments demonstrated that our approach can significantly improve the performance on WMT German-English and English-Chinese translation tasks in terms of NIST and BLEU score.
SN 2164-2508
BN 978-1-5386-6113-0
PY 2018
BP 73
EP 78
UT WOS:000459847600014
ER

PT J
AU Grandy, CA
   Donnan, JR
   Peddle, JT
   Romme, K
   Kim, S
   Gamble, JM
AF Grandy, Catherine Anne
   Donnan, Jennifer R.
   Peddle, Justin T.
   Romme, Kristen
   Kim, Satpyul
   Gamble, John-Michael
TI A systematic assessment of the availability and clinical drug
   information coverage of machine-readable clinical drug data sources for
   building knowledge translation products
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
AB Objective: To identify and describe clinical drug data sources that have the potential to serve as a repository of information for developing drug knowledge translation products.
   Methods: Two reviewers independently screened citations from PubMed and Embase, websites from the web search engine Google, and references from selected journals. Publicly licensed or non-proprietary data sources containing clinical drug information accessible in a machine-readable format were eligible. Data sources were assessed for their coverage across 18 pre-specified domains and 74 elements of clinical drug information.
   Results: Of the 3369 unique citations or webpages screened, 44 drug information data sources were identified. Of these, 22 data sources met the study inclusion criteria. There was a mean of 4.5 (SD = 5.19) domains covered by each source and a mean of 10.9 (SD = 18) elements covered by each source. None of the data sources covered all domains and eight elements were not addressed by any source. All of the data sources identified by the study are government or academic databases.
   Conclusion: Our study demonstrated the availability of machine-readable clinical drug data that could help facilitate the creation of novel drug knowledge translation products. However, we identified clinical content gaps in the available non-proprietary drug information sources. Further evaluation of the quality of each data source would be necessary prior to incorporating these sources into any knowledge translation products intended for clinical use.
RI Romme, Kristen/AAB-9037-2019
OI Romme, Kristen/0000-0003-1859-1913; Gamble,
   John-Michael/0000-0001-6891-8721
SN 1067-5027
EI 1527-974X
PD SEP
PY 2018
VL 25
IS 9
BP 1240
EP 1247
DI 10.1093/jamia/ocy074
UT WOS:000443542400019
PM 29982512
ER

PT C
AU Gu, SH
   Feng, Y
   Liu, Q
AF Gu, Shuhao
   Feng, Yang
   Liu, Qun
GP Assoc Computat Linguist
TI Improving Domain Adaptation Translation with Domain Invariant and
   Specific Information
SO 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019),
   VOL. 1
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 02-07, 2019
CL Minneapolis, MN
SP Assoc Computat Linguist, N Amer Chapter, Comp Res Assoc, Comp Community Consortium, Natl Sci Fdn, Natl Rees Council Canada, Google
AB In domain adaptation for neural machine translation, translation performance can benefit from separating features into domain-specific features and common features. In this paper, we propose a method to explicitly model the two kinds of information in the encoderdecoder framework so as to exploit out-ofdomain data in in-domain training. In our method, we maintain a private encoder and a private decoder for each domain which are used to model domain-specific information. In the meantime, we introduce a common encoder and a common decoder shared by all the domains which can only have domainindependent information flow through. Besides, we add a discriminator to the shared encoder and employ adversarial training for the whole model to reinforce the performance of information separation and machine translation simultaneously. Experiment results show that our method can outperform competitive baselines greatly on multiple data sets.
BN 978-1-950737-13-0
PY 2019
BP 3081
EP 3091
UT WOS:000900116903016
ER

PT C
AU Stuker, S
   Besacier, L
   Waibel, A
AF Stueker, Sebastian
   Besacier, Laurent
   Waibel, Alex
GP ISCA-INST SPEECH COMMUN ASSOC
TI Human Translations Guided Language Discovery for ASR Systems
SO INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH
   COMMUNICATION ASSOCIATION 2009, VOLS 1-5
CT 10th INTERSPEECH 2009 Conference
CY SEP 06-10, 2009
CL Brighton, ENGLAND
SP Int Speech Commun Assoc
AB The traditional approach of collecting and annotating the necessary training data is due to economic constraints not feasible for most of the 7,000 languages in the world. At the same time it is of vital interest to have natural language processing systems address practically all of them. Therefore, new, efficient ways of gathering the needed training material have to be found. In this paper we continue our experiments on exploiting the knowledge gained from human simultaneous translations that happen frequently in the real world, in order to discover word units in a new language. We evaluate our approach by measuring the performance of statistical machine translation systems trained on the word units discovered from an oracle phoneme sequence. We improve it then by combining it with a word discovery technique that works without supervision, solely on the unsegmented phoneme sequences.
BN 978-1-61567-692-7
PY 2009
BP 2991
EP +
UT WOS:000276842801289
ER

PT J
AU Gregg, D
   Beatty, A
   Casey, K
   Davis, B
   Nisbet, A
AF Gregg, D
   Beatty, A
   Casey, K
   Davis, B
   Nisbet, A
TI The case for virtual register machines
SO SCIENCE OF COMPUTER PROGRAMMING
CT 1st Workshop on Interpreters, Virtual Machines and Emulators (IVME 03)
CY JUN 12, 2003
CL San Diego, CA
AB Virtual machines (VMs) are a popular target for language implementers. A long-running question in the design of virtual machines has been whether stack or register architectures can be implemented more efficiently with an interpreter. Many designers favour stack architectures since the location of operands is implicit in the stack pointer. In contrast, the operands of register machine instructions must be specified explicitly. In this paper, we present a working system for translating stack-based Java virtual machine (JVM) code to a simple register code. We describe the translation process, the complicated parts of the JVM which make translation more difficult, and the optimisations needed to eliminate copy instructions. Experimental results show that a register format reduced the number of executed instructions by 34.88%, while increasing the number of bytecode loads by an average of 44.81%. Overall, this corresponds to an increase of 2.32 loads for each dispatch removed. We believe that the high cost of dispatches makes register machines attractive even at the cost of increased loads. (c) 2005 Elsevier B.V. All rights reserved.
OI Davis, Brian/0000-0002-5759-2655
SN 0167-6423
EI 1872-7964
PD SEP
PY 2005
VL 57
IS 3
BP 319
EP 338
DI 10.1016/j.scico.2004.08.005
UT WOS:000231409800005
ER

PT C
AU Maroof, MKH
   Alam, L
   Hoque, MM
AF Maroof, Mohammad Kamrul Huq
   Alam, Lamia
   Hoque, Mohammed Moshiul
GP IEEE
TI Transformational Generative Grammar (TGG): An Efficient Way of Parsing
   Bangla Sentences
SO 2016 2ND INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER &
   TELECOMMUNICATION ENGINEERING (ICECTE)
CT 2nd International Conference on Electrical, Computer & Telecommunication
   Engineering (ICECTE)
CY DEC 08-10, 2016
CL Rajshahi Univ Engn & Technol, Rajshahi, BANGLADESH
SP Rajshahi Univ Engn & Technol, Fac Elect & Comp Engn, IEEE Bangladesh Sect, Dhaka Power Distribut Co Ltd, Walton, Energypac
HO Rajshahi Univ Engn & Technol
AB Natural language processing (NLP) refers to the ability of systems to process sentences in a natural language such as Bangla, rather than in a specialized artificial computer language. Computer processing of Bangla language is a challenging task due to its varieties of words formation and way of speaking. The same meaning can be expressed in different ways which is a great challenge to face for translation by an automatic machine translation system. With the advent of internet technology and e-commerce, the demand of automatic machine translation has been increased. Parsing is essential for any type of natural language processing. Parsing of Bangla natural language can be used as a subsystem for Bangla to another language machine aided translation. A parser usually checks the validity of a sentence using grammatical rule. In this paper, we propose a set of transformational generative grammar (TGG) in conjunction with phrase structure grammar to generate parse tree and to recognize assertive, interrogative, imperative, optative and exclamatory sentences of Bangla language. It is applicable for many sentences that cannot be parsed using only phrase structure grammars. The process involves analysis of Bangla sentence morphologically, syntactically where tokens and grammatical information are passed through parsing stage and finally output can be achieved. A dictionary of lexicon is used which contains some syntactic, semantic, and possibly some pragmatic information. We have tested our system for different kinds of Bangla sentences and experimental result reveals that the overall success rate of the proposed system is 84.4%.
RI Hoque, Mohammed Moshiul/AAC-8902-2021
OI Hoque, Mohammed Moshiul/0000-0001-8806-708X
BN 978-1-5090-5785-6
PY 2016
UT WOS:000405571300023
ER

PT C
AU Miculicich, L
   Dhananjay, R
   Pappas, N
   Henderson, J
AF Miculicich, Lesly
   Dhananjay, Ram
   Pappas, Nikolaos
   Henderson, James
GP Assoc Computat Linguist
TI Document-Level Neural Machine Translation with Hierarchical Attention
   Networks
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB Neural Machine Translation (NMT) can be improved by including document-level contextual information. For this purpose, we propose a hierarchical attention model to capture the context in a structured and dynamic manner. The model is integrated in the original NMT architecture as another level of abstraction, conditioning on the NMT model's own previous hidden states. Experiments show that hierarchical attention significantly improves the BLEU score over a strong NMT baseline with the state-of-the-art in context-aware methods, and that both the encoder and decoder benefit from context in complementary ways.
BN 978-1-948087-84-1
PY 2018
BP 2947
EP 2954
UT WOS:000865723403014
ER

PT C
AU Xu, MH
   Hong, Y
AF Xu, Minhan
   Hong, Yu
GP Assoc Computa Linguist
TI Sub-Word Alignment is Still Useful: A Vest-Pocket Method for Enhancing
   Low-Resource Machine Translation
SO PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB We leverage embedding duplication between aligned sub-words to extend the Parent-Child transfer learning method, so as to improve low-resource machine translation. We conduct experiments on benchmark datasets of My -> En, Id!En and Tr!En translation scenarios. The test results show that our method produces substantial improvements, achieving the BLEU scores of 22.5, 28.0 and 18.1 respectively. In addition, the method is computationally efficient which reduces the consumption of training time by 63.8%, reaching the duration of 1.6 hours when training on a Tesla 16GB P100 GPU. All the models and source codes in the experiments will be made publicly available to support reproducible research.
BN 978-1-955917-22-3
PY 2022
BP 613
EP 619
UT WOS:000828732800068
ER

PT C
AU Roberts, W
   Egg, M
AF Roberts, Will
   Egg, Markus
BA Declerck, T
BF Declerck, T
BE Calzolari, N
   Choukri, K
   Cieri, C
   Hasida, K
   Isahara, H
   Maegaard, B
   Mariani, J
   Moreno, A
   Odijk, J
   Piperidis, S
   Tokunaga, T
   Goggi, S
   Mazo, H
TI A Large Automatically-Acquired All-Words List of Multiword Expressions
   Scored for Compositionality
SO PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE
   RESOURCES AND EVALUATION (LREC 2018)
CT 11th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 07-12, 2018
CL Miyazaki, JAPAN
AB We present and make available a large automatically-acquired all-words list of English multiword expressions scored for compositionality. Intrinsic evaluation against manually-produced gold standards demonstrates that our compositionality estimates are sound, and extrinsic evaluation via incorporation of our list into a machine translation system to better handle idiomatic expressions results in a statistically significant improvement to the system's BLEU scores. As the method used to produce the list is language-independent, we also make available lists in seven other European languages.
BN 979-10-95546-00-9
PY 2018
BP 304
EP 310
UT WOS:000725545000046
ER

PT C
AU Logacheva, V
   Lukasik, M
   Specia, L
AF Logacheva, Varvara
   Lukasik, Michal
   Specia, Lucia
BE Erk, K
   Smith, NA
TI Metrics for Evaluation of Word-Level Machine Translation Quality
   Estimation
SO PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2
CT 54th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY AUG 07-12, 2016
CL Berlin, GERMANY
SP Assoc Computat Linguist, Google, Baidu, Amazon Com, Bloomberg, Facebook, Microsoft Res, eBay, Elsevier, IBM Res, MaluubA, Huawei Technologies, Nuance, Grammarly, VoiceBox Technologies, Yandex, Textkernel, Zalando SE
AB The aim of this paper is to investigate suitable evaluation strategies for the task of word-level quality estimation of machine translation. We suggest various metrics to replace F-1-score for the "BAD" class, which is currently used as main metric. We compare the metrics' performance on real system outputs and synthetically generated datasets and suggest a reliable alternative to the F-1-BAD score - the multiplication of F-1-scores for different classes. Other metrics have lower discriminative power and are biased by unfair labellings.
OI Specia, Lucia/0000-0002-5495-3128
BN 978-1-945626-01-2
PY 2016
BP 585
EP 590
UT WOS:000493805000095
ER

PT C
AU Imamura, K
   Fujita, A
   Sumita, E
AF Imamura, Kenji
   Fujita, Atsushi
   Sumita, Eiichiro
GP Assoc Computat Linguist
TI Enhancement of Encoder and Attention Using Target Monolingual Corpora in
   Neural Machine Translation
SO NEURAL MACHINE TRANSLATION AND GENERATION
CT 2nd Workshop on Neural Machine Translation and Generation
CY JUL 20, 2018
CL Melbourne, AUSTRALIA
SP Amazon, Apple, Google
AB A large-scale parallel corpus is required to train encoder-decoder neural machine translation. The method of using synthetic parallel texts, in which target monolingual corpora are automatically translated into source sentences, is effective in improving the decoder, but is unreliable for enhancing the encoder. In this paper, we propose a method that enhances the encoder and attention using target monolingual corpora by generating multiple source sentences via sampling. By using multiple source sentences, diversity close to that of humans is achieved. Our experimental results show that the translation quality is improved by increasing the number of synthetic source sentences for each given target sentence, and quality close to that using a manually created parallel corpus was achieved.
BN 978-1-948087-40-7
PY 2018
BP 55
EP 63
UT WOS:000538330600008
ER

PT S
AU Tambouratzis, G
   Sofianopoulos, S
   Spilioti, V
   Vassiliou, M
   Yannoutsou, O
   Markantonatou, S
AF Tambouratzis, George
   Sofianopoulos, Sokratis
   Spilioti, Vassiliki
   Vassiliou, Marina
   Yannoutsou, Olga
   Markantonatou, Stella
BE Antoniou, G
   Potamias, G
   Spyropoulos, C
   Plexousakis, D
TI Pattern matching based system for machine translation (MT)
SO ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS
SE Lecture Notes in Computer Science
CT 4th Hellenic Conference on Artificial Intelligence
CY MAY 18-20, 2006
CL Univ Crete, Heraklion, GREECE
SP EETN
HO Univ Crete
AB The innovative feature of the system presented in this paper is the use of pattern-matching techniques to retrieve translations resulting in a flexible, language-independent approach, which employs a limited amount of explicit a priori linguistic knowledge. Furthering, while all state-of-the-art corpus-based approaches to Machine Translation (MT) rely on bitexts, this system relies on extensive target language monolingual corpora. The translation process distinguishes three phases: 1) pre-processing with 'light' rule and statistics-based NLP techniques 2) search & retrieval, 3) synthesising. At Phase 1, the source language sentence is mapped onto a lemma-to-lemma translated string. This string then forms till, input to fie search algorithm, which retrieves similar sentences from the corpus (Phase 2) This retrieval process is performed iteratively at increasing levels of detail. until the best match is detected. The best retrieved sentence is sent to the synthesising algorithm (Phase 3), which handles phenomena such as agreement.
OI Tambouratzis, George/0000-0002-8356-0227
SN 0302-9743
EI 1611-3349
BN 3-540-34117-X
PY 2006
VL 3955
BP 345
EP 355
UT WOS:000238053100033
ER

PT J
AU Engelfriet, J
   Inaba, K
   Maneth, S
AF Engelfriet, Joost
   Inaba, Kazuhiro
   Maneth, Sebastian
TI Linear-bounded composition of tree-walking tree transducers: linear size
   increase and complexity
SO ACTA INFORMATICA
AB Compositions of tree-walking tree transducers form a hierarchy with respect to the number of transducers in the composition. As main technical result it is proved that any such composition can be realized as a linear-bounded composition, which means that the sizes of the intermediate results can be chosen to be at most linear in the size of the output tree. This has consequences for the expressiveness and complexity of the translations in the hierarchy. First, if the computed translation is a function of linear size increase, i.e., the size of the output tree is at most linear in the size of the input tree, then it can be realized by just one, deterministic, tree-walking tree transducer. For compositions of deterministic transducers it is decidable whether or not the translation is of linear size increase. Second, every composition of deterministic transducers can be computed in deterministic linear time on a RAM and in deterministic linear space on a Turing machine, measured in the sum of the sizes of the input and output tree. Similarly, every composition of nondeterministic transducers can be computed in simultaneous polynomial time and linear space on a nondeterministic Turing machine. Their output tree languages are deterministic context-sensitive, i.e., can be recognized in deterministic linear space on a Turing machine. The membership problem for compositions of nondeterministic translations is nondeterministic polynomial time and deterministic linear space. All the above results also hold for compositions of macro tree transducers. The membership problem for the composition of a nondeterministic and a deterministic tree-walking tree translation (for a nondeterministic IO macro tree translation) is log-space reducible to a context-free language, whereas the membership problem for the composition of a deterministic and a nondeterministic tree-walking tree translation (for a nondeterministic OI macro tree translation) is possibly NP-complete.
SN 0001-5903
EI 1432-0525
PD APR
PY 2021
VL 58
IS 1-2
BP 95
EP 152
DI 10.1007/s00236-019-00360-8
EA DEC 2019
UT WOS:000566140500001
ER

PT C
AU Oktem, A
   Jaam, MA
   DeLuca, E
   Tang, G
AF Oktem, Alp
   Jaam, Muhannad Albayk
   DeLuca, Eric
   Tang, Grace
GP IEEE
TI Gamayun - Language Technology for Humanitarian Response
SO 2020 IEEE GLOBAL HUMANITARIAN TECHNOLOGY CONFERENCE (GHTC)
SE IEEE Global Humanitarian Technology Conference Proceedings
CT 10th Annual IEEE Global Humanitarian Technology Conference (IEEE GHTC)
CY OCT 29-NOV 01, 2020
CL IEEE Reg 6, ELECTR NETWORK
SP IEEE, IEEE Seattle Sect, IEEE Soc Social Implicat Technol, IEEE USA, IEEE Consumer Technol Soc, IEEE Engn Med & Biol Soc, IEEE Microwave Theory & Tech Soc, IEEE Power & Energy Soc, IEEE Smart Village, IEEE Humanitarian Activit Comm
HO IEEE Reg 6
AB Over half of the world's population do not have access to knowledge and information because it's not available in their language. Translators without Borders (TWB) wants to change this with Gamayun, an initiative to promote language equality. Gamayun uses advanced language technologies to improve communication with people who speak marginalized languages in humanitarian and development contexts. In this paper, we present the early implementation results of the project in building machine translation and automatic speech recognition systems for various marginalized languages.
SN 2377-6919
BN 978-1-7281-7388-7
PY 2020
DI 10.1109/GHTC46280.2020.9342939
UT WOS:000657247100087
ER

PT C
AU Wang, ZX
   Xie, G
   Du, JH
   Zhang, YR
AF Wang, Zhuxin
   Xie, Guo
   Du, Jinhua
   Zhang, Yaru
GP IEEE
TI A Syntactic Knowledge Constrained Paraphrase Extraction for
   Chinese-English Statistical Machine Translation
SO 2017 CHINESE AUTOMATION CONGRESS (CAC)
SE Chinese Automation Congress
CT Chinese Automation Congress (CAC)
CY OCT 20-22, 2017
CL Jinan, PEOPLES R CHINA
SP IEEE, CAA, IEEE Syst Man & Cybernet Soc
AB On the basis of general pivot method for paraphrase extraction which might introduce much noise in extracted paraphrases, this paper proposes a syntactic knowledge-enhanced method to extract higher-quality paraphrases to further improve the quality of statistical machine translation. Firstly, the syntactic knowledge is acquired and added to paraphrase extraction algorithm as constraints to obtain higher quality paraphrases from a parallel corpora. Then the extracted paraphrases are used to update the phrase table and reordering table of the translation system based on the unknown words and phrases in the source-side sentences of the development set and test set. Specifically, if a paraphrase of an unknown word or phrase in a source-side sentence of the development set and test set exists in the phrase table or reordering table, then a new phrase pair constructed with this unknown word or phrase with the target-side word or phrase of this paraphrase will be added to the phrase table or reordering table. In doing so, it can reduce the number of our-of-vocabulary words, and improve the coverage of the test set by the paraphrase-enhanced tables. Finally, the translation results are obtained using the updated phrase table and reordering table by translating the source language sentences. Experiments are carried out on NIST 2005 and NIST 2008 test sets, and results show that the method can significantly improve translation performance compared with the baseline system.
OI xie, guo/0000-0002-9948-453X
SN 2688-092X
EI 2688-0938
BN 978-1-5386-3524-7
PY 2017
BP 5166
EP 5170
UT WOS:000427816105045
ER

PT C
AU Jang, DW
   Kim, DJ
   Hong, KS
AF Jang, Do-won
   Kim, Dong-Ju
   Hong, Kwang-Seok
BE Sato, M
   Matsuoka, S
   Sloot, PMA
   VanAlbada, GD
   Dongarra, J
TI Personalized Translation Listening System for Age Groups
SO PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE
   (ICCS)
SE Procedia Computer Science
CT International Conference on Computational Science (ICCS) on the Ascent
   of Computational Excellence
CY 2011
CL Campus Nanyang Technolog Univ, Singapore, SINGAPORE
SP Elsevier, Univ Tsukuba, Ctr Computat Sci
HO Campus Nanyang Technolog Univ
AB Present translation systems play back their results with specific speed and volume regardless of the type of user. In this paper, we describe a personalized translation listening system by identifying user information. User groups are classified by age group after inputting speech. This suggested translation system gives the translated result back to the user, speaking at an emphasized speech based on the user's age. The personalized translation listening system performs age recognition, speech recognition, language recognition, Google machine translation, and TTS web services. We showed the comparison of normal speech and emphasized speech by realizing a user-oriented translation system in a mobile device. A Mean Opinion Score was used for the experiment. Average score of the Mean Opinion Score experiment was 3.21.
SN 1877-0509
PY 2011
VL 4
BP 1336
EP 1342
DI 10.1016/j.procs.2011.04.144
UT WOS:000299165200143
ER

PT J
AU Marshman, E
AF Marshman, Elizabeth
TI Taking Control: Language Professionals and Their Perception of Control
   when Using Language Technologies
SO META
AB Language technologies (for example, computer-aided and machine translation tools) are now well established in the language industry. Unfortunately, so are questions about their advantages and drawbacks. Many of these appear to be linked to language professionals' control over their work and working environment. We surveyed these professionals to discover how they perceive language technologies' effect on their control over the amount of work they do, the tasks they carry out and the methods they use, the quality of the product, the relationships with clients/employers, and their remuneration. The results reveal that most current users have positive opinions of technologies overall and generally feel that these tools increase their control over their work and working environment (and particularly the quantity and quality of the work). However, hesitations remain, in particular in regard to relationships with clients/employers and remuneration.
SN 0026-0452
PD AUG
PY 2014
VL 59
IS 2
BP 380
EP 405
DI 10.7202/1027481ar
UT WOS:000346327800009
ER

PT J
AU Moon, H
   Park, C
   Eo, S
   Seo, J
   Lim, H
AF Moon, Hyeonseok
   Park, Chanjun
   Eo, Sugyeong
   Seo, Jaehyung
   Lim, Heuiseok
TI An Empirical Study on Automatic Post Editing for Neural Machine
   Translation
SO IEEE ACCESS
AB Automatic post editing (APE) researches aim to correct errors in the machine translation results. Recently, APE research has mainly been conducted in two directions: noise-based APE and adapter-based APE. This study poses three questions based on existing APE studies and conducted a verification. The first is a question about the optimal APE research direction, and this has been figured out through a comparative analysis of the previous studies on noise-based APE and adapter-based APE. The second is about the substantial effectiveness of the bottleneck adapter layer (BAL) in adapter based APE. For the verification, various experiments on the different size of BAL has been conducted, and through these experiments, optimal approaches in adapter based APE has been proposed. For the last, this work raises a question about the reason why leveraging external knowledge is influential in APE. In this regard, we conducted several comparative experiments on the method of utilizing external data to APE training to achieve a better performance. The results revealed that the performance can be improved by applying the method of concatenating the external data with the existing data when training the APE model.Through deep analysis on these experiments, this work propose the optimal research direction in APE.
RI eo, sugyeong/HIK-2033-2022
OI Moon, Hyeonseok/0000-0002-0841-4262; Seo, Jaehyung/0000-0002-4761-9818;
   Park, Chanjun/0000-0002-7200-9632
SN 2169-3536
PY 2021
VL 9
BP 123754
EP 123763
DI 10.1109/ACCESS.2021.3109903
UT WOS:000696060300001
ER

PT S
AU Kim, CY
   Hong, MY
   Huang, YX
   Kim, YK
   Yang, SI
   Seo, YA
   Choi, SK
AF Kim, CY
   Hong, MY
   Huang, YX
   Kim, YK
   Yang, SI
   Seo, YA
   Choi, SK
BE Richardson, SD
TI Korean-Chinese machine translation based on verb patterns
SO MACHINE TRANSLATION: FROM RESEARCH TO REAL USERS
SE Lecture Notes in Artificial Intelligence
CT 5th Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 08-12, 2002
CL Tiburon, CA
SP Assoc Machine Translat Americas
AB This paper describes our ongoing project "Korean-Chinese Machine Translation System". The main knowledge of our system is verb patterns. Each verb can have several meanings and each meaning of a verb is represented by a verb pattern. A verb pattern consists of a source language pattern part for the analysis and the corresponding target language pattern part for the generation. Each pattern part, according to the degree of generality, contains lexical or semantic information for the arguments or adjuncts of each verb meaning. In this approach, accurate analysis can directly lead to natural and correct generation. Furthermore as the transfer mainly depends upon verb patterns, the translation rate is expected to go higher, as the size of verb pattern grows larger.
SN 0302-9743
EI 1611-3349
BN 3-540-44282-0
PY 2002
VL 2499
BP 94
EP 103
UT WOS:000189412300010
ER

PT C
AU Wilken, P
   Alkhouli, T
   Matusov, E
   Golik, P
AF Wilken, Patrick
   Alkhouli, Tamer
   Matusov, Evgeny
   Golik, Pavel
GP Assoc Comp Linguist
TI Neural Simultaneous Speech Translation Using Alignment-Based Chunking
SO 17TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE TRANSLATION (IWSLT
   2020)
CT 17th International Conference on Spoken Language Translation (IWSLT)
CY JUL 09-10, 2020
CL ELECTR NETWORK
AB In simultaneous machine translation, the objective is to determine when to produce a partial translation given a continuous stream of source words, with a trade-off between latency and quality. We propose a neural machine translation (NMT) model that makes dynamic decisions when to continue feeding on input or generate output words. The model is composed of two main components: one to dynamically decide on ending a source chunk, and another that translates the consumed chunk. We train the components jointly and in a manner consistent with the inference conditions. To generate chunked training data, we propose a method that utilizes word alignment while also preserving enough context. We compare models with bidirectional and unidirectional encoders of different depths, both on real speech and text input. Our results on the IWSLT1 2020 English-to-German task outperform a wait-k baseline by 2.6 to 3.7% BLEU absolute.
BN 978-1-952148-07-1
PY 2020
BP 237
EP 246
UT WOS:000563427100029
ER

PT C
AU Kim, Y
   Gao, YB
   Ney, H
AF Kim, Yunsu
   Gao, Yingbo
   Ney, Hermann
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Effective Cross-lingual Transfer of Neural Machine Translation Models
   without Shared Vocabularies
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB Transfer learning or multilingual model is essential for low-resource neural machine translation (NMT), but the applicability is limited to cognate languages by sharing their vocabularies. This paper shows effective techniques to transfer a pre-trained NMT model to a new, unrelated language without shared vocabularies. We relieve the vocabulary mismatch by using cross-lingual word embedding, train a more language-agnostic encoder by injecting artificial noises, and generate synthetic data easily from the pre-training data without back-translation. Our methods do not require restructuring the vocabulary or retraining the model. We improve plain NMT transfer by up to +5.1% BLEU in five low-resource translation tasks, outperforming multilingual joint training by a large margin. We also provide extensive ablation studies on pre-trained embedding, synthetic data, vocabulary size, and parameter freezing for a better understanding of NMT transfer.
BN 978-1-950737-48-2
PY 2019
BP 1246
EP 1257
UT WOS:000493046102024
ER

PT C
AU Siddhant, A
   Johnson, M
   Tsai, H
   Ari, N
   Riesa, J
   Bapna, A
   Firat, O
   Raman, K
AF Siddhant, Aditya
   Johnson, Melvin
   Tsai, Henry
   Ari, Naveen
   Riesa, Jason
   Bapna, Ankur
   Firat, Orhan
   Raman, Karthik
GP Assoc Advancement Artificial Intelligence
TI Evaluating the Cross-Lingual Effectiveness of Massively Multilingual
   Neural Machine Translation
SO THIRTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THE
   THIRTY-SECOND INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE
   CONFERENCE AND THE TENTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN
   ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 34th AAAI Conference on Artificial Intelligence / 32nd Innovative
   Applications of Artificial Intelligence Conference / 10th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 07-12, 2020
CL New York, NY
SP Assoc Advancement Artificial Intelligence
AB The recently proposed massively multilingual neural machine translation (NMT) system has been shown to be capable of translating over 100 languages to and from English within a single model (Aharoni, Johnson, and Firat 2019). Its improved translation performance on low resource languages hints at potential cross-lingual transfer capability for downstream tasks. In this paper, we evaluate the cross-lingual effectiveness of representations from the encoder of a massively multilingual NMT model on 5 downstream classification and sequence labeling tasks covering a diverse set of over 50 languages. We compare against a strong baseline, multilingual BERT (mBERT) (Devlin et al. 2018), in different cross-lingual transfer learning scenarios and show gains in zero-shot transfer in 4 out of these 5 tasks.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-835-0
PY 2020
VL 34
BP 8854
EP 8861
UT WOS:000668126801036
ER

PT J
AU Magdy, W
   Jones, GJF
AF Magdy, Walid
   Jones, Gareth J. F.
TI Studying machine translation technologies for large-data CLIR tasks: a
   patent prior-art search case study
SO INFORMATION RETRIEVAL
AB Prior-art search in patent retrieval is concerned with finding all existing patents relevant to a patent application. Since patents often appear in different languages, cross-language information retrieval (CLIR) is an essential component of effective patent search. In recent years machine translation (MT) has become the dominant approach to translation in CLIR. Standard MT systems focus on generating proper translations that are morphologically and syntactically correct. Development of effective MT systems of this type requires large training resources and high computational power for training and translation. This is an important issue for patent CLIR where queries are typically very long sometimes taking the form of a full patent application, meaning that query translation using MT systems can be very slow. However, in contrast to MT, the focus for information retrieval (IR) is on the conceptual meaning of the search words regardless of their surface form, or the linguistic structure of the output. Thus much of the complexity of MT is not required for effective CLIR. We present an adapted MT technique specifically designed for CLIR. In this method IR text pre-processing in the form of stop word removal and stemming are applied to the MT training corpus prior to the training phase. Applying this step leads to a significant decrease in the MT computational and training resources requirements. Experimental application of the new approach to the cross language patent retrieval task from CLEF-IP 2010 shows that the new technique to be up to 23 times faster than standard MT for query translations, while maintaining IR effectiveness statistically indistinguishable from standard MT when large training resources are used. Furthermore the new method is significantly better than standard MT when only limited translation training resources are available, which can be a significant issue for translation in specialized domains. The new MT technique also enables patent document translation in a practical amount of time with a resulting significant improvement in the retrieval effectiveness.
OI Jones, Gareth/0000-0003-2923-8365; Magdy, Walid/0000-0001-9676-1338
SN 1386-4564
EI 1573-7659
PD OCT
PY 2014
VL 17
IS 5-6
SI SI
BP 492
EP 519
DI 10.1007/s10791-013-9231-6
UT WOS:000342411200006
ER

PT J
AU Lee, YS
   Lee, HG
   Rim, HC
   Hwang, YS
AF Lee, Yeon-Soo
   Lee, Hyoung-Gyu
   Rim, Hae-Chang
   Hwang, Young-Sook
TI Utilizing Global Syntactic Tree Features for Phrase Reordering
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
AB In phrase-based statistical machine translation, long distance reordering problem is one of the most challenging issues when translating syntactically distant language pairs. In this paper, we propose a novel reordering model to solve this problem. In our model, reordering is affected by the overall structures of sentences such as listings, reduplications. and modifications as well as the relationships of adjacent phrases. To this end, we reflect global syntactic contexts including the parts that are not yet translated during the decoding process.
SN 1745-1361
PD JUN
PY 2014
VL E97D
IS 6
BP 1694
EP 1698
DI 10.1587/transinf.E97.D.1694
UT WOS:000342784300040
ER

PT C
AU Huang, L
   Chen, WY
AF Huang, Li
   Chen, Wenyu
GP IEEE
TI GATED RESIDUAL CONNECTION FOR NERUAL MACHINE TRANSLATION
SO 2019 16TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA
   TECHNOLOGY AND INFORMATION PROCESSING (ICWAMTIP)
SE International Computer Conference on Wavelet Active Media Technology and
   Information Processing
CT 16th IEEE International Computer Conference on Wavelet Active Media
   Technology and Information Processing (ICCWAMTIP)
CY DEC 13-15, 2019
CL Univ Elect Sci & Technol China, Chengdu, PEOPLES R CHINA
SP IEEE
HO Univ Elect Sci & Technol China
AB The Transformer framework has shown its flexibility in parallel computation and the effectiveness of modeling word dependencies since it is proposed. Due to the exploding and vanishing gradient problem, Transformer adopted the residual connection among the layers in a stack. However, normally residual connection layer just simply element-added the input and output. In this work, we focus on improving the residual connection layer through regulating the appropriate probability of the input and output flow but not only simply added. To maintain the simplicity and flexibility of the Transformer framework, we leverage the internal representations of the output. The results of experiments on WMT14 English-German translation dataset demonstrate the effectiveness of our proposed method.
OI KAWANO, Masaya/0000-0003-3183-5572
SN 2576-8972
EI 2576-8964
BN 978-1-7281-4242-5
PY 2019
BP 258
EP 261
UT WOS:000553538700055
ER

PT J
AU Khatri, J
   Murthy, R
   Banerjee, T
   Bhattacharyya, P
AF Khatri, Jyotsana
   Murthy, Rudra
   Banerjee, Tamali
   Bhattacharyya, Pushpak
TI Simple measures of bridging lexical divergence help unsupervised neural
   machine translation for low-resource languages
SO MACHINE TRANSLATION
AB Unsupervised Neural Machine Translation (UNMT) approaches have gained widespread popularity in recent times. Though these approaches show impressive translation performance using only monolingual corpora of the languages involved, these approaches have mostly been tried on high-resource European language pairs viz.English-French, English-German, etc. In this paper, we explore UNMT for 6 Indic language pairs viz., Hindi-Bengali, Hindi-Gujarati, Hindi-Marathi, Hindi-Malayalam, Hindi-Tamil, and Hindi-Telugu which are low-resource language pairs. We additionally perform experiments on 4 European language pairs viz., English-Czech, English-Estonian, English-Lithuanian, and English-Finnish. We observe that the lexical divergence within these language pairs plays a big role in the success of UNMT. In this context, we explore three approaches viz., (i) script conversion, (ii) unsupervised bilingual embedding-based initialization to bring the vocabulary of the two languages closer, and (iii) dictionary word substitution using a bilingual dictionary. We found that the script conversion using a simple rule-based system benefits language pairs that have high cognate overlap but use different scripts. We observe that script conversion combined with word substitution using a dictionary further improves the UNMT performance. We use a ground truth bilingual dictionary in our dictionary word substitution experiments, and such dictionaries can also be obtained using unsupervised bilingual embeddings. We empirically demonstrate that minimizing lexical divergence using simple heuristics leads to significant improvements in the BLEU score for both related and distant language pairs.
OI Khatri, Jyotsana/0000-0001-8519-661X
SN 0922-6567
EI 1573-0573
PD DEC
PY 2021
VL 35
IS 4
BP 711
EP 744
DI 10.1007/s10590-021-09292-y
EA JAN 2022
UT WOS:000739291600001
ER

PT J
AU Li, ZJ
   Chi, CY
   Zhan, YY
AF Li, Zijian
   Chi, Chengying
   Zhan, Yunyun
TI Corpus Augmentation for Improving Neural Machine Translation
SO CMC-COMPUTERS MATERIALS & CONTINUA
AB The translation quality of neural machine translation (NMT) systems depends largely on the quality of large-scale bilingual parallel corpora available. Research shows that under the condition of limited resources, the performance of NMT is greatly reduced, and a large amount of high-quality bilingual parallel data is needed to train a competitive translation model. However, not all languages have large-scale and high-quality bilingual corpus resources available. In these cases, improving the quality of the corpora has become the main focus to increase the accuracy of the NMT results. This paper proposes a new method to improve the quality of data by using data cleaning, data expansion, and other measures to expand the data at the word and sentence-level, thus improving the richness of the bilingual data. The long short-term memory (LSTM) language model is also used to ensure the smoothness of sentence construction in the process of sentence construction. At the same time, it uses a variety of processing methods to improve the quality of the bilingual data. Experiments using three standard test sets are conducted to validate the proposed method; the most advanced fairseq-transformer NMT system is used in the training. The results show that the proposed method has worked well on improving the translation results. Compared with the state-of-the-art methods, the BLEU value of our method is increased by 2.34 compared with that of the baseline.
SN 1546-2218
EI 1546-2226
PY 2020
VL 64
IS 1
BP 637
EP 650
DI 10.32604/cmc.2020.010265
UT WOS:000535726900036
ER

PT C
AU Bang, S
   Nam, S
   Chun, I
   Jhoo, HY
   Lee, J
AF Bang, Seongwon
   Nam, Seunghyeon
   Chun, Inwhan
   Jhoo, Ho Young
   Lee, Juneyoung
BE Shoham, S
   Vizel, Y
TI SMT-Based Translation Validation for Machine Learning Compiler
SO COMPUTER AIDED VERIFICATION (CAV 2022), PT II
SE Lecture Notes in Computer Science
CT 34th International Conference on Computer-Aided Verification (CAV) held
   as part of the Federated Logic Conference (FLoC)
CY AUG 07-10, 2022
CL Haifa, ISRAEL
AB Machine learning compilers are large software containing complex transformations for deep learning models, and any buggy transformation may cause a crash or silently bring a regression to the prediction accuracy and performance. This paper proposes an SMT-based translation validation framework for Multi-Level IR (MLIR), a compiler framework used by many deep learning compilers. It proposes an SMT encoding tailored for translation validation that is an over-approximation of the FP arithmetic and reduction operations. It performs abstraction refinement if validation fails. We also propose a new approach for encoding arithmetic properties of reductions in SMT. We found mismatches between the specification and implementation of MLIR, and validated high-level transformations for SqueezeNet, MobileNet, and text_classification with proper splitting.
SN 0302-9743
EI 1611-3349
BN 978-3-031-13188-2; 978-3-031-13187-5
PY 2022
VL 13372
BP 386
EP 407
DI 10.1007/978-3-031-13188-2_19
UT WOS:000870310500019
ER

PT C
AU Madnani, N
AF Madnani, Nitin
GP IEEE Comp Soc
TI iBLEU: Interactively Debugging & Scoring Statistical Machine Translation
   Systems
SO FIFTH IEEE INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC 2011)
SE IEEE International Conference on Semantic Computing
CT 5th Annual IEEE International Conference on Semantic Computing (ICSC)
CY SEP 18-22, 2011
CL Stanford Univ, Palo Alto, CA
SP IEEE, IEEE Comp Soc, Microsoft, Wells Fargo, Franz Inc
HO Stanford Univ
AB Machine Translation (MT) systems are evaluated and debugged using the BLEU automated metric. However, the current community implementation of BLEU is not ideal for MT system developers and researchers since it only produces textual information. I present a novel tool called iBLEU that organizes BLEU scoring information in a visual and easy-to-understand manner, making it easier for MT system developers & researchers to quickly locate documents and sentences on which their system performs poorly. It also allows comparing translations from two different MT systems. Furthermore, one can also choose to compare to the publicly available MT systems, e.g., Google Translate and Bing Translator, with a single click. It can run on all major platforms and requires no setup whatsoever.
SN 2325-6516
BN 978-0-7695-4492-2
PY 2011
BP 213
EP 214
DI 10.1109/ICSC.2011.36
UT WOS:000410187400038
ER

PT C
AU Zhao, MJ
   Wu, HJ
   Niu, D
   Wang, ZX
   Wang, XL
AF Zhao, Mingjun
   Wu, Haijiang
   Niu, Di
   Wang, Zixuan
   Wang, Xiaoli
GP ACM
TI Verdi: Quality Estimation and Error Detection for Bilingual Corpora
SO PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021)
CT 30th World Wide Web Conference (WWW)
CY APR 12-23, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery
AB Translation Quality Estimation is critical to reducing post-editing efforts in machine translation and to cross-lingual corpus cleaning. As a research problem, quality estimation (QE) aims to directly estimate the quality of translation in a given pair of source and target sentences, and highlight the words that need corrections, without referencing to golden translations. In this paper, we propose Verdi, a novel framework for word-level and sentence-level post-editing effort estimation for bilingual corpora. Verdi adopts two word predictors to enable diverse features to be extracted from a pair of sentences for subsequent quality estimation, including a transformer-based neural machine translation (NMT) model and a pre-trained cross-lingual language model (XLM). We exploit the symmetric nature of bilingual corpora and apply model-level dual learning in the NMT predictor, which handles a primal task and a dual task simultaneously with weight sharing, leading to stronger context prediction ability than single-direction NMT models. By taking advantage of the dual learning scheme, we further design a novel feature to directly encode the translated target information without relying on the source context. Extensive experiments conducted on WMT20 QE tasks demonstrate that our method beats the winner of the competition and outperforms other baseline methods by a great margin. We further use the sentence-level scores provided by Verdi to clean a parallel corpus and observe benefits on both model performance and training efficiency.
BN 978-1-4503-8312-7
PY 2021
BP 3023
EP 3031
DI 10.1145/3442381.3449931
UT WOS:000733621803005
ER

PT C
AU Yang, J
   Ma, S
   Zhang, D
   Wan, J
   Li, Z
   Zhou, M
AF Yang, Jian
   Ma, Shuming
   Zhang, Dongdong
   Wan, Juncheng
   Li, Zhoujun
   Zhou, Ming
GP Assoc Computat Linguist
TI Smart-Start Decoding for Neural Machine Translation
SO 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021)
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 06-11, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, N Amer Chapter, Google Res, Amazon Sci, Apple, Facebook AI, Megagon Labs, Microsoft, Bloomberg Engn, Grammarly, IBM, Vanguard, Duolingo, Babelscape, Human Language Technol, LegalForce
AB Most current neural machine translation models adopt a monotonic decoding order of either left-to-right or right-to-left. In this work, we propose a novel method that breaks up the limitation of these decoding orders, called Smart-Start decoding. More specifically, our method first predicts a median word. It starts to decode the words on the right side of the median word and then generates words on the left. We evaluate the proposed Smart-Start decoding method on three datasets. Experimental results show that the proposed method can significantly outperform strong baseline models.
BN 978-1-954085-46-6
PY 2021
BP 3982
EP 3988
UT WOS:000895685604010
ER

PT C
AU Kan, D
AF Kan, Dmitry
BE Escalona, MJ
   Shishkov, B
   Cordeiro, J
TI METHOD FOR AN AUTOMATIC GENERATION OF A SEMANTIC-LEVEL CONTEXTUAL
   TRANSLATIONAL DICTIONARY
SO ICSOFT 2011: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON SOFTWARE
   AND DATABASE TECHNOLOGIES, VOL 2
CT 6th International Conference on Software and Database Technologies
   (ICSOFT 2011)
CY JUL 18-21, 2011
CL Unov Seville, Seville, SPAIN
SP Inst Syst & Technol Informat Control & Commun
HO Unov Seville
AB In this paper we demonstrate the semantic feature machine translation (MT) system as a combination of two fundamental approaches, where the rule-based side is supported by the functional model of the Russian language and the statistical side utilizes statistical word alignment. The MT system relies on a semantic level contextual translational dictionary as its key component. We will present the method for an automatic generation of the dictionary where disambiguation is done on a semantic level.
BN 978-989-8425-77-5
PY 2011
BP 415
EP 418
UT WOS:000393364000063
ER

PT J
AU Zapata, C
   Benitez, S
AF Zapata, Carlos
   Benitez, Servio
TI Interlingua: a-state-of-the-art overview
SO REVISTA FACULTAD DE INGENIERIA-UNIVERSIDAD DE ANTIOQUIA
AB An Interlingua is any artificial or semi-natural language, with main features like precision, neutrality, non-ambiguity and some kind of formalism to express communicative ideas. These features have converted interlinguas in useful tools for solving problems in areas like machine translation, natural language processing, and artificial intelligence. In this paper, we make an Interlingua overview, which include concepts, applications, and developed projects about it. We hope this will be the starting point of new project development around this issue.
OI Zapata-Jaramillo, Carlos Mario/0000-0002-0628-4097
SN 0120-6230
EI 2422-2844
PD MAR
PY 2009
IS 47
BP 117
EP 128
UT WOS:000263527400012
ER

PT J
AU Mei, X
   Yao, J
   Lin, JG
   Xia, LZ
AF Mei, Xue
   Yao, Jing
   Lin, Jinguo
   Xia, Liangzheng
TI Similar image recognition by edge wavelet moment and support vector
   machines
SO DYNAMICS OF CONTINUOUS DISCRETE AND IMPULSIVE SYSTEMS-SERIES
   B-APPLICATIONS & ALGORITHMS
CT International Conference on Complex Systems and Applications
CY JUN 16-18, 2006
CL Huhhot, PEOPLES R CHINA
AB In this paper we propose an efficient technique to identify similar objects. The wavelet moment, which combined the moment character with the wavelet character, reflects the global information and local information simultaneously and is invariant to the translation, scaling and rotation. Support Vector Machines is used in recognition. The experiments show it is an effective method for images recognizing with similar characters and minor swatch, which improves the capability of distinguishing similar images, and resolves the problems that characteristics of images will vary with translations, scaling and rotation.
SN 1492-8760
PD DEC
PY 2006
VL 13
SU S
BP 1073
EP 1076
PN 3
UT WOS:000245061700033
ER

PT C
AU Shi, CD
   Wang, HL
AF Shi, CD
   Wang, HL
GP IEEE
TI Research on ontology-driven Chinese-English machine translation
SO PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON NATURAL
   LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING (IEEE NLP-KE'05)
CT International Conference on Natural Language Processing and Knowledge
   Engineering
CY OCT 30-NOV 01, 2005
CL Wuhan, PEOPLES R CHINA
SP IEEE, AAI, CIPSC, Chinese Assoc Artificial Intelligence, IEEE Signal Proc Soc, IEEE Beijing Sect
AB This paper presents an ontology-driven Chinese-English machine translation prototype system. We construct a small ontology called "SCIENTIST", based on which we develop a Chinese-English MT system. We introduce the basic rules and steps we follow to build the ontology and how we use ontology to represent meanings and deal with ambiguation. We show that ontology is necessary in semantic analysis and disambiguation. It provides a world model with meaning units and structures for meaning representation and reasoning. It provides a new perspective to handle the semantic analysis of MT.
BN 0-7803-9361-9
PY 2005
BP 426
EP 430
UT WOS:000235577200080
ER

PT J
AU DASGUPTA, P
AF DASGUPTA, P
TI IDIOMATICITY AND ESPERANTO TEXTS - AN EMPIRICAL-STUDY
SO LINGUISTICS
AB Esperanto has a highly productive word-formation system. Complex words are compositional to a very high degree. There is, however, a tendency toward idiomatization in complex word forms. With a view to machine translation with Esperanto as the intermediate language, the present paper examines the nature of noncompositional words in a corpus of scientific texts. Various structural types are investigated. Semantically noncompositional forms are rare in most groups but common in the group of preposition-contentive compounds. Suggestions are made for the resolution of noncompositionality in (machine translation-oriented) lexicography.
SN 0024-3949
PY 1993
VL 31
IS 2
BP 367
EP 386
DI 10.1515/ling.1993.31.2.367
UT WOS:A1993LK51200005
ER

PT S
AU Mahsut, M
   Ogawa, Y
   Sugino, K
   Toyama, K
   Inagaki, Y
AF Mahsut, M
   Ogawa, Y
   Sugino, K
   Toyama, K
   Inagaki, Y
BE Frederking, RE
   Taylor, KB
TI An experiment on Japanese-Uighur machine translation and its evaluation
SO MACHINE TRANSLATION: FROM REAL USERS TO RESEARCH, PROCEEDINGS
SE Lecture Notes in Computer Science
CT 6th Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY SEP 28-OCT 02, 2004
CL Washington, DC
SP Assoc Machine Translat Americas
AB This paper describes an evaluation experiment on a Japanese-Uighur machine translation system which consists of verbal suffix processing, case suffix processing, phonetic change processing, and a Japanese-Uighur dictionary including about 20,000 words. Japanese and Uighur have many syntactical and language structural similarities. For these reasons, it is considered that we can translate Japanese into Uighur in such a manner as word-by-word aligning after morphological analysis of the input sentences without complicated syntactical analysis. From the point of view of practical usage, we have chosen three articles and conducted a full-text translation experiment on the articles with our MT system, for clarifying our argument. As a result of the experiment, 84.8% of precision has been achieved.
SN 0302-9743
EI 1611-3349
BN 3-540-23300-8
PY 2004
VL 3265
BP 208
EP 216
UT WOS:000224611600023
ER

PT C
AU Miyabe, M
   Yoshino, T
AF Miyabe, Mai
   Yoshino, Takashi
GP IEEE
TI Evaluation of the Validity of Back-Translation as a Method of Assessing
   the Accuracy of Machine Translation
SO 2015 INTERNATIONAL CONFERENCE ON CULTURE AND COMPUTING (CULTURE
   COMPUTING)
CT International Conference on Culture and Computing (Culture Computing)
CY OCT 17-19, 2015
CL Kyoto, JAPAN
AB Inaccurate translation prevents effective communication between individuals and leads to misunderstandings. Back-translation is a process used to check the accuracy of a sentence by translating it to the checker's native language. We believe that there is a positive correlation between the accuracy of sentences translated to a target language and that of back-translated sentences. Some studies have discussed the validity of back-translation from the standpoint of the performance evaluation of machine translation systems and concluded that back-translation was unsuitable for checking translation accuracy. However, this result has been derived from the process of verification of whether there was a positive correlation between the accuracy of target-translated sentences and that of back-translated sentences. This mode of verification is not suitable to human verification of back-translation. In this paper, we verified the validity of back-translation from the standpoint of a human checker. We focused on differences that tend to occur between checkers, and determined whether there were differences between target- and back-translated sentences. Our study's contribution can be summarized as follows: (1) we examined the co-occurrence rate of each evaluated value in the same sentence and revealed possible differences in evaluated values between checkers; and (2) we defined an acceptable range of accuracy mismatch based on these differences. Moreover, we revealed how the rate of accuracy mismatch changes with the extension of the acceptable range, which can be different for different purposes. Our results enable people to judge whether they can use back-translation for their purposes.
BN 978-1-4673-8232-8
PY 2015
BP 145
EP 150
DI 10.1109/Culture.and.Computing.2015.35
UT WOS:000380455000024
ER

PT C
AU Wani, NJ
   Mohanty, SP
   Purini, S
   Sharma, DM
AF Wani, Nehal J.
   Mohanty, Sharada Prasanna
   Purini, Suresh
   Sharma, Dipti Misra
BE Drira, K
   Wang, H
   Yu, Q
   Wang, Y
   Yan, Y
   Charoy, F
   Mendling, J
   Mohamed, M
   Wang, Z
   Bhiri, S
TI Anuvaad Pranaali: A RESTful API for Machine Translation
SO SERVICE-ORIENTED COMPUTING - ICSOC 2016 WORKSHOPS
SE Lecture Notes in Computer Science
CT 14th International Conference on Service-Oriented Computing (ICSOC)
CY OCT 10-13, 2016
CL Banff, CANADA
AB The current web APIs are end-user centric as they mostly focus on the end results. In this paper, we break this paradigm for one class of scientific workflow problems-machine translation, by designing an API that caters not only to the end users but also allows researchers to find bugs in their systems by exposing the ability to programmatically manipulate the results. Moreover, it follows an easy to replicate workflow based mechanism, which is built on the concept of microservices.
SN 0302-9743
EI 1611-3349
BN 978-3-319-68136-8; 978-3-319-68135-1
PY 2017
VL 10380
BP 179
EP 183
DI 10.1007/978-3-319-68136-8_20
UT WOS:000716836400020
ER

PT J
AU Al Ghamdi, NM
   Khan, MB
AF Al Ghamdi, Norah Mohammad
   Khan, Muhammad Badruddin
TI Assessment of performance of machine learning based similarities
   calculated for different English translations of Holy Quran
SO INTERNATIONAL JOURNAL OF COMPUTER SCIENCE AND NETWORK SECURITY
AB This research article presents the work that is related to the application of different machine learning based similarity techniques on religious text for identifying similarities and differences among its various translations. The dataset includes 10 different English translations of verses (Arabic: Ayah) of two Surahs (chapters) namely, Al-Humazah and An-Nasr. The quantitative similarity values for different translations for the same verse were calculated by using the cosine similarity and semantic similarity. The corpus went through two series of experiments: before pre-processing and after pre-processing. In order to determine the performance of machine learning based similarities, human annotated similarities between translations of two Surahs (chapters) namely Al-Humazah and An-Nasr were recorded to construct the ground truth. The average difference between the human annotated similarity and the cosine similarity for Surah (chapter) Al-Humazah was found to be 1.38 per verse (ayah) per pair of translation. After pre-processing, the average difference increased to 2.24. Moreover, the average difference between human annotated similarity and semantic similarity for Surah (chapter) Al-Humazah was found to be 0.09 per verse (Ayah) per pair of translation. After pre-processing, it increased to 0.78. For the Surah (chapter) An-Nasr, before preprocessing, the average difference between human annotated similarity and cosine similarity was found to be 1.93 per verse (Ayah), per pair of translation. And. After pre-processing, the average difference further increased to 2.47. The average difference between the human annotated similarity and the semantic similarity for Surah An-Nasr before preprocessing was found to be 0.93 and after pre-processing, it was reduced to 0.87 per verse (ayah) per pair of translation. The results showed that as expected, the semantic similarity was proven to be better measurement indicator for calculation of the word meaning.
SN 1738-7906
PD APR 30
PY 2022
VL 22
IS 4
BP 111
EP 118
DI 10.22937/IJCSNS.2022.22.4.15
UT WOS:000784377100015
ER

PT C
AU Ren, S
   Chen, WH
   Liu, SJ
   Li, M
   Zhou, M
   Ma, S
AF Ren, Shuo
   Chen, Wenhu
   Liu, Shujie
   Li, Mu
   Zhou, Ming
   Ma, Shuai
BE Gurevych, I
   Miyao, Y
TI Triangular Architecture for Rare Language Translation
SO PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL), VOL 1
CT 56th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 15-20, 2018
CL Melbourne, AUSTRALIA
SP Assoc Computat Linguist, Google, ByteDance, Samsung Res, Apple, Facebook, Amazon, Baidu, Recruit Inst Technol, Tencent, IBM Res AI, Microsoft, Naver, Line, CVTE, Digital Hlth crc, Nuance, Huawei, Elsevier, Duolingo, ISI NLP, Australian Govt, Dept Def, Sci & Technol
AB Neural Machine Translation (NMT) performs poor on the low-resource language pair (X, Z), especially when Z is a rare language. By introducing another rich language Y, we propose a novel triangular training architecture (TA-NMT) to leverage bilingual data (Y, Z) (may be small) and (X, Y) (can be rich) to improve the translation performance of low-resource pairs. In this triangular architecture, Z is taken as the intermediate latent variable, and translation models of Z are jointly optimized with a unified bidirectional EM algorithm under the goal of maximizing the translation likelihood of (X, Y). Empirical results demonstrate that our method significantly improves the translation quality of rare languages on MultiUN and IWSLT2012 datasets, and achieves even better performance combining back-translation methods.
BN 978-1-948087-32-2
PY 2018
BP 56
EP 65
UT WOS:000493904300006
ER

PT C
AU Orhun, M
   Tantug, AC
   Adali, E
AF Orhun, Murat
   Tantug, Ahmet Cueneyd
   Adali, Esref
BE Ji, DH
   Dong, M
   Smavatkul, D
   Lua, KT
TI Rule Based Analysis of the Uygur Nouns
SO RECENT ADVANCES OF ASIAN LANGUAGE PROCESSING TECHNOLOGIES
CT International Conference on Asian Language Processing
CY NOV 12-14, 2008
CL Chiang Mai, THAILAND
SP Chinese & Oriental Languages Informat Proc Soc, Chiang Mai Univ, Dept Comp Sci
AB This paper describes the implementation of a rule-based analyzer for Uygur (spoken in Sin Kiang, China) Nouns. We hope this paper will give some contribution for advanced studies to the Uygur Language in Machine Translation and Natural Language Processing. Like all Turkic languages, the Uygur Language is an agglutinative language that has productive inflectional and derivational suffixes. In this work, we implemented a finite state two-level morphological analyzer for the Uygur Nouns by using Xerox Finite State Tools.
RI Tantug, Ahmet Cuneyd/M-4497-2013
OI Tantug, Ahmet Cuneyd/0000-0003-0524-3397
BN 978-981-08-1609-4
PY 2008
BP 8
EP +
UT WOS:000262873600002
ER

PT J
AU Organ, A
AF Organ, Alison
TI Attitudes to the use of Google Translate for L2 production: analysis of
   chatroom discussions among UK secondary school students
SO LANGUAGE LEARNING JOURNAL
AB This paper presents the findings of a research project on UK school students' attitudes to the use of Free Online Machine Translation for L2 production and more specifically in preparing for assessment. Data were collected from a publicly available online forum to analyse students' spontaneous discussion of the use of Free Online Machine Translation, predominantly Google Translate. The majority of relevant comments were posted by secondary school students in the UK, regarding the use of Google Translate for GCSE examinations. The findings reveal that use of Google Translate for assignments was accepted practice among secondary school students in the UK over the last decade. However, they show mixed attitudes to this usage, and the nature of the discussion changed over the decade as a result of the evolution of Google Translate and changes to UK examination requirements. This study is original in its use of netnography, the study of online communities, to analyse students' comments to each other about their use of Google Translate in preparing for modern foreign languages (MFL) coursework. These findings, therefore, serve to inform the debate on how schools and universities should respond to student Google Translate usage for language learning and assignments.
SN 0957-1736
EI 1753-2167
DI 10.1080/09571736.2021.2023896
EA JAN 2022
UT WOS:000743461600001
ER

PT J
AU Choi, YS
   Park, YH
   Yun, S
   Kim, SH
   Lee, KJ
AF Choi, Yong-Seok
   Park, Yo-Han
   Yun, Seung
   Kim, Sang-Hun
   Lee, Kong-Joo
TI Factors Behind the Effectiveness of an Unsupervised Neural Machine
   Translation System between Korean and Japanese
SO APPLIED SCIENCES-BASEL
AB Korean and Japanese have different writing scripts but share the same Subject-Object-Verb (SOV) word order. In this study, we pre-train a language-generation model using a Masked Sequence-to-Sequence pre-training (MASS) method on Korean and Japanese monolingual corpora. When building the pre-trained generation model, we allow the smallest number of shared vocabularies between the two languages. Then, we build an unsupervised Neural Machine Translation (NMT) system between Korean and Japanese based on the pre-trained generation model. Despite the different writing scripts and few shared vocabularies, the unsupervised NMT system performs well compared to other pairs of languages. Our interest is in the common characteristics of both languages that make the unsupervised NMT perform so well. In this study, we propose a new method to analyze cross-attentions between a source and target language to estimate the language differences from the perspective of machine translation. We calculate cross-attention measurements between Korean-Japanese and Korean-English pairs and compare their performances and characteristics. The Korean-Japanese pair has little difference in word order and a morphological system, and thus the unsupervised NMT between Korean and Japanese can be trained well even without parallel sentences and shared vocabularies.
OI choe, yongseog/0000-0002-7889-8004; Yun, Seung/0000-0002-4610-1777;
   PARK, YO-HAN/0000-0002-5023-5604; Lee, Kong Joo/0000-0003-0025-4230
EI 2076-3417
PD AUG
PY 2021
VL 11
IS 16
AR 7662
DI 10.3390/app11167662
UT WOS:000688675800001
ER

PT J
AU Ortiz-Martinez, D
AF Ortiz-Martinez, Daniel
TI Online Learning for Statistical Machine Translation
SO COMPUTATIONAL LINGUISTICS
AB We present online learning techniques for statistical machine translation (SMT). The availability of large training data sets that grow constantly over time is becoming more and more frequent in the field of SMTfor example, in the context of translation agencies or the daily translation of government proceedings. When new knowledge is to be incorporated in the SMT models, the use of batch learning techniques require very time-consuming estimation processes over the whole training set that may take days or weeks to be executed. By means of the application of online learning, new training samples can be processed individually in real time. For this purpose, we define a state-of-the-art SMT model composed of a set of submodels, as well as a set of incremental update rules for each of these submodels. To test our techniques, we have studied two well-known SMT applications that can be used in translation agencies: post-editing and interactive machine translation. In both scenarios, the SMT system collaborates with the user to generate high-quality translations. These user-validated translations can be used to extend the SMT models by means of online learning. Empirical results in the two scenarios under consideration show the great impact of frequent updates in the system performance. The time cost of such updates was also measured, comparing the efficiency of a batch learning SMT system with that of an online learning system, showing that online learning is able to work in real time whereas the time cost of batch retraining soon becomes infeasible. Empirical results also showed that the performance of online learning is comparable to that of batch learning. Moreover, the proposed techniques were able to learn from previously estimated models or from scratch. We also propose two new measures to predict the effectiveness of online learning in SMT tasks. The translation system with online learning capabilities presented here is implemented in the open-source Thot toolkit for SMT.
OI Ortiz-Martinez, Daniel/0000-0001-5659-6702
SN 0891-2017
EI 1530-9312
PD MAR
PY 2016
VL 42
IS 1
BP 121
EP 161
DI 10.1162/COLI_a_00244
UT WOS:000373936000004
ER

PT J
AU Ogura, K
   Nakaiwa, H
   Matsuo, Y
   Ooyama, Y
   Bond, F
AF Ogura, K
   Nakaiwa, H
   Matsuo, Y
   Ooyama, Y
   Bond, F
TI The electronic dictionary - Goi-Taikei - A Japanese lexicon and its
   applications
SO NTT REVIEW
AB NTT Communication Science Laboratories has developed an electronic dictionary using a format that can be understood by a computer to facilitate automatic translations from Japanese to English via computers. In order to achieve high-quality machine translation, the computer must be capable of handling meanings. The semantic dictionary that we have developed to allow computers to understand meaning is called the "Goi-Taikei-A Japanese Lexicon." Here, we will describe the contents of the Goi-Taikei, and explain how it is used in the context of machine translation. We will also explain how it can be used generally in natural language processing, using examples of applications in multi-lingual information retrieval systems on the Internet and digital library systems*(1).
OI Bond, Francis/0000-0003-4973-8068
SN 0915-2334
PD JUL
PY 2000
VL 12
IS 4
BP 53
EP 58
UT WOS:000088609900007
ER

PT C
AU Agrawal, S
   Carpuat, M
AF Agrawal, Sweta
   Carpuat, Marine
GP Assoc Computat Linguist
TI Controlling Text Complexity in Neural Machine Translation
SO 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND
   THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE
CT Conference on Empirical Methods in Natural Language Processing / 9th
   International Joint Conference on Natural Language Processing
   (EMNLP-IJCNLP)
CY NOV 03-07, 2019
CL Hong Kong, HONG KONG
SP Google, Facebook, Apple, ASAPP, Salesforce, Huawei, Baidu, Deepmind, Amazon, PolyAI, Naver, ByteDance, Megagon Labs, Zhuiyi, Verisk, MI
AB This work introduces a machine translation task where the output is aimed at audiences of different levels of target language proficiency. We collect a high quality dataset of news articles available in English and Spanish, written for diverse grade levels and propose a method to align segments across comparable bilingual articles. The resulting dataset makes it possible to train multi-task sequence-to-sequence models that translate Spanish into English targeted at an easier reading grade level than the original Spanish. We show that these multitask models outperform pipeline approaches that translate and simplify text independently.
BN 978-1-950737-90-1
PY 2019
BP 1549
EP 1564
UT WOS:000854193301088
ER

PT C
AU Xu, HF
   van Genabith, J
   Xiong, DY
   Liu, QH
   Zhang, JY
AF Xu, Hongfei
   van Genabith, Josef
   Xiong, Deyi
   Liu, Qiuhui
   Zhang, Jingyi
GP Assoc Computat Linguist
TI Learning Source Phrase Representations for Neural Machine Translation
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB The Transformer translation model (Vaswani et al., 2017) based on a multi-head attention mechanism can be computed effectively in parallel and has significantly pushed forward the performance of Neural Machine Translation (NMT). Though intuitively the attentional network can connect distant words via shorter network paths than RNNs, empirical analysis demonstrates that it still has difficulty in fully capturing long-distance dependencies (Tang et al., 2018). Considering that modeling phrases instead of words has significantly improved the Statistical Machine Translation (SMT) approach through the use of larger translation blocks ("phrases") and its reordering ability, modeling NMT at phrase level is an intuitive proposal to help the model capture long-distance relationships. In this paper, we first propose an attentive phrase representation generation mechanism which is able to generate phrase representations from corresponding token representations. In addition, we incorporate the generated phrase representations into the Transformer translation model to enhance its ability to capture long-distance relationships. In our experiments, we obtain significant improvements on the WMT 14 English-German and English-French tasks on top of the strong Transformer baseline, which shows the effectiveness of our approach. Our approach helps Transformer Base models perform at the level of Transformer Big models, and even significantly better for long sentences, but with substantially fewer parameters and training steps. The fact that phrase representations help even in the big setting further supports our conjecture that they make a valuable contribution to long-distance relations.
RI Xu, Hongfei/AAT-6505-2020
OI Xu, Hongfei/0000-0001-8397-1459; Xiong, Deyi/0000-0002-2353-5038; Liu,
   Qiuhui/0000-0002-6936-4107
BN 978-1-952148-25-5
PY 2020
BP 386
EP 396
UT WOS:000570978200037
ER

PT C
AU Kuang, SH
   Li, JH
   Branco, A
   Luo, WH
   Xiong, DY
AF Kuang, Shaohui
   Li, Junhui
   Branco, Antonio
   Luo, Weihua
   Xiong, Deyi
BE Gurevych, I
   Miyao, Y
TI Attention Focusing for Neural Machine Translation by Bridging Source and
   Target Embeddings
SO PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL), VOL 1
CT 56th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 15-20, 2018
CL Melbourne, AUSTRALIA
SP Assoc Computat Linguist, Google, ByteDance, Samsung Res, Apple, Facebook, Amazon, Baidu, Recruit Inst Technol, Tencent, IBM Res AI, Microsoft, Naver, Line, CVTE, Digital Hlth crc, Nuance, Huawei, Elsevier, Duolingo, ISI NLP, Australian Govt, Dept Def, Sci & Technol, NYU, Kaggle, Zendesk
AB In neural machine translation, a source sequence of words is encoded into a vector from which a target sequence is generated in the decoding phase. Differently from statistical machine translation, the associations between source words and their possible target counterparts are not explicitly stored. Source and target words are at the two ends of a long information processing procedure, mediated by hidden states at both the source encoding and the target decoding phases. This makes it possible that a source word is incorrectly translated into a target word that is not any of its admissible equivalent counterparts in the target language.
   In this paper, we seek to somewhat shorten the distance between source and target words in that procedure, and thus strengthen their association, by means of a method we term bridging source and target word embeddings. We experiment with three strategies: (1) a source-side bridging model, where source word embeddings are moved one step closer to the output target sequence; (2) a target-side bridging model, which explores the more relevant source word embeddings for the prediction of the target sequence; and (3) a direct bridging model, which directly connects source and target word embeddings seeking to minimize errors in the translation of ones by the others.
   Experiments and analysis presented in this paper demonstrate that the proposed bridging models are able to significantly
   [GRAPHICS]
   improve quality of both sentence translation, in general, and alignment and translation of individual source words with target words, in particular.
OI Xiong, Deyi/0000-0002-2353-5038
BN 978-1-948087-32-2
PY 2018
BP 1767
EP 1776
UT WOS:000493904300164
ER

PT J
AU Gao, TT
   Yang, ZX
   Wang, Y
   Jing, L
AF Gao, Tingting
   Yang, Zhixia
   Wang, Yong
   Jing, Ling
TI Identifying translation initiation sites in prokaryotes using support
   vector machine
SO JOURNAL OF THEORETICAL BIOLOGY
AB Motivation: Gene identification in genomes has been a fundamental and long-standing task in bioinformatics and computational biology. Many computational methods have been developed to predict genes in prokaryote genomes by identifying translation initiation site (TIS) in transcript data. However, the pseudo-TISs at the genome level make these methods suffer from a high number of false positive predictions. In addition, most of the existing tools use an unsupervised learning framework, whose predictive accuracy may depend on the choice of specific organism.
   Results: In this paper, we present a supervised learning method, support vector machine (SVM), to identify translation initiation site at the genome level. The features are extracted from the sequence data by modeling the sequence segment around predicted TISs as a position specific weight matrix (PSWM). We train the parameters of our SVM through well constructed positive and negative TIS datasets. Then we apply the method to recognize translation initiation sites in E. coli, B. subtilis, and validate our method on two GC-rich bacteria genomes: Pseudomonas aeruginosa and Burkholderia pseudomallei K96243. We show that translation initiation sites can be recognized accurately at the genome level by our method, irrespective of their GC content. Furthermore, we compare our method with four existing methods and demonstrate that our method outperform these methods by obtaining better performance in all the four organisms. (C) 2009 Published by Elsevier Ltd.
RI Wang, Yong/J-9193-2012
SN 0022-5193
EI 1095-8541
PD FEB 21
PY 2010
VL 262
IS 4
BP 644
EP 649
DI 10.1016/j.jtbi.2009.10.023
UT WOS:000274676700008
PM 19840808
ER

PT C
AU Elbayad, M
   Besacier, L
   Verbeek, J
AF Elbayad, Maha
   Besacier, Laurent
   Verbeek, Jakob
GP Int Speech Commun Assoc
TI Efficient Wait-k Models for Simultaneous Machine Translation
SO INTERSPEECH 2020
SE Interspeech
CT Interspeech Conference
CY OCT 25-29, 2020
CL Shanghai, PEOPLES R CHINA
AB Simultaneous machine translation consists in starting output generation before the entire input sequence is available. Wait-k decoders offer a simple but efficient approach for this problem. They first read k source tokens, after which they alternate between producing a target token and reading another source token. We investigate the behavior of wait-k decoding in low resource settings for spoken corpora using IWSLT datasets. We improve training of these models using unidirectional encoders, and training across multiple values of k. Experiments with Transformer and 2D-convolutional architectures show that our wait-k models generalize well across a wide range of latency levels. We also show that the 2D-convolution architecture is competitive with Transformers for simultaneous translation of spoken language.
SN 2308-457X
PY 2020
BP 1461
EP 1465
DI 10.21437/Interspeech.2020-1241
UT WOS:000833594101123
ER

PT C
AU Stanovsky, G
   Smith, NA
   Zettlemoyer, L
AF Stanovsky, Gabriel
   Smith, Noah A.
   Zettlemoyer, Luke
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Evaluating Gender Bias in Machine Translation
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB We present the first challenge set and evaluation protocol for the analysis of gender bias in machine translation (MD. Our approach uses two recent coreference resolution datasets composed of English sentences which cast participants into non-stereotypical gender roles (e.g., "The doctor asked the nurse to help her in the operation"). We devise an automatic gender bias evaluation method for eight target languages with grammatical gender, based on morphological analysis (e.g., the use of female inflection for the word "doctor"). Our analyses show that four popular industrial MT systems and two recent state-of-the-art academic MT models are significantly prone to gender-biased translation errors for all tested target languages. Our data and code are publicly available at https://github.com/gabrielStanovsky/mt_gender.
OI Stanovsky, Gabriel/0000-0002-2420-8979
BN 978-1-950737-48-2
PY 2019
BP 1679
EP 1684
UT WOS:000493046103018
ER

PT C
AU Tam, YC
   Lei, Y
AF Tam, Yik-Cheung
   Lei, Yun
GP IEEE
TI NEURAL NETWORK JOINT MODELING VIA CONTEXT-DEPENDENT PROJECTION
SO 2015 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING (ICASSP)
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
CT 40th IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP)
CY APR 19-24, 2015
CL Brisbane, AUSTRALIA
SP IEEE, Inst Elect & Elect Engineers Signal Proc Soc
AB Neural network joint modeling (NNJM) has produced huge improvement in machine translation performance. As in standard neural network language modeling, a context-independent linear projection is applied to project a sparse input vector into a continuous representation at each word position. Because neighboring words are dependent on each other, context-independent projection may not be optimal. We propose a context-dependent linear projection approach which considers neighboring words. Experimental results showed that the proposed approach further improves NNJM by 0.5 BLEU for English-Iraqi Arabic translation in N-best rescoring. Compared to a baseline using hierarchical phrases and sparse features, NNJM with our proposed approach has achieved a 2 BLEU improvement.
SN 1520-6149
BN 978-1-4673-6997-8
PY 2015
BP 5356
EP 5360
UT WOS:000427402905095
ER

PT S
AU Gamboa, R
   Cowles, J
AF Gamboa, R
   Cowles, J
BE Slind, K
   Bunker, A
   Gopalakrishnan, G
TI A mechanical proof of the Cook-Levin theorem
SO THEOREM PROVING IN HIGHER ORDER LOGICS, PROCEEDINGS
SE LECTURE NOTES IN COMPUTER SCIENCE
CT 17th International Conference on Theorem Proving in Higher Order Logics
CY SEP 14-17, 2004
CL Pk City, UT
SP INTEL, Natl Sci Fdn
AB As is the case with many theorems in complexity theory, typical proofs of the celebrated Cook-Levin theorem showing the NP-completeness of satisfiability are based on a clever construction. The Cook-Levin theorem is proved by carefully translating a possible computation of a Turing machine into a boolean expression. As the boolean expression is built, it is "obvious" that it can be satisfied if and only if the computation corresponds to a valid and accepting computation of the Turing machine. The details of the argument that the translation works as advertised are usually glossed over; it is the translation itself that is discussed. In this paper, we present a formal proof of the correctness of the translation. The proof is verified with the theorem prover ACL2.
SN 0302-9743
BN 3-540-23017-3
PY 2004
VL 3223
BP 99
EP 116
UT WOS:000224025900008
ER

PT C
AU Choubey, PK
   Currey, A
   Mathur, P
   Dinu, G
AF Choubey, Prafulla Kumar
   Currey, Anna
   Mathur, Prashant
   Dinu, Georgiana
GP Assoc Computat Linguist
TI GFST: Gender-Filtered Self-Training for More Accurate Gender in
   Translation
SO 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2021)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 07-11, 2021
CL Punta Cana, DOMINICAN REP
AB Targeted evaluations have found that machine translation systems often output incorrect gender in translations, even when the gender is clear from context. Furthermore, these incorrectly gendered translations have the potential to reflect or amplify social biases. We propose gender-filtered self-training (GFST) to improve gender translation accuracy on unambiguously gendered inputs. Our GFST approach uses a source monolingual corpus and an initial model to generate gender-specific pseudo-parallel corpora which are then filtered and added to the training data. We evaluate GFST on translation from English into five languages, finding that it improves gender accuracy without damaging generic quality. We also show the viability of GFST on several experimental settings, including re-training from scratch, fine-tuning, controlling the gender balance of the data, forward translation, and back-translation.
BN 978-1-955917-09-4
PY 2021
BP 1640
EP 1654
UT WOS:000855966301056
ER

PT C
AU Wang, Y
   Wang, LY
   Li, VOK
   Tu, ZP
AF Wang, Yong
   Wang, Longyue
   Li, Victor O. K.
   Tu, Zhaopeng
GP Assoc Computat Linguist
TI On the Sparsity of Neural Machine Translation Models
SO PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL
   LANGUAGE PROCESSING (EMNLP)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 16-20, 2020
CL ELECTR NETWORK
SP Bloomberg Engn, Google Res, Apple, Amazon Sci, Baidu, Megagon Labs, Facebook, DeepMind, Grammarly, ByteDance, Zeta Alpha, Babelscape, Naver, Adobe, Hitachi, Salesforce, Univ So Calif, Viterbi Sch Engn, Informat Sci Inst
AB Modern neural machine translation (NMT) models employ a large number of parameters, which leads to serious over-parameterization and typically causes the underutilization of computational resources. In response to this problem, we empirically investigate whether the redundant parameters can be reused to achieve better performance. Experiments and analyses are systematically conducted on different datasets and NMT architectures. We show that: 1) the pruned parameters can be rejuvenated to improve the baseline model by up to +0.8 BLEU points; 2) the rejuvenated parameters are reallocated to enhance the ability of modeling low-level lexical information.
BN 978-1-952148-60-6
PY 2020
BP 1060
EP 1066
UT WOS:000855160701018
ER

PT C
AU Liu, J
AF Liu, Jing
GP IEEE
TI Research on Feature-based Word Automatic Translation Technology in
   Japanese-Chinese Translation System
SO 2019 11TH INTERNATIONAL CONFERENCE ON MEASURING TECHNOLOGY AND
   MECHATRONICS AUTOMATION (ICMTMA 2019)
SE International Conference on Measuring Technology and Mechatronics
   Automation
CT 11th International Conference on Measuring Technology and Mechatronics
   Automation (ICMTMA)
CY APR 28-29, 2019
CL Qiqihar, PEOPLES R CHINA
SP Qiqihar Univ, Sch Comp & Control Engn, Hunan City Univ, Dept Urban Management, Hongkong Intelligent Computat Technol & Automat Assoc
AB For the limitation of terms translation in Japanese-Chinese machine translation system of dictionaries, this paper studies the technology of Japanese-Chinese terms automatic translation. IPC classification information is added to the translation model as a domain information feature of terms, and as one of the features, it participates in the calculation of translation cost. Then, the relative conditional entropy information with word collocation information is taken as a feature and combined with other features to participate in the calculation of translation model, to enhance the distinction between the pros and cons of translation candidates. Finally, an automatic Japanese-Chinese terms translation system based on multi-features is realized. The experimental results show that the terms translation method based on multi-feature fusion is effective. The bilingual terms dictionary can be established with the help of this system, which improves the accuracy of Japanese-Chinese scientific and technological literature translation.
SN 2157-1473
BN 978-1-7281-2165-9
PY 2019
BP 683
EP 687
DI 10.1109/ICMTMA.2019.00156
UT WOS:000591783400150
ER

PT C
AU Halder, M
   Tyagi, AD
AF Halder, Mitali
   Tyagi, Anant Dev
GP IEEE
TI English-Hindi Transliteration by applying finite rules to data before
   training using Statistical Machine Translation
SO 2013 INTERNATIONAL CONFERENCE ON IT CONVERGENCE AND SECURITY (ICITCS)
SE International Conference on IT Convergence and Security
CT 3rd International Conference on IT Convergence and Security (ICITCS)
CY DEC 16-18, 2013
CL Macau, PEOPLES R CHINA
SP IEEE
AB In this paper, we have presented that by applying finite rules of transliteration to the data before training, the transliteration result get remarkably increased. The rules are applied to bilingual corpus of Indian Name Entities with source in English and target in Hindi (Devnagri) script. We have incorporated this concept to an existing machine translation system name Anusaaraka. The efficiency is increased by 29.1 % compared to the system without applying finite rules before training.
SN 2473-0122
BN 978-1-4799-2845-3
PY 2013
UT WOS:000345618800062
ER

PT C
AU Jagfeld, G
   Ziering, P
   van der Plas, L
AF Jagfeld, Glorianna
   Ziering, Patrick
   van der Plas, Lonneke
BE Barzilay, R
   Kan, MY
TI Evaluating Compound Splitters Extrinsically with Textual Entailment
SO PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2
CT 55th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 30-AUG 04, 2017
CL Vancouver, CANADA
SP Alibaba Grp, Amazon, Apple, Baidu, Bloomberg, Facebook, Google, Samsung, Tencent, eBay, Elsevier, IBM Res, KPMG, Maluuba, Microsoft, Naver Line, NEC, Recruit Inst Technol, SAP, Adobe, Bosch, CVTE, Duolingo, Huawei, Nuance, Oracle, Sogou, Grammarly, Toutiao, Yandex
AB Traditionally, compound splitters are evaluated intrinsically on gold-standard data or extrinsically on the task of statistical machine translation. We explore a novel way for the extrinsic evaluation of compound splitters, namely recognizing textual entailment. Compound splitting has great potential for this novel task that is both transparent and well-defined. Moreover, we show that it addresses certain aspects that are either ignored in intrinsic evaluations or compensated for by task-internal mechanisms in statistical machine translation. We show significant improvements using different compound splitting methods on a German textual entailment dataset.
RI van der Plas, Lonneke/AAR-5562-2020
OI van der Plas, Lonneke/0000-0002-2871-2574
BN 978-1-945626-76-0
PY 2017
BP 58
EP 63
DI 10.18653/v1/P17-2010
UT WOS:000493992300010
ER

PT C
AU Cherry, C
   Arivazhagan, N
   Padfield, D
   Krikun, M
AF Cherry, Colin
   Arivazhagan, Naveen
   Padfield, Dirk
   Krikun, Maxim
GP Int Speech Commun Assoc
TI Subtitle Translation as Markup Translation
SO INTERSPEECH 2021
SE Interspeech
CT Interspeech Conference
CY AUG 30-SEP 03, 2021
CL Brno, CZECH REPUBLIC
AB Automatic subtitle translation is an important technology to make video content available across language barriers. Subtitle translation complicates the normal translation problem by adding the challenge of how to format the system output into subtitles. We propose a simple technique that treats subtitle translation as standard sentence translation plus alignment driven markup transfer, which enables us to reliably maintain timing and formatting information from the source subtitles. We also introduce two metrics to measure the quality of subtitle boundaries: a Timed BLEU that penalizes mistimed tokens with respect to a reference subtitle sequence, and a measure of how much Timed BLEU is lost due to suboptimal subtitle boundary placement. In experiments on TED and YouTube subtitles, we show that we are able to achieve much better translation quality than a baseline that translates each subtitle independently, while coming very close to optimal subtitle boundary placement.
SN 2308-457X
PY 2021
BP 2237
EP 2241
DI 10.21437/Interspeech.2021-744
UT WOS:000841879502066
ER

PT J
AU Ren, FL
   Zhu, JB
AF Ren, Feiliang
   Zhu, Jingbo
TI Translating Chinese-English Organization Names With Mix-language Web
   Pages
SO INFORMATION-AN INTERNATIONAL INTERDISCIPLINARY JOURNAL
AB In this paper, we propose a novel Chinese-English organization name translation method with the assistance of mix-language web resources. Firstly, all the implicit out-of-vocabulary terms in the input Chinese organization name are recognized by a CRFs model. Then the input Chinese organization name is translated without considering these recognized out-of-vocabulary terms. Secondly, we construct some efficient queries to find the mix-language web pages that contain both the original input organization name and its correct translation. At last, a similarity matching and limited expansion based translation identification approach is proposed to identify the correct translation from the returned web pages. Experimental results show that our method is effective for Chinese organization name translation and can improve performance of Chinese organization name translation significantly.
SN 1343-4500
EI 1344-8994
PD AUG
PY 2011
VL 14
IS 8
BP 2785
EP 2799
UT WOS:000296935400019
ER

PT C
AU Kim, Y
   Petrov, P
   Petrushkov, P
   Khadivi, S
   Ney, H
AF Kim, Yunsu
   Petrov, Petre
   Petrushkov, Pavel
   Khadivi, Shahram
   Ney, Hermann
GP Assoc Computat Linguist
TI Pivot-based Transfer Learning for Neural Machine Translation between
   Non-English Languages
SO 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND
   THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE
CT Conference on Empirical Methods in Natural Language Processing / 9th
   International Joint Conference on Natural Language Processing
   (EMNLP-IJCNLP)
CY NOV 03-07, 2019
CL Hong Kong, HONG KONG
SP Google, Facebook, Apple, ASAPP, Salesforce, Huawei, Baidu, Deepmind, Amazon, PolyAI, Naver, ByteDance, Megagon Labs, Zhuiyi, Verisk, MI
AB We present effective pre-training strategies for neural machine translation (NMT) using parallel corpora involving a pivot language, i.e., source-pivot and pivot-target, leading to a significant improvement in source -> target translation. We propose three methods to increase the relation among source, pivot, and target languages in the pre-training: 1) step-wise training of a single model for different language pairs, 2) additional adapter component to smoothly connect pre-trained encoder and decoder, and 3) cross-lingual encoder training via autoencoding of the pivot language. Our methods greatly outperform multilingual models up to +2.6% BLEU in WMT 2019 French -> German and German -> Czech tasks. We show that our improvements are valid also in zero-shot/zero-resource scenarios.
RI Pakhlov, Pavel N/K-2158-2013
OI Pakhlov, Pavel N/0000-0001-7426-4824
BN 978-1-950737-90-1
PY 2019
BP 866
EP 876
UT WOS:000854193301002
ER

PT C
AU Othman, A
   Jemni, M
AF Othman, Achraf
   Jemni, Mohamed
BE Miesenberger, K
   Fels, D
   Archambault, D
   Penaz, P
   Zagler, W
TI A Novel Approach for Translating English Statements to American Sign
   Language Gloss
SO COMPUTERS HELPING PEOPLE WITH SPECIAL NEEDS, ICCHP 2014, PT II
SE Lecture Notes in Computer Science
CT 14th International Conference on Computers Helping People with Special
   Needs (ICCHP)
CY JUL 09-11, 2014
CL Univ Paris 8 St Denis, Paris, FRANCE
HO Univ Paris 8 St Denis
AB In this paper, we present a study on the relationship between American Sign Language (ASL) statements and English written texts toward building a statistical machine translation (SMT) using 3D avatar for interpretation. The process included a novel algorithm which transforms an English part-of-speech sentence to ASL-Gloss. The algorithm uses a rule-based approach for building big parallel corpus from English to ASL-Gloss using dependency rules of grammatical parts of the sentence. The parallel corpus will be the input of the translation model of the SMT for ASL. The results we obtained are highly consistent, reproducible, with fairly high precision and accuracy.
RI Jemni, Mohamed/HCI-9541-2022; Othman, Achraf/ABC-5395-2021
OI Jemni, Mohamed/0000-0001-8841-5224; Othman, Achraf/0000-0003-1290-2098
SN 0302-9743
EI 1611-3349
BN 978-3-319-08599-9; 978-3-319-08598-2
PY 2014
VL 8548
BP 431
EP 438
UT WOS:000391218200066
ER

PT J
AU Qiu, L
   Feng, W
AF Qiu, Lu
   Feng, Wei
TI Resolution of English Event Pronouns Based on Machine Learning
SO MOBILE INFORMATION SYSTEMS
AB As the basis of machine translation, anaphora aims to let the machine determine the entity or event to which the sentence refers by exploring the anaphora relationship between sentences. Prior to this, the research on anaphora resolution mainly focused on the resolution of entity anaphora. Through unremitting efforts, the elimination of entity-reference relationship has achieved great success, but the equally important event reference has been stagnant. This means that we can promote the development of machine translation by enhancing event reference. In this paper, a new method is proposed, which uses the latest machine learning algorithm to eliminate English event pronouns. Through feature extraction, data preprocessing, and the introduction of end-to-end double-loop neural network and attention mechanism, the network's ability to acquire contextual features is improved, and finally, the purpose of eliminating English event pronouns is achieved. In the experimental part, this paper also conducts training and testing on the latest data set KBP. It is found that the model algorithm proposed in this paper can perform the task of experimental setup well, and the value of 40.3% F1 is given under CONLL evaluation index. This proves that the model can understand semantic information very effectively and extract relevant information from the given semantic information.
SN 1574-017X
EI 1875-905X
PD AUG 11
PY 2022
VL 2022
AR 8560873
DI 10.1155/2022/8560873
UT WOS:000843315000007
ER

PT C
AU Stoykova, V
AF Stoykova, Velislava
BE Iliadis, L
   Papadopoulos, H
   Jayne, C
TI Representation of Possessive Pronouns in Universal Networking Language
SO ENGINEERING APPLICATIONS OF NEURAL NETWORKS, PT II
SE Communications in Computer and Information Science
CT 14th International Conference on Engineering Applications of Neural
   Networks (EANN)
CY SEP 13-16, 2013
CL Halkidiki, GREECE
AB The paper(1) presents a complex approach to multilingual representation of possessive pronouns information using statistically-based knowledge discovery techniques of Sketch Engine (SE) software. It analyses semantics, grammar features and related ideas, principles and problems for formal representation of possessive pronouns in light of multidisciplinary complexity of the task. The analysis of representation of possessive pronouns for three different languages in frameworks of Universal Networking Language (UNL) is presented with respect to linguistic motivation used for representations and for machine translation.
RI Stoykova, Velislava/AAY-2794-2020; Stoykova, Velislava/A-7394-2010
OI Stoykova, Velislava/0000-0002-5897-9739; 
SN 1865-0929
BN 978-3-642-41015-4
PY 2013
VL 384
BP 129
EP 137
UT WOS:000345333000014
ER

PT C
AU Su, F
   Chen, G
   Xiao, XY
   Su, KL
AF Su, Fei
   Chen, Gang
   Xiao, Xinyan
   Su, Kaile
BE Gelbukh, A
TI Beam-Width Adaptation for Hierarchical Phrase-Based Translation
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING, CICLING 2014,
   PART II
SE Lecture Notes in Computer Science
CT 15th Annual Conference on Intelligent Text Processing and Computational
   Linguistics (CICLing)
CY APR 06-12, 2014
CL Ctr Commun & Dev, Kathmandu, NEPAL
SP Inst Politecnico Nacl Centro Invest Computac Nat Language &Text Proc Lab, Mexican Soc Artificial Intelligence
HO Ctr Commun & Dev
AB In terms of translation quality, hierarchical phrase-based translation model (Hiero) has shown state-of-the-art performance in various translation tasks. However, the slow decoding speed of Hiero prevents it from effective deployment in online scenarios.
   In this paper, we propose beam-width adaptation strategies to speed up Hiero decoding. We learn maximum entropy models to evaluate the quality of each span and then predict the optimal beam-width for it. The empirical studies on Chinese-to-English translation tasks show that, even in comparison with a competitive baseline which employs well designed cube pruning, our approaches still double the decoding speed without compromising translation quality. The approaches have already been applied to an online commercial translation system.
OI Su, Kaile/0000-0001-6741-9699
SN 0302-9743
EI 1611-3349
BN 978-3-642-54902-1; 978-3-642-54903-8
PY 2014
VL 8404
BP 224
EP 232
UT WOS:000342990000019
ER

PT J
AU Blagodarna, O
AF Blagodarna, Olena
TI Insights into post-editors' profiles and post-editing practices
SO TRADUMATICA-TRADUCCIO I TECNOLOGIES DE LA INFORMACIO I LA COMUNICACIO
AB The objective of this paper is to share results of the online survey Post -Editing in Action conducted among language experts currently engaged in the MTPE industry. By filling in an online questionnaire the respondents shared information concerning their professional profiles and day-to-day working routines. The survey outcomes give a richer understanding of the common tendencies - e.g. the use of PE mostly for high quality content - and provide information for tailoring translator training programs.
SN 1578-7559
PD DEC
PY 2018
IS 16
BP 35
EP 51
DI 10.5565/rev/tradumatica.198
UT WOS:000458032900003
ER

PT C
AU Salesky, E
   Sperber, M
   Waibel, A
AF Salesky, Elizabeth
   Sperber, Matthias
   Waibel, Alex
GP Assoc Computat Linguist
TI Fluent Translations from Disfluent Speech in End-to-End Speech
   Translation
SO 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019),
   VOL. 1
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 02-07, 2019
CL Minneapolis, MN
SP Assoc Computat Linguist, N Amer Chapter, Comp Res Assoc, Comp Community Consortium, Natl Sci Fdn, Natl Rees Council Canada, Google
AB Spoken language translation applications for speech suffer due to conversational speech phenomena, particularly the presence of disfluencies. With the rise of end-to-end speech translation models, processing steps such as disfluency removal that were previously an intermediate step between speech recognition and machine translation need to be incorporated into model architectures. We use a sequence-to-sequence model to translate from noisy, disfluent speech to fluent text with disfluencies removed using the recently collected 'copy-edited' references for the Fisher Spanish-English dataset. We are able to directly generate fluent translations and introduce considerations about how to evaluate success on this task. This work provides a baseline for a new task, the translation of conversational speech with joint removal of disfluencies.
BN 978-1-950737-13-0
PY 2019
BP 2786
EP 2792
UT WOS:000900116902096
ER

PT C
AU Zouhar, V
AF Zouhar, Vilem
GP Assoc Computat Linguist
TI Sampling and Filtering of Neural Machine Translation Distillation Data
SO 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021)
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 06-11, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, N Amer Chapter
AB In most of neural machine translation distillation or stealing scenarios, the goal is to preserve the performance of the target model (teacher). The highest-scoring hypothesis of the teacher model is commonly used to train a new model (student). If reference translations are also available, then better hypotheses (with respect to the references) can be upsampled and poor hypotheses either removed or under-sampled.
   This paper explores the importance sampling method landscape (pruning, hypothesis upsampling and undersampling, deduplication and their combination) with English to Czech and English to German MT models using standard MT evaluation metrics. We show that careful upsampling and combination with the original data leads to better performance when compared to training only on the original or synthesized data or their direct combination.
OI Zouhar, Vilem/0000-0001-9874-2069
BN 978-1-954085-50-3
PY 2021
BP 1
EP 8
UT WOS:000856100100001
ER

PT C
AU Pirinen, TA
AF Pirinen, Tommi A.
GP Assoc Computat Linguist
TI Apertium-fin-eng-Rule-based shallow machine translation for WMT 2019
   shared task
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019)
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB In this paper I describe a rule-based, bidirectional machine translation system for the Finnish-English language pair. The original system is based on the existing data of FinnWordNet, omorfi and apertium-eng. I have built the disambiguation, lexical selection and translation rules by hand. The dictionaries and rules have been developed based on the shared task data. I describe in this article the use of the shared task data as a kind of a test-driven development workflow in RBMT development and show that it suits perfectly to a modern software engineering continuous integration workflow of RBMT and yields big increases to BLEU scores with minimal effort. The system described in the article is mainly developed during shared tasks.
BN 978-1-950737-27-7
PY 2019
BP 335
EP 341
UT WOS:000538566200036
ER

PT C
AU Ameur, MSH
   Guessoum, A
   Meziane, F
AF Ameur, Mohamed Seghir Hadj
   Guessoum, Ahmed
   Meziane, Farid
BE Lachkar, A
   Bouzoubaa, K
   Mazroui, A
   Hamdani, A
   Lekhouaja, A
TI A POS-Based Preordering Approach for English-to-Arabic Statistical
   Machine Translation
SO ARABIC LANGUAGE PROCESSING: FROM THEORY TO PRACTICE
SE Communications in Computer and Information Science
CT 6th International Conference on Arabic Language Processing (ICALP)
CY OCT 11-12, 2017
CL Fez, MOROCCO
SP Sidi Mohammed Ben Abdellah Univ, Natl Sch Appl Sci, Arabic Language Engn Soc Morocco, Ctr Natl Rech Sci Tech, Acad Hassan II Sci Tech, Ecole Natl Sci Appliquees Fes, LISA, Fac Sci Tech, Fac Sci Scharia
AB In this work, we present a POS-based preordering approach that tackles both long-and short-distance reordering phenomena. Syntactic unlexicalized reordering rules are automatically extracted from a parallel corpus using only word alignment and a source-side language tagging. The reordering rules are used in a deterministic manner; this prevents the decoding speed from being bottlenecked in the reordering procedure. A new approach for both rule filtering and rule application is used to ensure a fast and efficient reordering. The tests performed on the IWSLT2016 English-to-Arabic evaluation benchmark show a noticeable increase in the overall Blue Score for our system over the baseline PSMT system.
RI Meziane, Farid/ABE-9919-2020; Guessoum, Ahmed/P-3954-2016
OI Meziane, Farid/0000-0001-9811-6914; Guessoum, Ahmed/0000-0003-3876-5204
SN 1865-0929
EI 1865-0937
BN 978-3-319-73500-9; 978-3-319-73499-6
PY 2018
VL 782
BP 34
EP 49
DI 10.1007/978-3-319-73500-9_3
UT WOS:000433974200003
ER

PT C
AU Fukushima, T
   Yoshino, T
   Shigeno, A
AF Fukushima, Taku
   Yoshino, Takashi
   Shigeno, Aguri
BE Konig, A
   Dengel, A
   Hinkelmann, K
   Kise, K
   Howlett, RJ
   Jain, LC
TI Development of Multilingual Interview-Sheet Composition System to
   Support Multilingual Communication in Medical Field
SO KNOWLEDGE-BASED AND INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT
   II: 15TH INTERNATIONAL CONFERENCE, KES 2011
SE Lecture Notes in Computer Science
CT 15th International Conference on Knowledge-Based and Intelligent
   Information and Engineering Systems (KES)
CY SEP 12-14, 2011
CL Univ Kaiserslautern, Kaiserslautern, GERMANY
SP German Res Ctr Artificial Intelligence (DFKI) GmbH, KES Int, Univ Kaiserslautern, Ctr Computat & Math Modeling (CM2), Univ Kaiserslautern, Inst Integrated Sensor Syst, Univ Kaiserslautern, Comp Sci Dept, Chairs Knowledge-Based Syst, Univ Kaiserslautern, Elect & Comp Engn Dept, Integrated Sensor Syst
HO Univ Kaiserslautern
AB Recently, the number of foreign residents and foreign visitors in Japan has been increasing every year. Consequently, the opportunities for communication amongst people whose native languages differ are increasing. In healthcare facilities, a paper-based multilingual interview sheet is used to facilitate communication between medical workers and foreign patients. However, this interview sheet has been found to be inadequate for such purposes. Moreover, Japanese medical workers find it difficult to understand the different languages written on a paper-based interview sheet. To resolve this problem, we have developed a multilingual interview-sheet composition system that uses parallel texts and machine translation. This system can convey essential patient information to a medical worker during consultation. The contributions of this study are as follows: (1) We have proposed a multilingual interview-sheet composition system that can be used for communication between medical workers and foreign patients. We have developed this system using both parallel texts and machine translation. (2) We showed that a patient is able to create a multilingual interview sheet using a parallel corpus and machine translation. (3) Because it may be difficult to indicate an affected area of the body using words alone, we suggest that affected areas be indicated by the user using a human-body image for more accurate communication.
SN 0302-9743
EI 1611-3349
BN 978-3-642-23862-8; 978-3-642-23863-5
PY 2011
VL 6882
BP 31
EP 40
UT WOS:000306461000004
ER

PT C
AU El Marouani, M
   Boudaa, T
   Enneya, N
AF El Marouani, Mohamed
   Boudaa, Tarik
   Enneya, Nourddine
BE Tabii, Y
   Lazaar, M
   AlAchhab, M
   Enneya, N
TI Incorporation of Linguistic Features in Machine Translation Evaluation
   of Arabic
SO BIG DATA, CLOUD AND APPLICATIONS, BDCA 2018
SE Communications in Computer and Information Science
CT 3rd International Conference on Big Data Cloud and Applications (BDCA)
CY APR 04-05, 2018
CL Kenitra, MOROCCO
SP Abdelmalek Essaadi Univ, IbnTofail Univ
AB This paper describes a study on the contribution of some basic linguistic features to the task of machine translation evaluation of Arabic as a target language. AL-TERp is used as a metric dedicated and tuned especially for Arabic. Performed experiments on a medium sized corpora show that linguistic knowledge improves the correlation of metric results with human assessments. Also a detailed qualitative analysis of the results highlights a number of resolved issues related to the use of linguistic features.
OI BOUDAA, Tarik/0000-0003-3526-7488
SN 1865-0929
EI 1865-0937
BN 978-3-319-96292-4; 978-3-319-96291-7
PY 2018
VL 872
BP 500
EP 511
DI 10.1007/978-3-319-96292-4_39
UT WOS:000460586700039
ER

PT C
AU Oda, Y
   Neubig, G
   Sakti, S
   Toda, T
   Nakamura, S
AF Oda, Yusuke
   Neubig, Graham
   Sakti, Sakriani
   Toda, Tomoki
   Nakamura, Satoshi
BE Zong, C
   Strube, M
TI Syntax-based Simultaneous Translation through Prediction of Unseen
   Syntactic Constituents
SO PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON
   NATURAL LANGUAGE PROCESSING, VOL 1
CT 53rd Annual Meeting of the Association-for-Computational-Linguistics
   (ACS) / 7th International Joint Conference on Natural Language
   Processing of the Asian-Federation-of-Natural-Language-Processing
   (IJCNLP)
CY JUL 26-31, 2015
CL Beijing, PEOPLES R CHINA
SP Assoc Computat Linguist, Asian Federat Nat Language Proc, CreditEase, Baidu, Tencent, Alibaba Grp, Samsung, Microsoft, Google, Facebook, SinoVoice, Huawei, Nuance, Amazon, Voicebox Technologies, Baobab, Sogou
AB Simultaneous translation is a method to reduce the latency of communication through machine translation (MT) by dividing the input into short segments before performing translation. However, short segments pose problems for syntax-based translation methods, as it is difficult to generate accurate parse trees for sub-sentential segments. In this paper, we perform the first experiments applying syntax-based SMT to simultaneous translation, and propose two methods to prevent degradations in accuracy: a method to predict unseen syntactic constituents that help generate complete parse trees, and a method that waits for more input when the current utterance is not enough to generate a fluent translation. Experiments on English-Japanese translation show that the proposed methods allow for improvements in accuracy, particularly with regards to word order of the target sentences.
OI Toda, Tomoki/0000-0001-8146-1279
BN 978-1-941643-72-3
PY 2015
BP 198
EP 207
UT WOS:000493808900020
ER

PT C
AU Mu, YQ
   Tan, XS
   Xiang, W
AF Mu, Yu Quan
   Tan, Xiao Su
   Xiang, Wei
GP IEEE
TI Implementation of Minority Language Translation System Based on Android
SO 2019 4TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND
   APPLICATIONS (ICCIA 2019)
CT 4th IEEE International Conference on Computational Intelligence and
   Applications (ICCIA)
CY JUN 21-23, 2019
CL Nanchang, PEOPLES R CHINA
SP IEEE
AB This paper designs a minority language translation system based on Android, which combines the development technology of TensorFlow building neural network. In addition, the Python-based flask framework helps us achieve data transmission, so that the translation of minority languages into Chinese or Chinese into minority languages, and in the form of deep learning, the above system can be used in practical applications to solve the communication barriers between ethnic minority areas and language lovers. We try to use the LSTM algorithm to realize the background translation of the system, and by comparing the translation results with the original text, we find that the translation results have a certain quality improvement over the traditional machine translation, rather than rigid mechanical translation. Therefore, it is hoped that a good translation system of minority languages can be realized.
BN 978-1-7281-2128-4
PY 2019
BP 93
EP 97
DI 10.1109/ICCIA.2019.00025
UT WOS:000604615900018
ER

PT C
AU Zheng, RJ
   Ma, MB
   Huang, L
AF Zheng, Renjie
   Ma, Mingbo
   Huang, Liang
GP Assoc Computat Linguist
TI Multi-Reference Training with Pseudo-References for Neural Translation
   and Text Generation
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB Neural text generation, including neural machine translation, image captioning, and summarization, has been quite successful recently. However, during training time, typically only one reference is considered for each example, even though there are often multiple references available, e.g., 4 references in NIST MT evaluations, and 5 references in image captioning data. We first investigate several different ways of utilizing multiple human references during training. But more importantly, we then propose an algorithm to generate exponentially many pseudo-references by first compressing existing human references into lattices and then traversing them to generate new pseudo-references. These approaches lead to substantial improvements over strong baselines in both machine translation (+1.5 BLEU) and image captioning (+3.1 BLEU / +11.7 CIDEr).
BN 978-1-948087-84-1
PY 2018
BP 3188
EP 3197
UT WOS:000865723403046
ER

PT C
AU Garcia, M
   Gimenez, J
   Marquez, L
AF Garcia, Miguel
   Gimenez, Jesus
   Marquez, Lluis
BE Gelbukh, A
TI Enriching Statistical Translation Models Using a Domain-Independent
   Multilingual Lexical Knowledge Base
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING
SE Lecture Notes in Computer Science
CT 10th International Conference on Intelligent Text Processing and
   Computational Linguistics
CY MAR 01-07, 2009
CL Mexico City, MEXICO
SP Natl Polytechn Inst, Ctr Comput Res, Nat Language & Text Processing, Mexican Soc Artificial Intelligence
AB This paper presents a method for improving phrase-based Statistical Machine Translation systems by enriching the original translation model with information derived from a multilingual lexical knowledge base. The method proposed exploits the Multilingual Central Repository (a group of linked WordNets from different languages). as a domain-independent knowledge database, to provide translation models with new possible translations for a large set of lexical tokens. Translation probabilities for these tokens are estimated using a set of simple heuristics based on WordNet topology and local context. During decoding, these probabilities are softly integrated so they can interact with other statistical models. We have applied this type of domain-independent translation modeling to several translation tasks obtaining a moderate but significant improvement in translation quality consistently according to a number of standard automatic evaluation metrics. This improvement is especially remarkable when we move to a very different domain, such as the translation of Biblical texts.
SN 0302-9743
EI 1611-3349
BN 978-3-642-00381-3
PY 2009
VL 5449
BP 306
EP 317
UT WOS:000265681200025
ER

PT C
AU Motazedi, Y
   Shamsfard, M
AF Motazedi, Yasaman
   Shamsfard, Mehnoush
GP IEEE
TI English to Persian Machine Translation exploiting Semantic Word Sense
   Disambiguation
SO 2009 14TH INTERNATIONAL COMPUTER CONFERENCE
CT 14th International Computer Conference
CY OCT 20-21, 2009
CL Tehran, IRAN
AB PEnT1 is an automatic English to Persian text translator. It translates simple English sentences into Persian, exploiting a combination of rule based and semantic approaches. It covers all the twelve tenses in English in both passive and active verbs for indicative, negative, interrogative sentences. In this paper, introducing PEnT1, we propose a new WSD method by presenting a hybrid measure to score different senses of a word. We also discuss prototyping some linguistic resources to test our methods.
BN 978-1-4244-4261-4
PY 2009
BP 252
EP +
UT WOS:000282068100043
ER

PT C
AU Feili, H
   Ghassem-Sani, G
AF Feili, H
   Ghassem-Sani, G
BE LopezdeMantaras, R
   Saitta, L
TI An application of lexicalized grammars in English-Persian translation
SO ECAI 2004: 16TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE,
   PROCEEDINGS
SE FRONTIERS IN ARTIFICIAL INTELLIGENCE AND APPLICATIONS
CT 16th European Conference on Artificial Intelligence
CY AUG 22-27, 2004
CL Valencia, SPAIN
SP European Coordinating Comm Artificial Intelligence, Asoc Espanola Inteligencia Artificial, Assoc Catalana Intelligencia Artificial, Univ Politecn Valencia, Grp Tecnol Informat
AB Increasing the domain of locality by using Tree Adjoining Grammars (TAG) caused some applications, such as machine translation, to employ it for the disambiguation process. Successful experiments of employing TAG in French-English and Korean-English machine translation encouraged us to use it for another language pairs with very divergent properties, Persian and English. Using Synchronous TAG (S-TAG) for this pair of languages can benefit from syntactic and semantic features for transferring the source into the target language. Here, we report our experiments in translating English into Persian. Also, we present a model for lexical selection disambiguation based on the decision trees notion. An automatic learning method of the required decision trees from a sample data set is introduced, too.
SN 0922-6389
BN 1-58603-452-9
PY 2004
VL 110
BP 596
EP 600
UT WOS:000225505100116
ER

PT S
AU Holland, M
   Schlesiger, C
   Tate, C
AF Holland, M
   Schlesiger, C
   Tate, C
BE White, JS
TI Evaluating embedded machine translation in military field exercises
SO ENVISIONING MACHINE TRANSLATION IN THE INFORMATION FUTURE, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
CT 4th Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 10-14, 2000
CL CUERNAVACA, MEXICO
SP Assoc Machine Translat Americas
AB "Embedded" machine translation (MT) refers to an end-to-end computational process of which MT is one of the components. Integrating these components and evaluating the whole has proved to be problematic. As an example of embedded MT, we describe a prototype system called Falcon, which permits paper documents to be scanned and translated into English. MT is thus embedded in the preprocessing of hardcopy pages and subject to its noise. Because Falcon is intended for use by people in the military who are trying to screen foreign documents, and not to understand them in detail, its application makes low demands on translation quality. We report on a series of user trials that speak to the utility of embedded MT in army tasks.
SN 0302-9743
EI 1611-3349
BN 3-540-41117-8
PY 2000
VL 1934
BP 239
EP 247
UT WOS:000174952300027
ER

PT C
AU Xu, J
   Zhang, XY
   Urban, C
AF Xu, Jian
   Zhang, Xingyuan
   Urban, Christian
BE Blazy, S
   PaulinMohring, C
   Pichardie, D
TI Mechanising Turing Machines and Computability Theory in Isabelle/HOL
SO INTERACTIVE THEOREM PROVING, ITP 2013
SE Lecture Notes in Computer Science
CT 4th International Conference on Interactive Theorem Proving (ITP)
CY JUL 22-26, 2013
CL Rennes, FRANCE
SP Inria, Univ Rennes 1, SISCom Bretagne, Rennes Metropole, Reg Bretagne
AB We formalise results from computability theory in the theorem prover Isabelle/HOL. Following the textbook by Boolos et al, we formalise Turing machines and relate them to abacus machines and recursive functions. We "tie the know" between these three computational models by formalising a universal function and obtaining from it a universal Turing machine by our verified translation from recursive functions to abacus programs and from abacus programs to Turing machine programs. Hoare-style reasoning techniques allow us to reason about concrete Turing machine and abacus programs.
SN 0302-9743
EI 1611-3349
BN 978-3-642-39634-2
PY 2013
VL 7998
BP 147
EP 162
UT WOS:000412581700013
ER

PT C
AU Lim, H
AF Lim, Hajin
GP ACM
TI Design for Computer-Mediated Multilingual Communication with AI Support
SO COMPANION OF THE 2018 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE
   WORK AND SOCIAL COMPUTING (CSCW'18)
CT ACM Conference on Computer Supported Cooperative Work and Social
   Computing (CSCW)
CY NOV 03-07, 2018
CL Jersey City, NJ
SP Assoc Comp Machinery, ACM SIGCHI, Facebook, IBM, Underwood Inst
AB Machine translation is often not enough for people to engage across languages due to translation errors and lack of cultural background. In addressing these challenges, my dissertation explores how AI-augmented analytics can improve computer-mediated communication between speakers of different native languages. First, to support better sense making of foreign language posts in social media, I designed SenseTrans, a tool that adds contextual information using AI-analytics such as sentiment analysis. In my future work, I intend to explore 1) how people perceive, interpret and make use of AI-generated information, and 2) how AI-augmented analytics could be applied to other settings.
BN 978-1-4503-6018-0
PY 2018
BP 93
EP 96
DI 10.1145/3272973.3272982
UT WOS:000482113000024
ER

PT C
AU Bell, P
   Lai, C
   Llewellyn, C
   Birch, A
   Sinclair, M
AF Bell, Peter
   Lai, Catherine
   Llewellyn, Clare
   Birch, Alexandra
   Sinclair, Mark
GP ISCA-INT SPEECH COMMUN ASSOC
TI A system for automatic broadcast news summarisation, geolocation and
   translation
SO 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2015), VOLS 1-5
CT 16th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2015)
CY SEP 06-10, 2015
CL Dresden, GERMANY
SP NISCAN, TU Berlin, TUBS Sci Mkt, EZ Alibaba Grp, Telekon Innovat Lab, Google, Amazon Echo, Facebook, Microsoft, Citrix, Datamall, NXP Software, E Sigma, ELRA, European Media Lab GmbH, EML, Nuance, Linguwerk, Speech Ocean
AB An increasing amount of news content is produced in audio video form every day. To effectively analyse and monitoring this multilingual data stream, we require methods to extract and present audio content in accessible ways. In this paper, we describe an end-to-end system for processing and browsing audio news data. This fully automated system brings together our recent research on audio scene analysis, speech recognition, summarisation, named entity detection, geolocation, and machine translation. The graphical interface allows users to visualise the distribution of news content by entity names and story location. Browsing of news events is facilitated through extractive summaries and the ability to view transcripts in multiple languages.
BN 978-1-5108-1790-6
PY 2015
BP 730
EP 731
UT WOS:000380581600152
ER

PT C
AU Ore, B
   Hansen, E
   Anderson, T
   Gwinnup, J
AF Ore, Brian
   Hansen, Eric
   Anderson, Timothy
   Gwinnup, Jeremy
GP Assoc Comp Linguist
TI The AFRL IWSLT 2020 Systems: Work-From-Home Edition
SO 17TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE TRANSLATION (IWSLT
   2020)
CT 17th International Conference on Spoken Language Translation (IWSLT)
CY JUL 09-10, 2020
CL ELECTR NETWORK
AB This report summarizes the Air Force Research Laboratory (AFRL) submission to the offline spoken language translation (SLT) task as part of the IWSLT 2020 evaluation campaign. As in previous years, we chose to adopt the cascade approach of using separate systems to perform speech activity detection, automatic speech recognition, sentence segmentation, and machine translation. All systems were neural based, including a fully-connected neural network for speech activity detection, a Kaldi factorized time delay neural network with recurrent neural network (RNN) language model rescoring for speech recognition, a bidirectional RNN with attention mechanism for sentence segmentation, and transformer networks trained with OpenNMT and Marian for machine translation. Our primary submission yielded BLEU scores of 21.28 on t st2019 and 23.33 on tst2020.
BN 978-1-952148-07-1
PY 2020
BP 103
EP 108
UT WOS:000563427100011
ER

PT C
AU Wang, WY
   Yang, ZJ
   Gao, YB
   Ney, EM
AF Wang, Weiyue
   Yang, Zijian
   Gao, Yingbo
   Ney, Hermann
GP Assoc Computat Linguist
TI Transformer-Based Direct Hidden Markov Model for Machine Translation
SO ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON
   NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE STUDENT RESEARCH
   WORKSHOP
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB The neural hidden Markov model has been proposed as an alternative to attention mechanism in machine translation with recurrent neural networks. However, since the introduction of the transformer models, its performance has been surpassed. This work proposes to introduce the concept of the hidden Markov model to the transformer architecture, which outperforms the transformer baseline. Interestingly, we find that the zero-order model already provides promising performance, giving it an edge compared to a model with first-order dependency, which performs similarly but is significantly slower in training and decoding.
RI YANG, ZIJIAN/GRS-4433-2022; Wang, Weiyue/HIZ-8247-2022
OI Wang, Weiyue/0000-0002-9127-7544
BN 978-1-954085-55-8
PY 2021
BP 23
EP 32
UT WOS:000694722600003
ER

PT C
AU Nishimura, K
   Kawanami, H
   Saruwatari, H
   Shikano, K
AF Nishimura, Kazuma
   Kawanami, Hiromichi
   Saruwatari, Hiroshi
   Shikano, Kiyohiro
GP IEEE
TI Response Generation based on Statistical Machine Translation for
   Speech-Oriented Guidance System
SO 2012 ASIA-PACIFIC SIGNAL AND INFORMATION PROCESSING ASSOCIATION ANNUAL
   SUMMIT AND CONFERENCE (APSIPA ASC)
SE Asia-Pacific Signal and Information Processing Association Annual Summit
   and Conference
CT Annual Summit and Conference of the
   Asia-Pacific-Signal-and-Information-Processing-Association (APSIPA)
CY DEC 03-06, 2012
CL Hollywood, CA
SP Asia Pacific Signal & Informat Proc Assoc (APSIPA)
AB An example-based response generation is a robust and practical approach for a real-environment information guidance system. However, this framework cannot reflect differences in nuance, because the set of answer sentences are fixed beforehand. To overcome this issue, we have proposed response generation using a statistical machine translation technique. In this paper, we make use of N-best speech recognition candidates instead of manual transcription used in our previous study. As a result, the generation rate of appropriate response sentences was improved by using multiple recognition hypothesis.
SN 2309-9402
BN 978-1-4673-4863-8
PY 2012
UT WOS:000319456200057
ER

PT S
AU Liu, Q
   Yu, SW
AF Liu, Q
   Yu, SW
BE Farwell, D
   Gerber, L
   Hovy, E
TI TransEasy: A Chinese-English machine translation system based on hybrid
   approach
SO MACHINE TRANSLATION AND THE INFORMATION SOUP
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
CT 3rd Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 28-31, 1998
CL LANGHORNE, PENNSYLVANIA
SP Systran Inc, Logos Corp, Globalink Inc, Univ Penn Inst Res Cognitive Sci
AB This paper describes the progress of a machine translation system from Chinese to English. The system is based on a reusable platform of MT software components. It's a rule-based system, and some statistical algorithms are used as heuristic functions in parsing as well. There are about 50,000 Chinese words and 100 global parsing rules in the system. The system got a good result in a public test of MT system in China in Mar. 1998. It is a research vehicle up to now.
SN 0302-9743
BN 3-540-65259-0
PY 1998
VL 1529
BP 514
EP 517
UT WOS:000086659400049
ER

PT C
AU Li, W
   Mak, B
AF Li, Wei
   Mak, Brian
GP Int Speech Commun Assoc
TI Fast Derivation of Cross-lingual Document Vectors from Self-attentive
   Neural Machine Translation Model
SO 19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING
   MARKETS IN MULTILINGUAL SOCIETIES
SE Interspeech
CT 19th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2018)
CY AUG 02-SEP 06, 2018
CL Hyderabad, INDIA
SP Int Speech Commun Assoc
AB A universal cross-lingual representation of documents, which can capture the underlying semantics is very useful in many natural language processing tasks. In this paper, we develop a new document vectorization method which effectively selects the most salient sequential patterns from the inputs to create document vectors via a self-attention mechanism using a neural machine translation (NMT) model. The model used by our method can be trained with parallel corpora that are unrelated to the task at hand. During testing, our method will take a monolingual document and convert it into a "Neural machine Translation framework based cross-lingual Document Vector" (NTDV). NTDV has two comparative advantages. Firstly. the NTDV can be produced by the forward-pass of the encoder in the NMT, and the process is very fast and does not require any training/optimization. Secondly, our model can be conveniently adapted from a pair of existing attention-based NMT models, and the training requirement on parallel corpus can be reduced significantly. In a cross-lingual document classification task, our NTDV embeddings surpass the previous stateof-the-art performance in the English-to-German classification test, and, to our best knowledge, it also achieves the best performance among the fast decoding methods in the German-to English classification test.
SN 2308-457X
BN 978-1-5108-7221-9
PY 2018
BP 107
EP 111
UT WOS:000465363900022
ER

PT J
AU Raulji, JK
   Saini, JR
   Pal, K
   Kotecha, K
AF Raulji, Jaideepsinh K.
   Saini, Jatinderkumar R.
   Pal, Kaushika
   Kotecha, Ketan
TI A Novel Framework for Sanskrit-Gujarati Symbolic Machine Translation
   System
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
AB Sanskrit falls under the Indo-European language family category. Gujarati, which has descended from the Sanskrit language, is a widely spoken language particularly in the Indian state of Gujarat. The proposed and realized Machine Translation framework uses a grammatical transfer approach to translate the written Sanskrit language to Gujarati. Because both languages are morphologically rich, studying the morphology of each item is difficult but necessary to incorporate into implementation. To improve the implementation accuracy and translation clarity, an in-depth research of the creation of Nouns, Verbs, Pronouns, and Indeclinables, as well as their mappings, has been carried out. Gujarati bilingual synonym-based dictionary, language synthesis, and transliteration are the proposed framework's primary components. The implementation outcome was tested on 1,000 phrases, using the automated Bilingual Evaluation Understudy (BLEU) scale which yielded a value of 58.04 It was also tested on the ALPAC scale, yielding the Intelligibility score of 69.16 and the Fidelity score of 68.11. The results are encouraging and prove that the proposed system is promising and robust for the implementation in the real world applications.
RI Saini, Jatinderkumar R./M-5584-2013; Kotecha, K/U-3927-2017
OI Saini, Jatinderkumar R./0000-0001-5205-5263; Kotecha,
   K/0000-0003-2653-3780
SN 2158-107X
EI 2156-5570
PD APR
PY 2022
VL 13
IS 4
BP 374
EP 380
UT WOS:000798659100001
ER

PT J
AU Tan, ZX
   Su, JS
   Wang, BL
   Chen, YD
   Shi, XD
AF Tan, Zhixing
   Su, Jinsong
   Wang, Boli
   Chen, Yidong
   Shi, Xiaodong
TI Lattice-to-sequence attentional Neural Machine Translation models
SO NEUROCOMPUTING
AB The dominant Neural Machine Translation (NMT) models usually resort to word-level modeling to embed input sentences into semantic space. However, it may not be optimal for the encoder modeling of NMT, especially for languages where tokenizations are usually ambiguous: On one hand, there may be tokenization errors which may negatively affect the encoder modeling of NMT. On the other hand, the optimal tokenization granularity is unclear for NMT. In this paper, we propose lattice-to-sequence attentional NMT models, which generalize the standard Recurrent Neural Network (RNN) encoders to lattice topology. Specifically, they take as input a word lattice which compactly encodes many tokenization alternatives, and learn to generate the hidden state for the current step from multiple inputs and hidden states in previous steps. Compared with the standard RNN encoder, the proposed encoders not only alleviate the negative impact of tokenization errors but are more expressive and flexible as well for encoding the meaning of input sentences. Experimental results on both Chinese-English and Japanese-English translations demonstrate the effectiveness of our models. (C) 2018 Elsevier B.V. All rights reserved.
OI Shi, Xiaodong/0000-0002-8163-7139
SN 0925-2312
EI 1872-8286
PD APR 5
PY 2018
VL 284
BP 138
EP 147
DI 10.1016/j.neucom.2018.01.010
UT WOS:000425883300015
ER

PT C
AU Yao, JM
   Sun, J
   Guo, L
   Zhu, QM
AF Yao, Jian-Min
   Sun, Jun
   Guo, Lei
   Zhu, Qiao-Ming
BE Ho, TB
   Zhou, ZH
TI Query Classification and Expansion for Translation Mining Via Search
   Engines
SO PRICAI 2008: TRENDS IN ARTIFICIAL INTELLIGENCE
SE Lecture Notes in Artificial Intelligence
CT 10th Pacific Rim International Conference on Artificial Intelligence
   (PRICAI 2008)
CY DEC 15-19, 2008
CL Hanoi, VIETNAM
SP Vietnamese Acad Sci & Technol, Minist Sci & Technol Vietnam, Hanoi Univ Technol, Vietnam Natl Univ, Air Force Off Sci Res, Asian Off Aerosp Res & Dev
AB Out-of-vocabulary lexicons, including new words, collocations, as well as phrases, are the key flesh of a human language while an obstacle to machine translation. But the translation of OOV is quite difficult to obtain. A web-mining solution to the OOV translation is adopted in our research. The basic assumption lies in that most of the OOV's translations exist on the web, and search engines can provide many web pages containing the OOV and corresponding translations. We mine the translation from returned snippets of the search engine with expanded OOV as the query term. The difference of our method from other methods lies in that a query classification is made before submitting to the search engine. Experiment shows our solution can discover the translation to many of the OOVs with quite high precision.
SN 0302-9743
EI 1611-3349
BN 978-3-540-89196-3
PY 2008
VL 5351
BP 1121
EP 1126
UT WOS:000262624600113
ER

PT J
AU Yu, ZQ
   Huang, YX
   Guo, JJ
AF Yu, Zhiqiang
   Huang, Yuxin
   Guo, Junjun
TI Improving thai-lao neural machine translation with similarity lexicon
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
AB It has been shown that the performance of neural machine translation (NMT) drops starkly in low-resource conditions. Thai-Lao is a typical low-resource language pair of tiny parallel corpus, leading to suboptimal NMT performance on it. However, Thai and Lao have considerable similarities in linguistic morphology and have bilingual lexicon which is relatively easy to obtain. To use this feature, we first build a bilingual similarity lexicon composed of pairs of similar words. Then we propose a novel NMT architecture to leverage the similarity between Thai and Lao. Specifically, besides the prevailing sentence encoder, we introduce an extra similarity lexicon encoder into the conventional encoder-decoder architecture, by which the semantic information carried by the similarity lexicon can be represented. We further provide a simple mechanism in the decoder to balance the information representations delivered from the input sentence and the similarity lexicon. Our approach can fully exploit linguistic similarity carried by the similarity lexicon to improve translation quality. Experimental results demonstrate that our approach achieves significant improvements over the state-of-the-art Transformer baseline system and previous similar works.
SN 1064-1246
EI 1875-8967
PY 2022
VL 42
IS 4
BP 4005
EP 4014
DI 10.3233/JIFS-212236
UT WOS:000771196600077
ER

PT J
AU Waardenburg, L
   Huysman, M
   Sergeeva, AV
AF Waardenburg, Lauren
   Huysman, Marleen
   Sergeeva, Anastasia V.
TI In the Land of the Blind, the One-Eyed Man Is King: Knowledge Brokerage
   in the Age of Learning Algorithms
SO ORGANIZATION SCIENCE
AB This paper presents research on how knowledge brokers attempt to translate opaque algorithmic predictions. The research is based on a 31-month ethnographic study of the implementation of a learning algorithm by the Dutch police to predict the occurrence of crime incidents and offers one of the first empirical accounts of algorithmic brokers. We studied a group of intelligence officers, who were tasked with brokering between a machine learning community and a user community by translating the outcomes of the learning algorithm to police management. We found that, as knowledge brokers, they performed different translation practices over time and enacted increasingly influential brokerage roles, namely, those of messenger, interpreter, and curator. Triggered by an impassable knowledge boundary yielded by the black-boxed machine learning, the brokers eventually acted like "kings in the land of the blind" and substituted the algorithmic predictions with their own judgments. By emphasizing the dynamic and influential nature of algorithmic brokerage work, we contribute to the literature on knowledge brokerage and translation in the age of learning algorithms.
RI Sergeeva, Anastasia/CAJ-0224-2022; Waardenburg, Lauren/HHN-5833-2022
OI Waardenburg, Lauren/0000-0002-9538-1824; Sergeeva,
   Anastasia/0000-0001-6599-1982; huysman, marleen/0000-0002-9005-8200
SN 1047-7039
PD JAN-FEB
PY 2022
VL 33
IS 1
BP 59
EP 82
AR 12
DI 10.1287/orsc.2021.1544
EA NOV 2021
UT WOS:000731935900001
ER

PT J
AU Buet, F
   Yvon, F
AF Buet, Francois
   Yvon, Francois
TI Automatic subtitling: study of adaptation strategies to television
   genres
SO TRAITEMENT AUTOMATIQUE DES LANGUES
AB Interest in automatic closed captioning systems has risen on account of legal obli-gations concerning accessibility and the sheer amount of audiovisual content being produced by multiple sources. Such systems usually proceed by coupling Automatic Speech Recognition (ASR) and Machine Translation (MT) from transcript to captions. The "translation " task con-sist of a simplification and segmentation of the text, which must observe norms with respect to display, while handling ASR errors. In the case of TV shows, both the initial audio stream and the target captions vary significantly in form and content according to the program. Taking inspiration in MT literature, this paper implements and compare televisual genre adaptation methods for closed captioning.
SN 1248-9433
EI 1965-0906
PY 2022
VL 63
IS 1
BP 11
EP 35
DI 10.4573/TAL.9748
UT WOS:000914896500002
ER

PT J
AU Yun, S
   Lee, YJ
   Kim, SH
AF Yun, Seung
   Lee, Young-Jik
   Kim, Sang-Hun
TI Multilingual Speech-to-Speech Translation System for Mobile Consumer
   Devices
SO IEEE TRANSACTIONS ON CONSUMER ELECTRONICS
AB Along with the advancement of speech recognition technology and machine translation technology in addition to the fast distribution of mobile devices, speech-to-speech translation technology no longer remains as a subject of research as it has become popularized throughout many users. In order to develop a speech-to-speech translation system that can be widely used by many users, however, the system needs to reflect various characteristics of utterances by the users who are actually to use the speech-to-speech translation system other than improving the basic functions under the experimental environment. This study has established a massive language and speech database closest to the environment where speech-to-speech translation device actually is being used after mobilizing plenty of people based on the survey on users' demands. Through this study, it was made possible to secure excellent basic performance under the environment similar to speech-to-speech translation environment, rather than just under the experimental environment. Moreover, with the speech-to-speech translation UI, a user-friendly UI has been designed; and at the same time, errors were reduced during the process of translation as many measures to enhance user satisfaction were employed. After implementing the actual services, the massive database collected through the service was additionally applied to the system following a filtering process in order to procure the best-possible robustness toward both the details and the environment of the users' utterances. By applying these measures, this study is to unveil the procedures where multi-language speech-to-speech translation system has been successfully developed for mobile devices(1).
SN 0098-3063
EI 1558-4127
PD AUG
PY 2014
VL 60
IS 3
BP 508
EP 516
DI 10.1109/TCE.2014.6937337
UT WOS:000344364700028
ER

PT J
AU Andreou, AZ
   Harms, U
   Krause, L
   Klostermeier, D
AF Andreou, Alexandra Z.
   Harms, Ulf
   Krause, Linda
   Klostermeier, Dagmar
TI Dissecting Structure, Function and Dynamics of Molecular Machines by
   Single-Molecule FRET Microscopy: Translation Initiation is Regulated
   through Modulation of the Conformational Dynamics of the Dead-Box
   Protein eIF4A
SO BIOPHYSICAL JOURNAL
CT 64th Annual Meeting of the Biophysical-Society
CY FEB 15-19, 2020
CL San Diego, CA
SP Biophys Soc
SN 0006-3495
EI 1542-0086
PD FEB 7
PY 2020
VL 118
IS 3
SU 1
MA 2673-Pos
BP 546A
EP 546A
UT WOS:000513023203471
ER

PT C
AU Wu, XQ
   Wang, LW
   Xia, YC
   Liu, WQ
   Wu, LJ
   Xie, SF
   Qin, T
   Liu, TY
AF Wu, Xueqing
   Wang, Lewen
   Xia, Yingce
   Liu, Weiqing
   Wu, Lijun
   Xie, Shufang
   Qin, Tao
   Liu, Tie-Yan
BE Meila, M
   Zhang, T
TI Temporally Correlated Task Scheduling for Sequence Learning
SO INTERNATIONAL CONFERENCE ON MACHINE LEARNING, VOL 139
SE Proceedings of Machine Learning Research
CT International Conference on Machine Learning (ICML)
CY JUL 18-24, 2021
CL ELECTR NETWORK
AB Sequence learning has attracted much research attention from the machine learning community in recent years. In many applications, a sequence learning task is usually associated with multiple temporally correlated auxiliary tasks, which are different in terms of how much input information to use or which future step to predict. For example, (i) in simultaneous machine translation, one can conduct translation under different latency (i.e., how many input words to read/wait before translation); (ii) in stock trend forecasting, one can predict the price of a stock in different future days (e.g., tomorrow, the day after tomorrow). While it is clear that those temporally correlated tasks can help each other, there is a very limited exploration on how to better leverage multiple auxiliary tasks to boost the performance of the main task. In this work, we introduce a learnable scheduler to sequence learning, which can adaptively select auxiliary tasks for training depending on the model status and the current training data. The scheduler and the model for the main task are jointly trained through bi-level optimization. Experiments show that our method significantly improves the performance of simultaneous machine translation and stock trend forecasting.
SN 2640-3498
PY 2021
VL 139
UT WOS:000768182701034
ER

PT S
AU Navarrete, D
   Davila, R
   Sanchez, A
AF Navarrete, D
   Davila, R
   Sanchez, A
BE Cairo, O
   Sucar, LE
   Cantu, FJ
TI A specific domain translator application in a floristic Digital Library
SO MICAI 2000: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
CT Mexican International Conference on Artificial Intelligence (MICAI 2000)
CY APR 11-14, 2000
CL ACAPULCO, MEXICO
SP Mexican Soc Artificial Intelligence, Acapulco Inst Technol, Amer Assoc Artificial Intelligence, Int Joint Conf Artificial Intelligence, Mexican Soc Comp Sci, CONACYT REDII
AB In this paper, SAVIA is introduced; a system for attaining automatic translation (English-to-Spanish) of morphological descriptions of plants. It was developed at Universidad de las Americas Puebla, as part of a collaborative research with the Flora of North America (FNA) project, currently under construction at the Missouri Botanical Garden [Schnase et al. 1994]. The system has been put forward as a potential solution to the problem of knowledge distribution and multilingual access to Digital Libraries.
   Digital Libraries (DLs) are one of the emerging fields of study in computer science and one of the more interesting multidisciplinary research areas. Knowledge distribution is one of its main objectives; hence, the need to develop multilingual applications that make knowledge available to every community that cannot communicate in the language in which DLs material and services where implemented.
   A prototype of the system has been developed using technologies based on Glossary-Based Machine Translation and the semantic grammar model. Some examples are presented showing the possibilities of the system. Conclusions will be drawn from the performance of the system and suggestions are included considering further developments.
SN 0302-9743
EI 1611-3349
BN 3-540-67354-7
PY 2000
VL 1793
BP 436
EP 442
UT WOS:000088970800040
ER

PT S
AU Bian, GW
   Chen, HH
AF Bian, GW
   Chen, HH
BE Farwell, D
   Gerber, L
   Hovy, E
TI Integrating query translation and document translation in a
   Cross-Language Information Retrieval system
SO MACHINE TRANSLATION AND THE INFORMATION SOUP
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
CT 3rd Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 28-31, 1998
CL LANGHORNE, PENNSYLVANIA
SP Systran Inc, Logos Corp, Globalink Inc, Univ Penn Inst Res Cognitive Sci
AB Due to the explosive growth of the WWW, very large multilingual textual resources have motivated the researches in Cross-Language Information Retrieval and online Web Machine Translation. In this paper, the integration of language translation and text processing system is proposed to build a multilingual information system. A distributed English-Chinese system on WWW is introduced to illustrate how to integrate query translation, search engines, and web translation system. Since July 1997, more than 46,000 users have accessed our system and about 250,000 English web pages have been translated to pages in Chinese or bilingual English-Chinese versions. And the average satisfaction degree of users at document level is 67.47% .
SN 0302-9743
BN 3-540-65259-0
PY 1998
VL 1529
BP 250
EP 265
UT WOS:000086659400023
ER

PT C
AU Poeta, N
   Giai, E
   Turnbull, D
AF Poeta, Nicola
   Giai, Enrico
   Turnbull, David
BE Ceci, M
   Flesca, S
   Masciari, E
   Manco, G
   Ras, ZW
TI Optimising the Machine Translation Workflow Analysis, Development,
   Benchmarking, Testing and Maintenance
SO FOUNDATIONS OF INTELLIGENT SYSTEMS (ISMIS 2022)
SE Lecture Notes in Artificial Intelligence
CT 26th International Symposium on Methodologies for Intelligent Systems
   (ISMIS)
CY OCT 03-05, 2022
CL Cosenza, ITALY
SP ICAR CNR, Univ Calabria, Dept Comp Engn Modeling Elect & Syst Engn, Univ Bari Aldo Moro, Comp Sci Dept, Univ Naples Federico II, DIETI Dept
AB Machine Translation (MT) has now become an essential part of the localisation industry. New roles connected with it have emerged, and new technologies have been adopted.
   As Language Service Providers (LSPs) need to implement these systems in their workflows - because of client demand, to improve cost efficiency, or to meet the rising demand for translated content - the need for clear guidelines to be followed in the adoption process grows.
   In this paper, we describe in detail eight steps to integrate an MT workflow into the translation process. These steps have been identified by analysing existing literature and thoroughly validated through real-world MT implementations by STAR7.
   The first step is to identify appropriate use cases. Thenwe must select the most suitable MT engine. Testing and benchmarking using scoring systems to evaluate the performance of the system is essential, as is supplier engagement in order to involve and inform all stakeholders. As the operational stage begins, several different Post-Editing Machine Translation (PEMT) workflows can be adopted. Quality Assurance (QA) and Language Quality Assessment (LQA) steps can then take place. Finally, feedback from all stakeholders can be collected to improve both the workflow and/or the MT engine performance itself.
SN 0302-9743
EI 1611-3349
BN 978-3-031-16564-1; 978-3-031-16563-4
PY 2022
VL 13515
BP 459
EP 466
DI 10.1007/978-3-031-16564-1_44
UT WOS:000886990100044
ER

PT J
AU Zhang, MY
   Holowko, MB
   Zumpe, HH
   Ong, CS
AF Zhang, Mengyan
   Holowko, Maciej Bartosz
   Zumpe, Huw Hayman
   Ong, Cheng Soon
TI Machine Learning Guided Batched Design of a Bacterial Ribosome Binding
   Site
SO ACS SYNTHETIC BIOLOGY
AB Optimization of gene expression levels is an essential part of the organism design process. Fine control of this process can be achieved by engineering transcription and translation control elements, including the ribosome binding site (RBS). Unfortunately, the design of specific genetic parts remains challenging because of the lack of reliable design methods. To address this problem, we have created a machine learning guided Design-Build-Test-Learn (DBTL) cycle for the experimental design of bacterial RBSs to demonstrate how small genetic parts can be reliably designed using relatively small, high-quality data sets. We used Gaussian Process Regression for the Learn phase of the cycle and the Upper Confidence Bound multiarmed bandit algorithm for the Design of genetic variants to be tested in vivo. We have integrated these machine learning algorithms with laboratory automation and high-throughput processes for reliable data generation. Notably, by Testing a total of 450 RBS variants in four DBTL cycles, we have experimentally validated RBSs with high translation initiation rates equaling or exceeding our benchmark RBS by up to 34%. Overall, our results show that machine learning is a powerful tool for designing RBSs, and they pave the way toward more complicated genetic devices.
OI Holowko, Maciej/0000-0002-1535-4296; Zhang, Mengyan/0000-0003-4853-5066
SN 2161-5063
DI 10.1021/acssynbio.2c00015
EA JUN 2022
UT WOS:000819376400001
PM 35704784
ER

PT J
AU Ucak, UV
   Ashyrmamatov, I
   Ko, J
   Lee, J
AF Ucak, Umit, V
   Ashyrmamatov, Islambek
   Ko, Junsu
   Lee, Juyong
TI Retrosynthetic reaction pathway prediction through neural machine
   translation of atomic environments
SO NATURE COMMUNICATIONS
AB Reaction route planning remains a major challenge in organic synthesis. The authors present a retrosynthetic prediction model using the fragment-based representation of molecules and the Transformer architecture in neural machine translation.
   Designing efficient synthetic routes for a target molecule remains a major challenge in organic synthesis. Atom environments are ideal, stand-alone, chemically meaningful building blocks providing a high-resolution molecular representation. Our approach mimics chemical reasoning, and predicts reactant candidates by learning the changes of atom environments associated with the chemical reaction. Through careful inspection of reactant candidates, we demonstrate atom environments as promising descriptors for studying reaction route prediction and discovery. Here, we present a new single-step retrosynthesis prediction method, viz. RetroTRAE, being free from all SMILES-based translation issues, yields a top-1 accuracy of 58.3% on the USPTO test dataset, and top-1 accuracy reaches to 61.6% with the inclusion of highly similar analogs, outperforming other state-of-the-art neural machine translation-based methods. Our methodology introduces a novel scheme for fragmental and topological descriptors to be used as natural inputs for retrosynthetic prediction tasks.
OI Lee, Juyong/0000-0003-1174-4358; , Umit/0000-0002-9088-0915;
   Ashyrmamatov, Islambek/0000-0001-6704-4233
EI 2041-1723
PD MAR 4
PY 2022
VL 13
IS 1
AR 1186
DI 10.1038/s41467-022-28857-w
UT WOS:000764895600027
PM 35246540
ER

PT C
AU Luo, MT
   He, LC
   Guo, MY
   Han, F
   Tian, L
   Pu, HB
   Zhang, DJ
AF Luo, Mengting
   He, Linchao
   Guo, Mingyue
   Han, Fei
   Tian, Long
   Pu, Haibo
   Zhang, Dejun
GP IOP
TI Word-to-word Machine Translation: Bilateral Similarity Retrieval for
   Mitigating Hubness
SO 2019 THE 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, CONTROL
   AND ROBOTICS (EECR 2019)
SE IOP Conference Series-Materials Science and Engineering
CT 5th International Conference on Electrical Engineering, Control and
   Robotics (EECR)
CY JAN 12-14, 2019
CL Guangzhou, PEOPLES R CHINA
SP Sichuan Inst Elect
AB Nearest neighbor search is playing a critical role in machine word translation, due to its ability to obtain the lingual labels of source word embeddings by searching k Nearest Neighbor (k NN) target embeddings from a shared bilingual semantic space. However, aligning two language distributions into a shared space usually requires amounts of target label, and k NN retrieval causes hubness problem in high-dimensions feature space. Although most the best-k retrievals get rid of hubs in the list of translation candidates to mitigate the hubness problem, it is flawed to eliminate hubs. Because hub also has a correct source word query corresponding to it and should not be crudely excluded. In this paper, we introduce an unsupervised machine word translation model based on Generative Adversarial Nets (GANs) with Bilingual Similarity retrieval, namely, Unsupervised-BSMWT. Our model addresses three main challenges: (1) reduce the dependence of parallel data with GANs in a fully unsupervised way. (2) Significantly decrease the training time of adversarial game. (3) Propose a novel Bilingual Similarity retrieval for mitigating hubness pollution regardless of whether it is a hub. Our model efficiently performs competitive results in 74min exceeding previous GANs-based models.
OI He, Linchao/0000-0002-0562-3026
SN 1757-8981
PY 2019
VL 533
AR 012051
DI 10.1088/1757-899X/533/1/012051
UT WOS:000492681300051
ER

PT J
AU Kumari, D
   Ekbal, A
   Haque, R
   Bhattacharyya, P
   Way, A
AF Kumari, Divya
   Ekbal, Asif
   Haque, Rejwanul
   Bhattacharyya, Pushpak
   Way, Andy
TI Reinforced NMT for Sentiment and Content Preservation in Low-resource
   Scenario
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB The preservation of domain knowledge from source to the target is crucial in any translation workflows. Hence, translation service providers that usemachine translation (MT) in production could reasonably expect that the translation process should transfer both the underlying pragmatics and the semantics of the source-side sentences into the target language. However, recent studies suggest that the MT systems often fail to preserve such crucial information (e.g., sentiment, emotion, gender traits) embedded in the source text in the target. In this context, the raw automatic translations are often directly fed to other natural language processing (NLP) applications (e.g., sentiment classifier) in a cross-lingual platform. Hence, the loss of such crucial information during the translation could negatively affect the performance of such downstream NLP tasks that heavily rely on the output of the MT systems.
   In our current research, we carefully balance both the sides (i.e., sentiment and semantics) during translation, by controlling a global-attention-based neural MT (NMT), to generate translations that encode the underlying sentiment of a source sentence while preserving its non-opinionated semantic content. Toward this, we use a state-of-the-art reinforcement learning method, namely, actor-critic, that includes a novel reward combination module, to fine-tune the NMT system so that it learns to generate translations that are best suited for a downstream task, viz. sentiment classification while ensuring the source-side semantics is intact in the process. Experimental results for Hindi-English language pair show that our proposed method significantly improves the performance of the sentiment classifier and alongside results in an improved NMT system.
RI Haque, Rejwanul/C-4581-2017
OI Haque, Rejwanul/0000-0003-1680-0099
SN 2375-4699
EI 2375-4702
PD JUL
PY 2021
VL 20
IS 4
AR 70
DI 10.1145/3450970
UT WOS:000721582900017
ER

PT C
AU Yang, J
AF Yang, Jing
BE Wang, T
   Patnaik, S
   Jack, WCH
   Varela, MLR
TI The Influence of Literature on Medio-translation Studies Based on
   Artificial Intelligence Algorithms: An Empirical Study of Shaanxi
   Literature
SO APPLICATIONS OF DECISION SCIENCE IN MANAGEMENT, ICDSM 2022
SE Smart Innovation Systems and Technologies
CT 4th International Conference on Decision Science and Management (ICDSM)
CY JAN 07-09, 2022
CL Changsha, PEOPLES R CHINA
SP Hunan Int Econ Univ, IRNet Int Acad Commun Ctr
AB Internet literary translation, as a brand new translation model, is a product of the fusion and collision of science and technology and humanity in the current social development. In the network technology rapid development era of information explosion, the Internet effectively combined with artificial intelligence technology and the traditional literary translation application advantages of literary translation, not only changed the human translation reading activity form, and enriched the research contents of translation study, at the present stage to translation study have sprung up in the production of spread to accept the changes more. On the basis of understanding the current development status of artificial intelligence algorithms, combined with relevant theories and current political cases, this paper deeply discusses the impact of artificial intelligence algorithms centered on Shaanxi literature on translation and media, so as to clarify the enlightenment of the algorithm.
SN 2190-3018
EI 2190-3026
BN 978-981-19-2768-3; 978-981-19-2767-6
PY 2023
VL 260
BP 231
EP 239
DI 10.1007/978-981-19-2768-3_21
UT WOS:000865739200021
ER

PT J
AU Rothwell, A
AF Rothwell, Andrew
TI Translating 'Pure Nonsense': Walter Benjamin Meets Systran on the
   Dissecting Table of Dada
SO ROMANCE STUDIES
AB The international Dada movement (c. 1916-1922) sought to subvert the rational, consensual social values which it saw as the cause of the First World War, notably by undermining the conceptual patterns and assumptions embodied in everyday language. Dada texts therefore provocatively challenge 'meaning', making them problematic to translate from the conventional perspective of equivalence. Walter Benjamin's contemporary essay 'The Task of the Translator' also critiques the assumption that translation involves a search for semantic equivalence, emphasizing instead the requirement for translators to follow the rhetorical and associative (dichterisch) patterns of the original at the expense of its meaning. Although his ideological standpoint is different from that of Dada, Benjamin's advocacy of a literalist, foreignizing (Venuti) method of translation offers a theoretically-grounded approach to translating Dada texts without betraying their underlying intentions. Machine Translation is here proposed as an ideologically neutral mechanism for performing such translations and two examples of its output, texts by Francis Picabia and Tristan Tzara transcoded into English, are analysed. These automatic translations are shown to reveal strikingly different associative patterns and lacunae in the two languages, offering an ironic, negative image of Benjamin's ideal of a Pure Language founded on the supplementarity of translations in the 'afterlife' of the original.
SN 0263-9904
PD NOV
PY 2009
VL 27
IS 4
SI SI
BP 259
EP 272
DI 10.1179/026399009X12523296128713
UT WOS:000275017500003
ER

PT C
AU Song, ZG
   Chai, JZ
   Shang, WQ
   Guo, YN
AF Song, Zhigang
   Chai, Jiazhao
   Shang, Wenqian
   Guo, Yuning
BE Gong, J
TI Transformer-IC: The Solution to Information Loss
SO 2021 IEEE/ACIS 20TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION
   SCIENCE (ICIS 2021-SUMMER)
CT 20th IEEE/ACIS International Summer Semi-Virtual Conference on Computer
   and Information Science (ICIS)
CY JUN 23-25, 2021
CL ELECTR NETWORK
SP Inst Elect & Elect Engineers, IEEE Comp Soc, Int Assoc Comp & Informat Sci, Shanghai Dev Ctr Comp Software Technol
AB With the development of information technology, machine translation technologies play a crucial role in cross-language communication. However, there is a problem of information loss in machine translation. In view of the common problem, this paper proposes three Transform-Information Combination (Transformer-IC) models based on information combination method. The models are based on the Transformer and select different middle-layer information to compensate the output through arithmetic mean combination method, linear transformation method and multi-layer information combination method respectively. Experimental results based on Linguistic Data Consortium (LDC) Chinese-to-English corpus and International Workshop on Spoken Language Translation (IWSLT) English-to-German corpus show that the BLEU values of all kinds of Transformer-IC model are higher than that of the reference model, in particular the arithmetic mean combination method improves the BLEU value by 1.9. Compared with the Bert model, the results show that even though the Bert model has a good performance, the Transformer-IC models are better than the Bert model. Transformer-IC models can make full use of the middle-layer information and effectively avoid the problem of information loss.
BN 978-1-6654-1893-5
PY 2021
BP 97
EP 101
DI 10.1109/ICIS51600.2021.9516861
UT WOS:000934859600019
ER

PT J
AU Dhanjal, AS
   Singh, W
AF Dhanjal, Amandeep Singh
   Singh, Williamjeet
TI An optimized machine translation technique for multi-lingual speech to
   sign language notation
SO MULTIMEDIA TOOLS AND APPLICATIONS
AB Due to the lack of assistive resources, hard-of-hearing people cannot live independently. Sign language or gesture language is the natural language and it is the primary mode of communication for hard-of-hearing people. Researchers and IT companies are continuously trying to find the best solutions to minimize the communication barriers for hearing-impaired people. Existing translation techniques for speech to sign language on the web platform are consuming higher resources. This study presents an optimized technique for direct machine translation of multi-lingual speech to Indian sign language using the HamNoSys notation system, whereas existing techniques were translating speech-text-HamNoSys. Performance comparison of both existing and the proposed techniques is analyzed in this study. The proposed technique optimizes the resources for the following parameters: CPU, heap memory, primary memory, and classes load. The result shows that the existing technique takes 220 MB heap memory, 10 threads, 2236 classes, and CPU for 12 s. The proposed technique consumes only 210.4 MB, 9 threads, 2113 classes, and CPU for 9 s.
OI Singh, Amandeep/0000-0002-7763-9174
SN 1380-7501
EI 1573-7721
PD JUL
PY 2022
VL 81
IS 17
BP 24099
EP 24117
DI 10.1007/s11042-022-12763-w
EA MAR 2022
UT WOS:000770754000019
ER

PT J
AU Cohen, H
AF Cohen, Hart
TI The "Untranslatables" as Symptoms of Difference: From a Network of
   Languages to a Language of Networks
SO ASIATIC-IIUM JOURNAL OF ENGLISH LANGUAGE AND LITERATURE
CT International Conference on Language and Literature (ICLL)
CY JAN 15-17, 2020
CL Int Islam Univ Malaysia, MALAYSIA
HO Int Islam Univ Malaysia
AB The purpose of this paper is to address the concern for the preservation of language difference and diversity. The threat to language diversity can be found historically in the dominance given to English and more recently, in the emergent forms of digital technologies. Their point of contact is the act of translation. In taking up Cassin's concept of the "untranslatables", the paper provides a critical foundation for thinking through the issue of language diversity. A focus on the translation of the bible into the Central Australian Aboriginal language of Aranda underpins how universal concepts are absorbed by the singularity of languages. In a re-think of the issues raised for translation practices when they are dominated by machine translation, digital technologies have also innovated new language usage exemplified by evolving forms in text messaging and the rise of image translation formats such as emojis. This raises the question as to whether specifically designed emojis for Indigenous speakers is a threat to, or a form that preserves and extends, Indigenous languages. The paper concludes with a consideration of the value of translation in a digital world where post-truth dominates the information landscape.
SN 1985-3106
PD JUN
PY 2021
VL 15
IS 1
SI SI
BP 14
EP 35
UT WOS:000661425100003
ER

PT C
AU Park, SB
   Yoon, HG
AF Park, Seong-Bae
   Yoon, Hee-Geun
BE Ardil, C
TI Determining the Gender of Korean Names for Pronoun Generation
SO PROCEEDINGS OF WORLD ACADEMY OF SCIENCE, ENGINEERING AND TECHNOLOGY, VOL
   26, PARTS 1 AND 2, DECEMBER 2007
SE Proceedings of World Academy of Science Engineering and Technology
CT Conference of the World-Academy-of-Science-Engineering-and-Technology
CY DEC 14-16, 2007
CL Bangkok, THAILAND
SP World Acad Sci Engn & Technol
AB It is an important task in Korean-English machine translation to classify the gender of names correctly. When a sentence is composed of two or more clauses and only one subject is given as a proper noun, it is important to find the gender of the proper noun for correct translation of the sentence. This is because a singular pronoun has a gender in English while it does not in Korean. Thus, in Korean-English machine translation, the gender of a proper noun should be determined. More generally, this task can be expanded into the classification of the general Korean names. This paper proposes a statistical method for this problem. By considering a name as just a sequence of syllables, it is possible to get a statistics for each name from a collection of names. An evaluation of the proposed method yields the improvement in accuracy over the simple looking-up of the collection. While the accuracy of the looking-up method is 64.11%, that of the proposed method is 81.49%. This implies that the proposed method is more plausible for the gender classification of the Korean names.
SN 1307-6884
PY 2007
VL 26
BP 42
EP 46
PN 1 & 2
UT WOS:000259869900009
ER

PT S
AU Duygulu, P
   Ozcanli, OC
   Papernick, N
AF Duygulu, P
   Ozcanli, OC
   Papernick, N
BE Yazici, A
   Sener, C
TI Comparison of feature sets using multimedia translation
SO COMPUTER AND INFORMATION SCIENCES - ISCIS 2003
SE Lecture Notes in Computer Science
CT 18th International Symposium on Computer and Information Sciences (ISCIS
   2003)
CY NOV 03-05, 2003
CL ANTALYA, TURKEY
SP Middle E Tech Univ, Sci & Tech Res Council Turkey, IEEE, Turkey Sect, Int Federat Informat Proc
AB Feature selection is very important for many computer vision applications. However, it is hard to find a good measure for the comparison. In this study, feature sets are compared using the translation model of object recognition which is motivated by the availablity of large annotated data sets. Image regions are linked to words using a model which is inspired by machine translation. Word prediction performance is used to evaluate large numbers of images.
RI Duygulu, Pinar/N-2707-2013
OI Duygulu, Pinar/0000-0002-6420-2838
SN 0302-9743
EI 1611-3349
BN 3-540-20409-1
PY 2003
VL 2869
BP 513
EP 520
UT WOS:000188096800064
ER

PT J
AU Xu, J
AF Xu Jun
TI Machine Translation for Editing Compositions in a Chinese Language
   Class: Task Design and Student Beliefs
SO JOURNAL OF TECHNOLOGY AND CHINESE LANGUAGE TEACHING
AB The frequent use of machine translation (MT) in the daily lives of the digital generation presents challenges and opportunities for language teaching and learning. Rather than excluding MT from the classroom, educators have begun exploring various ways to integrate it into classroom instruction. While most studies ask students to post-edit a translation provided by MT, this study employed a different task design: having students post-edit self-written Chinese compositions with the help of MT. The study was conducted in a fourth-year Chinese language class at a public university. The beliefs of 12 students in the value of MT were investigated based on responses to a questionnaire and open-ended questions. The study found that students hold a positive attitude towards using MT in writing assignments. The students noted that MT helped them learn vocabulary and grammar, improve the quality of writing, boost confidence in Chinese use, and acquire autonomous learning skills. A comparison between this study and previous studies also revealed the critical role of task design in successfully implementing MT in classroom instruction.
SN 1949-260X
PD JUN
PY 2020
VL 11
IS 1
BP 1
EP 18
UT WOS:000546492200001
ER

PT J
AU Deng, XJ
   Yu, ZG
AF Deng, Xinjie
   Yu, Zhonggen
TI A Systematic Review of Machine-Translation-Assisted Language Learning
   for Sustainable Education
SO SUSTAINABILITY
AB With the rapid development of artificial intelligence, machine translation (MT) has gained popularity in recent years. This study aims to present a systematic review of literature on MT-assisted language learning in terms of main users, theoretical frameworks, users' attitudes, and the ways in which MT tools are integrated with language teaching and learning. To this end, relevant peer-reviewed articles (n = 26) were selected through the Preferred Reporting Items for Systematic Review and Meta-Analysis Protocol (PRISMA-P) for further analysis. The findings revealed that the main MT users were undergraduate and graduate students. Both teachers and students held mixed attitudes for different reasons. It was also found that MT integration followed four steps, i.e., introduction, demonstration, task assignment, and reflection. The procedures of MT integration could be updated and perfected by introducing other features in the future.
OI Deng, Xinjie/0000-0002-8901-3080; Yu, Zhonggen/0000-0002-3873-980X
EI 2071-1050
PD JUL
PY 2022
VL 14
IS 13
AR 7598
DI 10.3390/su14137598
UT WOS:000824051800001
ER

PT C
AU Abrego, GH
   Liang, BW
   Wang, W
   Parekh, Z
   Yang, YF
   Sung, Y
AF Abrego, Gustavo Hernandez
   Liang, Bowen
   Wang, Wei
   Parekh, Zarana
   Yang, Yinfei
   Sung, Yunhsuan
GP Assoc Computat Linguist
TI Self-Supervised Learning for Pairwise Data Refinement
SO 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON
   NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020)
CT 1st Conference of the Asia-Pacific Chapter of the
   Association-for-Computational-Linguistics / 10th International Joint
   Conference on Natural Language Processing (AACL-IJCNLP)
CY DEC 04-07, 2020
CL Soochow Univ, ELECTR NETWORK
SP Assoc Computat Linguist, Asia Pacific Chapter, Baidu, Huawei
HO Soochow Univ
AB Pairwise data automatically constructed from weakly supervised signals has been widely used for training deep learning models. Pairwise datasets such as parallel texts can have uneven quality levels overall, but usually contain data subsets that are more useful as learning examples. We present two methods to refine data that are aimed at obtaining that kind of subsets in a self-supervised way. Our methods are based on iteratively training dual-encoder models to compute similarity scores. We evaluate our methods on de-noising parallel texts and training neural machine translation models. We find that: (i) The self-supervised refinement achieves most machine translation gains in the first iteration, but following iterations further improve its intrinsic evaluation. (ii) Machine translations can improve the de-noising performance when combined with selection steps. (iii) Our methods are able to reach the performance of a supervised method. Being entirely self-supervised, our methods are well-suited to handle pairwise data without the need of prior knowledge or human annotations.
BN 978-1-952148-91-0
PY 2020
BP 435
EP 446
UT WOS:000857113500045
ER

PT J
AU Zhu, LY
   Liu, LJ
AF Zhu, Lingyi
   Liu, Lijuan
TI Application of Stochastic Matrix Model with Improved GLR Algorithm in
   English Translation Studies
SO MATHEMATICAL PROBLEMS IN ENGINEERING
AB The rapid development of todays society is accompanied by the explosive growth of information data; in the process of information transmission, language is a very important carrier. Among all kinds of communication languages, English always occupies an important position and is one of the most commonly used languages in social life. Therefore, the practical significance of English education is self-evident. With the popularization of the Internet, intelligent phrase recognition in machine translation is the key technology. With the help of natural language processing technology, an English translation corpus can be built to accurately mark the parts of speech of short words, and phrase recognition technology is used to correct grammatical ambiguity effectively. Structural ambiguity is a difficult problem in the field of English translation. Based on the random matrix model of the improved GLR algorithm, phrase structure labelling is constructed through the phrase corpus. Revised annotation can effectively improve the accuracy of academic translation, and intelligent English translation is realized through recognition technology. Simulation experiments verify the effectiveness of the model, and the results show that the English translation intelligent recognition model has a high proofreading accuracy. When the value of P is 0.95, the high accuracy can be retained to the maximum and the efficiency and feasibility of improving the GLR algorithm in machine translation can be improved.
SN 1024-123X
EI 1563-5147
PD AUG 10
PY 2022
VL 2022
AR 5137951
DI 10.1155/2022/5137951
UT WOS:000883008100009
ER

PT C
AU Gupta, G
   Ramesh, K
   Singh, S
AF Gupta, Gauri
   Ramesh, Krithika
   Singh, Sanjay
GP Assoc Computat Linguist
TI Evaluating Gender Bias in Hindi-English Machine Translation
SO GEBNLP 2021: THE 3RD WORKSHOP ON GENDER BIAS IN NATURAL LANGUAGE
   PROCESSING
CT 3rd Workshop on Gender Bias in Natural Language Processing (GeBNLP)
CY AUG 05, 2021
CL ELECTR NETWORK
AB With language models being deployed increasingly in the real world, it is essential to address the issue of the fairness of their outputs. The word embedding representations of these language models often implicitly draw unwanted associations that form a social bias within the model. The nature of gendered languages like Hindi, poses an additional problem to the quantification and mitigation of bias, owing to the change in the form of the words in the sentence, based on the gender of the subject. Additionally, there is sparse work done in the realm of measuring and debiasing systems for Indic languages. In our work, we attempt to evaluate and quantify the gender bias within a Hindi-English machine translation system. We implement a modified version of the existing TGBI metric based on the grammatical considerations for Hindi. We also compare and contrast the resulting bias measurements across multiple metrics for pre-trained embeddings and the ones learned by our machine translation model.
BN 978-1-954085-61-9
PY 2021
BP 16
EP 23
UT WOS:000694722900003
ER

PT C
AU Pagliari, DJ
   Panini, F
   Macii, E
   Poncino, M
AF Pagliari, Daniele Jahier
   Panini, Francesco
   Macii, Enrico
   Poncino, Massimo
GP Assoc Comp Machinery
TI Dynamic Beam Width Tuning for Energy-Efficient Recurrent Neural Networks
SO GLSVLSI '19 - PROCEEDINGS OF THE 2019 ON GREAT LAKES SYMPOSIUM ON VLSI
SE Proceedings - Great Lakes Symposium on VLSI
CT 29th Great Lakes Symposium on VLSI (GLSVLSI)
CY MAY 09-11, 2019
CL Tysons Corner, VA
SP Assoc Comp Machinery
AB Recurrent Neural Networks (RNNs) are state-of-the-art models for many machine learning tasks, such as language modeling and machine translation. Executing the inference phase of a RNN directly in edge nodes, rather than in the cloud, would provide benefits in terms of energy consumption, latency and network bandwidth, provided that models can be made efficient enough to run on energy-constrained embedded devices.
   To this end, we propose an algorithmic optimization for improving the energy efficiency of encoder-decoder RNNs. Our method operates on the Beam Width (BW), i.e. one of the parameters that most influences inference complexity, modulating it depending on the currently processed input based on a metric of the network's "confidence".
   Results on two different machine translation models show that our method is able to reduce the average BW by up to 33%, thus significantly reducing the inference execution time and energy consumption, while maintaining the same translation performance.
RI PAGLIARI, DANIELE JAHIER/Z-5988-2019; Pagliari, Daniele
   Jahier/AAU-8670-2021
OI PAGLIARI, DANIELE JAHIER/0000-0002-2872-7071; 
SN 1066-1395
BN 978-1-4503-6252-8
PY 2019
BP 69
EP 74
DI 10.1145/3299874.3317974
UT WOS:000474339800015
ER

PT C
AU Do, TND
   Nguyen, DB
   Mac, DK
   Tran, DD
AF Thi Ngoc Diep Do
   Duy Binh Nguyen
   Dang Khoa Mac
   Do Dat Tran
GP IEEE
TI Machine Translation Approach for Vietnamese Diacritic Restoration
SO 2013 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP 2013)
SE International Conference on Asian Language Processing
CT International Conference on Asian Language Processing (IALP)
CY AUG 17-19, 2013
CL Urumqi, PEOPLES R CHINA
SP Xinjiang Normal Univ, Beijing Inst Technol, Heilongjiang Univ, IEEE Singapore Comp Chapter, COLIPS, Natl Nat Sci Fdn China, Projects Int Cooperat & Exchanges, Chinese Informat Proc Soc China, Software Ind Assoc Xinjiang Uygur Autonomous Reg, Comp Federat Xinjiang
AB The diacritic marks exist in many languages such as French, German, Slovak, Vietnamese, etc. However for some reasons, sometime they are omitted in writing. This phenomenon may lead to the ambiguity for reader when reading a non-diacritic text. The automatic diacritic restoration problem has been proposed and resolved in several languages using the character-based approach, word-based approach, point-wise approach, etc. However, these approaches lean heavily on the linguistics information, size of training corpus and sometime they are language dependent. In this paper, a simple and effective restoration method will be presented. The machine translation approach will be used as a new solution for this problem. The restoration method has been applied for Vietnamese language, and integrated in an Android application named VIVA (Vietnamese Voice Assistant) that reads out the content of incoming text messages on mobile phone. Our experiments show that the proposed restoration method can recover diacritic marks with a 99.0% accuracy rate.
OI Do, Thi Ngoc Diep/0000-0001-9197-7850
SN 2159-1962
EI 2159-1970
BN 978-0-7695-5063-3
PY 2013
BP 103
EP 106
DI 10.1109/IALP.2013.30
UT WOS:000704404800025
ER

PT S
AU McKenzie, P
   Schwentick, T
   Therien, D
   Vollmer, H
AF McKenzie, P
   Schwentick, T
   Therien, D
   Vollmer, H
BE Montanari, U
   Rolim, JDP
   Welzl, E
TI The many faces of a translation
SO AUTOMATA LANGUAGES AND PROGRAMMING
SE LECTURE NOTES IN COMPUTER SCIENCE
CT 27th International Colloquium on Automata Languages and Programming
   (ICALP 2000)
CY JUL 09-15, 2000
CL GENEVA, SWITZERLAND
SP Swiss Natl Sci Fdn, Univ Geneva, Dept Comp Sci, INTAS, EATCS
AB First-order translations have recently been characterized as the maps computed by aperiodic single-valued nondeterministic finite transducers (NFTs). It is shown here that this characterization lifts to "V-translations" and "V-single-valued-NFTs", where V is an arbitrary monoid pseudovariety. More strikingly, 2-way V-machines are introduced, and the following three models are shown exactly equivalent to Eilenberg's classical notion of a bimachine when V is a group variety or when V is the variety of aperiodic monoids: V-translations, V-single-valued-NFTs and 2-way V-transducers.
OI Vollmer, Heribert/0000-0002-9292-1960
SN 0302-9743
BN 3-540-67715-1
PY 2000
VL 1853
BP 890
EP 901
UT WOS:000089738700075
ER

PT J
AU Ureche, V
   Talau, C
   Odersky, M
AF Ureche, Vlad
   Talau, Cristian
   Odersky, Martin
TI Miniboxing: Improving the Speed to Code Size Tradeoff in Parametric
   Polymorphism Translations
SO ACM SIGPLAN NOTICES
CT 2013 ACM SIGPLAN International Conference on Object Oriented Programming
   Systems Languages
CY OCT 29-31, 2013
CL Indianapolis, IN
AB Parametric polymorphism enables code reuse and type safety. Underneath the uniform interface exposed to programmers, however, its low level implementation has to cope with inherently non-uniform data: value types of different sizes and semantics (bytes, integers, floating point numbers) and reference types (pointers to heap objects). On the Java Virtual Machine, parametric polymorphism is currently translated to bytecode using two competing approaches: homogeneous and heterogeneous. Homogeneous translation requires boxing, and thus introduces indirect access delays. Heterogeneous translation duplicates and adapts code for each value type individually, producing more bytecode. Therefore bytecode speed and size are at odds with each other. This paper proposes a novel translation that significantly reduces the bytecode size without affecting the execution speed. The key insight is that larger value types (such as integers) can hold smaller ones (such as bytes) thus reducing the duplication necessary in heterogeneous translations. In our implementation, on the Scala compiler, we encode all primitive value types in long integers. The resulting bytecode approaches the performance of monomorphic code, matches the performance of the heterogeneous translation and obtains speedups of up to 22x over the homogeneous translation, all with modest increases in size.
SN 0362-1340
EI 1558-1160
PD OCT
PY 2013
VL 48
IS 10
BP 73
EP 92
DI 10.1145/2544173.2509537
UT WOS:000327697300004
ER

PT J
AU Jooken, L
   Rooryck, G
AF Jooken, Lieve
   Rooryck, Guy
TI ELIE LUZAC AND L'HOMME PLUS QUE MACHINE ( 1748): THE DIALOGIC VOICE OF
   AN ENLIGHTENMENT PRINTER
SO CADERNOS DE TRADUCAO
AB Early into his career as one of the most successful printer-publishers of the Dutch Republic, Elie Luzac (1721-1796) played a pivotal role in disseminating the materialist ideas of La Mettrie's Homme machine (1747). This paper focuses on the dialogic voice (Bakhtine) in a publication by Luzac himself, which oscillates between asserting and refuting La Mettrie's views. Descended from Huguenot refugees, Luzac condemns what he publishes and publishes what he condemns. This discursive ambiguity emerges in Luzac's L'homme plus que machine (1748), a work which cites La Mettrie's theses in order to contest them. Building on the succes de scandale of the English version of L'homme machine (Man a Machine, 1749), the English translation of L'homme plus que machine, Man more than a Machine, appeared in 1752. The present contribution examines how the translator's Voice, which is defined as an enarrative voice, effaces the concealed claims of the original text and replaces them with a discourse whose explicit anti-materialist tenor contrasts with the vehement rhetoric of Man a Machine.
SN 1414-526X
EI 2175-7968
PD JAN-APR
PY 2018
VL 38
IS 1
BP 197
EP 225
DI 10.5007/2175-7968.2018v38n1p197
UT WOS:000432312500012
ER

PT C
AU Conneau, A
   Lample, G
AF Conneau, Alexis
   Lample, Guillaume
BE Wallach, H
   Larochelle, H
   Beygelzimer, A
   d'Alche-Buc, F
   Fox, E
   Garnett, R
TI Cross-lingual Language Model Pretraining
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 32 (NIPS 2019)
SE Advances in Neural Information Processing Systems
CT 33rd Conference on Neural Information Processing Systems (NeurIPS)
CY DEC 08-14, 2019
CL Vancouver, CANADA
AB Recent studies have demonstrated the efficiency of generative pretraining for English natural language understanding. In this work, we extend this approach to multiple languages and show the effectiveness of cross-lingual pretraining. We propose two methods to learn cross-lingual language models (XLMs): one unsupervised that only relies on monolingual data, and one supervised that leverages parallel data with a new cross-lingual language model objective. We obtain state-of-the-art results on cross-lingual classification, unsupervised and supervised machine translation. On XNLI, our approach pushes the state of the art by an absolute gain of 4.9% accuracy. On unsupervised machine translation, we obtain 34.3 BLEU on WMT'16 German-English, improving the previous state of the art by more than 9 BLEU. On supervised machine translation, we obtain a new state of the art of 38.5 BLEU on WMT'16 Romanian-English, outperforming the previous best approach by more than 4 BLEU. Our code and pretrained models are publicly available(1).
SN 1049-5258
PY 2019
VL 32
UT WOS:000534424307011
ER

PT C
AU Ljubesic, N
   Erjavec, T
   Fiser, D
AF Ljubesic, Nikola
   Erjavec, Tomaz
   Fiser, Darja
BE Gelbukh, A
TI Standardizing Tweets with Character-Level Machine Translation
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING, CICLING 2014,
   PART II
SE Lecture Notes in Computer Science
CT 15th Annual Conference on Intelligent Text Processing and Computational
   Linguistics (CICLing)
CY APR 06-12, 2014
CL Ctr Commun & Dev, Kathmandu, NEPAL
SP Inst Politecnico Nacl Centro Invest Computac Nat Language &Text Proc Lab, Mexican Soc Artificial Intelligence
HO Ctr Commun & Dev
AB This paper presents the results of the standardization procedure of Slovene tweets that are full of colloquial, dialectal and foreign-language elements. With the aim of minimizing the human input required we produced a manually normalized lexicon of the most salient out-of-vocabulary (OOV) tokens and used it to train a character-level statistical machine translation system (CSMT). Best results were obtained by combining the manually constructed lexicon and CSMT as fallback with an overall improvement of 9.9% increase on all tokens and 31.3% on OOV tokens. Manual preparation of data in a lexicon manner has proven to be more efficient than normalizing running text for the task at hand. Finally we performed an extrinsic evaluation where we automatically lemmatized the test corpus taking as input either original or automatically standardized wordforms, and achieved 75.1% per-token accuracy with the former and 83.6% with the latter, thus demonstrating that standardization has significant benefits for upstream processing.
OI Erjavec, Tomaz/0000-0002-1560-4099
SN 0302-9743
EI 1611-3349
BN 978-3-642-54902-1; 978-3-642-54903-8
PY 2014
VL 8404
BP 164
EP 175
UT WOS:000342990000014
ER

PT J
AU Yin, YJ
   Su, JS
   Wen, HT
   Zeng, JL
   Liu, Y
   Chen, YD
AF Yin, Yongjing
   Su, Jinsong
   Wen, Huating
   Zeng, Jiali
   Liu, Yang
   Chen, Yidong
TI POS Tag-enhanced Coarse-to-fine Attention for Neural Machine Translation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB Although neural machine translation (NMT) has certain capability to implicitly learn semantic information of sentences, we explore and show that Part-of-Speech (POS) tags can be explicitly incorporated into the attention mechanism of NMT effectively to yield further improvements. In this article, we propose an NMT model with tag-enhanced attention mechanism. In our model, NMT and POS tagging are jointly modeled via multi-task learning. Besides following common practice to enrich encoder annotations by introducing predicted source POS tags, we exploit predicted target POS tags to refine attention model in a coarse-to-fine manner. Specifically, we first implement a coarse attention operation solely on source annotations and target hidden state, where the produced context vector is applied to update target hidden state used for target POS tagging. Then, we perform a fine attention operation that extends the coarse one by further exploiting the predicted target POS tags. Finally, we facilitate word prediction by simultaneously utilizing the context vector from fine attention and the predicted target POS tags. Experimental results and further analyses on Chinese-English and Japanese-English translation tasks demonstrate the superiority of our proposed model over the conventional NMT models.
SN 2375-4699
EI 2375-4702
PD AUG
PY 2019
VL 18
IS 4
AR 46
DI 10.1145/3321124
UT WOS:000495430700013
ER

PT C
AU Zhang, TF
   Huang, HY
   Feng, C
   Cao, LB
AF Zhang, Tianfu
   Huang, Heyan
   Feng, Chong
   Cao, Longbing
GP Assoc Computat Linguist
TI Enlivening Redundant Heads in Multi-head Self-attention for Machine
   Translation
SO 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2021)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 07-11, 2021
CL Punta Cana, DOMINICAN REP
AB Multi-head self-attention recently attracts enormous interest owing to its specialized functions, significant parallelizable computation, and flexible extensibility. However, very recent empirical studies show that some self-attention heads make little contribution and can be pruned as redundant heads. This work takes a novel perspective of identifying and then vitalizing redundant heads. We propose a redundant head enlivening (RHE) method to precisely identify redundant heads, and then vitalize their potential by learning syntactic relations and prior knowledge in text without sacrificing the roles of important heads. Two novel syntax-enhanced attention (SEA) mechanisms: a dependency mask bias and a relative local-phrasal position bias, are introduced to revise self-attention distributions for syntactic enhancement in machine translation. The importance of individual heads is dynamically evaluated during the redundant heads identification, on which we apply SEA to vitalize redundant heads while maintaining the strength of important heads. Experimental results on WMT14 and WMT16 English -> German and English -> Czech language machine translation validate the RHE effectiveness.
RI zhang, tian/GZK-6001-2022
OI cao, longbing/0000-0003-1562-9429
BN 978-1-955917-09-4
PY 2021
BP 3238
EP 3248
UT WOS:000855966303032
ER

PT C
AU Wang, YR
   Wu, LJ
   Xia, YC
   Qin, T
   Zhai, CX
   Liu, TY
AF Wang, Yiren
   Wu, Lijun
   Xia, Yingce
   Qin, Tao
   Zhai, ChengXiang
   Liu, Tie-Yan
GP Assoc Advancement Artificial Intelligence
TI Transductive Ensemble Learning for Neural Machine Translation
SO THIRTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THE
   THIRTY-SECOND INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE
   CONFERENCE AND THE TENTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN
   ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 34th AAAI Conference on Artificial Intelligence / 32nd Innovative
   Applications of Artificial Intelligence Conference / 10th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 07-12, 2020
CL New York, NY
SP Assoc Advancement Artificial Intelligence
AB Ensemble learning, which aggregates multiple diverse models for inference, is a common practice to improve the accuracy of machine learning tasks. However, it has been observed that the conventional ensemble methods only bring marginal improvement for neural machine translation (NMT) when individual models are strong or there are a large number of individual models. In this paper, we study how to effectively aggregate multiple NMT models under the transductive setting where the source sentences of the test set are known. We propose a simple yet effective approach named transductive ensemble learning (TEL), in which we use all individual models to translate the source test set into the target language space and then finetune a strong model on the translated synthetic corpus. We conduct extensive experiments on different settings (with/without monolingual data) and different language pairs (English <-> {German, Finnish}). The results show that our approach boosts strong individual models with significant improvement and benefits a lot from more individual models. Specifically, we achieve the state-of-the-art performances on the WMT2016-2018 English <-> German translations.
OI Qin, Tao/0000-0002-9095-0776
SN 2159-5399
EI 2374-3468
BN 978-1-57735-835-0
PY 2020
VL 34
BP 6291
EP 6298
UT WOS:000667722806046
ER

PT C
AU Yan, R
   Song, YP
   Li, CT
   Zhang, M
   Hu, XH
AF Yan, Rui
   Song, Yiping
   Li, Cheng-Te
   Zhang, Ming
   Hu, Xiaohua
BE Yang, Q
   Wooldridge, M
TI Opportunities or Risks to Reduce Labor in Crowdsourcing Translation?
   Characterizing Cost Versus Quality via a PageRank-HITS Hybrid Model
SO PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON
   ARTIFICIAL INTELLIGENCE (IJCAI)
CT 1st International Workshop on Social Influence Analysis / 24th
   International Joint Conference on Artificial Intelligence (IJCAI)
CY JUL 25-31, 2015
CL Buenos Aires, ARGENTINA
AB Crowdsourcing machine translation shows advantages of lower expense in money to collect the translated data. Yet, when compared with translation by trained professionals, results collected from non-professional translators might yield low-quality outputs. A general solution for crowdsourcing practitioners is to employ a large amount of labor force to gather enough redundant data and then solicit from it. Actually we can further save money by avoid collecting bad translations. We propose to score Turkers by their authorities during observation, and then stop hiring the unqualified Turkers. In this way, we bring both opportunities and risks in crowdsourced translation: we can make it cheaper than cheaper while we might suffer from quality loss. In this paper, we propose a graph-based PageRank-HITS Hybrid model to distinguish authoritative workers from unreliable ones. The algorithm captures the intuition that good translation and good workers are mutually reinforced iteratively in the proposed frame. We demonstrate the algorithm will keep the performance while reduce work force and hence cut cost. We run experiments on the NIST 2009 Urdu-to-English evaluation set with Mechanical Turk, and quantitatively evaluate the performance in terms of BLEU score, Pearson correlation and real money.
BN 978-1-57735-738-4
PY 2015
BP 1025
EP 1032
UT WOS:000442637801016
ER

PT J
AU Wang, Y
   Wang, YL
   Dang, K
   Liu, J
   Liu, Z
AF Wang, Yu
   Wang, Yuelin
   Dang, Kai
   Liu, Jie
   Liu, Zhuo
TI A Comprehensive Survey of Grammatical Error Correction
SO ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY
AB Grammatical error correction (GEC) is an important application aspect of natural language processing techniques, and GEC system is a kind of very important intelligent system that has long been explored both in academic and industrial communities. The past decade has witnessed significant progress achieved in GEC for the sake of increasing popularity of machine learning and deep learning. However, there is not a survey that untangles the large amount of research works and progress in this field. We present the first survey in GEC for a comprehensive retrospective of the literature in this area. We first give the definition of GEC task and introduce the public datasets and data annotation schema. After that, we discuss six kinds of basic approaches, six commonly applied performance boosting techniques for GEC systems, and three data augmentation methods. Since GEC is typically viewed as a sister task of Machine Translation (MI), we put more emphasis on the statistical machine translation (SMT)-based approaches and neural machine translation (NMT)-based approaches for the sake of their importance. Similarly, some performance-boosting techniques are adapted from MT and are successfully combined with GEC systems for enhancement on the final performance. More importantly, after the introduction of the evaluation in GEC, we make an in-depth analysis based on empirical results in aspects of GEC approaches and GEC systems for a clearer pattern of progress in GEC, where error type analysis and system recapitulation are clearly presented. Finally, we discuss five prospective directions for future GEC researches.
SN 2157-6904
EI 2157-6912
PD DEC
PY 2021
VL 12
IS 5
AR 65
DI 10.1145/3474840
UT WOS:000732997200014
ER

PT C
AU Shen, TX
   Ott, M
   Auli, M
   Ranzato, MA
AF Shen, Tianxiao
   Ott, Myle
   Auli, Michael
   Ranzato, Marc Aurelio
BE Chaudhuri, K
   Salakhutdinov, R
TI Mixture Models for Diverse Machine Translation: Tricks of the Trade
SO INTERNATIONAL CONFERENCE ON MACHINE LEARNING, VOL 97
SE Proceedings of Machine Learning Research
CT 36th International Conference on Machine Learning (ICML)
CY JUN 09-15, 2019
CL Long Beach, CA
AB Mixture models trained via EM are among the simplest, most widely used and well understood latent variable models in the machine learning literature. Surprisingly, these models have been hardly explored in text generation applications such as machine translation. In principle, they provide a latent variable to control generation and produce a diverse set of hypotheses. In practice, however, mixture models are prone to degeneracies-often only one component gets trained or the latent variable is simply ignored. We find that disabling dropout noise in responsibility computation is critical to successful training. In addition, the design choices of parameterization, prior distribution, hard versus soft EM and online versus offline assignment can dramatically affect model performance. We develop an evaluation protocol to assess both quality and diversity of generations against multiple references, and provide an extensive empirical study of several mixture model variants. Our analysis shows that certain types of mixture models are more robust and offer the best trade-off between translation quality and diversity compared to variational models and diverse decoding approaches.(1)
SN 2640-3498
PY 2019
VL 97
UT WOS:000684034305087
ER

PT C
AU Luong, MT
   Sutskever, I
   Le, QV
   Vinyals, O
   Zaremba, W
AF Minh-Thang Luong
   Sutskever, Ilya
   Le, Quoc V.
   Vinyals, Oriol
   Zaremba, Wojciech
BE Zong, C
   Strube, M
TI Addressing the Rare Word Problem in Neural Machine Translation
SO PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON
   NATURAL LANGUAGE PROCESSING, VOL 1
CT 53rd Annual Meeting of the Association-for-Computational-Linguistics
   (ACS) / 7th International Joint Conference on Natural Language
   Processing of the Asian-Federation-of-Natural-Language-Processing
   (IJCNLP)
CY JUL 26-31, 2015
CL Beijing, PEOPLES R CHINA
SP Assoc Computat Linguist, Asian Federat Nat Language Proc, CreditEase, Baidu, Tencent, Alibaba Grp, Samsung, Microsoft, Google, Facebook, SinoVoice, Huawei, Nuance, Amazon, Voicebox Technologies, Baobab, Sogou
AB Neural Machine Translation (NMT) is a new approach to machine translation that has shown promising results that are comparable to traditional approaches. A significant weakness in conventional NMT systems is their inability to correctly translate very rare words: end-to-end NMTs tend to have relatively small vocabularies with a single unk symbol that represents every possible out-of-vocabulary (OOV) word. In this paper, we propose and implement an effective technique to address this problem. We train an NMT system on data that is augmented by the output of a word alignment algorithm, allowing the NMT system to emit, for each OOV word in the target sentence, the position of its corresponding word in the source sentence. This information is later utilized in a post-processing step that translates every OOV word using a dictionary. Our experiments on the WMT' 14 English to French translation task show that this method provides a substantial improvement of up to 2.8 BLEU points over an equivalent NMT system that does not use this technique. With 37.5 BLEU points, our NMT system is the first to surpass the best result achieved on a WMT' 14 contest task.
BN 978-1-941643-72-3
PY 2015
BP 11
EP 19
UT WOS:000493808900002
ER

PT C
AU Carrion, S
   Casacuberta, F
AF Carrion, Salvador
   Casacuberta, Francisco
BE Guetl, C
   Ceravolo, P
   Jararweh, Y
   Benkhelifa, E
   Adedugbe, O
TI Quasi Character-Level Transformers to Improve Neural Machine Translation
   on Small Datasets
SO 2021 EIGHTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORK ANALYSIS,
   MANAGEMENT AND SECURITY (SNAMS)
CT 8th International Conference on Social Network Analysis, Management and
   Security (SNAMS)
CY DEC 06-09, 2021
CL ELECTR NETWORK
SP IEEE Spain Sect, Univ Politecnica Valencia, Al Ain Univ, TU Graz, Staffordshire Univ
AB In the Neural Machine Translation community, it is a common practice to use some form of subword segmentation to encode words as a sequence of subword units. This allows practitioners to represent their entire dataset using the least amount of tokens, thus avoiding memory and performance-related problems derived from the full word- or purely character-level representations. Even though there is strong evidence that each dataset has an optimal vocabulary size, in practice it is common to use as many "words" as possible. In this work, we show how this standard approach might be counter-productive for small datasets or low-resource environments, where models trained with quasi character-level vocabularies seem to consistently outperform models with large subword vocabularies. Nonetheless, these improvements come at the expense of requiring a neural architecture capable of dealing with long sequences and long-term dependencies.
BN 978-1-6654-9495-3
PY 2021
BP 184
EP 189
DI 10.1109/SNAMS53716.2021.9732120
UT WOS:000813133100026
ER

PT C
AU Cui, Q
   Huang, SJ
   Li, JH
   Geng, X
   Zheng, ZX
   Huang, GP
   Chen, JJ
AF Cui, Qu
   Huang, Shujian
   Li, Jiahuan
   Geng, Xiang
   Zheng, Zaixiang
   Huang, Guoping
   Chen, Jiajun
GP Assoc Advancement Artificial Intelligence
TI DirectQE: Direct Pretraining for Machine Translation Quality Estimation
SO THIRTY-FIFTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THIRTY-THIRD
   CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE AND THE
   ELEVENTH SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 35th AAAI Conference on Artificial Intelligence / 33rd Conference on
   Innovative Applications of Artificial Intelligence / 11th Symposium on
   Educational Advances in Artificial Intelligence
CY FEB 02-09, 2021
CL ELECTR NETWORK
SP Assoc Advancement Artificial Intelligence
AB Machine Translation Quality Estimation (QE) is a task of predicting the quality of machine translations without relying on any reference. Recently, the predictor-estimator framework trains the predictor as a feature extractor, which leverages the extra parallel corpora without QE labels, achieving promising QE performance. However, we argue that there are gaps between the predictor and the estimator in both data quality and training objectives, which preclude QE models from benefiting from a large number of parallel corpora more directly. We propose a novel framework called DirectQE that provides a direct pretraining for QE tasks. In DirectQE, a generator is trained to produce pseudo data that is closer to the real QE data, and a detector is pretrained on these data with novel objectives that are akin to the QE task. Experiments on widely used benchmarks show that DirectQE outperforms existing methods, without using any pretraining models such as BERT. We also give extensive analyses showing how fixing the two gaps contributes to our improvements.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-866-4
PY 2021
VL 35
BP 12719
EP 12727
UT WOS:000681269804044
ER

PT C
AU Imani, A
   Sabet, MJ
   Senel, LK
   Dufter, P
   Yvon, F
   Schutze, H
AF Imani, Ayyoob
   Sabet, Masoud Jalili
   Senel, Luetfi Kerem
   Dufter, Philipp
   Yvon, Francois
   Schuetze, Hinrich
GP Assoc Computat Linguist
TI Graph Algorithms for Multiparallel Word Alignment
SO 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2021)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 07-11, 2021
CL Punta Cana, DOMINICAN REP
AB With the advent of end-to-end deep learning approaches in machine translation, interest in word alignments initially decreased; however, they have again become a focus of research more recently. Alignments are useful for typological research, transferring formatting like markup to translated texts and can be used in the decoding of machine translation systems. At the same time, massively multilingual processing is becoming an important NLP scenario and pretrained language and machine translation models that are truly multilingual are proposed. However, most alignment algorithms rely on bitexts only and do not leverage the fact that many parallel corpora are multiparallel. In this work, we exploit multiparallelity of corpora by representing an initial set of bilingual alignments as a graph and then predicting additional edges in the graph. We present two graph algorithms for edge prediction: one inspired by recommender systems and one based on network link prediction. Our experimental results show absolute improvements of F-1 of up to 28% over the baseline bilingual word aligner in different datasets.
BN 978-1-955917-09-4
PY 2021
BP 8457
EP 8469
UT WOS:000860727002043
ER

PT C
AU Nishikawa, S
   Ri, R
   Tsuruoka, Y
AF Nishikawa, Sosuke
   Ri, Ryokan
   Tsuruoka, Yoshimasa
GP Assoc Computat Linguist
TI Data Augmentation with Unsupervised Machine Translation Improves the
   Structural Similarity of Cross-lingual Word Embeddings
SO ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON
   NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE STUDENT RESEARCH
   WORKSHOP
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB Unsupervised cross-lingual word embedding (CLWE) methods learn a linear transformation matrix that maps two monolingual embedding spaces that are separately trained with mon-olingual corpora. This method relies on the assumption that the two embedding spaces are structurally similar, which does not necessarily hold true in general. In this paper, we argue that using a pseudo-parallel corpus generated by an unsupervised machine translation model facilitates the structural similarity of the two embedding spaces and improves the quality of CLWEs in the unsupervised mapping method. We show that our approach outperforms other alternative approaches given the same amount of data, and, through detailed analysis, we show that data augmentation with the pseudo data from unsupervised machine translation is especially effective for mapping-based CLWEs because (1) the pseudo data makes the source and target corpora (partially) parallel; (2) the pseudo data contains information on the original language that helps to learn similar embedding spaces between the source and target languages.
BN 978-1-954085-55-8
PY 2021
BP 163
EP 173
UT WOS:000694722600017
ER

PT C
AU Junczys-Dowmunt, M
AF Junczys-Dowmunt, Marcin
GP Assoc Computat Linguist
TI Microsoft Translator at WMT 2019: Towards Large-Scale Document-Level
   Neural Machine Translation
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019)
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB This paper describes the Microsoft Translator submissions to the WMT19 news translation shared task for English-German. Our main focus is document-level neural machine translation with deep transformer models. We start with strong sentence-level baselines, trained on large-scale data created via data-filtering and noisy back-translation and find that back-translation seems to mainly help with translationese input. We explore fine-tuning techniques, deeper models and different ensembling strategies to counter these effects. Using document boundaries present in the authentic and synthetic parallel data, we create sequences of up to 1000 subword segments and train transformer translation models. We experiment with data augmentation techniques for the smaller authentic data with document-boundaries and for larger authentic data without boundaries. We further explore multi-task training for the incorporation of document-level source language monolingual data via the BERT-objective on the encoder and two-pass decoding for combinations of sentence-level and document-level systems. Based on preliminary human evaluation results, evaluators strongly prefer the document-level systems over our comparable sentence-level system. The document-level systems also seem to score higher than the human references in source-based direct assessment.
BN 978-1-950737-27-7
PY 2019
BP 225
EP 233
UT WOS:000538566200021
ER

PT C
AU Ruckle, A
   Swarnkar, K
   Gurevych, I
AF Ruckle, Andreas
   Swarnkar, Krishnkant
   Gurevych, Iryna
GP Assoc Comp Machinery
TI Improved Cross-Lingual Question Retrieval for Community Question
   Answering
SO WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW
   2019)
CT World Wide Web Conference (WWW)
CY MAY 13-17, 2019
CL San Francisco, CA
SP Assoc Comp Machinery, Microsoft, Amazon, Bloomberg, Google, Criteo AI Lab, CISCO, NTENT, Spotify, Yahoo Res, Wikimedia Fdn, Baidu, DiDi, eBay, Facebook, LinkedIn, Megagon Labs, Mix, Mozilla, Netflix Res, NE Univ, Khoury Coll Comp Sci, Pinterest, Quora, Visa Res, Walmart Labs, Airbnb, Letgo, Gordon & Betty Moore Fdn, Webcastor
AB We perform cross-lingual question retrieval in community question answering (cQA), i.e., we retrieve similar questions for queries that are given in another language. The standard approach to cross-lingual information retrieval, which is to automatically translate the query to the target language and continue with a monolingual retrieval model, typically falls short in cQA due to translation errors. This is even more the case for specialized domains such as in technical cQA, which we explore in this work. To remedy, we propose two extensions to this approach that improve cross-lingual question retrieval: (1) we enhance an NMT model with monolingual cQA data to improve the translation quality, and (2) we improve the robustness of a state-of-the-art neural question retrieval model to common translation errors by adding back-translations during training. Our results show that we achieve substantial improvements over the baseline approach and considerably close the gap to a setup where we have access to an external commercial machine translation service (i.e., Google Translate), which is often not the case in many practical scenarios. Our source code and data is publicly available.(1)
OI Ruckle, Andreas/0000-0002-4962-0556
BN 978-1-4503-6674-8
PY 2019
BP 3179
EP 3186
DI 10.1145/3308558.3313502
UT WOS:000483508403036
ER

PT C
AU Lapshinova-Koltunski, E
   Ferreira, P
   Lartaud, E
   Hardmeier, C
AF Lapshinova-Koltunski, Ekaterina
   Ferreira, Pedro
   Lartaud, Elina
   Hardmeier, Christian
BA Mariani, J
BF Mariani, J
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mazo, H
   Odijk, H
   Piperidis, S
TI ParCorFull2.0: a Parallel Corpus Annotated with Full Coreference
SO LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION
CT 13th International Conference on Language Resources and Evaluation
   (LREC)
CY JUN 20-25, 2022
CL Marseille, FRANCE
SP Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur
AB In this paper, we describe ParCorFull2.0, a parallel corpus annotated with full coreference chains for multiple languages, which is an extension of the existing corpus ParCorFull (Lapshinova-Koltunski et al., 2018). Similar to the previous version, this corpus has been created to address translation of coreference across languages, a phenomenon still challenging for machine translation (MT) and other multilingual natural language processing (NLP) applications. The current version of the corpus that we present here contains not only parallel texts for the language pair English-German, but also for English-French and English-Portuguese, which are all major European languages. The new language pairs belong to the Romance languages. The addition of a new language group creates a need of extension not only in terms of texts added, but also in terms of the annotation guidelines. Both French and Portuguese contain structures not found in English and German. Moreover, Portuguese is a pro-drop language bringing even more systemic differences in the realisation of coreference into our cross-lingual resources. These differences cause problems for multilingual coreference resolution and machine translation. Our parallel corpus with full annotation of coreference will be a valuable resource with a variety of uses not only for NLP applications, but also for contrastive linguists and researchers in translation studies.
BN 979-10-95546-72-6
PY 2022
BP 805
EP 813
UT WOS:000889371700085
ER

PT J
AU Li, MX
   Wang, MW
   Li, HX
   Xu, F
AF Li, Maoxi
   Wang, Mingwen
   Li, Hanxi
   Xu, Fan
TI Modeling Monolingual Character Alignment for Automatic Evaluation of
   Chinese Translation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB Automatic evaluation of machine translations is an important task. Most existing evaluation metrics rely on matching the same word or letter n-grams. This strategy leads to poor results on Chinese translations because one has to rely merely on matching identical characters. In this article, we propose a new evaluation metric that allows different characters with the same or similar meaning to match. An Indirect Hidden Markov Model (IHMM) is proposed to align the Chinese translation with human references at the character level. In the model, the emission probabilities are estimated by character similarity, including character semantic similarity and character surface similarity, and transition probabilities are estimated by a heuristic distance-based distortion model. When evaluating the submitted output of English-to-Chinese translation systems in the IWSLT'08 CT-EC and NIST'08 EC tasks, the experimental results indicate that the proposed metric has a significantly better correlation with human evaluation than the state-of-the-art machine translation metrics (i.e., BLEU, Meteor Universal, and TESLA-CELAB). This study shows that it is important to allow different characters to match in the evaluation of Chinese translations and that the IHMM is a reasonable approach for the alignment of Chinese characters.
SN 2375-4699
EI 2375-4702
PD MAR
PY 2016
VL 15
IS 3
AR 16
DI 10.1145/2815619
UT WOS:000373913600006
ER

PT C
AU Gladkoff, S
   Han, LF
AF Gladkoff, Serge
   Han, Lifeng
BA Mariani, J
BF Mariani, J
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mazo, H
   Odijk, H
   Piperidis, S
TI HOPE: A Task-Oriented and Human-Centric Evaluation Framework Using
   Professional Post-Editing Towards More Effective MT Evaluation
SO LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION
CT 13th International Conference on Language Resources and Evaluation
   (LREC)
CY JUN 20-25, 2022
CL Marseille, FRANCE
SP Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur
AB Traditional automatic evaluation metrics for machine translation have been widely criticized by linguists due to their low accuracy, lack of transparency, focus on language mechanics rather than semantics, and low agreement with human quality evaluation. Human evaluations in the form of MQM-like scorecards have always been carried out in real industry setting by both clients and translation service providers (TSPs). However, traditional human translation quality evaluations are costly to perform and go into great linguistic detail, raise issues as to inter-rater reliability (IRR) and are not designed to measure quality of worse than premium quality translations. In this work, we introduce HOPE, a task-oriented and human-centric evaluation framework for machine translation output based on professional post-editing annotations. It contains only a limited number of commonly occurring error types, and uses a scoring model with geometric progression of error penalty points (EPPs) reflecting error severity level to each translation unit. The initial experimental work carried out on English-Russian language pair MT outputs on marketing content type of text from highly technical domain reveals that our evaluation framework is quite effective in reflecting the MT output quality regarding both overall system-level performance and segment-level transparency, and it increases the IRR for error type interpretation. The approach has several key advantages, such as ability to measure and compare less than perfect MT output from different systems, ability to indicate human perception of quality, immediate estimation of the labor effort required to bring MT output to premium quality, low-cost and faster application, as well as higher IRR. Our experimental data is available at https://github.com/lHan87/HOPE.
BN 979-10-95546-72-6
PY 2022
BP 13
EP 21
UT WOS:000889371700002
ER

PT C
AU Ucan, A
   Naderalvojoud, B
   Sezer, EA
   Sever, H
AF Ucan, Alaettin
   Naderalvojoud, Behzad
   Sezer, Ebru Akcapinar
   Sever, Hayri
BE Yetongnon, K
   Dipanda, A
   DePietro, RCG
   Gallo, L
TI SentiWordNet for New Language: Automatic Translation Approach
SO 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY &
   INTERNET-BASED SYSTEMS (SITIS)
CT 12th International Conference on Signal-Image Technology and
   Internet-Based Systems (SITIS)
CY NOV 28-DEC 01, 2016
CL Naples, ITALY
SP IEEE, IEEE Comp Soc, Univ Bourgogne, CNRS, ACM SIGAPP, IFIP, Natl Res Council Italy, Inst High Performance Comp & Networking, Univ Naples Federico II, Univ Milan, Univ Bourgogne, Lab Elect Image Informatique Res Grp, Univ Stvdiorvm Mediolanensis, Distretto Alta Tecnologia Beni Culturali, ACM
AB This paper proposes an automatic translation approach to create a sentiment lexicon for a new language from available English resources. In this approach, an automatic mapping is generated from a sense-level resource to a word-level by applying a triple unification process. This process produces a single polarity score for each term by incorporating all sense polarities. The major idea is to deal with the sense ambiguity during the lexicon transfer and provide a general sentiment lexicon for languages like Turkish which do not have a freely available machine-readable dictionary. On the other hand, the translation quality is critical in the lexicon transfer due to the ambiguity problem. Thus, this paper also proposes a multiple bilingual translation approach to find the most appropriate equivalents for the source language terms. In this approach, three parallel, series and hybrid algorithms are used to integrate the translation results. Finally, three lexicons are achieved for the target language with different sizes. The performance of three lexicons is evaluated in the lexicon-based sentiment classification task and compared with the results achieved by the supervised approach. According to experimental results, the proposed approach can produce reliable sentiment lexicons for the target language.
RI Sezer, Ebru Akcapinar/H-5566-2011; UÇAN, Alaettin/E-9147-2013
OI Sezer, Ebru Akcapinar/0000-0002-9287-2679; UÇAN,
   Alaettin/0000-0002-2493-4022; Sever, Hayri/0000-0002-8261-0675
BN 978-1-5090-5698-9
PY 2016
BP 308
EP 315
DI 10.1109/SITIS.2016.57
UT WOS:000406473000048
ER

PT C
AU D'Haro, LF
   Banchs, RE
AF D'Haro, Luis Fernando
   Banchs, Rafael E.
GP Int Speech Commun Assoc
TI Automatic Correction of ASR outputs by Using Machine Translation
SO 17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH
   PROCESSING IN HUMANS AND MACHINES
SE Interspeech
CT 17th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2016)
CY SEP 08-12, 2016
CL San Francisco, CA
SP apple, amazon alexa, Google, Microsoft, ebay, facebook, YAHOO JAPAN, Baidu Res, IBM Res, CIRRUS LOGIC, DATATANG, NUANCE, Speechocean Ltd, Yandex, Raytheon Technol
AB One of the main challenges when working with a domain independent automatic speech recognizers (ASR) is to correctly transcribe rare or out-of-vocabulary words that are not included in the language model or whose probabilities are sub-estimated. Although the common solution would be to adapt the language models and pronunciation vocabularies, in some conditions, like when using free online recognizers, that is not possible and therefore it is necessary to apply post recognition rectifications. In this paper, we propose an automatic correction procedure based on using a phrase-based machine translation system trained using words and phonetic encoding representations to the generated n-best lists of ASR results. Our experiments on two different datasets: human computer interfaces for robots, and human to human dialogs about tourism information show that the proposed methodology can provide a quick and robust mechanism to improve the performance of the ASR by reducing the word error rate (WER) and character error rate (CER).
RI D'Haro, Luis Fernando L.F/B-8194-2011
OI D'Haro, Luis Fernando L.F/0000-0002-3411-7384
SN 2308-457X
BN 978-1-5108-3313-5
PY 2016
BP 3469
EP 3473
DI 10.21437/Interspeech.2016-299
UT WOS:000409394402075
ER

PT C
AU Fang, M
   Gao, QS
   Yu, ZB
AF Fang, M
   Gao, QS
   Yu, ZB
GP IEEE
TI A semi-automatic extraction of the SERB in machine translation based on
   SL
SO PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON NATURAL
   LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING (IEEE NLP-KE'05)
CT International Conference on Natural Language Processing and Knowledge
   Engineering
CY OCT 30-NOV 01, 2005
CL Wuhan, PEOPLES R CHINA
SP IEEE, AAI, CIPSC, Chinese Assoc Artificial Intelligence, IEEE Signal Proc Soc, IEEE Beijing Sect
AB Machine translation based on semantic language (SL) should include a large scale Semantic Element Representation Base (SERB), which needs to be extracted from corpus automatically or at least semi-automatically. This paper presents a practical and efficient semi-automatic method to build a SERB from parallel corpus. This method processes the basic characters in both Chinese sentences and English sentences directly, instead of using Chinese word segmentation. First, a preliminary SERB is built. Then some Semantic Elements (SEs) are picked up by SER pattern match algorithm from the SERB and some of them are pruned by SE pruning algorithm. Last, the SEs are reconstructed to build some SE trees and new SEs and the SEs whose parameter vector categories need to be modified are put forward to users to examine and the correct SEs are appended to the SERB. Thus the SERB is built up. The correctness of the SEs in SERB can be guaranteed.
BN 0-7803-9361-9
PY 2005
BP 398
EP 403
UT WOS:000235577200075
ER

PT J
AU Casacuberta, F
   Vidal, E
AF Casacuberta, F
   Vidal, E
TI Machine translation with inferred stochastic finite-state transducers
SO COMPUTATIONAL LINGUISTICS
AB Finite-state transducers are models that are being used in different areas of pattern recognition and computational linguistics. One of these areas is machine translation, in which the approaches that are based on building models automatically from training examples are becoming more and more attractive. Finite-state transducers are very adequate for use in constrained tasks in which training samples of pairs of sentences are available. A technique for inferring finite-state transducers is proposed in this article. This technique is based on formal relations between finite-state transducers and rational grammars. Given a training corpus of source-target pairs of sentences, the proposed approach uses statistical alignment methods to produce a set of conventional strings from which a stochastic rational grammar (e.g., an n-gram) is inferred. This grammar is finally converted into a finite-state transducer. The proposed methods are assessed through a series of machine translation experiments within the framework of the EuTrans project.
RI Casacuberta, Francisco/T-3667-2017
OI Casacuberta, Francisco/0000-0002-8497-5598
SN 0891-2017
EI 1530-9312
PD JUN
PY 2004
VL 30
IS 2
BP 205
EP 225
DI 10.1162/089120104323093294
UT WOS:000222533400004
ER

PT C
AU Wu, NE
   Hou, HX
   Sun, S
   Zheng, W
AF Wu, Nier
   Hou, Hongxu
   Sun, Shuo
   Zheng, Wei
GP IEEE
TI Low-Resource Neural Machine Translation with Neural Episodic Control
SO 2021 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY JUL 18-22, 2021
CL ELECTR NETWORK
SP Int Neural Network Soc, IEEE Computat Intelligence Soc
AB Reinforcement Learning (RL) has been proved to alleviate metric inconsistency and exposure deviation in training-evaluation of neural machine translation (NMT), but the sample efficiency is limited by sampling methods (Temporal-Difference (TD) or Monte-Carlo (MC)), and still cannot compensate for the inefficient non-zero rewards caused by insufficient data sets. In addition, RL rewards can only be effective when the model parameters are basically determined. Therefore, we proposed episodic control reinforcement learning method, which obtains the model with basically determined parameters through the knowledge transfer, and records the historical action trajectory by introducing semi-tabular differentiable neural dictionary (DND), the model can quickly approximate the real state-value according to samples reward when updating policy. We verified on CCMT2019 Mongolian-Chinese (Mo-Zh), Tibetan-Chinese (Ti-Zh), and Uyghur-Chinese (Ug-Zh) tasks, and the results showed that the quality was significantly improved, which fully demonstrated the effectiveness of the method.
RI Zheng, Wei/GQQ-8951-2022
SN 2161-4393
BN 978-0-7381-3366-9
PY 2021
DI 10.1109/IJCNN52387.2021.9533677
UT WOS:000722581703010
ER

PT C
AU Inoue, G
   Habash, N
   Matsumoto, Y
   Aoyama, H
AF Inoue, Go
   Habash, Nizar
   Matsumoto, Yuji
   Aoyama, Hiroyuki
BA Declerck, T
BF Declerck, T
BE Calzolari, N
   Choukri, K
   Cieri, C
   Hasida, K
   Isahara, H
   Maegaard, B
   Mariani, J
   Moreno, A
   Odijk, J
   Piperidis, S
   Tokunaga, T
   Goggi, S
   Mazo, H
TI A Parallel Corpus of Arabic-Japanese News Articles
SO PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE
   RESOURCES AND EVALUATION (LREC 2018)
CT 11th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 07-12, 2018
CL Miyazaki, JAPAN
AB Much work has been done on machine translation between major language pairs including Arabic-English and English-Japanese thanks to the availability of large-scale parallel corpora with manually verified subsets of parallel sentences. However, there has been little research conducted on the Arabic-Japanese language pair due to its parallel-data scarcity, despite being a good example of interestingly contrasting differences in typology. In this paper, we describe the creation process and statistics of the Arabic-Japanese portion of the TUFS Media Corpus, a parallel corpus of translated news articles collected at Tokyo University of Foreign Studies (TUFS). Part of the corpus is manually aligned at the sentence level for development and testing. The corpus is provided in two formats: A document-level parallel corpus in XML format, and a sentence-level parallel corpus in plain text format. We also report the first results of Arabic-Japanese phrase-based machine translation trained on our corpus.
OI Habash, Nizar/0000-0002-1831-3457
BN 979-10-95546-00-9
PY 2018
BP 918
EP 924
UT WOS:000725545000147
ER

PT J
AU Passban, P
   Liu, Q
   Way, A
AF Passban, Peyman
   Liu, Qun
   Way, Andy
TI Translating Low-Resource Languages by Vocabulary Adaptation from Close
   Counterparts
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB Some natural languages belong to the same family or share similar syntactic and/or semantic regularities. This property persuades researchers to share computational models across languages and benefit from high-quality models to boost existing low-performance counterparts. In this article, we follow a similar idea, whereby we develop statistical and neural machine translation (MT) engines that are trained on one language pair but are used to translate another language. First we train a reliable model for a high-resource language, and then we exploit cross-lingual similarities and adapt the model to work for a close language with almost zero resources. We chose Turkish (Tr) and Azeri or Azerbaijani (Az) as the proposed pair in our experiments. Azeri suffers from lack of resources as there is almost no bilingual corpus for this language. Via our techniques, we are able to train an engine for the Az. English (En) direction, which is able to outperform all other existing models.
OI Way, Andy/0000-0001-5736-5930
SN 2375-4699
EI 2375-4702
PD SEP
PY 2017
VL 16
IS 4
AR 29
DI 10.1145/3099556
UT WOS:000414326000008
ER

PT J
AU Liu, Y
AF Liu, Yan
TI A B/S-Based Computer-Aided Translation Teaching Method
SO MOBILE INFORMATION SYSTEMS
AB English and Chinese are fundamentally different in many ways, due to which miscommunications are common in both languages. For this purpose, there are several English-Chinese translation systems available these days, but most of them provide a sluggish interactive experience, primarily due to erroneous language, grammatical problems, imprecise pronunciation of the system, and slow translation feedback speed. Therefore, there is a need to develop an efficient and collaborative system. Due to these factors, this paper proposes an interactive machine translation system for English-Chinese based on the B/S architecture to aid communication between English and Chinese speakers in both directions. This system is designed based on the B/S three-layer architecture. To achieve the desired results, this paper explains the machine translations mode and then implements the overall system design based on the process of system operation, algorithm for translation enhancement, network structure, and application, respectively. Lastly, an investigational platform is created using the WINCC6.0 operating system to evaluate the overall system performance. Results of the system testing demonstrate that the comprehensive score of manual evaluation is 3.769 points, which is higher than the limit value of 3.5, which shows that the system's translation quality is high and that it can fulfill the expectations of users.
SN 1574-017X
EI 1875-905X
PD MAY 31
PY 2022
VL 2022
AR 3819239
DI 10.1155/2022/3819239
UT WOS:000811271700024
ER

PT J
AU Formiga, L
   Barron-Cedeno, A
   Marquez, L
   Henriquez, CA
   Marino, JB
AF Formiga, Lluis
   Barron-Cedeno, Alberto
   Marquez, Lluis
   Henriquez, Carlos A.
   Marino, Jose B.
TI Leveraging Online User Feedback to Improve Statistical Machine
   Translation
SO JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH
AB In this article we present a three-step methodology for dynamically improving a statistical machine translation (SMT) system by incorporating human feedback in the form of free edits on the system translations. We target at feedback provided by casual users, which is typically error-prone. Thus, we first propose a filtering step to automatically identify the better user-edited translations and discard the useless ones. A second step produces a pivot-based alignment between source and user-edited sentences, focusing on the errors made by the system. Finally, a third step produces a new translation model and combines it linearly with the one from the original system. We perform a thorough evaluation on a real-world dataset collected from the Reverso.net translation service and show that every step in our methodology contributes significantly to improve a general purpose SMT system. Interestingly, the quality improvement is not only due to the increase of lexical coverage, but to a better lexical selection, reordering, and morphology. Finally, we show the robustness of the methodology by applying it to a different scenario, in which the new examples come from an automatically Web-crawled parallel corpus. Using exactly the same architecture and models provides again a significant improvement of the translation quality of a general purpose baseline SMT system.
OI Barron-Cedeno, Alberto/0000-0003-4719-3420; Formiga,
   Lluis/0000-0001-9515-6611
SN 1076-9757
EI 1943-5037
PY 2015
VL 54
BP 159
EP 192
DI 10.1613/jair.4716
UT WOS:000365177800004
ER

PT J
AU Matricciani, E
AF Matricciani, Emilio
TI Linguistic Mathematical Relationships Saved or Lost in Translating
   Texts: Extension of the Statistical Theory of Translation and Its
   Application to the New Testament
SO INFORMATION
AB The purpose of the paper is to extend the general theory of translation to texts written in the same language and show some possible applications. The main result shows that the mutual mathematical relationships of texts in a language have been saved or lost in translating them into another language and consequently texts have been mathematically distorted. To make objective comparisons, we have defined a "likeness index"-based on probability and communication theory of noisy binary digital channels-and have shown that it can reveal similarities and differences of texts. We have applied the extended theory to the New Testament translations and have assessed how much the mutual mathematical relationships present in the original Greek texts have been saved or lost in 36 languages. To avoid the inaccuracy, due to the small sample size from which the input data (regression lines) are calculated, we have adopted a "renormalization" based on Monte Carlo simulations whose results we consider as "experimental". In general, we have found that in many languages/translations the original linguistic relationships have been lost and texts mathematically distorted. The theory can be applied to texts translated by machines. Because the theory deals with linear regression lines, the concepts of signal-to-noise-ratio and likenss index can be applied any time a scientific/technical problem involves two or more linear regression lines, therefore it is not limited to linguistic variables but it is universal.
OI Matricciani, Emilio/0000-0002-6506-4238
EI 2078-2489
PD JAN
PY 2022
VL 13
IS 1
AR 20
DI 10.3390/info13010020
UT WOS:000757644900001
ER

PT C
AU Al-Obaidli, F
   Cox, S
   Nakov, P
AF Al-Obaidli, Fahad
   Cox, Stephen
   Nakov, Preslav
BE Gelbukh, A
TI Bi-text Alignment of Movie Subtitles for Spoken English-Arabic
   Statistical Machine Translation
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING, (CICLING
   2016), PT II
SE Lecture Notes in Computer Science
CT 17th International Conference on Intelligent Text Processing and
   Computational Linguistics (CICLing)
CY APR 03-09, 2016
CL Mevlana Univ, Konya, TURKEY
HO Mevlana Univ
AB We describe efforts towards getting better resources for English-Arabic machine translation of spoken text. In particular, we look at movie subtitles as a unique, rich resource, as subtitles in one language often get translated into other languages. Movie subtitles are not new as a resource and have been explored in previous research; however, here we create a much larger bi-text (the biggest to date), and we further generate better quality alignment for it. Given the subtitles for the same movie in different languages, a key problem is how to align them at the fragment level. Typically, this is done using length-based alignment, but for movie subtitles, there is also time information. Here we exploit this information to develop an original algorithm that outperforms the current best subtitle alignment tool, subalign. The evaluation results show that adding our bi-text to the IWSLT training bi-text yields an improvement of over two BLEU points absolute.
RI Nakov, Preslav/D-2421-2017
OI Nakov, Preslav/0000-0002-3600-1510
SN 0302-9743
EI 1611-3349
BN 978-3-319-75487-1; 978-3-319-75486-4
PY 2018
VL 9624
BP 127
EP 139
DI 10.1007/978-3-319-75487-1_11
PN II
UT WOS:000540377700011
ER

PT C
AU Parameswarappa, S
   Narayana, VN
AF Parameswarappa, S.
   Narayana, V. N.
BE Krishna, PV
   Babu, MR
   Ariwa, E
TI Kannada Word Sense Disambiguation Using Association Rules
SO GLOBAL TRENDS IN INFORMATION SYSTEMS AND SOFTWARE APPLICATIONS, PT 2
SE Communications in Computer and Information Science
CT 4th ObCom International Conference on Recent Trends in Computing,
   Communication and Information Technology
CY DEC 09-11, 2011
CL Vellore, INDIA
SP Vellore Inst Technol Univ, Sch Comp Sci & Engn
AB Disambiguating the polysemous word is one of the major issues in the process of Machine Translation. The word may have many senses, selecting the most appropriate sense for an ambiguous word in a sentence is a central problem in Machine Translation. Because, each sense of a word in a source language sentence may generate different target language sentences. Knowledge and corpus based methods are usually applied for disambiguation task. In the present paper, we propose an algorithm to disambiguate Kannada polysemous words using association rules. We built Kannada corpora using web resources. The corpora are divided in to training and testing corpora. The association rules required for disambiguation tasks are extracted from training corpora. The example sentences needs to be disambiguated are stored in testing corpora. The proposed algorithm attempts to disambiguate all the content words such as nouns, verbs, adverbs, adjectives in an unrestricted text using association rules.
SN 1865-0929
BN 978-3-642-29215-6
PY 2012
VL 270
BP 47
EP +
UT WOS:000312877200007
ER

PT C
AU Wei, XP
   Hu, Y
   Xing, LX
   Wang, YP
   Gao, L
AF Wei, Xiangpeng
   Hu, Yue
   Xing, Luxi
   Wang, Yipeng
   Gao, Li
GP AAAI
TI Translating with Bilingual Topic Knowledge for Neural Machine
   Translation
SO THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 33rd AAAI Conference on Artificial Intelligence / 31st Innovative
   Applications of Artificial Intelligence Conference / 9th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY JAN 27-FEB 01, 2019
CL Honolulu, HI
SP Assoc Advancement Artificial Intelligence
AB The dominant neural machine translation (NMT) models that based on the encoder-decoder architecture have recently achieved the state-of-the-art performance. Traditionally, the NMT models only depend on the representations learned during training for mapping a source sentence into the target domain. However, the learned representations often suffer from implicit and inadequately informed properties. In this paper, we propose a novel bilingual topic enhanced NMT (BLTNMT) model to improve translation performance by incorporating bilingual topic knowledge into NMT. Specifically, the bilingual topic knowledge is included into the hidden states of both encoder and decoder, as well as the attention mechanism. With this new setting, the proposed BLT-NMT has access to the background knowledge implied in bilingual topics which is beyond the sequential context, and enables the attention mechanism to attend to topic-level attentions for generating accurate target words during translation. Experimental results show that the proposed model consistently outperforms the traditional RNNsearch and the previous topic-informed NMT on Chinese-English and English-German translation tasks. We also introduce the bilingual topic knowledge into the newly emerged Transformer base model on English-German translation and achieve a notable improvement.
RI Hu, Yue/HGE-1673-2022
SN 2159-5399
EI 2374-3468
BN 978-1-57735-809-1
PY 2019
BP 7257
EP 7264
UT WOS:000486572501098
ER

PT C
AU Chousa, K
   Morishita, M
AF Chousa, Katsuki
   Morishita, Makoto
GP Assoc Computat Linguist
TI Input Augmentation Improves Constrained Beam Search for Neural Machine
   Translation: NTT at WAT 2021
SO WAT 2021: THE 8TH WORKSHOP ON ASIAN TRANSLATION
CT 8th Workshop on Asian Translation (WAT)
CY AUG 05-06, 2021
CL ELECTR NETWORK
AB This paper describes our systems that were submitted to the restricted translation task at WAT 2021. In this task, the systems are required to output translated sentences that contain all given word constraints. Our system combined input augmentation and constrained beam search algorithms. Through experiments, we found that this combination significantly improves translation accuracy and can save inference time while containing all the constraints in the output. For both En -> Ja and Ja -> En, our systems obtained the best translation performances in both automatic and human evaluations.
BN 978-1-954085-63-3
PY 2021
BP 53
EP 61
UT WOS:000686140700003
ER

PT C
AU Murakami, S
   Morishita, M
   Hirao, T
   Nagata, M
AF Murakami, Soichiro
   Morishita, Makoto
   Hirao, Tsutomu
   Nagata, Masaaki
GP Assoc Computat Linguist
TI NTT's Machine Translation Systems for WMT19 Robustness Task
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019)
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB This paper describes NTT's submission to the WMT19 robustness task. This task mainly focuses on translating noisy text (e.g., posts on Twitter), which presents different difficulties from typical translation tasks such as news. Our submission combined techniques including utilization of a synthetic corpus, domain adaptation, and a placeholder mechanism, which significantly improved over the previous baseline. Experimental results revealed the placeholder mechanism, which temporarily replaces the non-standard tokens including emojis and emoticons with special placeholder tokens during translation, improves translation accuracy even with noisy texts.
BN 978-1-950737-27-7
PY 2019
BP 544
EP 551
UT WOS:000538566200065
ER

PT J
AU Vilares, J
   Vilares, M
   Alonso, MA
   Oakes, MP
AF Vilares, Jesus
   Vilares, Manuel
   Alonso, Miguel A.
   Oakes, Michael P.
TI On the feasibility of character n-grams pseudo-translation for
   Cross-Language Information Retrieval tasks
SO COMPUTER SPEECH AND LANGUAGE
AB The field of Cross-Language Information Retrieval relates techniques close to both the Machine Translation and Information Retrieval fields, although in a context involving characteristics of its own. The present study looks to widen our knowledge about the effectiveness and applicability to that field of non-classical translation mechanisms that work at character n-gram level. For the purpose of this study, an n-gram based system of this type has been developed. This system requires only a bilingual machine-readable dictionary of n-grams, automatically generated from parallel corpora, which serves to translate queries previously n-grammed in the source language. n-Gramming is then used as an approximate string matching technique to perform monolingual text retrieval on the set of n-grammed documents in the target language.
   The tests for this work have been performed on CLEF collections for seven European languages, taking English as the target language. After an initial tuning phase in order to analyze the most effective way for its application, the results obtained, close to the upper baseline, not only confirm the consistency across languages of this kind of character n-gram based approaches, but also constitute a further proof of their validity and applicability, these not being tied to a given implementation. (C) 2015 Elsevier Ltd. All rights reserved.
RI Alonso, Miguel A./A-5903-2011; Vilares, Jesus/A-8863-2013
OI Alonso, Miguel A./0000-0001-9254-4934; Vilares,
   Jesus/0000-0003-2941-1834; Oakes, Michael/0000-0003-2793-8245
SN 0885-2308
EI 1095-8363
PD MAR
PY 2016
VL 36
BP 136
EP 164
DI 10.1016/j.csl.2015.09.004
UT WOS:000367123000009
ER

PT J
AU Su, JS
   Zeng, JL
   Xie, J
   Wen, HT
   Yin, YJ
   Liu, Y
AF Su, Jinsong
   Zeng, Jiali
   Xie, Jun
   Wen, Huating
   Yin, Yongjing
   Liu, Yang
TI Exploring Discriminative Word-Level Domain Contexts for Multi-Domain
   Neural Machine Translation
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB Owing to its practical significance, multi-domain Neural Machine Translation (NMT) has attracted much attention recently. Recent studies mainly focus on constructing a unified NMT model with mixed-domain training corpora to switch translation between different domains. In these models, the words in the same sentence are not well distinguished, while intuitively, they are related to the sentence domain to varying degrees and thus should exert different effects on the multi-domain NMT model. In this article, we are committed to distinguishing and exploiting different word-level domain contexts for multi-domain NMT. For this purpose, we adopt multi-task learning to jointly model NMT and monolingual attention-based domain classification tasks, improving the NMT model in two ways: 1) One domain classifier and one adversarial domain classifier are introduced to conduct domain classifications of input sentences. During this process, two generated gating vectors are used to produce domain-specific and domain-shared annotations for decoder; 2) We equip decoder with an attentional domain classifier. Then, the derived attentional weights are utilized to refine the model training via word-level cost weighting, so that the impacts of target words can be discriminated by their relevance to sentence domain. Experimental results on several multi-domain translations demonstrate the effectiveness of our model.
OI Liu, Yang/0000-0002-3087-242X
SN 0162-8828
EI 1939-3539
PD MAY 1
PY 2021
VL 43
IS 5
BP 1530
EP 1545
DI 10.1109/TPAMI.2019.2954406
UT WOS:000637533800005
PM 31751225
ER

PT J
AU Kang, LY
   He, SJ
   Wang, MX
   Long, F
   Su, JS
AF Kang, Liyan
   He, Shaojie
   Wang, Mingxuan
   Long, Fei
   Su, Jinsong
TI Bilingual attention based neural machine translation
SO APPLIED INTELLIGENCE
AB In recent years, Recurrent Neural Network based Neural Machine Translation (RNN-based NMT) equipped with an attention mechanism from the decoder to encoder, has achieved great advancements and exhibited good performance in many language pairs. However, little work has been done on the attention mechanism for the target side, which has the potential to further improve NMT. To address this issue, in this paper, we propose a novel bilingual attention based NMT, where its bilingual attention mechanism exploits decoding history and enables the NMT model to better dynamically select and exploit source side and target side information. Compared with previous RNN-based NMT models, our model has two advantages: First, our model exercises a dynamic control over the ratios at which source and target contexts respectively contribute to the generation of the next target word. In this way, the weakly induced structure relations on both sides can be exploited for NMT. Second, through short-cut connections, the training errors of our model can be directly back-propagated, which effectively alleviates the gradient vanishing or exploding issue. Experimental results and in-depth analyses on Chinese-English, English-German, and English-French translation tasks show that our model with proper configurations can significantly surpass the dominant NMT model, Transformer. Particularly, our proposed model has won the first prize in the English-Chinese translation task of WMT2018.
SN 0924-669X
EI 1573-7497
PD FEB
PY 2023
VL 53
IS 4
BP 4302
EP 4315
DI 10.1007/s10489-022-03563-8
EA JUN 2022
UT WOS:000807372600004
ER

PT J
AU Zhang, WT
   Dai, LR
   Liu, JH
   Wang, SJ
AF Zhang, Weitai
   Dai, Lirong
   Liu, Junhua
   Wang, Shijin
TI Improving Many-to-Many Neural Machine Translation via Selective and
   Aligned Online Data Augmentation
SO APPLIED SCIENCES-BASEL
AB Multilingual neural machine translation (MNMT) models are theoretically attractive for low- and zero-resource language pairs with the impact of cross-lingual knowledge transfer. Existing approaches mainly focus on English-centric directions and always underperform compared to their pivot-based counterparts for non-English directions. In this work, we aim to build a many-to-many MNMT system with an emphasis on the quality of non-English directions by exploring selective and aligned online data augmentation algorithms. Based on our findings showing that the augmented synthetic samples are not "the more, the better" we propose selective online back-translation (SOBT) and thoroughly study different selection criteria to pick suitable samples for training. Furthermore, we boost SOBT with cross-lingual online substitution (CLOS) to align token representations and encourage transfer learning. Our intuition is based on the hypothesis that a universal cross-lingual representation leads to a better multilingual translation performance, especially for non-English directions. Comparing to previous state-of-the-art many-to-many MNMT models and conventional pivot-based methods, experiments on IWSLT2014 and OPUS-100 translation benchmarks show that our approach achieves a competitive or even better performance on English-centric directions and achieves up to similar to 12 BLEU for non-English directions. All of our models and codes are publicly available.
EI 2076-3417
PD MAR
PY 2023
VL 13
IS 6
AR 3946
DI 10.3390/app13063946
UT WOS:000954229500001
ER

PT C
AU Tsiamas, I
   Gallego, GI
   Escolano, C
   Fonollosa, JAR
   Costa-jussa, MR
AF Tsiamas, Ioannis
   Gallego, Gerard, I
   Escolano, Carlos
   Fonollosa, Jose A. R.
   Costa-jussa, Marta R.
GP Associ Computat Linguist
TI Pretrained Speech Encoders and Efficient Fine-tuning Methods for Speech
   Translation: UPC at IWSLT 2022
SO PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE
   TRANSLATION (IWSLT 2022)
CT 19th International Conference on Spoken Language Translation (IWSLT)
CY MAY 26-27, 2022
CL Dublin, IRELAND
SP Apple, AWS, Meta, Zoom, Microsoft, AppTek
AB This paper describes the submissions of the UPC Machine Translation group to the IWSLT 2022 Offline Speech Translation and Speech-to-Speech Translation tracks. The offline task involves translating English speech to German, Japanese and Chinese text. Our Speech Translation systems are trained end-to-end and are based on large pretrained speech and text models. We use an efficient fine-tuning technique that trains only specific layers of our system, and explore the use of adapter modules for the non-trainable layers. We further investigate the suitability of different speech encoders (wav2vec 2.0, HuBERT) for our models and the impact of knowledge distillation from the Machine Translation model that we use for the decoder (mBART). For segmenting the IWSLT test sets we fine-tune a pretrained audio segmentation model and achieve improvements of 5 BLEU compared to the given segmentation. Our best single model uses HuBERT and parallel adapters and achieves 29.42 BLEU at English-German MuST-C tstCOMMON and 26.77 at IWSLT 2020 test. By ensembling many models, we further increase translation quality to 30.83 BLEU and 27.78 accordingly. Furthermore, our submission for English-Japanese achieves 15.85 and EnglishChinese obtains 25.63 BLEU on the MuST-C tst-COMMON sets. Finally, we extend our system to perform English-German Speech-to-Speech Translation with a pretrained Text-to-Speech model.
BN 978-1-955917-41-4
PY 2022
BP 265
EP 276
UT WOS:000846899900023
ER

PT J
AU Buttner, B
   Firat, M
   Raiteri, E
AF Buttner, Benjamin
   Firat, Murat
   Raiteri, Emilio
TI Patents and knowledge diffusion The impact of machine translation
SO RESEARCH POLICY
AB One of the main rationales for the existence of the patent system is to encourage knowledge diffusion through the full disclosure of the technical knowledge embodied in a patented invention. Yet, economists and legal scholars cast doubts on the validity of the disclosure theory. The empirical evidence on the actual benefits of the disclosure function remains limited. The present paper aims to expand our understanding of how information spreads via patent disclosure and exploits recent improvements in machine translation (MT) to identify the effect of broader access to patented knowledge. More specifically, the paper uses a unique natural experiment. In September 2013, Google launched a major upgrade to its Google Patents service and added patent applications from the China National Intellectual Property Agency (CNIPA) to its searchable patent database. Using a difference-in-differences approach, we show that the translation of the Chinese patents into English resulted in an increase in citations received from patents filed by US inventors compared to a suitable control group comprising patents that Google translated only in 2016. Our results suggest that improved access to patented knowledge fosters knowledge diffusion.
OI FIRAT, Murat/0000-0001-8483-3533; raiteri, emilio/0000-0002-2769-1660
SN 0048-7333
EI 1873-7625
PD DEC
PY 2022
VL 51
IS 10
AR 104584
DI 10.1016/j.respol.2022.104584
EA JUL 2022
UT WOS:000830915500007
ER

PT J
AU Bakhshaei, S
   Safabakhsh, R
   Khadivi, S
AF Bakhshaei, Somayeh
   Safabakhsh, Reza
   Khadivi, Shahram
TI Extracting parallel fragments from comparable documents using a
   generative model
SO COMPUTER SPEECH AND LANGUAGE
AB Although parallel corpora are essential language resources for many natural language processing tasks, they are rare or even not available for many language pairs. Instead, comparable corpora are widely available and contain parallel fragments of information that can be used in applications like statistical machine translation systems. In this research, we propose a generative latent Dirichlet allocation based model for extracting parallel fragments from comparable documents without using any initial parallel data or bilingual lexicon. The experimental results show significant improvement if the extracted fragments generated by the proposed method are used for augmenting an existing parallel corpus in an statistical machine translation system. According to the human judgment, the accuracy of the proposed method for an English-Persian task is about 59.7%. Also, the out of vocabulary error rate for the same task is reduced by 28%. (C) 2018 Elsevier Ltd. All rights reserved.
SN 0885-2308
EI 1095-8363
PD JAN
PY 2019
VL 53
BP 25
EP 42
DI 10.1016/j.csl.2018.07.002
UT WOS:000445400100003
ER

PT C
AU Mao, ZY
   Cromieres, F
   Dabre, R
   Song, HY
   Kurohashi, S
AF Mao, Zhuoyuan
   Cromieres, Fabien
   Dabre, Raj
   Song, Haiyue
   Kurohashi, Sadao
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mariani, J
   Mazo, H
   Moreno, A
   Odijk, J
   Piperidis, S
TI JASS: Japanese-specific Sequence to Sequence Pre-training for Neural
   Machine Translation
SO PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES
   AND EVALUATION (LREC 2020)
CT 12th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 11-16, 2020
CL Marseille, FRANCE
AB Neural machine translation (NMT) needs large parallel corpora for state-of-the-art translation quality. Low-resource NMT is typically addressed by transfer learning which leverages large monolingual or parallel corpora for pre-training. Monolingual pre-training approaches such as MASS (MAsked Sequence to Sequence) are extremely effective in boosting NMT quality for languages with small parallel corpora. However, they do not account for linguistic information obtained using syntactic analyzers which is known to be invaluable for several Natural Language Processing (NLP) tasks. To this end, we propose JASS, Japanese-specific Sequence to Sequence, as a novel pre-training alternative to MASS for NMT involving Japanese as the source or target language. JASS is joint BMASS (Bunsetsu MASS) and BRSS (Bunsetsu Reordering Sequence to Sequence) pre-training which focuses on Japanese linguistic units called bunsetsus. In our experiments on ASPEC Japanese-English and News Commentary Japanese-Russian translation we show that JASS can give results that are competitive with if not better than those given by MASS. Furthermore, we show for the first time that joint MASS and JASS pre-training gives results that significantly surpass the individual methods indicating their complementary nature. We will release our code, pre-trained models and bunsetsu annotated data as resources for researchers to use in their own NLP tasks.
BN 979-10-95546-34-4
PY 2020
BP 3683
EP 3691
UT WOS:000724697204086
ER

PT C
AU White, R
   Krinke, J
AF White, Robert
   Krinke, Jens
BE Yu, Y
   Fredericks, E
   Devanbu, P
TI TESTNMT: Function-to-Test Neural Machine Translation
SO PROCEEDINGS OF THE 4TH ACM SIGSOFT INTERNATIONAL WORKSHOP ON NLP FOR
   SOFTWARE ENGINEERING (NL4SE '18)
CT 4th ACM SIGSOFT International Workshop on NLP for Software Engineering
   (NL4SE)
CY NOV 04, 2018
CL Lake Buena Vista, FL
SP Assoc Comp Machinery, ACM SIGSOFT
AB Test generation can have a large impact on the software engineering process by decreasing the amount of time and effort required to maintain a high level of test coverage. This increases the quality of the resultant software while decreasing the associated effort. In this paper, we present TestNMT, an experimental approach to test generation using neural machine translation. TestNMT aims to learn to translate from functions to tests, allowing a developer to generate an approximate test for a given function, which can then be adapted to produce the final desired test.
   We also present a preliminary quantitative and qualitative evaluation of TestNMT in both cross-project and within-project scenarios. This evaluation shows that TestNMT is potentially useful in the within-project scenario, where it achieves a maximum BLEU score of 21.2, a maximum ROUGE-L score of 38.67, and is shown to be capable of generating approximate tests that are easy to adapt to working tests.
RI Krinke, Jens/E-9011-2011
OI Krinke, Jens/0000-0003-1009-2861; White, Robert/0000-0001-9579-7072
BN 978-1-4503-6055-5
PY 2018
BP 30
EP 33
DI 10.1145/3283812.3283823
UT WOS:000462776100008
ER

PT J
AU Wang, R
   Utiyama, M
   Goto, I
   Sumita, E
   Zhao, H
   Lu, BL
AF Wang, Rui
   Utiyama, Masao
   Goto, Isao
   Sumita, Eiichiro
   Zhao, Hai
   Lu, Bao-Liang
TI Converting Continuous-Space Language Models into N-gram Language Models
   with Efficient Bilingual Pruning for Statistical Machine Translation
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB The Language Model (LM) is an essential component of Statistical Machine Translation (SMT). In this article, we focus on developing efficient methods for LM construction. Our main contribution is that we propose a Natural N-grams based Converting (NNGC) method for transforming a Continuous-Space Language Model (CSLM) to a Back-off N-gram Language Model (BNLM). Furthermore, a Bilingual LM Pruning (BLMP) approach is developed for enhancing LMs in SMT decoding and speeding up CSLM converting. The proposed pruning and converting methods can convert a large LM efficiently by working jointly. That is, a LM can be effectively pruned before it is converted from CSLM without sacrificing performance, and further improved if an additional corpus contains out-of-domain information. For different SMT tasks, our experimental results indicate that the proposed NNGC and BLMP methods outperform the existing counterpart approaches significantly in BLEU and computational cost.
RI Wang, Rui/AAI-1990-2020
OI Wang, Rui/0000-0001-8007-2503; Lu, Bao-Liang/0000-0001-8359-0058
SN 2375-4699
EI 2375-4702
PD MAR
PY 2016
VL 15
IS 3
AR 11
DI 10.1145/2843942
UT WOS:000373913600001
ER

PT C
AU Park, S
   Lee, S
   Kim, Y
   Jeon, H
   Jung, S
   Bok, J
   Seo, J
AF Park, Sebeom
   Lee, Soohyun
   Kim, Youngtaek
   Jeon, Hyeon
   Jung, Seokweon
   Bok, Jinwook
   Seo, Jinwook
GP IEEE Comp Soc
TI VANT : A Visual Analytics System for Refining Parallel Corpora in Neural
   Machine Translation
SO 2022 IEEE 15TH PACIFIC VISUALIZATION SYMPOSIUM (PACIFICVIS 2022)
SE IEEE Pacific Visualization Symposium
CT IEEE 15th Pacific Visualization Symposium (PacificVis)
CY APR 11-14, 2022
CL Tsukuba Univ, ELECTR NETWORK
SP IEEE, IEEE Comp Soc, IEEE Comp Soc, Visualizat & Graph Tech Comm
HO Tsukuba Univ
AB The quality of parallel corpora used to train a Neural Machine Translation (NMT) model can critically influence the model's performance. Various approaches for refining parallel corpora have been introduced, but there is still much room for improvements, such as enhancing the efficiency and the quality of refinement. We introduce VANT, a novel visual analytics system for refining parallel corpora used in training an NMT model. Our system helps users to readily detect and filter noisy parallel corpora by (1) aiding the quality estimation of individual sentence pairs within the corporaby providing diverse quality metrics (e.g., cosine similarity, BLEU, length ratio) and (2) allowing users to visually examine and manage the corpora based on the pre-computed metrics scores. Our system's effectiveness and usefulness are demonstrated through a qualitative user study with eight participants, including four domain experts with real-world datasets.
SN 2165-8765
BN 978-1-6654-2335-9
PY 2022
BP 181
EP 185
DI 10.1109/PacificVis53943.2022.00029
UT WOS:000850180500021
ER

PT C
AU Wolk, K
   Marasek, K
AF Wolk, Krzysztof
   Marasek, Krzysztof
BE Cooper, EW
   Rutkowski, TM
   Wierzbicki, A
   Kobzev, GA
   Kryssanov, VV
TI Building subject-aligned comparable corpora and mining it for truly
   parallel sentence pairs
SO INTERNATIONAL WORKSHOP ON INNOVATIONS IN INFORMATION AND COMMUNICATION
   SCIENCE AND TECHNOLOGY, IICST 2014
SE Procedia Technology
CT 4th International Workshop on Innovations in Information and
   Communication Science and Technology (IICST)
CY SEP 03-05, 2014
CL Polish Japanese Inst Informat Technol, Warsaw, POLAND
HO Polish Japanese Inst Informat Technol
AB Parallel sentences are a relatively scarce but extremely useful resource for many applications including cross-lingual retrieval and statistical machine translation. This research explores our methodology for mining such data from previously obtained comparable corpora. The task is highly practical since non-parallel multilingual data exist in far greater quantities than parallel corpora, but parallel sentences are a much more useful resource. Here we propose a web crawling method for building subject-aligned comparable corpora from Wikipedia articles. We also introduce a method for extracting truly parallel sentences that are filtered out from noisy or just comparable sentence pairs. We describe our implementation of a specialized tool for this task as well as training and adaption of a machine translation system that supplies our filter with additional information about the similarity of comparable sentence pairs. (C) 2014 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/3.0/).
RI Wołk, Krzysztof/E-9957-2015
OI Wołk, Krzysztof/0000-0001-5030-334X
SN 2212-0173
PY 2014
VL 18
BP 126
EP 132
DI 10.1016/j.protcy.2014.11.024
UT WOS:000359950600022
ER

PT C
AU Xiao, T
   Zhu, JB
   Zhang, CL
   Liu, TR
AF Xiao, Tong
   Zhu, Jingbo
   Zhang, Chunliang
   Liu, Tongran
GP AAAI
TI Syntactic Skeleton-Based Translation
SO THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 30th Association-for-the-Advancement-of-Artificial-Intelligence (AAAI)
   Conference on Artificial Intelligence
CY FEB 12-17, 2016
CL Phoenix, AZ
SP Assoc Advancement Artificial Intelligence
AB In this paper we propose an approach to modeling syntactically-motivated skeletal structure of source sentence for machine translation. This model allows for application of high-level syntactic transfer rules and low-level non-syntactic rules. It thus involves fully syntactic, non-syntactic, and partially syntactic derivations via a single grammar and decoding paradigm. On large-scale Chinese-English and English-Chinese translation tasks, we obtain an average improvement of +0.9 BLEU across the newswire and web genres.
SN 2159-5399
EI 2374-3468
PY 2016
BP 2856
EP 2862
UT WOS:000485474202125
ER

PT C
AU Xu, YYF
   Liu, YJ
   Meng, FD
   Zhang, JJ
   Xu, JA
   Zhou, J
AF Xu, Yangyifan
   Liu, Yijin
   Meng, Fandong
   Zhang, Jiajun
   Xu, Jinan
   Zhou, Jie
GP Assoc Computat Linguist
TI Bilingual Mutual Information Based Adaptive Training for Neural Machine
   Translation
SO ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON
   NATURAL LANGUAGE PROCESSING, VOL 2
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB Recently, token-level adaptive training has achieved promising improvement in machine translation, where the cross-entropy loss function is adjusted by assigning different training weights to different tokens, in order to alleviate the token imbalance problem. However, previous approaches only use static word frequency information in the target language without considering the source language, which is insufficient for bilingual tasks like machine translation. In this paper, we propose a novel bilingual mutual information (BMI) based adaptive objective, which measures the learning difficulty for each target token from the perspective of bilingualism, and assigns an adaptive weight accordingly to improve token-level adaptive training. This method assigns larger training weights to tokens with higher BMI, so that easy tokens are updated with coarse granularity while difficult tokens are updated with fine granularity. Experimental results on WMT14 English-to-German and WMT19 Chinese-to-English demonstrate the superiority of our approach compared with the Transformer baseline and previous token-level adaptive training approaches. Further analyses confirm that our method can improve the lexical diversity.
BN 978-1-954085-53-4
PY 2021
BP 511
EP 516
UT WOS:000694699200065
ER

PT C
AU Schlippe, T
   Zhu, CF
   Gebhardt, J
   Schultz, T
AF Schlippe, Tim
   Zhu, Chenfei
   Gebhardt, Jan
   Schultz, Tanja
GP INST SPEECH COMMUN ASSOC
TI Text Normalization based on Statistical Machine Translation and Internet
   User Support
SO 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4
CT 11th Annual Conference of the
   International-Speech-Communication-Association 2010
CY SEP 26-30, 2010
CL Makuhari, JAPAN
SP Japan World Exposit, Commemorat Org, Japan Soc Promot Sci, Telecommunicat Advancement Fdn, KDDI Fdn, Murata Sci Fdn, Adv Telecommunicat Technol Res Fdn, Support Ctr, Chiba Convent Bur & Int Ctr, Renesas Elect Corp, Google, Microsoft Corp, Nuance Commun Inc, Appen Pty Ltd, IBM Res, Sony Corp, Hitachi Ltd, Yahoo Japan Corp, Asahi Kasei Corp, KDDI R & D Lab Inc, Yamaha Corp, Toshiba Corp, Fujitsu Ltd, Mitsubishi Elect Corp, RION Co Ltd, NEC Corp
AB In this paper, we describe and compare systems for text normalization based on statistical machine translation (SMT) methods which are constructed with the support of internet users. Internet users normalize text displayed in a web interface, thereby providing a parallel corpus of normalized and non-normalized text. With this corpus, SMT models are generated to translate non-normalized into normalized text. To build traditional language-specific text normalization systems, knowledge of linguistics as well as established computer skills to implement text normalization rules are required. Our systems are built without profound computer knowledge due to the simple self-explanatory user interface and the automatic generation of the SMT models. Additionally, no inhouse knowledge of the language to normalize is required due to the multilingual expertise of the internet community. All techniques are applied on French texts, crawled with our Rapid Language Adaptation Toolkit [1] and compared through Levenshtein edit distance [2], BLEU score [3], and perplexity.
OI Schultz, Tanja/0000-0002-9809-7028
BN 978-1-61782-123-3
PY 2010
BP 1816
EP 1819
UT WOS:000313086500066
ER

PT J
AU MAYER, R
AF MAYER, R
TI COMPUTER-BASED TRANSLATION - TASK, MARKET, AND TRENDS
SO NACHRICHTEN FUR DOKUMENTATION
AB Translators are confronted with a rapidly growing number of documents to be translated. The necessity of translating rapidly, correctly and at a competitive price makes it nearly impossible to manage without computer-based tools. This paper shows the working methods of technical translators and describes machine translation tools (MT) as well as computer aided translation (CAT). Electronic dictionaries play an important role in CAT. Several termbanks and electronic dictionaries are described and compared.
SN 0027-7436
PD MAY-JUN
PY 1993
VL 44
IS 3
BP 141
EP 148
UT WOS:A1993LJ75400001
ER

PT J
AU Sakti, S
   Paul, M
   Finch, A
   Sakai, S
   Vu, TT
   Kimura, N
   Hori, C
   Sumita, E
   Nakamura, S
   Park, J
   Wutiwiwatchai, C
   Xu, B
   Riza, H
   Arora, K
   Luong, CM
   Li, HZ
AF Sakti, Sakriani
   Paul, Michael
   Finch, Andrew
   Sakai, Shinsuke
   Thang Tat Vu
   Kimura, Noriyuki
   Hori, Chiori
   Sumita, Eiichiro
   Nakamura, Satoshi
   Park, Jun
   Wutiwiwatchai, Chai
   Xu, Bo
   Riza, Hammam
   Arora, Karunesh
   Chi Mai Luong
   Li, Haizhou
TI A-STAR: Toward translating Asian spoken languages
SO COMPUTER SPEECH AND LANGUAGE
AB This paper outlines the first Asian network-based speech-to-speech translation system developed by the Asian Speech Translation Advanced Research (A-STAR) consortium. Eight research groups comprising the A-STAR members participated in the experiments, covering nine languages, i.e., eight Asian languages (Hindi. Indonesian, Japanese, Korean, Malay, Thai, Vietnamese, and Chinese) and English. Each A-STAR member contributed one or more of the following spoken language technologies: automatic speech recognition, machine translation, and text-to-speech through Web servers. The system was designed to translate common spoken utterances of travel conversations from a given source language into multiple target languages in order to facilitate multiparty travel conversations between people speaking different Asian languages. It covers travel expressions including proper nouns that are names of famous places or attractions in Asian countries. In this paper. we describe the issues of developing spoken language technologies for Asian languages. and discuss the difficulties involved in connecting different heterogeneous spoken language translation systems through Web servers. This paper also presents speech-translation results including subjective evaluation, from the first A-STAR field testing which was carried out in July 2009. (C) 2011 Elsevier Ltd. All rights reserved.
RI arora, karunesh/AAY-7096-2020; Li, Haizhou/Q-6438-2019
OI Li, Haizhou/0000-0001-9158-9401
SN 0885-2308
EI 1095-8363
PD FEB
PY 2013
VL 27
IS 2
SI SI
BP 509
EP 527
DI 10.1016/j.csl.2011.07.001
UT WOS:000312471500008
ER

PT C
AU Grega, M
   Smaili, K
   Leszczuk, M
   Gonzalez-Gallardo, CE
   Torres-Moreno, JM
   Pontes, EL
   Fohr, D
   Mella, O
   Menacer, M
   Jouvet, D
AF Grega, Michal
   Smaili, Kamel
   Leszczuk, Mikolaj
   Gonzalez-Gallardo, Carlos-Emiliano
   Torres-Moreno, Juan-Manuel
   Pontes, Elvys Linhares
   Fohr, Dominique
   Mella, Odile
   Menacer, Mohamed
   Jouvet, Denis
BE Choros, K
   Kopel, M
   Kukla, E
   Sieminski, A
TI An Integrated AMIS Prototype for Automated Summarization and Translation
   of Newscasts and Reports
SO MULTIMEDIA AND NETWORK INFORMATION SYSTEMS
SE Advances in Intelligent Systems and Computing
CT 11th International Conference on Multimedia and Network Information
   Systems (MISSI)
CY SEP 12-14, 2018
CL Wroclaw Univ, Wroclaw, POLAND
SP Wroclaw Univ Sci & Technol, Polish Acad Sci, Comm Informat, Wroclaw Sci Soc, Forum IT Co, Polish Informat Proc Soc
HO Wroclaw Univ
AB In this paper we present the results of the integration works on the system designed for automated summarization and translation of newscast and reports. We show the proposed system architectures and list the available software modules. Thanks to well defined interfaces the software modules may be used as building blocks allowing easy experimentation with different summarization scenarios.
RI Leszczuk, Mikolaj/C-4857-2011
OI Leszczuk, Mikolaj/0000-0001-9123-1039
SN 2194-5357
EI 2194-5365
BN 978-3-319-98678-4; 978-3-319-98677-7
PY 2019
VL 833
BP 415
EP 423
DI 10.1007/978-3-319-98678-4_42
UT WOS:000540907500042
ER

PT C
AU Zhang, B
   Ghorbani, B
   Bapna, A
   Cheng, Y
   Garcia, X
   Shen, J
   Firat, O
AF Zhang, Biao
   Ghorbani, Behrooz
   Bapna, Ankur
   Cheng, Yong
   Garcia, Xavier
   Shen, Jonathan
   Firat, Orhan
BE Chaudhuri, K
   Jegelka, S
   Song, L
   Szepesvari, C
   Niu, G
   Sabato, S
TI Examining Scaling and Transfer of Language Model Architectures for
   Machine Translation
SO INTERNATIONAL CONFERENCE ON MACHINE LEARNING, VOL 162
SE Proceedings of Machine Learning Research
CT 38th International Conference on Machine Learning (ICML)
CY JUL 17-23, 2022
CL Baltimore, MD
AB Natural language understanding and generation models follow one of the two dominant architectural paradigms: language models (LMs) that process concatenated sequences in a single stack of layers, and encoder-decoder models (EncDec) that utilize separate layer stacks for input and output processing. In machine translation, EncDec has long been the favoured approach, but with few studies investigating the performance of LMs. In this work, we thoroughly examine the role of several architectural design choices on the performance of LMs on bilingual, (massively) multilingual and zero-shot translation tasks, under systematic variations of data conditions and model sizes. Our results show that: (i) Different LMs have different scaling properties, where architectural differences often have a significant impact on model performance at small scales, but the performance gap narrows as the number of parameters increases, (ii) Several design choices, including causal masking and language-modeling objectives for the source sequence, have detrimental effects on translation quality, and (iii) When paired with full-visible masking for source sequences, LMs could perform on par with EncDec on supervised bilingual and multilingual translation tasks, and improve greatly on zero-shot directions by facilitating the reduction of off-target translations.
SN 2640-3498
PY 2022
UT WOS:000900130207016
ER

PT J
AU Salami, S
   Shamsfard, M
AF Salami, Shahram
   Shamsfard, Mehrnoush
TI Integrating Shallow Syntactic Labels in the Phrase-Boundary Translation
   Model
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB Using a novel rule labeling method, this article proposes a hierarchical model for statistical machine translation. The proposed model labels translation rules by matching the boundaries of target side phrases with the shallow syntactic labels including POS tags and chunk labels on the target side of the training corpus. The boundary labels are concatenated if there is no label for the whole target span. Labeling with the classes of boundary words on the target side phrases has been previously proposed as a phrase-boundary model which can be considered as the base form of our model. In the extended model, the labeler uses a POS tag if there is no chunk label in one boundary. Using chunks as phrase labels, the proposed model generalizes the rules to decrease the model sparseness. The sparseness is a more important issue in the language pairs with a lot of differences in the word order because they have less number of aligned phrase pairs for extraction of rules. The extended phrase-boundary model is also applicable for low-resource languages having no syntactic parser. Some experiments are performed with the proposed model, the base phrase-boundary model, and variants of Syntax Augmented Machine Translation (SAMT) in translation from Persian and German to English as source and target languages with different word orders. According to the results, the proposed model improves the translation performance in the quality and decoding time aspects. Using BLEU as our metric, the proposed model has achieved a statistically significant improvement of about 0.5 point over the base phrase-boundary model.
RI Shamsfard, Mehrnoush/Q-7671-2019; Shamsfard, Mehrnoush/I-1707-2019
OI Shamsfard, Mehrnoush/0000-0002-7027-7529
SN 2375-4699
EI 2375-4702
PD MAY
PY 2018
VL 17
IS 3
AR 17
DI 10.1145/3178460
UT WOS:000433090800004
ER

PT C
AU Zhang, SQ
   Liu, Y
   Xiong, DY
   Zhang, P
   Chen, BX
AF Zhang, Shiqi
   Liu, Yan
   Xiong, Deyi
   Zhang, Pei
   Chen, Boxing
GP Int Speech Commun Assoc
TI Domain-Aware Self-Attention for Multi-Domain Neural Machine Translation
SO INTERSPEECH 2021
SE Interspeech
CT Interspeech Conference
CY AUG 30-SEP 03, 2021
CL Brno, CZECH REPUBLIC
AB In this paper, we investigate multi-domain neural machine translation (NMT) that translates sentences of different domains in a single model. To this end, we propose a domain-aware self-attention mechanism that jointly learns domain representations with the single NMT model. The learned domain representations are integrated into both the encoder and decoder. We further propose two different domain representation learning approaches: 1) word-level unsupervised learning via a domain attention network and 2) guided learning with an auxiliary loss. The two learning approaches allow our multi-domain NMT to work in different settings as to whether the domain information is available or not. Experiments on both Chinese-English and English-French demonstrate that our multi-domain model outperforms a strong baseline built on the Transformer and other previous multi-domain NMT approaches. Further analyses show that our model is able to learn domain clusters even without prior knowledge about the domain structure.
SN 2308-457X
PY 2021
BP 2047
EP 2051
DI 10.21437/Interspeech.2021-1477
UT WOS:000841879502029
ER

PT C
AU Morishita, M
   Suzuki, J
   Nagata, M
AF Morishita, Makoto
   Suzuki, Jun
   Nagata, Masaaki
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mariani, J
   Mazo, H
   Moreno, A
   Odijk, J
   Piperidis, S
TI JParaCrawl: A Large ScaleWeb-Based English-Japanese Parallel Corpus
SO PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES
   AND EVALUATION (LREC 2020)
CT 12th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 11-16, 2020
CL Marseille, FRANCE
AB Recent machine translation algorithms mainly rely on parallel corpora. However, since the availability of parallel corpora remains limited, only some resource-rich language pairs can benefit from them. We constructed a parallel corpus for English-Japanese, for which the amount of publicly available parallel corpora is still limited. We constructed the parallel corpus by broadly crawling the web and automatically aligning parallel sentences. Our collected corpus, called JParaCrawl, amassed over 8.7 million sentence pairs. We show how it includes a broader range of domains and how a neural machine translation model trained with it works as a good pre-trained model for fine-tuning specific domains. The pre-training and fine-tuning approaches achieved or surpassed performance comparable to model training from the initial state and reduced the training time. Additionally, we trained the model with an in-domain dataset and JParaCrawl to show how we achieved the best performance with them. JParaCrawl and the pre-trained models are freely available online for research purposes.
OI Suzuki, Jun/0000-0003-2108-1340
BN 979-10-95546-34-4
PY 2020
BP 3603
EP 3609
UT WOS:000724697204075
ER

PT J
AU Wang, B
   Zhou, M
   Liu, SJ
   Li, M
   Zhang, DD
AF Wang, Bo
   Zhou, Ming
   Liu, Shujie
   Li, Mu
   Zhang, Dongdong
TI Woodpecker: An Automatic Methodology for Machine Translation Diagnosis
   with Rich Linguistic Knowledge
SO JOURNAL OF INFORMATION SCIENCE AND ENGINEERING
AB Different from the "black-box" evaluation, the diagnostic evaluation aims to provide a better explanatory power into various aspects of the performance of artificial intelligence systems. However, for machine translation (MT) systems, due to its complexity and knowledge dependency, such diagnostic evaluation often demands a large amount of manual work. To tackle this problem, we propose an automatic diagnostic evaluation methodology, called Woodpecker, which enables multi-factored evaluation of MT systems based on linguistic categories and automatically constructed linguistic checkpoints. The taxonomy of the categories is defined with rich linguistic knowledge, including phenomena on different linguistic levels. The instances of the categories are composed into test cases called linguistic checkpoints. We present a method that automatically extracts checkpoints from parallel sentences, through which, Woodpecker can automatically monitor a MT system in translating various linguistic phenomena, thereby facilitating diagnostic evaluation. The effectiveness of Woodpecker is verified through in-house experiments and open MT evaluation tracks on various types of MT systems.
SN 1016-2364
PD SEP
PY 2014
VL 30
IS 5
BP 1407
EP 1424
UT WOS:000342328800007
ER

PT C
AU Dragoni, M
   Ghidini, C
   Bosca, A
AF Dragoni, Mauro
   Ghidini, Chiara
   Bosca, Alessio
BE Cimiano, P
   Fernandez, M
   Lopez, V
   Schlobach, S
   Volker, J
TI Multilingual MoKi: How to Manage Multilingual Ontologies in a Wiki
SO SEMANTIC WEB: ESWC 2013 SATELLITE EVENTS
SE Lecture Notes in Computer Science
CT ESWC Conference
CY MAY 26-30, 2013
CL Montpellier, FRANCE
SP DATALIFT, FREIGHT, Educat Curriculum Usage Linked Data, iSOCO, Linked Data Benchmark Council, LinkedUp, Logilab, Monnet, MSEE, Ontologos Corp, Ontotext, PeerAssist, PlanetData, Preserving Linked Data, Render, SIFR Project, Robust, PortDial, Videolectures net, Support, VPH Share, Yahoo Labs, Cnrs, Lab Informatique Robotique Microelectronique Montpellier, Polytech Montpellier, Univ Montpellier 2, Sci Tech
AB In this paper we describe an extension of the MoKi tool able to support the management of multilingual ontologies. The multilingual features of MoKi are based on an integration with Dictionary Based Translation ad Machine Translation technologies. Also the collaborative features of MoKi are used to support the interaction between domain experts in order to discuss and agree on the translations of the terms to be used in each language.
RI Ghidini, Chiara/M-3931-2017
OI Ghidini, Chiara/0000-0003-1563-4965; Dragoni, Mauro/0000-0003-0380-6571
SN 0302-9743
EI 1611-3349
BN 978-3-642-41242-4; 978-3-642-41241-7
PY 2013
VL 7955
BP 162
EP 166
UT WOS:000342797300017
ER

PT J
AU Nakamura, M
   Kong, WQ
   Gata, K
   Futatsugi, K
AF Nakamura, Masaki
   Kong, Weiqiang
   Gata, Kazuhiro
   Futatsugi, Kokichi
TI A specification translation from behavioral specifications to rewrite
   specifications
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
AB There are two ways to describe a state machine as an algebraic specification: a behavioral specification and a rewrite specification. In this study, we propose a translation system from behavioral specifications to rewrite specifications to obtain a verification system which has the strong points of verification techniques for both specifications. Since our translation system is complete with respect to invariant properties, it helps us to obtain a counter-example for an invariant property through automatic exhaustive searching for a rewrite specification.
RI Ogata, Kazuhiro/AAV-1342-2020
OI Ogata, Kazuhiro/0000-0002-4441-3259
SN 1745-1361
PD MAY
PY 2008
VL E91D
IS 5
BP 1492
EP 1503
DI 10.1093/ietisy/e91-d.5.1492
UT WOS:000256860900032
ER

PT J
AU Vieira, LN
   O'Hagan, M
   O'Sullivan, C
AF Vieira, Lucas Nunes
   O'Hagan, Minako
   O'Sullivan, Carol
TI Understanding the societal impacts of machine translation: a critical
   review of the literature on medical and legal use cases
SO INFORMATION COMMUNICATION & SOCIETY
AB The ready availability of machine translation (MT) systems such as Google Translate has profoundly changed how society engages with multilingual communication practices. In addition to private use situations, this technology is now used to overcome language barriers in high-risk settings such as hospitals and courts. MT errors pose serious risks in environments like these, but there is little understanding of the nature of these risks and of the wider implications of using this technology. This article is the first structured study of the consequences of uninformed MT use in healthcare and law. Based on a critical literature review, the article presents a qualitative meta-analysis of official documents and published research on the use of MT in these two fields. Its findings prompt calls for action in three areas. First, the review shows that research on MT use in healthcare and law can often disregard the complexities of language and language translation. The article calls for cross-disciplinary research to address this gap by ensuring that a growing body of relevant knowledge in translation studies informs research conducted within the medical and legal sectors. Second, the review highlights a broad societal need for higher levels of awareness of the specific strengths and, crucially, of the limitations of MT. Finally, the article concludes that MT technology can in its current state exacerbate social inequalities and put certain communities of users at greater risk. We highlight this as a persistent issue that merits further attention from researchers and policymakers.
RI O'Sullivan, Carol/GQH-4677-2022
OI O'Hagan, Minako/0000-0003-0870-0725
SN 1369-118X
EI 1468-4462
PD AUG 18
PY 2021
VL 24
IS 11
BP 1515
EP 1532
DI 10.1080/1369118X.2020.1776370
EA JUN 2020
UT WOS:000544797800001
ER

PT J
AU Akiba, Y
   Imamura, K
   Sumita, E
   Nakaiwa, H
   Yamamoto, S
   Okuno, HG
AF Akiba, Y
   Imamura, K
   Sumita, E
   Nakaiwa, H
   Yamamoto, S
   Okuno, HG
TI Using multiple edit distances to automatically grade outputs from
   machine translation systems
SO IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB This paper addresses the challenging problem of automatically evaluating output from machine translation (MT) systems that are subsystems of speech-to-speech MT (SSMT) Systems. Conventional automatic MT evaluation methods include BLEU, which NIT researchers have frequently used. However, BLEU has two drawbacks in SSMT evaluation. First, BLEU assesses errors lightly at the beginning of translations and heavily in the middle, even though its assessments should be independent of position. Second, BLEU lacks tolerance in accepting colloquial sentences with small errors, although such errors do not prevent us from continuing an SSMT-mediated conversation. In this paper, the authors report a new evaluation method called "gRader based on Edit Distances (RED)" that automatically grades each MT output by using a decision tree (DT). The DT is learned from training data that are encoded by using multiple edit distances, that is, normal edit distance (ED) defined by insertion, deletion, and replacement, as well as its extensions. The use of multiple edit distances allows more tolerance than either ED or BLEU. Each evaluated NIT output is assigned a grade by using the DT. RED and BLEU were compared for the task of evaluating MT systems of varying quality on ATR's Basic Travel Expression Corpus (BTEC). Experimental results show that RED significantly outperforms BLEU.
RI Okuno, Hiroshi G./S-3130-2018
OI Okuno, Hiroshi G./0000-0002-8704-4318
SN 1558-7916
EI 1558-7924
PD MAR
PY 2006
VL 14
IS 2
BP 393
EP 402
DI 10.1109/TSA.2005.860770
UT WOS:000235615000003
ER

PT J
AU Candel-Mora, MA
AF Angel Candel-Mora, Miguel
TI Big data to assess genre-specific features of the machine translation
   output of online travel reviews in Spanish
SO QUADERNS DE FILOLOGIA-ESTUDIS LINGUISTICS
AB Big data analysis such as user-generated content and specifically online consumer reviews has attracted considerable attention in recent years due to its numerous research opportunities and commercial applications in almost all fields of knowledge. The origin of this digital genre in the oral tradition highlights the spontaneous features of the spoken language that are reflected in the written text which has its own characteristics depending on the user's culture and language. By comparing a corpus of 2,000 reviews, this paper proposes the identification and analysis of the unique characteristics of this new digital genre to determine the behavior of machine translation of users' reviews into Spanish. Thus, the aim of this work is to study the tourism reviews translated into Spanish and identify how MT handles the main characteristics that confer naturalness and credibility to this genre.
SN 1135-416X
EI 2444-1449
PY 2023
VL 27
BP 49
EP 69
DI 10.7203/QF.27.24667
UT WOS:000899234200003
ER

PT C
AU Honnet, PE
   Popescu-Belis, A
   Musat, C
   Baeriswyl, M
AF Honnet, Pierre-Edouard
   Popescu-Belis, Andrei
   Musat, Claudiu
   Baeriswyl, Michael
BA Declerck, T
BF Declerck, T
BE Calzolari, N
   Choukri, K
   Cieri, C
   Hasida, K
   Isahara, H
   Maegaard, B
   Mariani, J
   Moreno, A
   Odijk, J
   Piperidis, S
   Tokunaga, T
   Goggi, S
   Mazo, H
TI Machine Translation of Low-Resource Spoken Dialects: Strategies for
   Normalizing Swiss German
SO PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE
   RESOURCES AND EVALUATION (LREC 2018)
CT 11th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 07-12, 2018
CL Miyazaki, JAPAN
AB The goal of this work is to design a machine translation (MT) system for a low-resource family of dialects, collectively known as Swiss German, which are widely spoken in Switzerland but seldom written. We collected a significant number of parallel written resources to start with, up to a total of about 60k words. Moreover, we identified several other promising data sources for Swiss German. Then, we designed and compared three strategies for normalizing Swiss German input in order to address the regional diversity. We found that character-based neural MT was the best solution for text normalization. In combination with phrase-based statistical MT, our solution reached 36% BLEU score when translating from the Bernese dialect. This value, however, decreases as the testing data becomes more remote from the training one, geographically and topically. These resources and normalization techniques are a first step towards full MT of Swiss German dialects.
BN 979-10-95546-00-9
PY 2018
BP 3781
EP 3788
UT WOS:000725545003136
ER

PT J
AU Dale, R
AF Dale, Robert
TI How to make money in the translation business
SO NATURAL LANGUAGE ENGINEERING
AB Machine Translation research suffered a major blow in the 1960s, but it came back with a vengeance. From a commercial point of view, it's now a mature technology that many Internet users take for granted. We look at where we are now, and consider the scope for new entrants into the market.
RI Dale, Robert/A-1803-2008
SN 1351-3249
EI 1469-8110
PD MAR
PY 2016
VL 22
IS 2
BP 321
EP 325
DI 10.1017/S1351324916000012
UT WOS:000370862900006
ER

PT C
AU Ayan, NF
   Mandal, A
   Frandsen, M
   Zheng, J
   Blasco, P
   Kathol, A
   Bechet, F
   Favre, B
   Marin, A
   Kwiatkowski, T
   Ostendorf, M
   Zettlemoyer, L
   Salletmayr, P
   Hirschberg, J
   Stoyanchev, S
AF Ayan, Necip Fazil
   Mandal, Arindam
   Frandsen, Michael
   Zheng, Jing
   Blasco, Peter
   Kathol, Andreas
   Bechet, Frederic
   Favre, Benoit
   Marin, Alex
   Kwiatkowski, Tom
   Ostendorf, Mari
   Zettlemoyer, Luke
   Salletmayr, Philipp
   Hirschberg, Julia
   Stoyanchev, Svetlana
GP IEEE
TI "CAN YOU GIVE ME ANOTHER WORD FOR HYPERBARIC?": IMPROVING SPEECH
   TRANSLATION USING TARGETED CLARIFICATION QUESTIONS
SO 2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
CT IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP)
CY MAY 26-31, 2013
CL Vancouver, CANADA
SP Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc
AB We present a novel approach for improving communication success between users of speech-to-speech translation systems by automatically detecting errors in the output of automatic speech recognition (ASR) and statistical machine translation (SMT) systems. Our approach initiates system-driven targeted clarification about errorful regions in user input and repairs them given user responses. Our system has been evaluated by unbiased subjects in live mode, and results show improved success of communication between users of the system.
OI Favre, Benoit/0000-0002-9777-4613
SN 1520-6149
BN 978-1-4799-0356-6
PY 2013
BP 8391
EP 8395
UT WOS:000329611508112
ER

PT J
AU WATANABE, H
   MARUYAMA, H
AF WATANABE, H
   MARUYAMA, H
TI A TRANSFER SYSTEM USING EXAMPLE-BASED APPROACH
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
AB This paper proposes a new type of transfer system, called Similarity-driven Transfer System (or Sim Tran), which uses an example-based approach to the transfer phase of MT. In this paper, we describe a method for calculating similarity, a method for searching the most appropriate set of translation rules, and a method for constructing an output structure from those selected rules. Further, we show that Sim Tran can use not only translation examples but also syntax-based translation rules used in conventional transfer systems at the same time.
SN 0916-8532
PD FEB
PY 1994
VL E77D
IS 2
BP 247
EP 257
UT WOS:A1994MY97400010
ER

PT J
AU Liu, CM
   Yu, JQ
AF Liu, Chuanming
   Yu, Jingqi
TI Uncertainty-aware non-autoregressive neural machine translation
SO COMPUTER SPEECH AND LANGUAGE
AB Most existing non-autoregressive neural machine translation (NAT) models generally employ the posterior probability to indicate the model confidence during training, which seems to lag behind the novel uncertainty estimations (UEs) methods successfully deployed in other natural language processing (NLP) tasks. Previous research has practically ignored the large-scale exploration of UE methods in the NAT problem. In this paper, we propose a strategy based on Active Learning employed to investigate whether these sophisticated uncertainty -aware methods are more effective in the NAT problem. Besides, we provide an in-depth analysis of the impact of different widely employed UE methods and propose several tailored ones. In the end, we incorporate these exceptional ones into the practical one-pass GLAT model to obtain enhanced performance. Experimental results demonstrate that sophisticated uncertainty-aware UE methods with the two-step training paradigm are potentially superior to represent the model confidence in facilitating token-level decision-making compared to the posterior probability in NAT to a certain extent.
OI Liu, Chuanming/0000-0002-2784-7768
SN 0885-2308
EI 1095-8363
PD MAR
PY 2023
VL 78
AR 101444
DI 10.1016/j.csl.2022.101444
UT WOS:000864656900001
ER

PT J
AU Li, PR
   Chen, C
   Zheng, WJ
   Deng, YT
   Ye, FH
   Zheng, ZB
AF Li, Pairui
   Chen, Chuan
   Zheng, Wujie
   Deng, Yuetang
   Ye, Fanghua
   Zheng, Zibin
TI STD: An Automatic Evaluation Metric for Machine Translation Based on
   Word Embeddings
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB Lexical-based metrics such as BLEU, NIST, and WER have been widely used in machine translation (MT) evaluation. However, these metrics badly represent semantic relationships and impose strict identity matching, leading to moderate correlation with human judgments. In this paper, we propose a novel MT automatic evaluation metric Semantic Travel Distance (STD) based on word embeddings. STD incorporates both semantic and lexical features (word embeddings and n-gram and word order) into one metric. It measures the semantic distance between the hypothesis and reference by calculating the minimum cumulative cost that the embedded n-grams of the hypothesis need to "travel" to reach the embedded n-grams of the reference. Experiment results show that STD has a better and more robust performance than a range of state-of-the-art metrics for both the segment-level and system-level evaluation.
RI Zheng, Zibin/E-3024-2014; Zheng, Zibin/HCH-2408-2022
OI Zheng, Zibin/0000-0002-7878-4330; Zheng, Zibin/0000-0002-7878-4330; Li,
   Pairui/0000-0003-3001-8933
SN 2329-9290
EI 2329-9304
PD OCT
PY 2019
VL 27
IS 10
BP 1497
EP 1506
DI 10.1109/TASLP.2019.2922845
UT WOS:000473621000001
ER

PT C
AU Sennrich, R
   Zhang, BA
AF Sennrich, Rico
   Zhang, Biao
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Revisiting Low-Resource Neural Machine Translation: A Case Study
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB It has been shown that the performance of neural machine translation (NMT) drops starkly in low-resource conditions, underperforming phrase-based statistical machine translation (PBSMT) and requiring large amounts of auxiliary data to achieve competitive results. In this paper, we re-assess the validity of these results, arguing that they are the result of lack of system adaptation to low-resource settings. We discuss some pitfalls to be aware of when training low-resource NMT systems, and recent techniques that have shown to be especially helpful in low-resource settings, resulting in a set of best practices for low-resource NMT. In our experiments on German-English with different amounts of IWSLT14 training data, we show that, without the use of any auxiliary monolingual or multilingual data, an optimized NMT system can outperform PBSMT with far less data than previously claimed. We also apply these techniques to a low-resource Korean-English dataset, surpassing previously reported results by 4 BLEU.
OI Sennrich, Rico/0000-0002-1438-4741
BN 978-1-950737-48-2
PY 2019
BP 211
EP 221
UT WOS:000493046100021
ER

PT C
AU Bao, JW
   Zheng, DQ
   Xu, B
   Zhao, TJ
AF Bao, Jun-Wei
   Zheng, De-Qvan
   Xu, Bing
   Zhao, Tie-Jun
GP IEEE
TI QUERY REWRITING USING STATISTICAL MACHINE TRANSLATION
SO PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   CYBERNETICS (ICMLC), VOLS 1-4
SE International Conference on Machine Learning and Cybernetics
CT International Conference on Machine Learning and Cybernetics (ICMLC)
CY JUL 14-17, 2013
CL Tianjin, PEOPLES R CHINA
SP IEEE, Hebei Univ, IEEE Syst, Man & Cybernet Soc, S China Univ Technol, Univ Macau, Chongqing Univ, Shenzhen Grad Sch, Harbin Inst Technol, Univ Ulster, City Univ Hong Kong, Univ Cagliari Dept Elect & Elect Engn, Hebei Univ Sci & Technol
AB In the area of Information Retrieval, user queries often mismatch the documents users exactly want. We regard this problem as a Query Rewriting task from user queries to document space. Using query logs containing query-keywords-CTR pairs, we trained a state-of-the-art statistical machine translation model to translate the user query to keywords of a web document. Using this method we successfully built the "lecical gap" between user queries and document keywords, and got the keywords as rewritings of the queries. We separately use BLUE and CTR-Recall as optimization target to complete eight comparable experiments. CTR-Recall is presented by us as an optimization target and evaluation indicator. It shows that if forcing the same word to be aligned in word alignment and using BLEU as optimization target we get both the best CTR-Recall and BLEU. At the same time using CTR-Recall as optimization target we get both the best CTR-Recall and BLEU too.
SN 2160-133X
BN 978-1-4799-0260-6
PY 2013
BP 814
EP 819
UT WOS:000366853800107
ER

PT C
AU Wehrmann, J
   Becker, W
   Cagnini, HEL
   Barros, RC
AF Wehrmann, Jonatas
   Becker, Willian
   Cagnini, Henry E. L.
   Barros, Rodrigo C.
GP IEEE
TI A Character-based Convolutional Neural Network for Language-Agnostic
   Twitter Sentiment Analysis
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
SP Int Neurol Network Soc, IEEE Computat Intelligence Soc, Intel, BMI, Budapest Semester Cognit Sci
AB Most work on tweet sentiment analysis is monolingual and the models that are generated by machine learning strategies do not generalize across multiple languages. Cross-language sentiment analysis is usually performed through machine translation approaches that translate a given source language into the target language of choice. Machine translation is expensive and the results that are provided by theses strategies are limited by the quality of the translation that is performed. In this paper, we propose a language-agnostic translation-free method for Twitter sentiment analysis, which makes use of deep convolutional neural networks with character-level embeddings for pointing to the proper polarity of tweets that may be written in distinct (or multiple) languages. The proposed method is more accurate than several other deep neural architectures while requiring substantially less learnable parameters. The resulting model is capable of learning latent features from all languages that are employed during the training process in a straightforward fashion and it does not require any translation process to be performed whatsoever. We empirically evaluate the efficiency and effectiveness of the proposed approach in tweet corpora based on tweets from four different languages, showing that our approach comfortably outperforms the baselines. Moreover, we visualize the knowledge that is learned by our method to qualitatively validate its effectiveness for tweet sentiment classification.
RI Barros, Rodrigo Coelho/I-4319-2012; Barros, Rodrigo Coelho/M-2588-2019
OI Barros, Rodrigo Coelho/0000-0002-0782-9482; Barros, Rodrigo
   Coelho/0000-0002-0782-9482
SN 2161-4393
BN 978-1-5090-6182-2
PY 2017
BP 2384
EP 2391
UT WOS:000426968702083
ER

PT C
AU Antony, PJ
   Ajith, VP
   Soman, KP
AF Antony, P. J.
   Ajith, V. P.
   Soman, K. P.
BE Das, VV
   Vijayakumar, R
   Debnath, NC
   Stephen, J
   Meghanathan, N
   Sankaranarayanan, S
   Thankachan, PM
   Gaol, FL
   Thankachan, N
TI Statistical Method for English to Kannada Transliteration
SO INFORMATION PROCESSING AND MANAGEMENT
SE Communications in Computer and Information Science
CT International Conference on Recent Trends in Business Administration and
   Information Processing
CY MAR 26-27, 2010
CL Trivandrum, INDIA
SP ACEEE
AB Language transliteration is one of the important area in natural language processing. Machine Transliteration is the conversion of a character or word from one language to another without losing its phonological characteristics. It is an orthographical and phonetic converting process. Therefore, both grapheme and phoneme information should be considered. Accurate transliteration of named entities plays an important role in the performance of machine translation and cross-language information retrieval processes. The transliteration model must be design in such a way that the phonetic structure of words should be preserve as closely as possible. This paper address the problem of transliterating English to Kannada language using a publically available translation tool called Statistical Machine Translation (SMT).This transliteration technique was demonstrated for English to Kannada Transliteration and achieved exact Kannada transliterations for 89.27% of English names. The result of proposed model is compared with the SVM based transliteration system as well as Google Indic transliteration system.
RI J, Antony P/AAQ-8909-2020
OI Kutti Padannayil, Soman/0000-0003-1082-4786; P J,
   Antony/0000-0003-1205-0534
SN 1865-0929
BN 978-3-642-12213-2
PY 2010
VL 70
BP 356
EP 362
UT WOS:000278080700057
ER

PT C
AU Fishel, M
   Bojar, O
   Zeman, D
   Berka, J
AF Fishel, Mark
   Bojar, Ondrej
   Zeman, Daniel
   Berka, Jan
BE Habernal, I
   Matousek, V
TI Automatic Translation Error Analysis
SO TEXT, SPEECH AND DIALOGUE, TSD 2011
SE Lecture Notes in Artificial Intelligence
CT 14th International Conferences on Text, Speech and Dialogue
CY SEP 01-05, 2011
CL Pilsen, CZECH REPUBLIC
SP Univ W Bohemia, Fac Appl Sci, Masaryk Univ, Fac Informat, Int Speech Commun Assoc, Czech Soc Cybernet & Informat (CSKI)
AB We propose a method of automatic identification of various error types in machine translation output. The approach is mostly based on monolingual word alignment of the hypothesis and the reference translation. In addition to common lexical errors misplaced words are also detected. A comparison to manually classified MT errors is presented. Our error classification is inspired by that of Vilar (2006; [17]), although distinguishing some of their categories is beyond the reach of the current version of our system.
RI Zeman, Daniel/B-2844-2009; Fishel, Mark/AAN-5245-2020; Bojar,
   Ondřej/D-4416-2017
OI Zeman, Daniel/0000-0002-5791-6568; Bojar, Ondřej/0000-0002-0606-0050
SN 0302-9743
EI 1611-3349
BN 978-3-642-23537-5; 978-3-642-23538-2
PY 2011
VL 6836
BP 72
EP 79
UT WOS:000312640500010
ER

PT C
AU Yabe, T
   Tsubouchi, K
   Shimizu, T
   Sekimoto, Y
   Ukkusuri, SV
AF Yabe, Takahiro
   Tsubouchi, Kota
   Shimizu, Toru
   Sekimoto, Yoshihide
   Ukkusuri, Satish, V
GP ASSOC COMP MACHINERY
TI Unsupervised Translation via Hierarchical Anchoring: Functional Mapping
   of Places across Cities
SO KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY & DATA MINING
CT 26th ACM SIGKDD International Conference on Knowledge Discovery and Data
   Mining (KDD)
CY AUG 23-27, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGMOD, ACM SIGKDD
AB Unsupervised translation has become a popular task in natural language processing (NLP) due to difficulties in collecting large scale parallel datasets. In the urban computing field, place embeddings generated using human mobility patterns via recurrent neural networks are used to understand the functionality of urban areas. Translating place embeddings across cities allow us to transfer knowledge across cities, which may be used for various downstream tasks such as planning new store locations. Despite such advances, current methods fail to translate place embeddings across domains with different scales (e.g. Tokyo to Niigata), due to the straightforward adoption of neural machine translation (NMT) methods from NLP, where vocabulary sizes are similar across languages. We refer to this issue as the domain imbalance problem in unsupervised translation tasks. We address this problem by proposing an unsupervised translation method that translates embeddings by exploiting common hierarchical structures that exist across imbalanced domains. The effectiveness of our method is tested using place embeddings generated from mobile phone data in 6 Japanese cities of heterogeneous sizes. Validation using landuse data clarify that using hierarchical anchors improves the translation accuracy across imbalanced domains. Our method is agnostic to input data type, thus could be applied to unsupervised translation tasks in various fields in addition to linguistics and urban computing.
BN 978-1-4503-7998-4
PY 2020
BP 2841
EP 2851
DI 10.1145/3394486.3403335
UT WOS:000749552302084
ER

PT C
AU Gildea, D
AF Gildea, D
GP ACL
TI Loosely tree-based alignment for machine translation
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We augment a model of translation based on re-ordering nodes in syntactic trees in order to allow alignments not conforming to the original tree structure, while keeping computational complexity polynomial in the sentence length. This is done by adding a new subtree cloning operation to either tree-to-string or tree-to-tree alignment algorithms.
OI Gildea, Daniel/0000-0002-7858-2624
BN 1-932432-09-4
PY 2003
BP 80
EP 87
UT WOS:000223097500011
ER

PT C
AU Joshi, N
   Katyayan, P
   Pandey, A
AF Joshi, Nisheeth
   Katyayan, Pragya
   Pandey, Anupriya
BE Khanna, A
   Gupta, D
   Kansal, V
   Fortino, G
   Hassanien, AE
TI Improving the Quality of English-Bharati Braille Machine Translation
   Using Syntax Analysis
SO PROCEEDINGS OF THIRD DOCTORAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE,
   DOSCI 2022
SE Lecture Notes in Networks and Systems
CT 3rd Doctoral Symposium on Computational Intelligence (DoSCI)
CY MAR 05, 2022
CL Inst of Eng and Tech, Lucknow, INDIA
HO Inst of Eng and Tech
AB Life is tough for people who are blind or deafblind. Braille is a medium through which they can read the text available in the world. Unfortunately, due to the lack of resources that can transcribe textual material into Braille, they are deprived of a lot of knowledge available in books. This paper is an attempt to address this issue. We have developed a system that can transcribe the text available in English into Hindi Braille. We have developed a hybrid machine assisted translation system, which can translate English text into Bharati(Hindi) Braille. This research would be helpful to people in our country who have a desire to learn and gain knowledge but are unable to do so due to the unavailability of literature in Bharati Braille. The developed system is critically important to the lives of visually impaired people because the ability to read and write in Braille opens the door to literacy, intellectual freedom, equal opportunity, and personal security for them. We have evaluated our MT system against standard MT evaluation metrics which provides promising results. We also did quality analysis of the MT output and found that for almost all the simple sentences, and the translations were good while for complex sentences. The system produced above average translations.
SN 2367-3370
EI 2367-3389
BN 978-981-19-3147-5; 978-981-19-3148-2
PY 2023
VL 479
BP 671
EP 683
DI 10.1007/978-981-19-3148-2_58
UT WOS:000937074400056
ER

PT J
AU Luong, NQ
   Besacier, L
   Lecouteux, B
AF Ngoc-Quang Luong
   Besacier, Laurent
   Lecouteux, Benjamin
TI Towards accurate predictors of word quality for Machine Translation:
   Lessons learned on French-English and English-Spanish systems
SO DATA & KNOWLEDGE ENGINEERING
AB This paper proposes some ideas to build effective estimators, which predict the quality of words in a Machine Translation (MT) output. We propose a number of novel features of various types (system-based, lexical, syntactic and semantic) and then integrate them into the conventional (previously used) feature set, for our baseline classifier training. The classifiers are built over two different bilingual corpora: French-English (fr-en) and English-Spanish (en-es). After the experiments with all features, we deploy a "Feature Selection" strategy to filter the best performing ones. Then, a method that combines multiple "weak" classifiers to constitute a strong "composite" classifier by taking advantage of their complementarity allows us to achieve a significant improvement in terms of F-score, for both fr-en and en-es systems. Finally, we exploit word confidence scores for improving the quality estimation system at sentence level. (C) 2015 Elsevier B.V. All rights reserved.
SN 0169-023X
EI 1872-6933
PD MAR-MAY
PY 2015
VL 96-97
SI SI
BP 32
EP 42
DI 10.1016/j.datak.2015.04.003
UT WOS:000357627200004
ER

PT J
AU Poncelas, A
   Wenniger, GMD
   Way, A
AF Poncelas, Alberto
   Wenniger, Gideon Maillette de Buy
   Way, Andy
TI Improved feature decay algorithms for statistical machine translation
SO NATURAL LANGUAGE ENGINEERING
AB In machine-learning applications, data selection is of crucial importance if good runtime performance is to be achieved. In a scenario where the test set is accessible when the model is being built, training instances can be selected so they are the most relevant for the test set. Feature Decay Algorithms (FDA) are a technique for data selection that has demonstrated excellent performance in a number of tasks. This method maximizes the diversity of the n-grams in the training set by devaluing those ones that have already been included. We focus on this method to undertake deeper research on how to select better training data instances. We give an overview of FDA and propose improvements in terms of speed and quality. Using German-to-English parallel data, first we create a novel approach that decreases the execution time of FDA when multiple computation units are available. In addition, we obtain improvements on translation quality by extending FDA using information from the parallel corpus that is generally ignored.
OI Poncelas, Alberto/0000-0002-5089-1687; Way, Andy/0000-0001-5736-5930
SN 1351-3249
EI 1469-8110
PD JAN
PY 2022
VL 28
IS 1
BP 71
EP 91
AR PII S1351324920000467
DI 10.1017/S1351324920000467
UT WOS:000741015800005
ER

PT C
AU Shtekh, G
   Kazakova, P
   Nikitinsky, N
AF Shtekh, Gennady
   Kazakova, Polina
   Nikitinsky, Nikita
BE Sojka, P
   Horak, A
   Kopecek, I
   Pala, K
TI Adjusting Machine Translation Datasets for Document-Level Cross-Language
   Information Retrieval: Methodology
SO TEXT, SPEECH, AND DIALOGUE (TSD 2018)
SE Lecture Notes in Artificial Intelligence
CT 21st Annual International Conference on Text, Speech, and Dialogue (TSD)
CY SEP 11-14, 2018
CL Brno, CZECH REPUBLIC
SP Masaryk Univ, Fac Informat, Univ W Bohemia Plzen, Lexical Comp Ltd, IBM Ceska Republika spol s r o
AB Evaluating the performance of Cross-Language Information Retrieval models is a rather difficult task since collecting and assessing substantial amount of data for CLIR systems evaluation could be a nontrivial and expensive process. At the same time, substantial number of machine translation datasets are available now. In the present paper we attempt to solve the problem stated above by suggesting a strict workflow for transforming machine translation datasets to a CLIR evaluation dataset (with automatically obtained relevance assessments), as well as a workflow for extracting a representative subsample from the initial large corpus of documents so that it is appropriate for further manual assessment. We also hypothesize and then prove by the number of experiments on the United Nations Parallel Corpus data that the quality of an information retrieval algorithm on the automatically assessed sample could be in fact treated as a reasonable metric.
RI Nikitinsky, Nikita/AAE-4248-2022
SN 0302-9743
EI 1611-3349
BN 978-3-030-00794-2; 978-3-030-00793-5
PY 2018
VL 11107
BP 84
EP 94
DI 10.1007/978-3-030-00794-2_9
UT WOS:000611532300009
ER

PT C
AU Iranzo-Sanchez, J
   Diaz-Munio, GVG
   Civera, J
   Juan, A
AF Iranzo-Sanchez, Javier
   Garces Diaz-Munio, Goncal, V
   Civera, Jorge
   Juan, Alfons
GP Assoc Computat Linguist
TI The MLLP-UPV Supervised Machine Translation Systems for WMT19 News
   Translation Task
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019)
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB This paper describes the participation of the MLLP research group of the Universitat Politecnica de Valencia in the WMT 2019 News Translation Shared Task. In this edition, we have submitted systems for the German <-> English and German <-> French language pairs, participating in both directions of each pair. Our submitted systems, based on the Transformer architecture, make ample use of data filtering, synthetic data and domain adaptation through fine-tuning.
RI Garcés Díaz-Munío, Gonçal V./O-6725-2015
OI Garcés Díaz-Munío, Gonçal V./0000-0002-2594-5858
BN 978-1-950737-27-7
PY 2019
BP 218
EP 224
UT WOS:000538566200020
ER

PT C
AU Pathak, AK
   Acharya, P
   Kaur, D
   Balabantaray, RC
AF Pathak, Aditya Kumar
   Acharya, Priyankit
   Kaur, Dilpreet
   Balabantaray, Rakesh Chandra
GP IEEE
TI Automatic Parallel Corpus Creation for Hindi-English News Translation
   Task
SO 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS
   AND INFORMATICS (ICACCI)
CT 7th International Conference on Computing, Communications and
   Informatics (ICACCI)
CY SEP 19-22, 2018
CL Bangalore, INDIA
SP PES Inst Technol, Bangalore South Campus, IEEE, IEEE Communicat Soc, IEEE Photon Soc, IEEE Robot & Automat Soc
AB Parallel corpus for multilingual NLP tasks, deep learning applications like Statistical Machine Translation Systems is very important. The parallel corpus of Hindi-English language pair available for news translation task till date is of very limited size as per the requirement of the systems are concerned. In this work we have developed an automatic parallel corpus generation system prototype, which creates HindiEnglish parallel corpus for news translation task. Further to verify the quality of generated parallel corpus we have experimented by taking various performance metrics and the results are quiet interesting.
RI Balabantaray, Rakesh Chandra/D-4935-2016
BN 978-1-5386-5314-2
PY 2018
BP 1069
EP 1075
UT WOS:000455682100178
ER

PT C
AU Parcheta, Z
   Sanchis-Trilles, G
   Casacuberta, F
AF Parcheta, Zuzanna
   Sanchis-Trilles, German
   Casacuberta, Francisco
GP Assoc Computat Linguist
TI Filtering of Noisy Parallel Corpora Based on Hypothesis Generation
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 3: SHARED TASK
   PAPERS, DAY 2
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB The filtering task of noisy parallel corpora in WMT2019 aims to challenge participants to create filtering methods to be useful for training machine translation systems. In this work, we introduce a noisy parallel corpora filtering system based on generating hypotheses by means of a translation model. We train translation models in both language pairs: Nepali-English and Sinhala-English using provided parallel corpora. To create the best possible translation model, we first join all provided parallel corpora (Nepali, Sinhala and Hindi to English) and after that, we applied bilingual cross-entropy selection for both language pairs (Nepali-English and Sinhala-English). Once the translation models are trained, we translate the noisy corpora and generate a hypothesis for each sentence pair. We compute the smoothed BLEU score between the target sentence and generated hypothesis. In addition, we apply several rules to discard very noisy or inadequate sentences which can lower the translation score. These heuristics are based on sentence length, source and target similarity and source language detection. We compare our results with the baseline published on the shared task website, which uses the Zipporah model, over which we achieve significant improvements in one of the conditions in the shared task. The designed filtering system is domain independent and all experiments are conducted using neural machine translation.
RI Parcheta, Zuzanna/AAK-6071-2020
OI Parcheta, Zuzanna/0000-0002-3490-6068
BN 978-1-950737-27-7
PY 2019
BP 282
EP 288
UT WOS:000538569000039
ER

PT C
AU Koyama, A
   Kiyuna, T
   Kobayashi, K
   Arai, M
   Komachi, M
AF Koyama, Aomi
   Kiyuna, Tomoshige
   Kobayashi, Kenji
   Arai, Mio
   Komachi, Mamoru
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mariani, J
   Mazo, H
   Moreno, A
   Odijk, J
   Piperidis, S
TI Construction of an Evaluation Corpus for Grammatical Error Correction
   for Learners of Japanese as a Second Language
SO PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES
   AND EVALUATION (LREC 2020)
CT 12th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 11-16, 2020
CL Marseille, FRANCE
AB The NAIST Lang-8 Learner Corpora (Lang-8 corpus) is one of the largest second-language learner corpora. The Lang-8 corpus is suitable as a training dataset for machine translation-based grammatical error correction systems. However, it is not suitable as an evaluation dataset because the corrected sentences sometimes include inappropriate sentences. Therefore, we created and released an evaluation corpus for correcting grammatical errors made by learners of Japanese as a Second Language (JSL). As our corpus has less noise and its annotation scheme reflects the characteristics of the dataset, it is ideal as an evaluation corpus for correcting grammatical errors in sentences written by JSL learners. In addition, we applied neural machine translation (NMT) and statistical machine translation (SMT) techniques to correct the grammar of the JSL learners' sentences and evaluated their results using our corpus. We also compared the performance of the NMT system with that of the SMT system.
OI Komachi, Mamoru/0000-0003-1166-1739
BN 979-10-95546-34-4
PY 2020
BP 204
EP 211
UT WOS:000724697200026
ER

PT C
AU Ehsan, N
   Faili, H
AF Ehsan, Nava
   Faili, Heshaam
BE Paleologu, C
   Mavromoustakis, C
   Minea, M
TI Statistical Machine Translation as a Grammar Checker for Persian
   Language
SO SIXTH INTERNATIONAL MULTI-CONFERENCE ON COMPUTING IN THE GLOBAL
   INFORMATION TECHNOLOGY (ICCGI 2011)
SE International Multi-Conference on Computing in the Global Information
   Technology
CT 6th International Multi-Conference on Computing in the Global
   Information Technology (ICCGI)
CY JUN 19-24, 2011
CL Luxembourg, LUXEMBOURG
SP IARIA
AB Existence of automatic writing assistance tools such as spell and grammar checker/corrector can help in increasing electronic texts with higher quality by removing noises and cleaning the sentences. Different kinds of errors in a text can be categorized into spelling, grammatical and real-word errors. In this article, the concepts of an automatic grammar checker for Persian (Farsi) language, is explained. A statistical grammar checker based on phrasal statistical machine translation (SMT) framework is proposed and a hybrid model is suggested by merging it with an existing rule-based grammar checker. The results indicate that these two approaches are complimentary in detecting and correcting syntactic errors, although statistical approach is able to correct more probable errors. The state-of-the-art results on Persian grammar checking are achieved by using the hybrid model. The obtained recall is about 0.5 for correction and about 0.57 for detection with precision about 0.63.
RI Ehsan, Nava/GXA-1341-2022
SN 2308-4529
BN 978-1-61208-139-7
PY 2011
BP 20
EP 26
UT WOS:000456651700004
ER

PT C
AU Gu, SH
   Zhang, JC
   Meng, FD
   Feng, Y
   Xie, WY
   Zhou, J
   Yu, D
AF Gu, Shuhao
   Zhang, Jinchao
   Meng, Fandong
   Feng, Yang
   Xie, Wanying
   Zhou, Jie
   Yu, Dong
GP Assoc Computat Linguist
TI Token-level Adaptive Training for Neural Machine Translation
SO PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL
   LANGUAGE PROCESSING (EMNLP)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 16-20, 2020
CL ELECTR NETWORK
SP Bloomberg Engn, Google Res, Apple, Amazon Sci, Baidu, Megagon Labs, Facebook, DeepMind, Grammarly, ByteDance, Zeta Alpha, Babelscape, Naver, Adobe, Hitachi, Salesforce, Univ So Calif, Viterbi Sch Engn, Informat Sci Inst
AB There exists a token imbalance phenomenon in natural language as different tokens appear with different frequencies, which leads to different learning difficulties for tokens in Neural Machine Translation (NMT). The vanilla NMT model usually adopts trivial equal-weighted objectives for target tokens with different frequencies and tends to generate more high-frequency tokens and less low-frequency tokens compared with the golden token distribution. However, low-frequency tokens may carry critical semantic information that will affect the translation quality once they are neglected. In this paper, we explored target token-level adaptive objectives based on token frequencies to assign appropriate weights for each target token during training. We aimed that those meaningful but relatively low-frequency words could be assigned with larger weights in objectives to encourage the model to pay more attention to these tokens. Our method yields consistent improvements in translation quality on ZH-EN, ENRO, and EN-DE translation tasks, especially on sentences that contain more low-frequency tokens where we can get 1.68, 1.02, and 0.52 BLEU increases compared with baseline, respectively. Further analyses show that our method can also improve the lexical diversity of translation.
BN 978-1-952148-60-6
PY 2020
BP 1035
EP 1046
UT WOS:000855160701016
ER

PT J
AU Hillerstrom, D
   Lindley, S
   Atkey, R
AF Hillerstrom, Daniel
   Lindley, Sam
   Atkey, Robert
TI Effect handlers via generalised continuations
SO JOURNAL OF FUNCTIONAL PROGRAMMING
AB Plotkin and Pretnar's effect handlers offer a versatile abstraction for modular programming with user-defined effects. This paper focuses on foundations for implementing effect handlers, for the three different kinds of effect handlers that have been proposed in the literature: deep, shallow, and parameterised. Traditional deep handlers are defined by folds over computation trees and are the original construct proposed by Plotkin and Pretnar. Shallow handlers are defined by case splits (rather than folds) over computation trees. Parameterised handlers are deep handlers extended with a state value that is threaded through the folds over computation trees. We formulate the extensions both directly and via encodings in terms of deep handlers and illustrate how the direct implementations avoid the generation of unnecessary closures. We give two distinct foundational implementations of all the kinds of handlers we consider: a continuation-passing style (CPS) transformation and a CEK-style abstract machine. In both cases, the key ingredient is a generalisation of the notion of continuation to accommodate stacks of effect handlers. We obtain our CPS translation through a series of refinements as follows. We begin with a first-order CPS translation into untyped lambda calculus which manages a stack of continuations and handlers as a curried sequence of arguments. We then refine the initial CPS translation by uncurrying it to yield a properly tail-recursive translation and then moving towards more and more intensional representations of continuations in order to support different kinds of effect handlers. Finally, we make the translation higher order in order to contract administrative redexes at translation time. Our abstract machine design then uses the same generalised continuation representation as the CPS translation. We have implemented both the abstract machine and the CPS transformation (plus extensions) as backends for the Links web programming language.
OI Hillerstrom, Daniel/0000-0003-4730-9315
SN 0956-7968
EI 1469-7653
PD MAR 16
PY 2020
VL 30
AR e5
DI 10.1017/S0956796820000040
UT WOS:000524929500001
ER

PT C
AU Caseli, HD
   Nunes, IA
AF Caseli, Helena de Medeiros
   Nunes, Israel Aono
BE Costa, ACD
   Vicari, RM
   Tonidandel, F
TI Factored Translation between Brazilian Portuguese and English
SO ADVANCES IN ARTIFICIAL INTELLIGENCE - SBIA 2010
SE Lecture Notes in Artificial Intelligence
CT Joint Conference of 20th Brazilian Symposium on Artificial Intelligence
   (SBIA) /SBRN/JRI
CY OCT 23-28, 2010
CL Sao Bernardo do Campo, BRAZIL
SP Coordenacao Aperfeicoamento Pessoal Nivel Super (CAPES), Conselho Nacl Desenvolvimento Cientifico & Tecnologica, Fundacao Amparo Pesquisa Estado Sao Paulo (FAPESP), Soc Brasileira Computacao (SBC)
AB Factored translation is an extension of the state-of-theart phrase-based statistical machine translation (PB-SMT). The main difference in factored translation approach is that a word is not only a token (its surface form) but a vector composed of different information such as lemma, part-of-speech or morphologic/syntactic tags. In this paper we present some experiments carried out to train and test factored translation models on Brazilian Portuguese and English texts. Using part-of-speech and morphological information, the factored models showed better results than the baseline (a PB-SMT), but the same gain in performance was not reached when flat syntactic tags were considered.
OI Caseli, Helena/0000-0003-3996-8599
SN 0302-9743
EI 1611-3349
BN 978-3-642-16137-7
PY 2010
VL 6404
BP 163
EP 172
UT WOS:000314803500017
ER

PT C
AU Kano, T
   Sakti, S
   Nakamura, S
AF Kano, Takatomo
   Sakti, Sakriani
   Nakamura, Satoshi
GP Int Speech Commun Assoc
TI Structured-based Curriculum Learning for End-to-end English-Japanese
   Speech Translation
SO 18TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2017), VOLS 1-6: SITUATED INTERACTION
SE Interspeech
CT 18th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2017)
CY AUG 20-24, 2017
CL Stockholm, SWEDEN
SP Int Speech Commun Assoc, Stockholm Univ, KTH Royal Inst Technol, Karolinska Inst, Amazon Alexa, DiDi, Furhat Robot, Microsoft, EZ Alibaba Grp, CIRRUS LOGIC, CVTE, Google, Baidu, IBM Res, YAHOO Japan, Nuance, Voice Provider, ASM Solut Ltd, Mitsubishi Elect Res Lab, Yandex
AB Sequence-to-sequence attentional-based neural network architectures have been shown to provide a powerful model for machine translation and speech recognition. Recently, several works have attempted to extend the models for end-to-end speech translation task. However, the usefulness of these models were only investigated on language pairs with similar syntax and word order (e.g.. English-French or English-Spanish). In this work, we focus on end-to-end speech translation tasks on syntactically distant language pairs (e.g., English-Japanese) that require distant word reordering. To guide the encoder-decoder attentional model to learn this difficult problem, we propose a structured-based curriculum learning strategy. Unlike conventional curriculum learning that gradually emphasizes difficult data examples, we formalize learning strategics from easier network structures to more difficult network structures. Here, we start the training with end-to-end encoder-decoder for speech recognition or text-based machine translation task then gradually move to end-to-end speech translation task. The experiment results show that the proposed approach could provide significant improvements in comparison with the one without curriculum learning.
SN 2308-457X
BN 978-1-5108-4876-4
PY 2017
BP 2630
EP 2634
DI 10.21437/Interspeech.2017-944
UT WOS:000457505000546
ER

PT C
AU Wang, SK
   Zhang, W
   Guo, WY
   Yu, D
   Liu, PY
AF Wang, Shike
   Zhang, Wen
   Guo, Wenyu
   Yu, Dong
   Liu, Pengyuan
GP IEEE
TI Contrastive Learning Based Visual Representation Enhancement for
   Multimodal Machine Translation
SO 2022 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / IEEE World
   Congress on Computational Intelligence (IEEE WCCI) / International Joint
   Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary
   Computation (IEEE CEC)
CY JUL 18-23, 2022
CL Padua, ITALY
SP IEEE, Int Neural Network Soc, IEEE Computat Intelligence Soc, Evolutionary Programming Soc, IET, Univ Padova, Dept Math Tullio Levi Civita, European Space Agcy, expert.ai, Elsevier, Springer Nature, Google, Baker & Hughes, NVIDIA
AB Multimodal machine translation (MMT) is a task that incorporates extra image modality with text to translate. Previous works have worked on the interaction between two modalities and investigated the need of visual modality. However, few works focus on the models with better and more effective visual representation as input. We argue that the performance of MMT systems will get improved when better visual representation inputs into the systems. To investigate the thought, we introduce mT-ICL, a multimodal Transformer model with image contrastive learning. The contrastive objective is optimized to enhance the representation ability of the image encoder so that the encoder can generate better and more adaptive visual representation. Experiments show that our mT-ICL significantly outperforms the strong baseline and achieves the new SOTA on most of test sets of English-to-German and English-to-French. Further analysis reveals that visual modality works more than a regularization method under contrastive learning framework.
SN 2161-4393
BN 978-1-7281-8671-9
PY 2022
DI 10.1109/IJCNN55064.2022.9892312
UT WOS:000867070903072
ER

PT C
AU Gao, F
   Zhu, JH
   Wu, LJ
   Xia, YC
   Qin, T
   Cheng, XQ
   Zhou, WG
   Liu, TY
AF Gao, Fei
   Zhu, Jinhua
   Wu, Lijun
   Xia, Yingce
   Qin, Tao
   Cheng, Xueqi
   Zhou, Wengang
   Liu, Tie-Yan
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Soft Contextual Data Augmentation for Neural Machine Translation
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB While data augmentation is an important trick to boost the accuracy of deep learning methods in computer vision tasks, its study in natural language tasks is still very limited. In this paper, we present a novel data augmentation method for neural machine translation. Different from previous augmentation methods that randomly drop, swap or replace words with other words in a sentence, we softly augment a randomly chosen word in a sentence by its contextual mixture of multiple related words. More accurately, we replace the onehot representation of a word by a distribution (provided by a language model) over the vocabulary, i.e., replacing the embedding of this word by a weighted combination of multiple semantically similar words. Since the weights of those words depend on the contextual information of the word to be replaced, the newly generated sentences capture much richer information than previous augmentation methods. Experimental results on both small scale and large scale machine translation datasets demonstrate the superiority of our method over strong baselines.
BN 978-1-950737-48-2
PY 2019
BP 5539
EP 5544
UT WOS:000493046108005
ER

PT C
AU Ghorbel, H
AF Ghorbel, Hatem
BE Aberer, K
   Flache, A
   Jager, W
   Liu, L
   Tang, J
   Gueret, C
TI Experiments in Cross-Lingual Sentiment Analysis in Discussion Forums
SO SOCIAL INFORMATICS, SOCINFO 2012
SE Lecture Notes in Computer Science
CT 4th International Conference on Social Informatics (SocInfo)
CY DEC 05-07, 2012
CL Lausanne, SWITZERLAND
AB One of the objectives of sentiment analysis is to classify the polarity of conveyed opinions from the perspective of textual evidence. Most of the work in the field has been intensively applied to the English language and only few experiments have explored other languages. In this paper, we present a supervised classification of posts in French online forums where sentiment analysis is based on shallow linguistic features such as POS tagging, chunking and common negation forms. Furthermore, we incorporate word semantic orientation extracted from the English lexical resource SentiWordNet as an additional feature. Since SentiWordNet is an English resource, lexical entries in the studied French corpus should be translated into English. For this purpose, we propose a number of French to English translation experiments such as machine translation and WordNet synset translation using EuroWordNet. Obtained results show that WordNet synset translation have not significantly improved the classification performance with respect to the bag of words baseline due to the shortage in coverage. Automatic translation haven't either significantly improved the results due to its insufficient quality. Propositions of improving the classification performance are given by the end of the article.
OI ghorbel, hatem/0000-0001-5501-9807
SN 0302-9743
EI 1611-3349
BN 978-3-642-35385-7; 978-3-642-35386-4
PY 2012
VL 7710
BP 138
EP 151
UT WOS:000320472700011
ER

PT C
AU Richardson, A
   Wiles, J
AF Richardson, Ashleigh
   Wiles, Janet
BA Mariani, J
BF Mariani, J
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mazo, H
   Odijk, H
   Piperidis, S
TI A Systematic Study Reveals Unexpected Interactions in Pre-Trained Neural
   Machine Translation
SO LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION
CT 13th International Conference on Language Resources and Evaluation
   (LREC)
CY JUN 20-25, 2022
CL Marseille, FRANCE
SP Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur
AB A significant challenge in developing translation systems for the world's similar to 7,000 languages is that very few have sufficient data for state-of-the-art techniques. Transfer learning is a promising direction for low-resource neural machine translation (NMT), but introduces many new variables which are often selected through ablation studies, costly trial-and-error, or niche expertise. When pre-training an NMT system for low-resource translation, the pre-training task is often chosen based on data abundance and similarity to the main task. Factors such as dataset sizes and similarity have typically been analysed independently in previous studies, due to the computational cost associated with systematic studies. However, these factors are not independent. We conducted a three-factor experiment to examine how language similarity, pre-training dataset size and main dataset size interacted in their effect on performance in pre-trained transformer-based low-resource NMT. We replicated the common finding that more data was beneficial in bilingual systems, but also found a statistically significant interaction between the three factors, which reduced the effectiveness of large pre-training datasets for some main task dataset sizes (p-value < 0:0018). The surprising trends identified in these interactions indicate that systematic studies of interactions may be a promising long-term direction for guiding research in low-resource neural methods.
BN 979-10-95546-72-6
PY 2022
BP 1437
EP 1443
UT WOS:000889371701058
ER

PT C
AU Wei, W
   Xu, B
AF Wei, Wei
   Xu, Bo
GP IEEE
TI Hierarchical chunking-phrase based translation
SO PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON NATURAL
   LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING (NLP-KE'07)
CT International Conference on Natural Language Processing and Knowledge
   Engineering
CY AUG 30-SEP 01, 2007
CL Beijing, PEOPLES R CHINA
SP IEEE Signal Proc Soc, Chinese Assoc Artificial Intelligence, Chinese Informat Proc Soc China, IEEE Beijing Sect, Beijing Univ Posts & Telecommun
AB We present a statistical machine translation system which uses hierarchical chunking phrases (HCPB). The system can be seen as combination with fundamental ideas from both syntax-based translation and phrase-based translation, because the model not only complies with formal synchronous context-free grammar but also learned partial parsing knowledge CRF (Conditional Random Fields) method. The decoder for HCPB MT system is based on chart-based CKY algorithm, and integrates N-gram language model effectively. Currently, this paper is focused on the research of Chinese-English spoken language translation. According to our final experiments, our method achieves a higher accuracy in the final results with BLEU and NIST score in IWSLT2005.
BN 978-1-4244-1610-3
PY 2007
BP 268
EP +
DI 10.1109/NLPKE.2007.4368042
UT WOS:000250781000041
ER

PT C
AU Shree, MR
   Shambhavi, BR
AF Shree, M. Rajani
   Shambhavi, B. R.
GP IEEE
TI Performance Comparison of Word Sense Disambiguation Approaches for
   Indian Languages
SO 2015 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE (IACC)
SE IEEE International Advance Computing Conference
CT IEEE International Advance Computing Conference (IACC 2015)
CY JUN 12-13, 2015
CL Bangalore, INDIA
AB Natural Language Processing (NLP) involves many phases of which the significant one is Word-sense disambiguation (WSD). WSD includes the techniques of identifying a suitable meaning of words and sentences in a particular context by applying various computational procedures. WSD is an Artificial Intelligence problem that needs resolution for ambiguity of words. WSD is essential for many NLP applications like Machine Translation, Information Retrieval, Information Extraction and for many others. The WSD techniques are mainly categorized into knowledge-based approaches, Machine Learning based approaches and hybrid approaches. The assessment of WSD systems is discussed in this study and it includes comparisons of different WSD approaches in the context of Indian languages.
RI Ravi, Shambhavi/P-2798-2015; Shree, M Rajani/AAQ-9122-2020
OI Ravi, Shambhavi/0000-0002-3389-4253; Shree, M Rajani/0000-0002-8853-2065
SN 2164-8263
BN 978-1-4799-8047-5
PY 2015
BP 166
EP 169
UT WOS:000380493300032
ER

PT C
AU Chen, XX
   Ge, SL
AF Chen, Xiaoxiao
   Ge, Shili
BE Yang, Y
TI The Construction of English-Chinese Parallel Corpus of Medical Works
   Based on Self-Coded Python Programs
SO INTERNATIONAL CONFERENCE ON ADVANCES IN ENGINEERING 2011
SE Procedia Engineering
CT International Conference on Advances in Engineering (ICAE)
CY DEC 17-18, 2011
CL Nanjing, PEOPLES R CHINA
SP Int Informat Management Assoc, California State Univ, Nanjing Univ Informat Sci & Technol, US Jiangsu Econ Trade & Culture Assoc
AB In order to provide sufficient training data for statistical machine(-aided) translation in medical field, a large scale English-Chinese parallel corpus of medical works is constructed. Eighteen English medical printed books with Chinese translation are selected as raw materials. With the help of an OCR scanner, all texts are recognized, manually proofread and stored in electrical form. Within a rigid scheme of corpus construction and with the help of a self-coded Python program, English and Chinese texts are separated, sentence aligned and XML marked. After careful manual proofreading, an Internet-based corpus retrieval platform is constructed. The present parallel corpus contains 54,522 sentence pairs and more than 2,500,000 English words / Chinese characters, which can be preliminarily applied in the training and testing of statistical machine(-aided) translation researches in medical field. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of ICAE2011
RI Chen, xiaoxiao/GRS-0925-2022
SN 1877-7058
PY 2011
VL 24
BP 598
EP 603
DI 10.1016/j.proeng.2011.11.2702
UT WOS:000300042400112
ER

PT C
AU Skadins, R
   Pinnis, M
   Vasilevskis, A
   Vasiljevs, A
   Sics, V
   Rozis, R
   Lagzdins, A
AF Skadins, Raivis
   Pinnis, Marcis
   Vasilevskis, Arturs
   Vasiljevs, Andrejs
   Sics, Valters
   Rozis, Roberts
   Lagzdins, Andis
BE Utka, A
   Vaicenoniene, J
   Kovalevskaite, J
   Kalinauskaite, D
TI Language Technology Platform for Public Administration
SO HUMAN LANGUAGE TECHNOLOGIES - THE BALTIC PERSPECTIVE (HLT 2020)
SE Frontiers in Artificial Intelligence and Applications
CT 9th International Conference on Human Language Technologies - The Baltic
   Perspective (Baltic HLT)
CY SEP 22-23, 2020
CL Vytautas Magnus Univ, ELECTR NETWORK
SP Ctr Computat Linguist, Vytautas Magnus Univ, CLARIN LT Ctr, Res Council Lithuania
HO Vytautas Magnus Univ
AB The paper describes the Latvian e-government language technology platform HUGO.LV. It provides an instant translation of text snippets, formatting-rich documents and websites, an online computer-assisted translation tool with a built-in translation memory, a website translation widget, speech recognition and speech synthesis services, a terminology management and publishing portal, language data storage, analytics, and data sharing functionality. The paper describes the motivation for the creation of the platform, its main components, architecture, usage statistics, conclusions, and future developments. Evaluation results of language technology tools integrated in the platform are provided.
RI Pinnis, Mārcis/N-8009-2013
OI Pinnis, Mārcis/0000-0001-6832-5600
SN 0922-6389
EI 1879-8314
BN 978-1-64368-117-7; 978-1-64368-116-0
PY 2020
VL 328
BP 182
EP 190
DI 10.3233/FAIA200621
UT WOS:000648590800025
ER

PT C
AU Nobari, AD
   Gharebagh, SS
   Neshati, M
AF Nobari, Arash Dargahi
   Gharebagh, Sajad Sotudeh
   Neshati, Mahmood
GP ACM/SIGIR
TI Skill Translation Models in Expert Finding
SO SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON
   RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL
CT 40th International ACM SIGIR conference on research and development in
   Information Retrieval
CY AUG 07-11, 2017
CL Shinjuku, JAPAN
SP ACM SIGIR
AB Finding talented users on Stackoverflow can be a challenging task due to term mismatch between queries and content published on it. In this paper, we propose two translation models to augment a given query with relevant words. The first model is based on a statistical approach and the second one is a word embedding model. Interestingly, the translations provided by these methods are not the same. Although the first model in most cases selects pieces of program codes as translations, the second model provides more semantically related words. Our experiments on a large dataset indicate the efficiency of proposed models.
BN 978-1-4503-5022-8
PY 2017
BP 1057
EP 1060
DI 10.1145/3077136.3080719
UT WOS:000454711900147
ER

PT C
AU Ri, R
   Nakazawa, T
   Tsuruoka, Y
AF Ri, Ryokan
   Nakazawa, Toshiaki
   Tsuruoka, Yoshimasa
GP Assoc Computat Linguist
TI Zero-pronoun Data Augmentation for Japanese-to-English Translation
SO WAT 2021: THE 8TH WORKSHOP ON ASIAN TRANSLATION
CT 8th Workshop on Asian Translation (WAT)
CY AUG 05-06, 2021
CL ELECTR NETWORK
AB For Japanese-to-English translation, zero pronouns in Japanese pose a challenge, since the model needs to infer and produce the corresponding pronoun in the target side of the English sentence. However, although fully resolving zero pronouns often needs discourse context, in some cases, the local context within a sentence gives clues to the inference of the zero pronoun. In this study, we propose a data augmentation method that provides additional training signals for the translation model to learn correlations between local context and zero pronouns. We show that the proposed method significantly improves the accuracy of zero pronoun translation with machine translation experiments in the conversational domain.
BN 978-1-954085-63-3
PY 2021
BP 117
EP 123
UT WOS:000686140700011
ER

PT C
AU Domhan, T
   Hasler, E
   Tran, K
   Trenous, S
   Byrne, B
   Hieber, F
AF Domhan, Tobias
   Hasler, Eva
   Tran, Ke
   Trenous, Sony
   Byrne, Bill
   Hieber, Felix
GP ASSOC COMPUTAT LINGUIST
TI The Devil is in the Details: On the Pitfalls of Vocabulary Selection in
   Neural Machine Translation
SO NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE
   ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES
CT Conference of the
   North-American-Chapter-of-the-Association-for-Computational-Linguistics
   (NAAACL) - Human Language Technologies
CY JUL 10-15, 2022
CL Seattle, WA
SP Assoc Computat Linguist, N Amer Chapter, Amazon Sci, Bloomberg Engn, Google Res, LivepersoMetan, ByteDance, KENSH, Grammarly, Megagon Labs, Microsoft, Reveal Brainspace, Cohere, GResearch, Relativity, Servicenow, ASAPP, Duolingo, Adobe, Linkedin, Babelscape, Rakuten Inst Technol, UC Santa Cruz, Baskin Engn, Nat Language Proc, NSF, ETS, OpenAI, TIAA, Two Sigma, Mag Data
AB Vocabulary selection, or lexical shortlisting, is a well-known technique to improve latency of Neural Machine Translation models by constraining the set of allowed output words during inference. The chosen set is typically determined by separately trained alignment model parameters, independent of the sourcesentence context at inference time. While vocabulary selection appears competitive with respect to automatic quality metrics in prior work, we show that it can fail to select the right set of output words, particularly for semantically non-compositional linguistic phenomena such as idiomatic expressions, leading to reduced translation quality as perceived by humans. Trading off latency for quality by increasing the size of the allowed set is often not an option in real-world scenarios. We propose a model of vocabulary selection, integrated into the neural translation model, that predicts the set of allowed output words from contextualized encoder representations. This restores translation quality of an unconstrained system, as measured by human evaluations on WMT newstest2020 and idiomatic expressions, at an inference latency competitive with alignment-based selection using aggressive thresholds, thereby removing the dependency on separately trained alignment models.
OI Byrne, William/0000-0003-1896-4492
BN 978-1-955917-71-1
PY 2022
BP 1861
EP 1874
UT WOS:000859869501071
ER

PT C
AU Sebastian, MP
   Sheena, KK
   Kumar, GS
AF Sebastian, Mary Priya
   Kurian, Sheena K.
   Kumar, G. Santhosh
GP ACM
TI English to Malayalam Translation: A Statistical Approach
SO PROCEEDINGS OF THE FIRST AMRITA ACM-W CELEBRATION OF WOMEN IN COMPUTING
   IN INDIA (A2WIC)
CT 1st Amrita ACM-W Celebration of Women in Computing in India (A2CWiC)
CY SEP 16-17, 2010
CL Coimbatore, INDIA
SP Assoc Comp Machinery, Govt India, DIT, ISRO, Infosys, Inst Elect & Telecommunicat Engineers, Comp Soc India, ACM Women Comp
AB This paper underlines a methodology for translating text from English into the Dravidian language, Malayalam using statistical models. By using a monolingual Malayalam corpus and a bilingual English/Malayalam corpus in the training phase, the machine automatically generates Malayalam translations of English sentences. This paper also discusses a technique to improve the alignment model by incorporating the parts of speech information into the bilingual corpus. Removing the insignificant alignments from the sentence pairs by this approach has ensured better training results. Pre-processing techniques like suffix separation from the Malayalam corpus and stop word elimination from the bilingual corpus also proved to be effective in training. Various handcrafted rules designed for the suffix separation process which can be used as a guideline in implementing suffix separation in Malayalam language are also presented in this paper. The structural difference between the English Malayalam pair is resolved in the decoder by applying the order conversion rules. Experiments conducted on a sample corpus have generated reasonably good Malayalam translations and the results are verified with F measure, BLEU and WER evaluation metrics.
RI G, Santhosh Kumar/G-6027-2010; Gopalan, Santhosh Kumar/I-7361-2012;
   Sebastian, Mary Priya/AAE-6721-2022
OI G, Santhosh Kumar/0000-0001-5518-5725; Gopalan, Santhosh
   Kumar/0000-0001-6855-426X; Sebastian, Mary Priya/0000-0001-9772-4256
BN 978-1-4503-0194-7
PY 2010
UT WOS:000397326500063
ER

PT C
AU D'Haro, LF
   San-Segundo, R
   de Cordoba, R
   Bungeroth, J
   Stein, D
   Ney, H
AF Fernando D'Haro, Luis
   San-Segundo, Ruben
   de Cordoba, Ricardo
   Bungeroth, Jan
   Stein, Daniel
   Ney, Hermann
GP ISCA-INST SPEECH COMMUNICATION ASSOC
TI Language Model Adaptation for a Speech to Sign Language Translation
   System using Web Frequencies and a MAP Framework
SO INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH
   COMMUNICATION ASSOCIATION 2008, VOLS 1-5
CT 9th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2008)
CY SEP 22-26, 2008
CL Brisbane, AUSTRALIA
AB This paper presents a successful technique for creating a new language model (LM) that adapts the original target LM used by a machine translation (MT) system. This technique is especially useful for situations where there are very scarce resources for training the target side (Spanish Sign Language (LSE) in our case) in order to properly estimate the target LM, the Sign Language Model (SLM), used by the MT system. The technique uses information from the source language, Spanish in our task, and from the phrase-based translation matrix in order to create a new LM, estimated using web frequencies, which adapts the counts of the SLM through the Maximum A Posteriori method (MAP). The corpus consists of common used sentences spoken by an officer when assisting people in applying for, or renewing, the National Identification Document. The proposed technique allows relative reductions of 15.5% on perplexity and 2.7% on WER for translation, which are close to half the maximum performance obtainable when only the LM is optimized.
RI San-Segundo, Rubén/J-6027-2017; de Córdoba Herralde,
   Ricardo/B-5861-2008; D'Haro, Luis Fernando L.F/B-8194-2011
OI San-Segundo, Rubén/0000-0001-9659-5464; de Córdoba Herralde,
   Ricardo/0000-0002-7136-9636; D'Haro, Luis Fernando
   L.F/0000-0002-3411-7384
BN 978-1-61567-378-0
PY 2008
BP 2199
EP +
UT WOS:000277026101125
ER

PT C
AU Zhou, Z
   Sperber, M
   Waibel, A
AF Zhou, Zhong
   Sperber, Matthias
   Waibel, Alex
GP Associ Computat Linguist
TI Paraphrases as Foreign Languages in Multilingual Neural Machine
   Translation
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019:): STUDENT RESEARCH WORKSHOP
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB Paraphrases, the rewordings of the same semantic meaning, are useful for improving generalization and translation. However, prior works only explore paraphrases at the word or phrase level, not at the sentence or corpus level. Unlike previous works that only explore paraphrases at the word or phrase level, we use different translations of the whole training data that are consistent in structure as paraphrases at the corpus level. We train on parallel paraphrases in multiple languages from various sources. We treat paraphrases as foreign languages, tag source sentences with paraphrase labels, and train on parallel paraphrases in the style of multilingual Neural Machine Translation (NMT). Our multi-paraphrase NMT that trains only on two languages outperforms the multilingual baselines. Adding paraphrases improves the rare word translation and increases entropy and diversity in lexical choice. Adding the source paraphrases boosts performance better than adding the target ones. Combining both the source and the target paraphrases lifts performance further; combining paraphrases with multilingual data helps but has mixed performance. We achieve a BLEU score of 57.2 for French-to-English translation using 24 corpus-level paraphrases of the Bible, which outperforms the multilingual baselines and is +34.7 above the single-source singletarget NMT baseline.
BN 978-1-950737-47-5
PY 2019
BP 113
EP 122
UT WOS:000521483200015
ER

PT C
AU Wei, XP
   Yu, H
   Hu, Y
   Zhang, Y
   Weng, RX
   Luo, WH
AF Wei, Xiangpeng
   Yu, Heng
   Hu, Yue
   Zhang, Yue
   Weng, Rongxiang
   Luo, Weihua
GP Assoc Computat Linguist
TI Multiscale Collaborative Deep Models for Neural Machine Translation
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB Recent evidence reveals that Neural Machine Translation (NMT) models with deeper neural networks can be more effective but are difficult to train. In this paper, we present a MultiScale Collaborative (MSC) framework to ease the training of NMT models that are substantially deeper than those used previously. We explicitly boost the gradient backpropagation from top to bottom levels by introducing a block-scale collaboration mechanism into deep NMT models. Then, instead of forcing the whole encoder stack directly learns a desired representation, we let each encoder block learns a fine-grained representation and enhance it by encoding spatial dependencies using a context-scale collaboration. We provide empirical evidence showing that the MSC nets are easy to optimize and can obtain improvements of translation quality from considerably increased depth. On IWSLT translation tasks with three translation directions, our extremely deep models (with 72-layer encoders) surpass strong baselines by +2.2 similar to+3.1 BLEU points. In addition, our deep MSC achieves a BLEU score of 30.56 on WMT14 English -> German task that significantly outperforms state-of-the-art deep NMT models.
RI Hu, Yue/HGE-1673-2022
BN 978-1-952148-25-5
PY 2020
BP 414
EP 426
UT WOS:000570978200040
ER

PT C
AU Shin, S
   Matson, ET
   Park, J
   Yang, B
   Lee, J
   Jung, JW
AF Shin, Sangmi
   Matson, Eric T.
   Park, Jinok
   Yang, Bowon
   Lee, Juhee
   Jung, Jin-Woo
BE Bailey, D
   Gupta, GS
   Demidenko, S
TI Speech-to-Speech Translation Humanoid Robot in Doctor's Office
SO PROCEEDINGS OF THE 2015 6TH INTERNATIONAL CONFERENCE ON AUTOMATION,
   ROBOTICS AND APPLICATIONS (ICARA)
CT 6th International Conference on Automation, Robotics and Applications
   (ICARA)
CY FEB 17-19, 2015
CL Queenstown, NEW ZEALAND
SP IEEE NZ Cent Sect, IEEE Instrumentat & Measurement Soc Tech Comm Robot & Automat, IEEE, Massey Univ, Sch Engn & Adv Technol
AB This paper illustrates the implementation of a speech-to-speech translation humanoid robot in the domain of medical care. At this stage, the proposed system is a one-way translation that is designed to help English speaking patients describe their symptoms to Korean doctors or nurses. A humanoid robot is useful because it can be extended to reach out to people in need first and may substitute the role of human workers, unlike laptops or tablets. The system consists of three main parts - speech recognition, English-Korean translation, and Korean speech generation. It utilizes CMU Sphinx-4 as a speech recognition tool. English-Korean translation in this system is based on the rule-based translation. The success rate of the translation shows reliable results from an experiment with a closed scenario.
BN 978-1-4799-6466-6
PY 2015
BP 484
EP 489
UT WOS:000381564700081
ER

PT C
AU Ruiz-Pinales, J
   Acosta-Reyes, JJ
   Jaime-Rivas, R
   Salazar-Garibay, A
AF Ruiz-Pinales, Jose
   Acosta-Reyes, Juan Jorge
   Jaime-Rivas, Rene
   Salazar-Garibay, Adan
BE Sukhoivanov, IA
   Shmaily, YS
   TorresCisneros, M
   IbarraManzano, OG
   GuzmanCabrera, R
TI Rotation invariant image recognition using Hough transform and support
   vector machines
SO MEP 2006: PROCEEDINGS OF MULTICONFERENCE ON ELECTRONICS AND PHOTONICS
CT 3rd International Conference on Advanced Optoelectronics and Lasers/3rd
   International Conference on Precision Oscillations in Electronics and
   Optics/1st International Workshop on Image and Signal Processing (MEP
   2006)
CY NOV 07-11, 2006
CL Univ Guanajuato, Guanajuato, MEXICO
SP Univ Guanajuato, Fac Ingenieria Mecan, Elect & Elect, Natl Inst Astrophys, Opt & Elect, CONACYT, Res Ctr Opt, Presidencia Municipal Salamanca 2006 2009, IEEE LEOS, Ukraine Chapter
HO Univ Guanajuato
AB The Hough transform is an information preservation transformation which converts rotations of the image into translations. For this reason, it constitutes an ideal candidate for adding rotation invariance to SVM based image recognition systems. Experiments performed on face recognition are presented. The problem of translation invariance is also dealt with.
RI Ruiz-Pinales, José/AAC-1891-2021; Pinales, José Ruiz/T-6102-2019
OI Ruiz-Pinales, Jose/0000-0003-2639-1487
BN 978-1-4244-0627-2
PY 2006
BP 196
EP +
UT WOS:000245429600051
ER

PT J
AU Tian, L
   Wong, DF
   Chao, LS
   Oliveira, F
AF Tian, Liang
   Wong, Derek F.
   Chao, Lidia S.
   Oliveira, Francisco
TI A Relationship: Word Alignment, Phrase Table, and Translation Quality
SO SCIENTIFIC WORLD JOURNAL
AB In the last years, researchers conducted several studies to evaluate the machine translation quality based on the relationship between word alignments and phrase table. However, existing methods usually employ ad-hoc heuristics without theoretical support. So far, there is no discussion from the aspect of providing a formula to describe the relationship among word alignments, phrase table, and machine translation performance. In this paper, on one hand, we focus on formulating such a relationship for estimating the size of extracted phrase pairs given one or more word alignment points. On the other hand, a corpus-motivated pruning technique is proposed to prune the default large phrase table. Experiment proves that the deduced formula is feasible, which not only can be used to predict the size of the phrase table, but also can be a valuable reference for investigating the relationship between the translation performance and phrase tables based on different links of word alignment. The corpus-motivated pruning results show that nearly 98% of phrases can be reduced without any significant loss in translation quality.
RI Wong, Fai/A-7994-2012; Wong, Derek F/CAI-7740-2022
OI Wong, Fai/0000-0002-5307-7322; 
SN 1537-744X
PY 2014
AR 438106
DI 10.1155/2014/438106
UT WOS:000335028800001
PM 24883402
ER

PT J
AU Betanzos, M
   Costa-jussa, MR
   Belanche, L
AF Betanzos, Miguel
   Costa-jussa, Marta R.
   Belanche, Lluis
TI Tradares: A Tool for the Automatic Evaluation of Human Translation
   Quality within a MOOC Environment
SO APPLIED ARTIFICIAL INTELLIGENCE
AB In this paper, we introduce TradARES, a tool for the automatic evaluation of human translation quality developed in the context of an OpenEdx MOOC (Massive Open Online Course), setting the foundation for a tool that provides efficient and trustful feedback to students. Our further goal is to release a small corpus of Arabic-Spanish translations from the first edition of the course. The evaluation tool is based on prediction models and at the moment is able to indicate the quality of a given piece of textin the numerical scale {1,2,3,4}as a translation of another piece of text.
SN 0883-9514
EI 1087-6545
PY 2017
VL 31
IS 3
BP 288
EP 297
DI 10.1080/08839514.2017.1317154
UT WOS:000402053400006
ER

PT C
AU Wu, XC
   Matsuzaki, T
   Tsujii, J
AF Wu, Xianchao
   Matsuzaki, Takuya
   Tsujii, Jun'ichi
GP Assoc Computat Linguist
TI Fine-grained Tree-to-String Translation Rule Extraction
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Tree-to-string translation rules are widely used in linguistically syntax-based statistical machine translation systems. In this paper, we propose to use deep syntactic information for obtaining fine-grained translation rules. A head-driven phrase structure grammar (HPSG) parser is used to obtain the deep syntactic information, which includes a fine-grained description of the syntactic property and a semantic representation of a sentence. We extract fine-grained rules from aligned HPSG tree/ forest-string pairs and use them in our tree-to-string and string-to-tree systems. Extensive experiments on largescale bidirectional Japanese-English translations testified the effectiveness of our approach.
BN 978-1-932432-66-4
PY 2010
BP 325
EP 334
UT WOS:000391195300034
ER

PT J
AU Gildea, D
AF Gildea, Daniel
TI On the String Translations Produced by Multi Bottom-Up Tree Transducers
SO COMPUTATIONAL LINGUISTICS
AB Tree transducers are defined as relations between trees, but in syntax-based machine translation, we are ultimately concerned with the relations between the strings at the yields of the input and output trees. We examine the formal power of Multi Bottom-Up Tree Transducers from this point of view.
OI Gildea, Daniel/0000-0002-7858-2624
SN 0891-2017
EI 1530-9312
PD SEP
PY 2012
VL 38
IS 3
BP 673
EP 693
DI 10.1162/COLI_a_00108
UT WOS:000308083100008
ER

PT J
AU Su, JS
   Shi, XD
   Huang, YZ
   Liu, Y
   Wu, QQ
   Chen, YD
   Dong, HL
AF Su, Jin-song
   Shi, Xiao-dong
   Huang, Yan-zhou
   Liu, Yang
   Wu, Qing-qiang
   Chen, Yi-dong
   Dong, Huai-lin
TI Topic-aware pivot language approach for statisticalmachine translation
SO JOURNAL OF ZHEJIANG UNIVERSITY-SCIENCE C-COMPUTERS & ELECTRONICS
AB The pivot language approach for statistical machine translation (SMT) is a good method to break the resource bottleneck for certain language pairs. However, in the implementation of conventional approaches, pivot-side context information is far from fully utilized, resulting in erroneous estimations of translation probabilities. In this study, we propose two topic-aware pivot language approaches to use different levels of pivot-side context. The first method takes advantage of document-level context by assuming that the bridged phrase pairs should be similar in the document-level topic distributions. The second method focuses on the effect of local context. Central to this approach are that the phrase sense can be reflected by local context in the form of probabilistic topics, and that bridged phrase pairs should be compatible in the latent sense distributions. Then, we build an interpolated model bringing the above methods together to further enhance the system performance. Experimental results on French-Spanish and French-German translations using English as the pivot language demonstrate the effectiveness of topic-based context in pivot-based SMT.
OI Shi, Xiaodong/0000-0002-8163-7139
SN 1869-1951
EI 1869-196X
PD APR
PY 2014
VL 15
IS 4
BP 241
EP 253
DI 10.1631/jzus.C1300208
UT WOS:000334522500001
ER

PT C
AU Nie, JY
   Chen, J
AF Nie, JY
   Chen, J
GP IEEE
   IEEE
TI Learning translation models from the web
SO 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS
   1-4, PROCEEDINGS
CT International Conference on Machine Learning and Cybernetics
CY NOV 04-05, 2002
CL BEIJING, PEOPLES R CHINA
SP IEEE, SMC, Hebei Univ, Machine Learning Ctr
AB Query translation is the key problem in Cross-Language Information Retrieval. It can be made by exploiting a large set of parallel texts. In this paper, we describe a mining system that automatically discovers parallel Web pages on the Web. This system exploits the existing search engines, and the common characteristics in the organization of Web pages. Several large text corpora have been constructed using this system. Our experiments show that query translation using the obtained corpora can be as good as those by high-quality machine translation systems. This study shows the feasibility of building automatically a query translation system for all the active languages on the Web.
BN 0-7803-7508-4
PY 2002
BP 1999
EP 2004
UT WOS:000181396300434
ER

PT J
AU Filhol, M
   Hadjadj, MN
   Testu, B
AF Filhol, Michael
   Hadjadj, Mohamed N.
   Testu, Benoit
TI A rule triggering system for automatic text-to-sign translation
SO UNIVERSAL ACCESS IN THE INFORMATION SOCIETY
AB The topic of this paper is machine translation (MT) from French text into French sign language (LSF). After arguing in favour of a rule-based method, it presents the architecture of an original MT system, built on two distinct efforts: formalising LSF production rules and triggering them with text processing. The former is made without any concern for text or translation and involves corpus analysis to link LSF form features to linguistic functions. It produces a set of production rules which may constitute a full LSF production grammar. The latter is an information extraction task from text, broken down in as many subtasks as there are rules in the grammar. After discussing this architecture, comparing it to the traditional methods and presenting the methodology for each task, the paper present the set of production rules found to govern event precedence and duration in LSF and gives a progress report on the implementation of the rule triggering system. With this proposal, it is also hoped to show how MT can benefit today from sign language processing.
SN 1615-5289
EI 1615-5297
PD NOV
PY 2016
VL 15
IS 4
BP 487
EP 498
DI 10.1007/s10209-015-0413-4
UT WOS:000386374200002
ER

PT J
AU Aleksandrova, EM
AF Aleksandrova, Elena M.
TI "Quasi-Translation" of the Pun: The Specificity of Using Algorithms
SO TOMSK STATE UNIVERSITY JOURNAL
AB The article is devoted to the problem of the translation of pun, which poses a challenge not only for beginners, but also for experienced translators and interpreters. The leading approach to solving this problem is to build translation algorithms for various types of puns. The need to develop algorithms is caused by the variety of operations that a translator performs to meet the challenge. The experiments on the translation of jokes containing puns based on the use of homonyms, paronyms, polysemants and phraseological units (more than 500 examples have been considered) revealed the most common types and sequences of the operations performed by a translator. The revealed regularities formed the basis of algorithms in which the cognitive processes occurring in the brain of a translator are simulated. The algorithm includes three main steps: recognition of signs used to create ambiguity in the source language; search for matching signs in the target language; the re-creation of the pun with the use of the matching signs in the target language. Each step involves a particular sequence of operations consisting of conditional and non-conditional steps. The translation and didactic experiments were carried out in order to identify the specificity of using algorithms. The translation experiment consisted in using algorithms by translation practitioners. At the first stage, the participants had to draw on their own experience when translating puns; at the second stage, they were offered the stimulus material. The survey revealed that more than 91% of participants stated that the algorithms simplify the translation task; more than 83% noted that they also help to reduce the time of translation. Under the didactic experiment the students of the translation department were proposed to translate four pun-based jokes from English into Russian. At the first stage, the participants of the experiment had to translate the jokes by using their own knowledge; at the second stage, they were given a course of lectures on the application of algorithms when creating a "quasi-translation". The experiment demonstrated that the use of algorithms improves the quality and the variety of translations (the number of "quasi-translations" increased by 72%, the variability by more than 30%). It also helps to avoid stalemates and develops a creative approach that does not allow to go beyond the scope of the translation. The materials of the article are of practical value for translation teachers, as well as translation practitioners. The results of the study may also have an applied nature. The algorithms associated with searching for matching signs in the target language can be used to build training and testing sets for machine learning when composing language pairs. This will increase the amount of teaching material and improve the quality of neural machine translation.
SN 1561-7793
EI 1561-803X
PD AUG
PY 2019
IS 445
BP 5
EP 11
DI 10.17223/15617793/445/1
UT WOS:000489686300001
ER

PT C
AU Waelbers, B
   Bromuri, S
   Henkel, AP
AF Waelbers, Bea
   Bromuri, Stefano
   Henkel, Alexander P.
GP IEEE
TI Comparing Neural Networks for Speech Emotion Recognition in Customer
   Service Interactions
SO 2022 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / IEEE World
   Congress on Computational Intelligence (IEEE WCCI) / International Joint
   Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary
   Computation (IEEE CEC)
CY JUL 18-23, 2022
CL Padua, ITALY
SP IEEE, Int Neural Network Soc, IEEE Computat Intelligence Soc, Evolutionary Programming Soc, IET, Univ Padova, Dept Math Tullio Levi Civita, European Space Agcy, expert.ai, Elsevier, Springer Nature, Google, Baker & Hughes, NVIDIA
AB Automatic speech emotion recognition (SER) may assist call center service employees in deciphering and regulating customer emotions. In order to contribute to a successful augmentation of service employees with AI, the main goal of this study is to identify effective machine learning approaches to classify discrete basic emotions in customer service conversations. A comparison is presented of the recognition performance of different neural network architectures on speech features extracted from service interactions in a naturalistic customer service setting. Baseline classifiers, including a zero-rule classifier, a random classifier, a frequency classifier, and non-sequential multi-class classifiers are compared to different neural network architectures. A multi-layer perceptron (MLP), a one-dimensional convolutional neural network (CNN), and a neural machine translation (NMT) outperform the baseline classifiers, suggesting a pattern in the data relating to emotion labels. While the neural machine translation model with attention attains the highest f1-score, no significant difference in performance among the neural networks is detected. Results therefore support the use of the the multi-label multi-layer perceptron as the simplest model.
OI Waelbers, Bea/0000-0003-3720-4886
SN 2161-4393
BN 978-1-7281-8671-9
PY 2022
DI 10.1109/IJCNN55064.2022.9892165
UT WOS:000867070902048
ER

PT C
AU Ji, BJ
   Zhang, ZR
   Duan, XY
   Zhang, M
   Chen, BX
   Luo, WH
AF Ji, Baijun
   Zhang, Zhirui
   Duan, Xiangyu
   Zhang, Min
   Chen, Boxing
   Luo, Weihua
GP Assoc Advancement Artificial Intelligence
TI Cross-Lingual Pre-Training Based Transfer for Zero-Shot Neural Machine
   Translation
SO THIRTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THE
   THIRTY-SECOND INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE
   CONFERENCE AND THE TENTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN
   ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 34th AAAI Conference on Artificial Intelligence / 32nd Innovative
   Applications of Artificial Intelligence Conference / 10th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 07-12, 2020
CL New York, NY
SP Assoc Advancement Artificial Intelligence
AB Transfer learning between different language pairs has shown its effectiveness for Neural Machine Translation (NMT) in low-resource scenario. However, existing transfer methods involving a common target language are far from success in the extreme scenario of zero-shot translation, due to the language space mismatch problem between transferor (the parent model) and transferee (the child model) on the source side. To address this challenge, we propose an effective transfer learning approach based on cross-lingual pre-training. Our key idea is to make all source languages share the same feature space and thus enable a smooth transition for zero-shot translation. To this end, we introduce one monolingual pre-training method and two bilingual pre-training methods to obtain a universal encoder for different languages. Once the universal encoder is constructed, the parent model built on such encoder is trained with large-scale annotated data and then directly applied in zero-shot translation scenario. Experiments on two public datasets show that our approach significantly outperforms strong pivot-based baseline and various multilingual NMT approaches.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-835-0
PY 2020
VL 34
BP 115
EP 122
UT WOS:000667722800014
ER

PT J
AU Burton, SD
   Mahfoud, T
   Aicardi, C
   Rose, N
AF Datta Burton, S.
   Mahfoud, T.
   Aicardi, C.
   Rose, N.
TI Clinical translation of computational brain models: understanding the
   salience of trust in clinician-researcher relationships
SO INTERDISCIPLINARY SCIENCE REVIEWS
AB Computational brain models use machine learning, algorithms and statistical models to harness big data for delivering disease-specific diagnosis or prognosis for individuals. While intended to support clinical decision-making, their translation into clinical practice remains challenging despite efforts to improve implementation through training clinicians and clinical staff in their use and benefits. Drawing on the specific case of neurology, we argue that existing implementation efforts are insufficient for the responsible translation of computational models. Our research based on a collective seven-year engagement with the Human Brain Project, participant observation at workshops and conferences, and expert interviews, suggests that relationships of trust between clinicians and researchers (modellers, data scientists) are essential to the meaningful translation of computational models. In particular, efforts to increase model transparency, strengthen upstream collaboration, and integrate clinicians' perspectives and tacit knowledge have the potential to reinforce trust building and increase translation of technologies that are beneficial to patients.
RI ; Rose, Nikolas/A-4229-2013
OI Aicardi, Christine/0000-0003-1112-7720; Datta,
   Saheli/0000-0001-8268-9013; Rose, Nikolas/0000-0003-4007-5077
SN 0308-0188
EI 1743-2790
PD APR 3
PY 2021
VL 46
IS 1-2
SI SI
BP 138
EP 157
DI 10.1080/03080188.2020.1840223
UT WOS:000626277900008
ER

PT J
AU Prasad, R
   Natarajan, P
   Stallard, D
   Saleem, S
   Ananthakrishnan, S
   Tsakalidis, S
   Kao, CL
   Choi, F
   Meermeier, R
   Rawls, M
   Devlin, J
   Krstovski, K
   Challenner, A
AF Prasad, Rohit
   Natarajan, Prem
   Stallard, David
   Saleem, Shirin
   Ananthakrishnan, Shankar
   Tsakalidis, Stavros
   Kao, Chia-lin
   Choi, Fred
   Meermeier, Ralf
   Rawls, Mark
   Devlin, Jacob
   Krstovski, Kriste
   Challenner, Aaron
TI BBN Trans Talk: Robust multilingual two-way speech-to-speech translation
   for mobile platforms
SO COMPUTER SPEECH AND LANGUAGE
AB In this paper we present a speech-to-speech (S2S) translation system called the BBN TransTalk that enables two-way communication between speakers of English and speakers who do not understand or speak English. The BBN TransTalk has been configured for several languages including Iraqi Arabic. Pashto. Dad. Farsi. Malay. Indonesian, and Levantine Arabic. We describe the key components of our system: automatic speech recognition (ASR), machine translation (MT). text-to-speech (TTS), dialog manager, and the user interface (UI). In addition, we present novel techniques for overcoming specific challenges in developing high-performing S2S systems. For ASR, we present techniques for dealing with lack of pronunciation and linguistic resources and effective modeling of ambiguity in pronunciations of words in these languages. For MT. we describe techniques for dealing with data sparsity as well as modeling context. We also present and compare different user confirmation techniques for detecting errors that can cause the dialog to drift or stall. (C) 2011 Elsevier Ltd. All rights reserved.
OI Natarajan, Premkumar/0000-0002-4386-6651; Krstovski,
   Kriste/0000-0001-9341-8745
SN 0885-2308
EI 1095-8363
PD FEB
PY 2013
VL 27
IS 2
SI SI
BP 475
EP 491
DI 10.1016/j.csl.2011.10.003
UT WOS:000312471500006
ER

PT C
AU Zhu, HL
   Zheng, DQ
   Zhao, TJ
AF Zhu, Honglei
   Zheng, Dequan
   Zhao, Tiejun
BE Wang, GJ
   Chen, J
   Fellows, MR
   Ma, HD
TI Research on Query Translation Disambiguation for CLIR Based on HowNet
SO PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER
   SCIENTISTS, VOLS 1-5
CT 9th International Conference for Young Computer Scientists
CY NOV 18-21, 2008
CL Zhangjiajie, PEOPLES R CHINA
AB Query translation is an important task for cross-language information retrieval (CLIR), which aims at translating the query described in source language into target language. The approach to query translation based on bilingual dictionary is becoming the mainstream thinking because of its simplicity and the increasing availability of machine readable bilingual dictionary. However, this kind of approach faces two necessary problems that is ambiguity in translation and the incompleteness of the dictionary. This paper focuses on the first problem, and it presents three statistical models based on HowNet to resolve query translation ambiguity of CLIR: Query translation selection based on semantic relation; Bilingual decaying co-occurrence model and Semantic decaying co-occurrence model. Through test and summarizing this paper gets the best algorithm to integrate the traits of the three models, which gradually filters and optimizes the translation.
BN 978-1-4244-4198-3
PY 2008
BP 1677
EP 1682
UT WOS:000269081800286
ER

PT C
AU Caliwag, A
   Angsanto, SR
   Lim, W
AF Caliwag, Angela
   Angsanto, Stephen Ryan
   Lim, Wansu
GP IEEE
TI Korean Sign Language Translation using Machine Learning
SO 2018 TENTH INTERNATIONAL CONFERENCE ON UBIQUITOUS AND FUTURE NETWORKS
   (ICUFN 2018)
SE International Conference on Ubiquitous and Future Networks
CT 10th International Conference on Ubiquitous and Future Networks (ICUFN)
CY JUL 03-06, 2018
CL Prague, CZECH REPUBLIC
SP IEEE, IEEE Commun Soc, IEICE Commun Soc, Springer, Korean Inst Commun & Informat Sci, Elect & Telecommunicat Res Inst, Natl Informat Soc Agcy, KT, SK Telecom, LG U+, Samsung Elect, LG Elect, LG, Ericsson, Modacom, Korea Elect Technol Inst, Dasan, Sensors, Inha Univ, UWB Wireless Commun Res Ctr, Kookmin Univ, LED Convergence Res Ctr, Multi Screen Serv Forum, Tech Univ Vienna, Informat & Software Engn Grp, Yonsei Univ, Next Generat RFID USN Res Ctr, Kyungpook Natl Univ, Ctr ICT & Automot Convergence, Soc Safety Syst Forum
AB Advancement in technology provides a means of doings things that even humankind is incapable of doing. A sign language glove aims to help the hearing-impaired people to eliminate the boundary and communicate with other people even without knowledge in Sign Language. Applying Machine Learning in hand gesture recognition provides a smarter means of conveying information with high accuracy.
SN 2165-8528
EI 2165-8536
BN 978-1-5386-4646-5
PY 2018
BP 826
EP 828
UT WOS:000790260800191
ER

PT J
AU Brisset, A
AF Brisset, Annie
TI Globalization, translation, and cultural diversity
SO TRANSLATION AND INTERPRETING STUDIES
AB The share of the economy related to translation activities is growing steadily under the influence of the globalization of exchanges. Today it numbers dozens of billions of which an increasing share belongs to machine translation. Various factors, such as migratory flows or the propagation of mobile telephony, prompt new translation practices in a variety of languages with simultaneous coverage enabled by networks. Nevertheless, is it true as we intuitively believe that translation promotes linguistic and cultural diversity? This article originates from a study conducted for UNESCO's world report on cultural diversity (2009). This study notably reveals that 75% of all books are translated from three languages with 55% being from English. On a planetary scale, translation is dominated by some twenty languages, primarily European. In the new world economic order, the urgent and paradoxical task is to "rebabelize" the world.
SN 1932-2798
EI 1876-2700
PY 2017
VL 12
IS 2
BP 253
EP 277
DI 10.1075/tis.12.2.04bri
UT WOS:000415337200004
ER

PT C
AU Gao, PZ
   He, ZJ
   Wu, H
   Wang, HF
AF Gao, Pengzhi
   He, Zhongjun
   Wu, Hua
   Wang, Haifeng
GP ASSOC COMPUTAT LINGUIST
TI Bi-SimCut: A Simple Strategy for Boosting Neural Machine Translation
SO NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE
   ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES
CT Conference of the
   North-American-Chapter-of-the-Association-for-Computational-Linguistics
   (NAAACL) - Human Language Technologies
CY JUL 10-15, 2022
CL Seattle, WA
SP Assoc Computat Linguist, N Amer Chapter, Amazon Sci, Bloomberg Engn, Google Res, LivepersoMetan, ByteDance, KENSH, Grammarly, Megagon Labs, Microsoft, Reveal Brainspace, Cohere, GResearch, Relativity, Servicenow, ASAPP, Duolingo, Adobe, Linkedin, Babelscape, Rakuten Inst Technol, UC Santa Cruz, Baskin Engn, Nat Language Proc, NSF, ETS, OpenAI, TIAA, Two Sigma, Mag Data
AB We introduce Bi-SimCut: a simple but effective training strategy to boost neural machine translation (NMT) performance. It consists of two procedures: bidirectional pretraining and unidirectional finetuning. Both procedures utilize SimCut, a simple regularization method that forces the consistency between the output distributions of the original and the cutoff sentence pairs. Without leveraging extra dataset via back-translation or integrating large-scale pretrained model, Bi-SimCut achieves strong translation performance across five translation benchmarks (data sizes range from 160K to 20.2M): BLEU scores of 31.16 for en -> de and 38.37 for de -> en on the IWSLT14 dataset, 30.78 for en -> de and 35.15 for de -> en on the WMT14 dataset, and 27.17 for zh -> en on the WMT17 dataset. SimCut is not a new method, but a version of Cutoff (Shen et al., 2020) simplified and adapted for NMT, and it could be considered as a perturbation-based method. Given the universality and simplicity of SimCut and Bi-SimCut, we believe they can serve as strong baselines for future NMT research.
BN 978-1-955917-71-1
PY 2022
BP 3938
EP 3948
UT WOS:000859869504004
ER

PT J
AU Liu, FZ
AF Liu, Fengzhen
TI Design of Chinese-English Wireless Simultaneous Interpretation System
   Based on Speech Recognition Technology
SO INTERNATIONAL JOURNAL OF ANTENNAS AND PROPAGATION
AB A Chinese-English wireless simultaneous interpretation system based on speech recognition technology is suggested to solve the problems of low translation accuracy and a high number of ambiguous terms in current Chinese-English simultaneous interpretation systems. The system's general structure and hardware architecture are summarized The chairman unit, representative unit, transliteration unit, and auditing unit are the four basic components of the simultaneous interpretation system. The CPU is the nRF24E1 hardware wireless radio frequency transceiver chip, while the chairman machine, representative machine, translator, and auditorium are all created separately. Speech recognition technology is used by the system software to create a speech recognition process that properly produces speech-related semantics.)e input text is used as the search criteria, a manual interactive synchronous translation program is created, and the results for the optimum translation impact are trimmed. The experimental findings reveal that this system's sentence translation accuracy rate is 0.9-1.0, and the number of ambiguous terms is minimal, which is an improvement on previous systems' low translation accuracy.
SN 1687-5869
EI 1687-5877
PD SEP 30
PY 2021
VL 2021
AR 7346984
DI 10.1155/2021/7346984
UT WOS:000779974500002
ER

PT J
AU Daems, J
   Vandepitte, S
   Hartsuiker, RJ
   Macken, L
AF Daems, Joke
   Vandepitte, Sonia
   Hartsuiker, Robert J.
   Macken, Lieve
TI Translation Methods and Experience: A Comparative Analysis of Human
   Translation and Post-editing with Students and Professional Translators
SO META
AB While the benefits of using post-editing for technical texts have been more or less acknowledged, it remains unclear whether post-editing is a viable alternative to human translation for more general text types. In addition, we need a better understanding of both translation methods and how they are performed by students as well as professionals, so that pitfalls can be determined and translator training can be adapted accordingly. In this article, we aim to get a better understanding of the differences between human translation and post-editing for newspaper articles. Processes are registered by means of eye tracking and keystroke logging, which allows us to study translation speed, cognitive load, and the use of external resources. We also look at the final quality of the product as well as translators' attitude towards both methods of translation. Studying these different aspects shows that both methods and groups are more similar than anticipated.
RI Hartsuiker, Robert J./N-1668-2019
OI Macken, Lieve/0000-0001-7516-7487; Daems, Joke/0000-0003-3734-5160
SN 0026-0452
PD AUG
PY 2017
VL 62
IS 2
BP 245
EP 270
DI 10.7202/1041023ar
UT WOS:000412214200002
ER

PT C
AU Bernier-Colborne, G
   Lo, CK
AF Bernier-Colborne, Gabriel
   Lo, Chi-kiu
GP Assoc Computat Linguist
TI NRC Parallel Corpus Filtering System for WMT 2019
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 3: SHARED TASK
   PAPERS, DAY 2
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB We describe the National Research Council Canada team's submissions to the parallel corpus filtering task at the Fourth Conference on Machine Translation.
BN 978-1-950737-27-7
PY 2019
BP 252
EP 260
UT WOS:000538569000034
ER

PT C
AU Fomicheva, M
   Sun, S
   Fonseca, E
   Zerva, C
   Blain, F
   Chaudhary, V
   Guzman, F
   Lopatina, N
   Martins, AFT
   Specia, L
AF Fomicheva, Marina
   Sun, Shuo
   Fonseca, Erick
   Zerva, Chrysoula
   Blain, Frederic
   Chaudhary, Vishrav
   Guzman, Francisco
   Lopatina, Nina
   Martins, Andre F. T.
   Specia, Lucia
BA Mariani, J
BF Mariani, J
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mazo, H
   Odijk, H
   Piperidis, S
TI MLQE-PE: A Multilingual Quality Estimation and Post-Editing Dataset
SO LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION
CT 13th International Conference on Language Resources and Evaluation
   (LREC)
CY JUN 20-25, 2022
CL Marseille, FRANCE
SP Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur
AB We present MLQE-PE, a new dataset for Machine Translation (MT) Quality Estimation (QE) and Automatic Post-Editing (APE). The dataset contains annotations for eleven language pairs, including both high- and low-resource languages. Specifically, it is annotated for translation quality with human labels for up to 10,000 translations per language pair in the following formats: sentence-level direct assessments and post-editing effort, and word-level binary good/bad labels. Apart from the quality-related scores, each source-translation sentence pair is accompanied by the corresponding post-edited sentence, as well as titles of the articles where the sentences were extracted from, and information on the neural MT models used to translate the text. We provide a thorough description of the data collection and annotation process as well as an analysis of the annotation distribution for each language pair. We also report the performance of baseline systems trained on the MLQE-PE dataset. The dataset is freely available and has already been used for several WMT shared tasks.
BN 979-10-95546-72-6
PY 2022
BP 4963
EP 4974
UT WOS:000889371705008
ER

PT C
AU Battaglino, C
   Geraci, C
   Lombardo, V
   Mazzei, A
AF Battaglino, Cristina
   Geraci, Carlo
   Lombardo, Vincenzo
   Mazzei, Alessandro
BE Antona, M
   Stephanidis, C
TI Prototyping and Preliminary Evaluation of Sign Language Translation
   System in the Railway Domain
SO UNIVERSAL ACCESS IN HUMAN-COMPUTER INTERACTION: ACCESS TO INTERACTION,
   PT II
SE Lecture Notes in Computer Science
CT 9th International Conference on Universal Access in Human-Computer
   Interaction (UAHCI) Held as Part of 17th International Conference on
   Human-Computer Interaction (HCI)
CY AUG 02-07, 2015
CL Los Angeles, CA
AB This paper presents the prototype and the preliminary evaluation of an automatic translation system developed in the LIS4ALL project. The system domain is the corpus of railway station announcements in Italian. The output of the system is a 3D animated avatar that signs announcements in Italian Sign Language. The preliminary evaluation, which measures the accuracy of the translations at the sentence level, relies through the BLEU-RAC4 metric, a variant of the traditional BLEU metric used to evaluate Machine Translation, specifically designed for sentence level evaluation. The aim of the evaluation is to compare the LIS4ALL translation outputs with the human counterparts.
OI Lombardo, Vincenzo/0000-0002-8166-9827
SN 0302-9743
EI 1611-3349
BN 978-3-319-20681-3; 978-3-319-20680-6
PY 2015
VL 9176
BP 339
EP 350
DI 10.1007/978-3-319-20681-3_32
UT WOS:000364183800032
ER

PT C
AU Shen, S
   Baevski, A
   Morcos, AS
   Keutzer, K
   Auli, M
   Kiela, D
AF Shen, Sheng
   Baevski, Alexei
   Morcos, Ari S.
   Keutzer, Kurt
   Auli, Michael
   Kiela, Douwe
GP Assoc Computat Linguist
TI Reservoir Transformers
SO 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND
   THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (ACL-IJCNLP 2021), VOL 1
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB We demonstrate that transformers obtain impressive performance even when some of the layers are randomly initialized and never updated. Inspired by old and well-established ideas in machine learning, we explore a variety of non-linear "reservoir" layers interspersed with regular transformer layers, and show improvements in wall-clock compute time until convergence, as well as overall performance, on various machine translation and (masked) language modelling tasks.
BN 978-1-954085-52-7
PY 2021
BP 4294
EP 4309
UT WOS:000698679200131
ER

PT C
AU Ananthakrishnan, S
   Prasad, R
   Natarajan, P
AF Ananthakrishnan, Sankaranarayanan
   Prasad, Rohit
   Natarajan, Prem
GP INST SPEECH COMMUN ASSOC
TI Phrase Alignment Confidence for Statistical Machine Translation
SO 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4
CT 11th Annual Conference of the
   International-Speech-Communication-Association 2010
CY SEP 26-30, 2010
CL Makuhari, JAPAN
SP Japan World Exposit, Commemorat Org, Japan Soc Promot Sci, Telecommunicat Advancement Fdn, KDDI Fdn, Murata Sci Fdn, Adv Telecommunicat Technol Res Fdn, Support Ctr, Chiba Convent Bur & Int Ctr, Renesas Elect Corp, Google, Microsoft Corp, Nuance Commun Inc, Appen Pty Ltd, IBM, Sony Corp, Hitachi Ltd, Yahoo Japan Corp, Asahi Kasei Corp, KDDI R & D Lab Inc, Yamaha Corp, Toshiba Corp, Fujitsu Ltd, Mitsubishi Elect Corp, RION Co Ltd, NEC Corp
AB The performance of phrase-based statistical machine translation (SMT) systems is crucially dependent on the quality of the extracted phrase pairs, which is in turn a function of word alignment quality. Data sparsity, an inherent problem in SMT even with large training corpora, often has an adverse impact on the reliability of the extracted phrase translation pairs. In this paper, we present a novel feature based on bootstrap resampling of the training corpus, termed phrase alignment confidence, that measures the goodness of a phrase translation pair. We integrate this feature within a phrase-based SMT system and show an improvement of 1.7% BLEU and 4.4% METEOR over a baseline English-to-Pashto (E2P) SMT system that does not use any measure of phrase pair quality. We then show that the proposed measure compares well to an existing indicator of phrase pair reliability, the lexical smoothing probability. We also demonstrate that combining the two measures leads to a further improvement of 0.4% BLEU and 0.3% METEOR on the E2P system. Commensurate translation improvements are obtained on automatic speech recognition (ASR) transcripts of the source speech utterances.
OI Natarajan, Premkumar/0000-0002-4386-6651
BN 978-1-61782-123-3
PY 2010
BP 2878
EP 2881
UT WOS:000313086500332
ER

PT C
AU Shu, R
   Nakayama, H
   Cho, K
AF Shu, Raphael
   Nakayama, Hideki
   Cho, Kyunghyun
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Generating Diverse Translations with Sentence Codes
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB Users of machine translation systems may desire to obtain multiple candidates translated in different ways. In this work, we attempt to obtain diverse translations by using sentence codes to condition the sentence generation. We describe two methods to extract the codes, either with or without the help of syntax information. For diverse generation, we sample multiple candidates, each of which conditioned on a unique code. Experiments show that the sampled translations have much higher diversity scores when using reasonable sentence codes, where the translation quality is still on par with the baselines even under strong constraint imposed by the codes. In qualitative analysis, we show that our method is able to generate paraphrase translations with drastically different structures. The proposed approach can be easily adopted to existing translation systems as no modification to the model is required.
RI Nakayama, Hideki/AAT-5270-2020
OI Nakayama, Hideki/0000-0001-8726-2780
BN 978-1-950737-48-2
PY 2019
BP 1823
EP 1827
UT WOS:000493046103031
ER

PT S
AU Yang, GL
   Li, YH
AF Yang, GL
   Li, YH
BE Jywe, W
   Chen, CL
   Fan, KC
   Fung, RF
   Hanson, SG
   Hsieh, WH
   Hsu, CL
   Huang, YM
   Hwang, YL
   Jager, G
   Jeng, YR
   Li, W
   Liao, YS
   Lin,, CC
   Lin, ZC
   Sung, CK
   Tzeng, CH
TI Performance analysis of a novel 6-DOF parallel-kinematics machine with
   decoupled motion characteristics
SO PROGRESS ON ADVANCED MANUFACTURE FOR MICRO/NANO TECHNOLOGY 2005, PT 1
   AND 2
SE Materials Science Forum
CT International Conference on Advanced Manufacture
CY NOV 28-DEC 02, 2005
CL Taipei, TAIWAN
SP Soc Mfg Engineers
AB This paper is focused on the performance analysis of a newly developed 6-DOF Parallel-Kinematics Machine (PKM). The design related analysis issues such as the instantaneous kinematics, manipulability, accuracy, and stiffness are addressed. This new PKM has three identical RPRS legs to support the moving platform. Since all joint axes, excluding the three spherical joints at the leg-ends, are parallel to each other and perpendicular to the base plane, this 6-DOF 3RPRS PKM exhibits decoupled motion characteristics such that translation along the vertical direction and rotation about horizontal axes are only driven by the three active-prismatic joints, while translation in horizontal planes and rotation about vertical axes are mainly driven by the three active-revolute joints. The PKM also has a large cylindrical reachable workspace and high stiffness in vertical directions. These features make it a promising 6-DOF machine structure for light machining and heavy parts assembly tasks.
RI li, yunhua/D-9361-2011
OI li, yunhua/0000-0001-6573-1267
SN 0255-5476
BN 0-87849-990-3
PY 2006
VL 505-507
BP 1177
EP 1182
DI 10.4028/www.scientific.net/MSF.505-507.1177
UT WOS:000235279200197
ER

PT J
AU Tillmann, C
   Ney, H
AF Tillmann, C
   Ney, H
TI Word reordering and a dynamic programming beam search algorithm for
   statistical machine translation
SO COMPUTATIONAL LINGUISTICS
AB In this article, we describe an efficient beam search algorithm for statistical machine translation based on dynamic programming (DP). The search algorithm uses the translation model presented in Brown et al. (1993). Starting from a DP-based solution to the traveling-salesman problem, we present a novel technique to restrict the possible word reorderings between source and target language in order to achieve an efficient search algorithm. Word reordering restrictions especially useful for the translation direction German to English are presented. The restrictions are generalized, and a set of four parameters to control the word reordering is introduced, which then can easily be adopted to new translation directions. The beam search procedure has been successfully tested on the Verbmobil task (German to English, 8,000-word vocabulary) and on the Canadian Hansards task (French to English, 100,000-word vocabulary). For the medium-sized Verbmobil task, a sentence can be translated in a few seconds, only a small number of search errors occur, and there is no performance degradation as measured by the word error criterion used in this article.
SN 0891-2017
EI 1530-9312
PD MAR
PY 2003
VL 29
IS 1
BP 97
EP 133
DI 10.1162/089120103321337458
UT WOS:000181707500005
ER

PT C
AU Goel, NK
   Sarnia, M
   Valluri, S
   Agrawal, D
   Braich, S
   Kuswah, TS
   Iqbal, Z
   Chauhan, S
   Karbar, R
AF Goel, Nagendra Kumar
   Sarnia, Mousmita
   Valluri, Saikiran
   Agrawal, Dharmeshkumar
   Braich, Steve
   Kuswah, Tejendra Singh
   Iqbal, Zikra
   Chauhan, Surbhi
   Karbar, Raj
GP Int Speech Commun Assoc
TI CaptionAI: a real-time multilingual captioning application
SO INTERSPEECH 2019
SE Interspeech
CT Interspeech Conference
CY SEP 15-19, 2019
CL Graz, AUSTRIA
AB We demonstrate CaptionAI, the system that can be used for speech to text transcription, multilingual translation, and real-time closed captioning. It can also broadcast the audio and translated text to personal devices. There are three components of the application, namely, speech to text conversion, machine translation, and real time broadcast of audio and its multilingual text transcription. CaptionAI makes meetings, conference, and events accessible to global audience members with its real-time multilingual captioning and broadcast capabilities, improving comprehension and retention. In this application, we support English and Spanish real-time speech transcription. It also supports seventeen popular languages for real-time Machine Translation of transcribed speech. The front-end is coded on c# and in back-end we use combination of python and c++ based software and packages such as Janus, Gstreamer, and libwebsockets.
SN 2308-457X
PY 2019
BP 4632
EP 4633
UT WOS:000831796404158
ER

PT C
AU Zhang, JJ
   Zong, CQ
AF Zhang, Jiajun
   Zong, Chenqqing
BE Zhou, M
   Zhou, GD
   Zhao, DY
   Liu, Q
   Zou, L
TI A Comparative Study on Discontinuous Phrase Translation
SO NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING
SE Communications in Computer and Information Science
CT 1st CCF Conference on Natural Language Processing and Chinese Computing
CY OCT 31-NOV 05, 2012
CL Peking Univ, Beijing, PEOPLES R CHINA
SP China Comp Federat, Microsoft Res Asia, State Key Lab Digital Publish, ACTA Scientarum Naturalium Univ, Springer, Sina Weibo, Tencent Weibo, Mingbo Educ Technol
HO Peking Univ
AB Many research works have reported discontinuous phrase translation can significantly improve translation quality, but experiments are conducted in only one translation direction (e.g. Chinese-to-English) with only one language pair. Thus, two questions remain that whether the discontinuous rules are always much helpful in different language pairs? Furthermore, what kind of discontinuous rules (e.g. source-side discontinuity or target-side discontinuity) contributes most to the performance improvement? To answer these two questions, this paper conducts a comparative study on the contribution of different kinds of discontinuous rules in both translation directions with various language pairs. Then, with this comparative study, this paper proposes a role-based rule filtering strategy to filter the large amount of discontinuous rules that contribute very little to translation quality.
OI Zong, Chengqing/0000-0002-9864-3818
SN 1865-0929
BN 978-3-642-34455-8
PY 2012
VL 333
BP 164
EP 175
UT WOS:000315974300016
ER

PT C
AU Zhang, JJ
   Zhang, DK
   Hao, J
AF Zhang, Jiajun
   Zhang, Dakun
   Hao, Jie
BE Yang, Q
   Wooldridge, M
TI Local Translation Prediction with Global Sentence Representation
SO PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON
   ARTIFICIAL INTELLIGENCE (IJCAI)
CT 1st International Workshop on Social Influence Analysis / 24th
   International Joint Conference on Artificial Intelligence (IJCAI)
CY JUL 25-31, 2015
CL Buenos Aires, ARGENTINA
AB Statistical machine translation models have made great progress in improving the translation quality. However, the existing models predict the target translation with only the source-and target-side local context information. In practice, distinguishing good translations from bad ones does not only depend on the local features, but also rely on the global sentence-level information. In this paper, we explore the source-side global sentence-level features for target-side local translation prediction. We propose a novel bilingually-constrained chunk-based convolutional neural network to learn sentence semantic representations. With the sentence-level feature representation, we further design a feed-forward neural network to better predict translations using both local and global information. The large-scale experiments show that our method can obtain substantial improvements in translation quality over the strong baseline: the hierarchical phrase-based translation model augmented with the neural network joint model.
RI Hao, Jie/HSE-6117-2023
OI Hao, Jie/0000-0002-1602-4686
BN 978-1-57735-738-4
PY 2015
BP 1398
EP 1404
UT WOS:000442637801068
ER

PT J
AU Benaida, M
   Taleb, A
   Namoun, A
AF Benaida, Mohamed
   Taleb, Ahmad
   Namoun, Abdallah
TI The link between automated translation of the Arabic language and
   quality of websites
SO INTERNATIONAL JOURNAL OF COMPUTER SCIENCE AND NETWORK SECURITY
AB Statistics show that Arabic is the fourth used language on the Internet with more than two hundred and twenty million users and Arabic speakers represent more than 5% of the World's population.. This study examines the effect of translating web content from the English language to the Arabic language and how the accuracy of translation may influence the overall quality of websites. This study also carries a deep analysis of the Arabic morphology to illustrate the complexity and richness of the Arabic language and how this morphology could impose difficulties for content writers and designers of websites. The infamous Alibaba website, a gigantic online e-commerce company, is chosen as a key case study to investigate in this research. Expert evaluation of the website's translated content, including the morphology of the language used, is conducted and data were collected to identify the challenges and mistakes of translation that could influence the perceived quality of the website.
   The main finding indicates that the Arabic language is more complicated than expected, especially when diacritics are not used. When diacritics are omitted, Arabic words can be pronounced in multiple ways resulting in different meanings. The combination of a machine translation and human translator is the appropriate method to achieve the most accurate form of translation. Practically, translation through machine systems may be used to reduce translation costs and expedite the translation process. However, it is vital to follow up this process by a professional translation service to rectify any translation errors made during the automated translation. This study also shows that the acceptance or rejection of a website could be highly dependent on the accuracy of translation to the Arabic language. Another finding shows that Google translation is not the right choice when translating long text to the Arabic language. Occasionally, Google translate is unable to recognize and translate several words from Arabic due to the richness of the language.
RI Namoun, Abdallah/AAT-1905-2021
OI Namoun, Abdallah/0000-0002-7050-0532
SN 1738-7906
PD SEP 30
PY 2018
VL 18
IS 9
BP 65
EP 72
UT WOS:000447195800008
ER

PT S
AU Li, H
   Japkowicz, N
   Barriere, C
AF Li, H
   Japkowicz, N
   Barriere, C
BE Kegl, B
   Lapalme, G
TI English to Chinese translation of prepositions
SO ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS
SE LECTURE NOTES IN COMPUTER SCIENCE
CT 18th Conference of the
   Canadian-Society-for-Computational-Studies-of-Intelligence
CY MAY 09-11, 2005
CL Victoria, CANADA
SP Canadian Soc Computat Studies Intelligence
AB Machine translation of prepositions is a difficult task; little work has been done, to date, in this area. This article suggests addressing the problem using a semantic framework for the interpretation of the surrounding elements of a preposition in the source language. This framework, called Use Types, will reduce the set of possible prepositions in the target language, therefore helping the translation process. This approach is not language dependent, but we focus, here, on English and Chinese, and we also specifically look at three prepositions: in, on and at. The article describes machine learning experiments designed and conducted in which WordNet is employed to lead to an automatic discovery of the Use Types. Results are analyzed and discussed and a practical use of the system is suggested along with the preliminary results it obtains.
SN 0302-9743
BN 3-540-25864-7
PY 2005
VL 3501
BP 412
EP 416
UT WOS:000229965500043
ER

PT J
AU O'Thomas, M
AF O'Thomas, Mark
TI Humanum ex machina Translation in the post-global, posthuman world
SO TARGET-INTERNATIONAL JOURNAL OF TRANSLATION STUDIES
AB Translation sits at the epicentre of the biotech era's exponential growth. The terms of reference of this discipline are becoming increasingly unstable as humans interface with machines, become melded with them, and ultimately become a networked entity alongside other networked entities. In this brave new world, the posthuman offers a critical perspective that allows us to liberate our thinking in new ways and points towards the possibility of a translation theory that actively engages with other disciplines as a response to disciplinary hegemony. This article looks at how technology has changed and is changing translation. It then explores the implications of transhumanism and the possibilities for a posthuman translation theory. Ultimately, the survival of translation studies will be contingent on the survival of translation itself and its ability to question its own subjective, posthuman self.
RI O'THOMAS, MARK/D-4402-2018
OI O'THOMAS, MARK/0000-0001-9264-8813
SN 0924-1884
EI 1569-9986
PY 2017
VL 29
IS 2
SI SI
BP 284
EP 300
DI 10.1075/target.29.2.05oth
UT WOS:000407574400006
ER

PT J
AU Calvo, E
AF Calvo, Elisa
TI Postediting as a prospective learning opportunity?: Value-Added Services
   in Translator Training
SO QUADERNS DE FILOLOGIA-ESTUDIS LINGUISTICS
AB Value-added service (VAS) refers to differentiated language services offered by language service providers (LSP). Such services require the exercise of basic core translation and intercultural skills but also entail differences when compared to more general, conventional translation tasks. Specific technological input and different processes, formats and managerial frameworks require hard and soft skills from the language professional. This proposal reviews an integrative work framework for bringing students into contact with different facets of the language industry today with focus on the uses and limitations of machine translation and postediting within specialised translation contexts.
SN 1135-416X
EI 2444-1449
PY 2023
VL 27
BP 203
EP 219
DI 10.7203/QF.27.24666
UT WOS:000899234200009
ER

PT C
AU Gu, J
   Shavarani, HS
   Sarkar, A
AF Gu, Jetic
   Shavarani, Hassan S.
   Sarkar, Anoop
GP Assoc Computat Linguist
TI Top-down Tree Structured Decoding with Syntactic Connections for Neural
   Machine Translation and Parsing
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB The addition of syntax-aware decoding in Neural Machine Translation (NMT) systems requires an effective tree-structured neural network, a syntax-aware attention model and a language generation model that is sensitive to sentence structure. We exploit a top-down tree-structured model called DRNN (Doubly-Recurrent Neural Networks) first proposed by Alvarez-Melis and Jaakola (2017) to create an NMT model called Seq2DRNN that combines a sequential encoder with tree-structured decoding augmented with a syntax-aware attention model. Unlike previous approaches to syntax-based NMT which use dependency parsing models our method uses constituency parsing which we argue provides useful information for translation. In addition, we use the syntactic structure of the sentence to add new connections to the tree-structured decoder neural network (Seq2DRNN+SynC). We compare our NMT model with sequential and state of the art syntax-based NMT models and show that our model produces more fluent translations with better reordering. Since our model is capable of doing translation and constituency parsing at the same time we also compare our parsing accuracy against other neural parsing models.
BN 978-1-948087-84-1
PY 2018
BP 401
EP 413
UT WOS:000865723400037
ER

PT J
AU Hwang, YS
   Finch, A
   Sasaki, Y
AF Hwang, Young-Sook
   Finch, Andrew
   Sasaki, Yutaka
TI Improving statistical machine translation using shallow linguistic
   knowledge
SO COMPUTER SPEECH AND LANGUAGE
AB We describe methods for improving the performance of statistical machine translation (SMT) between four linguistically different languages, i.e., Chinese, English, Japanese, and Korean by using morphosyntactic knowledge. For the purpose of reducing the translation ambiguities and generating grammatically correct and fluent translation output, we address the use of shallow linguistic knowledge, that is: (1) enriching a word with its morphosyntactic features, (2) obtaining shallow linguistically-motivated phrase pairs, (3) iteratively refining word alignment using filtered phrase pairs, and (4) building a language model from morphosyntactically enriched words. Previous studies reported that the introduction of syntactic features into SMT models resulted in only a slight improvement in performance in spite of the heavy computational expense, however, this study demonstrates the effectiveness of morphosyntactic features, when reliable, discriminative features are used. Our experimental results show that word representations that incorporate morphosyntactic features significantly improve the performance of the translation model and language model. Moreover, we show that refining the word alignment using fine-grained phrase pairs is effective in improving system performance. (c) 2006 Elsevier Ltd. All rights reserved.
SN 0885-2308
EI 1095-8363
PD APR
PY 2007
VL 21
IS 2
BP 350
EP 372
DI 10.1016/j.csl.2006.06.007
UT WOS:000242491800007
ER

PT J
AU Malaterre, C
   Lareau, F
AF Malaterre, Christophe
   Lareau, Francis
TI The early days of contemporary philosophy of science: novel insights
   from machine translation and topic-modeling of non-parallel multilingual
   corpora
SO SYNTHESE
AB Topic model is a well proven tool to investigate the semantic content of textual corpora. Yet corpora sometimes include texts in several languages, making it impossible to apply language-specific computational approaches over their entire content. This is the problem we encountered when setting to analyze a philosophy of science corpus spanning over eight decades and including original articles in Dutch, German and French, on top of a large majority of articles in English. To circumvent this multilingual problem, we use machine-translation tools to bulk translate non-English documents into English. Though largely imperfect, especially syntactically, these translations nevertheless provide correctly translated terms and preserve the semantic proximity of documents with respect to one another. To assess the quality of this translation step, we develop a "semantic topology preservation test" that relies on estimating the extent to which document-to-document distances have been preserved during translation. We then conduct an LDA topic-model analysis over the entire corpus of translated and English original texts, and compare it to a topic-model done over the English original texts only. We thereby identify the specific contribution of the translated texts. These studies reveal a more complete picture of main topics that can found in the philosophy of science literature, especially during the early days of the discipline when numerous articles were published in languages other than English.
OI Lareau, Francis/0000-0002-0352-5246
SN 0039-7857
EI 1573-0964
PD MAY 31
PY 2022
VL 200
IS 3
AR 242
DI 10.1007/s11229-022-03722-x
UT WOS:000804017100001
ER

PT C
AU Sherborne, T
   Lapata, M
AF Sherborne, Tom
   Lapata, Mirella
GP Assoc Computat Linguist
TI Zero-Shot Cross-lingual Semantic Parsing
SO PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS)
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB Recent work in cross-lingual semantic parsing has successfully applied machine translation to localize parsers to new languages. However, these advances assume access to high-quality machine translation systems and word alignment tools. We remove these assumptions and study cross-lingual semantic parsing as a zero-shot problem, without parallel data (i.e., utterance-logical form pairs) for new languages. We propose a multi-task encoder-decoder model to transfer parsing knowledge to additional languages using only English-logical form paired data and in-domain natural language corpora in each new language. Our model encourages language-agnostic encodings by jointly optimizing for logical-form generation with auxiliary objectives designed for cross-lingual latent representation alignment. Our parser performs significantly above translation-based baselines and, in some cases, competes with the supervised upper-bound.(1)
BN 978-1-955917-21-6
PY 2022
BP 4134
EP 4153
UT WOS:000828702304016
ER

PT J
AU Espla-Gomis, M
   Sanchez-Martinez, F
   Forcada, ML
AF Espla-Gomis, Miquel
   Sanchez-Martinez, Felipe
   Forcada, Mikel L.
TI Predicting insertion positions in word-level machine translation quality
   estimation
SO APPLIED SOFT COMPUTING
AB Word-level machine translation (MT) quality estimation (QE) is usually formulated as the task of automatically identifying which words need to be edited (either deleted or replaced) in a translation T produced by an MT system. The advantage of estimating MT quality at the word level is that this information can be used to guide post-editors since it enables the identification of the specific words in T that need to be edited in order to ease their work. However, word-level MT QE, as defined in the current literature, has an obvious limitation: it does not identify the positions in T in which missing words need to be inserted. To deal with this limitation, we propose a method which identifies both word deletions and insertion positions in T. This is, to the best of our knowledge, the first approach allowing the identification of insertion positions in word-levelMTQE. The method proposed can use any source of bilingual information-such as MT, dictionaries, or phrase-level translation memories - to extract features that are then used by a neural network to produce a prediction for both words and insertion positions (gaps between words) in the translation T. In this paper, several feature sets and neural network architectures are explored and evaluated on publicly-available datasets used in previous evaluation campaigns for word-levelMTQE. The results confirm the feasibility of the proposed approach, as well as the usefulness of sharing information between the two prediction tasks in order to obtain more reliable quality estimations. (C) 2018 Elsevier B.V. All rights reserved.
RI Forcada, Mikel/ABG-9539-2020; Sánchez-Martínez, Felipe/G-9689-2016;
   Esplà-Gomis, Miquel/ABF-8816-2021
OI Sánchez-Martínez, Felipe/0000-0002-2295-2630; Esplà-Gomis,
   Miquel/0000-0002-2682-066X; FORCADA ZUBIZARRETA, Mikel
   L./0000-0003-0843-6442
SN 1568-4946
EI 1872-9681
PD MAR
PY 2019
VL 76
BP 174
EP 192
DI 10.1016/j.asoc.2018.11.036
UT WOS:000461145200013
ER

PT J
AU Freeman, J
AF Freeman, Justin
TI Content enhancement with augmented reality and machine learning
SO JOURNAL OF SOUTHERN HEMISPHERE EARTH SYSTEMS SCIENCE
AB Content enhancement of real-world environments is demonstrated through the combination of machine learning methods with augmented reality displays. Advances in machine learning methods and neural network architectures have facilitated fast and accurate object and image detection, recognition and classification, as well as providing machine translation, natural language processing and neural network approaches for environmental forecasting and prediction. These methods equip computers with a means of interpreting the natural environment. Augmented reality is the embedding of computer-generated assets within the real-world environment. Here I demonstrate, through the development of four sample mobile applications, how machine learning and augmented reality may be combined to create localised, context aware and user-centric environmental information delivery channels. The sample mobile applications demonstrate augmented reality content enhancement of static real-world objects to deliver additional environmental and contextual information, language translation to facilitate accessibility of forecast information and a location aware rain event augmented reality notification application that leverages a nowcasting neural network.
EI 2206-5865
PY 2020
VL 70
IS 1
BP 143
EP 150
DI 10.1071/ES19046
EA OCT 2020
UT WOS:000598036000001
ER

PT C
AU Sogaard, A
   Ruder, S
   Vulic, I
AF Sogaard, Anders
   Ruder, Sebastian
   Vulic, Ivan
BE Gurevych, I
   Miyao, Y
TI On the Limitations of Unsupervised Bilingual Dictionary Induction
SO PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL), VOL 1
CT 56th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 15-20, 2018
CL Melbourne, AUSTRALIA
SP Assoc Computat Linguist, Google, ByteDance, Samsung Res, Apple, Facebook, Amazon, Baidu, Recruit Inst Technol, Tencent, IBM Res AI, Microsoft, Naver, Line, CVTE, Digital Hlth crc, Nuance, Huawei, Elsevier, Duolingo, ISI NLP, Australian Govt, Dept Def, Sci & Technol
AB Unsupervised machine translation-i.e., not assuming any cross-lingual supervision signal, whether a dictionary, translations, or comparable corpora-seems impossible, but nevertheless, Lample et al. (2018a) recently proposed a fully unsupervised machine translation (MT) model. The model relies heavily on an adversarial, unsupervised alignment of word embedding spaces for bilingual dictionary induction (Conneau et al., 2018), which we examine here. Our results identify the limitations of current unsupervised MT: unsupervised bilingual dictionary induction performs much worse on morphologically rich languages that are not dependent marking, when monolingual corpora from different domains or different embedding algorithms are used. We show that a simple trick, exploiting a weak supervision signal from identical words, enables more robust induction, and establish a near-perfect correlation between unsupervised bilingual dictionary induction performance and a previously unexplored graph similarity metric.
BN 978-1-948087-32-2
PY 2018
BP 778
EP 788
UT WOS:000493904300072
ER

PT J
AU Ayala, BR
   Knudson, R
   Chen, JP
   Cao, GH
   Wang, XY
AF Ayala, Brenda Reyes
   Knudson, Ryan
   Chen, Jiangping
   Cao, Gaohui
   Wang, Xinyue
TI Metadata Records Machine Translation Combining Multi Engine Outputs With
   Limited Parallel Data
SO JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY
AB One way to facilitate Multilingual Information Access (MLIA) for digital libraries is to generate multilingual metadata records by applying Machine Translation (MT) techniques. Current online MT services are available and affordable, but are not always effective for creating multilingual metadata records. In this study, we implemented 3 different MT strategies and evaluated their performance when translating English metadata records to Chinese and Spanish. These strategies included combining MT results from 3 online MT systems (Google, Bing, and Yahoo!) with and without additional linguistic resources, such as manually-generated parallel corpora, and metadata records in the two target languages obtained from international partners. The open-source statistical MT platform Moses was applied to design and implement the three translation strategies. Human evaluation of the MT results using adequacy and fluency demonstrated that two of the strategies produced higher quality translations than individual online MT systems for both languages. Especially, adding small, manually-generated parallel corpora of metadata records significantly improved translation performance. Our study suggested an effective and efficient MT approach for providing multilingual services for digital collections.
RI Wang, Xin/GYU-1129-2022
OI Chen, Jiangping/0000-0002-7016-4583
SN 2330-1635
EI 2330-1643
PD JAN
PY 2018
VL 69
IS 1
BP 47
EP 59
DI 10.1002/asi.23925
UT WOS:000418157900005
ER

PT J
AU Ortega, JE
   Mamani, RC
   Cho, K
AF Ortega, John E.
   Mamani, Richard Castro
   Cho, Kyunghyun
TI Neural machine translation with a polysynthetic low resource language
SO MACHINE TRANSLATION
AB Low-resource languages (LRL) with complex morphology are known to be more difficult to translate in an automatic way. Some LRLs are particularly more difficult to translate than others due to the lack of research interest or collaboration. In this article, we experiment with a specific LRL, Quechua, that is spoken by millions of people in South America yet has not undertaken a neural approach for translation until now. We improve the latest published results with baseline BLEU scores using the state-of-the-art recurrent neural network approaches for translation. Additionally, we experiment with several morphological segmentation techniques and introduce a new one in order to decompose the language's suffix-based morphemes. We extend our work to other high-resource languages (HRL) like Finnish and Spanish to show that Quechua, for qualitative purposes, can be considered compatible with and translatable into other major European languages with measurements comparable to the state-of-the-art HRLs at this time. We finalize our work by making our best two Quechua-Spanish translation engines available on-line.
OI Ortega, John Evan/0000-0002-2328-3205
SN 0922-6567
EI 1573-0573
PD DEC
PY 2020
VL 34
IS 4
SI SI
BP 325
EP 346
DI 10.1007/s10590-020-09255-9
EA FEB 2021
UT WOS:000614703800001
ER

PT C
AU Herbig, N
   Pal, S
   Duwel, T
   Meladaki, K
   Monshizadeh, M
   Hnatovskiy, V
   Kruger, A
   van Genabith, J
AF Herbig, Nico
   Pal, Santanu
   Duewel, Tim
   Meladaki, Kalliopi
   Monshizadeh, Mahsa
   Hnatovskiy, Vladislav
   Krueger, Antonio
   van Genabith, Josef
GP Assoc Computat Linguist
TI MMPE: A Multi-Modal Interface Using Handwriting, Touch Reordering, and
   Speech Commands for Post-Editing Machine Translation
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020): SYSTEM DEMONSTRATIONS
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB The shift from traditional translation to post-editing (PE) of machine-translated (MT) text can save time and reduce errors, but it also affects the design of translation interfaces, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Since this paradigm shift offers potential for modalities other than mouse and keyboard, we present MMPE, the first prototype to combine traditional input modes with pen, touch, and speech modalities for PE of MT. Users can directly cross out or hand-write new text, drag and drop words for reordering, or use spoken commands to update the text in place. All text manipulations are logged in an easily interpretable format to simplify subsequent translation process research. The results of an evaluation with professional translators suggest that pen and touch interaction are suitable for deletion and reordering tasks, while speech and multi-modal combinations of select & speech are considered suitable for replacements and insertions. Overall, experiment participants were enthusiastic about the new modalities and saw them as useful extensions to mouse & keyboard, but not as a complete substitute.
RI Pal, Santanu/AAB-4161-2021
OI Pal, Santanu/0000-0003-3079-6903
BN 978-1-952148-04-0
PY 2020
BP 327
EP 334
UT WOS:000563368700037
ER

PT J
AU Li, JZ
AF Li, Junzheng
TI 撤稿声明: 被撤回的出版物: Critical thinking of a translator: Expanding the practice
   of using and editing machine translation (Retraction of Vol 46,
   10.1016/J.TSC.2022.101165, 2022) (Retracted article. See vol. 46, 2022)
SO THINKING SKILLS AND CREATIVITY
SN 1871-1871
EI 1878-0423
PD DEC
PY 2022
VL 46
AR 101165
DI 10.1016/j.tsc.2022.101165
UT WOS:000928121900037
ER

PT J
AU Su, JS
   Song, ZQ
   Lu, YJ
   Xu, M
   Wu, CX
   Chen, YD
AF Su, Jinsong
   Song, Zhenqiao
   Lu, Yaojie
   Xu, Mu
   Wu, Changxing
   Chen, Yidong
TI Exploring Implicit Semantic Constraints for Bilingual Word Embeddings
SO NEURAL PROCESSING LETTERS
AB Bilingual word embeddings (BWEs) have proven to be useful in many cross-lingual natural language processing tasks. Previous studies often require bilingual texts or dictionaries that are scarce resources. As a result, in these studies, the exploited explicit semantic information, such as monolingual word co-occurrences and cross-lingual semantic equivalences, is often insufficient for BWE learning, leading to the limitation of learned word representations. To overcome this problem, in this paper, we study how to exploit implicit semantic constraints for better BWEs. Concretely, we first discover implicit monolingual word-level semantic equivalences by pivoting their translations in the other language. Then, we perform BWE learning under various semantic constraints. Experimental results on machine translation and cross-lingual document classification demonstrate the effectiveness of our model.
OI Chen, Yidong/0000-0002-0243-7228
SN 1370-4621
EI 1573-773X
PD OCT
PY 2018
VL 48
IS 2
SI SI
BP 1073
EP 1088
DI 10.1007/s11063-017-9762-8
UT WOS:000446501500021
ER

PT J
AU Zhou, D
   Truran, M
   Brailsford, T
   Wade, V
   Ashman, H
AF Zhou, Dong
   Truran, Mark
   Brailsford, Tim
   Wade, Vincent
   Ashman, Helen
TI Translation Techniques in Cross-Language Information Retrieval
SO ACM COMPUTING SURVEYS
AB Cross-language information retrieval (CLIR) is an active sub-domain of information retrieval (IR). Like IR, CLIR is centered on the search for documents and for information contained within those documents. Unlike IR, CLIR must reconcile queries and documents that are written in different languages. The usual solution to this mismatch involves translating the query and/or the documents before performing the search. Translation is therefore a pivotal activity for CLIR engines. Over the last 15 years, the CLIR community has developed a wide range of techniques and models supporting free text translation. This article presents an overview of those techniques, with a special emphasis on recent developments.
OI Ashman, Helen/0000-0003-3587-4608; Brailsford, Tim/0000-0002-0816-2093
SN 0360-0300
EI 1557-7341
PD NOV
PY 2012
VL 45
IS 1
AR 1
DI 10.1145/2379776.2379777
UT WOS:000312211700001
ER

PT C
AU Muller, M
   Sennrich, R
AF Mueller, Mathias
   Sennrich, Rico
GP Assoc Computat Linguist
TI Understanding the Properties of Minimum Bayes Risk Decoding in Neural
   Machine Translation
SO 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND
   THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING,
   VOL 1 (ACL-IJCNLP 2021)
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB Neural Machine Translation (NMT) currently exhibits biases such as producing translations that are too short and overgenerating frequent words, and shows poor robustness to copy noise in training data or domain shift. Recent work has tied these shortcomings to beam search - the de facto standard inference algorithm in NMT - and Eikema and Aziz (2020) propose to use Minimum Bayes Risk (MBR) decoding on unbiased samples instead.
   In this paper, we empirically investigate the properties of MBR decoding on a number of previously reported biases and failure cases of beam search. We find that MBR still exhibits a length and token frequency bias, owing to the MT metrics used as utility functions, but that MBR also increases robustness against copy noise in the training data and domain shift.(1)
BN 978-1-954085-52-7
PY 2021
BP 259
EP 272
UT WOS:000698663100022
ER

PT J
AU Walter, M
   Alizadeh, S
   Jamalabadi, H
   Lueken, U
   Dannlowski, U
   Walter, H
   Olbrich, S
   Colic, L
   Kambeitz, J
   Koutsouleris, N
   Hahn, T
   Dwyer, DB
AF Walter, Martin
   Alizadeh, Sarah
   Jamalabadi, Hamidreza
   Lueken, Ulrike
   Dannlowski, Udo
   Walter, Henrik
   Olbrich, Sebastian
   Colic, Lejla
   Kambeitz, Joseph
   Koutsouleris, Nikolaos
   Hahn, Tim
   Dwyer, Dominic B.
TI Translational machine learning for psychiatric neuroimaging
SO PROGRESS IN NEURO-PSYCHOPHARMACOLOGY & BIOLOGICAL PSYCHIATRY
AB Despite its initial promise, neuroimaging has not been widely translated into clinical psychiatry to assist in the prediction of diagnoses, prognoses, and optimal therapeutic strategies. Machine learning approaches may enhance the translational potential of neuroimaging because they specifically focus on overcoming biases by optimizing the generalizability of pipelines that measure complex brain patterns to predict targets at a single-subject level. This article introduces some fundamentals of a translational machine learning approach before selectively reviewing literature to-date. Promising initial results are then balanced by the description of limitations that should be considered in order to interpret existing research and maximize the possibility of future translation. Future directions are then presented in order to inspire further research and progress the field towards clinical translation.
RI Koutsouleris, Nikolaos/AAJ-7428-2020; Dwyer, Dominic/Z-1225-2018;
   Walter, Henrik/O-2612-2013; Kambeitz, Joseph/AAR-7087-2021
OI Dwyer, Dominic/0000-0003-3949-5867; Kambeitz,
   Joseph/0000-0002-8988-3959; Colic, Lejla/0000-0002-8809-4034; Walter,
   Henrik/0000-0002-9403-6121; Olbrich, Sebastian/0000-0001-5557-4878
SN 0278-5846
EI 1878-4216
PD APR 20
PY 2019
VL 91
SI SI
BP 113
EP 121
DI 10.1016/j.pnpbp.2018.09.014
UT WOS:000461161200013
PM 30290208
ER

PT C
AU Xiao, FS
   Li, JT
   Zhao, H
   Wang, R
   Chen, KH
AF Xiao, Fengshun
   Li, Jiangtong
   Zhao, Hai
   Wang, Rui
   Chen, Kehai
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Lattice-Based Transformer Encoder for Neural Machine Translation
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB Neural machine translation (NMT) takes deterministic sequences for source representations. However, either word- level or subword-level segmentations have multiple choices to split a source sequence with different word segmentors or different subword vocabulary sizes. We hypothesize that the diversity in segmentations may affect the NMT performance. To integrate different segmentations with the state-of-the-art NMT model, Transformer, we propose lattice-based encoders to explore effective word or subword representation in an automatic way during training We propose two methods: 1) lattice positional encoding and 2) lattice-aware self-attention. These two methods can be used together and show complementary to each other to further improve translation performance. Experiment results show superiorities of lattice-based encoders in word-level and subword-level representations over conventional Transformer encoder.
RI Wang, Rui/AAI-1990-2020; Chen, Kehai/ABF-1874-2020
OI Wang, Rui/0000-0001-8007-2503; 
BN 978-1-950737-48-2
PY 2019
BP 3090
EP 3097
UT WOS:000493046105011
ER

PT C
AU Lin, TY
   Shah, AH
AF Lin, Tsau-Young
   Shah, Asmi H.
GP IEEE
BE Lin, J
   Hu, XH
   Chang, W
   Nambiar, R
   Aggarwal, C
   Cercone, N
   Honavar, V
   Huan, J
   Mobasher, B
   Pyne, S
TI Stochastic Finite Automata for the Translation of DNA to Protein
SO 2014 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
SE IEEE International Conference on Big Data
CT IEEE International Conference on Big Data
CY OCT 27-30, 2014
CL Washington, DC
SP IEEE, IEEE Comp Soc, ELSEVIER, Natl Sci Fdn, CISCO, CCF
AB The use of Statistical Finite Automata (SFA) has been explored in the field of understanding the DNA sequences; many focus on local patterns, namely partial representations of DNA sequences. In this paper, we focus on global and complete representations to understand the patterns in whole DNA sequences. Obviously, DNA sequences are not random. Based on Kolmogorov complexity theory, there should be some simple Turing machines that write out such sequences; here simple means the complexity of the Turing machine is simpler than the data. The primary goal of this paper is to approximate such simple Turing machines by SFA. We use SFA, via ALERGIA algorithm (in the light granular computing), to capture and analyze the translation process (DNA to protein) based on amino acids' chemical property viz., polarity. This, in turn, enables the understanding of interspecies DNA comparisons and the creation of phylogeny - the 'tree of life'.
SN 2639-1589
BN 978-1-4799-5666-1
PY 2014
BP 1060
EP 1067
UT WOS:000380462900137
ER

PT C
AU Braun, S
   Vasilyev, O
   Iskender, N
   Bohannon, J
AF Braun, Spencer
   Vasilyev, Oleg
   Iskender, Neslihan
   Bohannon, John
GP ASSOC COMPUTAT LINGUIST
TI Does Summary Evaluation Survive Translation to Other Languages?
SO NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE
   ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES
CT Conference of the
   North-American-Chapter-of-the-Association-for-Computational-Linguistics
   (NAAACL) - Human Language Technologies
CY JUL 10-15, 2022
CL Seattle, WA
SP Assoc Computat Linguist, N Amer Chapter, Amazon Sci, Bloomberg Engn, Google Res, LivepersoMetan, ByteDance, KENSH, Grammarly, Megagon Labs, Microsoft, Reveal Brainspace, Cohere, GResearch, Relativity, Servicenow, ASAPP, Duolingo, Adobe, Linkedin, Babelscape, Rakuten Inst Technol, UC Santa Cruz, Baskin Engn, Nat Language Proc, NSF, ETS, OpenAI, TIAA, Two Sigma, Mag Data
AB The creation of a quality summarization dataset is an expensive, time-consuming effort, requiring the production and evaluation of summaries by both trained humans and machines. The returns to such an effort would increase significantly if the dataset could be used in additional languages without repeating human annotations. To investigate how much we can trust machine translation of summarization datasets, we translate the English SummEval dataset to seven languages and compare performances across automatic evaluation measures. We explore equivalence testing as the appropriate statistical paradigm for evaluating correlations between human and automated scoring of summaries. We also consider the effect of translation on the relative performance between measures. We find some potential for dataset reuse in languages similar to the source and along particular dimensions of summary quality.
BN 978-1-955917-71-1
PY 2022
BP 2425
EP 2435
UT WOS:000859869502035
ER

PT J
AU Durola, F
   Sauvage, JP
AF Durola, Fabien
   Sauvage, Jean-Pierre
TI Fast electrochemically induced translation of the ring in a
   copper-complexed [2]rotaxane: The biisoquinoline effect
SO ANGEWANDTE CHEMIE-INTERNATIONAL EDITION
RI Durola, Fabien/A-5978-2013
OI Durola, Fabien/0000-0002-9720-4848
SN 1433-7851
EI 1521-3773
PY 2007
VL 46
IS 19
BP 3537
EP 3540
DI 10.1002/anie.200604815
UT WOS:000246538200029
PM 17397018
ER

PT C
AU Athanasiou, V
   Maragoudakis, M
AF Athanasiou, Vasileios
   Maragoudakis, Manolis
BE Iliadis, L
   Maglogiannis, I
TI Dealing with High Dimensional Sentiment Data Using Gradient Boosting
   Machines
SO ARTIFICIAL INTELLIGENCE APPLICATIONS AND INNOVATIONS, AIAI 2016
SE IFIP Advances in Information and Communication Technology
CT 12th IFIP WG 12.5 International Conference on Artificial Intelligence
   Applications and Innovations (AIAI)
CY SEP 16-18, 2016
CL Thessaloniki, GREECE
SP Int Federat Informat Proc Working Grp 12 5
AB One of the most common classification tasks that applies on textual information is sentiment analysis, i.e. the prediction of the sentiment of a given document. With the vast use of social media and internet applications such as e-commerce, e-tourism and e-government, numerous comments and opinions are broadcasted per day, thus an automatic way of analyzing them is of great importance. The present paper focuses on sentiment analysis for Greek texts, obtained from Web 2.0 platforms. Greek is a language that lacks an in-depth availability of natural language processing tools in the sense that most of them are not publicly available. The novelty of the article is that instead of utilizing preprocessing tools such as Part-of-Speech taggers, text stemmers and polar-word lexica, it incorporates the translation of the Greek token as provided by the Google Translator (R) API. Since automatic translation of Greek sentences often results in poor translations where the meaning of the original sentence is severely deteriorated, the translation of each token individually is almost 100 % correct. However, taking the translation of every Greek token poses a significant issue to the outcome of the classification process for practically any classifier, therefore, we introduce the use of a powerful ensemble algorithm that is highly customizable to the particular needs of the application, such as being learned with respect to different loss functions and thus dealing with a large number of dimensions. This algorithm is called Gradient Boosting Machines and experimental results support our claim that it surpasses other, well-known machine learning techniques with a significant improvement for our task.
RI Maragoudakis, Manolis/AAS-8112-2020
OI Maragoudakis, Manolis/0000-0001-7701-0141
SN 1868-4238
EI 1868-422X
BN 978-3-319-44944-9; 978-3-319-44943-2
PY 2016
VL 475
BP 481
EP 489
DI 10.1007/978-3-319-44944-9_42
UT WOS:000392413700042
ER

PT C
AU Ishiwatari, S
   Yoshinaga, N
   Toyoda, M
   Kitsuregawa, M
AF Ishiwatari, Shonosuke
   Yoshinaga, Naoki
   Toyoda, Masashi
   Kitsuregawa, Masaru
BE Gelbukh, A
TI Instant Translation Model Adaptation by Translating Unseen Words in
   Continuous Vector Space
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING, (CICLING
   2016), PT II
SE Lecture Notes in Computer Science
CT 17th International Conference on Intelligent Text Processing and
   Computational Linguistics (CICLing)
CY APR 03-09, 2016
CL Mevlana Univ, Konya, TURKEY
HO Mevlana Univ
AB In statistical machine translation (SMT), differences between domains of training and test data result in poor translations. Although there have been many studies on domain adaptation of language models and translation models, most require supervised in-domain language resources such as parallel corpora for training and tuning the models. The necessity of supervised data has made such methods difficult to adapt to practical SMT systems. We thus propose a novel method that adapts translation models without in-domain parallel corpora. Our method infers translation candidates of unseen words by nearest-neighbor search after projecting their vector-based semantic representations to the semantic space of the target language. In our experiment of out-of-domain translation from Japanese to English, our method improved bleu score by 0.5-1.5.
SN 0302-9743
EI 1611-3349
BN 978-3-319-75487-1; 978-3-319-75486-4
PY 2018
VL 9624
BP 51
EP 62
DI 10.1007/978-3-319-75487-1_5
PN II
UT WOS:000540377700005
ER

PT J
AU Shailesh, K
   Sumit, G
   Vikram, K
   Sumita, K
   Kothari, SL
AF Shailesh, Kumar
   Sumit, Govil
   Vikram, Kumar
   Sumita, Kachhawah
   Kothari, S. L.
TI Classification of 5 ' and 3 ' Untranslated Regions in Human
   transcriptome by Machine Learning methods
SO RESEARCH JOURNAL OF BIOTECHNOLOGY
AB Untranslated regions (UTRs) are non-coding part present upstream and downstream of translation unit of mRNA and contribute to regulation of translational process, gene composition and expression. Here, 5' and 3' UTRs are classified by various machine learning methods on genomic features contributing to UTRs composition. Supervised Machine learning based classification algorithms such as Random forest, Logistic Regression and Naive Bayesian are used to classify UTRs. Merged and resampled dataset were used for training of classifiers. Tree based method like Random forest was found best among all methods for classification of UTRs with average sensitivity on merged and resampled dataset 0.865 and 0.968 respectively
   The key finding is that 3 'UTRs composition is different from 5' UTRs and can be classified by every classifier with variable sensitivity and specificity. These models can be used to identify the diseased causing UTRs on its features.
RI Kumar, Vikram/N-5460-2015; KUMAR, SHAILESH/B-8384-2018; Kothari, Shanker
   Lal/I-3021-2018
OI Kumar, Vikram/0000-0002-9994-8904; KUMAR, SHAILESH/0000-0002-1394-4815;
   Kothari, Shanker Lal/0000-0002-0378-4897
SN 2278-4535
PD DEC
PY 2018
VL 13
IS 12
BP 47
EP 53
UT WOS:000452132000008
ER

PT C
AU Wang, XY
   Pham, H
   Dai, ZH
   Neubig, G
AF Wang, Xinyi
   Pham, Hieu
   Dai, Zihang
   Neubig, Graham
GP Assoc Computat Linguist
TI SwitchOut: an Efficient Data Augmentation Algorithm for Neural Machine
   Translation
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB In this work, we examine methods for data augmentation for text-based tasks such as neural machine translation (NMT). We formulate the design of a data augmentation policy with desirable properties as an optimization problem, and derive a generic analytic solution. This solution not only subsumes some existing augmentation schemes, but also leads to an extremely simple data augmentation strategy for NMT: randomly replacing words in both the source sentence and the target sentence with other random words from their corresponding vocabularies. We name this method SwitchOut. Experiments on three translation datasets of different scales show that SwitchOut yields consistent improvements of about 0.5 BLEU, achieving better or comparable performances to strong alternatives such as word dropout (Sennrich et al., 2016a). Code to implement this method is included in the appendix.
BN 978-1-948087-84-1
PY 2018
BP 856
EP 861
UT WOS:000865723400100
ER

PT C
AU He, TY
   Tan, X
   Xia, YC
   He, D
   Qin, T
   Chen, ZB
   Liu, TY
AF He, Tianyu
   Tan, Xu
   Xia, Yingce
   He, Di
   Qin, Tao
   Chen, Zhibo
   Liu, Tie-Yan
BE Bengio, S
   Wallach, H
   Larochelle, H
   Grauman, K
   CesaBianchi, N
   Garnett, R
TI Layer-Wise Coordination between Encoder and Decoder for Neural Machine
   Translation
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 31 (NIPS 2018)
SE Advances in Neural Information Processing Systems
CT 32nd Conference on Neural Information Processing Systems (NIPS)
CY DEC 02-08, 2018
CL Montreal, CANADA
AB Neural Machine Translation (NMT) has achieved remarkable progress with the quick evolvement of model structures. In this paper, we propose the concept of layer-wise coordination for NMT, which explicitly coordinates the learning of hidden representations of the encoder and decoder together layer by layer, gradually from low level to high level. Specifically, we design a layer-wise attention and mixed attention mechanism, and further share the parameters of each layer between the encoder and decoder to regularize and coordinate the learning. Experiments show that combined with the state-of-the-art Transformer model, layer-wise coordination achieves improvements on three IWSLT and two WMT translation tasks. More specifically, our method achieves 34.43 and 29.01 BLEU score on WMT16 English-Romanian and WMT14 English-German tasks, outperforming the Transformer baseline.
OI Qin, Tao/0000-0002-9095-0776
SN 1049-5258
PY 2018
VL 31
UT WOS:000461852002049
ER

PT J
AU Zhang, JY
   Tian, Y
   Mao, JN
   Han, M
   Wen, F
   Guo, C
   Gao, ZH
   Matsumoto, T
AF Zhang, Jinyi
   Tian, Ye
   Mao, Jiannan
   Han, Mei
   Wen, Feng
   Guo, Cong
   Gao, Zhonghui
   Matsumoto, Tadahiro
TI WCC-JC 2.0: A Web-Crawled and Manually Aligned Parallel Corpus for
   Japanese-Chinese Neural Machine Translation
SO ELECTRONICS
AB Movie and TV subtitles are frequently employed in natural language processing (NLP) applications, but there are limited Japanese-Chinese bilingual corpora accessible as a dataset to train neural machine translation (NMT) models. In our previous study, we effectively constructed a corpus of a considerable size containing bilingual text data in both Japanese and Chinese by collecting subtitle text data from websites that host movies and television series. The unsatisfactory translation performance of the initial corpus, Web-Crawled Corpus of Japanese and Chinese (WCC-JC 1.0), was predominantly caused by the limited number of sentence pairs. To address this shortcoming, we thoroughly analyzed the issues associated with the construction of WCC-JC 1.0 and constructed the WCC-JC 2.0 corpus by first collecting subtitle data from movie and TV series websites. Then, we manually aligned a large number of high-quality sentence pairs. Our efforts resulted in a new corpus that includes about 1.4 million sentence pairs, an 87% increase compared with WCC-JC 1.0. As a result, WCC-JC 2.0 is now among the largest publicly available Japanese-Chinese bilingual corpora in the world. To assess the performance of WCC-JC 2.0, we calculated the BLEU scores relative to other comparative corpora and performed manual evaluations of the translation results generated by translation models trained on WCC-JC 2.0. We provide WCC-JC 2.0 as a free download for research purposes only.
EI 2079-9292
PD MAR
PY 2023
VL 12
IS 5
AR 1140
DI 10.3390/electronics12051140
UT WOS:000947635400001
ER

PT C
AU Papavassiliou, V
   Prokopidis, P
   Piperidis, S
AF Papavassiliou, Vassilis
   Prokopidis, Prokopis
   Piperidis, Stelios
BA Declerck, T
BF Declerck, T
BE Calzolari, N
   Choukri, K
   Cieri, C
   Hasida, K
   Isahara, H
   Maegaard, B
   Mariani, J
   Moreno, A
   Odijk, J
   Piperidis, S
   Tokunaga, T
   Goggi, S
   Mazo, H
TI Discovering Parallel Language Resources for Training MT Engines
SO PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE
   RESOURCES AND EVALUATION (LREC 2018)
CT 11th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 07-12, 2018
CL Miyazaki, JAPAN
AB Web crawling is an efficient way for compiling the monolingual, parallel and/or domain-specific corpora needed for machine translation and other HLT applications. These corpora can be automatically processed to generate second order or synthesized derivative resources, including bilingual (general or domain-specific) lexica and terminology lists. In this submission, we discuss the architecture and use of the ILSP Focused Crawler (ILSP-FC), a system developed by researchers of the ILSP/Athena RIC for the acquisition of such resources, and currently being used through the European Language Resource Coordination effort. ELRC aims to identify and gather language and translation data relevant to public services and governmental institutions across 30 European countries participating in the Connecting Europe Facility (CEF).
BN 979-10-95546-00-9
PY 2018
BP 3795
EP 3798
UT WOS:000725545003138
ER

PT C
AU Codina-Filba, J
   Cambara, G
   Peiro-Lilja, A
   Grivolla, J
   Carlini, R
   Farrus, M
AF Codina-Filba, Joan
   Cambara, Guillermo
   Peiro-Lilja, Alex
   Grivolla, Jens
   Carlini, Roberto
   Farrus, Mireia
GP Int Speech Commun Assoc
TI The INGENIOUS Multilingual Operations App
SO INTERSPEECH 2021
SE Interspeech
CT Interspeech Conference
CY AUG 30-SEP 03, 2021
CL Brno, CZECH REPUBLIC
AB This paper presents the integration of a speech-to-speech translation service into a Telegram bot as a part of the EU funded INGENIOUS project. The bot is thought as a multilingual communication channel where First Responders talk in their own language and receive other's messages in English. The Speechto-Speech translation system is currently being adapted to the emergency domains, so it will correctly deal with emergency codes and geographical data.
SN 2308-457X
PY 2021
BP 3315
EP 3316
UT WOS:000841879503083
ER

PT J
AU Bilous, O
   Mishchenko, A
   Datska, T
   Ivanenko, N
   Kit, L
   Piankovska, I
   Vereshchak, Y
AF Bilous, O.
   Mishchenko, A.
   Datska, T.
   Ivanenko, N.
   Kit, L.
   Piankovska, I
   Vereshchak, Y.
TI Modern Linguistic Technologies: Strategy for Teaching Translation
   Studies
SO RUPKATHA JOURNAL ON INTERDISCIPLINARY STUDIES IN HUMANITIES
AB How often students use IT resources is a key factor in the acquisition of skills associated to the new technologies. Strategies aimed at increasing student autonomy need to be developed and should offer resources that encourage them to make use of computing tools in class hours. The analysis of the modern linguistic technologies, concerning intellectual language processing necessary for the creation and function of the highly effective technologies of knowledge operation was considered in the paper under consideration. Computerization of the information sphere has triggered extensive search for solving the problem of the use of natural language mechanisms in automated systems of various types. One of them was creating Controlled languages based on a set of features which made machine translation more refined. Triggered by the economic demand, they are not artificial languages like Esperanto, but natural simplified languages, in terms of vocabulary, grammatical and syntactic structures. More than ever, the tasks of modern computer linguistics behold creating software for natural language processing, information retrieval in large data sets, support of technical authors in the process of creating professional texts and users of computer technology, hence creating new translation tools. Such powerful linguistic resources as corpora of texts, terminology databases and ontologies may facilitate more efficient use of modern multilingual information technology. Creating and improving all methods considered will help make the job of a translator more efficient. One of the programs, CLA Tdoes not aim at producing machine translation, but allows technical editors to create flawless, sequential professional texts through integrated punctuation and spelling modules. Other programs under consideration are to be implemented in Ukrainian translation departments. Moreover, the databases considered in the paper enable studying of the dynamics of the linguistic system and developing areas of applied research such as terminography, terminology, automated data processing etc. Effective cooperation of developers, translators and declarative institutes in the creation of innovative linguistic technologies will promote further development of translation and applied linguistics.
RI Vereshchak, Yulia/HPE-5151-2023; Piankovska, Iryna/ACV-3481-2022;
   Datska, Tetiana/HPF-3201-2023; Bilous, Oleksandr/ADJ-2676-2022
OI Piankovska, Iryna/0000-0002-0818-644X; Bilous,
   Oleksandr/0000-0002-9574-4402
SN 0975-2935
PY 2021
VL 13
IS 4
DI 10.21659/rupkatha.v13n4.65
UT WOS:000750668100017
ER

PT J
AU Le, NT
   Sadat, F
AF Ngoc Tan Le
   Sadat, Fatiha
TI Towards a Low-Resource Neural Machine Translation for Indigenous
   Languages in Canada
SO TRAITEMENT AUTOMATIQUE DES LANGUES
AB The Natural Language Processing research community is increasingly interested in less-resourced languages and linguistic diversity through technology. Translation to and from low-resource polysynthetic languages has, in particular, always faced numerous challenges, such as morphological complexity, dialectal variations, noisy data due to different spellings and low-resource scenarios. Moreover, the morphological segmentation for indigenous polysynthetic languages is particularly challenging with multiple individual morphemes by word and several meanings per morpheme. The present research focuses on Inuktitut and Inuinnaqtun, indigenous polysynthetic languages spoken in Northern Canada. We then build a morphological segmenter and a NMT system for these indigenous languages. Our proposed NMT model outperformed the state-of-the-art in the context of low-resource Inuktitut-English Neural Machine Translation.
SN 1248-9433
EI 1965-0906
PY 2021
VL 62
IS 3
BP 39
EP 63
UT WOS:000773358000003
ER

PT C
AU Cheok, SM
   Hoi, LM
   Tang, SK
   Tse, R
AF Cheok, Sai Man
   Hoi, Lap Man
   Tang, Su-Kit
   Tse, Rita
BE Bastieri, D
   Wills, G
   Kacsuk, P
   Chang, V
TI Constructing High Quality Bilingual Corpus using Parallel Data from the
   Web
SO PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INTERNET OF THINGS,
   BIG DATA AND SECURITY (IOTBDS)
CT 7th International Conference on Internet of Things, Big Data and
   Security (IoTBDS)
CY APR 22-24, 2022
CL ELECTR NETWORK
SP INSTICC
AB Natural language machine translation system requires a high-quality bilingual corpus to support its efficient translation operation at high accuracy rate. In this paper, we propose a bilingual corpus construction method using parallel data from the Web. It acts as a stimulus to significantly speed up the construction. In our proposal, there are 4 phases. Parallel data is first pre-processed and refined into three sets of data for training the CNN model. Using the well-trained model, future parallel data can be selected, classified and added to the bilingual corpus. The training result showed that the test accuracy reached 98.46%. Furthermore, the result on precision, recall and f1-score is greater than 0.9, which outperforms RNN and LSTM models.
BN 978-989-758-564-7
PY 2022
BP 127
EP 132
DI 10.5220/0010997000003194
UT WOS:000808049200012
ER

PT J
AU Fuentes, JSPD
   Pegna, FG
AF de Corcho Fuentes, Jorge Simon Perez
   Garbati Pegna, Francesco
TI Mathematically modelling the power requirement for a vertical shaft
   mowing machine
SO INGENIERIA E INVESTIGACION
AB This work describes a mathematical model for determining the power demand for a vertical shaft mowing machine, particularly taking into account the influence of speed on cutting power, which is different from that of other models of mowers. The influence of the apparatus' rotation and translation speeds was simulated in determining power demand. The results showed that no changes in cutting power were produced by varying the knives' angular speed (if translation speed was constant), while cutting power become increased if translation speed was increased. Variations in angular speed, however, influenced other parameters determining total power demand. Determining this vertical shaft mower's cutting pattern led to obtaining good crop stubble quality at the mower's lower rotation speed, hence reducing total energy requirements.
SN 0120-5609
PD DEC
PY 2008
VL 28
IS 3
BP 122
EP 125
UT WOS:000207503700018
ER

PT S
AU Kishida, K
   Kando, N
AF Kishida, Kazuaki
   Kando, Noriko
BE Peters, C
   Gey, FC
   Gonzalo, J
   Muller, H
   Jones, GJF
   Kluck, M
   Magnini, B
   DeRijke, M
TI A hybrid approach to query and document translation using a pivot
   language for cross-language information retrieval
SO ACCESSING MULTILINGUAL INFORMATION REPOSITORIES
SE LECTURE NOTES IN COMPUTER SCIENCE
CT 6th Workshop of the Cross-Language Evaluation Forum
CY SEP 21-23, 2005
CL Vienna, AUSTRIA
AB This paper reports experimental results for cross-language information retrieval (CLIR) from German to French, in which a hybrid approach to query and document translation was attempted, i.e., combining the results of query translation (German to French) and of document translation (French to German). In order to reduce the complexity of computation when translating a large amount of texts, we performed pseudo-translation, i.e., a simple replacement of terms by a bilingual dictionary (for query translation, a machine translation system was used). In particular, since English was used as an intermediary language for both translation directions between German and French, English translations at the middle stage were employed as document representations in order to reduce the number of translation steps. By omitting a translation step (English to German), the performance was improved. Unfortunately, our hybrid approach did not show better performance than a simple query translation. This may be due to the low performance of document translation, which was carried out by a simple replacement of terms using a bilingual dictionary with no term disambiguation.
OI Kando, Noriko/0000-0002-2133-0215
SN 0302-9743
BN 3-540-45697-X
PY 2006
VL 4022
BP 93
EP 101
UT WOS:000241359000010
ER

PT J
AU Vandeghinste, V
AF Vandeghinste, Vincent
TI Scaling up a hybrid MT system: From low to full resources
SO LINGUISTICA ANTVERPIENSIA NEW SERIES-THEMES IN TRANSLATION STUDIES
AB This article describes a hybrid approach to machine translation (MT) that is inspired by the rule-based, statistical, example-based, and other hybrid machine translation approaches currently used or described in academic literature. It describes how the approach was implemented fir language pairs using only limited monolingual resources and hardly any parallel resources (the METIS-II system,), and how it is currently implemented with rich resources on both the source and target side as well as rich parallel data (the PaCo-MT system). We aim to illustrate that a similar paradigm can be used, irrespectively of the resources available, but of course with an impact on translation quality
RI Vandeghinste, Vincent/D-3141-2013
OI Vandeghinste, Vincent/0000-0002-5450-201X
SN 2295-5739
PY 2009
VL 8
BP 65
EP 80
UT WOS:000208284200004
ER

PT J
AU Diedrich, A
   Guzman, G
AF Diedrich, Andreas
   Guzman, Gustavo
TI From implementation to appropriation: understanding knowledge management
   system development and introduction as a process of translation
SO JOURNAL OF KNOWLEDGE MANAGEMENT
AB Purpose - This paper aims to examine the complexities emerging in the attempts to develop a sophisticated IT-based knowledge management system (KMS) for sharing knowledge. Using actor-network theory, the authors conceptualise this as continuous processes of translation, whereby heterogeneous human and non-human (e.g. technologies, methods and plans) elements are drawn together and mobilised to produce stable networks through associations between them.
   Design/methodology/approach - The case study method was adopted using a narrative approach that studies the ways of organising work in organisations. Shadowing, field notes, diary studies and participant observation were the main data collection methods used.
   Findings - The development and introduction of a KMS is a contingent and local process shaped by messy translations whereby the original idea, human and other non-human elements are reconfigured. By considering humans and non-humans symmetrically, the intended and unintended actions, and the role of unexpected events, this approach overcomes the deterministic view of human nature of the conventional KMS approaches.
   Research limitations/implications - A conceptual framework is presented as a means to improve the understanding of the complex associations emerging within networks of people, objects and machines during the development and introduction of KMS.
   Practical implications - The translation approach helps practitioners to consider their taken-for-granted assumptions about people, machines and the associations among them. This assists practitioners to uncover emerging conflicting issues between human and machines, among machines and among humans. Furthermore, this allows practitioners to recognise the different identities humans and non-humans take, overtime, as a result of emerging associations.
   Originality/value - The originality of this paper lies in the use of alternative conceptual lenses to understand KMS development and introduction as processes of translation. Additionally, rather than exploring the success stories, it focuses on a failed attempt to introduce a KMS.
SN 1367-3270
EI 1758-7484
PY 2015
VL 19
IS 6
BP 1273
EP 1294
DI 10.1108/JKM-02-2015-0055
UT WOS:000369179500009
ER

PT J
AU Li, YC
   Li, JH
   Zhang, M
   Li, YX
   Zou, P
AF Li, Yachao
   Li, Junhui
   Zhang, Min
   Li, Yixin
   Zou, Peng
TI Improving Neural Machine Translation with Linear Interpolation of a
   Short-Path Unit
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB In neural machine translation (NMT), the source and target words are at the two ends of a large deep neural network, normally mediated by a series of non-linear activations. The problem with such consequent non-linear activations is that they significantly decrease the magnitude of the gradient in a deep neural network, and thus gradually loosen the interaction between source words and their translations. As a result, a source word may be incorrectly translated into a target word out of its translational equivalents. In this article, we propose short-path units (SPUs) to strengthen the association of source and target words by allowing information flow over adjacent layers effectively via linear interpolation. In particular, we enrich three critical NMT components with SPUs: (1) an enriched encoding model with SPU, which interpolates source word embeddings linearly into source annotations; (2) an enriched decoding model with SPU, which enables the source context linearly flow to target-side hidden states; and (3) an enriched output model with SPU, which further allows linear interpolation of target-side hidden states into output states. Experimentation on Chinese-to-English, English-to-German, and low-resource Tibetan-to-Chinese translation tasks demonstrates that the linear interpolation of SPUs significantly improves the overall translation quality by 1.88, 1.43, and 3.75 BLEU, respectively. Moreover, detailed analysis shows that our approaches much strengthen the association of source and target words. From the preceding, we can see that our proposed model is effective both in rich- and low-resource scenarios.
SN 2375-4699
EI 2375-4702
PD JUL
PY 2020
VL 19
IS 3
AR 44
DI 10.1145/3377851
UT WOS:000582616600011
ER

PT J
AU Lin, Q
   Yang, J
   Zhang, XW
   Wang, HJ
   Lu, YJ
   Su, JS
AF Lin, Qian
   Yang, Jing
   Zhang, Xiangwen
   Wang, Hongji
   Lu, Yaojie
   Su, Jinsong
TI Semantically Smooth Bilingual Phrase Embeddings Based on Recursive
   Autoencoders
SO NEURAL PROCESSING LETTERS
AB In this paper, we propose Semantically Smooth Bilingual Recursive Autoencoders to learn bilingual phrase embeddings. The intuition behind our work is to exploit the intrinsic geometric structure of the embedding space and enforce the learned phrase embeddings to be semantically smooth. Specifically, we extend the conventional bilingual recursive autoencoders by preserving the translation and paraphrase probability distributions via regularization terms to simultaneously exploit richer explicit and implicit similarity constraints for bilingual phrase embeddings. To examine the effectiveness of our model, we incorporate two phrase-level similarity features based on the proposed model into a state-of-the-art phrase-based statistical machine translation system. Experiments on NIST Chinese-English test sets show that our model achieves substantial improvements over the baseline.
RI Zhang, Xiangwen/ABD-9717-2021
SN 1370-4621
EI 1573-773X
PD JUN
PY 2020
VL 51
IS 3
SI SI
BP 2497
EP 2512
DI 10.1007/s11063-020-10210-1
EA FEB 2020
UT WOS:000516967100001
ER

PT C
AU Sun, HP
   Wang, R
   Chen, KH
   Utiyama, M
   Sumita, E
   Zhao, TJ
AF Sun, Haipeng
   Wang, Rui
   Chen, Kehai
   Utiyama, Masao
   Sumita, Eiichiro
   Zhao, Tiejun
GP ACL
BE Korhonen, A
   Traum, D
   Marquez, L
TI Unsupervised Bilingual Word Embedding Agreement for Unsupervised Neural
   Machine Translation
SO 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2019)
CT 57th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 28-AUG 02, 2019
CL Florence, ITALY
SP Assoc Computat Linguist, Apple, ASAPP, Bloomberg Engn, Bosch, Expedia, Facebook, Google, Microsoft, Salesforce, Amazon, Baidu, DeepMind, Grammarly, Huawei, IBM, Tencent, ByteDance, DiDi, Keiosk Analyt, Megagon Labs, Naver, PolyAi, Samsung, Bebelscape, BMW, Cisco, Duolingo, Ebay, G Res, SAP, Raytheon BBN Technologies, USC Viterbi, Sch Engn, Shannon Ai
AB Unsupervised bilingual word embedding (UBWE), together with other technologies such as back-translation and denoising, has helped unsupervised neural machine translation (UNMT) achieve remarkable results in several language pairs. In previous methods, UBWE is first trained using non-parallel monolingual corpora and then this pre-trained UBWE is used to initialize the word embedding in the encoder and decoder of UNMT. That is, the training of UBWE and UNMT are separate. In this paper, we first empirically investigate the relationship between UBWE and UNMT. The empirical findings show that the performance of UNMT is significantly affected by the performance of UBWE. Thus, we propose two methods that train UNMT with UBWE agreement. Empirical results on several language pairs show that the proposed methods significantly outperform conventional UNMT.
RI Chen, Kehai/ABF-1874-2020; Wang, Rui/AAI-1990-2020
OI Wang, Rui/0000-0001-8007-2503
BN 978-1-950737-48-2
PY 2019
BP 1235
EP 1245
UT WOS:000493046102023
ER

PT C
AU Briakou, E
   Carpuat, M
AF Briakou, Eleftheria
   Carpuat, Marine
GP Assoc Computat Linguist
TI The University of Maryland's Kazakh-English Neural Machine Translation
   System at WMT19
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019)
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB This paper describes the University of Maryland's submission to the WMT 2019 Kazakh to English news translation task. We study the impact of transfer learning from another low-resource but related language. We experiment with different ways of encoding lexical units to maximize lexical overlap between the two language pairs, as well as back-translation and ensembling. The submitted system improves over a Kazakh-only baseline by +5.45 BLEU on newstest2019.
BN 978-1-950737-27-7
PY 2019
BP 134
EP 140
UT WOS:000538566200008
ER

PT C
AU Kadriu, A
   Abazi, L
AF Kadriu, Arbana
   Abazi, Lejla
BE Kazovsky, L
   Borne, P
   Mastorakis, N
   KuriMorales, A
   Sakellaris, I
TI Generating the translation equivalent of agentive nouns using two-level
   morphology
SO ADVANCES ON ARTIFICIAL INTELLIGENCE, KNOWLEDGE ENGINEERING AND DATA
   BASES, PROCEEDINGS
SE Artificial Intelligence Series-WSEAS
CT 7th WSEAS International Conference on Artificial Intelligence, Knowledge
   Engineering and Data Bases
CY FEB 20-22, 2008
CL Univ Cambridge, Cambridge, ENGLAND
SP WSEAS
HO Univ Cambridge
AB This paper is about generation of translation equivalent of agentive nouns with the use of automatically learned two-level phonological rules. The system is implemented using the PC-KIMMO environment. The basis for the research presented in this paper are two lexicons that contain a list of agentive nouns in Macedonian and English including their components (noun, verb, adjective, pronoun) and their semantic attributes.
BN 978-960-6766-41-1
PY 2008
BP 392
EP +
UT WOS:000257462700057
ER

PT C
AU Zhuang, YM
   Zhang, Y
   Wang, LJ
AF Zhuang, Yimeng
   Zhang, Yuan
   Wang, Lijie
GP Assoc Comp Linguist
TI LIT Team's System Description for Japanese-Chinese Machine Translation
   Task in IWSLT 2020
SO 17TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE TRANSLATION (IWSLT
   2020)
CT 17th International Conference on Spoken Language Translation (IWSLT)
CY JUL 09-10, 2020
CL ELECTR NETWORK
AB This paper describes the LIT Team's submission to the IWSLT2020 open domain translation task, focusing primarily on Japanese-to-Chinese translation direction. Our system is based on the organizers' baseline system, but we do more works on improving the Transformer baseline system by elaborate data preprocessing. We manage to obtain significant improvements, and this paper aims to share some data processing experiences in this translation task. Large-scale back-translation on monolingual corpus is also investigated. In addition, we also try shared and exclusive word embeddings, compare different granularity of tokens like sub-word level. Our Japanese-to-Chinese translation system achieves a performance of BLEU=34.0 and ranks 2nd among all participating systems.
BN 978-1-952148-07-1
PY 2020
BP 109
EP 113
UT WOS:000563427100012
ER

PT C
AU Tang, GB
   Sennrich, R
   Nivre, J
AF Tang, Gongbo
   Sennrich, Rico
   Nivre, Joakim
GP Assoc Computat Linguist
TI Encoders Help You Disambiguate Word Senses in Neural Machine Translation
SO 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND
   THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (EMNLP-IJCNLP 2019): PROCEEDINGS OF THE CONFERENCE
CT Conference on Empirical Methods in Natural Language Processing / 9th
   International Joint Conference on Natural Language Processing
   (EMNLP-IJCNLP)
CY NOV 03-07, 2019
CL Hong Kong, HONG KONG
SP Google, Facebook, Apple, ASAPP, Salesforce, Huawei, Baidu, Deepmind, Amazon, PolyAI, Naver, ByteDance, Megagon Labs, Zhuiyi, Verisk, MI
AB Neural machine translation (NMT) has achieved new state-of-the-art performance in translating ambiguous words. However, it is still unclear which component dominates the process of disambiguation. In this paper, we explore the ability of NMT encoders and decoders to disambiguate word senses by evaluating hidden states and investigating the distributions of self-attention. We train a classifier to predict whether a translation is correct given the representation of an ambiguous noun. We find that encoder hidden states outperform word embeddings significantly which indicates that encoders adequately encode relevant information for disambiguation into hidden states. In contrast to encoders, the effect of decoder is different in models with different architectures. Moreover, the attention weights and attention entropy show that self-attention can detect ambiguous nouns and distribute more attention to the context.
OI Sennrich, Rico/0000-0002-1438-4741
BN 978-1-950737-90-1
PY 2019
BP 1429
EP 1435
UT WOS:000854193301071
ER

PT C
AU Moh, TS
   Zhang, Z
AF Moh, Teng-Sheng
   Zhang, Zhang
GP ACM
TI Cross-Lingual Text Classification with Model Translation and Document
   Translation
SO PROCEEDINGS OF THE 50TH ANNUAL ASSOCIATION FOR COMPUTING MACHINERY
   SOUTHEAST CONFERENCE
CT 50th Annual Association-for-Computing-Machinery (ACM) Southeast
   Conference
CY MAR 29-31, 2012
CL Univ Alabama, Tuscaloosa, AL
SP Assoc Comp Machinery
HO Univ Alabama
AB Text classification assumes that the documents are in the same language, so when a classifier tries to categorize these documents in different languages, the trained model in mono-language will not work. The most direct solution is to translate all the documents in other languages into one language with the machine translator. Another approach is to translate the features extracted from one language into a second language and use them to classify the second language. In this paper, the authors propose a new method that adopts both the model translation and the document translation methods. This new method can take advantage of the best of the functionality between both the document translation and model translation methods.
BN 978-1-4503-1203-5
PY 2012
UT WOS:000395791900013
ER

PT C
AU Huang, Y
   Zhao, F
   He, MZ
   He, X
AF Huang Ying
   Zhao Fang
   He Manze
   He Xiang
BE Li, X
   Plummer, WT
   Fan, B
   Pu, M
   Wan, Y
   Luo, X
TI Research on the Control Technology of Machining Marks in Double-Side
   Polishing of Large Aperture Optical Element
SO 9TH INTERNATIONAL SYMPOSIUM ON ADVANCED OPTICAL MANUFACTURING AND
   TESTING TECHNOLOGIES: ADVANCED OPTICAL MANUFACTURING TECHNOLOGIES
SE Proceedings of SPIE
CT 9th International Symposium on Advanced Optical Manufacturing and
   Testing Technologies - Advanced Optical Manufacturing Technologies
CY JUN 26-29, 2018
CL Chengdu, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Opt & Elect, Chinese Opt Soc, SPIE
AB For the high demand of large aperture optical element, the regular trajectory errors in machining marks of double-side polishing need to be determinately controlled. The mechanism and control method of the regular trajectory errors in machining marks were deeply studied. The process was simulated and compared with the experiment. The method of active translation and pendulum motion and polishing plate correction were proposed, proved to be efficacious on eliminating the regular machining marks by the groove of the polishing pad and local surface figure errors of the polishing plate. The method of dynamic loading and motion combination was adopted, retaining the independence of the original fast convergence process on surface figure. For the optical element with 430mmx430mmx 10mm, the surface figure was controlled below li,(PV, i,=632.8nm). Meanwhile, the regular machining marks repeatedly produced were eliminated, which provided the essential condition for the intermediate frequency index in the rear stage, small tool precision polishing, and the high efficiency and stable machining of the optical element in the index system was realized.
SN 0277-786X
EI 1996-756X
BN 978-1-5106-2319-4
PY 2019
VL 10838
AR UNSP 108381O
DI 10.1117/12.2507812
UT WOS:000459715700059
ER

PT C
AU Taghbalout, I
   Allah, FA
   El Marraki, M
AF Taghbalout, Imane
   Allah, Fadoua Ataa
   El Marraki, Mohamed
BE Boubiche, DE
   Hidoussi, F
   Cruz, HT
TI Amazigh Representation in the UNL Framework: Resource Implementation
SO INTERNATIONAL CONFERENCE ON ADVANCED WIRELESS INFORMATION AND
   COMMUNICATION TECHNOLOGIES (AWICT 2015)
SE Procedia Computer Science
CT International Conference on Advanced Wireless Information and
   Communication Technologies (AWICT)
CY OCT 05-07, 2015
CL Natl Sch Engineers Sousse, TUNISIA
HO Natl Sch Engineers Sousse
AB This paper discusses the first steps undertaken to create necessary linguistic resources to incorporate Amazigh language within the Universal Networking Language (UNL) framework for machine translation purpose. This universal interlanguage allows to any source text to be translated into different other related languages with UNL by converting the meaning of the source text into semantic graph. This encoding is considered as a pivot interlanguage used in translation systems. Thus in this work, we focus on presenting morphological, syntactical and lexical mapping stages needed for building an "Amazigh dictionary" according to the UNL framework and the "UNL-Amazigh Dictionary" that are both taking part in enconversion and deconversion processes. (C) 2015 The Authors. Published by Elsevier B.V.
SN 1877-0509
PY 2015
VL 73
BP 234
EP 241
DI 10.1016/j.procs.2015.12.023
UT WOS:000373736100029
ER

PT C
AU Kim, H
   Komachi, M
AF Kim, Hwichan
   Komachi, Mamoru
GP Assoc Computat Linguist
TI TMU NMT System with Japanese BART for the Patent task of WAT 2021
SO WAT 2021: THE 8TH WORKSHOP ON ASIAN TRANSLATION
CT 8th Workshop on Asian Translation (WAT)
CY AUG 05-06, 2021
CL ELECTR NETWORK
AB In this paper, we introduce our TMU Neural Machine Translation (NMT) system submitted for the Patent task (Korean reversible arrow Japanese and English reversible arrow Japanese) of 8th Workshop on Asian Translation (Nakazawa et al., 2021). Recently, several studies proposed pre-trained encoder-decoder models using monolingual data. One of the pre-trained models, BART (Lewis et al., 2020), was shown to improve translation accuracy via fine-tuning with bilingual data. However, they experimented only Romanian -> English translation using English BART. In this paper, we examine the effectiveness of Japanese BART using Japan Patent Office Corpus 2.0. Our experiments indicate that Japanese BART can also improve translation accuracy in both Korean reversible arrow Japanese and English reversible arrow Japanese translations.
OI Komachi, Mamoru/0000-0003-1166-1739
BN 978-1-954085-63-3
PY 2021
BP 133
EP 137
UT WOS:000686140700013
ER

PT J
AU Oliver, A
AF Oliver, Antoni
TI The parallel corpus of the Official Journal of the Catalan Government
SO LINGUAMATICA
AB In this paper, the process of compilation of the new version of the Catalan-Spanish parallel corpus of the Official Journal of the Catalan Government (DOGC) is presented. The processes of downloading, conversion to text, segmentation and automatic alignment are described. All the programs that have been developed to perform these processes are distributed under a free license and the compiled corpus can be freely downloaded. Furthermore, the process of training and evaluation of two neural machine translation systems, Catalan-Spanish and Spanish-Catalan, using this corpus is presented.
SN 1647-0818
PY 2022
VL 14
IS 2
BP 75
EP 81
DI 10.21814/lm.14.2.380
UT WOS:000926180300005
ER

PT C
AU Bapna, A
   Chen, MX
   Firat, O
   Cao, Y
   Wu, YH
AF Bapna, Ankur
   Chen, Mia Xu
   Firat, Orhan
   Cao, Yuan
   Wu, Yonghui
GP Assoc Computat Linguist
TI Training Deeper Neural Machine Translation Models with Transparent
   Attention
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB While current state-of-the-art NMT models, such as RNN seq2seq and Transformers, possess a large number of parameters, they are still shallow in comparison to convolutional models used for both text and vision applications. In this work we attempt to train significantly (2-3x) deeper Transformer and BiRNN encoders for machine translation. We propose a simple modification to the attention mechanism that eases the optimization of deeper models, and results in consistent gains of 0.7-1.1 BLEU on the benchmark WMT'14 English-German and WMT'15 Czech-English tasks for both architectures.
BN 978-1-948087-84-1
PY 2018
BP 3028
EP 3033
UT WOS:000865723403027
ER

PT C
AU Skadina, I
   Auzina, I
   Deksne, D
   Skadins, R
   Vasiljevs, A
   Gailuna, M
   Portnaja, I
AF Skadina, Inguna
   Auzina, Ilze
   Deksne, Daiga
   Skadins, Raivis
   Vasiljevs, Andrejs
   Gailuna, Madara
   Portnaja, Ieva
BE Skadina, I
   Rozis, R
TI Filling the Gaps in Latvian BLARK: Case of the Latvian IT Competence
   Centre
SO HUMAN LANGUAGE TECHNOLOGIES - THE BALTIC PERSPECTIVE
SE Frontiers in Artificial Intelligence and Applications
CT 7th International Conference on Human Language Technologies - The Baltic
   Perspective (Baltic HLT)
CY OCT 06-07, 2016
CL Riga, LATVIA
AB We present the results of the Latvian IT Competence Centre (IT CC) in developing several essential language technologies and applications. 11 language technology projects have been completed in the first phase of the IT CC work. We describe how IT CC has contributed to filling in the gaps and improving the quality of the basic language technologies for Latvian in speech processing, machine translation, parsing and grammar checking, intelligent media monitoring and multi-modal human-computer interaction.
RI Auziņa, Ilze/GXG-5722-2022
OI Auziņa, Ilze/0000-0001-6143-2841; Skadina, Inguna/0000-0003-4787-7099
SN 0922-6389
EI 1879-8314
BN 978-1-61499-701-6; 978-1-61499-700-9
PY 2016
VL 289
BP 3
EP 11
DI 10.3233/978-1-61499-701-6-3
UT WOS:000390307700001
ER

PT C
AU Pal, P
   Heafield, K
AF Pal, Proyag
   Heafield, Kenneth
GP ASSOC COMPUTAT LINGUIST
TI Cheat Codes to Quantify Missing Source Information in Neural Machine
   Translation
SO NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE
   ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES
CT Conference of the
   North-American-Chapter-of-the-Association-for-Computational-Linguistics
   (NAAACL) - Human Language Technologies
CY JUL 10-15, 2022
CL Seattle, WA
SP Assoc Computat Linguist, N Amer Chapter, Amazon Sci, Bloomberg Engn, Google Res, LivepersoMetan, ByteDance, KENSH, Grammarly, Megagon Labs, Microsoft, Reveal Brainspace, Cohere, GResearch, Relativity, Servicenow, ASAPP, Duolingo, Adobe, Linkedin, Babelscape, Rakuten Inst Technol, UC Santa Cruz, Baskin Engn, Nat Language Proc, NSF, ETS, OpenAI, TIAA, Two Sigma, Mag Data
AB This paper describes a method to quantify the amount of information H(t vertical bar s) added by the target sentence t that is not present in the source s in a neural machine translation system. We do this by providing the model the target sentence in a highly compressed form (a "cheat code"), and exploring the effect of the size of the cheat code. We find that the model is able to capture extra information from just a single float representation of the target and nearly reproduces the target with two 32-bit floats per target token.
BN 978-1-955917-71-1
PY 2022
BP 2472
EP 2477
UT WOS:000859869502039
ER

PT C
AU Inaba, R
   Murakami, Y
   Nadamoto, A
   Ishida, T
AF Inaba, Rieko
   Murakami, Yohei
   Nadamoto, Akiyo
   Ishida, Toru
BE Ishida, T
   Fussell, SR
   Vossen, PTJM
TI Multilingual communication support using the Language Grid
SO INTERCULTURAL COLLABORATION
SE Lecture Notes in Computer Science
CT 1st International Workshop on Intercultural Collaboration
CY JAN 25-26, 2007
CL Kyoto, JAPAN
SP Natl Inst Informat, Ctr Excellence Knowledge Soc, Kyoto Univ, Language Grid Project, IEICE Special Interest Grp Intercultural Collaborat
AB Our proposed "Language Grid" infrastructure supports multilingual communication by combining in new way language resources, such as machine translators, morphological analyzers, and dictionaries specific to user communities. We developed the Language Grid as a language infrastructure on the Internet. The Language Grid enables user communities to combine two or more machine translators and their community dictionaries by workflows, and to easily create new multilingual services specific to the communities. Because the quality of language services is not often defined, however, we need to confirm that the created multilingual service is really useful. We need to extend the process of general usability testing to the multilingual environment. For example, cooperation between user communities and language grid providers can significantly improve the accuracy of machine translation: it turns out that machine translations can be useful for interactive communication in the field of inter-cultural collaboration.
RI Ishida, Toru/H-5553-2017; Ishida, Toru/AAI-2102-2020
OI Ishida, Toru/0000-0002-0479-4990; Ishida, Toru/0000-0002-0479-4990
SN 0302-9743
EI 1611-3349
BN 978-3-540-73999-9
PY 2007
VL 4568
BP 118
EP +
UT WOS:000249580400009
ER

PT C
AU Pryzant, R
   Chung, Y
   Jurafsky, D
   Britz, D
AF Pryzant, Reid
   Chung, Youngjoo
   Jurafsky, Dan
   Britz, Denny
BA Declerck, T
BF Declerck, T
BE Calzolari, N
   Choukri, K
   Cieri, C
   Hasida, K
   Isahara, H
   Maegaard, B
   Mariani, J
   Moreno, A
   Odijk, J
   Piperidis, S
   Tokunaga, T
   Goggi, S
   Mazo, H
TI JESC: Japanese-English Subtitle Corpus
SO PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE
   RESOURCES AND EVALUATION (LREC 2018)
CT 11th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 07-12, 2018
CL Miyazaki, JAPAN
AB In this paper we describe the Japanese-English Subtitle Corpus (JESC). JESC is a large Japanese-English parallel corpus covering the underrepresented domain of conversational dialogue. It consists of more than 3.2 million examples, making it the largest freely available dataset of its kind. The corpus was assembled by crawling and aligning subtitles found on the web. The assembly process incorporates a number of novel preprocessing elements to ensure high monolingual fluency and accurate bilingual alignments. We summarize its contents and evaluate its quality using human experts and baseline machine translation (MT) systems.
BN 979-10-95546-00-9
PY 2018
BP 1133
EP 1137
UT WOS:000725545001035
ER

PT C
AU Abualkishik, AM
   Omar, K
AF Abualkishik, Abdallah M.
   Omar, Khairuddin
GP IEEE
TI Quran Vibrations in Braille Code
SO 2009 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS,
   VOLS 1 AND 2
CT International Conference on Electrical Engineering and Informatics
CY AUG 05-07, 2009
CL Bangi, MALAYSIA
SP Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Univ Kebangsaan Malaysia, Fac Engn & Built Environm
AB This article concerned with reorganize new Braille symbols to represent the vibrations in the Arabic Quran, the aim of this study is building a system that translate the Quran verses to Braille symbols including new vibrations. This study limited for the (Noun + Scoon) vibrations, (Meem + Scoon) vibrations and (Lam + Scoon) vibrations. It builds on an existing translation system that combines a finite state machine with left and right context matching and a set of translation rules. This allows to translate the Arabic language from text to Braille symbols after detect the vibration for the Quran verses.
RI Omar, Khairuddin/C-3534-2017
OI Omar, Khairuddin/0000-0003-1794-019X; abualkishik,
   abdallah/0000-0001-9961-5563
BN 978-1-4244-4912-5
PY 2009
BP 12
EP 17
DI 10.1109/ICEEI.2009.5254826
UT WOS:000275102300003
ER

PT J
AU Garg, KD
   Shekhar, S
   Kumar, A
   Goyal, V
   Sharma, B
   Chengoden, R
   Srivastava, G
AF Garg, Kamal Deep
   Shekhar, Shashi
   Kumar, Ajit
   Goyal, Vishal
   Sharma, Bhisham
   Chengoden, Rajeswari
   Srivastava, Gautam
TI Framework for Handling Rare Word Problems in Neural Machine Translation
   System Using Multi-Word Expressions
SO APPLIED SCIENCES-BASEL
AB Machine Translation (MT) systems are now being improved with the use of an ongoing methodology known as Neural Machine Translation (NMT). Natural language processing (NLP) researchers have shown that NMT systems are unable to deal with out-of-vocabulary (OOV) words and multi-word expressions (MWEs) in the text. OOV terms are those that are not currently included in the vocabulary that is used by the NMT system. MWEs are phrases that consist of a minimum of two terms but are treated as a single unit. MWEs have great importance in NLP, linguistic theory, and MT systems. In this article, OOV words and MWEs are handled for the Punjabi to English NMT system. A parallel corpus for Punjabi to English containing MWEs was developed and used to train the different models of NMT. Punjabi is a low-resource language as it lacks the availability of a large parallel corpus for building various NLP tools, and this is an attempt to improve the accuracy of Punjabi in the English NMT system by using named entities and MWEs in the corpus. The developed NMT models were assessed using human evaluation through adequacy, fluency and overall rating as well as automated assessment tools such as the bilingual evaluation study (BLEU) and translation error rate (TER) score. Results show that using word embedding (WE) and MWEs corpus increased the accuracy of translation for the Punjabi to English language pair. The best BLEU score obtained was 15.45 for the small test set, 43.32 for the medium test set, and 34.5 for the large test set, respectively. The best TER rate score obtained was 57.34% for the small test set, 37.29% for the medium test set, and 53.79% for the large test set, repectively.
RI Sharma, Bhisham/AAB-7076-2020
OI Sharma, Bhisham/0000-0002-3400-3504; Garg, Kamal
   Deep/0000-0001-9551-9830; Srivastava, Gautam/0000-0001-9851-4103;
   Chengoden, Rajeswari/0000-0001-6536-8402
EI 2076-3417
PD NOV
PY 2022
VL 12
IS 21
AR 11038
DI 10.3390/app122111038
UT WOS:000880907300001
ER

PT J
AU Munteanu, DS
   Marcu, D
AF Munteanu, DS
   Marcu, D
TI Improving machine translation performance by exploiting non-parallel
   corpora
SO COMPUTATIONAL LINGUISTICS
AB We present a novel method for discovering parallel sentences in comparable, non-parallel corpora. We train a maximum entropy classifier that, given a pair of sentences, can reliably determine whether or not they are translations of each other. Using this approach, we extract parallel data from large Chinese, Arabic, and English non-parallel newspaper corpora. We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system. We also show that a good-quality MT system can be built from scratch by starting with a very small parallel corpus (100,000 words) and exploiting a large non-parallel corpus. Thus, our method can be applied with great benefit to language pairs for which only scarce resources are available.
RI Munteanu, Dragos V/AAB-7656-2020
SN 0891-2017
EI 1530-9312
PD DEC
PY 2005
VL 31
IS 4
BP 477
EP 504
DI 10.1162/089120105775299168
UT WOS:000235203600003
ER

PT C
AU Zeng, WY
   Liu, C
AF Zeng, Weiyuan
   Liu, Cong
GP IEEE
TI Improving Lexical-Constraint-Aware Machine Translation by Factoring
   Encoders
SO 2021 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
CT International Joint Conference on Neural Networks (IJCNN)
CY JUL 18-22, 2021
CL ELECTR NETWORK
SP Int Neural Network Soc, IEEE Computat Intelligence Soc
AB Existing lexically constrained machine translation employs data augmentation and incorporates lexical constraints during decoding period, which requires a bilingual dictionary or costs much decoding time. In this paper, we propose a simple but effective method to leverage lexical constraints. We use separate encoders to encode source sentence and lexical constraints, with self-attention layer mask to disentangle the two encoding sub-tasks. Our method does not require bilingual dictionaries or modify decoding process. Experiments on WMT 2016 English-German (En-De) and IWSLT 2017 English-Chinese (En-Zh) datasets show that our method gains improvement compared to baseline models.
SN 2161-4393
BN 978-0-7381-3366-9
PY 2021
DI 10.1109/IJCNN52387.2021.9533673
UT WOS:000722581703007
ER

PT C
AU Currey, A
   Heafield, K
AF Currey, Anna
   Heafield, Kenneth
GP Assoc Computat Linguist
TI Multi-Source Syntactic Neural Machine Translation
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB We introduce a novel multi-source technique for incorporating source syntax into neural machine translation using linearized parses. This is achieved by employing separate encoders for the sequential and parsed versions of the same source sentence; the resulting representations are then combined using a hierarchical attention mechanism. The proposed model improves over both seq2seq and parsed baselines by over 1 BLEU on the WMT17 English -> German task. Further analysis shows that our multi-source syntactic model is able to translate successfully without any parsed input, unlike standard parsed methods. In addition, performance does not deteriorate as much on long sentences as for the baselines.
BN 978-1-948087-84-1
PY 2018
BP 2961
EP 2966
UT WOS:000865723403016
ER

PT S
AU Carbonell, J
   Probst, K
   Peterson, E
   Monson, C
   Lavie, A
   Brown, R
   Levin, L
AF Carbonell, J
   Probst, K
   Peterson, E
   Monson, C
   Lavie, A
   Brown, R
   Levin, L
BE Richardson, SD
TI Automatic rule learning for resource-limited MT
SO MACHINE TRANSLATION: FROM RESEARCH TO REAL USERS
SE Lecture Notes in Artificial Intelligence
CT 5th Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY OCT 08-12, 2002
CL Tiburon, CA
SP Assoc Machine Translat Americas
AB Machine Translation of minority languages presents unique challenges, including the paucity of bilingual training data and the unavailability of linguistically-trained speakers. This paper focuses on a machine learning approach to transfer-based MT, where data in the form of translations and lexical alignments are elicited from bilingual speakers, and a seeded version-space learning algorithm formulates and refines transfer rules. A rule-generalization lattice is defined based on LFG-style f-structures, permitting generalization operators in the search for the most general rules consistent with the elicited data. The paper presents these methods and illustrates examples.
SN 0302-9743
EI 1611-3349
BN 3-540-44282-0
PY 2002
VL 2499
BP 1
EP 10
UT WOS:000189412300001
ER

PT S
AU Gordin, I
   Leviathan, R
   Pnueli, A
AF Gordin, I
   Leviathan, R
   Pnueli, A
BE Wang, F
TI Validating the translation of an industrial optimizing compiler
SO AUTOMATED TECHNOLOGY FOR VERIFICATION AND ANALYSIS, PROCEEDINGS
SE Lecture Notes in Computer Science
CT 2nd International Conference on Automated Technology for Verification
   and Analysis
CY OCT 31-NOV 03, 2004
CL Taipei, TAIWAN
SP Natl Sci Council, Minist Educ, Acad Sinica, Inst Informat Sci, Natl Taiwan Univ, Ctr Informat & Elect Technol, Natl Taiwan Univ, SOC Ctr, Natl Taiwan Univ, Grad Inst Elect Engn, Synopsys Inc
AB The paper presents an approach to the translation validation of an optimizing compiler which translates synchronous C programs into machine code programs. Being synchronous means that both source and target programs are loop free. This enables representation of each of these programs by a single state transformer, and verification of the translation correctness is based on comparison of the source and target state transformers. The approach has been implemented on a tool called MCVT which is also described.
SN 0302-9743
EI 1611-3349
BN 3-540-23610-4
PY 2004
VL 3299
BP 230
EP 247
UT WOS:000225163400019
ER

PT C
AU Ravishankar, V
   Tyers, FM
   Gatt, A
AF Ravishankar, Vinit
   Tyers, Francis M.
   Gatt, Albert
BE Shaalan, K
   ElBeltagy, SR
TI A morphological analyser for Maltese
SO ARABIC COMPUTATIONAL LINGUISTICS (ACLING 2017)
SE Procedia Computer Science
CT 3rd Arabic Computational Linguistics Conference (ACLing)
CY NOV 05-06, 2017
CL British Univ Dubai, Dubai, U ARAB EMIRATES
HO British Univ Dubai
AB This article describes the development of a free/open-source morphological description of Maltese, originally created as the analysis component in a rule-based machine translation system for Maltese to Arabic and later applied to other tasks. The lexicon formalism we use is lttoolbox, part of the Apertium machine translation platform. An evaluation of the analyser shows that the coverage is adequate, at 84.90%, while precision is 92.5% on a large automatically annotated test set and 96.2% on a smaller hand-validated set. (C) 2017 The Authors. Published by Elsevier B.V.
RI Gatt, Albert/HOH-4660-2023
OI Gatt, Albert/0000-0001-6388-8244
SN 1877-0509
PY 2017
VL 117
BP 175
EP 182
DI 10.1016/j.procs.2017.10.107
UT WOS:000425029300022
ER

PT C
AU Sebastian, MP
   Kurian, KS
   Kumar, GS
AF Sebastian, Mary Priya
   Kurian, K. Sheena
   Kumar, G. Santhosh
BE Ranka, S
   Banerjee, A
   Biswas, KK
   Dua, S
   Mishra, P
   Moona, R
   Poon, SH
   Wang, CL
TI Alignment Model and Training Technique in SMT from English to Malayalam
SO CONTEMPORARY COMPUTING, PT 1
SE Communications in Computer and Information Science
CT 3rd International Conference on Contemporary Computing
CY AUG 09-11, 2010
CL Noida, INDIA
SP Jaypee Inst Informat Technol, Univ Florida
AB This paper investigates certain methods of training adopted in the Statistical Machine Translator (SMT) from English to Malayalam. In English Malayalam SMT, the word to word translation is determined by training the parallel corpus. Our primary goal is to improve the alignment model by reducing the number of possible alignments of all sentence pairs present in the bilingual corpus. Incorporating morphological information into the parallel corpus with the help of the parts of speech tagger has brought around better training results with improved accuracy.
RI Gopalan, Santhosh Kumar/I-7361-2012; G, Santhosh Kumar/G-6027-2010;
   Sebastian, Mary Priya/AAE-6721-2022
OI Gopalan, Santhosh Kumar/0000-0001-6855-426X; G, Santhosh
   Kumar/0000-0001-5518-5725; Sebastian, Mary Priya/0000-0001-9772-4256
SN 1865-0929
BN 978-3-642-14833-0
PY 2010
VL 94
BP 305
EP 315
DI 10.1007/978-3-642-14834-7_29
UT WOS:000289705700029
ER

PT C
AU Sun, M
   Jiang, BJ
   Xiong, H
   He, ZJ
   Wu, H
   Wang, HF
AF Sun, Meng
   Jiang, Bojian
   Xiong, Hao
   He, Zhongjun
   Wu, Hua
   Wang, Haifeng
GP Assoc Computat Linguist
TI Baidu Neural Machine Translation Systems for WMT19
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019)
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB In this paper we introduce the systems Baidu submitted for the WMT19 shared task on Chinese <-> English news translation. Our systems are based on the Transformer architecture with some effective improvements. Data selection, back translation, data augmentation, knowledge distillation, domain adaptation, model ensemble and re-ranking are employed and proven effective in our experiments. Our Chinese -> English system achieved the highest case-sensitive BLEU score among all constrained submissions, and our English -> Chinese system ranked the second in all submissions.
BN 978-1-950737-27-7
PY 2019
BP 374
EP 381
UT WOS:000538566200041
ER

PT C
AU Peng, W
   Liu, JF
   Li, LY
   Liu, Q
AF Peng, Wei
   Liu, Jianfeng
   Li, Liangyou
   Liu, Qun
GP Assoc Computat Linguist
TI Huawei's NMT Systems for the WMT 2019 Biomedical Translation Task
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 3: SHARED TASK
   PAPERS, DAY 2
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB This paper describes Huawei's neural machine translation systems for the WMT 2019 biomedical translation shared task. We trained and fine-tuned our systems on a combination of out-of-domain and in-domain parallel corpora for six translation directions covering English-Chinese, English-French and English-German language pairs. Our submitted systems achieve the best BLEU scores on English-French and English-German language pairs according to the official evaluation results. In the English-Chinese translation task, our systems are in the second place. The enhanced performance is attributed to more in-domain training and more sophisticated models developed. Development of translation models and transfer learning (or domain adaptation) methods has significantly contributed to the progress of the task.
BN 978-1-950737-27-7
PY 2019
BP 164
EP 168
UT WOS:000538569000020
ER

PT C
AU Ahmed, I
   Catano, N
AF Ahmed, Ijaz
   Catano, Nestor
GP IEEE
TI Checking JML-Encoded Finite State Machine Properties
SO 2018 INTERNATIONAL CONFERENCE ON ADVANCEMENTS IN COMPUTATIONAL SCIENCES
   (ICACS)
SE International Conference on Advancements in Computational Sciences ICACS
CT International Conference on Advancements in Computational Sciences
   (ICACS)
CY FEB 19-21, 2018
CL Lahore, PAKISTAN
SP Univ Lahore, Dept Comp Sci & Informat Technol, Punjab Higher Educ Commiss, Higher Educ Commiss, IEEE Comp Soc, IEEE Lahore Sect, IEEE Commun Soc
AB This paper presents a recent work on the encoding of JML specifications as Finite State Machines (FSM). We show how these specifications can be translated to the input language of the Pulse tool and how they can be checked with the tool. The output given by the tool can help programmers to analyse the concurrent behaviour of the FSM and therefore some errors of the JML specification that originated it. We define a set of rules that encode the translation of a subset of the JML language into the input language of Pulse. We present various translation examples and discuss results.
SN 2616-3330
BN 978-1-5386-2170-7
PY 2018
BP 154
EP 162
UT WOS:000462561700023
ER

PT J
AU Isahara, H
   Uchida, Y
AF Isahara, H
   Uchida, Y
TI Analysis, generation and semantic representation in CONTRAST - A
   context-based machine translation system
SO SYSTEMS AND COMPUTERS IN JAPAN
AB This paper describes both a Japanese language analysis system and an English language generation system. The knowledge utilized by these systems has been incorporated into a context-based machine translation system (CONTRAST) developed by the Electrotechnical Laboratory (ETL). The Japanese language analysis component of the CONTRAST system consists of individual modules to analyze syntax, semantics and context. The syntactic analysis module is a completely parallel parsing system based on Earley's algorithm. The semantic analysis module conducts analysis based on case relations. The contextual analysis module creates an intermediate representation that correspond to original text. It does this by placing events included in the semantic analysis results for each individual sentence within a framework that is read out from the general knowledge described as a process model in the concept dictionary. The English text generation system of CONTRAST begins with this intermediate representation. Then, referring to the concept dictionary (common with the analysis module), it creates English text according to generation rules created from the real life text data dependent knowledge relating to English newspaper articles. The format of the concept dictionary, which consists of descriptions of general knowledge, and the format of the intermediate representation, which is a description of the contextual information contained in each body of text, are the same. The outline of the conceptual system employed and studies on the process of creating this system are also discussed.
SN 0882-1666
PD NOV 15
PY 1995
VL 26
IS 14
BP 37
EP 53
DI 10.1002/scj.4690261404
UT WOS:A1995TT47200004
ER

PT C
AU Hoshino, S
   Miyao, Y
   Sudoh, K
   Hayashi, K
   Nagata, M
AF Hoshino, Sho
   Miyao, Yusuke
   Sudoh, Katsuhito
   Hayashi, Katsuhiko
   Nagata, Masaaki
BE Zong, C
   Strube, M
TI Discriminative Preordering Meets Kendall's tau Maximization
SO PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT
   CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2
CT 53rd Annual Meeting of the Association-for-Computational-Linguistics
   (ACS) / 7th International Joint Conference on Natural Language
   Processing of the Asian-Federation-of-Natural-Language-Processing
   (IJCNLP)
CY JUL 26-31, 2015
CL Beijing, PEOPLES R CHINA
SP Assoc Computat Linguist, Asian Federat Nat Language Proc, CreditEase, Baidu, Tencent, Alibaba Grp, Samsung, Microsoft, Google, Facebook, SinoVoice, Huawei, Nuance, Amazon, Voicebox Technologies, Baobab, Sogou
AB This paper explores a simple discriminative preordering model for statistical machine translation. Our model traverses binary constituent trees, and classifies whether children of each node should be reordered. The model itself is not extremely novel, but herein we introduce a new procedure to determine oracle labels so as to maximize Kendall's tau. Experiments in Japanese-to-English translation revealed that our simple method is comparable with, or superior to, state-of-the-art methods in translation accuracy.
RI Miyao, Yusuke/AAT-5285-2020
BN 978-1-941643-73-0
PY 2015
BP 139
EP 144
UT WOS:000493810000023
ER

PT J
AU Sitender
   Bawa, S
AF Sitender
   Bawa, Seema
TI Sanskrit to universal networking language EnConverter system based on
   deep learning and context-free grammar
SO MULTIMEDIA SYSTEMS
AB Machine Translation is a mechanism of transforming text from one language to another with the help of computer technology. Earlier in 2018, a machine translation system had been developed by the authors that translate Sanskrit text to Universal Networking Language expressions and was named as SANSUNL. The work presented in this paper is an extension of SANSUNL system by enhancing POS tagging, Sanskrit language processing and parsing. A Sanskrit stemmer having 23 prefixes and 774 suffixes with grammar rules are used for stemming the Sanskrit sentence in the proposed system. Bidirectional long short-term memory (Bi-LSTM) and stacked LSTM deep neural network models have been used for part of speech tagging of the input Sanskrit text. A tagged dataset of around 400 k entries for Sanskrit have been used for training and testing the neural network models. Proposed Sanskrit context-free grammar has been used with CYK parser to perform the parsing of the input sentence. Size of the Sanskrit-Universal Word dictionary has been increased from 15000 to 25000 entries. Approximately 1500 UNL generation rules have been used to resolve the 46 UNL relations. Four datasets UC-A1, UC-A2, Spanish server gold standard dataset, and 500 Sanskrit sentences taken from the general domain have been used for validating the system. The proposed system is evaluated on BLEU and Fluency score metrics and has reported an efficiency of 95.375%.
RI Sitender, Dr/AAJ-9624-2021
OI Sitender, Dr/0000-0003-0341-2927
SN 0942-4962
EI 1432-1882
PD DEC
PY 2022
VL 28
IS 6
BP 2105
EP 2121
DI 10.1007/s00530-020-00692-3
EA OCT 2020
UT WOS:000578561800001
ER

PT J
AU Gad, W
   Alokla, A
   Nazih, W
   Aref, M
   Salem, AB
AF Gad, Walaa
   Alokla, Anas
   Nazih, Waleed
   Aref, Mustafa
   Salem, Abdel-badeeh
TI DLBT: Deep Learning-Based Transformer to Generate Pseudo-Code from
   Source Code
SO CMC-COMPUTERS MATERIALS & CONTINUA
AB Understanding the content of the source code and its regular expression is very difficult when they are written in an unfamiliar language. Pseudo-code explains and describes the content of the code without using syntax or programming language technologies. However, writing Pseudo-code to each code instruction is laborious. Recently, neural machine translation is used to generate textual descriptions for the source code. In this paper, a novel deep learning-based transformer (DLBT) model is proposed for automatic Pseudo-code generation from the source code. The proposed model uses deep learning which is based on Neural Machine Translation (NMT) to work as a language translator. The DLBT is based on the transformer which is an encoder-decoder structure. There are three major components: tokenizer and embeddings, transformer, and post-processing. Each code line is tokenized to dense vector. Then transformer captures the relatedness between the source code and the matching Pseudo-code without the need of Recurrent Neural Network (RNN). At the post-processing step, the generated Pseudo-code is optimized. The proposed model is assessed using a real Python dataset, which contains more than 18,800 lines of a source code written in Python. The experiments show promising performance results compared with other machine translation methods such as Recurrent Neural Network (RNN). The proposed DLBT records 47.32, 68. 49 accuracy and BLEU performance measures, respectively.
RI Nazih, Waleed/HDO-1156-2022
OI Nazih, Waleed/0000-0003-3153-4251
SN 1546-2218
EI 1546-2226
PY 2022
VL 70
IS 2
BP 3117
EP 3132
DI 10.32604/cmc.2022.019884
UT WOS:000705964000025
ER

PT C
AU Kalamkar, DD
   Banerjee, K
   Srinivasan, S
   Sridharan, S
   Georganas, E
   Smorkalov, ME
   Xu, C
   Heinecke, A
AF Kalamkar, Dhiraj D.
   Banerjee, Kunal
   Srinivasan, Sudarshan
   Sridharan, Srinivas
   Georganas, Evangelos
   Smorkalov, Mikhail E.
   Xu, Cong
   Heinecke, Alexander
GP IEEE
TI Training Google Neural Machine Translation on an Intel CPU Cluster
SO 2019 IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPUTING (CLUSTER)
SE IEEE International Conference on Cluster Computing
CT IEEE International Conference on Cluster Computing (IEEE CLUSTER)
CY SEP 23-26, 2019
CL Albuquerque, NM
SP IEEE, IEEE Comp Soc, IEEE Cluster Steering Comm
AB Google's neural machine translation (GNMT) is state-of-the-art recurrent neural network (RNN/LSTM) based language translation application. It is computationally more demanding than well-studied convolutional neural networks (CNNs). Also, in contrast to CNNs, RNNs heavily mix compute and memory bound layers which requires careful tuning on a latency machine to optimally use fast on-die memories for best single processor performance. Additionally, due to massive compute demand, it is essential to distribute the entire workload among several processors and even compute nodes. To the best of our knowledge, this is the first work which attempts to scale this application on an Intel CPU cluster. Our CPU-based GNMT optimization, the first of its kind, achieves this by the following steps: (i) we choose a monolithic long short-term memory (LSTM) cell implementation from LIBXSMM library (specifically tuned for CPUs) and integrate it into TensorFlow, (ii) we modify GNMT code to use fused time step LSTM op for the encoding stage, (iii) we combine Horovod and Intel MLSL scaling libraries for improved performance on multiple nodes, and (iv) we extend the bucketing logic for grouping similar length sentences together to multiple nodes for achieving load balance across multiple ranks. In summary, we demonstrate that due to these changes we are able to outperform Google's stock CPU-based GNMT implementation by similar to 2x on single node and potentially enable more than 25x speedup using 16 node CPU cluster.
OI Smorkalov, Mikhail/0000-0002-0454-5249
SN 1552-5244
BN 978-1-7281-4734-5
PY 2019
BP 193
EP 202
UT WOS:000518608700021
ER

PT C
AU Vaibhav
   Singh, S
   Stewart, C
   Neubig, G
AF Vaibhav
   Singh, Sumeet
   Stewart, Craig
   Neubig, Graham
GP Assoc Computat Linguist
TI Improving Robustness of Machine Translation with Synthetic Noise
SO 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019),
   VOL. 1
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 02-07, 2019
CL Minneapolis, MN
SP Assoc Computat Linguist, N Amer Chapter, Comp Res Assoc, Comp Community Consortium, Natl Sci Fdn, Natl Rees Council Canada, Google
AB Modern Machine Translation (MT) systems perform remarkably well on clean, in-domain text. However most human generated text, particularly in the realm of social media, is full of typos, slang, dialect, idiolect and other noise which can have a disastrous impact on the accuracy of MT. In this paper we propose methods to enhance the robustness of MT systems by emulating naturally occurring noise in otherwise clean data. Synthesizing noise in this manner we are ultimately able to make a vanilla MT system more resilient to naturally occurring noise, partially mitigating loss in accuracy resulting therefrom (1).
BN 978-1-950737-13-0
PY 2019
BP 1916
EP 1920
UT WOS:000900116902002
ER

PT C
AU Chu, CH
   Dabre, R
   Kurohashi, S
AF Chu, Chenhui
   Dabre, Raj
   Kurohashi, Sadao
BE Barzilay, R
   Kan, MY
TI An Empirical Comparison of Domain Adaptation Methods for Neural Machine
   Translation
SO PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2
CT 55th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 30-AUG 04, 2017
CL Vancouver, CANADA
SP Alibaba Grp, Amazon, Apple, Baidu, Bloomberg, Facebook, Google, Samsung, Tencent, eBay, Elsevier, IBM Res, KPMG, Maluuba, Microsoft, Naver Line, NEC, Recruit Inst Technol, SAP, Adobe, Bosch, CVTE, Duolingo, Huawei, Nuance, Oracle, Sogou, Grammarly, Toutiao, Yandex
AB In this paper, we propose a novel domain adaptation method named "mixed fine tuning" for neural machine translation (NMT). We combine two existing approaches namely fine tuning and multi domain NMT. We first train an NMT model on an out-of-domain parallel corpus, and then fine tune it on a parallel corpus which is a mix of the in-domain and out-of-domain corpora. All corpora are augmented with artificial tags to indicate specific domains. We empirically compare our proposed method against fine tuning and multi domain methods and discuss its benefits and shortcomings.
BN 978-1-945626-76-0
PY 2017
BP 385
EP 391
DI 10.18653/v1/P17-2061
UT WOS:000493992300061
ER

PT C
AU Sahu, S
   Schorr, R
   Medina-Bulo, I
   Wagner, M
AF Sahu, Sneha
   Schorr, Ruth
   Medina-Bulo, Inmaculada
   Wagner, Matthias
BE Cleophas, L
   Massink, M
TI Model Translation from Papyrus-RT into the NUXMV Model Checker
SO SOFTWARE ENGINEERING AND FORMAL METHODS, SEFM 2020
SE Lecture Notes in Computer Science
CT 18th International Conference on Software Engineering and Formal Methods
   (SEFM)
CY SEP 14-18, 2020
CL Ctr Math & Informat, ELECTR NETWORK
HO Ctr Math & Informat
AB Papyrus-RT is an eclipse based modelling tool for embedded systems that makes use of the Model-Driven Engineering approach to generate executable C++ code from UML-RT models. The UML-RT state diagrams are very similar to Finite State Machines used in the NUXMV model checker (an extension of the NuSMV symbolic model checker). In this paper we present an approach for automated verification of the UML-RT models by exporting them mechanically into equivalent NUXMV models with positive results.
RI ; Medina-Bulo, Inmaculada/L-5523-2014
OI Sahu, Sneha/0000-0002-6143-6153; Schorr, Ruth/0000-0001-6917-0284;
   Medina-Bulo, Inmaculada/0000-0002-7543-2671
SN 0302-9743
EI 1611-3349
BN 978-3-030-67220-1; 978-3-030-67219-5
PY 2021
VL 12524
BP 3
EP 20
DI 10.1007/978-3-030-67220-1_1
UT WOS:000723671300001
ER

PT C
AU Chaudhury, S
   Sukhada
   Bharati, A
AF Chaudhury, Sriram
   Sukhada
   Bharati, Akshar
BE Singh, C
   Lehal, GS
   Sengupta, J
   Sharma, DV
   Goyal, V
TI Open Logos Machine Translation: Exploring and Using It in Anusaaraka
   Platform
SO INFORMATION SYSTEMS FOR INDIAN LANGUAGES
SE Communications in Computer and Information Science
CT International Conference on Infirmation Systems for Indian Languages
   (ICISIL 2011)
CY MAR 09-11, 2011
CL Patiala, INDIA
AB Open Logos is the open source version of the Logos Machine Translation System. The current system translates from English and German into the European languages (French, Italian, Spanish and Portuguese). This papers deals with extracting parse and useful linguistic information from English-German Open Logos MT system. Understanding and extracting useful information from linguistic rich diagnosis file is explained in detail. Various parse relations such as POS, clause boundary, dependency, constituent information is extracted and mapped to Paninian format for use in English to Hindi MT system Anusaaraka.
SN 1865-0929
BN 978-3-642-19402-3
PY 2011
VL 139
BP 68
EP 73
UT WOS:000306397600011
ER

PT C
AU Nguyen, LT
   Tran, NL
   Doan, L
   Luong, M
   Nguyen, DQ
AF Linh The Nguyen
   Nguyen Luong Tran
   Long Doan
   Manh Luong
   Dat Quoc Nguyen
GP Int Speech Commun Assoc
TI A High-Quality and Large-Scale Dataset for English-Vietnamese Speech
   Translation
SO INTERSPEECH 2022
SE Interspeech
CT Interspeech Conference
CY SEP 18-22, 2022
CL Incheon, SOUTH KOREA
AB In this paper, we introduce a high-quality and large-scale benchmark dataset for English-Vietnamese speech translation with 508 audio hours, consisting of 331K triplets of (sentence-lengthed audio, English source transcript sentence, Vietnamese target subtitle sentence). We also conduct empirical experiments using strong baselines and find that the traditional "Cascaded" approach still outperforms the modern "End-to-End" approach. To the best of our knowledge, this is the first largescale English-Vietnamese speech translation study. We hope both our publicly available dataset and study can serve as a starting point for future research and applications on English-Vietnamese speech translation.
SN 2308-457X
PY 2022
BP 1726
EP 1730
DI 10.21437/Interspeech.2022-218
UT WOS:000900724501182
ER

PT C
AU Lynn, HM
   Choi, C
   Kim, P
AF Lynn, Htet Myet
   Choi, Chang
   Kim, Pankoo
GP Assoc Comp Machinery
TI Unsupervised Translated Word Sense Disambiguation in Constructing
   Bilingual Lexical Database
SO 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING
CT 33rd Annual ACM Symposium on Applied Computing (ACM SAC)
CY APR 09-13, 2018
CL Univ Pau Pays Adour, Pau, FRANCE
SP Assoc Comp Machinery
HO Univ Pau Pays Adour
AB The performance of a machine translation system depends on the availability of bilingual lexical dictionary and completion of its word sense disambiguation performance. Word sense disambiguation plays a vital role in several applications such as machine translation, information retrieval and many other Natural Language Processing (NLP). In oder to construct a reliable machine translation system, not only consistent lexical database like WordNet (WN), but also word sense distinguished database, and bilingual lexical machine readable dictionary (MRD) are required to achieve an accurate translation. Since WN is for the English language, there have been several approcaches building WN like database for other languages, also known as multilingual WN, by linking and extending bilingual MRDs with synsets from WN. Lexical database like WN for Myanmar languae have been proposed in recent years which are bilingual lexical databases as the synsets from WN are merged with bilingual MRD. However, there are few limitations in constructing bilingual database based on MRD where thesauries are derived from WN yet there are no directed alignemnt of meanings between English and Myanmar language. In order to design a complete lexical database with correct parallel meanings for both languages, our proposed method composes a model which accurately matches the similar meanings between English words and Myanmar words by translating and comparing the word senses for both languages. The experimental result shows that the meanings for both languages are aligned as accurate as the manual alignment of the word senses for lexical database.
OI Choi, Chang/0000-0002-2276-2378
BN 978-1-4503-5191-1
PY 2018
BP 1824
EP 1827
DI 10.1145/3167132.3167431
UT WOS:000455180700256
ER

PT C
AU Liu, Q
   He, ZJ
AF Liu, Qun
   He, Zhongjun
GP IEEE COMPUTER SOC
TI The Maximum Entropy based Rule Selection Model for Statistical Machine
   Translation
SO PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON UNIVERSAL
   COMMUNICATION
CT 2nd International Symposium on Universal Communication
CY DEC 15-16, 2008
CL Osaka, JAPAN
SP Natl Inst Informat & Commun Technol, Res Promot Council Keihanna Info Commun Open Lab, URCF
AB This paper presents a novel rule selection model for statistical machine translation (SMT) that uses the maximum entropy approach to predict target-side for an ambiguous source-side. The maximum entropy based rule selection (MERS) model combines rich contextual information as features, thus can help SMT systems perform context-dependent rule selection. We incorporate the MERS model into two kinds of the state-of-the-art syntax-based SMT models: the hierarchical phrase-based model and the tree-to-string alignment template model. Experiments show that our approach achieves significant improvements over both the baseline systems.
BN 978-0-7695-3433-6
PY 2008
BP 89
EP 96
DI 10.1109/ISUC.2008.85
UT WOS:000263678900012
ER

PT C
AU Suresh, V
   Krishnamurthy, A
   Badrinath, R
   Madhavan, CEV
AF Suresh, V.
   Krishnamurthy, Avanthi
   Badrinath, Rama
   Madhavan, C. E. Veni
BE Gama, J
   Bradley, E
   Hollmen, J
TI A Stylometric Study and Assessment of Machine Translators
SO ADVANCES IN INTELLIGENT DATA ANALYSIS X: IDA 2011
SE Lecture Notes in Computer Science
CT 10th International Symposium on Intelligent Data Analysis
CY OCT 29-31, 2011
CL Univ Porto, Dept Comp Sci, Fac Sci, Porto, PORTUGAL
HO Univ Porto, Dept Comp Sci, Fac Sci
AB In this work we present a statistical approach inspired by stylometry measurement of author style to study the characteristics of machine translators. Our approach quantifies the style of a translator in terms of the properties derived from the distribution of stopwords in its output a standard approach in modern stylometry. Our study enables us to match translated text to the source machine translator that generated them. Also, the stylometric closeness of human generated text to that generated by machine translators provides handles to assess the quality of machine translators.
SN 0302-9743
EI 1611-3349
BN 978-3-642-24799-6
PY 2011
VL 7014
BP 364
EP 375
UT WOS:000306504300034
ER

PT C
AU Guo, YN
   Hu, JF
AF Guo, Yinuo
   Hu, Junfeng
GP Assoc Computat Linguist
TI Meteor++2.0: Adopt Syntactic Level Paraphrase Knowledge into Machine
   Translation Evaluation
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019)
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB This paper describes Meteor++ 2.0, our submission to the WMT19 Metric Shared Task. The well known Meteor metric improves machine translation evaluation by introducing paraphrase knowledge. However, it only focuses on the lexical level and utilizes consecutive n-grams paraphrases. In this work, we take into consideration syntactic level paraphrase knowledge, which sometimes may be skip-grams. We describe how such knowledge can be extracted from Paraphrase Database (PPDB) and integrated into Meteor-based metrics. Experiments on WMT15 and WMT17 evaluation datasets show that the newly proposed metric outperforms all previous versions of Meteor.
BN 978-1-950737-27-7
PY 2019
BP 501
EP 506
UT WOS:000538566200057
ER

PT C
AU Li, L
   Hu, KX
   Tayir, T
   Liu, JQ
   Lee, KA
AF Li, Lin
   Hu, Kaixi
   Tayir, Turghun
   Liu, Jianquan
   Lee, Kong Aik
BE Khanna, S
   Cao, J
   Bai, Q
   Xu, G
TI Noise-Robust Semi-supervised Multi-modal Machine Translation
SO PRICAI 2022: TRENDS IN ARTIFICIAL INTELLIGENCE, PT II
SE Lecture Notes in Computer Science
CT 19th Pacific Rim International Conference on Artificial Intelligence
   (PRICAI)
CY NOV 10-13, 2022
CL Shanghai, PEOPLES R CHINA
AB Recent unsupervised multi-modal machine translation methods have shown promising performance for capturing semantic relationships in unannotated monolingual corpora by large-scale pretraining. Empirical studies show that small accessible parallel corpora can achieve comparable performance gains of large pretraining corpora in unsupervised setting. Inspired by the observation, we think semi-supervised learning can largely reduce the demand of pretraining corpora without performance degradation in low-cost scenario. However, images of parallel corpora typically contain much irrelevant information, i.e., visual noises. Such noises have a negative impact on the semantic alignment between source and target languages in semi-supervised learning, thus weakening the contribution of parallel corpora. To effectively utilize the valuable and expensive parallel corpora, we propose a Noise-robust Semisupervised Multi-modal Machine Translation method (Semi-MMT). In particular, a visual cross-attention sublayer is introduced into source and target language decoders, respectively. And, the representations of texts are used as a guideline to filter visual noises. Based on the visual cross-attention, we further devise a hybrid training strategy by employing four unsupervised and two supervised tasks to reduce the mismatch between the semantic representation spaces of source and target languages. Extensive experiments conducted on the Multi30k dataset show that our method outperforms the state-of-the-art unsupervised methods with large-scale extra corpora for pretraining in terms of METEOR metric, yet only requires 7% parallel corpora.
RI Hu, Kaixi/HNJ-3143-2023
SN 0302-9743
EI 1611-3349
BN 978-3-031-20864-5; 978-3-031-20865-2
PY 2022
VL 13630
BP 155
EP 168
DI 10.1007/978-3-031-20865-2_12
UT WOS:000899329500012
ER

PT C
AU Wagner, A
   Prehofer, C
AF Wagner, Andreas
   Prehofer, Christian
BE Hammoudi, S
   Pires, LF
   Selic, B
   Desfray, P
TI Translating Task Models to State Machines
SO PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MODEL-DRIVEN
   ENGINEERING AND SOFTWARE DEVELOPMENT (MODELSWARD 2016)
CT 4th International Conference on Model-Driven Engineering and Software
   Development (MODELSWARD)
CY FEB 19-21, 2016
CL Rome, ITALY
SP Inst Syst & Technologies Informat, Control & Commun, AIS Special Interest Grp Modeling & Simulat, Open Grp SOA Work Grp, IEEE Comp Soc Tech Comm Business Informat & Syst, IEEE Comp Soc Tech Council Software Engn
AB We present a new method to translate the established and well-known ConcurTaskTree (CTT) task modeling technique into state machines. For this purpose, we develop the concepts of partial state machines, Connectables and a connect operator, which form the theoretical framework for a new algorithm. For the translation, we develop and present a recursive, bottom-up algorithm, which exploits the inherent structure of CTTs and produces valid, partial state machines. This allows new development processes in the model-driven application and system development domain.
BN 978-9-8975-8232-5
PY 2016
BP 201
EP 208
UT WOS:000570754600022
ER

PT C
AU Ping, L
AF Ping, Lv
GP IEEE COMP SOC
TI Mobile Platform Speech Intelligent Recognition and Translation APP
SO 2021 13TH INTERNATIONAL CONFERENCE ON MEASURING TECHNOLOGY AND
   MECHATRONICS AUTOMATION (ICMTMA 2021)
SE International Conference on Measuring Technology and Mechatronics
   Automation
CT 13th International Conference on Measuring Technology and Mechatronics
   Automation (ICMTMA)
CY JAN 16-17, 2021
CL Beihai, PEOPLES R CHINA
SP Huaiyin Inst Technol, Changsha Univ Sci & Technol
AB This paper analyzes the function of voice translation software on mobile platform based on the existing technology. To improve the quality of translation, a phrase based translation statistical model is proposed and the training process is analyzed in detail. Then the architecture of the oral translation system is designed by using the speech recognition function of Android framework and the strategy of multi translation engine coordination. For the problem of data sparseness, we adopt a modeling method which combines the language model based on words and the language model with parts of speech. The log linear model is used to analyze the semantic of corpus annotation. The parameters obtained from training reflect the structural information of sentences. Finally, the actual test on the mobile client shows that the real-time speech translation system can not only effectively speed up the speed of data check and audit, but also appropriately improve the accuracy of speech recognition and ensure the quality of translation work.
SN 2157-1473
BN 978-1-6654-3892-6
PY 2021
BP 595
EP 598
DI 10.1109/ICMTMA52658.2021.00137
UT WOS:000672818900129
ER

PT C
AU Munteanu, DS
   Marcu, D
AF Munteanu, Dragos Stefan
   Marcu, Daniel
GP COLING
TI Extracting Parallel Sub-Sentential Fragments from Non-Parallel Corpora
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present a novel method for extracting parallel sub-sentential fragments from comparable, non-parallel bilingual corpora. By analyzing potentially similar sentence pairs using a signal processing-inspired approach, we detect which segments of the source sentence are translated into segments in the target sentence, and which are not. This method enables us to extract useful machine translation training data even from very non-parallel corpora, which contain no parallel sentence pairs. We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system.
RI Munteanu, Dragos V/AAB-7656-2020
BN 978-1-932432-65-7
PY 2006
BP 81
EP 88
UT WOS:000274500200011
ER

PT J
AU Chon, YV
   Shin, D
   Kim, GE
AF Chon, Yuah V.
   Shin, Dongkwang
   Kim, Go Eun
TI Comparing L2 learners' writing against parallel machine-translated
   texts: Raters' assessment, linguistic complexity and errors
SO SYSTEM
AB Recent developments in machine translation, such as in Google Translate, may help second language (L2) writers produce texts in the target language according to their intended meaning. The aim of the present study was to examine the role of machine translation (MT) in L2 writing. For this purpose, 66 Korean English as a foreign language (EFL) university learners produced compositions in which writing tasks were counterbalanced in three writing modes (i.e., Direct Writing, Self-Translated Writing, and Machine-Translated Writing). The learners' writing products were first graded by independent markers and later submitted for computerized text analyses using BNC-COCA 25000, Coh-Metrix, and SynLex to assess linguistic complexity. The texts were also analyzed for types of errors. The results indicate that MT narrowed the difference of writing ability between the skilled and less skilled learners, facilitated learner use of lower frequency words, and produced syntactically more complex sentences. Error analysis showed a reduction in the quantity of grammatical errors when MT was used to aid L2 writing. However, MT-translated compositions contained more mistranslations and a greater number of poor word choices. The results offer pedagogical implications for using MT for L2 writing. (C) 2020 Elsevier Ltd. All rights reserved.
RI Chon, Yuah/GMW-9647-2022
OI Chon, Yuah/0000-0002-4155-5892; Shin, Dongkwang/0000-0002-5583-0189
SN 0346-251X
EI 1879-3282
PD FEB
PY 2021
VL 96
AR 102408
DI 10.1016/j.system.2020.102408
UT WOS:000615722600008
ER

PT C
AU Anania, FD
   Pena, AE
   Canarache, RM
   Gruionu, LG
AF Anania, Florea Dorel
   Pena, Andra Elena
   Canarache, Radu Marian
   Gruionu, Lucian Gheorghe
BE Gomes, JFS
   Meguid, SA
TI THE DESIGN OF A RECONFIGURABLE MODULAR 5X MILLING MACHINE
SO 7TH INTERNATIONAL CONFERENCE INTEGRITY-RELIABILITY-FAILURE (IRF2020)
CT 7th International Conference on Integrity-Reliability-Failure (IRF)
CY SEP 06-10, 2020
CL Funchal, PORTUGAL
SP Univ Porto, Fac Engn, University of Toronto, MADL, Portuguese Soc Expt Mech, APAET, European Soc Expt Mech, Amer Soc Expt Mech, Japanese Soc Mech Engn, Int Measurement Confederat, European Assoc Dynam Mat, Inst Ciencia & Inovacao Engn Mecanica & Engn Ind, Fundacao Ciencia & Tecnologia, ABREU
AB This paper presents the design and construction of a prototype for a 5-axes desktop CNC reconfigurable and modular milling machine. 5x machine tool can be in three major architecture: table-table, table-head, head-head and some subdivision (table-table at 45(0), table 45(0) -head) according with the order of rotation axis. Our goal is to create a set of modulus for translation and rotation, which can be reconfigurable in order to obtain different machine architecture by using a limited number of assembly elements. The goal is to have a didactical reconfigurable 5x machine tool used in educational activities.
RI GRUIONU, Lucian Gheorghe/F-6121-2011
OI GRUIONU, Lucian Gheorghe/0000-0002-4526-0864
BN 978-989-54756-1-2
PY 2020
BP 395
EP 396
UT WOS:000731040500082
ER

PT J
AU Sharma, VK
   Mittal, N
   Vidyarthi, A
AF Sharma, Vijay Kumar
   Mittal, Namita
   Vidyarthi, Ankit
TI Semantic morphological variant selection and translation disambiguation
   for cross-lingual information retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
AB Cross-Lingual Information Retrieval (CLIR) enables a user to query in a language which is different from the target documents language. CLIR incorporates a translation technique based on either a manual dictionary or a probabilistic dictionary which is generated from a parallel corpus. The translation techniques for Hindi language suffer from a translation mis-mapped issue which is due to the morphological richness of Hindi language. In addition, a word may have multiple translations in a dictionary leading to word translation disambiguation issue. This paper addresses two key findings, i.e., Semantic Morphological Variant Selection (SMVS), and Hybrid Word Translation Disambiguation (HWTD), the former resolves translation mis-mapped issue and the later disambiguates the queries more effectively. The proposed techniques are investigated for FIRE ad-hoc datasets, where SMVS and HWTD at word level achieve better evaluation measures in comparison to the baseline Statistical Machine Translation.
RI Mittal, Namita/AAL-3336-2020; Vidyarthi, Ankit/AAD-4939-2020
OI Mittal, Namita/0000-0001-6886-9974; Vidyarthi, Ankit/0000-0002-8026-4246
SN 1380-7501
EI 1573-7721
PD MAR
PY 2023
VL 82
IS 6
BP 8197
EP 8212
DI 10.1007/s11042-021-11074-w
EA JUN 2021
UT WOS:000660358100002
ER

PT C
AU Wolk, K
   Korzinek, D
   Marasek, K
AF Wolk, Krzysztof
   Korzinek, Danijel
   Marasek, Krzysztof
BE Zgrzywa, A
   Choros, K
   Sieminski, A
TI Semi-automatic and Human-Aided Translation Evaluation Metric (HMEANT)
   for Polish Language in Re-speaking and MT Assessment
SO MULTIMEDIA AND NETWORK INFORMATION SYSTEMS, MISSI 2016
SE Advances in Intelligent Systems and Computing
CT 10th International on Conference Multimedia and Network Information
   Systems (MISSI)
CY SEP 14-16, 2016
CL POLAND
SP Wroclaw Univ Sci & Technol
AB In this article we report the initial results of experiments using HMEANT metric (semi-automatic evaluation metric used for scoring translation quality by matching semantic role fillers) on the Polish language. The metric is evaluated in the task of Machine Translation (MT) and in re-speaking quality assessment. GUI-based annotation interface was developed and with this tool (https:// github. com/ krzwolk/ HMEANT-metric-for-Polish) evaluation was conducted practically by not IT-related personnel. Reliability, correlation with automatic metrics,language independence and time costs were analysed as well. Role labelling and alignment using GUI interface were done by two annotators with no related background (they were only instructed for about 10 min). The results of our experiments showed high inter-annotator agreement as far as role labelling was concerned and a good correlation of the HMEANT metric with human judgements based on re-speaking evaluation.
RI Koržinek, Danijel/K-5168-2014; Wołk, Krzysztof/E-9957-2015; Marasek,
   Krzysztof/H-9949-2014
OI Koržinek, Danijel/0000-0002-2916-4856; Wołk,
   Krzysztof/0000-0001-5030-334X; Marasek, Krzysztof/0000-0003-1344-3524
SN 2194-5357
EI 2194-5365
BN 978-3-319-43982-2; 978-3-319-43981-5
PY 2017
VL 506
BP 241
EP 249
DI 10.1007/978-3-319-43982-2_21
UT WOS:000398736400021
ER

PT S
AU Ahn, K
   Alex, B
   Bos, J
   Dalmas, T
   Leidner, JL
   Smillie, MB
AF Ahn, K
   Alex, B
   Bos, J
   Dalmas, T
   Leidner, JL
   Smillie, MB
BE Peters, C
   Clough, P
   Gonzalo, J
   Jones, GJF
   Kluck, M
   Magnini, B
TI Cross-lingual question answering using off-the-shelf machine translation
SO MULTILINGUAL INFORMATION ACCESS FOR TEXT, SPEECH AND IMAGES
SE Lecture Notes in Computer Science
CT 5th Workshop of the Cross-Language Evaluation Forum
CY SEP 15-17, 2004
CL Bath, ENGLAND
SP Ist Sci Tecnol Informaz
AB We show how to adapt an existing monolingual open-domain QA system to perform in a cross-lingual environment, using off-the-shelf machine translation software. In our experiments we use French and German as source language, and English as target language. For answering factoid questions, our system performs with an accuracy of 16% (German to English) and 20% (French to English), respectively. The loss of correctly answered questions caused by the MT component is estimated at 10% for French, and 15% for German. The accuracy of our system on correctly translated questions is 28% for German and 29% for French.
RI Leidner, Jochen L./AAP-6871-2021
OI Alex, Beatrice/0000-0002-7279-1476
SN 0302-9743
EI 1611-3349
BN 3-540-27420-0
PY 2005
VL 3491
BP 446
EP 457
UT WOS:000231117600044
ER

PT C
AU Caglayan, O
   Madhyastha, P
AF Caglayan, Ozan
   Madhyastha, Pranava
GP Assoc Computat Linguist
TI Probing the Need for Visual Context in Multimodal Machine Translation
SO 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019),
   VOL. 1
CT Conference of the North-American-Chapter of the
   Association-for-Computational-Linguistics - Human Language Technologies
   (NAACL-HLT)
CY JUN 02-07, 2019
CL Minneapolis, MN
SP Assoc Computat Linguist, N Amer Chapter, Comp Res Assoc, Comp Community Consortium, Natl Sci Fdn, Natl Rees Council Canada, Google
AB Current work on multimodal machine translation (MMT) has suggested that the visual modality is either unnecessary or only marginally beneficial. We posit that this is a consequence of the very simple, short and repetitive sentences used in the only available dataset for the task (Multi30K), rendering the source text sufficient as context. In the general case, however, we believe that it is possible to combine visual and textual information in order to ground translations. In this paper we probe the contribution of the visual modality to state-of-the-art MMT models by conducting a systematic analysis where we partially deprive the models from source-side textual context. Our results show that under limited textual context, models are capable of leveraging the visual input to generate better translations. This contradicts the current belief that MMT models disregard the visual modality because of either the quality of the image features or the way they are integrated into the model.
OI Madhyastha, Pranava/0000-0002-4438-8161
BN 978-1-950737-13-0
PY 2019
BP 4159
EP 4170
UT WOS:000900116904034
ER

PT C
AU Sanders, DH
AF Sanders, Donald H.
BE Addison, AC
   Thwaites, H
TI Neural Networks, AI, Phone-based VR, Machine Learning, Computer Vision
   and the CUNAT Automated Translation App - not your father's
   archaeological toolkit
SO 2018 3RD DIGITAL HERITAGE INTERNATIONAL CONGRESS (DIGITALHERITAGE) HELD
   JOINTLY WITH 2018 24TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS &
   MULTIMEDIA (VSMM 2018)
CT 3rd Digital Heritage International Congress (DigitalHERITAGE) / 24th
   International Conference on Virtual Systems and Multimedia (VSMM)
CY OCT 26-30, 2018
CL San Francisco, CA
SP IEEE, IEEE Soc Social Implicat Technol
AB Hundreds of thousands of ancient Mesopotamian legal treatises, beer recipes, religious rituals, international treaties, medical records, astronomical observations, and mathematical problems-texts that tell us exactly what happened in the words of the very people whose actions formed our shared cultural history-languish untranslated, because there are too many of them, translation takes too long, and there are too few linguistic experts. And thousands more tablets are uncovered every year. This paper describes our CUNAT (the CUNeiform Automated Translator) app and how it sets out to use unconventional (for archaeology) approaches to solving the translation problem. CUNAT will allow anyone to create virtual reality models of complex inscribed artifacts and automatically extract meaning from them more effectively and quickly than existing tools. The app uses photogrammetry, computer vision, AI, and neural networks to complete the tasks.
BN 978-1-7281-0292-4
PY 2018
BP 333
EP 337
UT WOS:000702153800057
ER

PT J
AU Chang, Y
   Chen, DT
   Zhang, Y
   Yang, J
AF Chang, Yi
   Chen, Datong
   Zhang, Ying
   Yang, Jie
TI An image-based automatic Arabic translation system
SO PATTERN RECOGNITION
AB In this paper, we present a system that automatically translates Arabic text embedded in images into English. The system consists of three components: text detection from images, character recognition, and machine translation. We formulate the text detection as a binary classification problem and apply gradient boosting tree (GBT), support vector machine (SVM), and location-based prior knowledge to improve the F1 score of text detection from 78.95% to 87.05%. The detected text images are processed by off-the-shelf optical character recognition (OCR) software. We employ an error correction model to post-process the noisy OCR Output, and apply a bigram language model to reduce word segmentation errors. The translation module is tailored with compact data structure for hand-held devices. The experimental results show substantial improvements in both word recognition accuracy and translation quality. For instance, in the experiment of Arabic transparent font, the BLEU score increases from 18.70 to 33.47 with use of the error correction module. Published by Elsevier Ltd.
SN 0031-3203
PD SEP
PY 2009
VL 42
IS 9
BP 2127
EP 2134
DI 10.1016/j.patcog.2008.10.031
UT WOS:000267089000040
ER

PT C
AU Sun, HR
   Lei, YK
   Xiong, DY
AF Sun, Haoran
   Lei, Yikun
   Xiong, Deyi
BE Tong, R
   Lu, Y
   Dong, M
   Gong, W
   Li, H
TI Multilingual Neural Machine Transliteration with Adaptive Segmentation
   Schemes
SO 2022 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP 2022)
SE International Conference on Asian Language Processing
CT 26th International Conference on Asian Language Processing (IALP)
CY OCT 27-28, 2022
CL Shenzhen, PEOPLES R CHINA
SP IEEE, Chinese Univ Hong Kong, Chinese & Oriental Languages Informat Proc Soc, IEEE Singapore SMC Chapter, IEEE Syst, Man, & Cybernet Soc
AB The lack of training data and divergences in the phonological structures of languages pose challenges to machine transliteration. In this paper, we present a multilingual neural machine transliteration framework to encourage knowledge transfer from high-resource languages and low-resource languages. In order to mitigate the phonological divergence issue, we propose to use different segmentation schemes that are adaptive to the source or the target language. Experiment results on public datasets demonstrate that multilingual neural machine transliteration significantly outperforms bilingual transliteration on both mid- and low-resource languages and that segmentation schemes have a great impact on transliteration quality.
SN 2159-1962
EI 2159-1970
BN 978-1-6654-7674-4
PY 2022
BP 494
EP 499
DI 10.1109/IALP57159.2022.9961282
UT WOS:000896159700084
ER

PT J
AU Goyal, V
   Kumar, A
   Lehal, MS
AF Goyal, Vishal
   Kumar, Ajit
   Lehal, Manpreet Singh
TI Document Alignment for Generation of English-Punjabi Comparable Corpora
   from Wikipedia
SO INTERNATIONAL JOURNAL OF E-ADOPTION
AB Comparable corpora come as an alternative to parallel corpora for the languages where the parallel corpora is scarce. The efficiency of the models trained on comparable corpora is comparatively less to that of the parallel corpora however it helps to compensate much to the machine translation. In this article, the authors have explored Wikipedia as a potential source and delineated the process of alignment of documents which will be further used for the extraction of parallel data. The parallel data thus extracted will help to enhance the performance of Statistical Machine translation.
RI Goyal, Vishal/I-5538-2015
OI Goyal, Vishal/0000-0003-2269-7606
SN 1937-9633
EI 1937-9641
PD JAN-JUN
PY 2020
VL 12
IS 1
SI SI
BP 42
EP 51
DI 10.4018/IJEA.2020010104
UT WOS:000518420500004
ER

PT C
AU Zhou, MY
   Cheng, RX
   Lee, YJ
   Yu, Z
AF Zhou, Mingyang
   Cheng, Runxiang
   Lee, Yong Jae
   Yu, Zhou
GP Assoc Computat Linguist
TI A Visual Attention Grounding Neural Model for Multimodal Machine
   Translation
SO 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2018)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY OCT 31-NOV 04, 2018
CL Brussels, BELGIUM
SP Google, Facebook, Bloomberg, Salesforce, Apple, Amazon, Baidu, Grammarly, Naver Labs Europe, FWO, KU Leuven, Dept Comp Sci, CVTE, Ebay, Microsoft, Naver Line, Oracle, Polya, Huawei, Duolingo, Figure Eight, Nuance
AB We introduce a novel multimodal machine translation model that utilizes parallel visual and textual information. Our model jointly optimizes the learning of a shared visual-language embedding and a translator. The model leverages a visual attention grounding mechanism that links the visual semantics with the corresponding textual semantics. Our approach achieves competitive state-of-the-art results on the Multi30K and the Ambiguous COCO datasets. We also collected a new multilingual multimodal product description dataset to simulate a real-world international online shopping scenario. On this dataset, our visual attention grounding model outperforms other methods by a large margin.
BN 978-1-948087-84-1
PY 2018
BP 3643
EP 3653
UT WOS:000865723403089
ER

PT C
AU Caswell, I
   Chelba, C
   Grangier, D
AF Caswell, Isaac
   Chelba, Ciprian
   Grangier, David
GP Assoc Computat Linguist
TI Tagged Back-Translation
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 1: RESEARCH
   PAPERS
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB Recent work in Neural Machine Translation (NMT) has shown significant quality gains from noised-beam decoding during back-translation, a method to generate synthetic parallel data. We show that the main role of such synthetic noise is not to diversify the source side, as previously suggested, but simply to indicate to the model that the given source is synthetic. We propose a simpler alternative to noising techniques, consisting of tagging back-translated source sentences with an extra token. Our results on WMT outperform noised back-translation in English-Romanian and match performance on English-German, re-defining state-of-the-art in the former.
OI Grangier, David/0000-0002-8847-9532
BN 978-1-950737-27-7
PY 2019
BP 53
EP 63
UT WOS:000538567400006
ER

PT J
AU Kishida, K
AF Kishida, K
TI Technical issues of cross-language information retrieval: a review
SO INFORMATION PROCESSING & MANAGEMENT
AB This paper reviews state-of-the-art techniques and methods for enhancing effectiveness of cross-language information retrieval (CLIR). The following research issues are covered: (1) matching strategies and translation techniques, (2) methods for solving the problem of translation ambiguity, (3) formal models for CLIR such as application of the language model, (4) the pivot language approach, (5) methods for searching multilingual document collection, (6) techniques for combining multiple language resources, etc. (C) 2004 Elsevier Ltd. All rights reserved.
SN 0306-4573
EI 1873-5371
PD MAY
PY 2005
VL 41
IS 3
BP 433
EP 455
DI 10.1016/j.ipm.2004.06.007
UT WOS:000226297800002
ER

PT J
AU Miyagawa, N
   Watanabe, M
   Matsuyama, T
   Koyama, Y
   Moriuchi, T
   Hirao, T
   Furusho, Y
   Takata, T
AF Miyagawa, Norihito
   Watanabe, Masahiro
   Matsuyama, Takanori
   Koyama, Yasuhito
   Moriuchi, Toshiyuki
   Hirao, Toshikazu
   Furusho, Yoshio
   Takata, Toshikazu
TI Successive catalytic reactions specific to Pd-based rotaxane complexes
   as a result of wheel translation along the axle
SO CHEMICAL COMMUNICATIONS
AB Rotaxane-structure-specific Pd-catalyzed rearrangement of propargyl or allyl urethane groups to oxazolidinone moieties proceeded efficiently. The conversion took place successively by the translation of the wheel along the axle, thus providing a novel macrocyclic catalytic system.
RI Moriuchi, Toshiyuki/M-9494-2015; Koyama, Yasuhito/U-4098-2019; Takata,
   Toshikazu/S-7845-2018
OI Moriuchi, Toshiyuki/0000-0002-5884-0489; Koyama,
   Yasuhito/0000-0002-6985-4499
SN 1359-7345
EI 1364-548X
PY 2010
VL 46
IS 11
BP 1920
EP 1922
DI 10.1039/b917053g
UT WOS:000275099600035
PM 20198253
ER

PT J
AU Lakshmi, BSS
   Shambhavi, BR
AF Lakshmi, B. S. Sowmya
   Shambhavi, B. R.
TI LEARNING TO TRANSLATE KANNADA AND ENGLISH QUERIES FOR MIXED SCRIPT
   INFORMATION RETRIEVAL
SO COMPUTING AND INFORMATICS
AB Due to increase in the availability of numerous languages in the Web, cross language information retrieval is one of the happening issues in the field of natural language processing and information retrieval. Nowadays, people are habituated to combine two or more language words during oral or written discourse. Speakers have also employed intermixing of different languages and scripts in digital media while querying, blogging and on social media platforms. The way of representing two different language words of an utterance in their native scripts is known as mixed scripting. In the present work, we attempted to translate mixed script queries of Kannada and English languages into monolingual queries. We proposed three approaches for translation by constructing bilingual dictionary, word embeddings and Google translate. The proposed method outperforms the conventional dictionary based approach, when word embeddings were combined with the translations learnt from Google Translate and Dictionary.
RI , Shambhavi B R/P-2798-2015
OI , Shambhavi B R/0000-0002-3389-4253
SN 1335-9150
PY 2021
VL 40
IS 3
BP 628
EP 647
DI 10.31577/cai_2021_3_628
UT WOS:000726531500007
ER

PT C
AU Tu, ZP
   Xie, J
   Lv, YJ
   Liu, Q
AF Tu, Zhaopeng
   Xie, Jun
   Lv, Yajuan
   Liu, Qun
BE Zhou, G
   Li, J
   Zhao, D
   Feng, Y
TI A Simple, Fast Strategy for Weighted Alignment Hypergraph
SO NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING, NLPCC 2013
SE Communications in Computer and Information Science
CT 2nd Annual Conference of China-Computer-Federation
   Technical-Committee-of-Chinese-Information on Natural Language
   Processing and Chinese Computing (CCF TCCI NLPCC)
CY NOV 15-19, 2013
CL Chongqing Univ, State Key Lab Digital Publishing, Chongqing, PEOPLES R
   CHINA
SP China Comp Federat, Tech Comm Chinese Informat, Peking Univ, Microsoft Res Asia, Tsinghua Univ, ACTA Scientiarum Naturalium Univ Pekinensis, Sogou Inc, Sina Weibo, Tencent Weibo, Sichuan Inst Comp Sci, Mingbo Educ Technol, Springer, China Comp Federat
HO Chongqing Univ, State Key Lab Digital Publishing
AB Weighted alignment hypergraph [4] is potentially useful for statistical machine translation, because it is the first study to simultaneously exploit the compact representation and fertility model of word alignment. Since estimating the probabilities of rules extracted from hypergraphs is an NP-complete problem, they propose a divide-and-conquer strategy by decomposing a hypergraph into a set of independent subhypergraphs. However, they employ a Bull's algorithm to enumerate all consistent alignments for each rule in each subhypergraph, which is very time-consuming especially for the rules that contain non-terminals. This limits the applicability of this method to the syntax translation models, the rules of which contain many non-terminals (e. g. SCFG rules). In response to this problem, we propose an inside-outside algorithm to efficiently enumerate the consistent alignments. Experimental results show that our method is twice as fast as the Bull's algorithm. In addition, the efficient dynamic programming algorithm makes our approach applicable to syntax-based translation models.
RI Tu, Zhaopeng/AAS-4259-2021
SN 1865-0929
EI 1865-0937
BN 978-3-642-41643-9; 978-3-642-41644-6
PY 2013
VL 400
BP 188
EP 199
UT WOS:000329580900018
ER

PT S
AU Pico, D
   Tomas, J
   Casacuberta, F
AF Pico, D
   Tomas, J
   Casacuberta, F
BE Fred, A
   Caelli, T
   Duin, RPW
   Campilho, A
   DeRidder, D
TI GIATI: A general methodology for finite-state translation using
   alignments
SO STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION, PROCEEDINGS
SE LECTURE NOTES IN COMPUTER SCIENCE
CT 10th International Workshop on Structural and Syntactic Pattern
   Recognition/5th International Conference on Statistical Techniques in
   Pattern Recognition
CY AUG 18-20, 2004
CL Lisbon, PORTUGAL
SP Inst Telecommun, Inst Super Tecn, Int Assoc Pattern Recognit, Fund Luso-Amer Desenvolvimento
AB Statistical techniques for machine translation have experienced an increasing interest by the natural language research community in the last years. Both statistical language modeling and statistical machine translation are now well-established disciplines with solid basis and outstanding results. On the other hand, finite-state transducers have revealed as an efficient and flexible formalism for the representation of a wide range of the kind of information that arises in natural language processing.
   This paper presents a powerful general framework for combining statistical techniques with grammatical inference and finite-state traducers. The GIATI methodology proposed here provides a schema for building inference algorithms that are able to generate finite-state transducers from parallel corpora of text making use of information supplied by robust statistical techniques such as n-grams and alignments. Here, the general method is presented together with two concrete inference algorithms and some experiments that show the validity of the GIATI framework for real-world translation tasks.
SN 0302-9743
BN 3-540-22570-6
PY 2004
VL 3138
BP 216
EP 223
UT WOS:000223398900022
ER

PT C
AU Bazydlo, G
   Adamski, M
   Stefanowicz, L
AF Bazydlo, Grzegorz
   Adamski, Marian
   Stefanowicz, Lukasz
GP IEEE
TI Translation UML diagrams into Verilog
SO 2014 7TH INTERNATIONAL CONFERENCE ON HUMAN SYSTEM INTERACTIONS (HSI)
SE Conference on Human System Interaction
CT 7th International Conference on Human System Interactions (HSI)
CY JUN 16-18, 2014
CL Lisbon, PORTUGAL
SP Inst Elect & Elect Engineers, IEEE Ind Elect Soc, Inst Dev New Technologies, Nova Univ Lisbon, Fac Sci & Technol
AB The paper presents a method of using the UML state machine diagrams for specification of programs of logic controllers. The proposed method allows transformation from UML state machine diagram, using temporal Hierarchical Concurrent Finite State Machine (HCFSM) model, into Verilog hardware specification. The generated behavioral description in Hardware Description Language can afterwards be simulated, synthesized and implemented into e.g. FPGA device. A practical example illustrating the successive stages of the proposed method was also presented.
RI Bazydło, Grzegorz/A-2646-2015; Stefanowicz, Łukasz/A-1489-2015
OI Bazydło, Grzegorz/0000-0003-3103-4767; Stefanowicz,
   Łukasz/0000-0001-6959-4861
SN 2158-2246
BN 978-1-4799-4714-0
PY 2014
BP 267
EP 271
DI 10.1109/HSI.2014.6860487
UT WOS:000345791900041
ER

PT C
AU Catrina, D
   Ghionea, A
   Constantin, G
   Luncu, B
AF Catrina, Dumitru
   Ghionea, Adrian
   Constantin, George
   Luncu, Bogdan
BE Katalinc, B
TI FORMALISM OF INDUSTRIAL ROBOTS KINEMATICS APPLIED TO NUMERICAL COMMAND
   LATHES
SO ANNALS OF DAAAM FOR 2008 & PROCEEDINGS OF THE 19TH INTERNATIONAL DAAAM
   SYMPOSIUM
SE Annals of DAAAM and Proceedings
CT 19th International Symposium of the
   Danube-Adria-Association-for-Automation-and-Manufacturing
CY OCT 22-25, 2008
CL Trnava, SLOVAKIA
AB This paper presents a study concerning kinematics analysis method used in CNC machine-tools. Some lathe structures are analyzed having revolution (R) and translation (T) joints similar to industrial robots, that enable generation motions combined for generating trajectories that define the machined surfaces. This method is intended to be applied to different types of machine tools, and gives an instrument for easy choice of the machine for generating certain surfaces.
RI Constantin, George/U-5113-2019
OI Constantin, George/0000-0003-0568-8417
SN 1726-9679
BN 978-3-901509-68-1
PY 2008
BP 219
EP 220
UT WOS:000262860100109
ER

PT S
AU Han, XG
   Chen, WY
   Huang, B
   Wang, SH
AF Han, XG
   Chen, WY
   Huang, B
   Wang, SH
BE Cai, G
   Xu, XP
   Kang, R
TI Development of a virtual axis cutter grinder
SO ADVANCES IN GRINDING AND ABRASIVE TECHNOLOGY XIII
SE KEY ENGINEERING MATERIALS
CT 13th Conference on Abrasive Technology in China
CY AUG 20-22, 2005
CL Shenyang, PEOPLES R CHINA
SP China Comm Abras Technol
AB dThe development of a virtual axis cutter grinder was introduced. The main contents of this paper include layout design, parameters design method, control system and program system. The purpose of the development of the parallel machine tools is for cutter grinding. The dimension of the cutter and the translation workspace for cutter grinding usually is small and is therefore suitable for the parallel machine tool application. The new machine tool has high rigidity and good precision.
SN 1013-9826
PY 2006
VL 304-305
BP 483
EP 487
DI 10.4028/www.scientific.net/KEM.304-305.483
UT WOS:000236491500101
ER

PT C
AU Zhang, ZR
   Wu, SZ
   Liu, SJ
   Li, M
   Zhou, M
   Xu, T
AF Zhang, Zhirui
   Wu, Shuangzhi
   Liu, Shujie
   Li, Mu
   Zhou, Ming
   Xu, Tong
GP AAAI
TI Regularizing Neural Machine Translation by Target-Bidirectional
   Agreement
SO THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 33rd AAAI Conference on Artificial Intelligence / 31st Innovative
   Applications of Artificial Intelligence Conference / 9th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY JAN 27-FEB 01, 2019
CL Honolulu, HI
SP Assoc Advancement Artificial Intelligence
AB Although Neural Machine Translation (NMT) has achieved remarkable progress in the past several years, most NMT systems still suffer from a fundamental shortcoming as in other sequence generation tasks: errors made early in generation process are fed as inputs to the model and can be quickly amplified, harming subsequent sequence generation. To address this issue, we propose a novel model regularization method for NMT training, which aims to improve the agreement between translations generated by left-to-right (L2R) and right-to-left (R2L) NMT decoders. This goal is achieved by introducing two Kullback-Leibler divergence regularization terms into the NMT training objective to reduce the mismatch between output probabilities of L2R and R2L models. In addition, we also employ a joint training strategy to allow L2R and R2L models to improve each other in an interactive update process. Experimental results show that our proposed method significantly outperforms state-of-the-art baselines on Chinese-English and English-German translation tasks.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-809-1
PY 2019
BP 443
EP 450
UT WOS:000485292600055
ER

PT C
AU Ovodenko, A
   Bezzateev, S
   Mukhina, O
   Andreeva, E
   Ivanova, A
   Vlasova, O
   Goncova, A
AF Ovodenko, A.
   Bezzateev, S.
   Mukhina, O.
   Andreeva, E.
   Ivanova, A.
   Vlasova, O.
   Goncova, A.
BE Tan, DY
TI Methodology of using distributed systems in advanced-level language
   learning
SO PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON ADVANCED ICT AND
   EDUCATION
SE Advances in Intelligent Systems Research
CT International Conference on Advanced Information and Communication
   Technology for Education (ICAICTE)
CY SEP 20-22, 2013
CL Hainan, PEOPLES R CHINA
SP Int Assoc Cyber Sci & Engn
AB Development of information and internet technology has led to the appearance of distributed systems in different spheres of human life. Distributed systems are created to simplify and accelerate business processes, which is relevant in the translation industry. Nowadays for professional translator is not enough to have excellent knowledge of the language, he should be able to work with the translation tool: CAT, machine translation, translation memory. The paper illustrates methodology of using distributed systems in advanced-level language and shows an example of realization education programme in Saint-Petersburg State University of Aerospace Instrumentation.
RI Bezzateev, Sergey/M-2570-2013
OI Bezzateev, Sergey/0000-0002-0924-6221
SN 1951-6851
BN 978-90786-77-79-6
PY 2013
VL 33
BP 646
EP 648
UT WOS:000327670900130
ER

PT C
AU Chen, LQ
   Li, JH
   Gong, ZX
   Chen, BX
   Luo, WH
   Zhang, M
   Zhou, GD
AF Chen, Linqing
   Li, Junhui
   Gong, Zhengxian
   Chen, Boxing
   Luo, Weihua
   Zhang, Min
   Zhou, Guodong
GP Assoc Computat Linguist
TI Breaking Corpus Bottleneck for Context-Aware Neural Machine Translation
   with Cross-Task Pre-training
SO 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND
   THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING
   (ACL-IJCNLP 2021), VOL 1
CT Joint Conference of 59th Annual Meeting of the
   Association-for-Computational-Linguistics (ACL) / 11th International
   Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop
   on Representation Learning for NLP (RepL4NLP)
CY AUG 01-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS
AB Context-aware neural machine translation (NMT) remains challenging due to the lack of large-scale document-level parallel dataset. To break the corpus bottleneck, in this paper we aim to improve context-aware NMT by taking the advantage of the availability of both large-scale sentence-level parallel dataset and source-side monolingual documents.1 To this end, we propose two pre-training tasks. One learns to translate a sentence from source language to target language on the sentencelevel parallel dataset while the other learns to translate a document from deliberately noised to original on the monolingual documents. Importantly, the two pre-training tasks are jointly and simultaneously learned via the same model, thereafter fine-tuned on scalelimited parallel documents from both sentencelevel and document-level perspectives. Experimental results on four translation tasks show that our approach significantly improves translation performance. One nice property of our approach is that the fine-tuned model can be used to translate both sentences and documents.
RI 贡, 正仙/HNJ-1571-2023
BN 978-1-954085-52-7
PY 2021
BP 2851
EP 2861
UT WOS:000698679200022
ER

PT C
AU Huang, XY
   Xiong, J
AF Huang, Xinyan
   Xiong, Jing
GP IEEE Computer Society
TI Establishment and Management of the English-Chinese Ontology Based on
   the Bilingual Corpus
SO PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT,
   INNOVATION MANAGEMENT AND INDUSTRIAL ENGINEERING, VOL III
CT 1st International Conference on Information Management, Innovation
   Management and Industrial Engineering
CY DEC 19-21, 2008
CL Taipei, TAIWAN
SP Natl Taiwan Univ Sci & Technol, Shanghai Jiaotong Univ, Huazhong Normal Univ, Xian Univ Technol
AB English-Chinese ontology is of great importance to such fields as CLIR, machine aided translation and language leaming et al. Now, there are some perfect kinds of English ontology in foreign and some malum bilingual corpus in civil which can be used to build a new kind of English-Chinese ontology. The word translation probabilities was calculated by 4 common co-occurrence models in bilingual corpus and the translation equivalences was extracted according to translation probabilities The English ontology described by OWL was analyzed by Jena, and MySQL database is used to store ontology resource.
RI Jing, Xiong/AAN-3209-2020
OI Jing, Xiong/0000-0002-3604-9645
BN 978-0-7695-3435-0
PY 2008
BP 27
EP +
DI 10.1109/ICIII.2008.217
UT WOS:000263702200006
ER

PT C
AU He, ZW
   Wang, X
   Wang, R
   Shi, SM
   Tu, ZP
AF He, Zhiwei
   Wang, Xing
   Wang, Rui
   Shi, Shuming
   Tu, Zhaopeng
GP Assoc Computat Linguist
TI Bridging the Data Gap between Training and Inference for Unsupervised
   Neural Machine Translation
SO PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS)
CT 60th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY MAY 22-27, 2022
CL Dublin, IRELAND
SP Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple
AB Back-translation is a critical component of Unsupervised Neural Machine Translation (UNMT), which generates pseudo parallel data from target monolingual data. A UNMT model is trained on the pseudo parallel data with translated source, and translates natural source sentences in inference. The source discrepancy between training and inference hinders the translation performance of UNMT models. By carefully designing experiments, we identify two representative characteristics of the data gap in source: (1) style gap (i.e., translated vs. natural text style) that leads to poor generalization capability; (2) content gap that induces the model to produce hallucination content biased towards the target language. To narrow the data gap, we propose an online self-training approach, which simultaneously uses the pseudo parallel data {natural source, translated target} to mimic the inference scenario. Experimental results on several widelyused language pairs show that our approach outperforms two strong baselines (XLM and MASS) by remedying the style and content gaps. (1)
BN 978-1-955917-21-6
PY 2022
BP 6611
EP 6623
UT WOS:000828702306052
ER

PT C
AU Yang, PC
   Chen, BX
   Zhang, P
   Sun, X
AF Yang, Pengcheng
   Chen, Boxing
   Zhang, Pei
   Sun, Xu
GP Assoc Advancement Artificial Intelligence
TI Visual Agreement Regularized Training for Multi-Modal Machine
   Translation
SO THIRTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THE
   THIRTY-SECOND INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE
   CONFERENCE AND THE TENTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN
   ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
CT 34th AAAI Conference on Artificial Intelligence / 32nd Innovative
   Applications of Artificial Intelligence Conference / 10th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 07-12, 2020
CL New York, NY
SP Assoc Advancement Artificial Intelligence
AB Multi-modal machine translation aims at translating the source sentence into a different language in the presence of the paired image. Previous work suggests that additional visual information only provides dispensable help to translation, which is needed in several very special cases such as translating ambiguous words. To make better use of visual information, this work presents visual agreement regularized training. The proposed approach jointly trains the source-to-target and target-to-source translation models and encourages them to share the same focus on the visual information when generating semantically equivalent visual words (e.g. "ball" in English and "ballon" in French). Besides, a simple yet effective multi-head co-attention model is also introduced to capture interactions between visual and textual features. The results show that our approaches can outperform competitive baselines by a large margin on the Multi30k dataset. Further analysis demonstrates that the proposed regularized training can effectively improve the agreement of attention on the image, leading to better use of visual information.
SN 2159-5399
EI 2374-3468
BN 978-1-57735-835-0
PY 2020
VL 34
BP 9418
EP 9425
UT WOS:000668126801106
ER

PT J
AU Sun, PF
   Bon, P
   Collart-Dutilleul, S
AF Sun, Pengfei
   Bon, Philippe
   Collart-Dutilleul, Simon
TI A Joint Development of Coloured Petri Nets and the B Method in Critical
   Systems
SO JOURNAL OF UNIVERSAL COMPUTER SCIENCE
AB Model transformation is an interesting task, which could take advantage of several modelling languages, and meanwhile should respect all the safety requirements. The presented work studies the translation from a valid design solution to a valid implementation, which is a mapping method from coloured Petri nets to abstract B machines. Both modelling languages are well known formal methods in the context of safety requirement engineering. The Petri nets are widely accepted by French railway engineers because of a fine graphic representation and their dynamic analysis properties. The B machine offers verified software development based on B language, which has already been applied in some safety-critical systems. The proposed model translation technique will help to bridge the gap between these two formal methods. This paper shows the systematic process of the translation, which is also illustrated by several case studies. The limitations and future efforts are discussed at the end of the paper.
SN 0948-695X
PY 2015
VL 21
IS 12
BP 1654
EP 1683
DI 10.3217/jucs-021-12-1654
UT WOS:000368458100007
ER

PT C
AU Pu, X
   Mascarell, L
   Popescu-Belis, A
   Fishel, M
   Luong, NQ
   Volk, M
AF Pu, Xiao
   Mascarell, Laura
   Popescu-Belis, Andrei
   Fishel, Mark
   Ngoc-Quang Luong
   Volk, Martin
GP Assoc Computat Linguist
TI Leveraging Compounds to Improve Noun Phrase Translation from Chinese and
   German
SO 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND
   THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING:
   PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP (ACL-IJCNLP 2015)
CT 53rd Annual Meeting of the Association-for-Computational-Linguistics /
   7th International Joint Conference on Natural Language Processing
   (ACJ-IJCNLP)
CY JUL 28, 2015
CL Beijing, PEOPLES R CHINA
SP Assoc Computat Linguist, BAOBAG Language Solut, Google, Don & Betty Walker Scholarship, Natl Sci Fdn
AB This paper presents a method to improve the translation of polysemous nouns, when a previous occurrence of the noun as the head of a compound noun phrase is available in a text. The occurrences are identified through pattern matching rules, which detect XY compounds followed closely by a potentially coreferent occurrence of Y, such as "Nordwand ... Wand". Two strategies are proposed to improve the translation of the second occurrence of Y: re-using the cached translation of Y from the XY compound, or post-editing the translation of Y using the head of the translation of XY. Experiments are performed on Chinese-to-English and German-to-French statistical machine translation, over the WIT3 and Text+Berg corpora respectively, with 261 XY/Y pairs each. The results suggest that while the overall BLEU scores increase only slightly, the translations of the targeted polysemous nouns are significantly improved.
RI Fishel, Mark/AAN-5245-2020; Popescu-Belis, Andrei/P-2246-2017
OI Volk, Martin/0000-0002-2063-4516; Popescu-Belis,
   Andrei/0000-0003-4934-2071
BN 978-1-941643-74-7
PY 2015
BP 8
EP 15
UT WOS:000521477500002
ER

PT C
AU Moradi, P
   Kambhatla, N
   Sarkar, A
AF Moradi, Pooya
   Kambhatla, Nishant
   Sarkar, Anoop
GP ASSOC COMPUTAT LINGUIST
TI Training with Adversaries to Improve Faithfulness of Attention in Neural
   Machine Translation
SO AACL-IJCNLP 2020: THE 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE
   ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL
   JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE
   STUDENT RESEARCH WORKSHOP
CT 1st Conference of the
   Asia-Pacific-Chapter-of-the-Association-for-Computational-Linguistics
   (AACL) / 10th International Joint Conference on Natural Language
   Processing (IJCNLP)
CY DEC 04-07, 2020
CL Suzhou, PEOPLES R CHINA
SP Assoc Computat Linguist, Asia Pacific Chapter
AB Can we trust that the attention heatmaps produced by a neural machine translation (NMT) model reflect its true internal reasoning? We isolate and examine in detail the notion of faithfulness in NMT models. We provide a measure of faithfulness for NMT based on a variety of stress tests where model parameters are perturbed and measuring faithfulness based on how often the model output changes. We show that our proposed faithfulness measure for NMT models can be improved using a novel differentiable objective that rewards faithful behaviour by the model through probability divergence. Our experimental results on multiple language pairs show that our objective function is effective in increasing faithfulness and can lead to a useful analysis of NMT model behaviour and more trustworthy attention heatmaps. Our proposed objective improves faithfulness without reducing the translation quality and it also seems to have a useful regularization effect on the NMT model and can even improve translation quality in some cases.
BN 978-1-952148-93-4
PY 2020
BP 86
EP 93
UT WOS:000856437200013
ER

PT C
AU Moradi, P
   Kambhatla, N
   Sarkar, A
AF Moradi, Pooya
   Kambhatla, Nishant
   Sarkar, Anoop
GP Assoc Computat Linguist
TI Measuring and Improving Faithfulness of Attention in Neural Machine
   Translation
SO 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (EACL 2021)
CT 16th Conference of the
   European-Chapter-of-the-Association-for-Computational-Linguistics (EACL)
CY APR 19-23, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, European Chapter, Grammarly, Facebook AI, Bloomberg Engn, LegalForce, Babelscape
AB While the attention heatmaps produced by neural machine translation (NMT) models seem insightful, there is little evidence that they reflect a model's true internal reasoning. We provide a measure of faithfulness for NMT based on a variety of stress tests where attention weights which are crucial for prediction are perturbed and the model should alter its predictions if the learned weights are a faithful explanation of the predictions. We show that our proposed faithfulness measure for NMT models can be improved using a novel differentiable objective that rewards faithful behaviour by the model through probability divergence. Our experimental results on multiple language pairs show that our objective function is effective in increasing faithfulness and can lead to a useful analysis of NMT model behaviour and more trustworthy attention heatmaps. Our proposed objective improves faithfulness without reducing the translation quality and has a useful regularization effect on the NMT model and can even improve translation quality in some cases.
BN 978-1-954085-02-2
PY 2021
BP 2791
EP 2802
UT WOS:000863557002079
ER

PT C
AU Patel, CO
   Cimino, JJ
AF Patel, Chintan O.
   Cimino, James J.
BE Kuhn, KA
   Warren, JR
   Leong, TY
TI A Scale-Free Network View of the UMLS to Learn Terminology Translations
SO MEDINFO 2007: PROCEEDINGS OF THE 12TH WORLD CONGRESS ON HEALTH (MEDICAL)
   INFORMATICS, PTS 1 AND 2: BUILDING SUSTAINABLE HEALTH SYSTEMS
SE Studies in Health Technology and Informatics
CT 12th World Congress on Health (Medical) Informatics
CY AUG 20-24, 2007
CL Brisbane, AUSTRALIA
SP Hlth Informat Soc Australia
AB The UMLS Metathesaurus belongs to the class of scale-free networks with few concept hubs possessing a large number of relationships. The hubs provide useful links between the concepts from disparate terminologies in the UMLS: however, they also exponentially increase the number of possible transitive cross-terminology paths.
   Towards the goal of using machine learning to rank cross-terminology translations, we propose a traversal algorithm that exploits the scale-free property of the UMLS to reduce the number of candidate translations. We characterize the concept hubs into "informational" and "noisy" concept hubs and provide an automated method to detect them.
   Using gold standard mappings from SNOMED-CT to ICD9CM, we found an average 20-fold reduction in the number of candidate mappings while achieving comparable recall and ranking results. A hub-driven traversal strategy provides a promising approach to generate high quality cross-terminology translations from the UMLS.
OI Cimino, James/0000-0003-4101-1622
SN 0926-9630
EI 1879-8365
BN 978-1-58603-774-1
PY 2007
VL 129
BP 689
EP +
UT WOS:000272064000139
PM 17911805
ER

PT C
AU Hori, C
   Zhao, B
   Vogel, S
   Waibel, A
AF Hori, Chiori
   Zhao, Bing
   Vogel, Stephan
   Waibel, Alex
GP IEEE
TI Consolidation based speech translation
SO 2007 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING,
   VOLS 1 AND 2
CT IEEE Workshop on Automatic Speech Recognition and Understanding
CY DEC 09-13, 2007
CL Kyoto, JAPAN
SP IEEE
AB To alleviate the degradation of the performance of speech translation, this paper proposes a new approach to translate ASR results through consolidation which extracts meaningful phrases and remove redundant and irrelevant information caused by speaker's disfluency and recognition errors. The speech translation results via consolidation are partial translation and can not be directly compared with gold standards in which all words are translated. We would like to propose a new evaluation framework for partial translation by comparing with the most similar set of words extracted from a word network created by merging gradual summarizations of the gold standard translation. Chinese broadcast news speech in RT04 were recognized, consolidated and then translated. The performance of MT results was evaluated using BLEU. We propose Information Preservation Accuracy (IPAccy) and Meaning Preservation Accuracy (MPAccy) for consolidation and consolidation-based MT.
BN 978-1-4244-1745-2
PY 2007
BP 380
EP +
UT WOS:000255861600068
ER

PT J
AU Wang, JQ
   Oard, DW
AF Wang, Jianqiang
   Oard, Douglas W.
TI Matching meaning for cross-language information retrieval
SO INFORMATION PROCESSING & MANAGEMENT
AB This article describes a framework for cross-language information retrieval that efficiently leverages statistical estimation of translation probabilities. The framework provides a unified perspective into which some earlier work on techniques for cross-language information retrieval based on translation probabilities can be cast. Modeling synonymy and filtering translation probabilities using bidirectional evidence are shown to yield a balance between retrieval effectiveness and query-time (or indexing-time) efficiency that seems well suited large-scale applications. Evaluations with six test collections show consistent improvements over strong baselines. (C) 2011 Elsevier Ltd. All rights reserved.
SN 0306-4573
EI 1873-5371
PD JUL
PY 2012
VL 48
IS 4
BP 631
EP 653
DI 10.1016/j.ipm.2011.09.003
UT WOS:000305170900003
ER

PT C
AU Bender, O
   Matusov, E
   Hahn, S
   Hasan, S
   Khadivi, S
   Ney, H
AF Bender, Oliver
   Matusov, Evgeny
   Hahn, Stefan
   Hasan, Sasa
   Khadivi, Shahram
   Ney, Hermann
GP IEEE
TI The RWTH Arabic-to-English spoken language translation system
SO 2007 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING,
   VOLS 1 AND 2
CT IEEE Workshop on Automatic Speech Recognition and Understanding
CY DEC 09-13, 2007
CL Kyoto, JAPAN
SP IEEE
AB We present the RWTH phrase-based statistical machine translation system designed for the translation of Arabic speech into English text. This system was used in the Global Autonomous Language Exploitation (GALE) Go/No-Go Translation Evaluation 2007.
   Using a two-pass approach, we first generate n-best translation candidates and then rerank these candidates using additional models. We give a short review of the decoder as well as of the models used in both passes.
   We stress the difficulties of spoken language translation, i.e. how to combine the recognition and translation systems and how to compensate for missing punctuation. In addition, we cover our work on domain adaptation for the applied language models. We present translation results for the official GALE 2006 evaluation set and the GALE 2007 development set.
BN 978-1-4244-1745-2
PY 2007
BP 396
EP 401
DI 10.1109/ASRU.2007.4430145
UT WOS:000255861600071
ER

PT C
AU Kim, S
AF Kim, Seokhwan
GP IEEE
TI A GRAPH-BASED CROSS-LINGUAL PROJECTION APPROACH FOR SPOKEN LANGUAGE
   UNDERSTANDING PORTABILITY TO A NEW LANGUAGE
SO 2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
CT IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP)
CY MAY 26-31, 2013
CL Vancouver, CANADA
SP Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc
AB The portability of spoken language understanding to a new language can be improved by the results of automatic translation. However, the translation errors can cause the falling-off in the quality of the target language system. This paper proposes a graph-based projection approach to improve the robustness against the translation errors in cross-lingual spoken language understanding. The experimental results show that our proposed approach can significantly improve the performances of the task in a new language.
SN 1520-6149
BN 978-1-4799-0356-6
PY 2013
BP 8332
EP 8336
UT WOS:000329611508100
ER

PT C
AU Katsuhiko, T
   Yasuhiro, O
   Kazuhiro, I
   Yoshiharu, M
AF Katsuhiko, Toyama
   Yasuhiro, Ogawa
   Kazuhiro, Imai
   Yoshiharu, Matsuura
BE VanEngers, TM
TI Application of Word Alignment for Supporting Translation of Japanese
   Statutes into English
SO LEGAL KNOWLEDGE AND INFORMATION SYSTEMS
SE Frontiers in Artificial Intelligence and Applications
CT 19th Annual Conference on Legal Knowledge and Information Systems/Jurix
   2006 Conference
CY DEC 07-09, 2006
CL Univ Pantheon Assa, Paris II, Paris, FRANCE
HO Univ Pantheon Assa, Paris II
AB Recently, society has expressed increased demands for translation of Japanese statutes into foreign languages. The various motivations behind these demands include social and economic globalization and the need for technical assistance to legal reform. In this paper, we describe the problem of translating Japanese statues and show how to solve it by utilizing technologies developed for natural language processing. In particular, we show how to support both the compilation of a standard bilingual dictionary and the unification of translation equivalents of legal technical terms in compliance with the dictionary by using word alignment.
SN 0922-6389
BN 978-1-58603-698-0
PY 2006
VL 152
BP 141
EP 150
UT WOS:000280537400015
ER

PT J
AU Hkiri, E
   Mallat, S
   Zrigui, M
   Mars, M
AF Hkiri, Emna
   Mallat, Souheyl
   Zrigui, Mounir
   Mars, Mourad
TI Constructing a Lexicon of Arabic-English Named Entity using SMT and
   Semantic Linked Data
SO INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY
AB Named Entity Recognition (NER) is the problem of locating and categorizing atomic entities in a given text. In this work, we used DBpedia Linked datasets and combined existing open source tools to generate from a parallel corpus a bilingual lexicon of Named Entities (NE). To annotate NE in the monolingual English corpus, we used linked data entities by mapping them to Gate Gazetteers. In order to translate entities identified by the gate tool from the English corpus, we used moses, a Statistical Machine Translation (SMT) system. The construction of the Arabic-English NE lexicon is based on the results of moses translation. Our method is fully automatic and aims to help Natural Language Processing (NLP) tasks such as, Machine Translation (MT) information retrieval, text mining and question answering. Our lexicon contains 48753 pairs of Arabic-English NE, it is freely available for use by other researchers.
SN 1683-3198
PY 2017
VL 14
IS 6
BP 820
EP 825
UT WOS:000416286800003
ER

PT C
AU Gonzalez, J
   Sanchis, G
   Casacuberta, F
AF Gonzalez, Jorge
   Sanchis, German
   Casacuberta, Francisco
BE Gelbukh, A
TI Learning finite state transducers using bilingual phrases
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING
SE Lecture Notes in Computer Science
CT 9th International Conference on Intelligent Text Processing and
   Computational Linguistics
CY FEB 17-23, 2008
CL Univ Haifa, Haifa, ISRAEL
SP Computat Linguist Grp, Univ Haifa, Caesarea Edmond Benjamin de Rothschild Fdn Inst Interdisciplinary Applicat Comp Sci
HO Univ Haifa
AB Statistical Machine Translation is receiving more and more attention every day due to the success that the phrase-based alignment models are obtaining. However, despite their power, state-of-the-art systems using these models present a series of disadvantages that lessen their effectiveness in working environments where temporal or spacial computational resources are limited. A finite-state framework represents an interesting alternative because it constitutes an efficient paradigm where quality and realtime factors are properly integrated in order to build translation devices that may be of help for their potential users. Here, we describe a way to use the bilingual information in a phrase-based model in order to implement a phrase-based ngram model using finite state transducers. It will be worth the trouble due to the notable decrease in computational requirements that finite state transducers present in practice with respect to the use of some well-known stack-decoding algorithms. Results for the French-English EuroParl benchmark corpus from the 2006 Workshop on Machine Translation of the ACL are reported.
SN 0302-9743
EI 1611-3349
BN 978-3-540-78134-9
PY 2008
VL 4919
BP 411
EP 422
UT WOS:000253658200035
ER

PT J
AU Rossetti, A
   O'Brien, S
AF Rossetti, Alessandra
   O'Brien, Sharon
TI Helping the helpers: Evaluating the impact of a controlled language
   checker on the intralingual and interlingual translation tasks involving
   volunteer health professionals
SO TRANSLATION STUDIES
AB Cochrane is a non-profit organization which mainly relies on volunteer health professionals for the production, simplification, evaluation, and multilingual dissemination of high-quality health content. The approach that Cochrane volunteers adopt for the simplification (or intralingual translation) of English health content is non-automated and involves the manual checking and implementation of plain language guidelines. This study investigated whether and to what extent the introduction of a controlled language (CL) checker - which would make the simplification approach semi-automated - increased authors' satisfaction and machine translation (MT) quality. Twelve Cochrane authors completed a standardized questionnaire and answered follow-up questions on their level of satisfaction and preferences. Forty-one Cochrane evaluators assessed the quality of the Spanish MT outputs of simplified texts. Authors showed a preference for the introduction of a CL checker. Differences in MT quality scores were slight.
OI Rossetti, Alessandra/0000-0002-2162-9639; O'Brien,
   Sharon/0000-0003-4864-5986
SN 1478-1700
EI 1751-2921
PD MAY 4
PY 2019
VL 12
IS 2
SI SI
BP 253
EP 271
DI 10.1080/14781700.2019.1689161
EA NOV 2019
UT WOS:000498867800001
ER

PT C
AU Sanchis-Trilles, G
   Casacuberta, F
AF Sanchis-Trilles, German
   Casacuberta, Francisco
BE JuanCiscar, A
   SanchezAlbaladejo, G
TI Increasing Translation Speed in Phrase-based Models via Suboptimal
   Segmentation
SO PATTERN RECOGNITION IN INFORMATION SYSTEMS, PROCEEDINGS
CT International Workshop on Security in Information Systems held in
   Conjunction with the ICEIS
CY JUN, 2008
CL Barcelona, SPAIN
AB Phrase-Based Models constitute nowadays the core of the state of the art in the statistical pattern recognition approach to machine translation. Being able to introduce context information into the translation model, they usually produce translations whose quality is often difficult to improve. However, these models have usually an important drawback: the translation speed they are able to deliver is mostly not sufficient for real-time tasks, and translating a single sentence can sometimes take some minutes. In this paper, we describe a novel technique for reducing significantly the size of the translation table, by performing a Viterbi-style selection of the phrases that constitute the final phrase-table. Even in cases where the pruned phrase table contains only 6% of the segments of the original one, translation quality is not worsened. Furthermore, translation quality remains the same in the worst case, achieving an increase of 0.3 BLEU in the best case,
BN 978-989-8111-42-5
PY 2008
BP 135
EP 143
UT WOS:000263163100015
ER

PT C
AU Nguyen, TN
   Nguyen, TS
   Huber, C
   Awiszus, M
   Pham, NQ
   Ha, TL
   Schneider, F
   Stuker, S
   Waibel, A
AF Tuan-Nam Nguyen
   Thai-Son Nguyen
   Huber, Christian
   Awiszus, Maximilian
   Ngoc-Quan Pham
   Thanh-Le Ha
   Schneider, Felix
   Stuker, Sebastian
   Waibel, Alexander
GP Assoc Computat Linguist
TI KIT's IWSLT 2021 Offline Speech Translation System
SO IWSLT 2021: THE 18TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE
   TRANSLATION
CT 18th International Conference on Spoken Language Translation (IWSLT)
CY AUG 05-06, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB This paper describes KIT'submission to the IWSLT 2021 Offline Speech Translation Task. We describe a system in both cascaded condition and end-to-end condition. In the cascaded condition, we investigated different end-to-end architectures for the speech recognition module. For the text segmentation module, we trained a small transformer-based model on high-quality monolingual data. For the translation module, our last year's neural machine translation model was reused. In the end-to-end condition, we improved our Speech Relative Transformer architecture to reach or even surpass the result of the cascade system.
BN 978-1-954085-74-9
PY 2021
BP 125
EP 130
UT WOS:000694723100013
ER

PT C
AU Jiang, T
   Yu, HZ
   He, XZ
   Meng, XH
AF Jiang, Tao
   Yu, Hongzhi
   He, Xiangzhen
   Meng, Xianghe
BE Tong, R
   Zhang, Y
   Lu, Y
   Dong, M
TI Mining Tibetan-Chinese Bilingual Entities from Wikipedia
SO 2017 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP)
SE International Conference on Asian Language Processing
CT International Conference on Asian Language Processing (IALP)
CY DEC 05-07, 2017
CL Natl Univ Singapore, Singapore, SINGAPORE
SP Chinese & Oriental Languages Informat Proc Soc, IEEE, APSIPA, Singapore tourist board
HO Natl Univ Singapore
AB Entity translation pairs play an important role in NLP applications, such as cross language information retrieval and machine translation. The named entity and domain entity are key factors that affect the performance of the system. However, the entity translations can hardly he found in the present bilingual dictionary or parallel corpus. There are lots of Tibetan new neologisms and named entities in Tibetan Wikipedia, and this paper proposes a new method to automatically mining method of Tibetan and Chinese bilingual entity translation from Wikipedia based on the language interlink and page feature. We construct an extract pattern of Tibetan and Chinese entity translation pairs gained from the previous work, and adopt multi-feature candidate translation pairs to distinguish the selection model. The results verify that the entity translation mining method can achieve high accuracy.
RI Yu, Hongzhi/HGD-0220-2022
OI Yu, Hongzhi/0000-0002-5634-131X
SN 2159-1962
EI 2159-1970
BN 978-1-5386-1981-0
PY 2017
BP 9
EP 12
UT WOS:000428370700003
ER

PT C
AU Srihari, RK
   Peterson, E
AF Srihari, Rohini K.
   Peterson, Erik
BE Buchanan, G
   Masoodian, M
   Cunningham, SJ
TI Named Entity Recognition for Improving Retrieval and Translation of
   Chinese Documents
SO DIGITAL LIBRARIES: UNIVERSAL AND UBIQUITOUS ACCESS TO INFORMATION,
   PROCEEDINGS
SE Lecture Notes in Computer Science
CT 11th International Conference on Asian Digital Libraries
CY DEC 02-05, 2008
CL Bali, INDONESIA
SP Natl Lib Indonesia, Univ Indonesia, Petra Christian Univ
AB This paper focuses on named entity recognition corresponding to people, organizations, locations, etc. in Chinese scientific documents. Two key benefits are shown by performing NER: (i) improved quality of semantic retrieval, and (ii) improvement in subsequent machine translation. Experiments using the Semantex platform for information extraction illustrate and quantify the two benefits outlined.
SN 0302-9743
BN 978-3-540-89532-9
PY 2008
VL 5362
BP 404
EP +
UT WOS:000262503100056
ER

PT C
AU Clinchant, S
   Renders, JM
AF Clinchant, Stephane
   Renders, Jean-Michel
BE Peters, C
   Jikoun, V
   Mandl, T
   Muller, H
   Oard, DW
   Penas, A
   Petras, V
   Santos, D
TI Query Translation through Dictionary Adaptation
SO ADVANCES IN MULTILINGUAL AND MULTIMODAL INFORMATION RETRIEVAL
SE Lecture Notes in Computer Science
CT 8th Workshop of the Cross-Language Evaluation Forum
CY SEP 19-21, 2007
CL Budapest, HUNGARY
AB Our participation to CLEF07 (Domain-specific Track) was motivated this year by assessing several query translation and expansion strategies that we recently designed and developed. One line of research and development was to use our own Statistical Machine Translation system (called Matrax) and its intermediate outputs to perform query translation and disambiguation. Our idea was to benefit from Matrax' flexibility to output more than one plausible translations and to train its Language Model component on the CLEF07 target corpora. The second line of research consisted in designing algorithms to adapt an initial, general probabilistic dictionary to a particular pair (query, target corpus); this constitutes some extreme viewpoint on the "bilingual lexicon extraction and adaptation" topic. For this strategy, our main contributions lie in a pseudo-feedback algorithm and an EM-like optimisation algorithm that realize this adaptation. A third axis was to evaluate the potential impact of "Lexical Entailment" models in a cross-lingual framework, as they were only used in a monolingual setting up to now. Experimental results on CLEF-2007 corpora (domain-specific track) show that the dictionary adaptation mechanisms appear quite effective in the CUR framework, exceeding in certain cases the performance of much more complex Machine Translation systems and even the performance of the monolingual baseline. In most cases also, Lexical Entailment models, used as query expansion mechanisms, turned out to be beneficial.
SN 0302-9743
EI 1611-3349
BN 978-3-540-85759-4
PY 2008
VL 5152
BP 182
EP 187
UT WOS:000260420000024
ER

PT S
AU Kim, KY
   Park, SY
   Hong, DK
AF Kim, Kweon Yang
   Park, Se Young
   Hong, Dong Kwon
BE Ali, M
   Dapoigny, R
TI An unsupervised method for ranking translation words using a bilingual
   dictionary and WordNet
SO ADVANCES IN APPLIED ARTICIAL INTELLIGENCE, PROCEEDINGS
SE LECTURE NOTES IN COMPUTER SCIENCE
CT 19th International Conference on Industrial, Engineering and Other
   Applications of Applied Intelligent Systems
CY JUN 27-30, 2006
CL Annecy, FRANCE
SP Univ Savoie, Dept Comp Sci, Int Soc Appl Intelligence, LISTIC/ESIA, AIAA, ACM SIGART, AFIA, CSCSI/SCEIO, ECCAI, ENNS, INNS, JSAI, TAAI, Texas State Univ
AB In the context of machine translation, picking the correct translation for a target word among multiple candidates is an important process. In this paper, we propose an unsupervised method for ranking translation word selection for Korean verbs relying on only a bilingual Korean-English dictionary and WordNet. We focus on deciding which translation of the verb target word is the most appropriate by using a measure of inter-word semantic relatedness through the five extended relations between possible translations pair of target verb and some indicative noun clues. In order to reduce the weight of application of possibly unwanted senses for the noun translation, we rank the weight of possible senses for each noun translation word in advance. The evaluation shows that our method outperforms the default baseline performance and previous works. Moreover, this approach provides an alternative to the supervised corpus based approaches that rely on a large corpus of senses annotated data.
SN 0302-9743
BN 3-540-35453-0
PY 2006
VL 4031
BP 879
EP 888
UT WOS:000239623800094
ER

PT C
AU Khaing, PP
   Aung, TN
AF Khaing, Phyu Phyu
   Aung, Than Nwe
BE Zin, TT
   Lin, JCW
   Pan, JS
   Tin, P
   Yokota, M
TI Machine Learning Techniques for Myanmar Word-Sense Disambiguation
SO GENETIC AND EVOLUTIONARY COMPUTING, VOL I
SE Advances in Intelligent Systems and Computing
CT 9th International Conference on Genetic and Evolutionary Computing
   (ICGEC)
CY AUG 26-28, 2015
CL Univ Comp Studies, Yangon, MYANMAR
SP Springer, Minist Sci & Technol, Univ Miyazaki, Kaohsiung Univ Appl Sci, Fujian Univ Technol, Tech Univ Ostrava
HO Univ Comp Studies
AB Word Sense Disambiguation (WSD) is the vital of Natural Language processing such as machine translation, grammatical analysis, content analysis and information retrieval. WSD process is useful for automatically identifying the correct meaning of an ambiguous word in the sentence or the query when it has multiple meanings. In this paper, the supervised, semi-supervised, unsupervised and knowledge-based approaches for WSD are discussed. This work aim to explore the machine learning techniques for word sense disambiguation of Myanmar Nouns.
SN 2194-5357
BN 978-3-319-23204-1; 978-3-319-23203-4
PY 2016
VL 387
BP 175
EP 185
DI 10.1007/978-3-319-23204-1_18
UT WOS:000381803800018
ER

PT C
AU Cheng, Y
   Wang, W
   Jiang, L
   Macherey, W
AF Cheng, Yong
   Wang, Wei
   Jiang, Lu
   Macherey, Wolfgang
BE Meila, M
   Zhang, T
TI Self-supervised and Supervised Joint Training for Resource-rich Machine
   Translation
SO INTERNATIONAL CONFERENCE ON MACHINE LEARNING, VOL 139
SE Proceedings of Machine Learning Research
CT International Conference on Machine Learning (ICML)
CY JUL 18-24, 2021
CL ELECTR NETWORK
AB Self-supervised pre-training of text representations has been successfully applied to low-resource Neural Machine Translation (NMT). However, it usually fails to achieve notable gains on resource-rich NMT. In this paper, we propose a joint training approach, F-2-XEnDec, to combine self-supervised and supervised learning to optimize NMT models. To exploit complementary self-supervised signals for supervised learning, NMT models are trained on examples that are interbred from monolingual and parallel sentences through a new process called crossover encoder-decoder. Experiments on two resource-rich translation benchmarks, WMT' 14 English-German and WMT' 14 English-French, demonstrate that our approach achieves substantial improvements over several strong baseline methods and obtains a new state of the art of 46.19 BLEU on English-French when incorporating back translation. Results also show that our approach is capable of improving model robustness to input perturbations such as code-switching noise which frequently appears on social media.
SN 2640-3498
PY 2021
VL 139
UT WOS:000683104601075
ER

PT C
AU Shia, MS
   Lin, JH
   Yu, S
   Lu, WH
AF Shia, MS
   Lin, JH
   Yu, S
   Lu, WH
GP IEEE
TI A web-based unsupervised algorithm for learning transliteration model to
   improve translation of low-frequency proper names
SO Proceedings of the 2005 IEEE International Conference on Natural
   Language Processing and Knowledge Engineering (IEEE NLP-KE'05)
CT International Conference on Natural Language Processing and Knowledge
   Engineering
CY OCT 30-NOV 01, 2005
CL Wuhan, PEOPLES R CHINA
SP IEEE, AAI, CIPSC, Chinese Assoc Artificial Intelligence, IEEE Signal Proc Soc, IEEE Beijing Sect
AB In machine translation, cross-language information retrieval, and cross-language question answering, the problems of unknown term translation are difficult to be solved. Although we have proposed several effective Web-based term translation extraction methods exploring Web resources to deal with translation of frequent Web query terms. However, many low-frequency unknown terms are still difficult to be translated by using our previous Web-based term translation extraction methods. Therefore, in this paper we propose a two-stage hybrid translation extraction method, which is composed of our pervious Web-based term translation extraction method and a new Web-based transliteration method to improve translation of low-frequency unknown proper names. Additionally, to construct a good quality transliteration model, we also present a Web-based unsupervised learning algorithm to automatically collect diverse English-Chinese transliteration pairs from the Web. Experimental results showed that our new method can make great improvements for translation of unknown proper names.
BN 0-7803-9361-9
PY 2005
BP 420
EP 425
UT WOS:000235577200079
ER

PT J
AU Arcan, M
   Turchi, M
   Tonelli, S
   Buitelaar, P
AF Arcan, Mihael
   Turchi, Marco
   Tonelli, Sara
   Buitelaar, Paul
TI Leveraging bilingual terminology to improve machine translation in a CAT
   environment
SO NATURAL LANGUAGE ENGINEERING
AB This work focuses on the extraction and integration of automatically aligned bilingual terminology into a Statistical Machine Translation (SMT) system in a Computer Aided Translation scenario. We evaluate the proposed framework that, taking as input a small set of parallel documents, gathers domain-specific bilingual terms and injects them into an SMT system to enhance translation quality. Therefore, we investigate several strategies to extract and align terminology across languages and to integrate it in an SMT system. We compare two terminology injection methods that can be easily used at run-time without altering the normal activity of an SMT system: XML markup and cache-based model. We test the cache-based model on two different domains (information technology and medical) in English, Italian and German, showing significant improvements ranging from 2.23 to 6.78 BLEU points over a baseline SMT system and from 0.05 to 3.03 compared to the widely-used XML markup approach.
RI Turchi, Marco/AFN-0053-2022
OI Arcan, Mihael/0000-0002-3116-621X; Tonelli, Sara/0000-0001-8010-6689
SN 1351-3249
EI 1469-8110
PD SEP
PY 2017
VL 23
IS 5
BP 763
EP 788
DI 10.1017/S1351324917000195
UT WOS:000407573100005
ER

PT J
AU Liu, DYH
   Yang, KX
   Qu, Q
   Lv, JC
AF Liu, Dayiheng
   Yang, Kexin
   Qu, Qian
   Lv, Jiancheng
TI Ancient-Modern Chinese Translation with a New Large Training Dataset
SO ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION
   PROCESSING
AB Chinese brings the wisdom and spirit culture of the Chinese nation. Automatic translation from ancient Chinese to modern Chinese helps to inherit and carry forward the quintessence of the ancients. However, the lack of large-scale parallel corpus limits the study of machine translation in ancient-modern Chinese. In this article, we propose an ancient-modern Chinese clause alignment approach based on the characteristics of these two languages. This method combines both lexical-based information and statistical-based information, which achieves 94.2 F1-score on our manual annotation Test set. We use this method to create a new large-scale ancient-modern Chinese parallel corpus that contains 1.24M bilingual pairs. To our best knowledge, this is the first large high-quality ancient-modern Chinese dataset. Furthermore, we analyzed and compared the performance of the SMT and various NMT models on this dataset and provided a strong baseline for this task.
OI Liu, Dayiheng/0000-0002-8755-8941
SN 2375-4699
EI 2375-4702
PD JAN
PY 2020
VL 19
IS 1
AR 6
DI 10.1145/3325887
UT WOS:000512296500006
ER

PT C
AU Gladkoff, S
   Sorokina, I
   Han, LF
   Alekseeva, A
AF Gladkoff, Serge
   Sorokina, Irina
   Han, Lifeng
   Alekseeva, Alexandra
BA Mariani, J
BF Mariani, J
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mazo, H
   Odijk, H
   Piperidis, S
TI Measuring Uncertainty in Translation Quality Evaluation (TQE)
SO LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND
   EVALUATION
CT 13th International Conference on Language Resources and Evaluation
   (LREC)
CY JUN 20-25, 2022
CL Marseille, FRANCE
SP Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur
AB From both human translators (HT) and machine translation (MT) researchers' point of view, translation quality evaluation (TQE) is an essential task. Translation service providers (TSPs) have to deliver large volumes of translations which meet customer specifications with harsh constraints of required quality level in tight time-frames and costs. MT researchers strive to make their models better, which also requires reliable quality evaluation. While automatic machine translation evaluation (MTE) metrics and quality estimation (QE) tools are widely available and easy to access, existing automated tools are not good enough, and human assessment from professional translators (HAPs) are often chosen as the golden standard (Han et al., 2021b). Human evaluations, however, are often accused of having low reliability and agreement. Is this caused by subjectivity or statistics is at play? How to avoid the entire text to be checked and be more efficient with TQE from cost and efficiency perspectives, and what is the optimal sample size of the translated text, so as to reliably estimate the translation quality of the entire material? This work carries out such a motivated research to correctly estimate the confidence intervals (Brown et al., 2001) depending on the sample size of translated text, e.g. the amount of words or sentences, that needs to be processed on TQE workflow step for confident and reliable evaluation of overall translation quality. The methodology we applied for this work is from Bernoulli Statistical Distribution Modeling (BSDM) and Monte Carlo Sampling Analysis (MCSA).
BN 979-10-95546-72-6
PY 2022
BP 1454
EP 1461
UT WOS:000889371701060
ER

PT C
AU Ning, Q
AF Ning, Qi
BE Li, G
   Jai, Z
   Fu, Z
TI ITA: A Static Binary Translator
SO ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL
   SYSTEM SCIENCES, PT 2
CT International Conference on Informational Technology and Environmental
   System Science
CY MAY 15-17, 2008
CL Henan Polytechn Univ, Jiaozuo, PEOPLES R CHINA
HO Henan Polytechn Univ
AB ITA is a binary translator designed to translate the IA-64 binary executables to Alpha statically. IA-64 architecture uses 64-bit instruction set and applies Explicitly Parallel Instruction Computing technique to improve instruction level parallelism. ITA is implemented with a separation of machine-dependent and machine-independent concerns. The machine-independent components are reusable, and support for machine-dependent components is provided by specification languages. This paper presents an overview of ITA and provides preliminary results in the use of this binary translator.
BN 978-7-121-06324-4
PY 2008
BP 276
EP 284
UT WOS:000260457600045
ER

PT J
AU Lee, SM
AF Lee, Sangmin-Michelle
TI Different effects of machine translation on L2 revisions across
   students' L2 writing proficiency levels
SO LANGUAGE LEARNING & TECHNOLOGY
AB In recent years, machine translation (MT) has been gaining popularity, both in academic settings and in everyday life among foreign language students. However, insufficient research has been conducted in this field. Moreover, the findings of extant literature are often contradictory, and there are few empirical studies based on students ' actual outcomes. Therefore, the present study investigates the effectiveness of using MT in English-as-a-Foreign-Language (EFL) writing classes. It particularly examines whether students' L2 writing proficiency levels influence their revisions when using MT. According to the results, using MT helped all levels of students improve their revisions, but to a different extent depending on their L2 writing proficiency levels. Compared to the higher-level students, the lower-level students made fewer changes per error, resulting in less improvement in the revised versions. Furthermore, this study found that the lowest-level students benefited the least from MT, mainly due to their limited L2 knowledge. Conversely, the higher-level students benefited more from MT by critically selecting better options between their own translations and those produced by MT. Overall, this study includes several pedagogical implications for using MT in L2 writing classrooms.
SN 1094-3501
PD SEP
PY 2022
VL 26
IS 1
UT WOS:000855916400001
ER

PT C
AU Arthur, P
   Cohn, T
   Haffari, G
AF Arthur, Philip
   Cohn, Trevor
   Haffari, Gholamreza
GP Assoc Computat Linguist
TI Learning Coupled Policies for Simultaneous Machine Translation using
   Imitation Learning
SO 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS (EACL 2021)
CT 16th Conference of the
   European-Chapter-of-the-Association-for-Computational-Linguistics (EACL)
CY APR 19-23, 2021
CL ELECTR NETWORK
SP Assoc Computat Linguist, European Chapter, Grammarly, Facebook AI, Bloomberg Engn, LegalForce, Babelscape
AB We present a novel approach to efficiently learn a simultaneous translation model with coupled programmer-interpreter policies. First, we present an algorithmic oracle to produce oracle READ/WRITE actions for training bilingual sentence-pairs using the notion of word alignments. This oracle actions are designed to capture enough information from the partial input before writing the output. Next, we perform a coupled scheduled sampling to effectively mitigate the exposure bias when learning both policies jointly with imitation learning. Experiments on six language-pairs show our method outperforms strong baselines in terms of translation quality while keeping the translation delay low.
BN 978-1-954085-02-2
PY 2021
BP 2709
EP 2719
UT WOS:000863557002069
ER

PT J
AU Zhang, L
   Wang, YH
   Dai, H
   Zhou, J
AF Zhang, Ling
   Wang, Yinghui
   Dai, Hong
   Zhou, Jie
TI Structural and functional studies revealed key mechanisms underlying
   elongation step of protein translation
SO ACTA BIOCHIMICA ET BIOPHYSICA SINICA
AB The ribosome is an ancient and universally conserved macromolecular machine that synthesizes proteins in all organisms. Since the discovery of the ribosome by electron microscopy in the mid-1950s, rapid progress has been made in research on it, regarding its architecture and functions. As a machine that synthesizes polypeptides, the sequential addition of amino acids to a growing polypeptide chain occurs during a phase called the elongation cycle. This is the core step of protein translation and is highly conserved between bacteria and eukarya. The elongation cycle involves codon recognition by aminoacyl tRNAs, catalysis of peptide bond formation, and the most complex operation of translation-translocation. In this review, we discuss the fundamental results from structural and functional studies over the past decades that have led to understanding of the three key questions underlying translation.
RI ling, zhang/ABC-1702-2020
OI Zhou, Jie/0000-0001-6521-1384
SN 1672-9145
EI 1745-7270
PD JUL
PY 2020
VL 52
IS 7
BP 749
EP 756
DI 10.1093/abbs/gmaa046
UT WOS:000574277800007
PM 32400848
ER

PT J
AU Mermer, C
   Saraclar, M
   Sarikaya, R
AF Mermer, Coskun
   Saraclar, Murat
   Sarikaya, Ruhi
TI Improving Statistical Machine Translation Using Bayesian Word Alignment
   and Gibbs Sampling
SO IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB We present a Bayesian approach to word alignment inference in IBM Models 1 and 2. In the original approach, word translation probabilities (i.e., model parameters) are estimated using the expectation-maximization (EM) algorithm. In the proposed approach, they are random variables with a prior and are integrated out during inference. We use Gibbs sampling to infer the word alignment posteriors. The inferred word alignments are compared against EM and variational Bayes (VB) inference in terms of their end-to-end translation performance on several language pairs and types of corpora up to 15 million sentence pairs. We show that Bayesian inference outperforms both EM and VB in the majority of test cases. Further analysis reveals that the proposed method effectively addresses the high-fertility rare word problem in EM and unaligned rare word problem in VB, achieves higher agreement and vocabulary coverage rates than both, and leads to smaller phrase tables.
RI Saraclar, Murat/E-8640-2010
OI Saraclar, Murat/0000-0002-7435-8510
SN 1558-7916
EI 1558-7924
PD MAY
PY 2013
VL 21
IS 5
BP 1090
EP 1101
DI 10.1109/TASL.2013.2244087
UT WOS:000320450900002
ER

PT C
AU Wu, NE
   Hou, HX
   Jia, XN
   Chang, X
   Li, HR
AF Wu, Nier
   Hou, Hongxu
   Jia, Xiaoning
   Chang, Xin
   Li, Haoran
BE Su, J
   Sennrich, R
TI Low-Resource Neural Machine Translation Based on Improved Reptile
   Meta-learning Method
SO MACHINE TRANSLATION, CCMT 2021
SE Communications in Computer and Information Science
CT 17th China Conference on Machine Translation (CCMT)
CY OCT 08-10, 2021
CL Xining, PEOPLES R CHINA
SP Qinghai Normal Univ, Global Tone Commun Technol Co Ltd, Volctrans, NiuTrans Res, Youdao, NEWTRANX Technol, Transn, Tencent TranSmart, Xiaomi Corp, Baidu, Cloud Translat, Jeemaa
AB Multilingual transfer learning has been proved an effective method to solve the problem of low-resource neural machine translation (NMT). However, the global optimal parameters obtained through transfer learning can not effectively adapt to new tasks, which means the problem of local optimum will be caused when training the new task model. Although this problem can be alleviated by optimization-based meta-learning methods, but meta-parameters are determined by the second-order gradient term corresponding to the model parameters of a specific task, which consumes a lot of computing resources. Therefore, we proposed improved reptile meta-learning method. First, a multilingual unified word embedding method is proposed to represent multilingual knowledge. Secondly, the direction of meta-gradient is guided by calculating cumulative gradients on multiple specific tasks. In addition, the midpoint is taken as the meta-parameter in the space of the initial meta-parameter and the final task-specific model parameter to ensure that the meta-model has better multi-feature generalization ability. We conducted experiments in the CCMT2019 Mongolian-Chinese (Mo-Zh), Uyghur-Chinese (Uy-Zh) and Tibetan-Chinese (Ti-Zh), and the results show that our method has significantly improved the translation quality compared with the traditional methods.
SN 1865-0929
EI 1865-0937
BN 978-981-16-7512-6; 978-981-16-7511-9
PY 2021
VL 1464
BP 39
EP 50
DI 10.1007/978-981-16-7512-6_4
UT WOS:000833517700004
ER

PT C
AU Shukla, S
   Sinha, U
AF Shukla, Seema
   Sinha, Usha
GP IEEE
BE Nagabhusan, TN
   Sundararajan, N
   Suresh, S
TI Categorizing Sentence Structures for Phrase Level Morphological Analyzer
   for English to Hindi RBMT
SO 2015 INTERNATIONAL CONFERENCE ON COGNITIVE COMPUTING AND INFORMATION
   PROCESSING (CCIP)
CT 2015 International Conference on Cognitive Computing and Information
   Processing (CCIP)
CY MAR 03-04, 2015
CL Noida, INDIA
SP IEEE UP Sect, CDCC, Dept Sci & Technol, Punjab Natl Bank, Corp Bank
AB Algorithms for morphological analyzers have evolved majorly around words. Since writing styles are changing due to impact of languages on each other, higher version of morphological analyzers are desired for various NLP systems such as Machine Translation, Knowledge Extraction, Information Retrieval, etc. Often word level morphological analyzers adhere to language grammars and knowledge set pertaining to GNP and dictionary. Some algorithms use phrasal dictionaries also. But, impact of languages on each other leads to changes in GNP, grammatical and phrasal usage of words. General morph algorithms cannot deal with impact of such usage of words or phrases. Therefore new generation of morph analyzers are desired to handle cross lingual impact. In this paper, methodology for English language morphological analyzer is proposed for interpretation of phrases and group of words to derive knowledge in Hindi for tourism domain. The methodology, although general, is oriented towards Machine Translation. Proposed methodology is based on creation of knowledge base for morph analyzers using formulations of FST and RTN. Using this methodology, ten categories of phrasal structures in sentences have been identified which when used in MA of RBMT would improve the functional efficiency of MT in producing correct translation.
RI Shukla, Seema/HGF-3511-2022
OI Shukla, Seema/0000-0002-5273-9849
BN 978-1-4799-7171-8
PY 2015
UT WOS:000380430600063
ER

PT J
AU Sun, HP
   Wang, R
   Chen, KH
   Utiyama, M
   Sumita, E
   Zhao, TJ
AF Sun, Haipeng
   Wang, Rui
   Chen, Kehai
   Utiyama, Masao
   Sumita, Eiichiro
   Zhao, Tiejun
TI Unsupervised Neural Machine Translation With Cross-Lingual Language
   Representation Agreement
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB Unsupervised cross-lingual language representation initialization methods such as unsupervised bilingual word embedding (UBWE) pre-training and cross-lingual masked language model (CMLM) pre-training, together with mechanisms such as denoising and back-translation, have advanced unsupervised neural machine translation (UNMT), which has achieved impressive results on several language pairs, particularly French-English and German-English. Typically, UBWE focuses on initializing the word embedding layer in the encoder and decoder of UNMT, whereas the CMLM focuses on initializing the entire encoder and decoder of UNMT. However, UBWE/CMLM training and UNMT training are independent, which makes it difficult to assess how the quality of UBWE/CMLM affects the performance of UNMT during UNMT training. In this paper, we first empirically explore relationships between UNMT and UBWE/CMLM. The empirical results demonstrate that the performance of UBWE and CMLM has a significant influence on the performance of UNMT. Motivated by this, we propose a novel UNMT structure with cross-lingual language representation agreement to capture the interaction between UBWE/CMLM and UNMT during UNMT training. Experimental results on several language pairs demonstrate that the proposed UNMT models improve significantly over the corresponding state-of-the-art UNMT baselines.
RI Chen, Kehai/ABF-1874-2020; Wang, Rui/AAI-1990-2020
OI Wang, Rui/0000-0001-8007-2503; Sun, Haipeng/0000-0002-5899-0401
SN 2329-9290
EI 2329-9304
PY 2020
VL 28
BP 1170
EP 1182
DI 10.1109/TASLP.2020.2982282
UT WOS:000531365900001
ER

PT C
AU Salomie, I
   Cioara, T
   Anghel, I
   Dinsoreanu, M
   Salomie, TI
AF Salomie, Ioan
   Cioara, Tudor
   Anghel, Ionut
   Dinsoreanu, Mihaela
   Salomie, Tudor Ioan
BE Letia, IA
TI Machine simulation for workflow integration testing
SO ICCP 2007: IEEE 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTER
   COMMUNICATION AND PROCESSING, PROCEEDINGS
SE IEEE International Conference on Intelligent Computer Communication and
   Processing ICCP
CT IEEE 3rd International Conference on Intelligent Computer Communication
   and Processing
CY SEP 06-08, 2007
CL Cluj Napoca, ROMANIA
SP IEEE
AB This paper addresses the problems of modeling and simulating physical machines, part of complex industrial production lines. The direct execution of industrial workflows on production line machines before integration testing can be very expensive and may lead to improper machine operation and even to non recoverable faults. In order to simulate the execution of industrial workflow models for integration testing purposes, we propose a physical machine simulator based on nondeterministic, probability based state machines. For each physical machine a behavioral model is constructed using operational scenarios followed by its translation into a state machine representation. The proposed simulator was used for a sausage preparing production line in the context of the Food Trace project [8].
RI Dinsoreanu, Mihaela/B-9702-2011
OI Dinsoreanu, Mihaela/0000-0002-4947-0594; Anghel,
   Ionut/0000-0001-6166-5266; Cioara, Tudor/0000-0003-1177-5795
SN 2065-9946
BN 978-1-4244-1491-8
PY 2007
BP 193
EP +
UT WOS:000250749800026
ER

PT C
AU Nguyen, T
   Rigby, PC
   Nguyen, AT
   Karanfil, M
   Nguyen, TN
AF Thanh Nguyen
   Rigby, Peter C.
   Anh Tuan Nguyen
   Karanfil, Mark
   Nguyen, Tien N.
BE Zimmermann, T
   ClelandHuang, J
   Su, Z
TI T2API: Synthesizing API Code Usage Templates from English Texts with
   Statistical Translation
SO FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM
   ON FOUNDATIONS OF SOFTWARE ENGINEERING
CT 24th ACM SIGSOFT International Symposium on Foundations of Software
   Engineering (FSE)
CY NOV 13-18, 2016
CL Seattle, WA
SP ACM Special Interest Grp Software Engn, Assoc Comp Machinery
AB In this work, we develop T2API, a statistical machine translation-based tool that takes a given English description of a programming task as a query, and synthesizes the API usage template for the task by learning from training data. T2API works in two steps. First, it derives the API elements relevant to the task described in the input by statistically learning from a StackOverflow corpus of text descriptions and corresponding code. To infer those API elements, it also considers the context of the words in the textual input and the context of API elements that often go together in the corpus. The inferred API elements with their relevance scores are ensembled into an API usage by our novel API usage synthesis algorithm that learns the API usages from a large code corpus via a graph-based language model. Importantly, T2API is capable of generating new API usages from smaller, previously-seen usages.
RI Anh, Nguyễn/HGU-8434-2022; Nguyen, Anh/GQQ-3393-2022; Nguyen,
   Anh/HTO-8740-2023
OI Nguyen, Thanh/0000-0003-1576-5420
BN 978-1-4503-4218-6
PY 2016
BP 1013
EP 1017
DI 10.1145/2950290.2983931
UT WOS:000391133400101
ER

PT C
AU Sato, S
   Sugimoto, T
AF Sato, S
   Sugimoto, T
BE Gorlatch, S
   Lengauer, C
TI A lambda evaluator on linear chemical abstract machine
SO CONSTRUCTIVE METHODS FOR PARALLEL PROGRAMMING
SE ADVANCES IN COMPUTATION: THEORY AND PRACTICE
CT 2nd International Workshop on Constructive Methods for Parallel
   Programming
CY JUL   02, 2000
CL PONT DE LIMA, PORTUGAL
AB Abramsky's Linear Chemical Abstract Machine is a term calculus which corresponds to Linear Logic, via the Curry-Howard isomorphism. We show that the typed lambda-calculus is embedded into Linear Chemical Abstract Machine by Girard's embedding of Intuitionistic Logic into Linear Logic. We give a translation of typable lambda-terms into proof expressions and show that Linear CHAM computes the same answer as the call-by-value evaluation in the lambda-calculus. Then we extend our result to a simple functional programming language obtained from the typed lambda-calculus by adding constants from PCF. We show that the call-by-value evaluation of terms of ground types (Booleans and Natural numbers) are preserved and reflected by this translation.
BN 1-59033-374-8
PY 2002
VL 10
BP 111
EP 125
UT WOS:000178712300007
ER

PT C
AU Tinsley, J
   Hearne, M
   Way, A
AF Tinsley, John
   Hearne, Mary
   Way, Andy
BE Gelbukh, A
TI Exploiting Parallel Treebanks to Improve Phrase-Based Statistical
   Machine Translation
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING
SE Lecture Notes in Computer Science
CT 10th International Conference on Intelligent Text Processing and
   Computational Linguistics
CY MAR 01-07, 2009
CL Mexico City, MEXICO
SP Natl Polytechn Inst, Ctr Comput Res, Nat Language & Text Processing, Mexican Soc Artificial Intelligence
AB Given much recent discussion and the shift in focus of the field, it is becoming apparent that the incorporation of syntax is the way forward for the current state-of-the-art in machine translation (MT). Parallel treebanks are a relatively recent innovation and appear to be ideal candidates for NIT training material. However. until recently there has been no other means to build them than by hand. In this paper, we describe how we make use of new tools to automatically build a large parallel treebank and extract a set of linguistically motivated phrase pairs from it. We show that adding these phrase pairs to the translation model of a baseline phrase-based statistical NIT (PBSMT) system leads to significant improvements in translation quality. We describe further experiments on incorporating parallel treebank information into PBSMT, such as word alignments. We investigate the conditions under which the incorporation of parallel treebank data performs optimally. Finally. we discuss the potential of parallel treebanks in other paradigms of MT.
OI Way, Andy/0000-0001-5736-5930
SN 0302-9743
EI 1611-3349
BN 978-3-642-00381-3
PY 2009
VL 5449
BP 318
EP 331
UT WOS:000265681200026
ER

PT C
AU Chouksey, R
   Karfa, C
   Bhaduri, P
AF Chouksey, Ramanuj
   Karfa, Chandan
   Bhaduri, Purandar
BE Naik, R
   Sarkar, S
   Hildebrandt, T
   Kumar, A
   Sharma, R
TI Formal Verification of Optimizing Transformations during High-level
   Synthesis
SO PROCEEDINGS OF THE 12TH INNOVATIONS ON SOFTWARE ENGINEERING CONFERENCE
   (ISEC)
CT 12th Innovations in Software Engineering Conference (ISEC)
CY FEB 14-16, 2019
CL Coll Engn Pune, Pune, INDIA
SP ACM India, ACM India SIGSOFT, ACM In Cooperat, Tata Consultancy Serv, Icertis, IBM, Microsoft
HO Coll Engn Pune
AB Translation validation is the process of proving that the target code is a correct translation of the source program being compiled. In this work, we propose a translation validation method to verify code motion transformations involving loops applied during the scheduling phase of high-level synthesis (HLS). Our method is capable of ignoring false computations during translation validation. In this work, we show that how to generate a counter-trace (cTrace) using the internal information of verifier in the case of non-equivalence reported by a translation validation method. We also show how a Bounded Model Checker (CBMC) can be used to find a counter-example for a given cTrace. Experimental results demonstrate the usefulness of our method.
RI Bhaduri, Purandar/AAW-4661-2020; Karfa, Chandan/T-3597-2019
OI Bhaduri, Purandar/0000-0002-8847-0394; Karfa,
   Chandan/0000-0002-3835-4184
BN 978-1-4503-6215-3
PY 2019
DI 10.1145/3299771.3299797
UT WOS:000475555800027
ER

PT J
AU Farzi, S
   Faili, H
AF Farzi, Saeed
   Faili, Heshaam
TI A swarm-inspired re-ranker system for statistical machine translation
SO COMPUTER SPEECH AND LANGUAGE
AB Recently, re-ranking algorithms have been successfully applied on statistical machine translation systems. Due to the errors in the hypothesis alignment and varying word order between the source and target sentences and also the lack of sufficient resources such as parallel corpora, decoding may result in ungrammatical or non-fluent outputs. This paper proposes a re-ranking system based on swarm algorithms, which makes the use of sophisticated non-syntactical features to re-rank the n-best translation candidates. We introduce plenty of easy-computed non-syntactical features to deal with SMT system errors plus the quantum-behaved particle swarm optimization (QPSO) algorithm to adjust the weights of features. We have evaluated the proposed approach on 2 translation tasks in different language pairs (Persian -> English and German -> English) and genres (news and novel books). In comparison with PSO-, GA-, Perceptron- and averaged Perceptron-style re-ranking systems, the experimental study demonstrates the superiority of the proposed system in terms of translation quality on both translation tasks. In addition, the impacts of the proposed features on the translation quality have been analyzed, and the most positive ones have been recognized. At the end, the impact of the n-best list size on the proposed system is investigated. (C) 2014 Elsevier Ltd. All rights reserved.
RI Farzi, Saeed/ABF-8705-2021
SN 0885-2308
EI 1095-8363
PD JAN
PY 2015
VL 29
IS 1
SI SI
BP 45
EP 62
DI 10.1016/j.csl.2014.07.002
UT WOS:000345106900004
ER

PT C
AU He, XD
   Deng, L
   Acero, A
AF He, Xiaodong
   Deng, Li
   Acero, Alex
GP IEEE
TI WHY WORD ERROR RATE IS NOT A GOOD METRIC FOR SPEECH RECOGNIZER TRAINING
   FOR THE SPEECH TRANSLATION TASK?
SO 2011 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
CT IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP)
CY MAY 22-27, 2011
CL Prague Congress Ctr, Prague, CZECH REPUBLIC
SP Inst Elect & Elect Engineers Signal Processing Soc, IEEE
HO Prague Congress Ctr
AB Speech translation (ST) is an enabling technology for cross-lingual oral communication. A ST system consists of two major components: an automatic speech recognizer (ASR) and a machine translator (MT). Nowadays, most ASR systems are trained and tuned by minimizing word error rate (WER). However, WER counts word errors at the surface level. It does not consider the contextual and syntactic roles of a word, which are often critical for MT. In the end-to-end ST scenarios, whether WER is a good metric for the ASR component of the full ST system is an open issue and lacks systematic studies. In this paper, we report our recent investigation on this issue, focusing on the interactions of ASR and MT in a ST system. We show that BLEU-oriented global optimization of ASR system parameters improves the translation quality by an absolute 1.5% BLEU score, while sacrificing WER over the conventional, WER-optimized ASR system. We also conducted an in-depth study on the impact of ASR errors on the final ST output. Our findings suggest that the speech recognizer component of the full ST system should be optimized by translation metrics instead of the traditional WER.
SN 1520-6149
BN 978-1-4577-0539-7
PY 2011
BP 5632
EP 5635
UT WOS:000296062406085
ER

PT J
AU Sitender
   Bawa, S
AF Sitender
   Bawa, Seema
TI A Sanskrit-to-English machine translation using hybridization of direct
   and rule-based approach
SO NEURAL COMPUTING & APPLICATIONS
AB The work in this paper presents a MTS from Sanskrit to English language using a hybridized form of direct and rule-based machine translation technique. This paper also discusses the language divergence among Sanskrit and English languages with a recommended solution to handle the divergence. The proposed system has used two bilingual dictionaries (Sanskrit-English, Sanskrit-UNL), a tagged Sanskrit corpus, a Sanskrit analysis rule base and an ELGR base. Elasticsearch technique has enhanced the translation speed of the proposed system for accessing the data from different data dictionaries and rule bases used for the system development. The system uses CFG in CNF for Sanskrit language processing and CYK parsing technique for processing the input Sanskrit sentence. This work also presents a novel algorithm which creates a parse tree from the parsing table. ELGR base and bilingual dictionaries generate the target language sentence. The proposed system is evaluated using natural language toolkit API in python and achieved a BLEU score of 0.7606, fluency score of 3.63 and adequacy score of 3.72. A comparison of the proposed system with state-of-the-art systems shows that the proposed system outperforms existing systems.
RI Sitender, Dr/AAJ-9624-2021
OI Sitender, Dr/0000-0003-0341-2927
SN 0941-0643
EI 1433-3058
PD APR
PY 2021
VL 33
IS 7
BP 2819
EP 2838
DI 10.1007/s00521-020-05156-3
EA JUL 2020
UT WOS:000549685600002
ER

PT C
AU Liebling, DJ
   Lahav, M
   Evans, A
   Donsbach, A
   Holbrook, J
   Smus, B
   Boran, L
AF Liebling, Daniel J.
   Lahav, Michal
   Evans, Abigail
   Donsbach, Aaron
   Holbrook, Jess
   Smus, Boris
   Boran, Lindsey
GP ACM
TI Unmet Needs and Opportunities for Mobile Translation Al
SO PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
   SYSTEMS (CHI'20)
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGCHI
AB Translation apps and devices are often presented in the context of providing assistance while traveling abroad. However, the spectrum of needs for cross-language communication is much wider. To investigate these needs, we conducted three studies with populations spanning socioeconomic status and geographic regions: (1) United States-based travelers, (2) migrant workers in India, and (3) immigrant populations in the United States. We compare frequent travelers' perception and actual translation needs with those of the two migrant communities. The latter two, with low language proficiency, have the greatest translation needs to navigate their daily lives. However, current mobile translation apps do not meet these needs. Our findings provide new insights on the usage practices and limitations of mobile translation tools. Finally, we propose design implications to help apps better serve these unmet needs.
BN 978-1-4503-6708-0
PY 2020
DI 10.1145/3313831.3376261
UT WOS:000695432500134
ER

PT C
AU Kumar, R
AF Kumar, Ritesh
BE Singh, C
   Lehal, GS
   Sengupta, J
   Sharma, DV
   Goyal, V
TI Making Machine Translations Polite: The Problematic Speech Acts
SO INFORMATION SYSTEMS FOR INDIAN LANGUAGES
SE Communications in Computer and Information Science
CT International Conference on Infirmation Systems for Indian Languages
   (ICISIL 2011)
CY MAR 09-11, 2011
CL Patiala, INDIA
AB In this paper, a study of politeness in a translated parallel corpus of Hindi and English is done. It presents how politeness in a Hindi text is translated into English. A theoretical model (consisting of different situations that may arise while translating politeness from one language to another and different consequences of these situations) has been developed to compare the politeness value in the source and the translated text. The polite speech acts of Hindi which are most likely to be translated improperly into English are described. Based on this description, such rules will be developed which could be fed into the MT systems so that the problematic polite speech acts could be handled effectively and efficiently by the machine while translating.
RI Kumar, Ritesh/AHC-5197-2022
SN 1865-0929
BN 978-3-642-19402-3
PY 2011
VL 139
BP 185
EP 190
UT WOS:000306397600029
ER

PT C
AU Casas, N
   Fonollosa, JAR
   Escolano, C
   Basta, C
   Costa-Jussa, MR
AF Casas, Noe
   Fonollosa, Jose A. R.
   Escolano, Carlos
   Basta, Christine
   Costa-Jussa, Marta R.
GP Assoc Computat Linguist
TI The TALP-UPC Machine Translation Systems for WMT19 News Translation
   Task: Pivoting Techniques for Low Resource MT
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019)
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB In this article, we describe the TALP-UPC research group participation in the WMT19 news translation shared task for Kazakh-English. Given the low amount of parallel training data, we resort to using Russian as pivot language, training subword-based statistical translation systems for Russian-Kazakh and Russian-English that were then used to create two synthetic pseudo-parallel corpora for Kazakh-English and English-Kazakh respectively. Finally, a self-attention model based on the decoder part of the Transformer architecture was trained on the two pseudo-parallel corpora.
RI Casas, Noe/HPH-2320-2023; Basta, Christine/HLP-6713-2023
OI Casas, Noe/0000-0002-0248-899X; Basta, Christine/0000-0001-5551-0356
BN 978-1-950737-27-7
PY 2019
BP 155
EP 162
UT WOS:000538566200011
ER

PT C
AU Gros, JZ
   Mihelic, A
AF Gros, Jerneja Zganec
   Mihelic, Ales
BE Fierrez, J
   OrtegaGarcia, J
   Esposito, A
   Drygajlo, A
   Faundez-Zanuy, M
TI Audiovisual Alignment in a Face-to-Face Conversation Translation
   Framework
SO BIOMETRIC ID MANAGEMENT AND MULTIMODAL COMMUNICATION, PROCEEDINGS
SE Lecture Notes in Computer Science
CT Joint International Conference on Biometric ID Management and Multimodal
   Communication (BioID-MultiComm)
CY SEP 16-18, 2009
CL Biometr Recognit Grp, Madrid, SPAIN
SP Escuela Politecn Super, ATVS, Univ Autonoma, COST 2101 & 2102
HO Biometr Recognit Grp
AB Recent improvements in audiovisual alignment for a translating videophone are presented. A method for audiovisual alignment in the target language is proposed and the process of audiovisual speech synthesis is described. The proposed method has been evaluated in the VideoTRAN translating videophone environment, where an H.323 software client translating videophone allows for the transmission and translation of a set of multimodal verbal and nonverbal clues in a multilingual face-to-face communication setting. An extension of subjective evaluation metrics of fluency and adequacy, which are commonly used in subjective machine translation evaluation tests, is proposed for usage in ail audiovisual translation environment.
SN 0302-9743
EI 1611-3349
BN 978-3-642-04390-1
PY 2009
VL 5707
BP 57
EP 64
UT WOS:000274242800008
ER

PT C
AU Wang, YR
   Zhai, CX
   Awadalla, HH
AF Wang, Yiren
   Zhai, ChengXiang
   Awadalla, Hany Hassan
GP Assoc Computat Linguist
TI Multi-task Learning for Multilingual Neural Machine Translation
SO PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL
   LANGUAGE PROCESSING (EMNLP)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 16-20, 2020
CL ELECTR NETWORK
SP Bloomberg Engn, Google Res, Apple, Amazon Sci, Baidu, Megagon Labs, Facebook, DeepMind, Grammarly, ByteDance, Zeta Alpha, Babelscape, Naver, Adobe, Hitachi, Salesforce, Univ So Calif, Viterbi Sch Engn, Informat Sci Inst
AB While monolingual data has been shown to be useful in improving bilingual neural machine translation (NMT), effectively and efficiently leveraging monolingual data for Multilingual NMT (MNMT) systems is a less explored area. In this work, we propose a multi-task learning (MTL) framework that jointly trains the model with the translation task on bitext data and two denoising tasks on the monolingual data. We conduct extensive empirical studies on MNMT systems with 10 language pairs from WMT datasets. We show that the proposed approach can effectively improve the translation quality for both high-resource and low-resource languages with large margin, achieving significantly better results than the individual bilingual models. We also demonstrate the efficacy of the proposed approach in the zero-shot setup for language pairs without bitext training data. Furthermore, we show the effectiveness of MTL over pre-training approaches for both NMT and cross-lingual transfer learning NLU tasks; the proposed approach outperforms massive scale models trained on single task.
BN 978-1-952148-60-6
PY 2020
BP 1022
EP 1034
UT WOS:000855160701015
ER

PT C
AU Tanaka, S
   Nakakubo, A
   Kimura, M
   Takeda, K
   Koda, T
AF Tanaka, Seiya
   Nakakubo, Aika
   Kimura, Momoki
   Takeda, Kazuya
   Koda, Tomoko
BE Ishida, T
TI Development of a Multilingual Translation Service for Interpretations
   and Usage Examples of Mobile Phone Pictograms
SO CULTURE AND COMPUTING: COMPUTING AND COMMUNICATION FOR CROSSCULTURAL
   INTERACTION
SE Lecture Notes in Computer Science
CT 1st International Conference on Culture and Computing
CY FEB 22-23, 2010
CL Kyoto, JAPAN
SP Kyoto Univ, Graduate Sch Informat, Kyoto Univ, Acad Ctr Comp & Media Studies, Kyoto Univ Global COE Program Informat Educ & Res Ctr Knowledge Circulating Soc, Ritsumeikan Univ Global COE Program Digital Humanities Ctr Japanese Arts & Cultures, Inst Kyoto, Adv Sci Technol & Management Res, Kyoto Res Park Corp
AB To find mobile phone pictograms that have age-specific or gender-specific differences of interpretations, we surveyed 276 Japanese mobile phone users and compiled over 6,600 of their interpretations and usage examples for these pictograms. We used these reported pictogram interpretations and usage examples to develop a prototype of a web-based age-specific pictogram dictionary application that can be searched and viewed by specifying the pictogram, age group, and/or gender as search conditions. By applying Language Grid machine translation services to this application, we developed a web-based service that translates these pictogram interpretations and usage examples into several languages. This multilingual translation service for our age-specific pictogram dictionary enables the pictogram interpretations and usage examples reported by the Japanese survey respondents to be presented to foreign residents of Japan. It should help expedite and facilitate communication on mobile phones across different languages and cultures.
SN 0302-9743
BN 978-3-642-17183-3
PY 2010
VL 6259
BP 113
EP 126
UT WOS:000286092800009
ER

PT C
AU Cromm, O
   Masagbor, G
AF Cromm, O
   Masagbor, G
BE Callaos, N
   DiSciullo, AM
   Ohta, T
   Liu, TK
TI Asymmetry-based machine translation of deverbal compounds from German to
   French
SO 7TH WORLD MULTICONFERENCE ON SYSTEMICS, CYBERNETICS AND INFORMATICS, VOL
   I, PROCEEDINGS: INFORMATION SYSTEMS, TECHNOLOGIES AND APPLICATIONS
CT 7th World Multiconference on Systemics, Cybernetics and Informatics
CY JUL 27-30, 2003
CL ORLANDO, FL
SP Int Inst Informat & System
AB We are looking at Machine translation (MT) of deverbal compounds from two points of view, a theoretical and a practical one, in exploring the possibility of a theory-based query translation module for a multilingual IR system. In compounding, the relation between the constituents is implicit, and compositionality less strict than in syntax, thus interpretation is harder. Its productivity makes it unfeasible to include all compounds in the lexicon. On the other hand, compounds often appear in IR queries. Thus, a compound translation module is a valuable part of a multilingual IR system. Existing MT systems, as other NLP systems, generally apply superficial heuristics to compound processing, which lead to results of widely varying quality. Statistical approaches, as well as attempts to classify the relation between the constituents in compounds have turned out unsatisfactory, as compounds have proven resistant to pigeon-holing. Much less is there an algorithm to decide which relation holds for a given compound. Deverbals are often thought to be easier in this respect, as they frequently take adjuncts which correspond to the arguments of the underlying verb, but this is not always the case. Theoretical results on compounds have rarely been applied to MT. We show that Asymmetry Theory (Di Sciullo, (11]) gives a theoretically satisfying description of deverbal compounds which cuts across language types and as such promises to lead to a better treatment of deverbal compounds in NLP applications.
BN 980-6560-01-9
PY 2003
BP 1
EP 6
UT WOS:000189328300001
ER

PT C
AU Casan, GA
   Castano, MA
AF Casan, GA
   Castano, MA
BE LopezdeMantaras, R
   Saitta, L
TI Improvements on automatic word codification for Connectionist machine
   translation
SO ECAI 2004: 16TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE,
   PROCEEDINGS
SE FRONTIERS IN ARTIFICIAL INTELLIGENCE AND APPLICATIONS
CT 16th European Conference on Artificial Intelligence
CY AUG 22-27, 2004
CL Valencia, SPAIN
SP European Coordinating Comm Artificial Intelligence, Asoc Espanola Inteligencia Artificial, Assoc Catalana Intelligencia Artificial, Univ Politecn Valencia, Grp Tecnol Informat
AB Encouragingly accurate translations have recently been obtained using a connectionist translator called RECONTRA (Recurrent Connectionist Translator). In order to deal with tasks of medium or large vocabularies, distributed representations of the lexicons are required in this translator. A simple connectionist model has been recently designed to automatically obtain word distributed representations. In this paper several learning algorithms were used to train this connectionist encoder aiming to improve the translation rates achieved with the corresponding obtained codifications of the vocabularies involved.
RI Castano, M. Asuncion/ABF-6685-2020; Casañ, Gustavo A/M-8144-2014
OI Castano, M. Asuncion/0000-0002-4010-1813; Casañ, Gustavo
   A/0000-0001-7434-1244
SN 0922-6389
BN 1-58603-452-9
PY 2004
VL 110
BP 576
EP 580
UT WOS:000225505100112
ER

PT J
AU Chinea-Rios, M
   Sanchis-Trilles, G
   Casacuberta, F
AF Chinea-Rios, Mara
   Sanchis-Trilles, German
   Casacuberta, Francisco
TI Vector sentences representation for data selection in statistical
   machine translation
SO COMPUTER SPEECH AND LANGUAGE
AB One of the most popular approaches to machine translation consists in formulating the problem as a pattern recognition approach. Under this perspective, bilingual corpora are precious resources, as they allow for a proper estimation of the underlying models. In this framework, selecting the best possible corpus is critical, and data selection aims to find the best subset of the bilingual sentences from an available pool of sentences such that the final translation quality is improved. In this paper, we present a new data selection technique that leverages a continuous vector-space representation of sentences. Experimental results report improvements compared not only with a system trained only with in-domain data, but also compared with a system trained on all the available data. Finally, we compared our proposal with other state-of-the-art data selection techniques (Cross-entropy selection and Infrequent ngrams recovery) in two different scenarios, obtaining very promising results with our proposal: our data selection strategy is able to yield results that are at least as good as the best-performing strfategy for each scenario. The empirical results reported are coherent across different language pairs. (C) 2018 Elsevier Ltd. All rights reserved.
SN 0885-2308
EI 1095-8363
PD JUL
PY 2019
VL 56
BP 1
EP 16
DI 10.1016/j.csl.2018.12.005
UT WOS:000461691700001
ER

PT J
AU Luo, GX
   Yang, YT
   Yuan, Y
   Chen, ZH
   Ainiwaer, A
AF Luo, Gongxu
   Yang, Yating
   Yuan, Yang
   Chen, Zhanheng
   Ainiwaer, Aizimaiti
TI Hierarchical Transfer Learning Architecture for Low-Resource Neural
   Machine Translation
SO IEEE ACCESS
AB Neural Machine Translation(NMT) has achieved notable results in high-resource languages, but still works poorly on low-resource languages. As times goes on, It is widely recognized that transfer learning methods are effective for low-resource language problems. However, existing transfer learning methods are typically based on the parent-child architecture, which does not adequately take advantages of helpful languages. In this paper, inspired by human transitive inference and learning ability, we handle this issue by proposing a new hierarchical transfer learning architecture for low-resource languages. In the architecture, the NMT model is trained in the unrelated high-resource language pair, the similar intermediate language pair and the low-resource language pair in turn. Correspondingly, the parameters are transferred and fine-tuned layer by layer for initialization. In this way, our hierarchical transfer learning architecture simultaneously combines the data volume advantages of high-resource languages and the syntactic similarity advantages of cognate languages. Specially, we utilize Byte Pair Encoding(BPE) and character-level embedding for data pre-processing, which effectively solve the problem of out of vocabulary(OOV). Experimental results on Uygur-Chinese and Turkish-English translation demonstrate the superiorities of the proposed architecture over the NMT model with parent-child architecture.
OI anwar, azmat/0000-0002-0684-1527; Chen, Zhan-Heng/0000-0002-2331-4446
SN 2169-3536
PY 2019
VL 7
BP 154157
EP 154166
DI 10.1109/ACCESS.2019.2936002
UT WOS:000510258900008
ER

PT S
AU Pico, D
   Casacuberta, F
AF Pico, D
   Casacuberta, F
BE Ferri, FJ
   Inesta, JM
   Amin, A
   Pudil, P
TI A statistical-estimation method for stochastic finite-state transducers
   based on entropy measures
SO ADVANCES IN PATTERN RECOGNITION
SE Lecture Notes in Computer Science
CT Joint International-Association-of-Pattern-Recognition International
   Workshops - SSPR 2000 and SPR 2000
CY AUG 30-SEP 01, 2000
CL UNIV ALICANTE, ALICANTE, SPAIN
SP Int Assoc Pattern Recognit, Univ Valencia, Dept Informat
HO UNIV ALICANTE
AB The stochastic extension of formal translations constitutes a suitable framework for dealing with many problems in Syntactic Pattern Recognition. Some estimation criteria have already been proposed and developed for the parameter estimation of Regular Syntax-Directed Translation Schemata. Here, a new criterium is proposed for dealing with situations when training data is sparse. This criterium is based on entropy measurements, somehow inspired in the Maximum Mutual Information criterium, and it takes into account the possibility of ambiguity in translations (i.e., the translation model may yield different output strings for a single input string.) The goal in the stochastic framework is to find the most probable translation of a given input string. Experiments were performed on a translation task which has a high degree of ambiguity.
RI Ferri, Francesc Josep/L-7216-2014
OI Ferri, Francesc Josep/0000-0002-1543-3568
SN 0302-9743
EI 1611-3349
BN 3-540-67946-4
PY 2000
VL 1876
BP 417
EP 426
UT WOS:000171155700043
ER

PT J
AU Yang, YF
AF Yang, Yifang
TI Application of LSTM Neural Network Technology Embedded in English
   Intelligent Translation
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
AB With the rapid development of computer technology, the loss of long-distance information in the transmission process is a prominent problem faced by English machine translation. The self-attention mechanism is combined with convolutional neural network (CNN) and long-term and short-term memory network (LSTM). An English intelligent translation model based on LSTM-SA is proposed, and the performance of this model is compared with other deep neural network models. The study adds SA to the LSTM neural network model and constructs the English translation model of LSTM-SA attention embedding. Compared with other deep learning algorithms such as 3RNN and GRU, the LSTM-SA neural network algorithm has faster convergence speed and lower loss value, and the loss value is finally stable at about 8.6. Under the three values of adaptability, the accuracy of LSTM-SA neural network structure is higher than that of LSTM, and when the adaptability is 1, the accuracy of LSTM-SA neural network improved the fastest, with an accuracy of nearly 20%. Compared with other deep learning algorithms, the LSTM-SA neural network algorithm has a better translation level map under the three hidden layers. The proposed LSTM-SA model can better carry out English intelligent translation, enhance the representation of source language context information, and improve the performance and quality of English machine translation model.
SN 1687-5265
EI 1687-5273
PD SEP 27
PY 2022
VL 2022
AR 1085577
DI 10.1155/2022/1085577
UT WOS:000868633600002
PM 36203717
ER

PT C
AU Yao, JM
   Guo, L
   Zhou, ML
   Zhang, J
AF Yao Jianmin
   Guo Lei
   Zhou Meiling
   Zhang Jing
BE Maoqing, LI
TI A Comparison of Two Models for Mining Named Entity Pairs from Web Corpus
SO ICCSE 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON
   COMPUTER SCIENCE & EDUCATION: ADVANCED COMPUTER TECHNOLOGY, NEW
   EDUCATION
CT 3rd International Conference on Computer Science and Education
CY JUL 25-27, 2008
CL Kaifeng, PEOPLES R CHINA
SP Comp Educ Coll & Univ, China Natl Res Council, Henan Univ China, IEEE Control Syst Chapter, Singapore Sect, IEEE Control Syst Chapter, Beijing Sect, Univ Melbourne Australia, Univ Virginia, Natl Univ Singapore, Xiamen Univ
AB Named entities like person names, place names and organization names occur frequently in bilingual texts such as news papers, web pages etc. Correct translation of named entities help to improve performance of NLP systems in cross-language information retrieval and machine translation. This paper describes an effort towards mining translations of named entities from abundant resources of comparable web pages in the Internet. The maximum likelihood estimation and on DICE coefficient are compared for context modeling. Result shows DICE has better performance for translation mining from web pages.
BN 978-7-5615-3050-4
PY 2008
BP 108
EP 110
UT WOS:000259363100027
ER

PT C
AU Li, J
   Wang, B
AF Li, J
   Wang, B
GP IEEE
TI The automatic extraction of translation patterns and matching algorithm
   in an English-Chinese machine translation system
SO PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON NATURAL
   LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING (IEEE NLP-KE'05)
CT International Conference on Natural Language Processing and Knowledge
   Engineering
CY OCT 30-NOV 01, 2005
CL Wuhan, PEOPLES R CHINA
SP IEEE, AAI, CIPSC, Chinese Assoc Artificial Intelligence, IEEE Signal Proc Soc, IEEE Beijing Sect
AB In this paper, an automatic extraction algorithm of translation patterns between English and Chinese is presented. The patterns are extracted from a bilingual corpus aligned at the sentence level. Before the extraction of translation patterns, the sentences in the corpus will be pre-processed by the rule-based method. In the pattern-based method, a new algorithm of calculating sentence similarity is presented. Based on DP matching algorithm, we design a structure matching algorithm and the pattern matching rule. Then, a semantic similarity algorithm is presented. The experiment shows that the score of translation quality is 68.4 and the accurate rate can reach 88%.
BN 0-7803-9361-9
PY 2005
BP 839
EP 843
UT WOS:000235577200158
ER

PT J
AU Aljlayl, M
   Frieder, O
   Grossman, D
AF Aljlayl, M
   Frieder, O
   Grossman, D
TI On bidirectional English-Arabic search
SO JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY
AB In Cross-Language Information Retrieval (CLIR), queries in one language retrieve relevant documents in other languages. Machine-Readable Dictionaries (MRD) and Machine Translation (MT) systems are important resources for query translation in CLIR. We investigate the use of MT systems and MRD to Arabic-English and English-Arabic CUR. The translation ambiguity associated with these resources is the key problem. We present three methods of query translation using a bilingual dictionary for Arabic-English CUR. First, we present the Every-Match (EM) method. This method yields ambiguous translations because many extraneous terms are added to the original query. To disambiguate query translation, we present the First-Match (FM) method that considers the first match in the dictionary as the candidate term. Finally, we present the Two-Phase (TP) method. We show that good retrieval effectiveness can be achieved without complex resources using the Two-Phase method for Arabic-English CUR. We also empirically evaluate the effectiveness of the Arabic-English MT approach using short, medium, and long queries of TREC7 and TREC9 topics and collections. The effects of the query length to the quality of the MT-based CUR are investigated. English-Arabic CUR is evaluated via MRD and English-Arabic MT. The query expansion via post-translation approach is used to deemphasize the extraneous terms introduced by the MRD and MT for English-Arabic CUR.
SN 1532-2882
EI 1532-2890
PD NOV
PY 2002
VL 53
IS 13
BP 1139
EP 1151
DI 10.1002/asi.10143
UT WOS:000178776600008
ER

PT J
AU Moorkens, J
AF Moorkens, Joss
TI Comparative satisfaction among freelance and directly-employed
   Irish-language translators
SO TRANSLATION & INTERPRETING-THE INTERNATIONAL JOURNAL OF TRANSLATION AND
   INTERPRETING
AB This article reports results of a survey of government-accredited Irish language translators. The survey addresses a particular cohort of minority language translators in a particular linguistic context, where institutional demand for translation is growing. The survey may also be a useful basis for further work on translator job satisfaction. Participants in this survey were passionate about translation and about the Irish language, but conditions of employment clearly affected their concerns and perspectives regarding their profession. All translators report a strong sense of pride in their work, but freelance participants' perceptions of purpose and fairness in work, payment, colleagues, and job security compare poorly to those of their full-time public service colleagues. Freelancers report that they struggle to work together in the face of falling rates, with some accepting low-paying jobs that are against their own and their colleagues' best interests. Many of the freelance participants feel threatened by technology, the potential for machine translation to replace human translators, and their powerlessness regarding translations being repurposed for machine translation training. Responses show a fear of falling translation quality, a lack of translation talent, and the lack of an audience for translation. Participants tend to be negative about domestic Irish language policy but see policy at the EU-level to be beneficial, with forthcoming changes presenting an opportunity for skilled translators.
RI Moorkens, Joss/AAK-6278-2020
OI Moorkens, Joss/0000-0003-0766-0071
SN 1836-9324
PY 2020
VL 12
IS 1
BP 55
EP 73
DI 10.12807/ti.112201.2020.a04
UT WOS:000517830000004
ER

PT C
AU Yasuoka, M
   Bjorn, P
AF Yasuoka, Mika
   Bjorn, Pernille
BE Salmela, H
   Sell, A
TI Difficulties in Establishing Local Language in Machine-Translated
   Mediated Communication
SO NORDIC CONTRIBUTIONS IN IS RESEARCH
SE Lecture Notes in Business Information Processing
CT 2nd Scandinavian Conference on Information Systems
CY AUG 16-19, 2011
CL Turku, FINLAND
AB Establishing common ground is critical in intercultural communication. Still, little is known as for the practice of common ground in machine-translation mediated communication. In this paper, we report some of the critical communication difficulties related to common ground when intercultural communication is mediated by multilingual collaboration systems. Based on empirical investigation of the communication between Japanese and Danish students applying a multilingual communication system, we identify two main challenges influencing common ground: 1) Difficulties in exchanging socio-emotional aspects and 2) Difficulties in developing shared concepts. As theoretical constructs, social context and project jargon, which are known as essential contributors to the construction and the maintenance of common ground, are harnessed to explain such difficulties.
SN 1865-1348
BN 978-3-642-22765-3
PY 2011
VL 86
BP 41
EP +
UT WOS:000301961800006
ER

PT S
AU Richardson, SD
AF Richardson, SD
BE Frederking, RE
   Taylor, KB
TI Machine translation of online product support articles using a
   data-driven MT system
SO MACHINE TRANSLATION: FROM REAL USERS TO RESEARCH, PROCEEDINGS
SE Lecture Notes in Computer Science
CT 6th Conference of the
   Association-for-Machine-Translation-in-the-Americas
CY SEP 28-OCT 02, 2004
CL Washington, DC
SP Assoc Machine Translat Americas
AB At AMTA 2002, we reported on a pilot project to machine translate Microsoft's Product Support Knowledge Base into Spanish. The successful pilot has since resulted in the permanent deployment of both Spanish and Japanese versions of the knowledge base, as well as ongoing pilot projects for French and German. The translated articles in each case have been produced by MSR-MT, Microsoft Research's data-driven MT system, which has been trained on well over a million bilingual sentence pairs for each target language from previously translated materials contained in translation memories and glossaries. This paper describes our experience in deploying this system and the (positive) customer response to the availability of machine translated articles, as well as other uses of MSR-MT either planned or underway at Microsoft.
SN 0302-9743
EI 1611-3349
BN 3-540-23300-8
PY 2004
VL 3265
BP 246
EP 251
UT WOS:000224611600027
ER

PT J
AU Tukeyev, U
   Karibayeva, A
   Zhumanov, ZH
AF Tukeyev, U.
   Karibayeva, A.
   Zhumanov, Z. h
TI Morphological segmentation method for Turkic language neural machine
   translation
SO COGENT ENGINEERING
AB Dictionaries play an important role in neural machine translation (NMT). However, a large dictionary requires a significant amount of memory, which limits the application of NMT and can cause a memory error. This limitation can be solved by segmenting each word into morphemes in parallel source corpora. Therefore, this study introduces a new morphological segmentation approach for Turkic languages based on the complete set of endings (CSE), which reduces the vocabulary volume of the source corpora. Herein, we demonstrate the proposed CSE-based morphological segmentation method for the Kazakh, Kyrgyz, and Uzbek languages and present the results of computational NMT experiments for the Kazakh language. The NMT experiment results show that in comparison with byte-pair encoding (BPE)-based segmentation, the proposed CSE-based segmentation increases the bilingual evaluation understudy score of 0.5 and 0.2 points on average for Kazakh-English and English-Kazakh pairs, respectively. Furthermore, in comparison with the BPE-based segmentation, the proposed CSE-based segmentation approach reduced the vocabulary size in NMT by more than a factor of two. This feature of the proposed segmentation approach will be crucial for NMT as the size of the source corpora is increased to improve translation quality.
OI Zhumanov, Zhandos/0000-0002-0395-9730
SN 2331-1916
PD JAN 1
PY 2020
VL 7
IS 1
AR 1856500
DI 10.1080/23311916.2020.1856500
UT WOS:000597658200001
ER

PT J
AU Taghbalout, I
   Allah, FA
   El Marraki, M
AF Taghbalout, Imane
   Allah, Fadoua Ataa
   El Marraki, Mohamed
TI Towards UNL-based machine translation for Moroccan Amazigh language
SO INTERNATIONAL JOURNAL OF COMPUTATIONAL SCIENCE AND ENGINEERING
AB Amazigh languages, also called Berber, belong to the Afro-Asiatic languages (Hamito-Semitic) family. They are a family of similar and closely related languages and dialects indigenous to North Africa. They are spoken in Morocco, Algeria, and some populations in Libya, Tunisia, northern Mali, western and northern Niger, northern Burkina Faso, Mauritania, and in the Siwa Oasis of Egypt. Large Berber-speaking migrant communities have been living in Western Europe since the 1950s. In this paper, we study the Standard Moroccan Amazigh. It became a constitutionally official language of Morocco, in 2011. However, it is still considered as a less resourced language. So, it is time to develop linguistic resources and applications for processing automatically this language, in order to ensure its survival and promotion by integrating it into the new information and communication technologies (NICT). In this context and in the perspective to produce a Universal Networking Language (UNL) based machine translation system for this language, we have undertaken the creation of the Amazigh-UNL dictionary, as a first step of linguistic resources' development required by the UNL system to achieve translation. Thus, this paper is focused on presenting linguistic features' implementation such as morphological, syntactical and semantic information of the Amazigh language.
SN 1742-7185
EI 1742-7193
PY 2018
VL 17
IS 1
BP 43
EP 54
DI 10.1504/IJCSE.2018.094418
UT WOS:000443613400005
ER

PT C
AU Cui, L
   Zhang, DD
   Liu, SJ
   Chen, QM
   Li, M
   Zhou, M
   Yang, MY
AF Cui, Lei
   Zhang, Dongdong
   Liu, Shujie
   Chen, Qiming
   Li, Mu
   Zhou, Ming
   Yang, Muyun
BE Toutanova, K
   Wu, H
TI Learning Topic Representation for SMT with Neural Networks
SO PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR
   COMPUTATIONAL LINGUISTICS, VOL 1
CT 52nd Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUN 22-27, 2014
CL Baltimore, MD
SP Assoc Computat Linguist, Baidu, Bloomberg, Google, Microsoft, Nuance, Yahoo Labs, Informat Sci Inst, Xerox Res Ctr Europe, Brandeis Univ, Facebook, Yandex, Amazon Com, IBM Watson, Johns Hopkins Univ, A9, AI@ISI, Xerox
AB Statistical Machine Translation (SMT) usually utilizes contextual information to disambiguate translation candidates. However, it is often limited to contexts within sentence boundaries, hence broader topical information cannot be leveraged. In this paper, we propose a novel approach to learning topic representation for parallel data using a neural network architecture, where abundant topical contexts are embedded via topic relevant monolingual data. By associating each translation rule with the topic representation, topic relevant rules are selected according to the distributional similarity with the source text during SMT decoding. Experimental results show that our method significantly improves translation accuracy in the NIST Chinese-to-English translation task compared to a state-of-the-art baseline.
OI Yang, Muyun/0000-0002-5940-0266
BN 978-1-937284-72-5
PY 2014
BP 133
EP 143
UT WOS:000493814100013
ER

PT J
AU Liang, XB
   Wu, LJ
   Li, JT
   Qin, T
   Zhang, M
   Liu, TY
AF Liang, Xiaobo
   Wu, Lijun
   Li, Juntao
   Qin, Tao
   Zhang, Min
   Liu, Tie-Yan
TI Multi-Teacher Distillation With Single Model for Neural Machine
   Translation
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
AB Knowledge distillation (KD) is an effective strategy for neural machine translation (NMT) to improve the performance of a student model. Usually, the teacher can guide the student to be better by distilling the soft label or data knowledge fromthe teacher itself. However, the data diversity and teacher knowledge are limited with only one teacher model. Though a natural solution is to adopt multiple randomized teachermodels, one big shortcoming is that the model parameters and training costs are largely increased with the number of teacher models. In this work, we explore to mimic multiple teacher distillation from the sub-network space and permuted variants of one single teacher model. Specifically, we train a teacher by multiple sub-network extraction paradigms: sub-layer reordering, layer-drop, and dropout variants. In doing so, one teacher model can provide multiple outputs variants and causes neither additional parameters nor much extra training cost. Experiments on 8 IWSLT datasets: IWSLT14 En <-> De, En <-> Es and IWSLT17 En <-> Fr, En <-> Zh and the large WMT14 EN -> DE translation tasks show that our method even achieves nearly comparable performance with multiple teacher models with different randomized parameters, bothword-level and sequence-level knowledge distillation. Our code is available online at https:// github.com/dropreg/ RLD.
OI Qin, Tao/0000-0002-9095-0776; Li, Juntao/0000-0002-6286-7529; Wu,
   Lijun/0000-0002-3530-590X
SN 2329-9290
EI 2329-9304
PY 2022
VL 30
BP 992
EP 1002
DI 10.1109/TASLP.2022.3153264
UT WOS:000766602300004
ER

PT J
AU Turganbayeva, A
   Tukeyev, U
AF Turganbayeva, Aliya
   Tukeyev, Ualsher
TI The solution of the problem of unknown words under neural machine
   translation of the Kazakh language
SO JOURNAL OF INFORMATION AND TELECOMMUNICATION
AB The paper proposes a solution to the problem of unknown words for neural machine translation (NMT). The proposed solution is shown by the example of NMT of the Kazakh-English language pair. The novelty of the proposed technology for solving the problem of unknown words in the NMT of the Kazakh language is an algorithm proposed for searching for unknown words in the dictionary of a trained model of NMT and using the dictionary of synonyms of the Kazakh to replace an unknown word with a word that is close in meaning. A dictionary of synonyms is used to search for words that are similar in meaning to the unknown words, which was defined. Moreover, the found synonyms are checked for the presence in the vocabulary of a trained model. After that, a new translation of the edited sentence of the source language is performed. The base of words-synonyms of the Kazakh language is collected. Software solutions to the unknown word problem have been developed in the Python. The proposed technology solution to the problem of unknown words was tested on the two parallel Kazakh-English corpus in both variants: baseline NMT and NMT with using of the proposed technology.
OI Tukeyev, Ualsher/0000-0001-9878-981X
SN 2475-1839
EI 2475-1847
PD APR 3
PY 2021
VL 5
IS 2
BP 214
EP 225
DI 10.1080/24751839.2020.1838713
UT WOS:000710531400004
ER

PT C
AU Lavernhe, S
   Tournier, C
   Lartigue, C
AF Lavernhe, Sylvain
   Tournier, Christophe
   Lartigue, Claire
BE Tichkiewitch, S
   Tollenaere, M
   Ray, P
TI Kinematic performances in 5-axis machining
SO ADVANCES IN INTEGRATED DESIGN AND MANUFACTURING IN MECHANICAL
   ENGINEERING II
CT 6th International Conference on Integrated Design and Manufacturing in
   Mechanical Engineering
CY MAY 17-19, 2006
CL Inst Natl Polytech Grenoble, Grenoble, FRANCE
SP French AIP PRIMECA Network, Inter Inst Product Workshops, Pole Resources Informat Mecan, Comp Resource Pole Mech
HO Inst Natl Polytech Grenoble
AB This article presents a predictive model of the kinematic behaviour during 5-axis machining. This model highlights differences between the programmed tool-path and the actual follow-up of the trajectory. Within the High Speed Machining context, kinematic limits of the couple CNC-machine-tool have to be taken into account in the model. The originality of the model is the use of the inverse-time method to coordinate machine-tool axes, whatever their nature (translation or rotation). The model reconstructs the actual relative velocity tool-surface from each axis velocity profile highlighting trajectory portions for which cutting conditions are not respected.
RI Tournier, Christophe/J-7403-2013; LAVERNHE, Sylvain/HPC-0753-2023
OI Tournier, Christophe/0000-0003-4153-0836; LAVERNHE,
   Sylvain/0000-0002-6701-4648
BN 978-1-4020-6760-0
PY 2007
BP 489
EP +
DI 10.1007/978-1-4020-6761-7_33
UT WOS:000251416900033
ER

PT C
AU Baraniello, V
   Laura, L
   Naldi, M
AF Baraniello, Vincenzo
   Laura, Luigi
   Naldi, Maurizio
BE DiMascio, T
   Vittorini, P
   Gennari, R
   DeLaPrieta, F
   Rodriguez, S
   Temperini, M
   Silveira, RA
   Popescu, E
   Lancia, L
TI Collaborative Language Learning Through Computer-Assisted Translation on
   a Wiki-Based Platform: Operations and Management
SO METHODOLOGIES AND INTELLIGENT SYSTEMS FOR TECHNOLOGY ENHANCED LEARNING
SE Advances in Intelligent Systems and Computing
CT 8th International Conference in Methodologies and Intelligent Systems
   for Technology Enhanced Learning (MIS4TEL)
CY JUN 20-22, 2018
CL Univ Castilla Mancha, Toledo, SPAIN
SP IBM, Indra, IEEE SMC Spain
HO Univ Castilla Mancha
AB An ongoing project is described that aims at developing a computer-assisted translation tool in collaborative language learning, using a wiki approach. The technology stack makes extensive use of Mediawiki and relies on a Ubuntu-powered machine. The GUI closely resembles the familiar Wikipedia environment. Its integration in the syllabus of a university English language course is illustrated. The use of online surveys as a support tool is also described.
RI Naldi, Maurizio/GXW-3240-2022; Laura, Luigi/A-8970-2010
OI Laura, Luigi/0000-0001-6880-8477
SN 2194-5357
EI 2194-5365
BN 978-3-319-98872-6; 978-3-319-98871-9
PY 2019
VL 804
BP 88
EP 96
DI 10.1007/978-3-319-98872-6_11
UT WOS:000482789200011
ER

PT C
AU Cmejrek, M
   Curin, J
   Havelka, J
AF Cmejrek, M
   Curin, J
   Havelka, J
GP ACL
TI Czech-English dependency-based machine translation
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB We present some preliminary results of a Czech-English translation system based on dependency trees. The fully automated process includes: morphological tagging, analytical and tectogrammatical parsing of Czech, tectogrammatical transfer based on lexical substitution using word-to-word translation dictionaries enhanced by the information from the English-Czech parallel corpus of WSJ, and a simple rule-based system for generation from English tectogrammatical representation. In the evaluation part, we compare results of the fully automated and the manually annotated processes of building the tectogrammatical representation.(1)
RI Havelka, Jiří/D-2212-2013
BN 1-932432-00-0
PY 2003
BP 83
EP 90
UT WOS:000222995200012
ER

PT C
AU Guo, L
   Zhou, ML
   Yao, JM
   Zhu, QM
AF Guo Lei
   Zhou Mei-ling
   Yao Jian-Min
   Zhu Qiao-Ming
BE Li, M
   Yu, F
   Shu, J
   Chen, ZG
TI A Supervised Method for Transliterated Person Name Identification
SO PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE
   AND SECURITY, VOL II
CT 2nd International Symposium on Electronic Commerce and Security
CY MAY 22-24, 2009
CL Nanchang, PEOPLES R CHINA
SP Nanchang HangKong Univ, Peoples Friendship Univ Russia, Nanchang Univ, Jiangxi Normal Univ, Wuhan Univ, Natl Chung Hsing Univ, Chinese Acad Sci, Inst Software, Sichuan Univ, Jiaxing Univ, IEEE Comp Soc, IEEE Comp Soc, Tech Council E Commerce
AB Query translation mining is a key technique in cross-language information retrieval and machine translation knowledge acquisition. For better performance, the queries are classified into transliterated words and non-transliterated words, which can be further channeled to different mining processes. This paper is a pilot study on query classification for better translation mining performance, which is based on supervised classification and linguistic heuristics. The person name identification gets a precision of over 97%.
BN 978-0-7695-3643-9
PY 2009
BP 117
EP 120
DI 10.1109/ISECS.2009.212
UT WOS:000275134400027
ER

PT J
AU Way, A
   Haque, R
   Xie, GD
   Gaspari, F
   Popovic, M
   Poncelas, A
AF Way, Andy
   Haque, Rejwanul
   Xie, Guodong
   Gaspari, Federico
   Popovic, Maja
   Poncelas, Alberto
TI Rapid Development of Competitive Translation Engines for Access to
   Multilingual COVID-19 Information
SO INFORMATICS-BASEL
AB Every day, more people are becoming infected and dying from exposure to COVID-19. Some countries in Europe like Spain, France, the UK and Italy have suffered particularly badly from the virus. Others such as Germany appear to have coped extremely well. Both health professionals and the general public are keen to receive up-to-date information on the effects of the virus, as well as treatments that have proven to be effective. In cases where language is a barrier to access of pertinent information, machine translation (MT) may help people assimilate information published in different languages. Our MT systems trained on COVID-19 data are freely available for anyone to use to help translate information (such as promoting good practice for symptom identification, prevention, and treatment) published in German, French, Italian, Spanish into English, as well as the reverse direction.
RI Xie, Guodong/AAF-5586-2021; Haque, Rejwanul/C-4581-2017
OI Poncelas, Alberto/0000-0002-5089-1687; Way, Andy/0000-0001-5736-5930;
   Haque, Rejwanul/0000-0003-1680-0099
EI 2227-9709
PD JUN
PY 2020
VL 7
IS 2
AR 19
DI 10.3390/informatics7020019
UT WOS:000551252300002
ER

PT J
AU Acheampong, KN
   Tian, WH
AF Acheampong, Kingsley Nketia
   Tian, Wenhong
TI Toward perfect neural cascading architecture for grammatical error
   correction
SO APPLIED INTELLIGENCE
AB Grammatical Error Correction (GEC) is the task of correcting several diverse errors in a text such as spelling, punctuation, morphological, and word choice typos or mistakes. Expressed as a sentence correction task, models such as neural-based sequence-to-sequence (seq2seq) GECs have emerged to offer solutions to the task. However, neural-based seq2seq grammatical error correction models are computationally expensive both in training and in translation inference. Also, they tend to suffer from poor generalization and arrive at inept capabilities due to limited error-corrected data, and thus, incapable of effectively correcting grammar. In this work, we propose the use of Neural Cascading Architecture and different techniques in enhancing the effectiveness of neural sequence-to-sequence grammatical error correction models as inspired by post-editing processes of Neural Machine Translations (NMTs). The findings of our experiments show that, in low-resource NMT models, adapting the presented cascading techniques unleashes performances that is comparable to high setting NMT models, with improvements on state-of-the-art (SOTA) JHU FLuency- Extended GUG corpus (JFLEG) parallel corpus for developing and evaluating GEC model systems. We extensively exploit and evaluate multiple cascading learning strategies and establish best practices toward improving neural seq2seq GECs.
SN 0924-669X
EI 1573-7497
PD JUN
PY 2021
VL 51
IS 6
BP 3775
EP 3788
DI 10.1007/s10489-020-01980-1
EA NOV 2020
UT WOS:000590982200001
ER

PT J
AU Eriguchi, A
   Hashimoto, K
   Tsuruoka, Y
AF Eriguchi, Akiko
   Hashimoto, Kazuma
   Tsuruoka, Yoshimasa
TI Incorporating Source-Side Phrase Structures into Neural Machine
   Translation
SO COMPUTATIONAL LINGUISTICS
AB Neural machine translation (NMT) has shown great success as a new alternative to the traditional Statistical Machine Translation model in multiple languages. Early NMT models are based on sequence-to-sequence learning that encodes a sequence of source words into a vector space and generates another sequence of target words from the vector. In those NMT models, sentences are simply treated as sequences of words without any internal structure. In this article, we focus on the role of the syntactic structure of source sentences and propose a novel end-to-end syntactic NMT model, which we call a tree-to-sequence NMT model, extending a sequence-to-sequence model with the source-side phrase structure. Our proposed model has an attention mechanism that enables the decoder to generate a translated word while softly aligning it with phrases as well as words of the source sentence. We have empirically compared the proposed model with sequence-to-sequence models in various settings on Chinese-to-Japanese and English-to-Japanese translation tasks. Our experimental results suggest that the use of syntactic structure can be beneficial when the training data set is small, but is not as effective as using a bi-directional encoder. As the size of training data set increases, the benefits of using a syntactic tree tends to diminish.
SN 0891-2017
EI 1530-9312
PD JUN
PY 2019
VL 45
IS 2
BP 267
EP 292
DI 10.1162/coli_a_00348
UT WOS:000471703200003
ER

PT C
AU Fan, WT
   Hou, HX
   Wang, HB
   Li, JT
AF Fan, Wenting
   Hou, Hongxu
   Wang, Hongbin
   Li, Jinting
GP Destech Publicat Inc
TI Improve Mongolian-Chinese translation by Introducing SMT Information
   into NMT
SO INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING
   (CSAE)
SE DEStech Transactions on Computer Science and Engineering
CT INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING
   (CSAE)
CY OCT 21-23, 2017
CL Shanghai, PEOPLES R CHINA
AB In this paper, we improved the final accuracy of statistic alignment of phrase-based statistic machine translation (PBSMT) and introduced the improved alignment result into NMT. Moreover, we investigated syntax reordering and data augmentation for improving SMT alignments, which eventually leads to better NMT performance. The experiment results show that applying our approach to Mongolian-Chinese translation demonstrates promising improvements. With annotation alignment and compared to NMT baseline, we obtained up to 2.98 BLEU improvement on the low-resource language pair Mongolian-Chinese.
SN 2475-8841
BN 978-1-60595-505-6
PY 2017
VL 190
BP 209
EP 217
UT WOS:000426973900025
ER

PT J
AU BHARADWAJ, KK
   SRINIVAS, P
AF BHARADWAJ, KK
   SRINIVAS, P
TI TRANSLATION OF PASCAL PROGRAMS FOR EXECUTION ON LISP-BASED MACHINES
SO INFORMATION AND SOFTWARE TECHNOLOGY
AB The paper describes an implementation of source-to-source translation of programs from Pascal to Lisp. First, some motivations are given for doing the work. Then, various problems associated with the translation process are discussed. Many of these problems arise from the radical differences in the control and data structures of the two languages. Finally, some techniques are considered to improve the translated Lisp code that are based on the features of the target language. Even though the work is only experimental, it amply demonstrates the feasibility of extending this approach.
SN 0950-5849
PD JUL
PY 1992
VL 34
IS 7
BP 478
EP 484
DI 10.1016/0950-5849(92)90039-R
UT WOS:A1992JG30200006
ER

PT C
AU Pinnis, M
   Krislauks, R
   Rikters, M
AF Pinnis, Marcis
   Krislauks, Rihards
   Rikters, Matiss
GP Assoc Computat Linguist
TI Tilde's Machine Translation Systems for WMT 2019
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019)
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB The paper describes the development process of Tilde's NMT systems for the WMT 2019 shared task on news translation. We trained systems for the English-Lithuanian and Lithuanian-English translation directions in constrained and unconstrained tracks. We build upon the best methods of the previous year's competition and combine them with recent advancements in the field. We also present a new method to ensure source domain adherence in back-translated data. Our systems achieved a shared first place in human evaluation.
RI Rikters, Matīss/AAW-2142-2021; Pinnis, Mārcis/N-8009-2013
OI Rikters, Matīss/0000-0002-3530-6873; Pinnis, Mārcis/0000-0001-6832-5600
BN 978-1-950737-27-7
PY 2019
BP 327
EP 334
UT WOS:000538566200035
ER

PT C
AU Tong, A
   Przybocki, M
   Margner, V
   El Abed, H
AF Tong, Audrey
   Przybocki, Mark
   Maergner, Volker
   El Abed, Haikal
GP IEEE
TI NIST 2013 Open Handwriting Recognition and Translation (OpenHaRT'13)
   Evaluation
SO 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS
   2014)
CT 11th IAPR International Workshop on Document Analysis Systems (DAS)
CY APR 07-10, 2014
CL Tours, FRANCE
SP ABBYY, Vis Objects, Google, ITESOFT, Arkhenum, A2iA, Spigraph, Valconum, Casden, Reg Ctr, Univ Francois Rabelais Tours, Lab Informatique, IAPR
AB This paper describes the NIST 2013 Open Handwriting Recognition and Translation evaluation (OpenHaRT'13). A short background leading to the start of OpenHaRT is included. The test designs pertaining to the tasks, the data used, the performance measurements, and the protocols are presented. The participants and their submissions are mentioned followed by the evaluation results and some preliminary analyses. The paper concludes with some thoughts toward future evaluations.
RI Abed, Haikal El/M-9771-2013
OI Abed, Haikal El/0000-0002-2292-316X
BN 978-1-4799-3243-6
PY 2014
BP 81
EP 85
DI 10.1109/DAS.2014.43
UT WOS:000356615000017
ER

PT C
AU Liu, W
   Wang, GY
   Fu, JY
   Zou, X
AF Liu, Wen
   Wang, Guoyin
   Fu, Jianyu
   Zou, Xuan
BE Zhao, J
   Iranpour, R
   Li, X
   Jin, B
TI Water Quality Prediction Based on Improved Wavelet Transformation and
   Support Vector Machine
SO ADVANCES IN ENVIRONMENTAL TECHNOLOGIES, PTS 1-6
SE Advanced Materials Research
CT 2nd International Conference on Energy and Environmental Protection
   (ICEEP 2013)
CY APR 19-21, 2013
CL Guilin, PEOPLES R CHINA
SP Inner Mongolia Univ, Chinese Acad Sci, Res Ctr Eco Environm Sci, Key Lab Environm Biotechnol
AB In the process of monitoring water quality, as the transient variable data lead to unsound prediction models and the traditional parameter optimization method based on signal factor experiments is not only time-consuming but also can not ensure the most optimal parameters. We propose to combine wavelet transformation with data translation to reduce the influence of transient variations on prediction models, and use genetic algorithm (GA) to optimize the parameters of support vector machine (SVM). The new prediction model is applied to predict water quality time series, which is compared with the traditional modeling methods based on SVM and BP neural network. The results show that the new model is superior to traditional modeling methods.
RI Fu, JY/GRR-6179-2022
OI Wang, Guoyin/0000-0002-8521-5232
SN 1022-6680
BN 978-3-03785-742-7
PY 2013
VL 726-731
BP 3547
EP +
DI 10.4028/www.scientific.net/AMR.726-731.3547
UT WOS:000333767501203
ER

PT C
AU Kuwabara, K
   Kinomura, S
AF Kuwabara, Kazuhiro
   Kinomura, Shingo
BE Nguyen, NT
   Hoang, K
   Jedrzejowicz, P
TI Mediating Accesses to Multiple Information Sources in a Multi-lingual
   Application
SO COMPUTATIONAL COLLECTIVE INTELLIGENCE - TECHNOLOGIES AND APPLICATIONS,
   PT I
SE Lecture Notes in Computer Science
CT 4th International Conference on Computational Collective Intelligence -
   Technologies and Applications (ICCCI)
CY NOV 28-30, 2012
CL Ho Chi Minh City, VIETNAM
SP Wroclaw Univ Technol Poland, Vietnam Natl Univ, Univ Informat Technol, Polish Acad Sci, Comm Informat, IEEE SMC Tech Comm Computat Collect Intelligence, Natl Fdn Sci & Technol Dev, Inha Univ, Hue Univ
AB This paper describes an approach to mediating accesses to multiple information sources in a multi-lingual application. There are many information sources available on the Internet in different languages, and machine translation services are also available to allow multi-lingual access to information sources. Domain-dependent translation dictionaries are often used to make translation more appropriate. In the proposed approach, the domain-dependent translation dictionaries are represented as linked data. Using the data available from the translation dictionaries, accesses to the information sources that are represented as linked data can be customized. By applying the linked data concept, a multi-lingual application can be constructed in a flexible way.
SN 0302-9743
EI 1611-3349
BN 978-3-642-34630-9
PY 2012
VL 7653
BP 326
EP 334
UT WOS:000340573000034
ER

PT J
AU Shibata, D
   Ito, K
   Nagai, H
   Okahisa, T
   Kinoshita, A
   Aramaki, E
AF Shibata, Daisaku
   Ito, Kaoru
   Nagai, Hiroyuki
   Okahisa, Taro
   Kinoshita, Ayae
   Aramaki, Eiji
TI Idea density in Japanese for the early detection of dementia based on
   narrative speech
SO PLOS ONE
AB Background
   Idea density (ID), a natural language processing-based index, was developed to aid in the detection of dementia through the analysis of English narratives. However, it has not been applied to non-English languages due to the difficulties in translating grammatical concepts. In this study, we defined rules to count ideas in Japanese narratives based on a previous study and proposed a novel method to estimate ID in Japanese text using machine translation.
   Materials
   The study participants comprised 42 Japanese patients with dementia aged 69-98 years (mean: 84.95 years). We collected free narratives from the participants to build a speech corpus. The narratives of the patients were translated into English using three machine translation systems: Google Translate, Bing Translator, and Excite Translator. The ID in the translated text was then calculated using the Dependency-based Propositional ID (DEPID), an English ID scoring tool.
   Results
   The maximum correlation coefficient between ID calculated using DEPID-R-ADD (a modified DEPID method to calculate ID after removing vague sentences) and the Mini-Mental State Examination score was 0.473, indicating a moderate correlation.
   Discussion
   The results demonstrate the feasibility of machine translation-based ID measurement. We believe that the basic concept of this translation approach can be applied to other non-English languages.
OI ARAMAKI, Eiji/0000-0003-0201-3609
SN 1932-6203
PD DEC 5
PY 2018
VL 13
IS 12
AR e0208418
DI 10.1371/journal.pone.0208418
UT WOS:000452212400095
PM 30517200
ER

PT C
AU Chi, ZW
   Dong, L
   Ma, SM
   Huang, SH
   Mao, XL
   Huang, HY
   Wei, FR
AF Chi, Zewen
   Dong, Li
   Ma, Shuming
   Huang, Shaohan
   Mao, Xian-Ling
   Huang, Heyan
   Wei, Furu
GP Assoc Computat Linguist
TI mT6: Multilingual Pretrained Text-to-Text Transformer with Translation
   Pairs
SO 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING
   (EMNLP 2021)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 07-11, 2021
CL Punta Cana, DOMINICAN REP
AB Multilingual T5 (MT5; Xue et al. 2020) pretrains a sequence-to-sequence model on massive monolingual texts, which has shown promising results on many cross-lingual tasks. In this paper, we improve multilingual text-to-text transfer Transformer with translation pairs (MT6). Specifically, we explore three cross-lingual text-to-text pre-training tasks, namely, machine translation, translation pair span corruption, and translation span corruption. In addition, we propose a partially non-autoregressive objective for text-to-text pretraining. We evaluate the methods on eight multilingual benchmark datasets, including sentence classification, named entity recognition, question answering, and abstractive summarization. Experimental results show that the proposed MT6 improves cross-lingual transferability over MT5.
BN 978-1-955917-09-4
PY 2021
BP 1671
EP 1683
UT WOS:000855966301058
ER

PT C
AU Sen, S
   Gupta, KK
   Ekbal, A
   Bhattacharyya, P
AF Sen, Sukanta
   Gupta, Kamal Kumar
   Ekbal, Asif
   Bhattacharyya, Pushpak
GP Assoc Computat Linguist
TI IITP-MT System for Gujarati-English News Translation Task at WMT 2019
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019)
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB We describe our submission to WMT 2019 News translation shared task for Gujarati- English language pair. We submit constrained systems, i.e, we rely on the data provided for this language pair and do not use any external data. We train Transformer based subword-level neural machine translation (NMT) system using original parallel corpus along with synthetic parallel corpus obtained through back-translation of monolingual data. Our primary systems achieve BLEU scores of 10.4 and 8.1 for Gujarati -> English and English -> Gujarati, respectively. We observe that incorporating monolingual data through back-translation improves the BLEU score significantly over baseline NMT and SMT systems for this language pair.
BN 978-1-950737-27-7
PY 2019
BP 407
EP 411
UT WOS:000538566200046
ER

PT C
AU Zbib, R
   Zhao, LJ
   Karakos, D
   Hartmann, W
   DeYoung, J
   Huang, ZQ
   Jiang, ZL
   Rivkin, N
   Zhang, L
   Schwartz, R
   Makhoul, J
AF Zbib, Rabih
   Zhao, Lingjun
   Karakos, Damianos
   Hartmann, William
   DeYoung, Jay
   Huang, Zhongqiang
   Jiang, Zhuolin
   Rivkin, Noah
   Zhang, Le
   Schwartz, Richard
   Makhoul, John
GP ACM
TI Neural-Network Lexical Translation for Cross-lingual IR from Text and
   Speech
SO PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH
   AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19)
CT 42nd Annual International ACM SIGIR Conference on Research and
   Development in Information Retrieval (SIGIR)
CY JUL 21-25, 2019
CL Paris, FRANCE
SP Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval
AB We propose a neural network model to estimate word translation probabilities for Cross-Lingual Information Retrieval (CLIR). The model estimates better probabilities for word translations than automatic word alignments alone, and generalizes to unseen source-target word pairs. We further improve the lexical neural translation model (and subsequently CLIR), by incorporating source word context, and by encoding the character sequences of input source words to generate translations of out-of-vocabulary words. To be effective, neural network models typically need training on large amounts of data labeled directly on the final task, in this case relevance to queries. In contrast, our approach only requires parallel data to train the translation model, and uses an unsupervised model to compute CLIR relevance scores.
   We report results on the retrieval of text and speech documents from three morphologically complex languages with limited training data resources (Swahili, Tagalog, and Somali) and short English queries. Despite training on only about 2M words of parallel training data for each language, we obtain neural network translation models that are very effective for this task. We also obtain further improvements using (i) a modified relevance model, which uses the probability of occurrence of a translation of each query term in the source document, and (ii) confusion networks (instead of 1-best output) that encode multiple transcription alternatives in the output of an Automatic Speech Recognition (ASR) system.
   We achieve overall MAP relative improvements of up to 24% on Swahili, 50% on Tagalog, and 39% on Somali over the baseline probabilistic model, and larger improvements over monolingual retrieval from machine translation output.
RI Zhao, Lingjun/HPE-8072-2023
OI Hartmann, William/0000-0003-1678-3399
BN 978-1-4503-6172-9
PY 2019
BP 645
EP 654
DI 10.1145/3331184.3331222
UT WOS:000501488900067
ER

PT J
AU Day, AR
AF Day, Adam R.
TI Process and truth-table characterisations of randomness
SO THEORETICAL COMPUTER SCIENCE
AB This paper uses quick process machines to provide characterisations of computable randomness, Schnorr randomness and weak randomness. The quick process machine is a type of process machine first considered in work of Levin and Zvonkin. A new technique for building process machines and quick process machines is presented. This technique is similar to the KC theorem for prefix-free machines. Using this technique, a method of translating computable martingales to quick process machines is given. This translation forms the basis for these new randomness characterisations. Quick process machines are also used to provide characterisations of computable randomness. Schnorr randomness, and weak randomness in terms of truth-table reducibility. (c) 2012 Elsevier B.V. All rights reserved.
RI Day, Adam/GQA-5320-2022
SN 0304-3975
PD SEP 21
PY 2012
VL 452
BP 47
EP 55
DI 10.1016/j.tcs.2012.05.028
UT WOS:000307492900005
ER

PT C
AU Pandramish, V
   Sharma, DM
AF Pandramish, Vinay
   Sharma, Dipti Misra
GP Assoc Computat Linguist
TI Checkpoint Reranking: An Approach To Select Better Hypothesis For Neural
   Machine Translation Systems
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020): STUDENT RESEARCH WORKSHOP
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB In this paper, we propose a method of reranking the outputs of Neural Machine Translation (NMT) systems. After the decoding process, we select a few last iteration outputs in the training process as the N-best list. After training a Neural Machine Translation (NMT) baseline system, it has been observed that these iteration outputs have an oracle score higher than baseline up to 1.01 BLEU points compared to the last iteration of the trained system.We come up with a ranking mechanism by solely focusing on the decoder's ability to generate distinct tokens and without the usage of any language model or data. With this method, we achieved a translation improvement up to +0.16 BLEU points over baseline.We also evaluate our approach by applying the coverage penalty to the training process.In cases of moderate coverage penalty, the oracle scores are higher than the final iteration up to +0.99 BLEU points, and our algorithm gives an improvement up to +0.17 BLEU points.With excessive penalty, there is a decrease in translation quality compared to the baseline system. Still, an increase in oracle scores up to +1.30 is observed with the re-ranking algorithm giving an improvement up to +0.15 BLEU points is found in case of excessive penalty.The proposed re-ranking method is a generic one and can be extended to other language pairs as well.
BN 978-1-952148-03-3
PY 2020
BP 286
EP 291
UT WOS:000563380100037
ER

PT C
AU Opitz, D
   Hochgeschwender, N
AF Opitz, Dominik
   Hochgeschwender, Nico
GP IEEE
TI From Zero to Hero: Generating Training Data for Question-To-Cypher
   Models
SO 2022 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON NATURAL LANGUAGE-BASED
   SOFTWARE ENGINEERING (NLBSE 2022)
CT 1st IEEE/ACM International Workshop on Natural Language-Based Software
   Engineering (NLBSE)
CY MAY 08, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, Assoc Comp Machinery
AB Graph databases employ graph structures such as nodes, attributes and edges to model and store relationships among data. To access this data, graph query languages (GQL) such as Cypher are typically used, which might be difficult to master for end-users. In the context of relational databases, sequence to SQL models, which translate natural language questions to SQL queries, have been proposed. While these Neural Machine Translation (NMT) models increase the accessibility of relational databases, NMT models for graph databases are not yet available mainly due to the lack of suitable parallel training data. In this short paper we sketch an architecture which enables the generation of synthetic training data for the graph query language Cypher.
PY 2022
BP 17
EP 20
DI 10.1145/3528588.3528655
UT WOS:000853491600003
ER

PT C
AU Baquero-Arnal, P
   Iranzo-Sanchez, J
   Civera, J
   Juan, A
AF Baquero-Arnal, Pau
   Iranzo-Sanchez, Javier
   Civera, Jorge
   Juan, Alfons
GP Assoc Computat Linguist
TI The MLLP-UPV Spanish-Portuguese and Portuguese-Spanish Machine
   Translation Systems for WMT19 Similar Language Translation Task
SO FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 3: SHARED TASK
   PAPERS, DAY 2
CT 4th Conference on Machine Translation (WMT)
CY AUG 01-02, 2019
CL Florence, ITALY
AB This paper describes the participation of the MLLP research group of the Universitat Politecnica de Valencia in the WMT 2019 Similar Language Translation Shared Task. We have submitted systems for the Portuguese <-> Spanish language pair, in both directions. They are based on the Transformer architecture as well as on a novel architecture called 2D alternating RNN. Both systems have been domain adapted through fine-tuning that has been shown to be very effective.
BN 978-1-950737-27-7
PY 2019
BP 179
EP 184
UT WOS:000538569000023
ER

PT J
AU Ruthven, K
AF Ruthven, Kenneth
TI Resources in translation: towards a conceptual and technical apparatus
SO ZDM-MATHEMATICS EDUCATION
AB In mathematics education, translation of resources from one language to another occurs in a wide range of situations. This paper explores how conceptual and technical apparatus from contemporary translation studies may be of use in guiding and analysing such translation. Key concepts-including those of source, target and intermediate text, of paradigms of equivalence, purpose, uncertainty and localisation, and of semantic, syntactic and epistemological equivalence-are introduced and illustrated, primarily with reference to translation of a series of school mathematics workbooks. Significant types of tool to assist translation-translation protocols and machine translation-are examined. A more detailed case study illustrates techniques (and associated tools) for analysing translation shifts and terminological translatability, applying them to examine translation of documentation of a framework for researching teachers' interaction with resources-the Documentational Approach to Didactics. Specific insights that emerge are how translation is shaped by attention not just to fidelity to the source text but to the audience for, and function of, the target text; and how challenging it can be to formulate terms translatable across languages in such a way as to consistently anchor meaning in existing wordforms.
SN 1863-9690
EI 1863-9704
DI 10.1007/s11858-022-01392-0
EA JUL 2022
UT WOS:000825761100001
ER

PT C
AU Goyal, V
   Kumar, S
   Sharma, DM
AF Goyal, Vikrant
   Kumar, Sourav
   Sharma, Dipti Misra
GP Assoc Computat Linguist
TI Efficient Neural Machine Translation for Low-Resource Languages via
   Exploiting Related Languages
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020): STUDENT RESEARCH WORKSHOP
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB A large percentage of the world's population speaks a language of the Indian subcontinent, comprising languages from both Indo-Aryan (e.g. Hindi, Punjabi, Gujarati, etc.) and Dravidian (e.g. Tamil, Telugu, Malayalam, etc.) families. A universal characteristic of Indian languages is their complex morphology, which, when combined with the general lack of sufficient quantities of high-quality parallel data, can make developing machine translation (MT) systems for these languages difficult. Neural Machine Translation (NMT) is a rapidly advancing MT paradigm and has shown promising results for many language pairs, especially in large training data scenarios. Since the condition of large parallel corpora is not met for Indian-English language pairs, we present our efforts towards building efficient NMT systems between Indian languages (specifically Indo-Aryan languages) and English via efficiently exploiting parallel data from the related languages. We propose a technique called Unified Transliteration and Subword Segmentation to leverage language similarity while exploiting parallel data from related language pairs. We also propose a Multilingual Transfer Learning technique to leverage parallel data from multiple related languages to assist translation for low-resource language pair of interest. Our experiments demonstrate an overall average improvement of 5 BLEU points over the standard Transformer-based NMT baselines.
BN 978-1-952148-03-3
PY 2020
BP 162
EP 168
UT WOS:000563380100021
ER

PT C
AU Lee, J
   Shu, R
   Cho, K
AF Lee, Jason
   Shu, Raphael
   Cho, Kyunghyun
GP Assoc Computat Linguist
TI Iterative Refinement in the Continuous Space for Non-Autoregressive
   Neural Machine Translation
SO PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL
   LANGUAGE PROCESSING (EMNLP)
CT Conference on Empirical Methods in Natural Language Processing (EMNLP)
CY NOV 16-20, 2020
CL ELECTR NETWORK
SP Bloomberg Engn, Google Res, Apple, Amazon Sci, Baidu, Megagon Labs, Facebook, DeepMind, Grammarly, ByteDance, Zeta Alpha, Babelscape, Naver, Adobe, Hitachi, Salesforce, Univ So Calif, Viterbi Sch Engn, Informat Sci Inst
AB We propose an efficient inference procedure for non-autoregressive machine translation that iteratively refines translation purely in the continuous space. Given a continuous latent variable model for machine translation (Shu et al., 2020), we train an inference network to approximate the gradient of the marginal log probability of the target sentence, using only the latent variable as input. This allows us to use gradient-based optimization to find the target sentence at inference time that approximately maximizes its marginal probability. As each refinement step only involves computation in the latent space of low dimensionality (we use 8 in our experiments), we avoid computational overhead incurred by existing non-autoregressive inference procedures that often refine in token space. We compare our approach to a recently proposed EM-like inference procedure (Shu et al., 2020) that optimizes in a hybrid space, consisting of both discrete and continuous variables. We evaluate our approach on WMT'14 En -> De, WMT'16 Ro -> En and IWSLT'16 De -> En, and observe two advantages over the EM-like inference: (1) it is computationally efficient, i.e. each refinement step is twice as fast, and (2) it is more effective, resulting in higher marginal probabilities and BLEU scores with the same number of refinement steps. On WMT'14 En -> De, for instance, our approach is able to decode 6:2 times faster than the autoregressive model with minimal degradation to translation quality (0.9 BLEU).
RI Liu, Jason/HLX-2144-2023; Li, Jishuai/HMW-4412-2023
BN 978-1-952148-60-6
PY 2020
BP 1006
EP 1015
UT WOS:000855160701013
ER

PT J
AU Espla-Gomis, M
   Sanchez-Martinez, F
   Forcada, ML
AF Espla-Gomis, Miquel
   Sanchez-Martinez, Felipe
   Forcada, Mikel L.
TI Using Machine Translation to Provide Target-Language Edit Hints in
   Computer Aided Translation Based on Translation Memories
SO JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH
AB This paper explores the use of general-purpose machine translation (MT) in assisting the users of computer-aided translation (CAT) systems based on translation memory (TM) to identify the target words in the translation proposals that need to be changed (either replaced or removed) or kept unedited, a task we term as word-keeping recommendation. MT is used as a black box to align source and target sub-segments on the fly in the translation units (TUs) suggested to the user. Source-language (SL) and target-language (TL) segments in the matching TUs are segmented into overlapping sub-segments of variable length and machine-translated into the TL and the SL, respectively. The bilingual subsegments obtained and the matching between the SL segment in the TU and the segment to be translated are employed to build the features that are then used by a binary classifier to determine the target words to be changed and those to be kept unedited. In this approach, MT results are never presented to the translator. Two approaches are presented in this work: one using a word-keeping recommendation system which can be trained on the TM used with the CAT system, and a more basic approach which does not require any training.
   Experiments are conducted by simulating the translation of texts in several language pairs with corpora belonging to different domains and using three different MT systems. We compare the performance obtained to that of previous works that have used statistical word alignment for word-keeping recommendation, and show that the MT-based approaches presented in this paper are more accurate in most scenarios. In particular, our results confirm that the MT-based approaches are better than the alignment-based approach when using models trained on out-of-domain TMs. Additional experiments were also performed to check how dependent the MT-based recommender is on the language pair and MT system used for training. These experiments confirm a high degree of reusability of the recommendation models across various MT systems, but a low level of reusability across language pairs.
RI Sánchez-Martínez, Felipe/G-9689-2016; Forcada, Mikel/ABG-9539-2020;
   Esplà-Gomis, Miquel/ABF-8816-2021
OI Sánchez-Martínez, Felipe/0000-0002-2295-2630; Esplà-Gomis,
   Miquel/0000-0002-2682-066X; FORCADA ZUBIZARRETA, Mikel
   L./0000-0003-0843-6442
SN 1076-9757
EI 1943-5037
PY 2015
VL 53
BP 169
EP 222
DI 10.1613/jair.4630
UT WOS:000365176400005
ER

PT S
AU Jones, GJF
   Lam-Adesina, A
AF Jones, GJF
   Lam-Adesina, A
BE Peters, C
   Gonzalo, J
   Braschler, M
   Kluck, M
TI Exeter at CLEF 2003: Cross-language spoken document retrieval
   experiments
SO COMPARATIVE EVALUATION OF MULTILINGUAL INFORMATION ACCESS SYSTEMS
SE Lecture Notes in Computer Science
CT 4th Workshop of the Cross-Language Evaluation Forum (CLEF 2003)
CY AUG 21-22, 2003
CL Trondheim, NORWAY
SP US, Natl Inst Stand & Technol, DELOS, Network Excellence Digit Lib
AB Cross-Language Spoken Document Retrieval (CLSDR) combine's both the complexities of retrieval from collections characterized by speech transcription errors and language translation issues between search requests and documents. Thus achieving effective retrieval in this domain is potentially very challenging. For the CLEF 2003 SDR task we adopted a standard query translation strategy using commercial machine translation tools and explored pseudo-relevance feedback using a small contemporaneous collection and a much larger text collection from a different time period.
SN 0302-9743
EI 1611-3349
BN 3-540-24017-9
PY 2003
VL 3237
BP 653
EP 657
UT WOS:000226159600062
ER

PT J
AU Emeneker, W
   Apon, A
AF Emeneker, Wesley
   Apon, Amy
TI Characterising the performance of cache-aware placement of Virtual
   Machines on a multi-core architecture
SO INTERNATIONAL JOURNAL OF AD HOC AND UBIQUITOUS COMPUTING
AB Virtual machine acceptance and deployment has exploded with the advent of cloud computing. Unfortunately, virtual machines negatively impact application performance. For parallel scientific codes, any negative performance impact is undesirable. This paper presents an initial investigation of performance-impacting machine-level events, comparing the Xen virtual machine to native Linux, and using knowledge of the underlying CPU cache architecture to improve relevant cache behaviour. Several machine-level events are gathered, including translation lookaside buffer misses and cache misses. Results from the experiments show that cache-aware virtual machine placement has a significant impact on scientific applications.
SN 1743-8225
EI 1743-8233
PY 2012
VL 10
IS 2
SI SI
BP 84
EP 95
DI 10.1504/IJAHUC.2012.048260
UT WOS:000307168500004
ER

PT C
AU Gao, YQ
   Nikolov, NL
   Hu, YH
   Hahnloser, RHR
AF Gao, Yingqiang
   Nikolov, Nikola L.
   Hu, Yuhuang
   Hahnloser, Richard H. R.
GP Assoc Computat Linguist
TI Character-Level Translation with Self-attention
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB We explore the suitability of self-attention models for character-level neural machine translation. We test the standard transformer model, as well as a novel variant in which the encoder block combines information from nearby characters using convolutions. We perform extensive experiments on WMT and UN datasets, testing both bilingual and multilingual translation to English using up to three input languages (French, Spanish, and Chinese). Our transformer variant consistently outperforms the standard transformer at the character-level and converges faster while learning more robust character-level alignments.(1)
OI Hahnloser, Richard/0000-0002-4039-7773
BN 978-1-952148-25-5
PY 2020
BP 1591
EP 1604
UT WOS:000570978201080
ER

PT C
AU Gangadharaiah, R
   Brown, RD
   Carbonell, J
AF Gangadharaiah, Rashmi
   Brown, Ralf D.
   Carbonell, Jaime
BE Gelbukh, A
TI Phrasal Equivalence Classes for Generalized Corpus-Based Machine
   Translation
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING, PT II
SE Lecture Notes in Computer Science
CT 12th Annual Conference on Intelligent Text Processing and Computational
   Linguistics
CY FEB 20-26, 2011
CL Tokyo, JAPAN
SP Kayamori Fdn Informat Sci Adv
AB Generalizations of sentence-pairs in Example-based Machine Translation (EBMT) have been shown to increase coverage and translation quality in the past. These template-based approaches (G-EBMT) find common patterns in the bilingual corpus to generate generalized templates. In the past, patterns in the corpus were found by only few of the following ways: finding similar or dissimilar portions of text in groups of sentence-pairs, finding semantically similar words, or use dictionaries and parsers to find syntactic correspondences. This paper combines all the three aspects for generating templates. In this paper, the boundaries for aligning and extracting members (phrase-pairs) for clustering are found using chunkers (hence, syntactic information) trained independently on the two languages under consideration. Then semantically related phrase-pairs are grouped based on the contexts in which they appear. Templates are then constructed by replacing these clustered phrase-pairs by their class labels. We also perform a filtration step by simulating human labelers to obtain only those phrase-pairs that have high correspondences between the source and the target phrases that make up the phrase-pairs. Templates with English-Chinese and English-French language pairs gave significant improvements over a baseline with no templates.
SN 0302-9743
EI 1611-3349
BN 978-3-642-19436-8
PY 2011
VL 6609
BP 13
EP 28
UT WOS:000302000800002
ER

PT C
AU Edunov, S
   Ott, M
   Ranzato, M
   Auli, M
AF Edunov, Sergey
   Ott, Myle
   Ranzato, Marc'Aurelio
   Auli, Michael
GP Assoc Computat Linguist
TI On The Evaluation of Machine Translation Systems Trained With
   Back-Translation
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB Back-translation is a widely used data augmentation technique which leverages target monolingual data. However, its effectiveness has been challenged since automatic metrics such as BLEU only show significant improvements for test examples where the source itself is a translation, or translationese. This is believed to be due to translationese inputs better matching the back-translated training data. In this work, we show that this conjecture is not empirically supported and that back-translation improves translation quality of both naturally occurring text as well as translationese according to professional human translators. We provide empirical evidence to support the view that back-translation is preferred by humans because it produces more fluent outputs. BLEU cannot capture human preferences because references are translationese when source sentences are natural text. We recommend complementing BLEU with a language model score to measure fluency.
BN 978-1-952148-25-5
PY 2020
BP 2836
EP 2846
UT WOS:000570978203013
ER

PT C
AU Li, GH
   Li, XH
   Xu, B
AF Li, Gaohe
   Li, Xinhao
   Xu, Bo
GP IEEE
TI Numerical Simulation Technology Study on Automatic Translation of
   Foreign Language Images Based on Tesseract-ORC
SO 2019 INTERNATIONAL CONFERENCE ON ROBOTS & INTELLIGENT SYSTEM (ICRIS
   2019)
SE IEEE International Conference on Intelligent Robots and Systems
CT International Conference on Robots and Intelligent System (ICRIS)
CY JUN 15-16, 2019
CL Haikou, PEOPLES R CHINA
SP Hainan Univ, Hainan Trop Ocean Univ, Cent S Univ
AB First of all, Tesseract OCR technology is used to automatically identify English words on the picture, including English words in the horizontal direction, vertical direction and a certain tilt Angle direction on the picture. Then, the automatic translation system is used to translate English words into Chinese words. Finally, OpenCV technology is used to automatically fill the translated Chinese words into the corresponding position in the English of the original picture, replace the original English words, and realize the automatic recognition and translation of foreign words in the picture. This research greatly improves the efficiency of machine translation. The research content of the project can also be applied to the automatic translation of images between any other languages.
SN 2153-0858
BN 978-1-7281-2632-6
PY 2019
BP 86
EP 89
DI 10.1109/ICRIS.2019.00030
UT WOS:000568616800021
ER

EF